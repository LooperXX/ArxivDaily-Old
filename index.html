 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-08">2021-07-08</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DORA: Toward Policy Optimization for Task-oriented Dialogue System with Efficient Context. (arXiv:2107.03286v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1">Hyunmin Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gary Geunbae Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03286">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, reinforcement learning (RL) has been applied to task-oriented
dialogue systems by using latent actions to solve shortcomings of supervised
learning (SL). In this paper, we propose a multi-domain task-oriented dialogue
system, called Dialogue System with Optimizing a Recurrent Action Policy using
Efficient Context (DORA), that uses SL, with subsequently applied RL to
optimize dialogue systems using a recurrent dialogue policy. This dialogue
policy recurrently generates explicit system actions as a both word-level and
high-level policy. As a result, DORA is clearly optimized during both SL and RL
steps by using an explicit system action policy that considers an efficient
context instead of the entire dialogue history. The system actions are both
interpretable and controllable, whereas the latent actions are not. DORA
improved the success rate by 6.6 points on MultiWOZ 2.0 and by 10.9 points on
MultiWOZ 2.1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification. (arXiv:2007.15823v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garbacea_C/0/1/0/all/0/1">Cristina Garbacea</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mengtian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carton_S/0/1/0/all/0/1">Samuel Carton</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15823">
                                    <div class="article-summary-box-inner">
                                        <span>Text simplification reduces the language complexity of professional content
for accessibility purposes. End-to-end neural network models have been widely
adopted to directly generate the simplified version of input text, usually
functioning as a blackbox. We show that text simplification can be decomposed
into a compact pipeline of tasks to ensure the transparency and explainability
of the process. The first two steps in this pipeline are often neglected: 1) to
predict whether a given piece of text needs to be simplified, and 2) if yes, to
identify complex parts of the text. The two tasks can be solved separately
using either lexical or deep learning methods, or solved jointly. Simply
applying explainable complexity prediction as a preliminary step, the
out-of-sample text simplification performance of the state-of-the-art,
black-box simplification models can be improved by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interventional Video Grounding with Dual Contrastive Learning. (arXiv:2106.11013v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nan_G/0/1/0/all/0/1">Guoshun Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1">Rui Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1">Sicong Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11013">
                                    <div class="article-summary-box-inner">
                                        <span>Video grounding aims to localize a moment from an untrimmed video for a given
textual query. Existing approaches focus more on the alignment of visual and
language stimuli with various likelihood-based matching or regression
strategies, i.e., P(Y|X). Consequently, these models may suffer from spurious
correlations between the language and video features due to the selection bias
of the dataset. 1) To uncover the causality behind the model and data, we first
propose a novel paradigm from the perspective of the causal inference, i.e.,
interventional video grounding (IVG) that leverages backdoor adjustment to
deconfound the selection bias based on structured causal model (SCM) and
do-calculus P(Y|do(X)). Then, we present a simple yet effective method to
approximate the unobserved confounder as it cannot be directly sampled from the
dataset. 2) Meanwhile, we introduce a dual contrastive learning approach (DCL)
to better align the text and video by maximizing the mutual information (MI)
between query and video clips, and the MI between start/end frames of a target
moment and the others within a video to learn more informative visual
representations. Experiments on three standard benchmarks show the
effectiveness of our approaches. Our code is available on GitHub:
https://github.com/nanguoshun/IVG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trans4E: Link Prediction on Scholarly Knowledge Graphs. (arXiv:2107.03297v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayyeri_M/0/1/0/all/0/1">Mojtaba Nayyeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Cil_G/0/1/0/all/0/1">Gokce Muge Cil</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahdati_S/0/1/0/all/0/1">Sahar Vahdati</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_F/0/1/0/all/0/1">Francesco Osborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahfuzur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Angioni_S/0/1/0/all/0/1">Simone Angioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Salatino_A/0/1/0/all/0/1">Angelo Salatino</a>, <a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1">Diego Reforgiato Recupero</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilyeva_N/0/1/0/all/0/1">Nadezhda Vassilyeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Motta_E/0/1/0/all/0/1">Enrico Motta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1">Jens Lehmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03297">
                                    <div class="article-summary-box-inner">
                                        <span>The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the
quality of AI-based services. In the scholarly domain, KGs describing research
publications typically lack important information, hindering our ability to
analyse and predict research dynamics. In recent years, link prediction
approaches based on Knowledge Graph Embedding models became the first aid for
this issue. In this work, we present Trans4E, a novel embedding model that is
particularly fit for KGs which include N to M relations with N$\gg$M. This is
typical for KGs that categorize a large number of entities (e.g., research
articles, patents, persons) according to a relatively small set of categories.
Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry
DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the
information about Fields of Study (e.g., &#x27;neural networks&#x27;, &#x27;machine learning&#x27;,
&#x27;artificial intelligence&#x27;), and affiliation types (e.g., &#x27;education&#x27;,
&#x27;company&#x27;, &#x27;government&#x27;), improving the scope and accuracy of the resulting
data. We evaluated our approach against alternative solutions on AIDA, MAG, and
four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms
the other models when using low embedding dimensions and obtains competitive
results in high dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text2App: A Framework for Creating Android Apps from Text Descriptions. (arXiv:2104.08301v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Masum Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrab_K/0/1/0/all/0/1">Kazi Sajeed Mehrab</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1">Wasi Uddin Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahriyar_R/0/1/0/all/0/1">Rifat Shahriyar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08301">
                                    <div class="article-summary-box-inner">
                                        <span>We present Text2App -- a framework that allows users to create functional
Android applications from natural language specifications. The conventional
method of source code generation tries to generate source code directly, which
is impractical for creating complex software. We overcome this limitation by
transforming natural language into an abstract intermediate formal language
representing an application with a substantially smaller number of tokens. The
intermediate formal representation is then compiled into target source codes.
This abstraction of programming details allows seq2seq networks to learn
complex application structures with less overhead. In order to train sequence
models, we introduce a data synthesis method grounded in a human survey. We
demonstrate that Text2App generalizes well to unseen combination of app
components and it is capable of handling noisy natural language instructions.
We explore the possibility of creating applications from highly abstract
instructions by coupling our system with GPT-3 -- a large pretrained language
model. We perform an extensive human evaluation and identify the capabilities
and limitations of our system. The source code, a ready-to-run demo notebook,
and a demo video are publicly available at
\url{https://github.com/text2app/Text2App}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Over a Decade of Social Opinion Mining: A Systematic Review. (arXiv:2012.03091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cortis_K/0/1/0/all/0/1">Keith Cortis</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_B/0/1/0/all/0/1">Brian Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03091">
                                    <div class="article-summary-box-inner">
                                        <span>Social media popularity and importance is on the increase due to people using
it for various types of social interaction across multiple channels. This
systematic review focuses on the evolving research area of Social Opinion
Mining, tasked with the identification of multiple opinion dimensions, such as
subjectivity, sentiment polarity, emotion, affect, sarcasm and irony, from
user-generated content represented across multiple social media platforms and
in various media formats, like text, image, video and audio. Through Social
Opinion Mining, natural language can be understood in terms of the different
opinion dimensions, as expressed by humans. This contributes towards the
evolution of Artificial Intelligence which in turn helps the advancement of
several real-world use cases, such as customer service and decision making. A
thorough systematic review was carried out on Social Opinion Mining research
which totals 485 published studies and spans a period of twelve years between
2007 and 2018. The in-depth analysis focuses on the social media platforms,
techniques, social datasets, language, modality, tools and technologies, and
other aspects derived. Social Opinion Mining can be utilised in many
application areas, ranging from marketing, advertising and sales for
product/service management, and in multiple domains and industries, such as
politics, technology, finance, healthcare, sports and government. The latest
developments in Social Opinion Mining beyond 2018 are also presented together
with future research directions, with the aim of leaving a wider academic and
societal impact in several real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition. (arXiv:2106.05642v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Binbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhendong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wenjing Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xin Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05642">
                                    <div class="article-summary-box-inner">
                                        <span>The unified streaming and non-streaming two-pass (U2) end-to-end model for
speech recognition has shown great performance in terms of streaming
capability, accuracy, real-time factor (RTF), and latency. In this paper, we
present U2++, an enhanced version of U2 to further improve the accuracy. The
core idea of U2++ is to use the forward and the backward information of the
labeling sequences at the same time at training to learn richer information,
and combine the forward and backward prediction at decoding to give more
accurate recognition results. We also proposed a new data augmentation method
called SpecSub to help the U2++ model to be more accurate and robust. Our
experiments show that, compared with U2, U2++ shows faster convergence at
training, better robustness to the decoding method, as well as consistent 5\% -
8\% word error rate reduction gain over U2. On the experiment of AISHELL-1, we
achieve a 4.63\% character error rate (CER) with a non-streaming setup and
5.05\% with a streaming setup with 320ms latency by U2++. To the best of our
knowledge, 5.05\% is the best-published streaming result on the AISHELL-1 test
set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Representation Models for Text Classification with AutoML Tools. (arXiv:2106.12798v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brandle_S/0/1/0/all/0/1">Sebastian Br&#xe4;ndle</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanussek_M/0/1/0/all/0/1">Marc Hanussek</a>, <a href="http://arxiv.org/find/cs/1/au:+Blohm_M/0/1/0/all/0/1">Matthias Blohm</a>, <a href="http://arxiv.org/find/cs/1/au:+Kintz_M/0/1/0/all/0/1">Maximilien Kintz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12798">
                                    <div class="article-summary-box-inner">
                                        <span>Automated Machine Learning (AutoML) has gained increasing success on tabular
data in recent years. However, processing unstructured data like text is a
challenge and not widely supported by open-source AutoML tools. This work
compares three manually created text representations and text embeddings
automatically created by AutoML tools. Our benchmark includes four popular
open-source AutoML tools and eight datasets for text classification purposes.
The results show that straightforward text representations perform better than
AutoML tools with automatically created text embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Assignment of Radiology Examination Protocols Using Pre-trained Language Models with Knowledge Distillation. (arXiv:2009.00694v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lau_W/0/1/0/all/0/1">Wilson Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Aaltonen_L/0/1/0/all/0/1">Laura Aaltonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunn_M/0/1/0/all/0/1">Martin Gunn</a>, <a href="http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1">Meliha Yetisgen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00694">
                                    <div class="article-summary-box-inner">
                                        <span>Selecting radiology examination protocol is a repetitive, and time-consuming
process. In this paper, we present a deep learning approach to automatically
assign protocols to computer tomography examinations, by pre-training a
domain-specific BERT model ($BERT_{rad}$). To handle the high data imbalance
across exam protocols, we used a knowledge distillation approach that
up-sampled the minority classes through data augmentation. We compared
classification performance of the described approach with the statistical
n-gram models using Support Vector Machine (SVM), Gradient Boosting Machine
(GBM), and Random Forest (RF) classifiers, as well as the Google&#x27;s
$BERT_{base}$ model. SVM, GBM and RF achieved macro-averaged F1 scores of 0.45,
0.45, and 0.6 while $BERT_{base}$ and $BERT_{rad}$ achieved 0.61 and 0.63.
Knowledge distillation improved overall performance on the minority classes,
achieving a F1 score of 0.66.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustifying Multi-hop QA through Pseudo-Evidentiality Training. (arXiv:2107.03242v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyungjae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Seung-won Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Sang-eun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dohyeon Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03242">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the bias problem of multi-hop question answering models,
of answering correctly without correct reasoning. One way to robustify these
models is by supervising to not only answer right, but also with right
reasoning chains. An existing direction is to annotate reasoning chains to
train models, requiring expensive additional annotations. In contrast, we
propose a new approach to learn evidentiality, deciding whether the answer
prediction is supported by correct evidences, without such annotations.
Instead, we compare counterfactual changes in answer confidence with and
without evidence sentences, to generate &quot;pseudo-evidentiality&quot; annotations. We
validate our proposed model on an original set and challenge set in HotpotQA,
showing that our method is accurate and robust in multi-hop reasoning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plot and Rework: Modeling Storylines for Visual Storytelling. (arXiv:2105.06950v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1">Chi-Yang Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1">Yun-Wei Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Ting-Hao &#x27;Kenneth&#x27; Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ku_L/0/1/0/all/0/1">Lun-Wei Ku</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06950">
                                    <div class="article-summary-box-inner">
                                        <span>Writing a coherent and engaging story is not easy. Creative writers use their
knowledge and worldview to put disjointed elements together to form a coherent
storyline, and work and rework iteratively toward perfection. Automated visual
storytelling (VIST) models, however, make poor use of external knowledge and
iterative generation when attempting to create stories. This paper introduces
PR-VIST, a framework that represents the input image sequence as a story graph
in which it finds the best path to form a storyline. PR-VIST then takes this
path and learns to generate the final story via an iterative training process.
This framework produces stories that are superior in terms of diversity,
coherence, and humanness, per both automatic and human evaluations. An ablation
study shows that both plotting and reworking contribute to the model&#x27;s
superiority.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fibrational Initial Algebra-Final Coalgebra Coincidence over Initial Algebras: Turning Verification Witnesses Upside Down. (arXiv:2105.04817v2 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kori_M/0/1/0/all/0/1">Mayuko Kori</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasuo_I/0/1/0/all/0/1">Ichiro Hasuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Katsumata_S/0/1/0/all/0/1">Shin-ya Katsumata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04817">
                                    <div class="article-summary-box-inner">
                                        <span>The coincidence between initial algebras (IAs) and final coalgebras (FCs) is
a phenomenon that underpins various important results in theoretical computer
science. In this paper, we identify a general fibrational condition for the
IA-FC coincidence, namely in the fiber over an initial algebra in the base
category. Identifying (co)algebras in a fiber as (co)inductive predicates, our
fibrational IA-FC coincidence allows one to use coinductive witnesses (such as
invariants) for verifying inductive properties (such as liveness). Our general
fibrational theory features the technical condition of stability of chain
colimits; we extend the framework to the presence of a monadic effect, too,
restricting to fibrations of complete lattice-valued predicates. Practical
benefits of our categorical theory are exemplified by new &quot;upside-down&quot; witness
notions for three verification problems: probabilistic liveness, and acceptance
and model-checking with respect to bottom-up tree automata.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear-time calculation of the expected sum of edge lengths in random projective linearizations of trees. (arXiv:2107.03277v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alemany_Puig_L/0/1/0/all/0/1">Llu&#xed;s Alemany-Puig</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1">Ramon Ferrer-i-Cancho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03277">
                                    <div class="article-summary-box-inner">
                                        <span>The syntactic structure of a sentence is often represented using syntactic
dependency trees. The sum of the distances between syntactically related words
has been in the limelight for the past decades. Research on dependency
distances led to the formulation of the principle of dependency distance
minimization whereby words in sentences are ordered so as to minimize that sum.
Numerous random baselines have been defined to carry out related quantitative
studies on languages. The simplest random baseline is the expected value of the
sum in unconstrained random permutations of the words in the sentence, namely
when all the shufflings of the words of a sentence are allowed and equally
likely. Here we focus on a popular baseline: random projective permutations of
the words of the sentence, that is, permutations where the syntactic dependency
structure is projective, a formal constraint that sentences satisfy often in
languages. Thus far, the expectation of the sum of dependency distances in
random projective shufflings of a sentence has been estimated approximately
with a Monte Carlo procedure whose cost is of the order of $Zn$, where $n$ is
the number of words of the sentence and $Z$ is the number of samples; the
larger $Z$, the lower the error of the estimation but the larger the time cost.
Here we present formulae to compute that expectation without error in time of
the order of $n$. Furthermore, we show that star trees maximize it, and devise
a dynamic programming algorithm to retrieve the trees that minimize it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vocabulary Learning via Optimal Transport for Machine Translation. (arXiv:2012.15671v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chun Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zaixiang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15671">
                                    <div class="article-summary-box-inner">
                                        <span>The choice of token vocabulary affects the performance of machine
translation. This paper aims to figure out what is a good vocabulary and
whether one can find the optimal vocabulary without trial training. To answer
these questions, we first provide an alternative understanding of the role of
vocabulary from the perspective of information theory. Motivated by this, we
formulate the quest of vocabularization -- finding the best token dictionary
with a proper size -- as an optimal transport (OT) problem. We propose VOLT, a
simple and efficient solution without trial training. Empirical results show
that VOLT outperforms widely-used vocabularies in diverse scenarios, including
WMT-14 English-German and TED&#x27;s 52 translation directions. For example, VOLT
achieves almost 70% vocabulary size reduction and 0.5 BLEU gain on
English-German translation. Also, compared to BPE-search, VOLT reduces the
search time from 384 GPU hours to 30 GPU hours on English-German translation.
Codes are available at https://github.com/Jingjing-NLP/VOLT .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Training Instance Selection for Few-Shot Neural Text Generation. (arXiv:2107.03176v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xiaoyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_H/0/1/0/all/0/1">Hui-Syuan Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03176">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretrained language models have led to dramatic improvements in
text generation. Impressive performance can be achieved by finetuning only on a
small number of instances (few-shot setting). Nonetheless, almost all previous
work simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. In this work, we present a study on training
instance selection in few-shot neural text generation. The selection decision
is made based only on the unlabeled data so as to identify the most worthwhile
data points that should be annotated under some budget of labeling cost. Based
on the intuition that the few-shot training instances should be diverse and
representative of the entire data distribution, we propose a simple selection
strategy with K-means clustering. We show that even with the naive
clustering-based approach, the generation models consistently outperform random
sampling on three text generation tasks: data-to-text generation, document
summarization and question generation. We hope that this work will call for
more attention on this largely unexplored area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lemmatization of Historical Old Literary Finnish Texts in Modern Orthography. (arXiv:2107.03266v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hamalainen_M/0/1/0/all/0/1">Mika H&#xe4;m&#xe4;l&#xe4;inen</a>, <a href="http://arxiv.org/find/cs/1/au:+Partanen_N/0/1/0/all/0/1">Niko Partanen</a>, <a href="http://arxiv.org/find/cs/1/au:+Alnajjar_K/0/1/0/all/0/1">Khalid Alnajjar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03266">
                                    <div class="article-summary-box-inner">
                                        <span>Texts written in Old Literary Finnish represent the first literary work ever
written in Finnish starting from the 16th century. There have been several
projects in Finland that have digitized old publications and made them
available for research use. However, using modern NLP methods in such data
poses great challenges. In this paper we propose an approach for simultaneously
normalizing and lemmatizing Old Literary Finnish into modern spelling. Our best
model reaches to 96.3\% accuracy in texts written by Agricola and 87.7\%
accuracy in other contemporary out-of-domain text. Our method has been made
freely available on Zenodo and Github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MACCIF-TDNN: Multi aspect aggregation of channel and context interdependence features in TDNN-based speaker verification. (arXiv:2107.03104v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fangyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhigang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hongchen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Bo Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03104">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the recent state-of-the-art results for speaker verification are
achieved by X-vector and its subsequent variants. In this paper, we propose a
new network architecture which aggregates the channel and context
interdependence features from multi aspect based on Time Delay Neural Network
(TDNN). Firstly, we use the SE-Res2Blocks as in ECAPA-TDNN to explicitly model
the channel interdependence to realize adaptive calibration of channel
features, and process local context features in a multi-scale way at a more
granular level compared with conventional TDNN-based methods. Secondly, we
explore to use the encoder structure of Transformer to model the global context
interdependence features at an utterance level which can capture better long
term temporal characteristics. Before the pooling layer, we aggregate the
outputs of SE-Res2Blocks and Transformer encoder to leverage the complementary
channel and context interdependence features learned by themself respectively.
Finally, instead of performing a single attentive statistics pooling, we also
find it beneficial to extend the pooling method in a multi-head way which can
discriminate features from multiple aspect. The proposed MACCIF-TDNN
architecture can outperform most of the state-of-the-art TDNN-based systems on
VoxCeleb1 test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Extrapolation for Attribute-Enhanced Generation. (arXiv:2107.02968v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Alvin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Madani_A/0/1/0/all/0/1">Ali Madani</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1">Ben Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Naik_N/0/1/0/all/0/1">Nikhil Naik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Text Classification of Urdu News using Deep Neural Network. (arXiv:2107.03141v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Javed_T/0/1/0/all/0/1">Taimoor Ahmed Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_W/0/1/0/all/0/1">Waseem Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Arshad_U/0/1/0/all/0/1">Umair Arshad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03141">
                                    <div class="article-summary-box-inner">
                                        <span>Digital text is increasing day by day on the internet. It is very challenging
to classify a large and heterogeneous collection of data, which require
improved information processing methods to organize text. To classify large
size of corpus, one common approach is to use hierarchical text classification,
which aims to classify textual data in a hierarchical structure. Several
approaches have been proposed to tackle classification of text but most of the
research has been done on English language. This paper proposes a deep learning
model for hierarchical text classification of news in Urdu language -
consisting of 51,325 sentences from 8 online news websites belonging to the
following genres: Sports; Technology; and Entertainment. The objectives of this
paper are twofold: (1) to develop a large human-annotated dataset of news in
Urdu language for hierarchical text classification; and (2) to classify Urdu
news hierarchically using our proposed model based on LSTM mechanism named as
Hierarchical Multi-layer LSTMs (HMLSTM). Our model consists of two modules:
Text Representing Layer, for obtaining text representation in which we use
Word2vec embedding to transform the words to vector and Urdu Hierarchical LSTM
Layer (UHLSTML) an end-to-end fully connected deep LSTMs network to perform
automatic feature learning, we train one LSTM layer for each level of the class
hierarchy. We have performed extensive experiments on our self created dataset
named as Urdu News Dataset for Hierarchical Text Classification (UNDHTC). The
result shows that our proposed method is very effective for hierarchical text
classification and it outperforms baseline methods significantly and also
achieved good results as compare to deep neural model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bayer_M/0/1/0/all/0/1">Markus Bayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufhold_M/0/1/0/all/0/1">Marc-Andr&#xe9; Kaufhold</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_C/0/1/0/all/0/1">Christian Reuter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03158">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation, the artificial creation of training data for machine
learning by transformations, is a widely studied research field across machine
learning disciplines. While it is useful for increasing the generalization
capabilities of a model, it can also address many other challenges and
problems, from overcoming a limited amount of training data over regularizing
the objective to limiting the amount data used to protect privacy. Based on a
precise description of the goals and applications of data augmentation (C1) and
a taxonomy for existing works (C2), this survey is concerned with data
augmentation methods for textual classification and aims to achieve a concise
and comprehensive overview for researchers and practitioners (C3). Derived from
the taxonomy, we divided more than 100 methods into 12 different groupings and
provide state-of-the-art references expounding which methods are highly
promising (C4). Finally, research perspectives that may constitute a building
block for future work are given (C5).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SinSpell: A Comprehensive Spelling Checker for Sinhala. (arXiv:2107.02983v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liyanapathirana_U/0/1/0/all/0/1">Upuli Liyanapathirana</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunasinghe_K/0/1/0/all/0/1">Kaumini Gunasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Dias_G/0/1/0/all/0/1">Gihan Dias</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02983">
                                    <div class="article-summary-box-inner">
                                        <span>We have built SinSpell, a comprehensive spelling checker for the Sinhala
language which is spoken by over 16 million people, mainly in Sri Lanka.
However, until recently, Sinhala had no spelling checker with acceptable
coverage. Sinspell is still the only open source Sinhala spelling checker.
SinSpell identifies possible spelling errors and suggests corrections. It also
contains a module which auto-corrects evident errors. To maintain accuracy,
SinSpell was designed as a rule-based system based on Hunspell. A set of words
was compiled from several sources and verified. These were divided into
morphological classes, and the valid roots, suffixes and prefixes for each
class were identified, together with lists of irregular words and exceptions.
The errors in a corpus of Sinhala documents were analysed and commonly
misspelled words and types of common errors were identified. We found that the
most common errors were in vowel length and similar sounding letters. Errors
due to incorrect typing and encoding were also found. This analysis was used to
develop the suggestion generator and auto-corrector.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advancing CTC-CRF Based End-to-End Speech Recognition with Wordpieces and Conformers. (arXiv:2107.03007v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1">Huahuan Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_W/0/1/0/all/0/1">Wenjie Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Ou_Z/0/1/0/all/0/1">Zhijian Ou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jinsong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03007">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition systems have been largely improved in the past
few decades and current systems are mainly hybrid-based and end-to-end-based.
The recently proposed CTC-CRF framework inherits the data-efficiency of the
hybrid approach and the simplicity of the end-to-end approach. In this paper,
we further advance CTC-CRF based ASR technique with explorations on modeling
units and neural architectures. Specifically, we investigate techniques to
enable the recently developed wordpiece modeling units and Conformer neural
networks to be succesfully applied in CTC-CRFs. Experiments are conducted on
two English datasets (Switchboard, Librispeech) and a German dataset from
CommonVoice. Experimental results suggest that (i) Conformer can improve the
recognition performance significantly; (ii) Wordpiece-based systems perform
slightly worse compared with phone-based systems for the target language with a
low degree of grapheme-phoneme correspondence (e.g. English), while the two
systems can perform equally strong when such degree of correspondence is high
for the target language (e.g. German).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Answering Chinese Elementary School Social Study Multiple Choice Questions. (arXiv:2107.02893v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chao-Chun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_K/0/1/0/all/0/1">Keh-Yih Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02893">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach to answer the Chinese elementary school Social
Study Multiple Choice questions. Although BERT has demonstrated excellent
performance on Reading Comprehension tasks, it is found not good at handling
some specific types of questions, such as Negation, All-of-the-above, and
None-of-the-above. We thus propose a novel framework to cascade BERT with a
Pre-Processor and an Answer-Selector modules to tackle the above challenges.
Experimental results show the proposed approach effectively improves the
performance of BERT, and thus demonstrate the feasibility of supplementing BERT
with additional modules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Transformer for Direct Speech Translation. (arXiv:2107.03069v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alastruey_B/0/1/0/all/0/1">Belen Alastruey</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1">Gerard I. G&#xe1;llego</a>, <a href="http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1">Marta R. Costa-juss&#xe0;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03069">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of Transformer-based models has surpassed the barriers of text.
When working with speech, we must face a problem: the sequence length of an
audio input is not suitable for the Transformer. To bypass this problem, a
usual approach is adding strided convolutional layers, to reduce the sequence
length before using the Transformer. In this paper, we propose a new approach
for direct Speech Translation, where thanks to an efficient Transformer we can
work with a spectrogram without having to use convolutional layers before the
Transformer. This allows the encoder to learn directly from the spectrogram and
no information is lost. We have created an encoder-decoder model, where the
encoder is an efficient Transformer -- the Longformer -- and the decoder is a
traditional Transformer decoder. Our results, which are close to the ones
obtained with the standard approach, show that this is a promising research
direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MedGPT: Medical Concept Prediction from Clinical Narratives. (arXiv:2107.03134v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kraljevic_Z/0/1/0/all/0/1">Zeljko Kraljevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Shek_A/0/1/0/all/0/1">Anthony Shek</a>, <a href="http://arxiv.org/find/cs/1/au:+Bean_D/0/1/0/all/0/1">Daniel Bean</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendayan_R/0/1/0/all/0/1">Rebecca Bendayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Teo_J/0/1/0/all/0/1">James Teo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1">Richard Dobson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03134">
                                    <div class="article-summary-box-inner">
                                        <span>The data available in Electronic Health Records (EHRs) provides the
opportunity to transform care, and the best way to provide better care for one
patient is through learning from the data available on all other patients.
Temporal modelling of a patient&#x27;s medical history, which takes into account the
sequence of past events, can be used to predict future events such as a
diagnosis of a new disorder or complication of a previous or existing disorder.
While most prediction approaches use mostly the structured data in EHRs or a
subset of single-domain predictions and outcomes, we present MedGPT a novel
transformer-based pipeline that uses Named Entity Recognition and Linking tools
(i.e. MedCAT) to structure and organize the free text portion of EHRs and
anticipate a range of future medical events (initially disorders). Since a
large portion of EHR data is in text form, such an approach benefits from a
granular and detailed view of a patient while introducing modest additional
noise. MedGPT effectively deals with the noise and the added granularity, and
achieves a precision of 0.344, 0.552 and 0.640 (vs LSTM 0.329, 0.538 and 0.633)
when predicting the top 1, 3 and 5 candidate future disorders on real world
hospital data from King&#x27;s College Hospital, London, UK (\textasciitilde600k
patients). We also show that our model captures medical knowledge by testing it
on an experimental medical multiple choice question answering task, and by
examining the attentional focus of the model using gradient-based saliency
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Natural Language Processing for Unstructured Data in Electronic Health Records: a Review. (arXiv:2107.02975v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1">Irene Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jessica Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldwasser_J/0/1/0/all/0/1">Jeremy Goldwasser</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_N/0/1/0/all/0/1">Neha Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1">Wai Pan Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuzumlali_M/0/1/0/all/0/1">Muhammed Yavuz Nuzumlal&#x131;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosand_B/0/1/0/all/0/1">Benjamin Rosand</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Matthew Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">David Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_R/0/1/0/all/0/1">R. Andrew Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Krumholz_H/0/1/0/all/0/1">Harlan M. Krumholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1">Dragomir Radev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02975">
                                    <div class="article-summary-box-inner">
                                        <span>Electronic health records (EHRs), digital collections of patient healthcare
events and observations, are ubiquitous in medicine and critical to healthcare
delivery, operations, and research. Despite this central role, EHRs are
notoriously difficult to process automatically. Well over half of the
information stored within EHRs is in the form of unstructured text (e.g.
provider notes, operation reports) and remains largely untapped for secondary
use. Recently, however, newer neural network and deep learning approaches to
Natural Language Processing (NLP) have made considerable advances,
outperforming traditional statistical and rule-based systems on a variety of
tasks. In this survey paper, we summarize current neural NLP methods for EHR
applications. We focus on a broad scope of tasks, namely, classification and
prediction, word embeddings, extraction, generation, and other topics such as
question answering, phenotyping, knowledge graphs, medical dialogue,
multilinguality, interpretability, etc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1">Danny Tarlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time-Aware Ancient Chinese Text Translation and Inference. (arXiv:2107.03179v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiue_Y/0/1/0/all/0/1">Yow-Ting Shiue</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_H/0/1/0/all/0/1">Hui-Syuan Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03179">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we aim to address the challenges surrounding the translation
of ancient Chinese text: (1) The linguistic gap due to the difference in eras
results in translations that are poor in quality, and (2) most translations are
missing the contextual information that is often very crucial to understanding
the text. To this end, we improve upon past translation techniques by proposing
the following: We reframe the task as a multi-label prediction task where the
model predicts both the translation and its particular era. We observe that
this helps to bridge the linguistic gap as chronological context is also used
as auxiliary information. % As a natural step of generalization, we pivot on
the modern Chinese translations to generate multilingual outputs. %We show
experimentally the efficacy of our framework in producing quality translation
outputs and also validate our framework on a collected task-specific parallel
corpus. We validate our framework on a parallel corpus annotated with
chronology information and show experimentally its efficacy in producing
quality translation outputs. We release both the code and the data
https://github.com/orina1123/time-aware-ancient-text-translation for future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Dialogue Summarization: Recent Advances and New Frontiers. (arXiv:2107.03175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xiachong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xiaocheng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03175">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of dialogue systems and natural language generation
techniques, the resurgence of dialogue summarization has attracted significant
research attentions, which aims to condense the original dialogue into a
shorter version covering salient information. However, there remains a lack of
comprehensive survey for this task. To this end, we take the first step and
present a thorough review of this research field. In detail, we provide an
overview of publicly available research datasets, summarize existing works
according to the domain of input dialogue as well as organize leaderboards
under unified metrics. Furthermore, we discuss some future directions and give
our thoughts. We hope that this first survey of dialogue summarization can
provide the community with a quick access and a general picture to this task
and motivate future researches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Android Security using NLP Techniques: A Review. (arXiv:2107.03072v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1">Sevil Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Can_B/0/1/0/all/0/1">Burcu Can</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03072">
                                    <div class="article-summary-box-inner">
                                        <span>Android is among the most targeted platform by attackers. While attackers are
improving their techniques, traditional solutions based on static and dynamic
analysis have been also evolving. In addition to the application code, Android
applications have some metadata that could be useful for security analysis of
applications. Unlike traditional application distribution mechanisms, Android
applications are distributed centrally in mobile markets. Therefore, beside
application packages, such markets contain app information provided by app
developers and app users. The availability of such useful textual data together
with the advancement in Natural Language Processing (NLP) that is used to
process and understand textual data has encouraged researchers to investigate
the use of NLP techniques in Android security. Especially, security solutions
based on NLP have accelerated in the last 5 years and proven to be useful. This
study reviews these proposals and aim to explore possible research directions
for future studies by presenting state-of-the-art in this domain. We mainly
focus on NLP-based solutions under four categories: description-to-behaviour
fidelity, description generation, privacy and malware detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EchoEA: Echo Information between Entities and Relations for Entity Alignment. (arXiv:2107.03054v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xueyuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+E_H/0/1/0/all/0/1">Haihong E</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Wenyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haoran Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03054">
                                    <div class="article-summary-box-inner">
                                        <span>Entity alignment (EA) is to discover entities referring to the same object in
the real world from different knowledge graphs (KGs). It plays an important
role in automatically integrating KGs from multiple sources.

Existing knowledge graph embedding (KGE) methods based on Graph Neural
Networks (GNNs) have achieved promising results, which enhance entity
representation with relation information unidirectionally. Besides, more and
more methods introduce semi-supervision to ask for more labeled training data.

However, two challenges still exist in these methods: (1) Insufficient
interaction: The interaction between entities and relations is insufficiently
utilized. (2) Low-quality bootstrapping: The generated semi-supervised data is
of low quality.

In this paper, we propose a novel framework, Echo Entity Alignment (EchoEA),
which leverages self-attention mechanism to spread entity information to
relations and echo back to entities. The relation representation is dynamically
computed from entity representation. Symmetrically, the next entity
representation is dynamically calculated from relation representation, which
shows sufficient interaction.

Furthermore, we propose attribute-combined bi-directional global-filtered
strategy (ABGS) to improve bootstrapping, reduce false samples and generate
high-quality training data.

The experimental results on three real-world cross-lingual datasets are
stable at around 96\% at hits@1 on average, showing that our approach not only
significantly outperforms the state-of-the-art methods, but also is universal
and transferable for existing KGE methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Question Answering over Knowledge Graphs with Neural Machine Translation and Entity Linking. (arXiv:2107.02865v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diomedi_D/0/1/0/all/0/1">Daniel Diomedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogan_A/0/1/0/all/0/1">Aidan Hogan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02865">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of Question Answering over Knowledge Graphs (KGQA) is to find
answers for natural language questions over a knowledge graph. Recent KGQA
approaches adopt a neural machine translation (NMT) approach, where the natural
language question is translated into a structured query language. However, NMT
suffers from the out-of-vocabulary problem, where terms in a question may not
have been seen during training, impeding their translation. This issue is
particularly problematic for the millions of entities that large knowledge
graphs describe. We rather propose a KGQA approach that delegates the
processing of entities to entity linking (EL) systems. NMT is then used to
create a query template with placeholders that are filled by entities
identified in an EL phase. Slot filling is used to decide which entity fills
which placeholder. Experiments for QA over Wikidata show that our approach
outperforms pure NMT: while there remains a strong dependence on having seen
similar query templates during training, errors relating to entities are
greatly reduced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kosp2e: Korean Speech to English Translation Corpus. (arXiv:2107.02875v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1">Won Ik Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seok Min Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Hyunchang Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Nam Soo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02875">
                                    <div class="article-summary-box-inner">
                                        <span>Most speech-to-text (S2T) translation studies use English speech as a source,
which makes it difficult for non-English speakers to take advantage of the S2T
technologies. For some languages, this problem was tackled through corpus
construction, but the farther linguistically from English or the more
under-resourced, this deficiency and underrepresentedness becomes more
significant. In this paper, we introduce kosp2e (read as &#x60;kospi&#x27;), a corpus
that allows Korean speech to be translated into English text in an end-to-end
manner. We adopt open license speech recognition corpus, translation corpus,
and spoken language corpora to make our dataset freely available to the public,
and check the performance through the pipeline and training-based approaches.
Using pipeline and various end-to-end schemes, we obtain the highest BLEU of
21.3 and 18.0 for each based on the English hypothesis, validating the
feasibility of our data. We plan to supplement annotations for other target
languages through community contributions in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic Modeling in the Voynich Manuscript. (arXiv:2107.02858v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sterneck_R/0/1/0/all/0/1">Rachel Sterneck</a>, <a href="http://arxiv.org/find/cs/1/au:+Polish_A/0/1/0/all/0/1">Annie Polish</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowern_C/0/1/0/all/0/1">Claire Bowern</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02858">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents the results of investigations using topic modeling of
the Voynich Manuscript (Beinecke MS408). Topic modeling is a set of
computational methods which are used to identify clusters of subjects within
text. We use latent dirichlet allocation, latent semantic analysis, and
nonnegative matrix factorization to cluster Voynich pages into &#x60;topics&#x27;. We
then compare the topics derived from the computational models to clusters
derived from the Voynich illustrations and from paleographic analysis. We find
that computationally derived clusters match closely to a conjunction of scribe
and subject matter (as per the illustrations), providing further evidence that
the Voynich Manuscript contains meaningful text.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparative Study of Modular and Joint Approaches for Speaker-Attributed ASR on Monaural Long-Form Audio. (arXiv:2107.02852v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1">Naoyuki Kanda</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_X/0/1/0/all/0/1">Xiong Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_T/0/1/0/all/0/1">Tianyan Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Gaur_Y/0/1/0/all/0/1">Yashesh Gaur</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xiaofei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1">Zhong Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yoshioka_T/0/1/0/all/0/1">Takuya Yoshioka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02852">
                                    <div class="article-summary-box-inner">
                                        <span>Speaker-attributed automatic speech recognition (SA-ASR) is a task to
recognize &quot;who spoke what&quot; from multi-talker recordings. An SA-ASR system
usually consists of multiple modules such as speech separation, speaker
diarization and ASR. On the other hand, considering the joint optimization, an
end-to-end (E2E) SA-ASR model has recently been proposed with promising results
on simulation data. In this paper, we present our recent study on the
comparison of such modular and joint approaches towards SA-ASR on real monaural
recordings. We develop state-of-the-art SA-ASR systems for both modular and
joint approaches by leveraging large-scale training data, including 75 thousand
hours of ASR training data and the VoxCeleb corpus for speaker representation
learning. We also propose a new pipeline that performs the E2E SA-ASR model
after speaker clustering. Our evaluation on the AMI meeting corpus reveals that
after fine-tuning with a small real data, the joint system performs 9.2--29.4%
better in accuracy compared to the best modular system while the modular system
performs better before such fine-tuning. We also conduct various error analyses
to show the remaining issues for the monaural SA-ASR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantically Controllable Scene Generation with Guidance of Explicit Knowledge. (arXiv:2106.04066v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenhao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eun_K/0/1/0/all/0/1">Kim Ji Eun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04066">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Generative Models (DGMs) are known for their superior capability in
generating realistic data. Extending purely data-driven approaches, recent
specialized DGMs may satisfy additional controllable requirements such as
embedding a traffic sign in a driving scene, by manipulating patterns
\textit{implicitly} in the neuron or feature level. In this paper, we introduce
a novel method to incorporate domain knowledge \textit{explicitly} in the
generation process to achieve semantically controllable scene generation. We
categorize our knowledge into two types to be consistent with the composition
of natural scenes, where the first type represents the property of objects and
the second type represents the relationship among objects. We then propose a
tree-structured generative model to learn complex scene representation, whose
nodes and edges are naturally corresponding to the two types of knowledge
respectively. Knowledge can be explicitly integrated to enable semantically
controllable scene generation by imposing semantic rules on properties of nodes
and edges in the tree structure. We construct a synthetic example to illustrate
the controllability and explainability of our method in a clean setting. We
further extend the synthetic example to realistic autonomous vehicle driving
environments and conduct extensive experiments to show that our method
efficiently identifies adversarial traffic scenes against different
state-of-the-art 3D point cloud segmentation models satisfying the traffic
rules specified as the explicit knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on Components Segmentation Task of Document Photos. (arXiv:2106.08499v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Junior_C/0/1/0/all/0/1">Celso A. M. Lopes Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1">Ricardo B. das Neves Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezerra_B/0/1/0/all/0/1">Byron L. D. Bezerra</a>, <a href="http://arxiv.org/find/cs/1/au:+Toselli_A/0/1/0/all/0/1">Alejandro H. Toselli</a>, <a href="http://arxiv.org/find/cs/1/au:+Impedovo_D/0/1/0/all/0/1">Donato Impedovo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08499">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the short-term competition on Components Segmentation
Task of Document Photos that was prepared in the context of the 16th
International Conference on Document Analysis and Recognition (ICDAR 2021).
This competition aims to bring together researchers working on the filed of
identification document image processing and provides them a suitable benchmark
to compare their techniques on the component segmentation task of document
images. Three challenge tasks were proposed entailing different segmentation
assignments to be performed on a provided dataset. The collected data are from
several types of Brazilian ID documents, whose personal information was
conveniently replaced. There were 16 participants whose results obtained for
some or all the three tasks show different rates for the adopted metrics, like
Dice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning
models were applied by the entrants with diverse strategies to achieve the best
results in each of the tasks. Obtained results show that the current applied
methods for solving one of the proposed tasks (document boundary detection) are
already well stablished. However, for the other two challenge tasks (text zone
and handwritten sign detection) research and development of more robust
approaches are still required to achieve acceptable results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Shape Completion via IMLE. (arXiv:2106.16237v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_H/0/1/0/all/0/1">Himanshu Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Saurabh Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shichong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_Amiri_A/0/1/0/all/0/1">Ali Mahdavi-Amiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16237">
                                    <div class="article-summary-box-inner">
                                        <span>Shape completion is the problem of completing partial input shapes such as
partial scans. This problem finds important applications in computer vision and
robotics due to issues such as occlusion or sparsity in real-world data.
However, most of the existing research related to shape completion has been
focused on completing shapes by learning a one-to-one mapping which limits the
diversity and creativity of the produced results. We propose a novel multimodal
shape completion technique that is effectively able to learn a one-to-many
mapping and generates diverse complete shapes. Our approach is based on the
conditional Implicit MaximumLikelihood Estimation (IMLE) technique wherein we
condition our inputs on partial 3D point clouds. We extensively evaluate our
approach by comparing it to various baselines both quantitatively and
qualitatively. We show that our method is superior to alternatives in terms of
completeness and diversity of shapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interflow: Aggregating Multi-layer Feature Mappings with Attention Mechanism. (arXiv:2106.14073v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhicheng Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14073">
                                    <div class="article-summary-box-inner">
                                        <span>Traditionally, CNN models possess hierarchical structures and utilize the
feature mapping of the last layer to obtain the prediction output. However, it
can be difficulty to settle the optimal network depth and make the middle
layers learn distinguished features. This paper proposes the Interflow
algorithm specially for traditional CNN models. Interflow divides CNNs into
several stages according to the depth and makes predictions by the feature
mappings in each stage. Subsequently, we input these prediction branches into a
well-designed attention module, which learns the weights of these prediction
branches, aggregates them and obtains the final output. Interflow weights and
fuses the features learned in both shallower and deeper layers, making the
feature information at each stage processed reasonably and effectively,
enabling the middle layers to learn more distinguished features, and enhancing
the model representation ability. In addition, Interflow can alleviate gradient
vanishing problem, lower the difficulty of network depth selection, and lighten
possible over-fitting problem by introducing attention mechanism. Besides, it
can avoid network degradation as a byproduct. Compared with the original model,
the CNN model with Interflow achieves higher test accuracy on multiple
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Face Hallucination via Split-Attention in Split-Attention Network. (arXiv:2010.11575v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanduo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Junjun Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11575">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, convolutional neural networks (CNNs) have been widely employed to
promote the face hallucination due to the ability to predict high-frequency
details from a large number of samples. However, most of them fail to take into
account the overall facial profile and fine texture details simultaneously,
resulting in reduced naturalness and fidelity of the reconstructed face, and
further impairing the performance of downstream tasks (e.g., face detection,
facial recognition). To tackle this issue, we propose a novel external-internal
split attention group (ESAG), which encompasses two paths responsible for
facial structure information and facial texture details, respectively. By
fusing the features from these two paths, the consistency of facial structure
and the fidelity of facial details are strengthened at the same time. Then, we
propose a split-attention in split-attention network (SISN) to reconstruct
photorealistic high-resolution facial images by cascading several ESAGs.
Experimental results on face hallucination and face recognition unveil that the
proposed method not only significantly improves the clarity of hallucinated
faces, but also encourages the subsequent face recognition performance
substantially. Codes have been released at
https://github.com/mdswyz/SISN-Face-Hallucination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning. (arXiv:2105.12085v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Mingde Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zichao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yifeng Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range and short-range temporal modeling are two complementary and
crucial aspects of video recognition. Most of the state-of-the-arts focus on
short-range spatio-temporal modeling and then average multiple snippet-level
predictions to yield the final video-level prediction. Thus, their video-level
prediction does not consider spatio-temporal features of how video evolves
along the temporal dimension. In this paper, we introduce a novel Dynamic
Segment Aggregation (DSA) module to capture relationship among snippets. To be
more specific, we attempt to generate a dynamic kernel for a convolutional
operation to aggregate long-range temporal information among adjacent snippets
adaptively. The DSA module is an efficient plug-and-play module and can be
combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform
powerful long-range modeling with minimal overhead. The final video
architecture, coined as DSANet. We conduct extensive experiments on several
video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400,
Something-Something V1 and ActivityNet) to show its superiority. Our proposed
DSA module is shown to benefit various video recognition models significantly.
For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is
improved from 74.9% to 78.2% on Kinetics-400. Codes are available at
https://github.com/whwu95/DSANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KaFiStO: A Kalman Filtering Framework for Stochastic Optimization. (arXiv:2107.03331v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davtyan_A/0/1/0/all/0/1">Aram Davtyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sameni_S/0/1/0/all/0/1">Sepehr Sameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerkezi_L/0/1/0/all/0/1">Llukman Cerkezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Meishvilli_G/0/1/0/all/0/1">Givi Meishvilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielski_A/0/1/0/all/0/1">Adam Bielski</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1">Paolo Favaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03331">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization is often cast as a deterministic problem, where the solution is
found through some iterative procedure such as gradient descent. However, when
training neural networks the loss function changes over (iteration) time due to
the randomized selection of a subset of the samples. This randomization turns
the optimization problem into a stochastic one. We propose to consider the loss
as a noisy observation with respect to some reference optimum. This
interpretation of the loss allows us to adopt Kalman filtering as an optimizer,
as its recursive formulation is designed to estimate unknown parameters from
noisy measurements. Moreover, we show that the Kalman Filter dynamical model
for the evolution of the unknown parameters can be used to capture the gradient
dynamics of advanced methods such as Momentum and Adam. We call this stochastic
optimization method KaFiStO. KaFiStO is an easy to implement, scalable, and
efficient method to train neural networks. We show that it also yields
parameter estimates that are on par with or better than existing optimization
algorithms across several neural network architectures and machine learning
tasks, such as computer vision and language modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Alternative Practice of Tropical Convolution to Traditional Convolutional Neural Networks. (arXiv:2103.02096v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1">Shiqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liying_L/0/1/0/all/0/1">Liu Liying</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Ye Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02096">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been used in many machine learning
fields. In practical applications, the computational cost of convolutional
neural networks is often high with the deepening of the network and the growth
of data volume, mostly due to a large amount of multiplication operations of
floating-point numbers in convolution operations. To reduce the amount of
multiplications, we propose a new type of CNNs called Tropical Convolutional
Neural Networks (TCNNs) which are built on tropical convolutions in which the
multiplications and additions in conventional convolutional layers are replaced
by additions and min/max operations respectively. In addition, since tropical
convolution operators are essentially nonlinear operators, we expect TCNNs to
have higher nonlinear fitting ability than conventional CNNs. In the
experiments, we test and analyze several different architectures of TCNNs for
image classification tasks in comparison with similar-sized conventional CNNs.
The results show that TCNN can achieve higher expressive power than ordinary
convolutional layers on the MNIST and CIFAR10 image data set. In different
noise environments, there are wins and losses in the robustness of TCNN and
ordinary CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interventional Video Grounding with Dual Contrastive Learning. (arXiv:2106.11013v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nan_G/0/1/0/all/0/1">Guoshun Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1">Rui Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1">Sicong Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11013">
                                    <div class="article-summary-box-inner">
                                        <span>Video grounding aims to localize a moment from an untrimmed video for a given
textual query. Existing approaches focus more on the alignment of visual and
language stimuli with various likelihood-based matching or regression
strategies, i.e., P(Y|X). Consequently, these models may suffer from spurious
correlations between the language and video features due to the selection bias
of the dataset. 1) To uncover the causality behind the model and data, we first
propose a novel paradigm from the perspective of the causal inference, i.e.,
interventional video grounding (IVG) that leverages backdoor adjustment to
deconfound the selection bias based on structured causal model (SCM) and
do-calculus P(Y|do(X)). Then, we present a simple yet effective method to
approximate the unobserved confounder as it cannot be directly sampled from the
dataset. 2) Meanwhile, we introduce a dual contrastive learning approach (DCL)
to better align the text and video by maximizing the mutual information (MI)
between query and video clips, and the MI between start/end frames of a target
moment and the others within a video to learn more informative visual
representations. Experiments on three standard benchmarks show the
effectiveness of our approaches. Our code is available on GitHub:
https://github.com/nanguoshun/IVG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Architecture Pruning for Transfer Learning. (arXiv:2107.03375v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colombo_N/0/1/0/all/0/1">Nicolo Colombo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03375">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new gradient-based approach for extracting sub-architectures
from a given large model. Contrarily to existing pruning methods, which are
unable to disentangle the network architecture and the corresponding weights,
our architecture-pruning scheme produces transferable new structures that can
be successfully retrained to solve different tasks. We focus on a
transfer-learning setup where architectures can be trained on a large data set
but very few data points are available for fine-tuning them on new tasks. We
define a new gradient-based algorithm that trains architectures of arbitrarily
low complexity independently from the attached weights. Given a search space
defined by an existing large neural model, we reformulate the architecture
search task as a complexity-penalized subset-selection problem and solve it
through a two-temperature relaxation scheme. We provide theoretical convergence
guarantees and validate the proposed transfer-learning strategy on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An automatic multi-tissue human fetal brain segmentation benchmark using the Fetal Tissue Annotation Dataset. (arXiv:2010.15526v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Payette_K/0/1/0/all/0/1">Kelly Payette</a>, <a href="http://arxiv.org/find/eess/1/au:+Dumast_P/0/1/0/all/0/1">Priscille de Dumast</a>, <a href="http://arxiv.org/find/eess/1/au:+Kebiri_H/0/1/0/all/0/1">Hamza Kebiri</a>, <a href="http://arxiv.org/find/eess/1/au:+Ezhov_I/0/1/0/all/0/1">Ivan Ezhov</a>, <a href="http://arxiv.org/find/eess/1/au:+Paetzold_J/0/1/0/all/0/1">Johannes C. Paetzold</a>, <a href="http://arxiv.org/find/eess/1/au:+Shit_S/0/1/0/all/0/1">Suprosanna Shit</a>, <a href="http://arxiv.org/find/eess/1/au:+Iqbal_A/0/1/0/all/0/1">Asim Iqbal</a>, <a href="http://arxiv.org/find/eess/1/au:+Khan_R/0/1/0/all/0/1">Romesa Khan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kottke_R/0/1/0/all/0/1">Raimund Kottke</a>, <a href="http://arxiv.org/find/eess/1/au:+Grehten_P/0/1/0/all/0/1">Patrice Grehten</a>, <a href="http://arxiv.org/find/eess/1/au:+Ji_H/0/1/0/all/0/1">Hui Ji</a>, <a href="http://arxiv.org/find/eess/1/au:+Lanczi_L/0/1/0/all/0/1">Levente Lanczi</a>, <a href="http://arxiv.org/find/eess/1/au:+Nagy_M/0/1/0/all/0/1">Marianna Nagy</a>, <a href="http://arxiv.org/find/eess/1/au:+Beresova_M/0/1/0/all/0/1">Monika Beresova</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_T/0/1/0/all/0/1">Thi Dao Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Natalucci_G/0/1/0/all/0/1">Giancarlo Natalucci</a>, <a href="http://arxiv.org/find/eess/1/au:+Karayannis_T/0/1/0/all/0/1">Theofanis Karayannis</a>, <a href="http://arxiv.org/find/eess/1/au:+Menze_B/0/1/0/all/0/1">Bjoern Menze</a>, <a href="http://arxiv.org/find/eess/1/au:+Cuadra_M/0/1/0/all/0/1">Meritxell Bach Cuadra</a>, <a href="http://arxiv.org/find/eess/1/au:+Jakab_A/0/1/0/all/0/1">Andras Jakab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15526">
                                    <div class="article-summary-box-inner">
                                        <span>It is critical to quantitatively analyse the developing human fetal brain in
order to fully understand neurodevelopment in both normal fetuses and those
with congenital disorders. To facilitate this analysis, automatic multi-tissue
fetal brain segmentation algorithms are needed, which in turn requires open
databases of segmented fetal brains. Here we introduce a publicly available
database of 50 manually segmented pathological and non-pathological fetal
magnetic resonance brain volume reconstructions across a range of gestational
ages (20 to 33 weeks) into 7 different tissue categories (external
cerebrospinal fluid, grey matter, white matter, ventricles, cerebellum, deep
grey matter, brainstem/spinal cord). In addition, we quantitatively evaluate
the accuracy of several automatic multi-tissue segmentation algorithms of the
developing human fetal brain. Four research groups participated, submitting a
total of 10 algorithms, demonstrating the benefits the database for the
development of automatic algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification. (arXiv:2006.04150v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guile Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1">Shaogang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04150">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has been successful for many computer vision tasks due to the
availability of shared and centralised large-scale training data. However,
increasing awareness of privacy concerns poses new challenges to deep learning,
especially for human subject related recognition such as person
re-identification (Re-ID). In this work, we solve the Re-ID problem by
decentralised learning from non-shared private training data distributed at
multiple user sites of independent multi-domain label spaces. We propose a
novel paradigm called Federated Person Re-Identification (FedReID) to construct
a generalisable global model (a central server) by simultaneously learning with
multiple privacy-preserved local models (local clients). Specifically, each
local client receives global model updates from the server and trains a local
model using its local data independent from all the other clients. Then, the
central server aggregates transferrable local model updates to construct a
generalisable global feature embedding model without accessing local data so to
preserve local privacy. This client-server collaborative learning process is
iteratively performed under privacy control, enabling FedReID to realise
decentralised learning without sharing distributed data nor collecting any
centralised data. Extensive experiments on ten Re-ID benchmarks show that
FedReID achieves compelling generalisation performance beyond any locally
trained models without using shared training data, whilst inherently protects
the privacy of each local client. This is uniquely advantageous over
contemporary Re-ID methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partial 3D Object Retrieval using Local Binary QUICCI Descriptors and Dissimilarity Tree Indexing. (arXiv:2107.03368v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blokland_B/0/1/0/all/0/1">Bart Iver van Blokland</a>, <a href="http://arxiv.org/find/cs/1/au:+Theoharis_T/0/1/0/all/0/1">Theoharis Theoharis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03368">
                                    <div class="article-summary-box-inner">
                                        <span>A complete pipeline is presented for accurate and efficient partial 3D object
retrieval based on Quick Intersection Count Change Image (QUICCI) binary local
descriptors and a novel indexing tree. It is shown how a modification to the
QUICCI query descriptor makes it ideal for partial retrieval. An indexing
structure called Dissimilarity Tree is proposed which can significantly
accelerate searching the large space of local descriptors; this is applicable
to QUICCI and other binary descriptors. The index exploits the distribution of
bits within descriptors for efficient retrieval. The retrieval pipeline is
tested on the artificial part of SHREC&#x27;16 dataset with near-ideal retrieval
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-VAE: Learning Disentangled View-common and View-peculiar Visual Representations for Multi-view Clustering. (arXiv:2106.11232v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yazhou Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Huayi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_X/0/1/0/all/0/1">Xiaorong Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaofeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Ming Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11232">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view clustering, a long-standing and important research problem,
focuses on mining complementary information from diverse views. However,
existing works often fuse multiple views&#x27; representations or handle clustering
in a common feature space, which may result in their entanglement especially
for visual representations. To address this issue, we present a novel VAE-based
multi-view clustering framework (Multi-VAE) by learning disentangled visual
representations. Concretely, we define a view-common variable and multiple
view-peculiar variables in the generative model. The prior of view-common
variable obeys approximately discrete Gumbel Softmax distribution, which is
introduced to extract the common cluster factor of multiple views. Meanwhile,
the prior of view-peculiar variable follows continuous Gaussian distribution,
which is used to represent each view&#x27;s peculiar visual factors. By controlling
the mutual information capacity to disentangle the view-common and
view-peculiar representations, continuous visual information of multiple views
can be separated so that their common discrete cluster information can be
effectively mined. Experimental results demonstrate that Multi-VAE enjoys the
disentangled and explainable visual representations, while obtaining superior
clustering performance compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Deep Neural Network Saliency Visualizations with Gradual Extrapolation. (arXiv:2104.04945v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Szandala_T/0/1/0/all/0/1">Tomasz Szandala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04945">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, an enhancement technique for the class activation mapping
methods such as gradient-weighted class activation maps or excitation
backpropagation is proposed to present the visual explanations of decisions
from convolutional neural network-based models. The proposed idea, called
Gradual Extrapolation, can supplement any method that generates a heatmap
picture by sharpening the output. Instead of producing a coarse localization
map that highlights the important predictive regions in the image, the proposed
method outputs the specific shape that most contributes to the model output.
Thus, the proposed method improves the accuracy of saliency maps. The effect
has been achieved by the gradual propagation of the crude map obtained in the
deep layer through all preceding layers with respect to their activations. In
validation tests conducted on a selected set of images, the faithfulness,
interpretability, and applicability of the method are evaluated. The proposed
technique significantly improves the localization detection of the neural
networks attention at low additional computational costs. Furthermore, the
proposed method is applicable to a variety deep neural network models. The code
for the method can be found at
https://github.com/szandala/gradual-extrapolation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model. (arXiv:2010.13118v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lienen_J/0/1/0/all/0/1">Julian Lienen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>, <a href="http://arxiv.org/find/cs/1/au:+Nommensen_N/0/1/0/all/0/1">Nils Nommensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13118">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world applications, the relative depth of objects in an image is
crucial for scene understanding. Recent approaches mainly tackle the problem of
depth prediction in monocular images by treating the problem as a regression
task. Yet, being interested in an order relation in the first place, ranking
methods suggest themselves as a natural alternative to regression, and indeed,
ranking approaches leveraging pairwise comparisons as training information
(&quot;object A is closer to the camera than B&quot;) have shown promising performance on
this problem. In this paper, we elaborate on the use of so-called listwise
ranking as a generalization of the pairwise approach. Our method is based on
the Plackett-Luce (PL) model, a probability distribution on rankings, which we
combine with a state-of-the-art neural network architecture and a simple
sampling strategy to reduce training complexity. Moreover, taking advantage of
the representation of PL as a random utility model, the proposed predictor
offers a natural way to recover (shift-invariant) metric depth information from
ranking-only data provided at training time. An empirical evaluation on several
benchmark datasets in a &quot;zero-shot&quot; setting demonstrates the effectiveness of
our approach compared to existing ranking and regression methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reborn Mechanism: Rethinking the Negative Phase Information Flow in Convolutional Neural Network. (arXiv:2106.07026v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhicheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chenglei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07026">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel nonlinear activation mechanism typically for
convolutional neural network (CNN), named as reborn mechanism. In sharp
contrast to ReLU which cuts off the negative phase value, the reborn mechanism
enjoys the capacity to reborn and reconstruct dead neurons. Compared to other
improved ReLU functions, reborn mechanism introduces a more proper way to
utilize the negative phase information. Extensive experiments validate that
this activation mechanism is able to enhance the model representation ability
more significantly and make the better use of the input data information while
maintaining the advantages of the original ReLU function. Moreover, reborn
mechanism enables a non-symmetry that is hardly achieved by traditional CNNs
and can act as a channel compensation method, offering competitive or even
better performance but with fewer learned parameters than traditional methods.
Reborn mechanism was tested on various benchmark datasets, all obtaining better
performance than previous nonlinear activation functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection and Mitigation of Rare Subclasses in Deep Neural Network Classifiers. (arXiv:1911.12780v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paterson_C/0/1/0/all/0/1">Colin Paterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Calinescu_R/0/1/0/all/0/1">Radu Calinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Picardi_C/0/1/0/all/0/1">Chiara Picardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.12780">
                                    <div class="article-summary-box-inner">
                                        <span>Regions of high-dimensional input spaces that are underrepresented in
training datasets reduce machine-learnt classifier performance, and may lead to
corner cases and unwanted bias for classifiers used in decision making systems.
When these regions belong to otherwise well-represented classes, their presence
and negative impact are very hard to identify. We propose an approach for the
detection and mitigation of such rare subclasses in deep neural network
classifiers. The new approach is underpinned by an easy-to-compute commonality
metric that supports the detection of rare subclasses, and comprises methods
for reducing the impact of these subclasses during both model training and
model exploitation. We demonstrate our approach using two well-known datasets,
MNIST&#x27;s handwritten digits and Kaggle&#x27;s cats/dogs, identifying rare subclasses
and producing models which compensate for subclass rarity. In addition we
demonstrate how our run-time approach increases the ability of users to
identify samples likely to be misclassified at run-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Complexity Guided Network Compression for Biomedical Image Segmentation. (arXiv:2107.02927v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mishra_S/0/1/0/all/0/1">Suraj Mishra</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_D/0/1/0/all/0/1">Danny Z. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_X/0/1/0/all/0/1">X. Sharon Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02927">
                                    <div class="article-summary-box-inner">
                                        <span>Compression is a standard procedure for making convolutional neural networks
(CNNs) adhere to some specific computing resource constraints. However,
searching for a compressed architecture typically involves a series of
time-consuming training/validation experiments to determine a good compromise
between network size and performance accuracy. To address this, we propose an
image complexity-guided network compression technique for biomedical image
segmentation. Given any resource constraints, our framework utilizes data
complexity and network architecture to quickly estimate a compressed model
which does not require network training. Specifically, we map the dataset
complexity to the target network accuracy degradation caused by compression.
Such mapping enables us to predict the final accuracy for different network
sizes, based on the computed dataset complexity. Thus, one may choose a
solution that meets both the network size and segmentation accuracy
requirements. Finally, the mapping is used to determine the convolutional
layer-wise multiplicative factor for generating a compressed network. We
conduct experiments using 5 datasets, employing 3 commonly-used CNN
architectures for biomedical image segmentation as representative networks. Our
proposed framework is shown to be effective for generating compressed
segmentation networks, retaining up to $\approx 95\%$ of the full-sized network
segmentation accuracy, and at the same time, utilizing $\approx 32x$ fewer
network trainable weights (average reduction) of the full-sized networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlled Caption Generation for Images Through Adversarial Attacks. (arXiv:2107.03050v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aafaq_N/0/1/0/all/0/1">Nayyer Aafaq</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03050">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is found to be vulnerable to adversarial examples. However, its
adversarial susceptibility in image caption generation is under-explored. We
study adversarial examples for vision and language models, which typically
adopt an encoder-decoder framework consisting of two major components: a
Convolutional Neural Network (i.e., CNN) for image feature extraction and a
Recurrent Neural Network (RNN) for caption generation. In particular, we
investigate attacks on the visual encoder&#x27;s hidden layer that is fed to the
subsequent recurrent network. The existing methods either attack the
classification layer of the visual encoder or they back-propagate the gradients
from the language model. In contrast, we propose a GAN-based algorithm for
crafting adversarial examples for neural image captioning that mimics the
internal representation of the CNN such that the resulting deep features of the
input image enable a controlled incorrect caption generation through the
recurrent network. Our contribution provides new insights for understanding
adversarial attacks on vision systems with language component. The proposed
method employs two strategies for a comprehensive evaluation. The first
examines if a neural image captioning system can be misled to output targeted
image captions. The second analyzes the possibility of keywords into the
predicted captions. Experiments show that our algorithm can craft effective
adversarial images based on the CNN hidden layers to fool captioning framework.
Moreover, we discover the proposed attack to be highly transferable. Our work
leads to new robustness implications for neural image captioning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Security of Deepfake Detection. (arXiv:2107.02045v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaoyu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02045">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfakes pose growing challenges to the trust of information on the
Internet. Thus, detecting deepfakes has attracted increasing attentions from
both academia and industry. State-of-the-art deepfake detection methods consist
of two key components, i.e., face extractor and face classifier, which extract
the face region in an image and classify it to be real/fake, respectively.
Existing studies mainly focused on improving the detection performance in
non-adversarial settings, leaving security of deepfake detection in adversarial
settings largely unexplored. In this work, we aim to bridge the gap. In
particular, we perform a systematic measurement study to understand the
security of the state-of-the-art deepfake detection methods in adversarial
settings. We use two large-scale public deepfakes data sources including
FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes
are fake face images; and we train state-of-the-art deepfake detection methods.
These detection methods can achieve 0.94--0.99 accuracies in non-adversarial
settings on these datasets. However, our measurement results uncover multiple
security limitations of the deepfake detection methods in adversarial settings.
First, we find that an attacker can evade a face extractor, i.e., the face
extractor fails to extract the correct face regions, via adding small Gaussian
noise to its deepfake images. Second, we find that a face classifier trained
using deepfakes generated by one method cannot detect deepfakes generated by
another method, i.e., an attacker can evade detection via generating deepfakes
using a new method. Third, we find that an attacker can leverage backdoor
attacks developed by the adversarial machine learning community to evade a face
classifier. Our results highlight that deepfake detection should consider the
adversarial nature of the problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly detection and automatic labeling for solar cell quality inspection based on Generative Adversarial Network. (arXiv:2103.03518v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balzategui_J/0/1/0/all/0/1">Julen Balzategui</a>, <a href="http://arxiv.org/find/cs/1/au:+Eciolaza_L/0/1/0/all/0/1">Luka Eciolaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Maestro_Watson_D/0/1/0/all/0/1">Daniel Maestro-Watson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03518">
                                    <div class="article-summary-box-inner">
                                        <span>Quality inspection applications in industry are required to move towards a
zero-defect manufacturing scenario, withnon-destructive inspection and
traceability of 100 % of produced parts. Developing robust fault detection and
classification modelsfrom the start-up of the lines is challenging due to the
difficulty in getting enough representative samples of the faulty patternsand
the need to manually label them. This work presents a methodology to develop a
robust inspection system, targeting thesepeculiarities, in the context of solar
cell manufacturing. The methodology is divided into two phases: In the first
phase, an anomalydetection model based on a Generative Adversarial Network
(GAN) is employed. This model enables the detection and localizationof
anomalous patterns within the solar cells from the beginning, using only
non-defective samples for training and without anymanual labeling involved. In
a second stage, as defective samples arise, the detected anomalies will be used
as automaticallygenerated annotations for the supervised training of a Fully
Convolutional Network that is capable of detecting multiple types offaults. The
experimental results using 1873 EL images of monocrystalline cells show that
(a) the anomaly detection scheme can beused to start detecting features with
very little available data, (b) the anomaly detection may serve as automatic
labeling in order totrain a supervised model, and (c) segmentation and
classification results of supervised models trained with automatic labels
arecomparable to the ones obtained from the models trained with manual labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Left Atrium Segmentation with Mutual Consistency Training. (arXiv:2103.02911v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yicheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Minfeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02911">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised learning has attracted great attention in the field of
machine learning, especially for medical image segmentation tasks, since it
alleviates the heavy burden of collecting abundant densely annotated data for
training. However, most of existing methods underestimate the importance of
challenging regions (e.g. small branches or blurred edges) during training. We
believe that these unlabeled regions may contain more crucial information to
minimize the uncertainty prediction for the model and should be emphasized in
the training process. Therefore, in this paper, we propose a novel Mutual
Consistency Network (MC-Net) for semi-supervised left atrium segmentation from
3D MR images. Particularly, our MC-Net consists of one encoder and two slightly
different decoders, and the prediction discrepancies of two decoders are
transformed as an unsupervised loss by our designed cycled pseudo label scheme
to encourage mutual consistency. Such mutual consistency encourages the two
decoders to have consistent and low-entropy predictions and enables the model
to gradually capture generalized features from these unlabeled challenging
regions. We evaluate our MC-Net on the public Left Atrium (LA) database and it
obtains impressive performance gains by exploiting the unlabeled data
effectively. Our MC-Net outperforms six recent semi-supervised methods for left
atrium segmentation, and sets the new state-of-the-art performance on the LA
database.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Residual Star Generative Adversarial Network for multi-domain Image Super-Resolution. (arXiv:2107.03145v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Umer_R/0/1/0/all/0/1">Rao Muhammad Umer</a>, <a href="http://arxiv.org/find/eess/1/au:+Munir_A/0/1/0/all/0/1">Asad Munir</a>, <a href="http://arxiv.org/find/eess/1/au:+Micheloni_C/0/1/0/all/0/1">Christian Micheloni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03145">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, most of state-of-the-art single image super-resolution (SISR)
methods have attained impressive performance by using deep convolutional neural
networks (DCNNs). The existing SR methods have limited performance due to a
fixed degradation settings, i.e. usually a bicubic downscaling of
low-resolution (LR) image. However, in real-world settings, the LR degradation
process is unknown which can be bicubic LR, bilinear LR, nearest-neighbor LR,
or real LR. Therefore, most SR methods are ineffective and inefficient in
handling more than one degradation settings within a single network. To handle
the multiple degradation, i.e. refers to multi-domain image super-resolution,
we propose a deep Super-Resolution Residual StarGAN (SR2*GAN), a novel and
scalable approach that super-resolves the LR images for the multiple LR domains
using only a single model. The proposed scheme is trained in a StarGAN like
network topology with a single generator and discriminator networks. We
demonstrate the effectiveness of our proposed approach in quantitative and
qualitative experiments compared to other state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification. (arXiv:2107.03225v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1">Xiaohan Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yuenan Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yixuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_M/0/1/0/all/0/1">Max Q.-H. Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03225">
                                    <div class="article-summary-box-inner">
                                        <span>The amount of medical images for training deep classification models is
typically very scarce, making these deep models prone to overfit the training
data. Studies showed that knowledge distillation (KD), especially the
mean-teacher framework which is more robust to perturbations, can help mitigate
the over-fitting effect. However, directly transferring KD from computer vision
to medical image classification yields inferior performance as medical images
suffer from higher intra-class variance and class imbalance. To address these
issues, we propose a novel Categorical Relation-preserving Contrastive
Knowledge Distillation (CRCKD) algorithm, which takes the commonly used
mean-teacher model as the supervisor. Specifically, we propose a novel
Class-guided Contrastive Distillation (CCD) module to pull closer positive
image pairs from the same class in the teacher and student models, while
pushing apart negative image pairs from different classes. With this
regularization, the feature distribution of the student model shows higher
intra-class similarity and inter-class variance. Besides, we propose a
Categorical Relation Preserving (CRP) loss to distill the teacher&#x27;s relational
knowledge in a robust and class-balanced manner. With the contribution of the
CCD and CRP, our CRCKD algorithm can distill the relational knowledge more
comprehensively. Extensive experiments on the HAM10000 and APTOS datasets
demonstrate the superiority of the proposed CRCKD method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-View Exocentric to Egocentric Video Synthesis. (arXiv:2107.03120v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gaowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1">Hugo Latapie</a>, <a href="http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1">Jason Corso</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yan Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03120">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-view video synthesis task seeks to generate video sequences of one view
from another dramatically different view. In this paper, we investigate the
exocentric (third-person) view to egocentric (first-person) view video
generation task. This is challenging because egocentric view sometimes is
remarkably different from the exocentric view. Thus, transforming the
appearances across the two different views is a non-trivial task. Particularly,
we propose a novel Bi-directional Spatial Temporal Attention Fusion Generative
Adversarial Network (STA-GAN) to learn both spatial and temporal information to
generate egocentric video sequences from the exocentric view. The proposed
STA-GAN consists of three parts: temporal branch, spatial branch, and attention
fusion. First, the temporal and spatial branches generate a sequence of fake
frames and their corresponding features. The fake frames are generated in both
downstream and upstream directions for both temporal and spatial branches.
Next, the generated four different fake frames and their corresponding features
(spatial and temporal branches in two directions) are fed into a novel
multi-generation attention fusion module to produce the final video sequence.
Meanwhile, we also propose a novel temporal and spatial dual-discriminator for
more robust network optimization. Extensive experiments on the Side2Ego and
Top2Ego datasets show that the proposed STA-GAN significantly outperforms the
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?. (arXiv:2107.03332v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shoukui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wankou Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Erjin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03332">
                                    <div class="article-summary-box-inner">
                                        <span>The 2D heatmap representation has dominated human pose estimation for years
due to its high performance. However, heatmap-based approaches have some
drawbacks: 1) The performance drops dramatically in the low-resolution images,
which are frequently encountered in real-world scenarios. 2) To improve the
localization precision, multiple upsample layers may be needed to recover the
feature map resolution from low to high, which are computationally expensive.
3) Extra coordinate refinement is usually necessary to reduce the quantization
error of downscaled heatmaps. To address these issues, we propose a
\textbf{Sim}ple yet promising \textbf{D}isentangled \textbf{R}epresentation for
keypoint coordinate (\emph{SimDR}), reformulating human keypoint localization
as a task of classification. In detail, we propose to disentangle the
representation of horizontal and vertical coordinates for keypoint location,
leading to a more efficient scheme without extra upsampling and refinement.
Comprehensive experiments conducted over COCO dataset show that the proposed
\emph{heatmap-free} methods outperform \emph{heatmap-based} counterparts in all
tested input resolutions, especially in lower resolutions by a large margin.
Code will be made publicly available at \url{https://github.com/leeyegy/SimDR}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long Short-Term Transformer for Online Action Detection. (arXiv:2107.03377v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingze Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03377">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present Long Short-term TRansformer (LSTR), a new temporal
modeling algorithm for online action detection, by employing a long- and
short-term memories mechanism that is able to model prolonged sequence data. It
consists of an LSTR encoder that is capable of dynamically exploiting
coarse-scale historical information from an extensively long time window (e.g.,
2048 long-range frames of up to 8 minutes), together with an LSTR decoder that
focuses on a short time window (e.g., 32 short-range frames of 8 seconds) to
model the fine-scale characterization of the ongoing event. Compared to prior
work, LSTR provides an effective and efficient method to model long videos with
less heuristic algorithm design. LSTR achieves significantly improved results
on standard online action detection benchmarks, THUMOS&#x27;14, TVSeries, and HACS
Segment, over the existing state-of-the-art approaches. Extensive empirical
analysis validates the setup of the long- and short-term memories and the
design choices of LSTR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Space Regularization for Unsupervised Domain Adaptation in Semantic Segmentation. (arXiv:2104.02633v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbato_F/0/1/0/all/0/1">Francesco Barbato</a>, <a href="http://arxiv.org/find/cs/1/au:+Toldo_M/0/1/0/all/0/1">Marco Toldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Michieli_U/0/1/0/all/0/1">Umberto Michieli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanuttigh_P/0/1/0/all/0/1">Pietro Zanuttigh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02633">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks for semantic segmentation achieve
outstanding accuracy, however they also have a couple of major drawbacks:
first, they do not generalize well to distributions slightly different from the
one of the training data; second, they require a huge amount of labeled data
for their optimization. In this paper, we introduce feature-level space-shaping
regularization strategies to reduce the domain discrepancy in semantic
segmentation. In particular, for this purpose we jointly enforce a clustering
objective, a perpendicularity constraint and a norm alignment goal on the
feature vectors corresponding to source and target samples. Additionally, we
propose a novel measure able to capture the relative efficacy of an adaptation
strategy compared to supervised training. We verify the effectiveness of such
methods in the autonomous driving setting achieving state-of-the-art results in
multiple synthetic-to-real road scenes benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Samplets: A new paradigm for data compression. (arXiv:2107.03337v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Harbrecht_H/0/1/0/all/0/1">Helmut Harbrecht</a>, <a href="http://arxiv.org/find/math/1/au:+Multerer_M/0/1/0/all/0/1">Michael Multerer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03337">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we introduce the novel concept of samplets by transferring
the construction of Tausch-White wavelets to the realm of data. This way we
obtain a multilevel representation of discrete data which directly enables data
compression, detection of singularities and adaptivity. Applying samplets to
represent kernel matrices, as they arise in kernel based learning or Gaussian
process regression, we end up with quasi-sparse matrices. By thresholding small
entries, these matrices are compressible to O(N log N) relevant entries, where
N is the number of data points. This feature allows for the use of fill-in
reducing reorderings to obtain a sparse factorization of the compressed
matrices. Besides the comprehensive introduction to samplets and their
properties, we present extensive numerical studies to benchmark the approach.
Our results demonstrate that samplets mark a considerable step in the direction
of making large data sets accessible for analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical Transformer: Gated Axial-Attention for Medical Image Segmentation. (arXiv:2102.10662v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Oza_P/0/1/0/all/0/1">Poojan Oza</a>, <a href="http://arxiv.org/find/cs/1/au:+Hacihaliloglu_I/0/1/0/all/0/1">Ilker Hacihaliloglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10662">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past decade, Deep Convolutional Neural Networks have been widely
adopted for medical image segmentation and shown to achieve adequate
performance. However, due to the inherent inductive biases present in the
convolutional architectures, they lack understanding of long-range dependencies
in the image. Recently proposed Transformer-based architectures that leverage
self-attention mechanism encode long-range dependencies and learn
representations that are highly expressive. This motivates us to explore
Transformer-based solutions and study the feasibility of using
Transformer-based network architectures for medical image segmentation tasks.
Majority of existing Transformer-based network architectures proposed for
vision applications require large-scale datasets to train properly. However,
compared to the datasets for vision applications, for medical imaging the
number of data samples is relatively low, making it difficult to efficiently
train transformers for medical applications. To this end, we propose a Gated
Axial-Attention model which extends the existing architectures by introducing
an additional control mechanism in the self-attention module. Furthermore, to
train the model effectively on medical images, we propose a Local-Global
training strategy (LoGo) which further improves the performance. Specifically,
we operate on the whole image and patches to learn global and local features,
respectively. The proposed Medical Transformer (MedT) is evaluated on three
different medical image segmentation datasets and it is shown that it achieves
better performance than the convolutional and other related transformer-based
architectures. Code: https://github.com/jeya-maria-jose/Medical-Transformer</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Egocentric Videoconferencing. (arXiv:2107.03109v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elgharib_M/0/1/0/all/0/1">Mohamed Elgharib</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendiratta_M/0/1/0/all/0/1">Mohit Mendiratta</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_H/0/1/0/all/0/1">Hans-Peter Seidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ayush Tewari</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03109">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method for egocentric videoconferencing that enables
hands-free video calls, for instance by people wearing smart glasses or other
mixed-reality devices. Videoconferencing portrays valuable non-verbal
communication and face expression cues, but usually requires a front-facing
camera. Using a frontal camera in a hands-free setting when a person is on the
move is impractical. Even holding a mobile phone camera in the front of the
face while sitting for a long duration is not convenient. To overcome these
issues, we propose a low-cost wearable egocentric camera setup that can be
integrated into smart glasses. Our goal is to mimic a classical video call, and
therefore, we transform the egocentric perspective of this camera into a front
facing video. To this end, we employ a conditional generative adversarial
neural network that learns a transition from the highly distorted egocentric
views to frontal views common in videoconferencing. Our approach learns to
transfer expression details directly from the egocentric view without using a
complex intermediate parametric expressions model, as it is used by related
face reenactment methods. We successfully handle subtle expressions, not easily
captured by parametric blendshape-based solutions, e.g., tongue movement, eye
movements, eye blinking, strong expressions and depth varying movements. To get
control over the rigid head movements in the target view, we condition the
generator on synthetic renderings of a moving neutral face. This allows us to
synthesis results at different head poses. Our technique produces temporally
smooth video-realistic renderings in real-time using a video-to-video
translation network in conjunction with a temporal discriminator. We
demonstrate the improved capabilities of our technique by comparing against
related state-of-the art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HIDA: Towards Holistic Indoor Understanding for the Visually Impaired via Semantic Instance Segmentation with a Wearable Solid-State LiDAR Sensor. (arXiv:2107.03180v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huayao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruiping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03180">
                                    <div class="article-summary-box-inner">
                                        <span>Independently exploring unknown spaces or finding objects in an indoor
environment is a daily but challenging task for visually impaired people.
However, common 2D assistive systems lack depth relationships between various
objects, resulting in difficulty to obtain accurate spatial layout and relative
positions of objects. To tackle these issues, we propose HIDA, a lightweight
assistive system based on 3D point cloud instance segmentation with a
solid-state LiDAR sensor, for holistic indoor detection and avoidance. Our
entire system consists of three hardware components, two interactive
functions~(obstacle avoidance and object finding) and a voice user interface.
Based on voice guidance, the point cloud from the most recent state of the
changing indoor environment is captured through an on-site scanning performed
by the user. In addition, we design a point cloud segmentation model with dual
lightweight decoders for semantic and offset predictions, which satisfies the
efficiency of the whole system. After the 3D instance segmentation, we
post-process the segmented point cloud by removing outliers and projecting all
points onto a top-view 2D map representation. The system integrates the
information above and interacts with users intuitively by acoustic feedback.
The proposed 3D instance segmentation model has achieved state-of-the-art
performance on ScanNet v2 dataset. Comprehensive field tests with various tasks
in a user study verify the usability and effectiveness of our system for
assisting visually impaired people in holistic indoor understanding, obstacle
avoidance and object search.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Semantic Segmentation using Psychometric Learning. (arXiv:2107.03212v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1">Lu Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1">Vlado Menkovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03212">
                                    <div class="article-summary-box-inner">
                                        <span>Assigning meaning to parts of image data is the goal of semantic image
segmentation. Machine learning methods, specifically supervised learning is
commonly used in a variety of tasks formulated as semantic segmentation. One of
the major challenges in the supervised learning approaches is expressing and
collecting the rich knowledge that experts have with respect to the meaning
present in the image data. Towards this, typically a fixed set of labels is
specified and experts are tasked with annotating the pixels, patches or
segments in the images with the given labels. In general, however, the set of
classes does not fully capture the rich semantic information present in the
images. For example, in medical imaging such as histology images, the different
parts of cells could be grouped and sub-grouped based on the expertise of the
pathologist.

To achieve such a precise semantic representation of the concepts in the
image, we need access to the full depth of knowledge of the annotator. In this
work, we develop a novel approach to collect segmentation annotations from
experts based on psychometric testing. Our method consists of the psychometric
testing procedure, active query selection, query enhancement, and a deep metric
learning model to achieve a patch-level image embedding that allows for
semantic segmentation of images. We show the merits of our method with
evaluation on the synthetically generated image, aerial image and histology
image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Generation Shifts for Generalized Zero-Shot Learning. (arXiv:2107.03163v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yadan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03163">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized Zero-Shot Learning (GZSL) is the task of leveraging semantic
information (e.g., attributes) to recognize the seen and unseen samples, where
unseen classes are not observable during training. It is natural to derive
generative models and hallucinate training samples for unseen classes based on
the knowledge learned from the seen samples. However, most of these models
suffer from the &#x60;generation shifts&#x27;, where the synthesized samples may drift
from the real distribution of unseen data. In this paper, we conduct an
in-depth analysis on this issue and propose a novel Generation Shifts
Mitigating Flow (GSMFlow) framework, which is comprised of multiple conditional
affine coupling layers for learning unseen data synthesis efficiently and
effectively. In particular, we identify three potential problems that trigger
the generation shifts, i.e., semantic inconsistency, variance decay, and
structural permutation and address them respectively. First, to reinforce the
correlations between the generated samples and the respective attributes, we
explicitly embed the semantic information into the transformations in each of
the coupling layers. Second, to recover the intrinsic variance of the
synthesized unseen features, we introduce a visual perturbation strategy to
diversify the intra-class variance of generated data and hereby help adjust the
decision boundary of the classifier. Third, to avoid structural permutation in
the semantic space, we propose a relative positioning strategy to manipulate
the attribute embeddings, guiding which to fully preserve the inter-class
geometric structure. Experimental results demonstrate that GSMFlow achieves
state-of-the-art recognition performance in both conventional and generalized
zero-shot settings. Our code is available at:
https://github.com/uqzhichen/GSMFlow</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Units Recognition Using Improved Pairwise Deep Architecture. (arXiv:2107.03143v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saito_J/0/1/0/all/0/1">Junya Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_X/0/1/0/all/0/1">Xiaoyu Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_A/0/1/0/all/0/1">Akiyoshi Uchida</a>, <a href="http://arxiv.org/find/cs/1/au:+Youoku_S/0/1/0/all/0/1">Sachihiro Youoku</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_T/0/1/0/all/0/1">Takahisa Yamamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Murase_K/0/1/0/all/0/1">Kentaro Murase</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03143">
                                    <div class="article-summary-box-inner">
                                        <span>Facial Action Units (AUs) represent a set of facial muscular activities and
various combinations of AUs can represent a wide range of emotions. AU
recognition is often used in many applications, including marketing,
healthcare, education, and so forth. Although a lot of studies have developed
various methods to improve recognition accuracy, it still remains a major
challenge for AU recognition. In the Affective Behavior Analysis in-the-wild
(ABAW) 2020 competition, we proposed a new automatic Action Units (AUs)
recognition method using a pairwise deep architecture to derive the
Pseudo-Intensities of each AU and then convert them into predicted intensities.
This year, we introduced a new technique to last year&#x27;s framework to further
reduce AU recognition errors due to temporary face occlusion such as temporary
face occlusion such as face hiding or large face orientation. We obtained a
score of 0.65 in the validation data set for this year&#x27;s competition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trans4Trans: Efficient Transformer for Transparent Object Segmentation to Help Visually Impaired People Navigate in the Real World. (arXiv:2107.03172v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Constantinescu_A/0/1/0/all/0/1">Angela Constantinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1">Karin M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03172">
                                    <div class="article-summary-box-inner">
                                        <span>Common fully glazed facades and transparent objects present architectural
barriers and impede the mobility of people with low vision or blindness, for
instance, a path detected behind a glass door is inaccessible unless it is
correctly perceived and reacted. However, segmenting these safety-critical
objects is rarely covered by conventional assistive technologies. To tackle
this issue, we construct a wearable system with a novel dual-head Transformer
for Transparency (Trans4Trans) model, which is capable of segmenting general
and transparent objects and performing real-time wayfinding to assist people
walking alone more safely. Especially, both decoders created by our proposed
Transformer Parsing Module (TPM) enable effective joint learning from different
datasets. Besides, the efficient Trans4Trans model composed of symmetric
transformer-based encoder and decoder, requires little computational expenses
and is readily deployed on portable GPUs. Our Trans4Trans model outperforms
state-of-the-art methods on the test sets of Stanford2D3D and Trans10K-v2
datasets and obtains mIoU of 45.13% and 75.14%, respectively. Through various
pre-tests and a user study conducted in indoor and outdoor scenarios, the
usability and reliability of our assistive system have been extensively
verified.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation. (arXiv:2107.03358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bingchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03358">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we tackle the problem of novel visual category discovery,
i.e., grouping unlabelled images from new classes into different semantic
partitions by leveraging a labelled dataset that contains images from other
different but relevant categories. This is a more realistic and challenging
setting than conventional semi-supervised learning. We propose a two-branch
learning framework for this problem, with one branch focusing on local
part-level information and the other branch focusing on overall
characteristics. To transfer knowledge from the labelled data to the
unlabelled, we propose using dual ranking statistics on both branches to
generate pseudo labels for training on the unlabelled data. We further
introduce a mutual knowledge distillation method to allow information exchange
and encourage agreement between the two branches for discovering new
categories, allowing our model to enjoy the benefits of global and local
features. We comprehensively evaluate our method on public benchmarks for
generic object classification, as well as the more challenging datasets for
fine-grained visual recognition, achieving state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speaker embeddings by modeling channel-wise correlations. (arXiv:2104.02571v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Stafylakis_T/0/1/0/all/0/1">Themos Stafylakis</a>, <a href="http://arxiv.org/find/eess/1/au:+Rohdin_J/0/1/0/all/0/1">Johan Rohdin</a>, <a href="http://arxiv.org/find/eess/1/au:+Burget_L/0/1/0/all/0/1">Lukas Burget</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02571">
                                    <div class="article-summary-box-inner">
                                        <span>Speaker embeddings extracted with deep 2D convolutional neural networks are
typically modeled as projections of first and second order statistics of
channel-frequency pairs onto a linear layer, using either average or attentive
pooling along the time axis. In this paper we examine an alternative pooling
method, where pairwise correlations between channels for given frequencies are
used as statistics. The method is inspired by style-transfer methods in
computer vision, where the style of an image, modeled by the matrix of
channel-wise correlations, is transferred to another image, in order to produce
a new image having the style of the first and the content of the second. By
drawing analogies between image style and speaker characteristics, and between
image content and phonetic sequence, we explore the use of such channel-wise
correlations features to train a ResNet architecture in an end-to-end fashion.
Our experiments on VoxCeleb demonstrate the effectiveness of the proposed
pooling method in speaker recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FBC-GAN: Diverse and Flexible Image Synthesis via Foreground-Background Composition. (arXiv:2107.03166v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1">Kaiwen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03166">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have become the de-facto standard in
image synthesis. However, without considering the foreground-background
decomposition, existing GANs tend to capture excessive content correlation
between foreground and background, thus constraining the diversity in image
generation. This paper presents a novel Foreground-Background Composition GAN
(FBC-GAN) that performs image generation by generating foreground objects and
background scenes concurrently and independently, followed by composing them
with style and geometrical consistency. With this explicit design, FBC-GAN can
generate images with foregrounds and backgrounds that are mutually independent
in contents, thus lifting the undesirably learned content correlation
constraint and achieving superior diversity. It also provides excellent
flexibility by allowing the same foreground object with different background
scenes, the same background scene with varying foreground objects, or the same
foreground object and background scene with different object positions, sizes
and poses. It can compose foreground objects and background scenes sampled from
different datasets as well. Extensive experiments over multiple datasets show
that FBC-GAN achieves competitive visual realism and superior diversity as
compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting with Confidence on Unseen Distributions. (arXiv:2107.03315v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guillory_D/0/1/0/all/0/1">Devin Guillory</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1">Vaishaal Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1">Sayna Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1">Ludwig Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03315">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that the performance of machine learning models can
vary substantially when models are evaluated on data drawn from a distribution
that is close to but different from the training distribution. As a result,
predicting model performance on unseen distributions is an important challenge.
Our work connects techniques from domain adaptation and predictive uncertainty
literature, and allows us to predict model accuracy on challenging unseen
distributions without access to labeled data. In the context of distribution
shift, distributional distances are often used to adapt models and improve
their performance on new domains, however accuracy estimation, or other forms
of predictive uncertainty, are often neglected in these investigations. Through
investigating a wide range of established distributional distances, such as
Frechet distance or Maximum Mean Discrepancy, we determine that they fail to
induce reliable estimates of performance under distribution shift. On the other
hand, we find that the difference of confidences (DoC) of a classifier&#x27;s
predictions successfully estimates the classifier&#x27;s performance change over a
variety of shifts. We specifically investigate the distinction between
synthetic and natural distribution shifts and observe that despite its
simplicity DoC consistently outperforms other quantifications of distributional
difference. $DoC$ reduces predictive error by almost half ($46\%$) on several
realistic and challenging distribution shifts, e.g., on the ImageNet-Vid-Robust
and ImageNet-Rendition datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning based Micro-expression Recognition: A Survey. (arXiv:2107.02823v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yante Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jinsheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadifoumani_S/0/1/0/all/0/1">Seyednavid Mohammadifoumani</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guoying Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02823">
                                    <div class="article-summary-box-inner">
                                        <span>Micro-expressions (MEs) are involuntary facial movements revealing people&#x27;s
hidden feelings in high-stake situations and have practical importance in
medical treatment, national security, interrogations and many human-computer
interaction systems. Early methods for MER mainly based on traditional
appearance and geometry features. Recently, with the success of deep learning
(DL) in various fields, neural networks have received increasing interests in
MER. Different from macro-expressions, MEs are spontaneous, subtle, and rapid
facial movements, leading to difficult data collection, thus have small-scale
datasets. DL based MER becomes challenging due to above ME characters. To data,
various DL approaches have been proposed to solve the ME issues and improve MER
performance. In this survey, we provide a comprehensive review of deep
micro-expression recognition (MER), including datasets, deep MER pipeline, and
the bench-marking of most influential methods. This survey defines a new
taxonomy for the field, encompassing all aspects of MER based on DL. For each
aspect, the basic approaches and advanced developments are summarized and
discussed. In addition, we conclude the remaining challenges and and potential
directions for the design of robust deep MER systems. To the best of our
knowledge, this is the first survey of deep MER methods, and this survey can
serve as a reference point for future MER research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rotation Transformation Network: Learning View-Invariant Point Cloud for Classification and Segmentation. (arXiv:2107.03105v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shuang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhanyi Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03105">
                                    <div class="article-summary-box-inner">
                                        <span>Many recent works show that a spatial manipulation module could boost the
performances of deep neural networks (DNNs) for 3D point cloud analysis. In
this paper, we aim to provide an insight into spatial manipulation modules.
Firstly, we find that the smaller the rotational degree of freedom (RDF) of
objects is, the more easily these objects are handled by these DNNs. Then, we
investigate the effect of the popular T-Net module and find that it could not
reduce the RDF of objects. Motivated by the above two issues, we propose a
rotation transformation network for point cloud analysis, called RTN, which
could reduce the RDF of input 3D objects to 0. The RTN could be seamlessly
inserted into many existing DNNs for point cloud analysis. Extensive
experimental results on 3D point cloud classification and segmentation tasks
demonstrate that the proposed RTN could improve the performances of several
state-of-the-art methods significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Introducing the structural bases of typicality effects in deep learning. (arXiv:2107.03279v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pino_O/0/1/0/all/0/1">Omar Vidal Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1">Erickson Rangel Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Campos_M/0/1/0/all/0/1">Mario Fernando Montenegro Campos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03279">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we hypothesize that the effects of the degree of typicality in
natural semantic categories can be generated based on the structure of
artificial categories learned with deep learning models. Motivated by the human
approach to representing natural semantic categories and based on the Prototype
Theory foundations, we propose a novel Computational Prototype Model (CPM) to
represent the internal structure of semantic categories. Unlike other prototype
learning approaches, our mathematical framework proposes a first approach to
provide deep neural networks with the ability to model abstract semantic
concepts such as category central semantic meaning, typicality degree of an
object&#x27;s image, and family resemblance relationship. We proposed several
methodologies based on the typicality&#x27;s concept to evaluate our CPM-model in
image semantic processing tasks such as image classification, a global semantic
description, and transfer learning. Our experiments on different image
datasets, such as ImageNet and Coco, showed that our approach might be an
admissible proposition in the effort to endow machines with greater power of
abstraction for the semantic representation of objects&#x27; categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Data Balancing for Unlabeled Satellite Imagery. (arXiv:2107.03227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_E/0/1/0/all/0/1">Erin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1">Anirudh Koul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1">Meher Anand Kasam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03227">
                                    <div class="article-summary-box-inner">
                                        <span>Data imbalance is a ubiquitous problem in machine learning. In large scale
collected and annotated datasets, data imbalance is either mitigated manually
by undersampling frequent classes and oversampling rare classes, or planned for
with imputation and augmentation techniques. In both cases balancing data
requires labels. In other words, only annotated data can be balanced.
Collecting fully annotated datasets is challenging, especially for large scale
satellite systems such as the unlabeled NASA&#x27;s 35 PB Earth Imagery dataset.
Although the NASA Earth Imagery dataset is unlabeled, there are implicit
properties of the data source that we can rely on to hypothesize about its
imbalance, such as distribution of land and water in the case of the Earth&#x27;s
imagery. We present a new iterative method to balance unlabeled data. Our
method utilizes image embeddings as a proxy for image labels that can be used
to balance data, and ultimately when trained increases overall accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeClick: Weakly-Supervised Video Semantic Segmentation with Click Annotations. (arXiv:2107.03088v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peidong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zibin He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiyu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shutao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Maowei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03088">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with tedious per-pixel mask annotating, it is much easier to
annotate data by clicks, which costs only several seconds for an image.
However, applying clicks to learn video semantic segmentation model has not
been explored before. In this work, we propose an effective weakly-supervised
video semantic segmentation pipeline with click annotations, called WeClick,
for saving laborious annotating effort by segmenting an instance of the
semantic class with only a single click. Since detailed semantic information is
not captured by clicks, directly training with click labels leads to poor
segmentation predictions. To mitigate this problem, we design a novel memory
flow knowledge distillation strategy to exploit temporal information (named
memory flow) in abundant unlabeled video frames, by distilling the neighboring
predictions to the target frame via estimated motion. Moreover, we adopt
vanilla knowledge distillation for model compression. In this case, WeClick
learns compact video semantic segmentation models with the low-cost click
annotations during the training phase yet achieves real-time and accurate
models during the inference period. Experimental results on Cityscapes and
Camvid show that WeClick outperforms the state-of-the-art methods, increases
performance by 10.24% mIoU than baseline, and achieves real-time execution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Odometry with an Event Camera Using Continuous Ray Warping and Volumetric Contrast Maximization. (arXiv:2107.03011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xin Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Peng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Ling Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaben Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kneip_L/0/1/0/all/0/1">Laurent Kneip</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03011">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new solution to tracking and mapping with an event camera. The
motion of the camera contains both rotation and translation, and the
displacements happen in an arbitrarily structured environment. As a result, the
image matching may no longer be represented by a low-dimensional homographic
warping, thus complicating an application of the commonly used Image of Warped
Events (IWE). We introduce a new solution to this problem by performing
contrast maximization in 3D. The 3D location of the rays cast for each event is
smoothly varied as a function of a continuous-time motion parametrization, and
the optimal parameters are found by maximizing the contrast in a volumetric ray
density field. Our method thus performs joint optimization over motion and
structure. The practical validity of our approach is supported by an
application to AGV motion estimation and 3D reconstruction with a single
vehicle-mounted event camera. The method approaches the performance obtained
with regular cameras, and eventually outperforms in challenging visual
conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XPDNet for MRI Reconstruction: an application to the 2020 fastMRI challenge. (arXiv:2010.07290v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ramzi_Z/0/1/0/all/0/1">Zaccharie Ramzi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ciuciu_P/0/1/0/all/0/1">Philippe Ciuciu</a>, <a href="http://arxiv.org/find/eess/1/au:+Starck_J/0/1/0/all/0/1">Jean-Luc Starck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07290">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new neural network, the XPDNet, for MRI reconstruction from
periodically under-sampled multi-coil data. We inform the design of this
network by taking best practices from MRI reconstruction and computer vision.
We show that this network can achieve state-of-the-art reconstruction results,
as shown by its ranking of second in the fastMRI 2020 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Invariant Representation with Consistency and Diversity for Semi-supervised Source Hypothesis Transfer. (arXiv:2107.03008v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaodong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_J/0/1/0/all/0/1">Junbao Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuhao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03008">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised domain adaptation (SSDA) aims to solve tasks in target domain
by utilizing transferable information learned from the available source domain
and a few labeled target data. However, source data is not always accessible in
practical scenarios, which restricts the application of SSDA in real world
circumstances. In this paper, we propose a novel task named Semi-supervised
Source Hypothesis Transfer (SSHT), which performs domain adaptation based on
source trained model, to generalize well in target domain with a few
supervisions. In SSHT, we are facing two challenges: (1) The insufficient
labeled target data may result in target features near the decision boundary,
with the increased risk of mis-classification; (2) The data are usually
imbalanced in source domain, so the model trained with these data is biased.
The biased model is prone to categorize samples of minority categories into
majority ones, resulting in low prediction diversity. To tackle the above
issues, we propose Consistency and Diversity Learning (CDL), a simple but
effective framework for SSHT by facilitating prediction consistency between two
randomly augmented unlabeled data and maintaining the prediction diversity when
adapting model to target domain. Encouraging consistency regularization brings
difficulty to memorize the few labeled target data and thus enhances the
generalization ability of the learned model. We further integrate Batch
Nuclear-norm Maximization into our method to enhance the discriminability and
diversity. Experimental results show that our method outperforms existing SSDA
methods and unsupervised model adaptation methods on DomainNet, Office-Home and
Office-31 datasets. The code is available at
https://github.com/Wang-xd1899/SSHT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Learning by Integrating Spatial and Frequency Representation. (arXiv:2105.05348v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05348">
                                    <div class="article-summary-box-inner">
                                        <span>Human beings can recognize new objects with only a few labeled examples,
however, few-shot learning remains a challenging problem for machine learning
systems. Most previous algorithms in few-shot learning only utilize spatial
information of the images. In this paper, we propose to integrate the frequency
information into the learning model to boost the discrimination ability of the
system. We employ Discrete Cosine Transformation (DCT) to generate the
frequency representation, then, integrate the features from both the spatial
domain and frequency domain for classification. The proposed strategy and its
effectiveness are validated with different backbones, datasets, and algorithms.
Extensive experiments demonstrate that the frequency information is
complementary to the spatial representations in few-shot classification. The
classification accuracy is boosted significantly by integrating features from
both the spatial and frequency domains in different few-shot learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FasterPose: A Faster Simple Baseline for Human Pose Estimation. (arXiv:2107.03215v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hanbin Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Hailin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linfang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yinglu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03215">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of human pose estimation depends on the spatial accuracy of
keypoint localization. Most existing methods pursue the spatial accuracy
through learning the high-resolution (HR) representation from input images. By
the experimental analysis, we find that the HR representation leads to a sharp
increase of computational cost, while the accuracy improvement remains marginal
compared with the low-resolution (LR) representation. In this paper, we propose
a design paradigm for cost-effective network with LR representation for
efficient pose estimation, named FasterPose. Whereas the LR design largely
shrinks the model complexity, yet how to effectively train the network with
respect to the spatial accuracy is a concomitant challenge. We study the
training behavior of FasterPose, and formulate a novel regressive cross-entropy
(RCE) loss function for accelerating the convergence and promoting the
accuracy. The RCE loss generalizes the ordinary cross-entropy loss from the
binary supervision to a continuous range, thus the training of pose estimation
network is able to benefit from the sigmoid function. By doing so, the output
heatmap can be inferred from the LR features without loss of spatial accuracy,
while the computational cost and model size has been significantly reduced.
Compared with the previously dominant network of pose estimation, our method
reduces 58% of the FLOPs and simultaneously gains 1.3% improvement of accuracy.
Extensive experiments show that FasterPose yields promising results on the
common benchmarks, i.e., COCO and MPII, consistently validating the
effectiveness and efficiency for practical utilization, especially the
low-latency and low-energy-budget applications in the non-GPU scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering. (arXiv:2107.03216v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Haiwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shuning He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kejia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_B/0/1/0/all/0/1">Bo Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chunling Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Kun Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03216">
                                    <div class="article-summary-box-inner">
                                        <span>Medical Visual Question Answering (VQA) is a multi-modal challenging task
widely considered by research communities of the computer vision and natural
language processing. Since most current medical VQA models focus on visual
content, ignoring the importance of text, this paper proposes a multi-view
attention-based model(MuVAM) for medical visual question answering which
integrates the high-level semantics of medical images on the basis of text
description. Firstly, different methods are utilized to extract the features of
the image and the question for the two modalities of vision and text. Secondly,
this paper proposes a multi-view attention mechanism that include
Image-to-Question (I2Q) attention and Word-to-Text (W2T) attention. Multi-view
attention can correlate the question with image and word in order to better
analyze the question and get an accurate answer. Thirdly, a composite loss is
presented to predict the answer accurately after multi-modal feature fusion and
improve the similarity between visual and textual cross-modal features. It
consists of classification loss and image-question complementary (IQC) loss.
Finally, for data errors and missing labels in the VQA-RAD dataset, we
collaborate with medical experts to correct and complete this dataset and then
construct an enhanced dataset, VQA-RADPh. The experiments on these two datasets
show that the effectiveness of MuVAM surpasses the state-of-the-art method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IntraLoss: Further Margin via Gradient-Enhancing Term for Deep Face Recognition. (arXiv:2107.03352v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Chengzhi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yanzhou Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haiwei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haijun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jian Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03352">
                                    <div class="article-summary-box-inner">
                                        <span>Existing classification-based face recognition methods have achieved
remarkable progress, introducing large margin into hypersphere manifold to
learn discriminative facial representations. However, the feature distribution
is ignored. Poor feature distribution will wipe out the performance improvement
brought about by margin scheme. Recent studies focus on the unbalanced
inter-class distribution and form a equidistributed feature representations by
penalizing the angle between identity and its nearest neighbor. But the problem
is more than that, we also found the anisotropy of intra-class distribution. In
this paper, we propose the &#x60;gradient-enhancing term&#x27; that concentrates on the
distribution characteristics within the class. This method, named IntraLoss,
explicitly performs gradient enhancement in the anisotropic region so that the
intra-class distribution continues to shrink, resulting in isotropic and more
compact intra-class distribution and further margin between identities. The
experimental results on LFW, YTF and CFP-FP show that our outperforms
state-of-the-art methods by gradient enhancement, demonstrating the superiority
of our method. In addition, our method has intuitive geometric interpretation
and can be easily combined with existing methods to solve the previously
ignored problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangle Your Dense Object Detector. (arXiv:2107.02963v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zehui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenhongyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiaofei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Feng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zhengjun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02963">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based dense object detectors have achieved great success in the
past few years and have been applied to numerous multimedia applications such
as video understanding. However, the current training pipeline for dense
detectors is compromised to lots of conjunctions that may not hold. In this
paper, we investigate three such important conjunctions: 1) only samples
assigned as positive in classification head are used to train the regression
head; 2) classification and regression share the same input feature and
computational fields defined by the parallel head architecture; and 3) samples
distributed in different feature pyramid layers are treated equally when
computing the loss. We first carry out a series of pilot experiments to show
disentangling such conjunctions can lead to persistent performance improvement.
Then, based on these findings, we propose Disentangled Dense Object Detector
(DDOD), in which simple and effective disentanglement mechanisms are designed
and integrated into the current state-of-the-art dense object detectors.
Extensive experiments on MS COCO benchmark show that our approach can lead to
2.0 mAP, 2.4 mAP and 2.2 mAP absolute improvements on RetinaNet, FCOS, and ATSS
baselines with negligible extra overhead. Notably, our best model reaches 55.0
mAP on the COCO test-dev set and 93.5 AP on the hard subset of WIDER FACE,
achieving new state-of-the-art performance on these two competitive benchmarks.
Code is available at https://github.com/zehuichen123/DDOD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGD-Autoencoder: Attention Gated Deep Convolutional Autoencoder for Brain Tumor Segmentation. (arXiv:2107.03323v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cvetko_T/0/1/0/all/0/1">Tim Cvetko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Brain tumor segmentation is a challenging problem in medical image analysis.
The endpoint is to generate the salient masks that accurately identify brain
tumor regions in an fMRI screening. In this paper, we propose a novel attention
gate (AG model) for brain tumor segmentation that utilizes both the edge
detecting unit and the attention gated network to highlight and segment the
salient regions from fMRI images. This feature enables us to eliminate the
necessity of having to explicitly point towards the damaged area(external
tissue localization) and classify(classification) as per classical computer
vision techniques. AGs can easily be integrated within the deep convolutional
neural networks(CNNs). Minimal computional overhead is required while the AGs
increase the sensitivity scores significantly. We show that the edge detector
along with an attention gated mechanism provide a sufficient enough method for
brain segmentation reaching an IOU of 0.78</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blind Image Super-Resolution: A Survey and Beyond. (arXiv:2107.03055v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yihao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jinjin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Chao Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03055">
                                    <div class="article-summary-box-inner">
                                        <span>Blind image super-resolution (SR), aiming to super-resolve low-resolution
images with unknown degradation, has attracted increasing attention due to its
significance in promoting real-world applications. Many novel and effective
solutions have been proposed recently, especially with the powerful deep
learning techniques. Despite years of efforts, it still remains as a
challenging research problem. This paper serves as a systematic review on
recent progress in blind image SR, and proposes a taxonomy to categorize
existing methods into three different classes according to their ways of
degradation modelling and the data used for solving the SR model. This taxonomy
helps summarize and distinguish among existing methods. We hope to provide
insights into current research states, as well as to reveal novel research
directions worth exploring. In addition, we make a summary on commonly used
datasets and previous competitions related to blind image SR. Last but not
least, a comparison among different methods is provided with detailed analysis
on their merits and demerits using both synthetic and real testing images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Urban Tree Species Classification Using Aerial Imagery. (arXiv:2107.03182v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waters_E/0/1/0/all/0/1">Emily Waters</a>, <a href="http://arxiv.org/find/cs/1/au:+Oghaz_M/0/1/0/all/0/1">Mahdi Maktabdar Oghaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Saheer_L/0/1/0/all/0/1">Lakshmi Babu Saheer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03182">
                                    <div class="article-summary-box-inner">
                                        <span>Urban trees help regulate temperature, reduce energy consumption, improve
urban air quality, reduce wind speeds, and mitigating the urban heat island
effect. Urban trees also play a key role in climate change mitigation and
global warming by capturing and storing atmospheric carbon-dioxide which is the
largest contributor to greenhouse gases. Automated tree detection and species
classification using aerial imagery can be a powerful tool for sustainable
forest and urban tree management. Hence, This study first offers a pipeline for
generating labelled dataset of urban trees using Google Map&#x27;s aerial images and
then investigates how state of the art deep Convolutional Neural Network models
such as VGG and ResNet handle the classification problem of urban tree aerial
images under different parameters. Experimental results show our best model
achieves an average accuracy of 60% over 6 tree species.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-level Feature Alignment for Versatile Image Translation and Manipulation. (arXiv:2107.03021v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yingchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rongliang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1">Kaiwen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03021">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) have achieved great success in image
translation and manipulation. However, high-fidelity image generation with
faithful style control remains a grand challenge in computer vision. This paper
presents a versatile image translation and manipulation framework that achieves
accurate semantic and style guidance in image generation by explicitly building
a correspondence. To handle the quadratic complexity incurred by building the
dense correspondences, we introduce a bi-level feature alignment strategy that
adopts a top-$k$ operation to rank block-wise features followed by dense
attention between block features which reduces memory cost substantially. As
the top-$k$ operation involves index swapping which precludes the gradient
propagation, we propose to approximate the non-differentiable top-$k$ operation
with a regularized earth mover&#x27;s problem so that its gradient can be
effectively back-propagated. In addition, we design a novel semantic position
encoding mechanism that builds up coordinate for each individual semantic
region to preserve texture structures while building correspondences. Further,
we design a novel confidence feature injection module which mitigates mismatch
problem by fusing features adaptively according to the reliability of built
correspondences. Extensive experiments show that our method achieves superior
performance qualitatively and quantitatively as compared with the
state-of-the-art. The code is available at
\href{https://github.com/fnzhan/RABIT}{https://github.com/fnzhan/RABIT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bone Surface Reconstruction and Clinical Features Estimation from Sparse Landmarks and Statistical Shape Models: A feasibility study on the femur. (arXiv:2107.03292v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Asvadi_A/0/1/0/all/0/1">Alireza Asvadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Dardenne_G/0/1/0/all/0/1">Guillaume Dardenne</a>, <a href="http://arxiv.org/find/eess/1/au:+Troccaz_J/0/1/0/all/0/1">Jocelyne Troccaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Burdin_V/0/1/0/all/0/1">Valerie Burdin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03292">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we investigated a method allowing the determination of the
femur bone surface as well as its mechanical axis from some easy-to-identify
bony landmarks. The reconstruction of the whole femur is therefore performed
from these landmarks using a Statistical Shape Model (SSM). The aim of this
research is therefore to assess the impact of the number, the position, and the
accuracy of the landmarks for the reconstruction of the femur and the
determination of its related mechanical axis, an important clinical parameter
to consider for the lower limb analysis. Two statistical femur models were
created from our in-house dataset and a publicly available dataset. Both were
evaluated in terms of average point-to-point surface distance error and through
the mechanical axis of the femur. Furthermore, the clinical impact of using
landmarks on the skin in replacement of bony landmarks is investigated. The
predicted proximal femurs from bony landmarks were more accurate compared to
on-skin landmarks while both had less than 3.5 degrees mechanical axis angle
deviation error. The results regarding the non-invasive determination of the
mechanical axis are very encouraging and could open very interesting clinical
perspectives for the analysis of the lower limb either for orthopedics or
functional rehabilitation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Mesh Prior: Unsupervised Mesh Restoration using Graph Convolutional Networks. (arXiv:2107.02909v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hattori_S/0/1/0/all/0/1">Shota Hattori</a>, <a href="http://arxiv.org/find/cs/1/au:+Yatagawa_T/0/1/0/all/0/1">Tatsuya Yatagawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohtake_Y/0/1/0/all/0/1">Yutaka Ohtake</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_H/0/1/0/all/0/1">Hiromasa Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02909">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses mesh restoration problems, i.e., denoising and
completion, by learning self-similarity in an unsupervised manner. For this
purpose, the proposed method, which we refer to as Deep Mesh Prior, uses a
graph convolutional network on meshes to learn the self-similarity. The network
takes a single incomplete mesh as input data and directly outputs the
reconstructed mesh without being trained using large-scale datasets. Our method
does not use any intermediate representations such as an implicit field because
the whole process works on a mesh. We demonstrate that our unsupervised method
performs equally well or even better than the state-of-the-art methods using
large-scale datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAM-VO: Less is more in Visual Odometry. (arXiv:2107.02974v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cleveston_I/0/1/0/all/0/1">Iury Cleveston</a>, <a href="http://arxiv.org/find/cs/1/au:+Colombini_E/0/1/0/all/0/1">Esther L. Colombini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02974">
                                    <div class="article-summary-box-inner">
                                        <span>Building vehicles capable of operating without human supervision requires the
determination of the agent&#x27;s pose. Visual Odometry (VO) algorithms estimate the
egomotion using only visual changes from the input images. The most recent VO
methods implement deep-learning techniques using convolutional neural networks
(CNN) extensively, which add a substantial cost when dealing with
high-resolution images. Furthermore, in VO tasks, more input data does not mean
a better prediction; on the contrary, the architecture may filter out useless
information. Therefore, the implementation of computationally efficient and
lightweight architectures is essential. In this work, we propose the RAM-VO, an
extension of the Recurrent Attention Model (RAM) for visual odometry tasks.
RAM-VO improves the visual and temporal representation of information and
implements the Proximal Policy Optimization (PPO) algorithm to learn robust
policies. The results indicate that RAM-VO can perform regressions with six
degrees of freedom from monocular input images using approximately 3 million
parameters. In addition, experiments on the KITTI dataset demonstrate that
RAM-VO achieves competitive results using only 5.7% of the available visual
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Stixel-based Instance Segmentation. (arXiv:2107.03070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santarossa_M/0/1/0/all/0/1">Monty Santarossa</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_L/0/1/0/all/0/1">Lukas Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelenka_C/0/1/0/all/0/1">Claudius Zelenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmarje_L/0/1/0/all/0/1">Lars Schmarje</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_R/0/1/0/all/0/1">Reinhard Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Franke_U/0/1/0/all/0/1">Uwe Franke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03070">
                                    <div class="article-summary-box-inner">
                                        <span>Stixels have been successfully applied to a wide range of vision tasks in
autonomous driving, recently including instance segmentation. However, due to
their sparse occurrence in the image, until now Stixels seldomly served as
input for Deep Learning algorithms, restricting their utility for such
approaches. In this work we present StixelPointNet, a novel method to perform
fast instance segmentation directly on Stixels. By regarding the Stixel
representation as unstructured data similar to point clouds, architectures like
PointNet are able to learn features from Stixels. We use a bounding box
detector to propose candidate instances, for which the relevant Stixels are
extracted from the input image. On these Stixels, a PointNet models learns
binary segmentations, which we then unify throughout the whole image in a final
selection step. StixelPointNet achieves state-of-the-art performance on
Stixel-level, is considerably faster than pixel-based segmentation methods, and
shows that with our approach the Stixel domain can be introduced to many new 3D
Deep Learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer Network for Significant Stenosis Detection in CCTA of Coronary Arteries. (arXiv:2107.03035v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ma_X/0/1/0/all/0/1">Xinghua Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_G/0/1/0/all/0/1">Gongning Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_K/0/1/0/all/0/1">Kuanquan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03035">
                                    <div class="article-summary-box-inner">
                                        <span>Coronary artery disease (CAD) has posed a leading threat to the lives of
cardiovascular disease patients worldwide for a long time. Therefore, automated
diagnosis of CAD has indispensable significance in clinical medicine. However,
the complexity of coronary artery plaques that cause CAD makes the automatic
detection of coronary artery stenosis in Coronary CT angiography (CCTA) a
difficult task. In this paper, we propose a Transformer network (TR-Net) for
the automatic detection of significant stenosis (i.e. luminal narrowing &gt; 50%)
while practically completing the computer-assisted diagnosis of CAD. The
proposed TR-Net introduces a novel Transformer, and tightly combines
convolutional layers and Transformer encoders, allowing their advantages to be
demonstrated in the task. By analyzing semantic information sequences, TR-Net
can fully understand the relationship between image information in each
position of a multiplanar reformatted (MPR) image, and accurately detect
significant stenosis based on both local and global information. We evaluate
our TR-Net on a dataset of 76 patients from different patients annotated by
experienced radiologists. Experimental results illustrate that our TR-Net has
achieved better results in ACC (0.92), Spec (0.96), PPV (0.84), F1 (0.79) and
MCC (0.74) indicators compared with the state-of-the-art methods. The source
code is publicly available from the link (https://github.com/XinghuaMa/TR-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Simultaneous Learning of Single-particle Orientation and 3D Map Reconstruction from Cryo-electron Microscopy Data. (arXiv:2107.02958v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nashed_Y/0/1/0/all/0/1">Youssef S. G. Nashed</a>, <a href="http://arxiv.org/find/eess/1/au:+Poitevin_F/0/1/0/all/0/1">Frederic Poitevin</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_H/0/1/0/all/0/1">Harshit Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Woollard_G/0/1/0/all/0/1">Geoffrey Woollard</a>, <a href="http://arxiv.org/find/eess/1/au:+Kagan_M/0/1/0/all/0/1">Michael Kagan</a>, <a href="http://arxiv.org/find/eess/1/au:+Yoon_C/0/1/0/all/0/1">Chuck Yoon</a>, <a href="http://arxiv.org/find/eess/1/au:+Ratner_D/0/1/0/all/0/1">Daniel Ratner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02958">
                                    <div class="article-summary-box-inner">
                                        <span>Cryogenic electron microscopy (cryo-EM) provides images from different copies
of the same biomolecule in arbitrary orientations. Here, we present an
end-to-end unsupervised approach that learns individual particle orientations
from cryo-EM data while reconstructing the average 3D map of the biomolecule,
starting from a random initialization. The approach relies on an auto-encoder
architecture where the latent space is explicitly interpreted as orientations
used by the decoder to form an image according to the linear projection model.
We evaluate our method on simulated data and show that it is able to
reconstruct 3D particle maps from noisy- and CTF-corrupted 2D projection images
of unknown particle orientations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plot2Spectra: an Automatic Spectra Extraction Tool. (arXiv:2107.02827v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weixin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwenker_E/0/1/0/all/0/1">Eric Schwenker</a>, <a href="http://arxiv.org/find/cs/1/au:+Spreadbury_T/0/1/0/all/0/1">Trevor Spreadbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_M/0/1/0/all/0/1">Maria K.Y. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cossairt_O/0/1/0/all/0/1">Oliver Cossairt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02827">
                                    <div class="article-summary-box-inner">
                                        <span>Different types of spectroscopies, such as X-ray absorption near edge
structure (XANES) and Raman spectroscopy, play a very important role in
analyzing the characteristics of different materials. In scientific literature,
XANES/Raman data are usually plotted in line graphs which is a visually
appropriate way to represent the information when the end-user is a human
reader. However, such graphs are not conducive to direct programmatic analysis
due to the lack of automatic tools. In this paper, we develop a plot digitizer,
named Plot2Spectra, to extract data points from spectroscopy graph images in an
automatic fashion, which makes it possible for large scale data acquisition and
analysis. Specifically, the plot digitizer is a two-stage framework. In the
first axis alignment stage, we adopt an anchor-free detector to detect the plot
region and then refine the detected bounding boxes with an edge-based
constraint to locate the position of two axes. We also apply scene text
detector to extract and interpret all tick information below the x-axis. In the
second plot data extraction stage, we first employ semantic segmentation to
separate pixels belonging to plot lines from the background, and from there,
incorporate optical flow constraints to the plot line pixels to assign them to
the appropriate line (data instance) they encode. Extensive experiments are
conducted to validate the effectiveness of the proposed plot digitizer, which
shows that such a tool could help accelerate the discovery and machine learning
of materials properties.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A convolutional neural network for teeth margin detection on 3-dimensional dental meshes. (arXiv:2107.03030v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bifu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kenan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchun Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03030">
                                    <div class="article-summary-box-inner">
                                        <span>We proposed a convolutional neural network for vertex classification on
3-dimensional dental meshes, and used it to detect teeth margins. An expanding
layer was constructed to collect statistic values of neighbor vertex features
and compute new features for each vertex with convolutional neural networks. An
end-to-end neural network was proposed to take vertex features, including
coordinates, curvatures and distance, as input and output each vertex
classification label. Several network structures with different parameters of
expanding layers and a base line network without expanding layers were designed
and trained by 1156 dental meshes. The accuracy, recall and precision were
validated on 145 dental meshes to rate the best network structures, which were
finally tested on another 144 dental meshes. All networks with our expanding
layers performed better than baseline, and the best one achieved an accuracy of
0.877 both on validation dataset and test dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Outdoor Scene Relighting. (arXiv:2107.03106v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Ye Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1">Abhimitra Meka</a>, <a href="http://arxiv.org/find/cs/1/au:+Elgharib_M/0/1/0/all/0/1">Mohamed Elgharib</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_H/0/1/0/all/0/1">Hans-Peter Seidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_W/0/1/0/all/0/1">William A. P. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03106">
                                    <div class="article-summary-box-inner">
                                        <span>Outdoor scene relighting is a challenging problem that requires good
understanding of the scene geometry, illumination and albedo. Current
techniques are completely supervised, requiring high quality synthetic
renderings to train a solution. Such renderings are synthesized using priors
learned from limited data. In contrast, we propose a self-supervised approach
for relighting. Our approach is trained only on corpora of images collected
from the internet without any user-supervision. This virtually endless source
of training data allows training a general relighting solution. Our approach
first decomposes an image into its albedo, geometry and illumination. A novel
relighting is then produced by modifying the illumination parameters. Our
solution capture shadow using a dedicated shadow prediction map, and does not
rely on accurate geometry estimation. We evaluate our technique subjectively
and objectively using a new dataset with ground-truth relighting. Results show
the ability of our technique to produce photo-realistic and physically
plausible results, that generalizes to unseen scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Convolutional Correlation Iterative Particle Filter for Visual Tracking. (arXiv:2107.02984v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mozhdehi_R/0/1/0/all/0/1">Reza Jalil Mozhdehi</a>, <a href="http://arxiv.org/find/cs/1/au:+Medeiros_H/0/1/0/all/0/1">Henry Medeiros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02984">
                                    <div class="article-summary-box-inner">
                                        <span>This work proposes a novel framework for visual tracking based on the
integration of an iterative particle filter, a deep convolutional neural
network, and a correlation filter. The iterative particle filter enables the
particles to correct themselves and converge to the correct target position. We
employ a novel strategy to assess the likelihood of the particles after the
iterations by applying K-means clustering. Our approach ensures a consistent
support for the posterior distribution. Thus, we do not need to perform
resampling at every video frame, improving the utilization of prior
distribution information. Experimental results on two different benchmark
datasets show that our tracker performs favorably against state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poly-NL: Linear Complexity Non-local Layers with Polynomials. (arXiv:2107.02859v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Babiloni_F/0/1/0/all/0/1">Francesca Babiloni</a>, <a href="http://arxiv.org/find/cs/1/au:+Marras_I/0/1/0/all/0/1">Ioannis Marras</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1">Filippos Kokkinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiankang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1">Grigorios Chrysos</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02859">
                                    <div class="article-summary-box-inner">
                                        <span>Spatial self-attention layers, in the form of Non-Local blocks, introduce
long-range dependencies in Convolutional Neural Networks by computing pairwise
similarities among all possible positions. Such pairwise functions underpin the
effectiveness of non-local layers, but also determine a complexity that scales
quadratically with respect to the input size both in space and time. This is a
severely limiting factor that practically hinders the applicability of
non-local blocks to even moderately sized inputs. Previous works focused on
reducing the complexity by modifying the underlying matrix operations, however
in this work we aim to retain full expressiveness of non-local layers while
keeping complexity linear. We overcome the efficiency limitation of non-local
blocks by framing them as special cases of 3rd order polynomial functions. This
fact enables us to formulate novel fast Non-Local blocks, capable of reducing
the complexity from quadratic to linear with no loss in performance, by
replacing any direct computation of pairwise similarities with element-wise
multiplications. The proposed method, which we dub as &quot;Poly-NL&quot;, is competitive
with state-of-the-art performance across image recognition, instance
segmentation, and face detection tasks, while having considerably less
computational overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Offset-Guided Keypoint Grouping for Human Pose Estimation. (arXiv:2107.03098v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1">Linhua Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zengfu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03098">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a simple yet reliable bottom-up approach with a good trade-off
between accuracy and efficiency for the problem of multi-person pose
estimation. Given an image, we employ an Hourglass Network to infer all the
keypoints from different persons indiscriminately as well as the guiding
offsets connecting the adjacent keypoints belonging to the same persons. Then,
we greedily group the candidate keypoints into multiple human poses (if any),
utilizing the predicted guiding offsets. And we refer to this process as greedy
offset-guided keypoint grouping (GOG). Moreover, we revisit the
encoding-decoding method for the multi-person keypoint coordinates and reveal
some important facts affecting accuracy. Experiments have demonstrated the
obvious performance improvements brought by the introduced components. Our
approach is comparable to the state of the art on the challenging COCO dataset
under fair conditions. The source code and our pre-trained model are publicly
available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GA-NET: Global Attention Network for Point Cloud Semantic Segmentation. (arXiv:2107.03101v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shuang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03101">
                                    <div class="article-summary-box-inner">
                                        <span>How to learn long-range dependencies from 3D point clouds is a challenging
problem in 3D point cloud analysis. Addressing this problem, we propose a
global attention network for point cloud semantic segmentation, named as
GA-Net, consisting of a point-independent global attention module and a
point-dependent global attention module for obtaining contextual information of
3D point clouds in this paper. The point-independent global attention module
simply shares a global attention map for all 3D points. In the point-dependent
global attention module, for each point, a novel random cross attention block
using only two randomly sampled subsets is exploited to learn the contextual
information of all the points. Additionally, we design a novel point-adaptive
aggregation block to replace linear skip connection for aggregating more
discriminate features. Extensive experimental results on three 3D public
datasets demonstrate that our method outperforms state-of-the-art methods in
most cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Affect Analysis using standardized data within subjects in the Wild. (arXiv:2107.03009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Youoku_S/0/1/0/all/0/1">Sachihiro Youoku</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_T/0/1/0/all/0/1">Takahisa Yamamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_J/0/1/0/all/0/1">Junya Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_A/0/1/0/all/0/1">Akiyoshi Uchida</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_X/0/1/0/all/0/1">Xiaoyu Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Ziqiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhongling Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03009">
                                    <div class="article-summary-box-inner">
                                        <span>Human affective recognition is an important factor in human-computer
interaction. However, the method development with in-the-wild data is not yet
accurate enough for practical usage. In this paper, we introduce the affective
recognition method focusing on facial expression (EXP) and valence-arousal
calculation that was submitted to the Affective Behavior Analysis in-the-wild
(ABAW) 2021 Contest.

When annotating facial expressions from a video, we thought that it would be
judged not only from the features common to all people, but also from the
relative changes in the time series of individuals. Therefore, after learning
the common features for each frame, we constructed a facial expression
estimation model and valence-arousal model using time-series data after
combining the common features and the standardized features for each video.
Furthermore, the above features were learned using multi-modal data such as
image features, AU, Head pose, and Gaze. In the validation set, our model
achieved a facial expression score of 0.546. These verification results reveal
that our proposed framework can improve estimation accuracy and robustness
effectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1">Danny Tarlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maintaining a Reliable World Model using Action-aware Perceptual Anchoring. (arXiv:2107.03038v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Ying Siu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dongkyu Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_K/0/1/0/all/0/1">Kenneth Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03038">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable perception is essential for robots that interact with the world. But
sensors alone are often insufficient to provide this capability, and they are
prone to errors due to various conditions in the environment. Furthermore,
there is a need for robots to maintain a model of its surroundings even when
objects go out of view and are no longer visible. This requires anchoring
perceptual information onto symbols that represent the objects in the
environment. In this paper, we present a model for action-aware perceptual
anchoring that enables robots to track objects in a persistent manner. Our
rule-based approach considers inductive biases to perform high-level reasoning
over the results from low-level object detection, and it improves the robot&#x27;s
perceptual capability for complex tasks. We evaluate our model against existing
baseline models for object permanence and show that it outperforms these on a
snitch localisation task using a dataset of 1,371 videos. We also integrate our
action-aware perceptual anchoring in the context of a cognitive architecture
and demonstrate its benefits in a realistic gearbox assembly task on a
Universal Robot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video-Based Camera Localization Using Anchor View Detection and Recursive 3D Reconstruction. (arXiv:2107.03068v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taira_H/0/1/0/all/0/1">Hajime Taira</a>, <a href="http://arxiv.org/find/cs/1/au:+Onbe_K/0/1/0/all/0/1">Koki Onbe</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyashita_N/0/1/0/all/0/1">Naoyuki Miyashita</a>, <a href="http://arxiv.org/find/cs/1/au:+Okutomi_M/0/1/0/all/0/1">Masatoshi Okutomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03068">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we introduce a new camera localization strategy designed for
image sequences captured in challenging industrial situations such as
industrial parts inspection. To deal with peculiar appearances that hurt
standard 3D reconstruction pipeline, we exploit pre-knowledge of the scene by
selecting key frames in the sequence (called as anchors) which are roughly
connected to a certain location. Our method then seek the location of each
frame in time-order, while recursively updating an augmented 3D model which can
provide current camera location and surrounding 3D structure. In an experiment
on a practical industrial situation, our method can localize over 99% frames in
the input sequence, whereas standard localization methods fail to reconstruct a
complete camera trajectory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Vision Transformer with Squeeze and Excitation for Facial Expression Recognition. (arXiv:2107.03107v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aouayeb_M/0/1/0/all/0/1">Mouath Aouayeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Soladie_C/0/1/0/all/0/1">Catherine Soladie</a>, <a href="http://arxiv.org/find/cs/1/au:+Kpalma_K/0/1/0/all/0/1">Kidiyo Kpalma</a>, <a href="http://arxiv.org/find/cs/1/au:+Seguier_R/0/1/0/all/0/1">Renaud Seguier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03107">
                                    <div class="article-summary-box-inner">
                                        <span>As various databases of facial expressions have been made accessible over the
last few decades, the Facial Expression Recognition (FER) task has gotten a lot
of interest. The multiple sources of the available databases raised several
challenges for facial recognition task. These challenges are usually addressed
by Convolution Neural Network (CNN) architectures. Different from CNN models, a
Transformer model based on attention mechanism has been presented recently to
address vision tasks. One of the major issue with Transformers is the need of a
large data for training, while most FER databases are limited compared to other
vision applications. Therefore, we propose in this paper to learn a vision
Transformer jointly with a Squeeze and Excitation (SE) block for FER task. The
proposed method is evaluated on different publicly available FER databases
including CK+, JAFFE,RAF-DB and SFEW. Experiments demonstrate that our model
outperforms state-of-the-art methods on CK+ and SFEW and achieves competitive
results on JAFFE and RAF-DB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VIN: Voxel-based Implicit Network for Joint 3D Object Detection and Segmentation for Lidars. (arXiv:2107.02980v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yuanxin Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Minghan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Huei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02980">
                                    <div class="article-summary-box-inner">
                                        <span>A unified neural network structure is presented for joint 3D object detection
and point cloud segmentation in this paper. We leverage rich supervision from
both detection and segmentation labels rather than using just one of them. In
addition, an extension based on single-stage object detectors is proposed based
on the implicit function widely used in 3D scene and object understanding. The
extension branch takes the final feature map from the object detection module
as input, and produces an implicit function that generates semantic
distribution for each point for its corresponding voxel center. We demonstrated
the performance of our structure on nuScenes-lidarseg, a large-scale outdoor
dataset. Our solution achieves competitive results against state-of-the-art
methods in both 3D object detection and point cloud segmentation with little
additional computation load compared with object detection solutions. The
capability of efficient weakly supervision semantic segmentation of the
proposed method is also validated by experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpectralFormer: Rethinking Hyperspectral Image Classification with Transformers. (arXiv:2107.02988v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Danfeng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jing Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Lianru Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Plaza_A/0/1/0/all/0/1">Antonio Plaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1">Jocelyn Chanussot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02988">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral (HS) images are characterized by approximately contiguous
spectral information, enabling the fine identification of materials by
capturing subtle spectral discrepancies. Owing to their excellent locally
contextual modeling ability, convolutional neural networks (CNNs) have been
proven to be a powerful feature extractor in HS image classification. However,
CNNs fail to mine and represent the sequence attributes of spectral signatures
well due to the limitations of their inherent network backbone. To solve this
issue, we rethink HS image classification from a sequential perspective with
transformers, and propose a novel backbone network called \ul{SpectralFormer}.
Beyond band-wise representations in classic transformers, SpectralFormer is
capable of learning spectrally local sequence information from neighboring
bands of HS images, yielding group-wise spectral embeddings. More
significantly, to reduce the possibility of losing valuable information in the
layer-wise propagation process, we devise a cross-layer skip connection to
convey memory-like components from shallow to deep layers by adaptively
learning to fuse &quot;soft&quot; residuals across layers. It is worth noting that the
proposed SpectralFormer is a highly flexible backbone network, which can be
applicable to both pixel- and patch-wise inputs. We evaluate the classification
performance of the proposed SpectralFormer on three HS datasets by conducting
extensive experiments, showing the superiority over classic transformers and
achieving a significant improvement in comparison with state-of-the-art
backbone networks. The codes of this work will be available at
\url{https://sites.google.com/view/danfeng-hong} for the sake of
reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn to Learn Metric Space for Few-Shot Segmentation of 3D Shapes. (arXiv:2107.02972v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lingjing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yi Fang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02972">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has seen numerous supervised learning-based methods for 3D
shape segmentation and remarkable performance has been achieved on various
benchmark datasets. These supervised methods require a large amount of
annotated data to train deep neural networks to ensure the generalization
ability on the unseen test set. In this paper, we introduce a
meta-learning-based method for few-shot 3D shape segmentation where only a few
labeled samples are provided for the unseen classes. To achieve this, we treat
the shape segmentation as a point labeling problem in the metric space.
Specifically, we first design a meta-metric learner to transform input shapes
into embedding space and our model learns to learn a proper metric space for
each object class based on point embeddings. Then, for each class, we design a
metric learner to extract part-specific prototype representations from a few
support shapes and our model performs per-point segmentation over the query
shapes by matching each point to its nearest prototype in the learned metric
space. A metric-based loss function is used to dynamically modify distances
between point embeddings thus maximizes in-part similarity while minimizing
inter-part similarity. A dual segmentation branch is adopted to make full use
of the support information and implicitly encourages consistency between the
support and query prototypes. We demonstrate the superior performance of our
proposed on the ShapeNet part dataset under the few-shot scenario, compared
with well-established baseline and state-of-the-art semi-supervised methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge-aware Bidirectional Diffusion for Dense Depth Estimation from Light Fields. (arXiv:2107.02967v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Numair Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Min H. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tompkin_J/0/1/0/all/0/1">James Tompkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02967">
                                    <div class="article-summary-box-inner">
                                        <span>We present an algorithm to estimate fast and accurate depth maps from light
fields via a sparse set of depth edges and gradients. Our proposed approach is
based around the idea that true depth edges are more sensitive than texture
edges to local constraints, and so they can be reliably disambiguated through a
bidirectional diffusion process. First, we use epipolar-plane images to
estimate sub-pixel disparity at a sparse set of pixels. To find sparse points
efficiently, we propose an entropy-based refinement approach to a line estimate
from a limited set of oriented filter banks. Next, to estimate the diffusion
direction away from sparse points, we optimize constraints at these points via
our bidirectional diffusion method. This resolves the ambiguity of which
surface the edge belongs to and reliably separates depth from texture edges,
allowing us to diffuse the sparse set in a depth-edge and occlusion-aware
manner to obtain accurate dense depth maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN-based Data Augmentation for Chest X-ray Classification. (arXiv:2107.02970v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1">Shobhita Sundaram</a>, <a href="http://arxiv.org/find/eess/1/au:+Hulkund_N/0/1/0/all/0/1">Neha Hulkund</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02970">
                                    <div class="article-summary-box-inner">
                                        <span>A common problem in computer vision -- particularly in medical applications
-- is a lack of sufficiently diverse, large sets of training data. These
datasets often suffer from severe class imbalance. As a result, networks often
overfit and are unable to generalize to novel examples. Generative Adversarial
Networks (GANs) offer a novel method of synthetic data augmentation. In this
work, we evaluate the use of GAN- based data augmentation to artificially
expand the CheXpert dataset of chest radiographs. We compare performance to
traditional augmentation and find that GAN-based augmentation leads to higher
downstream performance for underrepresented classes. Furthermore, we see that
this result is pronounced in low data regimens. This suggests that GAN-based
augmentation a promising area of research to improve network performance when
data collection is prohibitively expensive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PoseRN: A 2D pose refinement network for bias-free multi-view 3D human pose estimation. (arXiv:2107.03000v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sayo_A/0/1/0/all/0/1">Akihiko Sayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_D/0/1/0/all/0/1">Diego Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawasaki_H/0/1/0/all/0/1">Hiroshi Kawasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakashima_Y/0/1/0/all/0/1">Yuta Nakashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikeuchi_K/0/1/0/all/0/1">Katsushi Ikeuchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03000">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new 2D pose refinement network that learns to predict the human
bias in the estimated 2D pose. There are biases in 2D pose estimations that are
due to differences between annotations of 2D joint locations based on
annotators&#x27; perception and those defined by motion capture (MoCap) systems.
These biases are crafted into publicly available 2D pose datasets and cannot be
removed with existing error reduction approaches. Our proposed pose refinement
network allows us to efficiently remove the human bias in the estimated 2D
poses and achieve highly accurate multi-view 3D human pose estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLiT: Neural Architecture Search for Global and Local Image Transformer. (arXiv:2107.02960v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+yan_J/0/1/0/all/0/1">Junjie yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02960">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the first Neural Architecture Search (NAS) method to find a
better transformer architecture for image recognition. Recently, transformers
without CNN-based backbones are found to achieve impressive performance for
image recognition. However, the transformer is designed for NLP tasks and thus
could be sub-optimal when directly used for image recognition. In order to
improve the visual representation ability for transformers, we propose a new
search space and searching algorithm. Specifically, we introduce a locality
module that models the local correlations in images explicitly with fewer
computational cost. With the locality module, our search space is defined to
let the search algorithm freely trade off between global and local information
as well as optimizing the low-level design choice in each module. To tackle the
problem caused by huge search space, a hierarchical neural architecture search
method is proposed to search the optimal vision transformer from two levels
separately with the evolutionary algorithm. Extensive experiments on the
ImageNet dataset demonstrate that our method can find more discriminative and
efficient transformer variants than the ResNet family (e.g., ResNet101) and the
baseline ViT for image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group Sampling for Unsupervised Person Re-identification. (arXiv:2107.03024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xumeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xuehui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guorong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhenjun Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03024">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised person re-identification (re-ID) remains a challenging task,
where the classifier and feature representation could be easily misled by the
noisy pseudo labels towards deteriorated over-fitting. In this paper, we
propose a simple yet effective approach, termed Group Sampling, to alleviate
the negative impact of noisy pseudo labels within unsupervised person re-ID
models. The idea behind Group Sampling is that it can gather a group of samples
from the same class in the same mini-batch, such that the model is trained upon
group normalized samples while alleviating the effect of a single sample. Group
sampling updates the pipeline of pseudo label generation by guaranteeing the
samples to be better divided into the correct classes. Group Sampling
regularizes classifier training and representation learning, leading to the
statistical stability of feature representation in a progressive fashion.
Qualitative and quantitative experiments on Market-1501, DukeMTMC-reID, and
MSMT17 show that Grouping Sampling improves the state-of-the-arts by up to
2.2%~6.1%. Code is available at https://github.com/wavinflaghxm/GroupSampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E-PixelHop: An Enhanced PixelHop Method for Object Classification. (arXiv:2107.02966v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yijing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Magoulianitis_V/0/1/0/all/0/1">Vasileios Magoulianitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02966">
                                    <div class="article-summary-box-inner">
                                        <span>Based on PixelHop and PixelHop++, which are recently developed using the
successive subspace learning (SSL) framework, we propose an enhanced solution
for object classification, called E-PixelHop, in this work. E-PixelHop consists
of the following steps. First, to decouple the color channels for a color
image, we apply principle component analysis and project RGB three color
channels onto two principle subspaces which are processed separately for
classification. Second, to address the importance of multi-scale features, we
conduct pixel-level classification at each hop with various receptive fields.
Third, to further improve pixel-level classification accuracy, we develop a
supervised label smoothing (SLS) scheme to ensure prediction consistency.
Forth, pixel-level decisions from each hop and from each color subspace are
fused together for image-level decision. Fifth, to resolve confusing classes
for further performance boosting, we formulate E-PixelHop as a two-stage
pipeline. In the first stage, multi-class classification is performed to get a
soft decision for each class, where the top 2 classes with the highest
probabilities are called confusing classes. Then,we conduct a binary
classification in the second stage. The main contributions lie in Steps 1, 3
and 5.We use the classification of the CIFAR-10 dataset as an example to
demonstrate the effectiveness of the above-mentioned key components of
E-PixelHop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SelfCF: A Simple Framework for Self-supervised Collaborative Filtering. (arXiv:2107.03019v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1">Aixin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03019">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is widely used to learn an informative latent
representation of a user or item from observed interactions. Existing CF-based
methods commonly adopt negative sampling to discriminate different items. That
is, observed user-item pairs are treated as positive instances; unobserved
pairs are considered as negative instances and are sampled under a defined
distribution for training. Training with negative sampling on large datasets is
computationally expensive. Further, negative items should be carefully sampled
under the defined distribution, in order to avoid selecting an observed
positive item in the training dataset. Unavoidably, some negative items sampled
from the training dataset could be positive in the test set. Recently,
self-supervised learning (SSL) has emerged as a powerful tool to learn a model
without negative samples. In this paper, we propose a self-supervised
collaborative filtering framework (SelfCF), that is specially designed for
recommender scenario with implicit feedback. The main idea of SelfCF is to
augment the output embeddings generated by backbone networks, because it is
infeasible to augment raw input of user/item ids. We propose and study three
output perturbation techniques that can be applied to different types of
backbone networks including both traditional CF models and graph-based models.
By encapsulating two popular recommendation models into the framework, our
experiments on three datasets show that the best performance of our framework
is comparable or better than the supervised counterpart. We also show that
SelfCF can boost up the performance by up to 8.93\% on average, compared with
another self-supervised framework as the baseline. Source codes are available
at: https://github.com/enoche/SelfCF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Are you sure?&quot;: Preliminary Insights from Scaling Product Comparisons to Multiple Shops. (arXiv:2107.03256v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chia_P/0/1/0/all/0/1">Patrick John Chia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bingqing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1">Jacopo Tagliabue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03256">
                                    <div class="article-summary-box-inner">
                                        <span>Large eCommerce players introduced comparison tables as a new type of
recommendations. However, building comparisons at scale without pre-existing
training/taxonomy data remains an open challenge, especially within the
operational constraints of shops in the long tail. We present preliminary
results from building a comparison pipeline designed to scale in a multi-shop
scenario: we describe our design choices and run extensive benchmarks on
multiple shops to stress-test it. Finally, we run a small user study on
property selection and conclude by discussing potential improvements and
highlighting the questions that remain to be addressed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graphing else matters: exploiting aspect opinions and ratings in explainable graph-based recommendations. (arXiv:2107.03226v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cantador_I/0/1/0/all/0/1">Iv&#xe1;n Cantador</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diez_F/0/1/0/all/0/1">Fernando Diez</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_D/0/1/0/all/0/1">Denis Parra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03226">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural network embeddings has entailed a renewed interest in
using knowledge graphs for a wide variety of machine learning and information
retrieval tasks. In particular, current recommendation methods based on graph
embeddings have shown state-of-the-art performance. These methods commonly
encode latent rating patterns and content features. Different from previous
work, in this paper, we propose to exploit embeddings extracted from graphs
that combine information from ratings and aspect-based opinions expressed in
textual reviews. We then adapt and evaluate state-of-the-art graph embedding
techniques over graphs generated from Amazon and Yelp reviews on six domains,
outperforming baseline recommenders. Our approach has the advantage of
providing explanations which leverage aspect-based opinions given by users
about recommended items. Furthermore, we also provide examples of the
applicability of recommendations utilizing aspect opinions as explanations in a
visualization dashboard, which allows obtaining information about the most and
least liked aspects of similar users obtained from the embeddings of an input
graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoDebias: Learning to Debias for Recommendation. (arXiv:2105.04170v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hande Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guli Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Keping Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04170">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems rely on user behavior data like ratings and clicks to
build personalization model. However, the collected data is observational
rather than experimental, causing various biases in the data which
significantly affect the learned model. Most existing work for recommendation
debiasing, such as the inverse propensity scoring and imputation approaches,
focuses on one or two specific biases, lacking the universal capacity that can
account for mixed or even unknown biases in the data.

Towards this research gap, we first analyze the origin of biases from the
perspective of \textit{risk discrepancy} that represents the difference between
the expectation empirical risk and the true risk. Remarkably, we derive a
general learning framework that well summarizes most existing debiasing
strategies by specifying some parameters of the general framework. This
provides a valuable opportunity to develop a universal solution for debiasing,
e.g., by learning the debiasing parameters from data. However, the training
data lacks important signal of how the data is biased and what the unbiased
data looks like. To move this idea forward, we propose \textit{AotoDebias} that
leverages another (small) set of uniform data to optimize the debiasing
parameters by solving the bi-level optimization problem with meta-learning.
Through theoretical analyses, we derive the generalization bound for AutoDebias
and prove its ability to acquire the appropriate debiasing strategy. Extensive
experiments on two real datasets and a simulated dataset demonstrated
effectiveness of AutoDebias. The code is available at
\url{https://github.com/DongHande/AutoDebias}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness. (arXiv:2105.00855v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1">Harrie Oosterhuis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00855">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has proposed stochastic Plackett-Luce (PL) ranking models as a
robust choice for optimizing relevance and fairness metrics. Unlike their
deterministic counterparts that require heuristic optimization algorithms, PL
models are fully differentiable. Theoretically, they can be used to optimize
ranking metrics via stochastic gradient descent. However, in practice, the
computation of the gradient is infeasible because it requires one to iterate
over all possible permutations of items. Consequently, actual applications rely
on approximating the gradient via sampling techniques. In this paper, we
introduce a novel algorithm: PL-Rank, that estimates the gradient of a PL
ranking model w.r.t. both relevance and fairness metrics. Unlike existing
approaches that are based on policy gradients, PL-Rank makes use of the
specific structure of PL models and ranking metrics. Our experimental analysis
shows that PL-Rank has a greater sample-efficiency and is computationally less
costly than existing policy gradients, resulting in faster convergence at
higher performance. PL-Rank further enables the industry to apply PL models for
more relevant and fairer real-world ranking systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Big Are Peoples&#x27; Computer Files? File Size Distributions Among User-managed Collections. (arXiv:2107.03272v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dinneen_J/0/1/0/all/0/1">Jesse David Dinneen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Ba Xuan Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03272">
                                    <div class="article-summary-box-inner">
                                        <span>Improving file management interfaces and optimising system performance
requires current data about users&#x27; digital collections and particularly about
the file size distributions of such collections. However, prior works have
examined only the sizes of system files and users&#x27; work files in varied
contexts, and there has been no such study since 2013; it therefore remains
unclear how today&#x27;s file sizes are distributed, particularly personal files,
and further if distributions differ among the major operating systems or common
occupations. Here we examine such differences among 49 million files in 348
user collections. We find that the average file size has grown more than
ten-fold since the mid-2000s, though most files are still under 8 MB, and that
there are demographic and technological influences in the size distributions.
We discuss the implications for user interfaces, system optimisation, and PIM
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Episodic Bandits with Stochastic Experts. (arXiv:2107.03263v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1">Nihal Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1">Soumya Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1">Karthikeyan Shanmugam</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03263">
                                    <div class="article-summary-box-inner">
                                        <span>We study a version of the contextual bandit problem where an agent is given
soft control of a node in a graph-structured environment through a set of
stochastic expert policies. The agent interacts with the environment over
episodes, with each episode having different context distributions; this
results in the &#x60;best expert&#x27; changing across episodes. Our goal is to develop
an agent that tracks the best expert over episodes. We introduce the Empirical
Divergence-based UCB (ED-UCB) algorithm in this setting where the agent does
not have any knowledge of the expert policies or changes in context
distributions. With mild assumptions, we show that bootstrapping from
$\tilde{O}(N\log(NT^2\sqrt{E}))$ samples results in a regret of
$\tilde{O}(E(N+1) + \frac{N\sqrt{E}}{T^2})$. If the expert policies are known
to the agent a priori, then we can improve the regret to $\tilde{O}(EN)$
without requiring any bootstrapping. Our analysis also tightens pre-existing
logarithmic regret bounds to a problem-dependent constant in the non-episodic
setting when expert policies are known. We finally empirically validate our
findings through simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KaFiStO: A Kalman Filtering Framework for Stochastic Optimization. (arXiv:2107.03331v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davtyan_A/0/1/0/all/0/1">Aram Davtyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sameni_S/0/1/0/all/0/1">Sepehr Sameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerkezi_L/0/1/0/all/0/1">Llukman Cerkezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Meishvilli_G/0/1/0/all/0/1">Givi Meishvilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielski_A/0/1/0/all/0/1">Adam Bielski</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1">Paolo Favaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03331">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization is often cast as a deterministic problem, where the solution is
found through some iterative procedure such as gradient descent. However, when
training neural networks the loss function changes over (iteration) time due to
the randomized selection of a subset of the samples. This randomization turns
the optimization problem into a stochastic one. We propose to consider the loss
as a noisy observation with respect to some reference optimum. This
interpretation of the loss allows us to adopt Kalman filtering as an optimizer,
as its recursive formulation is designed to estimate unknown parameters from
noisy measurements. Moreover, we show that the Kalman Filter dynamical model
for the evolution of the unknown parameters can be used to capture the gradient
dynamics of advanced methods such as Momentum and Adam. We call this stochastic
optimization method KaFiStO. KaFiStO is an easy to implement, scalable, and
efficient method to train neural networks. We show that it also yields
parameter estimates that are on par with or better than existing optimization
algorithms across several neural network architectures and machine learning
tasks, such as computer vision and language modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularization-based Continual Learning for Fault Prediction in Lithium-Ion Batteries. (arXiv:2107.03336v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maschler_B/0/1/0/all/0/1">Benjamin Maschler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatiyosyan_S/0/1/0/all/0/1">Sophia Tatiyosyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1">Michael Weyrich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03336">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the use of lithium-ion batteries has greatly expanded into
products from many industrial sectors, e.g. cars, power tools or medical
devices. An early prediction and robust understanding of battery faults could
therefore greatly increase product quality in those fields. While current
approaches for data-driven fault prediction provide good results on the exact
processes they were trained on, they often lack the ability to flexibly adapt
to changes, e.g. in operational or environmental parameters. Continual learning
promises such flexibility, allowing for an automatic adaption of previously
learnt knowledge to new tasks. Therefore, this article discusses different
continual learning approaches from the group of regularization strategies,
which are implemented, evaluated and compared based on a real battery wear
dataset. Online elastic weight consolidation delivers the best results, but, as
with all examined approaches, its performance appears to be strongly dependent
on task characteristics and task sequence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices. (arXiv:2008.02790v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1">Evan Zheran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Aditi Raghunathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02790">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of meta-reinforcement learning (meta-RL) is to build agents that can
quickly learn new tasks by leveraging prior experience on related tasks.
Learning a new task often requires both exploring to gather task-relevant
information and exploiting this information to solve the task. In principle,
optimal exploration and exploitation can be learned end-to-end by simply
maximizing task performance. However, such meta-RL approaches struggle with
local optima due to a chicken-and-egg problem: learning to explore requires
good exploitation to gauge the exploration&#x27;s utility, but learning to exploit
requires information gathered via exploration. Optimizing separate objectives
for exploration and exploitation can avoid this problem, but prior meta-RL
exploration objectives yield suboptimal policies that gather information
irrelevant to the task. We alleviate both concerns by constructing an
exploitation objective that automatically identifies task-relevant information
and an exploration objective to recover only this information. This avoids
local optima in end-to-end training, without sacrificing optimal exploration.
Empirically, DREAM substantially outperforms existing approaches on complex
meta-RL problems, such as sparse-reward 3D visual navigation. Videos of DREAM:
https://ezliu.github.io/dream/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Approximation for Log-concave Distributions using Well-conditioned Normalizing Flows. (arXiv:2107.02951v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Holden Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pabbaraju_C/0/1/0/all/0/1">Chirag Pabbaraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Sevekari_A/0/1/0/all/0/1">Anish Sevekari</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02951">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are a widely used class of latent-variable generative
models with a tractable likelihood. Affine-coupling (Dinh et al, 2014-16)
models are a particularly common type of normalizing flows, for which the
Jacobian of the latent-to-observable-variable transformation is triangular,
allowing the likelihood to be computed in linear time. Despite the widespread
usage of affine couplings, the special structure of the architecture makes
understanding their representational power challenging. The question of
universal approximation was only recently resolved by three parallel papers
(Huang et al.,2020;Zhang et al.,2020;Koehler et al.,2020) -- who showed
reasonably regular distributions can be approximated arbitrarily well using
affine couplings -- albeit with networks with a nearly-singular Jacobian. As
ill-conditioned Jacobians are an obstacle for likelihood-based training, the
fundamental question remains: which distributions can be approximated using
well-conditioned affine coupling flows?

In this paper, we show that any log-concave distribution can be approximated
using well-conditioned affine-coupling flows. In terms of proof techniques, we
uncover and leverage deep connections between affine coupling architectures,
underdamped Langevin dynamics (a stochastic differential equation often used to
sample from Gibbs measures) and H\&#x27;enon maps (a structured dynamical system
that appears in the study of symplectic diffeomorphisms). Our results also
inform the practice of training affine couplings: we approximate a padded
version of the input distribution with iid Gaussians -- a strategy which
Koehler et al.(2020) empirically observed to result in better-conditioned
flows, but had hitherto no theoretical grounding. Our proof can thus be seen as
providing theoretical evidence for the benefits of Gaussian padding when
training normalizing flows.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust learning under clean-label attack. (arXiv:2103.00671v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blum_A/0/1/0/all/0/1">Avrim Blum</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1">Steve Hanneke</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1">Jian Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1">Han Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00671">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of robust learning under clean-label data-poisoning
attacks, where the attacker injects (an arbitrary set of) correctly-labeled
examples to the training set to fool the algorithm into making mistakes on
specific test instances at test time. The learning goal is to minimize the
attackable rate (the probability mass of attackable test instances), which is
more difficult than optimal PAC learning. As we show, any robust algorithm with
diminishing attackable rate can achieve the optimal dependence on $\epsilon$ in
its PAC sample complexity, i.e., $O(1/\epsilon)$. On the other hand, the
attackable rate might be large even for some optimal PAC learners, e.g., SVM
for linear classifiers. Furthermore, we show that the class of linear
hypotheses is not robustly learnable when the data distribution has zero margin
and is robustly learnable in the case of positive margin but requires sample
complexity exponential in the dimension. For a general hypothesis class with
bounded VC dimension, if the attacker is limited to add at most $t&gt;0$ poison
examples, the optimal robust learning sample complexity grows almost linearly
with $t$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SoundStream: An End-to-End Neural Audio Codec. (arXiv:2107.03312v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeghidour_N/0/1/0/all/0/1">Neil Zeghidour</a>, <a href="http://arxiv.org/find/cs/1/au:+Luebs_A/0/1/0/all/0/1">Alejandro Luebs</a>, <a href="http://arxiv.org/find/cs/1/au:+Omran_A/0/1/0/all/0/1">Ahmed Omran</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoglund_J/0/1/0/all/0/1">Jan Skoglund</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_M/0/1/0/all/0/1">Marco Tagliasacchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03312">
                                    <div class="article-summary-box-inner">
                                        <span>We present SoundStream, a novel neural audio codec that can efficiently
compress speech, music and general audio at bitrates normally targeted by
speech-tailored codecs. SoundStream relies on a model architecture composed by
a fully convolutional encoder/decoder network and a residual vector quantizer,
which are trained jointly end-to-end. Training leverages recent advances in
text-to-speech and speech enhancement, which combine adversarial and
reconstruction losses to allow the generation of high-quality audio content
from quantized embeddings. By training with structured dropout applied to
quantizer layers, a single model can operate across variable bitrates from
3kbps to 18kbps, with a negligible quality loss when compared with models
trained at fixed bitrates. In addition, the model is amenable to a low latency
implementation, which supports streamable inference and runs in real time on a
smartphone CPU. In subjective evaluations using audio at 24kHz sampling rate,
SoundStream at 3kbps outperforms Opus at 12kbps and approaches EVS at 9.6kbps.
Moreover, we are able to perform joint compression and enhancement either at
the encoder or at the decoder side with no additional latency, which we
demonstrate through background noise suppression for speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic semi-nonnegative matrix factorization: a Skellam-based framework. (arXiv:2107.03317v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fuentes_B/0/1/0/all/0/1">Benoit Fuentes</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03317">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new probabilistic model to address semi-nonnegative matrix
factorization (SNMF), called Skellam-SNMF. It is a hierarchical generative
model consisting of prior components, Skellam-distributed hidden variables and
observed data. Two inference algorithms are derived: Expectation-Maximization
(EM) algorithm for maximum \emph{a posteriori} estimation and Variational Bayes
EM (VBEM) for full Bayesian inference, including the estimation of parameters
prior distribution. From this Skellam-based model, we also introduce a new
divergence $\mathcal{D}$ between a real-valued target data $x$ and two
nonnegative parameters $\lambda_{0}$ and $\lambda_{1}$ such that
$\mathcal{D}\left(x\mid\lambda_{0},\lambda_{1}\right)&#x3D;0\Leftrightarrow
x&#x3D;\lambda_{0}-\lambda_{1}$, which is a generalization of the Kullback-Leibler
(KL) divergence. Finally, we conduct experimental studies on those new
algorithms in order to understand their behavior and prove that they can
outperform the classic SNMF approach on real data in a task of automatic
clustering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossy Compression for Lossless Prediction. (arXiv:2106.10800v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1">Yann Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloem_Reddy_B/0/1/0/all/0/1">Benjamin Bloem-Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1">Karen Ullrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1">Chris J. Maddison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10800">
                                    <div class="article-summary-box-inner">
                                        <span>Most data is automatically collected and only ever &quot;seen&quot; by algorithms. Yet,
data compressors preserve perceptual fidelity rather than just the information
needed by algorithms performing downstream tasks. In this paper, we
characterize the bit-rate required to ensure high performance on all predictive
tasks that are invariant under a set of transformations, such as data
augmentations. Based on our theory, we design unsupervised objectives for
training neural compressors. Using these objectives, we train a generic image
compressor that achieves substantial rate savings (more than $1000\times$ on
ImageNet) compared to JPEG on 8 datasets, without decreasing downstream
classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model. (arXiv:2010.13118v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lienen_J/0/1/0/all/0/1">Julian Lienen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>, <a href="http://arxiv.org/find/cs/1/au:+Nommensen_N/0/1/0/all/0/1">Nils Nommensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13118">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world applications, the relative depth of objects in an image is
crucial for scene understanding. Recent approaches mainly tackle the problem of
depth prediction in monocular images by treating the problem as a regression
task. Yet, being interested in an order relation in the first place, ranking
methods suggest themselves as a natural alternative to regression, and indeed,
ranking approaches leveraging pairwise comparisons as training information
(&quot;object A is closer to the camera than B&quot;) have shown promising performance on
this problem. In this paper, we elaborate on the use of so-called listwise
ranking as a generalization of the pairwise approach. Our method is based on
the Plackett-Luce (PL) model, a probability distribution on rankings, which we
combine with a state-of-the-art neural network architecture and a simple
sampling strategy to reduce training complexity. Moreover, taking advantage of
the representation of PL as a random utility model, the proposed predictor
offers a natural way to recover (shift-invariant) metric depth information from
ranking-only data provided at training time. An empirical evaluation on several
benchmark datasets in a &quot;zero-shot&quot; setting demonstrates the effectiveness of
our approach compared to existing ranking and regression methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simulated Data Generation Through Algorithmic Force Coefficient Estimation for AI-Based Robotic Projectile Launch Modeling. (arXiv:2105.12833v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1">Sajiv Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Haque_A/0/1/0/all/0/1">Ayaan Haque</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12833">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling of non-rigid object launching and manipulation is complex
considering the wide range of dynamics affecting trajectory, many of which may
be unknown. Using physics models can be inaccurate because they cannot account
for unknown factors and the effects of the deformation of the object as it is
launched; moreover, deriving force coefficients for these models is not
possible without extensive experimental testing. Recently, advancements in
data-powered artificial intelligence methods have allowed learnable models and
systems to emerge. It is desirable to train a model for launch prediction on a
robot, as deep neural networks can account for immeasurable dynamics. However,
the inability to collect large amounts of experimental data decreases
performance of deep neural networks. Through estimating force coefficients, the
accepted physics models can be leveraged to produce adequate supplemental data
to artificially increase the size of the training set, yielding improved neural
networks. In this paper, we introduce a new framework for algorithmic
estimation of force coefficients for non-rigid object launching, which can be
generalized to other domains, in order to generate large datasets. We implement
a novel training algorithm and objective for our deep neural network to
accurately model launch trajectory of non-rigid objects and predict whether
they will hit a series of targets. Our experimental results demonstrate the
effectiveness of using simulated data from force coefficient estimation and
shows the importance of simulated data for training an effective neural
network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally Private Graph Neural Networks. (arXiv:2006.05535v9 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sajadmanesh_S/0/1/0/all/0/1">Sina Sajadmanesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatica_Perez_D/0/1/0/all/0/1">Daniel Gatica-Perez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have demonstrated superior performance in
learning node representations for various graph inference tasks. However,
learning over graph data can raise privacy concerns when nodes represent people
or human-related variables that involve sensitive or personal information.
While numerous techniques have been proposed for privacy-preserving deep
learning over non-relational data, there is less work addressing the privacy
issues pertained to applying deep learning algorithms on graphs. In this paper,
we study the problem of node data privacy, where graph nodes have potentially
sensitive data that is kept private, but they could be beneficial for a central
server for training a GNN over the graph. To address this problem, we develop a
privacy-preserving, architecture-agnostic GNN learning algorithm with formal
privacy guarantees based on Local Differential Privacy (LDP). Specifically, we
propose an LDP encoder and an unbiased rectifier, by which the server can
communicate with the graph nodes to privately collect their data and
approximate the GNN&#x27;s first layer. To further reduce the effect of the injected
noise, we propose to prepend a simple graph convolution layer, called KProp,
which is based on the multi-hop aggregation of the nodes&#x27; features acting as a
denoising mechanism. Finally, we propose a robust training framework, in which
we benefit from KProp&#x27;s denoising capability to increase the accuracy of
inference in the presence of noisy labels. Extensive experiments conducted over
real-world datasets demonstrate that our method can maintain a satisfying level
of accuracy with low privacy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparative Study of Using Spatial-Temporal Graph Convolutional Networks for Predicting Availability in Bike Sharing Schemes. (arXiv:2104.10644v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengyong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongde Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1">Noel E. O&#x27;Connor</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10644">
                                    <div class="article-summary-box-inner">
                                        <span>Accurately forecasting transportation demand is crucial for efficient urban
traffic guidance, control and management. One solution to enhance the level of
prediction accuracy is to leverage graph convolutional networks (GCN), a neural
network based modelling approach with the ability to process data contained in
graph based structures. As a powerful extension of GCN, a spatial-temporal
graph convolutional network (ST-GCN) aims to capture the relationship of data
contained in the graphical nodes across both spatial and temporal dimensions,
which presents a novel deep learning paradigm for the analysis of complex
time-series data that also involves spatial information as present in
transportation use cases. In this paper, we present an Attention-based ST-GCN
(AST-GCN) for predicting the number of available bikes in bike-sharing systems
in cities, where the attention-based mechanism is introduced to further improve
the performance of an ST-GCN. Furthermore, we also discuss the impacts of
different modelling methods of adjacency matrices on the proposed architecture.
Our experimental results are presented using two real-world datasets,
Dublinbikes and NYC-Citi Bike, to illustrate the efficacy of our proposed model
which outperforms the majority of existing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence of Overlapping Schwarz Decomposition for Nonlinear Optimal Control. (arXiv:2005.06674v4 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Na_S/0/1/0/all/0/1">Sen Na</a>, <a href="http://arxiv.org/find/math/1/au:+Shin_S/0/1/0/all/0/1">Sungho Shin</a>, <a href="http://arxiv.org/find/math/1/au:+Anitescu_M/0/1/0/all/0/1">Mihai Anitescu</a>, <a href="http://arxiv.org/find/math/1/au:+Zavala_V/0/1/0/all/0/1">Victor M. Zavala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06674">
                                    <div class="article-summary-box-inner">
                                        <span>We study the convergence properties of an overlapping Schwarz
decomposition~algorithm for solving nonlinear optimal control problems (OCPs).
The approach decomposes the time domain into a set of overlapping subdomains,
and solves subproblems defined over such subdomains in parallel. Convergence is
attained by updating primal-dual information at the boundaries of the
overlapping regions. We show that the algorithm exhibits local linear
convergence and that the convergence rate improves exponentially with the
overlap size. Our convergence results rely on a sensitivity result for OCPs
that we call &quot;exponential decay of sensitivity&quot; (EDS). Intuitively, EDS states
that the impact of parametric perturbations at the boundaries of the domain
(initial and final time) decays exponentially as one moves into the domain. We
show that EDS holds for nonlinear OCPs under a uniform second-order sufficient
condition, a controllability condition, and a uniform boundedness condition. We
conduct numerical experiments using a quadrotor motion planning problem and a
PDE control problem; and show that the approach is significantly more efficient
than ADMM and as efficient as the centralized solver Ipopt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faults in Deep Reinforcement Learning Programs: A Taxonomy and A Detection Approach. (arXiv:2101.00135v2 [cs.SE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1">Amin Nikanjam</a>, <a href="http://arxiv.org/find/cs/1/au:+Morovati_M/0/1/0/all/0/1">Mohammad Mehdi Morovati</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>, <a href="http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1">Houssem Ben Braiek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00135">
                                    <div class="article-summary-box-inner">
                                        <span>A growing demand is witnessed in both industry and academia for employing
Deep Learning (DL) in various domains to solve real-world problems. Deep
Reinforcement Learning (DRL) is the application of DL in the domain of
Reinforcement Learning (RL). Like any software systems, DRL applications can
fail because of faults in their programs. In this paper, we present the first
attempt to categorize faults occurring in DRL programs. We manually analyzed
761 artifacts of DRL programs (from Stack Overflow posts and GitHub issues)
developed using well-known DRL frameworks (OpenAI Gym, Dopamine, Keras-rl,
Tensorforce) and identified faults reported by developers/users. We labeled and
taxonomized the identified faults through several rounds of discussions. The
resulting taxonomy is validated using an online survey with 19
developers/researchers. To allow for the automatic detection of faults in DRL
programs, we have defined a meta-model of DRL programs and developed DRLinter,
a model-based fault detection approach that leverages static analysis and graph
transformations. The execution flow of DRLinter consists in parsing a DRL
program to generate a model conforming to our meta-model and applying detection
rules on the model to identify faults occurrences. The effectiveness of
DRLinter is evaluated using 15 synthetic DRLprograms in which we injected
faults observed in the analyzed artifacts of the taxonomy. The results show
that DRLinter can successfully detect faults in all synthetic faulty programs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Test for non-negligible adverse shifts. (arXiv:2107.02990v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kamulete_V/0/1/0/all/0/1">Vathy M. Kamulete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02990">
                                    <div class="article-summary-box-inner">
                                        <span>Statistical tests for dataset shift are susceptible to false alarms: they are
sensitive to minor differences where there is in fact adequate sample coverage
and predictive performance. We propose instead a robust framework for tests of
dataset shift based on outlier scores, D-SOS for short. D-SOS detects adverse
shifts and can identify false alarms caused by benign ones. It posits that a
new (test) sample is not substantively worse than an old (training) sample, and
not that the two are equal. The key idea is to reduce observations to outlier
scores and compare contamination rates. Beyond comparing distributions, users
can define what worse means in terms of predictive performance and other
relevant notions. We show how versatile and practical D-SOS is for a wide range
of real and simulated datasets. Unlike tests of equal distribution and of
goodness-of-fit, the D-SOS tests are uniquely tailored to serve as robust
performance metrics to monitor model drift and dataset shift.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RoFL: Attestable Robustness for Secure Federated Learning. (arXiv:2107.03311v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burkhalter_L/0/1/0/all/0/1">Lukas Burkhalter</a>, <a href="http://arxiv.org/find/cs/1/au:+Nijeholt_H/0/1/0/all/0/1">Hidde Lycklama &#xe0; Nijeholt</a>, <a href="http://arxiv.org/find/cs/1/au:+Viand_A/0/1/0/all/0/1">Alexander Viand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchler_N/0/1/0/all/0/1">Nicolas K&#xfc;chler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hithnawi_A/0/1/0/all/0/1">Anwar Hithnawi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03311">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning is an emerging decentralized machine learning paradigm
that allows a large number of clients to train a joint model without the need
to share their private data. Participants instead only share ephemeral updates
necessary to train the model. To ensure the confidentiality of the client
updates, Federated Learning systems employ secure aggregation; clients encrypt
their gradient updates, and only the aggregated model is revealed to the
server. Achieving this level of data protection, however, presents new
challenges to the robustness of Federated Learning, i.e., the ability to
tolerate failures and attacks. Unfortunately, in this setting, a malicious
client can now easily exert influence on the model behavior without being
detected. As Federated Learning is being deployed in practice in a range of
sensitive applications, its robustness is growing in importance. In this paper,
we take a step towards understanding and improving the robustness of secure
Federated Learning. We start this paper with a systematic study that evaluates
and analyzes existing attack vectors and discusses potential defenses and
assesses their effectiveness. We then present RoFL, a secure Federated Learning
system that improves robustness against malicious clients through input checks
on the encrypted model updates. RoFL extends Federated Learning&#x27;s secure
aggregation protocol to allow expressing a variety of properties and
constraints on model updates using zero-knowledge proofs. To enable RoFL to
scale to typical Federated Learning settings, we introduce several ML and
cryptographic optimizations specific to Federated Learning. We implement and
evaluate a prototype of RoFL and show that realistic ML models can be trained
in a reasonable time while improving robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A data-driven approach to the forecasting of ground-level ozone concentration. (arXiv:2012.00685v4 [physics.ao-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Marvin_D/0/1/0/all/0/1">Dario Marvin</a>, <a href="http://arxiv.org/find/physics/1/au:+Nespoli_L/0/1/0/all/0/1">Lorenzo Nespoli</a>, <a href="http://arxiv.org/find/physics/1/au:+Strepparava_D/0/1/0/all/0/1">Davide Strepparava</a>, <a href="http://arxiv.org/find/physics/1/au:+Medici_V/0/1/0/all/0/1">Vasco Medici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00685">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to forecast the concentration of air pollutants in an urban
region is crucial for decision-makers wishing to reduce the impact of pollution
on public health through active measures (e.g. temporary traffic closures). In
this study, we present a machine learning approach applied to the forecast of
the day-ahead maximum value of the ozone concentration for several geographical
locations in southern Switzerland. Due to the low density of measurement
stations and to the complex orography of the use case terrain, we adopted
feature selection methods instead of explicitly restricting relevant features
to a neighbourhood of the prediction sites, as common in spatio-temporal
forecasting methods. We then used Shapley values to assess the explainability
of the learned models in terms of feature importance and feature interactions
in relation to ozone predictions; our analysis suggests that the trained models
effectively learned explanatory cross-dependencies among atmospheric variables.
Finally, we show how weighting observations helps in increasing the accuracy of
the forecasts for specific ranges of ozone&#x27;s daily peak values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MD-split+: Practical Local Conformal Inference in High Dimensions. (arXiv:2107.03280v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+LeRoy_B/0/1/0/all/0/1">Benjamin LeRoy</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1">David Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03280">
                                    <div class="article-summary-box-inner">
                                        <span>Quantifying uncertainty in model predictions is a common goal for
practitioners seeking more than just point predictions. One tool for
uncertainty quantification that requires minimal assumptions is conformal
inference, which can help create probabilistically valid prediction regions for
black box models. Classical conformal prediction only provides marginal
validity, whereas in many situations locally valid prediction regions are
desirable. Deciding how best to partition the feature space X when applying
localized conformal prediction is still an open question. We present MD-split+,
a practical local conformal approach that creates X partitions based on
localized model performance of conditional density estimation models. Our
method handles complex real-world data settings where such models may be
misspecified, and scales to high-dimensional inputs. We discuss how our local
partitions philosophically align with expected behavior from an unattainable
conditional conformal inference approach. We also empirically compare our
method against other local conformal approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comparative study of various Deep Learning techniques for spatio-temporal Super-Resolution reconstruction of Forced Isotropic Turbulent flows. (arXiv:2107.03361v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Venkatesh_T/0/1/0/all/0/1">T.S.Sachin Venkatesh</a>, <a href="http://arxiv.org/find/physics/1/au:+Srivastava_R/0/1/0/all/0/1">Rajat Srivastava</a>, <a href="http://arxiv.org/find/physics/1/au:+Bhatt_P/0/1/0/all/0/1">Pratyush Bhatt</a>, <a href="http://arxiv.org/find/physics/1/au:+Tyagi_P/0/1/0/all/0/1">Prince Tyagi</a>, <a href="http://arxiv.org/find/physics/1/au:+Singh_R/0/1/0/all/0/1">Raj Kumar Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03361">
                                    <div class="article-summary-box-inner">
                                        <span>Super-resolution is an innovative technique that upscales the resolution of
an image or a video and thus enables us to reconstruct high-fidelity images
from low-resolution data. This study performs super-resolution analysis on
turbulent flow fields spatially and temporally using various state-of-the-art
machine learning techniques like ESPCN, ESRGAN and TecoGAN to reconstruct
high-resolution flow fields from low-resolution flow field data, especially
keeping in mind the need for low resource consumption and rapid results
production/verification. The dataset used for this study is extracted from the
&#x27;isotropic 1024 coarse&#x27; dataset which is a part of Johns Hopkins Turbulence
Databases (JHTDB). We have utilized pre-trained models and fine tuned them to
our needs, so as to minimize the computational resources and the time required
for the implementation of the super-resolution models. The advantages presented
by this method far exceed the expectations and the outcomes of regular single
structure models. The results obtained through these models are then compared
using MSE, PSNR, SAM, VIF and SCC metrics in order to evaluate the upscaled
results, find the balance between computational power and output quality, and
then identify the most accurate and efficient model for spatial and temporal
super-resolution of turbulent flow fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution. (arXiv:2106.02295v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhaoyang_Z/0/1/0/all/0/1">Zhang Zhaoyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenqi_S/0/1/0/all/0/1">Shao Wenqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jinwei_G/0/1/0/all/0/1">Gu Jinwei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiaogang_W/0/1/0/all/0/1">Wang Xiaogang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_L/0/1/0/all/0/1">Luo Ping</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02295">
                                    <div class="article-summary-box-inner">
                                        <span>Model quantization is challenging due to many tedious hyper-parameters such
as precision (bitwidth), dynamic range (minimum and maximum discrete values)
and stepsize (interval between discrete values). Unlike prior arts that
carefully tune these values, we present a fully differentiable approach to
learn all of them, named Differentiable Dynamic Quantization (DDQ), which has
several benefits. (1) DDQ is able to quantize challenging lightweight
architectures like MobileNets, where different layers prefer different
quantization parameters. (2) DDQ is hardware-friendly and can be easily
implemented using low-precision matrix-vector multiplication, making it capable
in many hardware such as ARM. (3) Extensive experiments show that DDQ
outperforms prior arts on many networks and benchmarks, especially when models
are already efficient and compact. e.g., DDQ is the first approach that
achieves lossless 4-bit quantization for MobileNetV2 on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GRIMGEP: Learning Progress for Robust Goal Sampling in Visual Deep Reinforcement Learning. (arXiv:2008.04388v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1">Grgur Kova&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Laversanne_Finot_A/0/1/0/all/0/1">Adrien Laversanne-Finot</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04388">
                                    <div class="article-summary-box-inner">
                                        <span>Designing agents, capable of learning autonomously a wide range of skills is
critical in order to increase the scope of reinforcement learning. It will both
increase the diversity of learned skills and reduce the burden of manually
designing reward functions for each skill. Self-supervised agents, setting
their own goals, and trying to maximize the diversity of those goals have shown
great promise towards this end. However, a currently known limitation of agents
trying to maximize the diversity of sampled goals is that they tend to get
attracted to noise or more generally to parts of the environments that cannot
be controlled (distractors). When agents have access to predefined goal
features or expert knowledge, absolute Learning Progress (ALP) provides a way
to distinguish between regions that can be controlled and those that cannot.
However, those methods often fall short when the agents are only provided with
raw sensory inputs such as images. In this work we extend those concepts to
unsupervised image-based goal exploration. We propose a framework that allows
agents to autonomously identify and ignore noisy distracting regions while
searching for novelty in the learnable regions to both improve overall
performance and avoid catastrophic forgetting. Our framework can be combined
with any state-of-the-art novelty seeking goal exploration approaches. We
construct a rich 3D image based environment with distractors. Experiments on
this environment show that agents using our framework successfully identify
interesting regions of the environment, resulting in drastically improved
performances. The source code is available at
https://sites.google.com/view/grimgep.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Samplets: A new paradigm for data compression. (arXiv:2107.03337v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Harbrecht_H/0/1/0/all/0/1">Helmut Harbrecht</a>, <a href="http://arxiv.org/find/math/1/au:+Multerer_M/0/1/0/all/0/1">Michael Multerer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03337">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we introduce the novel concept of samplets by transferring
the construction of Tausch-White wavelets to the realm of data. This way we
obtain a multilevel representation of discrete data which directly enables data
compression, detection of singularities and adaptivity. Applying samplets to
represent kernel matrices, as they arise in kernel based learning or Gaussian
process regression, we end up with quasi-sparse matrices. By thresholding small
entries, these matrices are compressible to O(N log N) relevant entries, where
N is the number of data points. This feature allows for the use of fill-in
reducing reorderings to obtain a sparse factorization of the compressed
matrices. Besides the comprehensive introduction to samplets and their
properties, we present extensive numerical studies to benchmark the approach.
Our results demonstrate that samplets mark a considerable step in the direction
of making large data sets accessible for analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UAV-assisted Online Machine Learning over Multi-Tiered Networks: A Hierarchical Nested Personalized Federated Learning Approach. (arXiv:2106.15734v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Su Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1">Seyyedali Hosseinalipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorlatova_M/0/1/0/all/0/1">Maria Gorlatova</a>, <a href="http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1">Christopher G. Brinton</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1">Mung Chiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15734">
                                    <div class="article-summary-box-inner">
                                        <span>We consider distributed machine learning (ML) through unmanned aerial
vehicles (UAVs) for geo-distributed device clusters. We propose five new
technologies/techniques: (i) stratified UAV swarms with leader, worker, and
coordinator UAVs, (ii) hierarchical nested personalized federated learning
(HN-PFL): a holistic distributed ML framework for personalized model training
across the worker-leader-core network hierarchy, (iii) cooperative UAV resource
pooling for distributed ML using the UAVs&#x27; local computational capabilities,
(iv) aerial data caching and relaying for efficient data relaying to conduct
ML, and (v) concept/model drift, capturing online data variations at the
devices. We split the UAV-enabled model training problem as two parts. (a)
Network-aware HN-PFL, where we optimize a tradeoff between energy consumption
and ML model performance by configuring data offloading among devices-UAVs and
UAV-UAVs, UAVs&#x27; CPU frequencies, and mini-batch sizes subject to
communication/computation network heterogeneity. We tackle this optimization
problem via the method of posynomial condensation and propose a distributed
algorithm with a performance guarantee. (b) Macro-trajectory and learning
duration design, which we formulate as a sequential decision making problem,
tackled via deep reinforcement learning. Our simulations demonstrate the
superiority of our methodology with regards to the distributed ML performance,
the optimization of network resources, and the swarm trajectory efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Jitter: Random Jittering Loss Function. (arXiv:2106.13749v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhicheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chenglei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Sidan Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13749">
                                    <div class="article-summary-box-inner">
                                        <span>Regularization plays a vital role in machine learning optimization. One novel
regularization method called flooding makes the training loss fluctuate around
the flooding level. It intends to make the model continue to random walk until
it comes to a flat loss landscape to enhance generalization. However, the
hyper-parameter flooding level of the flooding method fails to be selected
properly and uniformly. We propose a novel method called Jitter to improve it.
Jitter is essentially a kind of random loss function. Before training, we
randomly sample the Jitter Point from a specific probability distribution. The
flooding level should be replaced by Jitter point to obtain a new target
function and train the model accordingly. As Jitter point acting as a random
factor, we actually add some randomness to the loss function, which is
consistent with the fact that there exists innumerable random behaviors in the
learning process of the machine learning model and is supposed to make the
model more robust. In addition, Jitter performs random walk randomly which
divides the loss curve into small intervals and then flipping them over,
ideally making the loss curve much flatter and enhancing generalization
ability. Moreover, Jitter can be a domain-, task-, and model-independent
regularization method and train the model effectively after the training error
reduces to zero. Our experimental results show that Jitter method can improve
model performance more significantly than the previous flooding method and make
the test loss curve descend twice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Pseudo-Metric between Probability Distributions based on Depth-Trimmed Regions. (arXiv:2103.12711v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Staerman_G/0/1/0/all/0/1">Guillaume Staerman</a>, <a href="http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1">Pavlo Mozharovskyi</a>, <a href="http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1">St&#xe9;phan Cl&#xe9;men&#xe7;on</a>, <a href="http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1">Florence d&#x27;Alch&#xe9;-Buc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12711">
                                    <div class="article-summary-box-inner">
                                        <span>Data depth is a non parametric statistical tool that measures centrality of
any element $x\in\mathbb{R}^d$ with respect to (w.r.t.) a probability
distribution or a data set. It is a natural median-oriented extension of the
cumulative distribution function (cdf) to the multivariate case. Consequently,
its upper level sets -- the depth-trimmed regions -- give rise to a definition
of multivariate quantiles. In this work, we propose two new pseudo-metrics
between continuous probability measures based on data depth and its associated
central regions. The first one is constructed as the Lp-distance between data
depth w.r.t. each distribution while the second one relies on the Hausdorff
distance between their quantile regions. It can further be seen as an original
way to extend the one-dimensional formulae of the Wasserstein distance, which
involves quantiles and cdfs, to the multivariate space. After discussing the
properties of these pseudo-metrics and providing conditions under which they
define a distance, we highlight similarities with the Wasserstein distance.
Interestingly, the derived non-asymptotic bounds show that in contrast to the
Wasserstein distance, the proposed pseudo-metrics do not suffer from the curse
of dimensionality. Moreover, based on the support function of a convex body, we
propose an efficient approximation possessing linear time complexity w.r.t. the
size of the data set and its dimension. The quality of this approximation as
well as the performance of the proposed approach are illustrated in
experiments. Furthermore, by construction the regions-based pseudo-metric
appears to be robust w.r.t. both outliers and heavy tails, a behavior witnessed
in the numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How and Why to Use Experimental Data to Evaluate Methods for Observational Causal Inference. (arXiv:2010.03051v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gentzel_A/0/1/0/all/0/1">Amanda Gentzel</a>, <a href="http://arxiv.org/find/stat/1/au:+Pruthi_P/0/1/0/all/0/1">Purva Pruthi</a>, <a href="http://arxiv.org/find/stat/1/au:+Jensen_D/0/1/0/all/0/1">David Jensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03051">
                                    <div class="article-summary-box-inner">
                                        <span>Methods that infer causal dependence from observational data are central to
many areas of science, including medicine, economics, and the social sciences.
A variety of theoretical properties of these methods have been proven, but
empirical evaluation remains a challenge, largely due to the lack of
observational data sets for which treatment effect is known. We describe and
analyze observational sampling from randomized controlled trials (OSRCT), a
method for evaluating causal inference methods using data from randomized
controlled trials (RCTs). This method can be used to create constructed
observational data sets with corresponding unbiased estimates of treatment
effect, substantially increasing the number of data sets available for
empirical evaluation of causal inference methods. We show that, in expectation,
OSRCT creates data sets that are equivalent to those produced by randomly
sampling from empirical data sets in which all potential outcomes are
available. We then perform a large-scale evaluation of seven causal inference
methods over 37 data sets, drawn from RCTs, as well as simulators, real-world
computational systems, and observational data sets augmented with a synthetic
response variable. We find notable performance differences when comparing
across data from different sources, demonstrating the importance of using data
from a variety of sources when evaluating any causal inference method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Uncertainty in Deep Neural Networks. (arXiv:2107.03342v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gawlikowski_J/0/1/0/all/0/1">Jakob Gawlikowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Tassi_C/0/1/0/all/0/1">Cedrique Rovile Njieutcheu Tassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohsin Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jongseok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Humt_M/0/1/0/all/0/1">Matthias Humt</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianxiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kruspe_A/0/1/0/all/0/1">Anna Kruspe</a>, <a href="http://arxiv.org/find/cs/1/au:+Triebel_R/0/1/0/all/0/1">Rudolph Triebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_P/0/1/0/all/0/1">Peter Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Roscher_R/0/1/0/all/0/1">Ribana Roscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_M/0/1/0/all/0/1">Muhammad Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamler_R/0/1/0/all/0/1">Richard Bamler</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiao Xiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03342">
                                    <div class="article-summary-box-inner">
                                        <span>Due to their increasing spread, confidence in neural network predictions
became more and more important. However, basic neural networks do not deliver
certainty estimates or suffer from over or under confidence. Many researchers
have been working on understanding and quantifying uncertainty in a neural
network&#x27;s prediction. As a result, different types and sources of uncertainty
have been identified and a variety of approaches to measure and quantify
uncertainty in neural networks have been proposed. This work gives a
comprehensive overview of uncertainty estimation in neural networks, reviews
recent advances in the field, highlights current challenges, and identifies
potential research opportunities. It is intended to give anyone interested in
uncertainty estimation in neural networks a broad overview and introduction,
without presupposing prior knowledge in this field. A comprehensive
introduction to the most crucial sources of uncertainty is given and their
separation into reducible model uncertainty and not reducible data uncertainty
is presented. The modeling of these uncertainties based on deterministic neural
networks, Bayesian neural networks, ensemble of neural networks, and test-time
data augmentation approaches is introduced and different branches of these
fields as well as the latest developments are discussed. For a practical
application, we discuss different measures of uncertainty, approaches for the
calibration of neural networks and give an overview of existing baselines and
implementations. Different examples from the wide spectrum of challenges in
different fields give an idea of the needs and challenges regarding
uncertainties in practical applications. Additionally, the practical
limitations of current methods for mission- and safety-critical real world
applications are discussed and an outlook on the next steps towards a broader
usage of such methods is given.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Training Stop Point with Noisy Labeled Data. (arXiv:2012.13435v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamabattula_S/0/1/0/all/0/1">Sree Ram Kamabattula</a>, <a href="http://arxiv.org/find/cs/1/au:+Devarajan_V/0/1/0/all/0/1">Venkat Devarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Namazi_B/0/1/0/all/0/1">Babak Namazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankaranarayanan_G/0/1/0/all/0/1">Ganesh Sankaranarayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13435">
                                    <div class="article-summary-box-inner">
                                        <span>Training deep neural networks (DNNs) with noisy labels is a challenging
problem due to over-parameterization. DNNs tend to essentially fit on clean
samples at a higher rate in the initial stages, and later fit on the noisy
samples at a relatively lower rate. Thus, with a noisy dataset, the test
accuracy increases initially and drops in the later stages. To find an early
stopping point at the maximum obtainable test accuracy (MOTA), recent studies
assume either that i) a clean validation set is available or ii) the noise
ratio is known, or, both. However, often a clean validation set is unavailable,
and the noise estimation can be inaccurate. To overcome these issues, we
provide a novel training solution, free of these conditions. We analyze the
rate of change of the training accuracy for different noise ratios under
different conditions to identify a training stop region. We further develop a
heuristic algorithm based on a small-learning assumption to find a training
stop point (TSP) at or close to MOTA. To the best of our knowledge, our method
is the first to rely solely on the \textit{training behavior}, while utilizing
the entire training set, to automatically find a TSP. We validated the
robustness of our algorithm (AutoTSP) through several experiments on CIFAR-10,
CIFAR-100, and a real-world noisy dataset for different noise ratios, noise
types, and architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization. (arXiv:2102.06966v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baranwal_A/0/1/0/all/0/1">Aseem Baranwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1">Kimon Fountoulakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagannath_A/0/1/0/all/0/1">Aukosh Jagannath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06966">
                                    <div class="article-summary-box-inner">
                                        <span>Recently there has been increased interest in semi-supervised classification
in the presence of graphical information. A new class of learning models has
emerged that relies, at its most basic level, on classifying the data after
first applying a graph convolution. To understand the merits of this approach,
we study the classification of a mixture of Gaussians, where the data
corresponds to the node attributes of a stochastic block model. We show that
graph convolution extends the regime in which the data is linearly separable by
a factor of roughly $1/\sqrt{D}$, where $D$ is the expected degree of a node,
as compared to the mixture model data on its own. Furthermore, we find that the
linear classifier obtained by minimizing the cross-entropy loss after the graph
convolution generalizes to out-of-distribution data where the unseen data can
have different intra- and inter-class edge probabilities from the training
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGD-Autoencoder: Attention Gated Deep Convolutional Autoencoder for Brain Tumor Segmentation. (arXiv:2107.03323v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cvetko_T/0/1/0/all/0/1">Tim Cvetko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Brain tumor segmentation is a challenging problem in medical image analysis.
The endpoint is to generate the salient masks that accurately identify brain
tumor regions in an fMRI screening. In this paper, we propose a novel attention
gate (AG model) for brain tumor segmentation that utilizes both the edge
detecting unit and the attention gated network to highlight and segment the
salient regions from fMRI images. This feature enables us to eliminate the
necessity of having to explicitly point towards the damaged area(external
tissue localization) and classify(classification) as per classical computer
vision techniques. AGs can easily be integrated within the deep convolutional
neural networks(CNNs). Minimal computional overhead is required while the AGs
increase the sensitivity scores significantly. We show that the edge detector
along with an attention gated mechanism provide a sufficient enough method for
brain segmentation reaching an IOU of 0.78</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoDebias: Learning to Debias for Recommendation. (arXiv:2105.04170v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hande Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guli Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Keping Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04170">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems rely on user behavior data like ratings and clicks to
build personalization model. However, the collected data is observational
rather than experimental, causing various biases in the data which
significantly affect the learned model. Most existing work for recommendation
debiasing, such as the inverse propensity scoring and imputation approaches,
focuses on one or two specific biases, lacking the universal capacity that can
account for mixed or even unknown biases in the data.

Towards this research gap, we first analyze the origin of biases from the
perspective of \textit{risk discrepancy} that represents the difference between
the expectation empirical risk and the true risk. Remarkably, we derive a
general learning framework that well summarizes most existing debiasing
strategies by specifying some parameters of the general framework. This
provides a valuable opportunity to develop a universal solution for debiasing,
e.g., by learning the debiasing parameters from data. However, the training
data lacks important signal of how the data is biased and what the unbiased
data looks like. To move this idea forward, we propose \textit{AotoDebias} that
leverages another (small) set of uniform data to optimize the debiasing
parameters by solving the bi-level optimization problem with meta-learning.
Through theoretical analyses, we derive the generalization bound for AutoDebias
and prove its ability to acquire the appropriate debiasing strategy. Extensive
experiments on two real datasets and a simulated dataset demonstrated
effectiveness of AutoDebias. The code is available at
\url{https://github.com/DongHande/AutoDebias}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Dynamic Multi-Modal Data Fusion: A Model Uncertainty Perspective. (arXiv:2105.06018v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06018">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is concerned with multi-modal data fusion (MMDF) under unexpected
modality failures in nonlinear non-Gaussian dynamic processes. An efficient
framework to tackle this problem is proposed. In particular, a notion termed
modality &quot;\emph{usefulness}&quot;, which takes a value of 1 or 0, is used for
indicating whether the observation of this modality is useful or not. For $n$
modalities involved, $2^n$ combinations of their &quot;\emph{usefulness}&quot; values
exist. Each combination defines one hypothetical model of the true data
generative process. Then the problem of concern is formalized as a task of
nonlinear non-Gaussian state filtering under model uncertainty, which is
addressed by a dynamic model averaging (DMA) based particle filter (PF)
algorithm. This DMA algorithm employs $2^n$ models, while all models share the
same state-transition function and a unique set of particle values. That makes
the computational complexity of this algorithm only slightly larger than a
single model based PF algorithm, especially for scenarios in which $n$ is
small. Experimental results show that the proposed solution outperforms
remarkably state-of-the-art methods. Code and data are available at
https://github.com/robinlau1981/fusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing the Spatio-temporal Observability of Grid-Edge Resources in Distribution Grids. (arXiv:2102.07801v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lin_S/0/1/0/all/0/1">Shanny Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07801">
                                    <div class="article-summary-box-inner">
                                        <span>Enhancing the spatio-temporal observability of distributed energy resources
(DERs) is crucial for achieving secure and efficient operations in distribution
grids. This paper puts forth a joint recovery framework for residential loads
by leveraging the complimentary strengths of heterogeneous types of
measurements. The proposed approaches integrate the low-resolution smart meter
data collected for every load node with the fast-sampled feeder-level
measurements provided by limited number of phasor measurement units. To address
the lack of data, we exploit two key characteristics for the loads and DERs,
namely the sparse changes due to infrequent activities of appliances and
electric vehicles (EVs) and the locational dependence of solar photovoltaic
(PV) generation. Accordingly, meaningful regularization terms are introduced to
cast a convex load recovery problem, which will be further simplified to reduce
computational complexity. The load recovery solutions can be utilized to
identify the EV charging events at each load node and to infer the total
behind-the-meter PV output. Numerical tests using real-world data have
demonstrated the effectiveness of the proposed approaches in enhancing the
visibility of these grid-edge DERs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POLAR: A Polynomial Arithmetic Framework for Verifying Neural-Network Controlled Systems. (arXiv:2106.13867v3 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_J/0/1/0/all/0/1">Jiameng Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xin Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1">Wenchao Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13867">
                                    <div class="article-summary-box-inner">
                                        <span>We propose POLAR, a \textbf{pol}ynomial \textbf{ar}ithmetic framework that
leverages polynomial overapproximations with interval remainders for
bounded-time reachability analysis of neural network-controlled systems
(NNCSs). Compared with existing arithmetic approaches that use standard Taylor
models, our framework uses a novel approach to iteratively overapproximate the
neuron output ranges layer-by-layer with a combination of Bernstein polynomial
interpolation for continuous activation functions and Taylor model arithmetic
for the other operations. This approach can overcome the main drawback in the
standard Taylor model arithmetic, i.e. its inability to handle functions that
cannot be well approximated by Taylor polynomials, and significantly improve
the accuracy and efficiency of reachable states computation for NNCSs. To
further tighten the overapproximation, our method keeps the Taylor model
remainders symbolic under the linear mappings when estimating the output range
of a neural network. We show that POLAR can be seamlessly integrated with
existing Taylor model flowpipe construction techniques, and demonstrate that
POLAR significantly outperforms the current state-of-the-art techniques on a
suite of benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Neural Nets in Chemical Engineering: Foundations, Computations, and Applications. (arXiv:2101.04869v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shengli Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zavala_V/0/1/0/all/0/1">Victor M. Zavala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04869">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we review the mathematical foundations of convolutional neural
nets (CNNs) with the goals of: i) highlighting connections with techniques from
statistics, signal processing, linear algebra, differential equations, and
optimization, ii) demystifying underlying computations, and iii) identifying
new types of applications. CNNs are powerful machine learning models that
highlight features from grid data to make predictions (regression and
classification). The grid data object can be represented as vectors (in 1D),
matrices (in 2D), or tensors (in 3D or higher dimensions) and can incorporate
multiple channels (thus providing high flexibility in the input data
representation). CNNs highlight features from the grid data by performing
convolution operations with different types of operators. The operators
highlight different types of features (e.g., patterns, gradients, geometrical
features) and are learned by using optimization techniques. In other words,
CNNs seek to identify optimal operators that best map the input data to the
output data. A common misconception is that CNNs are only capable of processing
image or video data but their application scope is much wider; specifically,
datasets encountered in diverse applications can be expressed as grid data.
Here, we show how to apply CNNs to new types of applications such as optimal
control, flow cytometry, multivariate process monitoring, and molecular
simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Up Exact Neural Network Compression by ReLU Stability. (arXiv:2102.07804v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Serra_T/0/1/0/all/0/1">Thiago Serra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhinav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1">Srikumar Ramalingam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07804">
                                    <div class="article-summary-box-inner">
                                        <span>We can compress a neural network while exactly preserving its underlying
functionality with respect to a given input domain if some of its neurons are
stable. However, current approaches to determine the stability of neurons with
Rectified Linear Unit (ReLU) activations require solving or finding a good
approximation to multiple discrete optimization problems. In this work, we
introduce an algorithm based on solving a single optimization problem to
identify all stable neurons. Our approach is on median 100 times faster than
the state-of-art method, which allows us to explore exact compression on deeper
(5 x 100) and wider (2 x 800) networks within minutes. For classifiers trained
under an amount of L1 regularization that does not worsen accuracy, we can
remove up to 40% of the connections</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification. (arXiv:2007.15823v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garbacea_C/0/1/0/all/0/1">Cristina Garbacea</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mengtian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carton_S/0/1/0/all/0/1">Samuel Carton</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15823">
                                    <div class="article-summary-box-inner">
                                        <span>Text simplification reduces the language complexity of professional content
for accessibility purposes. End-to-end neural network models have been widely
adopted to directly generate the simplified version of input text, usually
functioning as a blackbox. We show that text simplification can be decomposed
into a compact pipeline of tasks to ensure the transparency and explainability
of the process. The first two steps in this pipeline are often neglected: 1) to
predict whether a given piece of text needs to be simplified, and 2) if yes, to
identify complex parts of the text. The two tasks can be solved separately
using either lexical or deep learning methods, or solved jointly. Simply
applying explainable complexity prediction as a preliminary step, the
out-of-sample text simplification performance of the state-of-the-art,
black-box simplification models can be improved by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Codomain Separability and Label Inference from (Noisy) Loss Functions. (arXiv:2107.03022v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1">Abhinav Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasiviswanathan_S/0/1/0/all/0/1">Shiva Prasad Kasiviswanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zekun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feyisetan_O/0/1/0/all/0/1">Oluwaseyi Feyisetan</a>, <a href="http://arxiv.org/find/cs/1/au:+Teissier_N/0/1/0/all/0/1">Nathanael Teissier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03022">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning classifiers rely on loss functions for performance
evaluation, often on a private (hidden) dataset. Label inference was recently
introduced as the problem of reconstructing the ground truth labels of this
private dataset from just the (possibly perturbed) loss function values
evaluated at chosen prediction vectors, without any other access to the hidden
dataset. Existing results have demonstrated this inference is possible on
specific loss functions like the cross-entropy loss. In this paper, we
introduce the notion of codomain separability to formally study the necessary
and sufficient conditions under which label inference is possible from any
(noisy) loss function values. Using this notion, we show that for many commonly
used loss functions, including multiclass cross-entropy with common activation
functions and some Bregman divergence-based losses, it is possible to design
label inference attacks for arbitrary noise levels. We demonstrate that these
attacks can also be carried out through actual neural network models, and
argue, both formally and empirically, the role of finite precision arithmetic
in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Residual Star Generative Adversarial Network for multi-domain Image Super-Resolution. (arXiv:2107.03145v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Umer_R/0/1/0/all/0/1">Rao Muhammad Umer</a>, <a href="http://arxiv.org/find/eess/1/au:+Munir_A/0/1/0/all/0/1">Asad Munir</a>, <a href="http://arxiv.org/find/eess/1/au:+Micheloni_C/0/1/0/all/0/1">Christian Micheloni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03145">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, most of state-of-the-art single image super-resolution (SISR)
methods have attained impressive performance by using deep convolutional neural
networks (DCNNs). The existing SR methods have limited performance due to a
fixed degradation settings, i.e. usually a bicubic downscaling of
low-resolution (LR) image. However, in real-world settings, the LR degradation
process is unknown which can be bicubic LR, bilinear LR, nearest-neighbor LR,
or real LR. Therefore, most SR methods are ineffective and inefficient in
handling more than one degradation settings within a single network. To handle
the multiple degradation, i.e. refers to multi-domain image super-resolution,
we propose a deep Super-Resolution Residual StarGAN (SR2*GAN), a novel and
scalable approach that super-resolves the LR images for the multiple LR domains
using only a single model. The proposed scheme is trained in a StarGAN like
network topology with a single generator and discriminator networks. We
demonstrate the effectiveness of our proposed approach in quantitative and
qualitative experiments compared to other state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Promises and Pitfalls of Deep Kernel Learning. (arXiv:2102.12108v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ober_S/0/1/0/all/0/1">Sebastian W. Ober</a>, <a href="http://arxiv.org/find/stat/1/au:+Rasmussen_C/0/1/0/all/0/1">Carl E. Rasmussen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1">Mark van der Wilk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12108">
                                    <div class="article-summary-box-inner">
                                        <span>Deep kernel learning (DKL) and related techniques aim to combine the
representational power of neural networks with the reliable uncertainty
estimates of Gaussian processes. One crucial aspect of these models is an
expectation that, because they are treated as Gaussian process models optimized
using the marginal likelihood, they are protected from overfitting. However, we
identify situations where this is not the case. We explore this behavior,
explain its origins and consider how it applies to real datasets. Through
careful experimentation on the UCI, CIFAR-10, and the UTKFace datasets, we find
that the overfitting from overparameterized maximum marginal likelihood, in
which the model is &quot;somewhat Bayesian&quot;, can in certain scenarios be worse than
that from not being Bayesian at all. We explain how and when DKL can still be
successful by investigating optimization dynamics. We also find that failures
of DKL can be rectified by a fully Bayesian treatment, which leads to the
desired performance improvements over standard neural networks and Gaussian
processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Path Planning using Neural A* Search. (arXiv:2009.07476v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yonetani_R/0/1/0/all/0/1">Ryo Yonetani</a>, <a href="http://arxiv.org/find/cs/1/au:+Taniai_T/0/1/0/all/0/1">Tatsunori Taniai</a>, <a href="http://arxiv.org/find/cs/1/au:+Barekatain_M/0/1/0/all/0/1">Mohammadamin Barekatain</a>, <a href="http://arxiv.org/find/cs/1/au:+Nishimura_M/0/1/0/all/0/1">Mai Nishimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanezaki_A/0/1/0/all/0/1">Asako Kanezaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07476">
                                    <div class="article-summary-box-inner">
                                        <span>We present Neural A*, a novel data-driven search method for path planning
problems. Despite the recent increasing attention to data-driven path planning,
machine learning approaches to search-based planning are still challenging due
to the discrete nature of search algorithms. In this work, we reformulate a
canonical A* search algorithm to be differentiable and couple it with a
convolutional encoder to form an end-to-end trainable neural network planner.
Neural A* solves a path planning problem by encoding a problem instance to a
guidance map and then performing the differentiable A* search with the guidance
map. By learning to match the search results with ground-truth paths provided
by experts, Neural A* can produce a path consistent with the ground truth
accurately and efficiently. Our extensive experiments confirmed that Neural A*
outperformed state-of-the-art data-driven planners in terms of the search
optimality and efficiency trade-off. Furthermore, Neural A* successfully
predicted realistic human trajectories by directly performing search-based
planning on natural image inputs. Project page:
https://omron-sinicx.github.io/neural-astar/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distribution-free uncertainty quantification for classification under label shift. (arXiv:2103.03323v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1">Aleksandr Podkopaev</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1">Aaditya Ramdas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Trustworthy deployment of ML models requires a proper measure of uncertainty,
especially in safety-critical applications. We focus on uncertainty
quantification (UQ) for classification problems via two avenues -- prediction
sets using conformal prediction and calibration of probabilistic predictors by
post-hoc binning -- since these possess distribution-free guarantees for i.i.d.
data. Two common ways of generalizing beyond the i.i.d. setting include
handling covariate and label shift. Within the context of distribution-free UQ,
the former has already received attention, but not the latter. It is known that
label shift hurts prediction, and we first argue that it also hurts UQ, by
showing degradation in coverage and calibration. Piggybacking on recent
progress in addressing label shift (for better prediction), we examine the
right way to achieve UQ by reweighting the aforementioned conformal and
calibration procedures whenever some unlabeled data from the target
distribution is available. We examine these techniques theoretically in a
distribution-free framework and demonstrate their excellent practical
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Label Uncertainty in Understanding Adversarial Robustness. (arXiv:2107.03250v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1">David Evans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03250">
                                    <div class="article-summary-box-inner">
                                        <span>A fundamental question in adversarial machine learning is whether a robust
classifier exists for a given task. A line of research has made progress
towards this goal by studying concentration of measure, but without considering
data labels. We argue that the standard concentration fails to fully
characterize the intrinsic robustness of a classification problem, since it
ignores data labels which are essential to any classification task. Building on
a novel definition of label uncertainty, we empirically demonstrate that error
regions induced by state-of-the-art models tend to have much higher label
uncertainty compared with randomly-selected subsets. This observation motivates
us to adapt a concentration estimation algorithm to account for label
uncertainty, resulting in more accurate intrinsic robustness measures for
benchmark image classification problems. We further provide empirical evidence
showing that adding an abstain option for classifiers based on label
uncertainty can help improve both the clean and robust accuracies of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization Error Analysis of Neural networks with Gradient Based Regularization. (arXiv:2107.02797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingfeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_X/0/1/0/all/0/1">Xue-Cheng Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02797">
                                    <div class="article-summary-box-inner">
                                        <span>We study gradient-based regularization methods for neural networks. We mainly
focus on two regularization methods: the total variation and the Tikhonov
regularization. Applying these methods is equivalent to using neural networks
to solve some partial differential equations, mostly in high dimensions in
practical applications. In this work, we introduce a general framework to
analyze the generalization error of regularized networks. The error estimate
relies on two assumptions on the approximation error and the quadrature error.
Moreover, we conduct some experiments on the image classification tasks to show
that gradient-based methods can significantly improve the generalization
ability and adversarial robustness of neural networks. A graphical extension of
the gradient-based methods are also considered in the experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Deterministic Annealing for Classification and Clustering. (arXiv:2102.05836v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mavridis_C/0/1/0/all/0/1">Christos Mavridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Baras_J/0/1/0/all/0/1">John Baras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05836">
                                    <div class="article-summary-box-inner">
                                        <span>Inherent in virtually every iterative machine learning algorithm is the
problem of hyper-parameter tuning, which includes three major design
parameters: (a) the complexity of the model, e.g., the number of neurons in a
neural network, (b) the initial conditions, which heavily affect the behavior
of the algorithm, and (c) the dissimilarity measure used to quantify its
performance. We introduce an online prototype-based learning algorithm that can
be viewed as a progressively growing competitive-learning neural network
architecture for classification and clustering. The learning rule of the
proposed approach is formulated as an online gradient-free stochastic
approximation algorithm that solves a sequence of appropriately defined
optimization problems, simulating an annealing process. The annealing nature of
the algorithm contributes to avoiding poor local minima, offers robustness with
respect to the initial conditions, and provides a means to progressively
increase the complexity of the learning model, through an intuitive bifurcation
phenomenon. The proposed approach is interpretable, requires minimal
hyper-parameter tuning, and allows online control over the
performance-complexity trade-off. Finally, we show that Bregman divergences
appear naturally as a family of dissimilarity measures that play a central role
in both the performance and the computational complexity of the learning
algorithm. Experimental results illustrate the properties and evaluate the
performance of the proposed learning algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling. (arXiv:2003.06060v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruixiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1">Jascha Sohl-Dickstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1">Liam Paull</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yuan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06060">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the sum of the implicit generator log-density $\log p_g$ of a
GAN with the logit score of the discriminator defines an energy function which
yields the true data density when the generator is imperfect but the
discriminator is optimal, thus making it possible to improve on the typical
generator (with implicit density $p_g$). To make that practical, we show that
sampling from this modified density can be achieved by sampling in latent space
according to an energy-based model induced by the sum of the latent prior
log-density and the discriminator output score. This can be achieved by running
a Langevin MCMC in latent space and then applying the generator function, which
we call Discriminator Driven Latent Sampling~(DDLS). We show that DDLS is
highly efficient compared to previous methods which work in the
high-dimensional pixel space and can be applied to improve on previously
trained GANs of many types. We evaluate DDLS on both synthetic and real-world
datasets qualitatively and quantitatively. On CIFAR-10, DDLS substantially
improves the Inception Score of an off-the-shelf pre-trained
SN-GAN~\citep{sngan} from $8.22$ to $9.09$ which is even comparable to the
class-conditional BigGAN~\citep{biggan} model. This achieves a new
state-of-the-art in unconditional image synthesis setting without introducing
extra parameters or additional training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intensity Prediction of Tropical Cyclones using Long Short-Term Memory Network. (arXiv:2107.03187v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_K/0/1/0/all/0/1">Koushik Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sandeep Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Ashish Kumar Pandey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03187">
                                    <div class="article-summary-box-inner">
                                        <span>Tropical cyclones can be of varied intensity and cause a huge loss of lives
and property if the intensity is high enough. Therefore, the prediction of the
intensity of tropical cyclones advance in time is of utmost importance. We
propose a novel stacked bidirectional long short-term memory network (BiLSTM)
based model architecture to predict the intensity of a tropical cyclone in
terms of Maximum surface sustained wind speed (MSWS). The proposed model can
predict MSWS well advance in time (up to 72 h) with very high accuracy. We have
applied the model on tropical cyclones in the North Indian Ocean from 1982 to
2018 and checked its performance on two recent tropical cyclones, namely, Fani
and Vayu. The model predicts MSWS (in knots) for the next 3, 12, 24, 36, 48,
60, and 72 hours with a mean absolute error of 1.52, 3.66, 5.88, 7.42, 8.96,
10.15, and 11.92, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Fault Detection for Deep Learning Programs Using Graph Transformations. (arXiv:2105.08095v2 [cs.SE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1">Amin Nikanjam</a>, <a href="http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1">Houssem Ben Braiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Morovati_M/0/1/0/all/0/1">Mohammad Mehdi Morovati</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08095">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, we are witnessing an increasing demand in both corporates and
academia for exploiting Deep Learning (DL) to solve complex real-world
problems. A DL program encodes the network structure of a desirable DL model
and the process by which the model learns from the training dataset. Like any
software, a DL program can be faulty, which implies substantial challenges of
software quality assurance, especially in safety-critical domains. It is
therefore crucial to equip DL development teams with efficient fault detection
techniques and tools. In this paper, we propose NeuraLint, a model-based fault
detection approach for DL programs, using meta-modelling and graph
transformations. First, we design a meta-model for DL programs that includes
their base skeleton and fundamental properties. Then, we construct a
graph-based verification process that covers 23 rules defined on top of the
meta-model and implemented as graph transformations to detect faults and design
inefficiencies in the generated models (i.e., instances of the meta-model).
First, the proposed approach is evaluated by finding faults and design
inefficiencies in 28 synthesized examples built from common problems reported
in the literature. Then NeuraLint successfully finds 64 faults and design
inefficiencies in 34 real-world DL programs extracted from Stack Overflow posts
and GitHub repositories. The results show that NeuraLint effectively detects
faults and design issues in both synthesized and real-world examples with a
recall of 70.5 % and a precision of 100 %. Although the proposed meta-model is
designed for feedforward neural networks, it can be extended to support other
neural network architectures such as recurrent neural networks. Researchers can
also expand our set of verification rules to cover more types of issues in DL
programs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Opioid Use Disorder from Longitudinal Healthcare Data using Multi-stream Transformer. (arXiv:2103.08800v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fouladvand_S/0/1/0/all/0/1">Sajjad Fouladvand</a>, <a href="http://arxiv.org/find/cs/1/au:+Talbert_J/0/1/0/all/0/1">Jeffery Talbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwoskin_L/0/1/0/all/0/1">Linda P. Dwoskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bush_H/0/1/0/all/0/1">Heather Bush</a>, <a href="http://arxiv.org/find/cs/1/au:+Meadows_A/0/1/0/all/0/1">Amy Lynn Meadows</a>, <a href="http://arxiv.org/find/cs/1/au:+Peterson_L/0/1/0/all/0/1">Lars E. Peterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kavuluru_R/0/1/0/all/0/1">Ramakanth Kavuluru</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08800">
                                    <div class="article-summary-box-inner">
                                        <span>Opioid Use Disorder (OUD) is a public health crisis costing the US billions
of dollars annually in healthcare, lost workplace productivity, and crime.
Analyzing longitudinal healthcare data is critical in addressing many
real-world problems in healthcare. Leveraging the real-world longitudinal
healthcare data, we propose a novel multi-stream transformer model called MUPOD
for OUD identification. MUPOD is designed to simultaneously analyze multiple
types of healthcare data streams, such as medications and diagnoses, by
attending to segments within and across these data streams. Our model tested on
the data from 392,492 patients with long-term back pain problems showed
significantly better performance than the traditional models and recently
developed deep learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graphing else matters: exploiting aspect opinions and ratings in explainable graph-based recommendations. (arXiv:2107.03226v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cantador_I/0/1/0/all/0/1">Iv&#xe1;n Cantador</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diez_F/0/1/0/all/0/1">Fernando Diez</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_D/0/1/0/all/0/1">Denis Parra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03226">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural network embeddings has entailed a renewed interest in
using knowledge graphs for a wide variety of machine learning and information
retrieval tasks. In particular, current recommendation methods based on graph
embeddings have shown state-of-the-art performance. These methods commonly
encode latent rating patterns and content features. Different from previous
work, in this paper, we propose to exploit embeddings extracted from graphs
that combine information from ratings and aspect-based opinions expressed in
textual reviews. We then adapt and evaluate state-of-the-art graph embedding
techniques over graphs generated from Amazon and Yelp reviews on six domains,
outperforming baseline recommenders. Our approach has the advantage of
providing explanations which leverage aspect-based opinions given by users
about recommended items. Furthermore, we also provide examples of the
applicability of recommendations utilizing aspect opinions as explanations in a
visualization dashboard, which allows obtaining information about the most and
least liked aspects of similar users obtained from the embeddings of an input
graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple Agent, Complex Environment: Efficient Reinforcement Learning with Agent States. (arXiv:2102.05261v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05261">
                                    <div class="article-summary-box-inner">
                                        <span>We design a simple reinforcement learning (RL) agent that implements an
optimistic version of $Q$-learning and establish through regret analysis that
this agent can operate with some level of competence in any environment. While
we leverage concepts from the literature on provably efficient RL, we consider
a general agent-environment interface and provide a novel agent design and
analysis. This level of generality positions our results to inform the design
of future agents for operation in complex real environments. We establish that,
as time progresses, our agent performs competitively relative to policies that
require longer times to evaluate. The time it takes to approach asymptotic
performance is polynomial in the complexity of the agent&#x27;s state representation
and the time required to evaluate the best policy that the agent can represent.
Notably, there is no dependence on the complexity of the environment. The
ultimate per-period performance loss of the agent is bounded by a constant
multiple of a measure of distortion introduced by the agent&#x27;s state
representation. This work is the first to establish that an algorithm
approaches this asymptotic condition within a tractable time frame.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed stochastic optimization with large delays. (arXiv:2107.02919v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>, <a href="http://arxiv.org/find/math/1/au:+Mertikopoulos_P/0/1/0/all/0/1">Panayotis Mertikopoulos</a>, <a href="http://arxiv.org/find/math/1/au:+Bambos_N/0/1/0/all/0/1">Nicholas Bambos</a>, <a href="http://arxiv.org/find/math/1/au:+Glynn_P/0/1/0/all/0/1">Peter W. Glynn</a>, <a href="http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1">Yinyu Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02919">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most widely used methods for solving large-scale stochastic
optimization problems is distributed asynchronous stochastic gradient descent
(DASGD), a family of algorithms that result from parallelizing stochastic
gradient descent on distributed computing architectures (possibly)
asychronously. However, a key obstacle in the efficient implementation of DASGD
is the issue of delays: when a computing node contributes a gradient update,
the global model parameter may have already been updated by other nodes several
times over, thereby rendering this gradient information stale. These delays can
quickly add up if the computational throughput of a node is saturated, so the
convergence of DASGD may be compromised in the presence of large delays. Our
first contribution is that, by carefully tuning the algorithm&#x27;s step-size,
convergence to the critical set is still achieved in mean square, even if the
delays grow unbounded at a polynomial rate. We also establish finer results in
a broad class of structured optimization problems (called variationally
coherent), where we show that DASGD converges to a global optimum with
probability $1$ under the same delay assumptions. Together, these results
contribute to the broad landscape of large-scale non-convex stochastic
optimization by offering state-of-the-art theoretical guarantees and providing
insights for algorithm design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DER Forecast using Privacy Preserving Federated Learning. (arXiv:2107.03248v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Venkataramanan_V/0/1/0/all/0/1">Venkatesh Venkataramanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kaza_S/0/1/0/all/0/1">Sridevi Kaza</a>, <a href="http://arxiv.org/find/eess/1/au:+Annaswamy_A/0/1/0/all/0/1">Anuradha M. Annaswamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03248">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing penetration of Distributed Energy Resources (DERs) in grid
edge including renewable generation, flexible loads, and storage, accurate
prediction of distributed generation and consumption at the consumer level
becomes important. However, DER prediction based on the transmission of
customer level data, either repeatedly or in large amounts, is not feasible due
to privacy concerns. In this paper, a distributed machine learning approach,
Federated Learning, is proposed to carry out DER forecasting using a network of
IoT nodes, each of which transmits a model of the consumption and generation
patterns without revealing consumer data. We consider a simulation study which
includes 1000 DERs, and show that our method leads to an accurate prediction of
preserve consumer privacy, while still leading to an accurate forecast. We also
evaluate grid-specific performance metrics such as load swings and load
curtailment and show that our FL algorithm leads to satisfactory performance.
Simulations are also performed on the Pecan street dataset to demonstrate the
validity of the proposed approach on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Large Language Models Trained on Code. (arXiv:2107.03374v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mark Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tworek_J/0/1/0/all/0/1">Jerry Tworek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jun_H/0/1/0/all/0/1">Heewoo Jun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1">Qiming Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponde_H/0/1/0/all/0/1">Henrique Ponde</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1">Jared Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Edwards_H/0/1/0/all/0/1">Harri Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Burda_Y/0/1/0/all/0/1">Yura Burda</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_N/0/1/0/all/0/1">Nicholas Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockman_G/0/1/0/all/0/1">Greg Brockman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1">Alex Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Puri_R/0/1/0/all/0/1">Raul Puri</a>, <a href="http://arxiv.org/find/cs/1/au:+Krueger_G/0/1/0/all/0/1">Gretchen Krueger</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrov_M/0/1/0/all/0/1">Michael Petrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Khlaaf_H/0/1/0/all/0/1">Heidy Khlaaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Sastry_G/0/1/0/all/0/1">Girish Sastry</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishkin_P/0/1/0/all/0/1">Pamela Mishkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_B/0/1/0/all/0/1">Brooke Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gray_S/0/1/0/all/0/1">Scott Gray</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryder_N/0/1/0/all/0/1">Nick Ryder</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlov_M/0/1/0/all/0/1">Mikhail Pavlov</a>, <a href="http://arxiv.org/find/cs/1/au:+Power_A/0/1/0/all/0/1">Alethea Power</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaiser_L/0/1/0/all/0/1">Lukasz Kaiser</a>, <a href="http://arxiv.org/find/cs/1/au:+Bavarian_M/0/1/0/all/0/1">Mohammad Bavarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1">Clemens Winter</a>, <a href="http://arxiv.org/find/cs/1/au:+Tillet_P/0/1/0/all/0/1">Philippe Tillet</a>, <a href="http://arxiv.org/find/cs/1/au:+Such_F/0/1/0/all/0/1">Felipe Such</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_D/0/1/0/all/0/1">Dave Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Plappert_M/0/1/0/all/0/1">Matthias Plappert</a>, <a href="http://arxiv.org/find/cs/1/au:+Chantzis_F/0/1/0/all/0/1">Fotios Chantzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_E/0/1/0/all/0/1">Elizabeth Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Herbert_Voss_A/0/1/0/all/0/1">Ariel Herbert-Voss</a>, <a href="http://arxiv.org/find/cs/1/au:+Guss_W/0/1/0/all/0/1">Will Guss</a>, <a href="http://arxiv.org/find/cs/1/au:+Nichol_A/0/1/0/all/0/1">Alex Nichol</a>, <a href="http://arxiv.org/find/cs/1/au:+Babuschkin_I/0/1/0/all/0/1">Igor Babuschkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaji_S/0/1/0/all/0/1">Suchir Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shantanu Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Carr_A/0/1/0/all/0/1">Andrew Carr</a>, <a href="http://arxiv.org/find/cs/1/au:+Leike_J/0/1/0/all/0/1">Jan Leike</a>, <a href="http://arxiv.org/find/cs/1/au:+Achiam_J/0/1/0/all/0/1">Josh Achiam</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_V/0/1/0/all/0/1">Vedant Misra</a>, <a href="http://arxiv.org/find/cs/1/au:+Morikawa_E/0/1/0/all/0/1">Evan Morikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Radford_A/0/1/0/all/0/1">Alec Radford</a>, <a href="http://arxiv.org/find/cs/1/au:+Knight_M/0/1/0/all/0/1">Matthew Knight</a>, <a href="http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1">Miles Brundage</a>, <a href="http://arxiv.org/find/cs/1/au:+Murati_M/0/1/0/all/0/1">Mira Murati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayer_K/0/1/0/all/0/1">Katie Mayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Welinder_P/0/1/0/all/0/1">Peter Welinder</a>, <a href="http://arxiv.org/find/cs/1/au:+McGrew_B/0/1/0/all/0/1">Bob McGrew</a>, <a href="http://arxiv.org/find/cs/1/au:+Amodei_D/0/1/0/all/0/1">Dario Amodei</a>, <a href="http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1">Sam McCandlish</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1">Ilya Sutskever</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1">Wojciech Zaremba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03374">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Codex, a GPT language model fine-tuned on publicly available
code from GitHub, and study its Python code-writing capabilities. A distinct
production version of Codex powers GitHub Copilot. On HumanEval, a new
evaluation set we release to measure functional correctness for synthesizing
programs from docstrings, our model solves 28.8% of the problems, while GPT-3
solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling
from the model is a surprisingly effective strategy for producing working
solutions to difficult prompts. Using this method, we solve 70.2% of our
problems with 100 samples per problem. Careful investigation of our model
reveals its limitations, including difficulty with docstrings describing long
chains of operations and with binding operations to variables. Finally, we
discuss the potential broader impacts of deploying powerful code generation
technologies, covering safety, security, and economics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An empirical evaluation of active inference in multi-armed bandits. (arXiv:2101.08699v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Markovic_D/0/1/0/all/0/1">Dimitrije Markovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojic_H/0/1/0/all/0/1">Hrvoje Stojic</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwoebel_S/0/1/0/all/0/1">Sarah Schwoebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiebel_S/0/1/0/all/0/1">Stefan J. Kiebel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08699">
                                    <div class="article-summary-box-inner">
                                        <span>A key feature of sequential decision making under uncertainty is a need to
balance between exploiting--choosing the best action according to the current
knowledge, and exploring--obtaining information about values of other actions.
The multi-armed bandit problem, a classical task that captures this trade-off,
served as a vehicle in machine learning for developing bandit algorithms that
proved to be useful in numerous industrial applications. The active inference
framework, an approach to sequential decision making recently developed in
neuroscience for understanding human and animal behaviour, is distinguished by
its sophisticated strategy for resolving the exploration-exploitation
trade-off. This makes active inference an exciting alternative to already
established bandit algorithms. Here we derive an efficient and scalable
approximate active inference algorithm and compare it to two state-of-the-art
bandit algorithms: Bayesian upper confidence bound and optimistic Thompson
sampling. This comparison is done on two types of bandit problems: a stationary
and a dynamic switching bandit. Our empirical evaluation shows that the active
inference algorithm does not produce efficient long-term behaviour in
stationary bandits. However, in the more challenging switching bandit problem
active inference performs substantially better than the two state-of-the-art
bandit algorithms. The results open exciting venues for further research in
theoretical and applied machine learning, as well as lend additional
credibility to active inference as a general framework for studying human and
animal behaviour.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XPDNet for MRI Reconstruction: an application to the 2020 fastMRI challenge. (arXiv:2010.07290v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ramzi_Z/0/1/0/all/0/1">Zaccharie Ramzi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ciuciu_P/0/1/0/all/0/1">Philippe Ciuciu</a>, <a href="http://arxiv.org/find/eess/1/au:+Starck_J/0/1/0/all/0/1">Jean-Luc Starck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07290">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new neural network, the XPDNet, for MRI reconstruction from
periodically under-sampled multi-coil data. We inform the design of this
network by taking best practices from MRI reconstruction and computer vision.
We show that this network can achieve state-of-the-art reconstruction results,
as shown by its ranking of second in the fastMRI 2020 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hub and Spoke Logistics Network Design for Urban Region with Clustering-Based Approach. (arXiv:2107.03080v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duong_Q/0/1/0/all/0/1">Quan Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quoc Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03080">
                                    <div class="article-summary-box-inner">
                                        <span>This study aims to propose effective modeling and approach for designing a
logistics network in the urban area in order to offer an efficient flow
distribution network as a competitive strategy in the logistics industry where
demand is sensitive to both price and time. A multi-stage approach is
introduced to select the number of hubs and allocate spokes to the hubs for
flow distribution and hubs&#x27; location detection. Specifically, a fuzzy
clustering model with the objective function is to minimize the approximate
transportation cost is employed, in the next phase is to focus on balancing the
demand capacity among the hubs with the help of domain experts, afterward, the
facility location vehicle routing problems within the network is introduced. To
demonstrate the approach&#x27;s advantages, an experiment was performed on the
designed network and its actual transportation cost for the real operational
data in which specific to the Ho Chi Minh city infrastructure conditions.
Additionally, we show the flexibility of the designed network in the flow
distribution and its computational experiments to develop the managerial
insights which contribute to the network design decision-making process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection and Mitigation of Rare Subclasses in Deep Neural Network Classifiers. (arXiv:1911.12780v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paterson_C/0/1/0/all/0/1">Colin Paterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Calinescu_R/0/1/0/all/0/1">Radu Calinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Picardi_C/0/1/0/all/0/1">Chiara Picardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.12780">
                                    <div class="article-summary-box-inner">
                                        <span>Regions of high-dimensional input spaces that are underrepresented in
training datasets reduce machine-learnt classifier performance, and may lead to
corner cases and unwanted bias for classifiers used in decision making systems.
When these regions belong to otherwise well-represented classes, their presence
and negative impact are very hard to identify. We propose an approach for the
detection and mitigation of such rare subclasses in deep neural network
classifiers. The new approach is underpinned by an easy-to-compute commonality
metric that supports the detection of rare subclasses, and comprises methods
for reducing the impact of these subclasses during both model training and
model exploitation. We demonstrate our approach using two well-known datasets,
MNIST&#x27;s handwritten digits and Kaggle&#x27;s cats/dogs, identifying rare subclasses
and producing models which compensate for subclass rarity. In addition we
demonstrate how our run-time approach increases the ability of users to
identify samples likely to be misclassified at run-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coastal water quality prediction based on machine learning with feature interpretation and spatio-temporal analysis. (arXiv:2107.03230v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Grbcic_L/0/1/0/all/0/1">Luka Grb&#x10d;i&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Druzeta_S/0/1/0/all/0/1">Sini&#x161;a Dru&#x17e;eta</a>, <a href="http://arxiv.org/find/stat/1/au:+Mausa_G/0/1/0/all/0/1">Goran Mau&#x161;a</a>, <a href="http://arxiv.org/find/stat/1/au:+Lipic_T/0/1/0/all/0/1">Tomislav Lipi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Lusic_D/0/1/0/all/0/1">Darija Vuki&#x107; Lu&#x161;i&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Alvir_M/0/1/0/all/0/1">Marta Alvir</a>, <a href="http://arxiv.org/find/stat/1/au:+Lucin_I/0/1/0/all/0/1">Ivana Lu&#x10d;in</a>, <a href="http://arxiv.org/find/stat/1/au:+Sikirica_A/0/1/0/all/0/1">Ante Sikirica</a>, <a href="http://arxiv.org/find/stat/1/au:+Davidovic_D/0/1/0/all/0/1">Davor Davidovi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Travas_V/0/1/0/all/0/1">Vanja Trava&#x161;</a>, <a href="http://arxiv.org/find/stat/1/au:+Kalafatovic_D/0/1/0/all/0/1">Daniela Kalafatovi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Pikelj_K/0/1/0/all/0/1">Kristina Pikelj</a>, <a href="http://arxiv.org/find/stat/1/au:+Fajkovic_H/0/1/0/all/0/1">Hana Fajkovi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Kranjcevic_L/0/1/0/all/0/1">Lado Kranj&#x10d;evi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03230">
                                    <div class="article-summary-box-inner">
                                        <span>Coastal water quality management is a public health concern, as poor coastal
water quality can harbor pathogens that are dangerous to human health.
Tourism-oriented countries need to actively monitor the condition of coastal
water at tourist popular sites during the summer season. In this study, routine
monitoring data of $Escherichia\ Coli$ and enterococci across 15 public beaches
in the city of Rijeka, Croatia, were used to build machine learning models for
predicting their levels based on environmental parameters as well as to
investigate their relationships with environmental stressors. Gradient Boosting
(Catboost, Xgboost), Random Forests, Support Vector Regression and Artificial
Neural Networks were trained with measurements from all sampling sites and used
to predict $E.\ Coli$ and enterococci values based on environmental features.
The evaluation of stability and generalizability with 10-fold cross validation
analysis of the machine learning models, showed that the Catboost algorithm
performed best with R$^2$ values of 0.71 and 0.68 for predicting $E.\ Coli$ and
enterococci, respectively, compared to other evaluated ML algorithms including
Xgboost, Random Forests, Support Vector Regression and Artificial Neural
Networks. We also use the SHapley Additive exPlanations technique to identify
and interpret which features have the most predictive power. The results show
that site salinity measured is the most important feature for forecasting both
$E.\ Coli$ and enterococci levels. Finally, the spatial and temporal accuracy
of both ML models were examined at sites with the lowest coastal water quality.
The spatial $E. Coli$ and enterococci models achieved strong R$^2$ values of
0.85 and 0.83, while the temporal models achieved R$^2$ values of 0.74 and
0.67. The temporal model also achieved moderate R$^2$ values of 0.44 and 0.46
at a site with high coastal water quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Closed-Form Approximation to the Conjugate Prior of the Dirichlet and Beta Distributions. (arXiv:2107.03183v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Thommen_K/0/1/0/all/0/1">Kaspar Thommen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03183">
                                    <div class="article-summary-box-inner">
                                        <span>We derive the conjugate prior of the Dirichlet and beta distributions and
explore it with numerical examples to gain an intuitive understanding of the
distribution itself, its hyperparameters, and conditions concerning its
convergence. Due to the prior&#x27;s intractability, we proceed to define and
analyze a closed-form approximation. Finally, we provide an algorithm
implementing this approximation that enables fully tractable Bayesian conjugate
treatment of Dirichlet and beta likelihoods without the need for Monte Carlo
simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impulse data models for the inverse problem of electrocardiography. (arXiv:2102.00570v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Peng_T/0/1/0/all/0/1">Tommy Peng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Malik_A/0/1/0/all/0/1">Avinash Malik</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bear_L/0/1/0/all/0/1">Laura Bear</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Trew_M/0/1/0/all/0/1">Mark L. Trew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00570">
                                    <div class="article-summary-box-inner">
                                        <span>The proposed method re-frames traditional inverse problems of
electrocardiography into regression problems, constraining the solution space
by decomposing signals with multidimensional Gaussian impulse basis functions.
Impulse HSPs were generated with single Gaussian basis functions at discrete
heart surface locations and projected to corresponding BSPs using a volume
conductor torso model. Both BSP (inputs) and HSP (outputs) were mapped to
regular 2D surface meshes and used to train a neural network. Predictive
capabilities of the network were tested with unseen synthetic and experimental
data. A dense full connected single hidden layer neural network was trained to
map body surface impulses to heart surface Gaussian basis functions for
reconstructing HSP. Synthetic pulses moving across the heart surface were
predicted from the neural network with root mean squared error of $9.1\pm1.4$%.
Predicted signals were robust to noise up to 20 dB and errors due to
displacement and rotation of the heart within the torso were bounded and
predictable. A shift of the heart 40 mm toward the spine resulted in a 4\%
increase in signal feature localization error. The set of training impulse
function data could be reduced and prediction error remained bounded. Recorded
HSPs from in-vitro pig hearts were reliably decomposed using space-time
Gaussian basis functions. Predicted HSPs for left-ventricular pacing had a mean
absolute error of $10.4\pm11.4$ ms. Other pacing scenarios were analyzed with
similar success. Conclusion: Impulses from Gaussian basis functions are
potentially an effective and robust way to train simple neural network data
models for reconstructing HSPs from decomposed BSPs. The HSPs predicted by the
neural network can be used to generate activation maps that non-invasively
identify features of cardiac electrical dysfunction and can guide subsequent
treatment options.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing an Intelligent Digital Twin with a Self-organized Reconfiguration Management based on Adaptive Process Models. (arXiv:2107.03324v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1">Timo M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindemann_B/0/1/0/all/0/1">Benjamin Lindemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_T/0/1/0/all/0/1">Tobias Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Jazdi_N/0/1/0/all/0/1">Nasser Jazdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1">Michael Weyrich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03324">
                                    <div class="article-summary-box-inner">
                                        <span>Shorter product life cycles and increasing individualization of production
leads to an increased reconfiguration demand in the domain of industrial
automation systems, which will be dominated by cyber-physical production
systems in the future. In constantly changing systems, however, not all
configuration alternatives of the almost infinite state space are fully
understood. Thus, certain configurations can lead to process instability, a
reduction in quality or machine failures. Therefore, this paper presents an
approach that enhances an intelligent Digital Twin with a self-organized
reconfiguration management based on adaptive process models in order to find
optimized configurations more comprehensively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PHOTONAI -- A Python API for Rapid Machine Learning Model Development. (arXiv:2002.05426v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leenings_R/0/1/0/all/0/1">Ramona Leenings</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_N/0/1/0/all/0/1">Nils Ralf Winter</a>, <a href="http://arxiv.org/find/cs/1/au:+Plagwitz_L/0/1/0/all/0/1">Lucas Plagwitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Holstein_V/0/1/0/all/0/1">Vincent Holstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernsting_J/0/1/0/all/0/1">Jan Ernsting</a>, <a href="http://arxiv.org/find/cs/1/au:+Steenweg_J/0/1/0/all/0/1">Jakob Steenweg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gebker_J/0/1/0/all/0/1">Julian Gebker</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarink_K/0/1/0/all/0/1">Kelvin Sarink</a>, <a href="http://arxiv.org/find/cs/1/au:+Emden_D/0/1/0/all/0/1">Daniel Emden</a>, <a href="http://arxiv.org/find/cs/1/au:+Grotegerd_D/0/1/0/all/0/1">Dominik Grotegerd</a>, <a href="http://arxiv.org/find/cs/1/au:+Opel_N/0/1/0/all/0/1">Nils Opel</a>, <a href="http://arxiv.org/find/cs/1/au:+Risse_B/0/1/0/all/0/1">Benjamin Risse</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dannlowski_U/0/1/0/all/0/1">Udo Dannlowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_T/0/1/0/all/0/1">Tim Hahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05426">
                                    <div class="article-summary-box-inner">
                                        <span>PHOTONAI is a high-level Python API designed to simplify and accelerate
machine learning model development. It functions as a unifying framework
allowing the user to easily access and combine algorithms from different
toolboxes into custom algorithm sequences. It is especially designed to support
the iterative model development process and automates the repetitive training,
hyperparameter optimization and evaluation tasks. Importantly, the workflow
ensures unbiased performance estimates while still allowing the user to fully
customize the machine learning analysis. PHOTONAI extends existing solutions
with a novel pipeline implementation supporting more complex data streams,
feature combinations, and algorithm selection. Metrics and results can be
conveniently visualized using the PHOTONAI Explorer and predictive models are
shareable in a standardized format for further external validation or
application. A growing add-on ecosystem allows researchers to offer data
modality specific algorithms to the community and enhance machine learning in
the areas of the life sciences. Its practical utility is demonstrated on an
exemplary medical machine learning problem, achieving a state-of-the-art
solution in few lines of code. Source code is publicly available on Github,
while examples and documentation can be found at www.photon-ai.com.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Performance Saturation in Neural Marked Point Processes: Architectures and Loss Functions. (arXiv:2107.03354v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tianze Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_Y/0/1/0/all/0/1">Yiping Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Sinno Jialin Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03354">
                                    <div class="article-summary-box-inner">
                                        <span>Attributed event sequences are commonly encountered in practice. A recent
research line focuses on incorporating neural networks with the statistical
model -- marked point processes, which is the conventional tool for dealing
with attributed event sequences. Neural marked point processes possess good
interpretability of probabilistic models as well as the representational power
of neural networks. However, we find that performance of neural marked point
processes is not always increasing as the network architecture becomes more
complicated and larger, which is what we call the performance saturation
phenomenon. This is due to the fact that the generalization error of neural
marked point processes is determined by both the network representational
ability and the model specification at the same time. Therefore we can draw two
major conclusions: first, simple network structures can perform no worse than
complicated ones for some cases; second, using a proper probabilistic
assumption is as equally, if not more, important as improving the complexity of
the network. Based on this observation, we propose a simple graph-based network
structure called GCHP, which utilizes only graph convolutional layers, thus it
can be easily accelerated by the parallel mechanism. We directly consider the
distribution of interarrival times instead of imposing a specific assumption on
the conditional intensity function, and propose to use a likelihood ratio loss
with a moment matching mechanism for optimization and model selection.
Experimental results show that GCHP can significantly reduce training time and
the likelihood ratio loss with interarrival time probability assumptions can
greatly improve the model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">L2P: An Algorithm for Estimating Heavy-tailed Outcomes. (arXiv:1908.04628v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xindi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Varol_O/0/1/0/all/0/1">Onur Varol</a>, <a href="http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1">Tina Eliassi-Rad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.04628">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world prediction tasks have outcome variables that have
characteristic heavy-tail distributions. Examples include copies of books sold,
auction prices of art pieces, demand for commodities in warehouses, etc. By
learning heavy-tailed distributions, &quot;big and rare&quot; instances (e.g., the
best-sellers) will have accurate predictions. Most existing approaches are not
dedicated to learning heavy-tailed distribution; thus, they heavily
under-predict such instances. To tackle this problem, we introduce Learning to
Place (L2P), which exploits the pairwise relationships between instances for
learning. In its training phase, L2P learns a pairwise preference classifier:
is instance A &gt; instance B? In its placing phase, L2P obtains a prediction by
placing the new instance among the known instances. Based on its placement, the
new instance is then assigned a value for its outcome variable. Experiments on
real data show that L2P outperforms competing approaches in terms of accuracy
and ability to reproduce heavy-tailed outcome distribution. In addition, L2P
provides an interpretable model by placing each predicted instance in relation
to its comparable neighbors. Interpretable models are highly desirable when
lives and treasure are at stake.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-horizon Competitive Markov Games. (arXiv:2102.04540v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chen-Yu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chung-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengxiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haipeng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04540">
                                    <div class="article-summary-box-inner">
                                        <span>We study infinite-horizon discounted two-player zero-sum Markov games, and
develop a decentralized algorithm that provably converges to the set of Nash
equilibria under self-play. Our algorithm is based on running an Optimistic
Gradient Descent Ascent algorithm on each state to learn the policies, with a
critic that slowly learns the value of each state. To the best of our
knowledge, this is the first algorithm in this setting that is simultaneously
rational (converging to the opponent&#x27;s best response when it uses a stationary
policy), convergent (converging to the set of Nash equilibria under self-play),
agnostic (no need to know the actions played by the opponent), symmetric
(players taking symmetric roles in the algorithm), and enjoying a finite-time
last-iterate convergence guarantee, all of which are desirable properties of
decentralized algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A case for new neural network smoothness constraints. (arXiv:2012.07969v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1">Mihaela Rosca</a>, <a href="http://arxiv.org/find/stat/1/au:+Weber_T/0/1/0/all/0/1">Theophane Weber</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>, <a href="http://arxiv.org/find/stat/1/au:+Mohamed_S/0/1/0/all/0/1">Shakir Mohamed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07969">
                                    <div class="article-summary-box-inner">
                                        <span>How sensitive should machine learning models be to input changes? We tackle
the question of model smoothness and show that it is a useful inductive bias
which aids generalization, adversarial robustness, generative modeling and
reinforcement learning. We explore current methods of imposing smoothness
constraints and observe they lack the flexibility to adapt to new tasks, they
don&#x27;t account for data modalities, they interact with losses, architectures and
optimization in ways not yet fully understood. We conclude that new advances in
the field are hinging on finding ways to incorporate data, tasks and learning
into our definitions of smoothness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning 1-Dimensional Submanifolds for Subsequent Inference on Random Dot Product Graphs. (arXiv:2004.07348v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Trosset_M/0/1/0/all/0/1">Michael W. Trosset</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_M/0/1/0/all/0/1">Mingyue Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_M/0/1/0/all/0/1">Minh Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1">Carey E. Priebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07348">
                                    <div class="article-summary-box-inner">
                                        <span>A random dot product graph (RDPG) is a generative model for networks in which
vertices correspond to positions in a latent Euclidean space and edge
probabilities are determined by the dot products of the latent positions. We
consider RDPGs for which the latent positions are randomly sampled from an
unknown $1$-dimensional submanifold of the latent space. In principle,
restricted inference, i.e., procedures that exploit the structure of the
submanifold, should be more effective than unrestricted inference; however, it
is not clear how to conduct restricted inference when the submanifold is
unknown. We submit that techniques for manifold learning can be used to learn
the unknown submanifold well enough to realize benefit from restricted
inference. To illustrate, we test $1$- and $2$-sample hypotheses about the
Fr\&#x27;{e}chet means of small communities of vertices, using the complete set of
vertices to infer latent structure. We propose test statistics that deploy the
Isomap procedure for manifold learning, using shortest path distances on
neighborhood graphs constructed from estimated latent positions to estimate arc
lengths on the unknown $1$-dimensional submanifold. Unlike conventional
applications of Isomap, the estimated latent positions do not lie on the
submanifold of interest. We extend existing convergence results for Isomap to
this setting and use them to demonstrate that, as the number of auxiliary
vertices increases, the power of our test converges to the power of the
corresponding test when the submanifold is known.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAM-VO: Less is more in Visual Odometry. (arXiv:2107.02974v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cleveston_I/0/1/0/all/0/1">Iury Cleveston</a>, <a href="http://arxiv.org/find/cs/1/au:+Colombini_E/0/1/0/all/0/1">Esther L. Colombini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02974">
                                    <div class="article-summary-box-inner">
                                        <span>Building vehicles capable of operating without human supervision requires the
determination of the agent&#x27;s pose. Visual Odometry (VO) algorithms estimate the
egomotion using only visual changes from the input images. The most recent VO
methods implement deep-learning techniques using convolutional neural networks
(CNN) extensively, which add a substantial cost when dealing with
high-resolution images. Furthermore, in VO tasks, more input data does not mean
a better prediction; on the contrary, the architecture may filter out useless
information. Therefore, the implementation of computationally efficient and
lightweight architectures is essential. In this work, we propose the RAM-VO, an
extension of the Recurrent Attention Model (RAM) for visual odometry tasks.
RAM-VO improves the visual and temporal representation of information and
implements the Proximal Policy Optimization (PPO) algorithm to learn robust
policies. The results indicate that RAM-VO can perform regressions with six
degrees of freedom from monocular input images using approximately 3 million
parameters. In addition, experiments on the KITTI dataset demonstrate that
RAM-VO achieves competitive results using only 5.7% of the available visual
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keiki: Towards Realistic Danmaku Generation via Sequential GANs. (arXiv:2107.02991v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakakis_G/0/1/0/all/0/1">Georgios N. Yannakakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02991">
                                    <div class="article-summary-box-inner">
                                        <span>Search-based procedural content generation methods have recently been
introduced for the autonomous creation of bullet hell games. Search-based
methods, however, can hardly model patterns of danmakus -- the bullet hell
shooting entity -- explicitly and the resulting levels often look
non-realistic. In this paper, we present a novel bullet hell game platform
named Keiki, which allows the representation of danmakus as a parametric
sequence which, in turn, can model the sequential behaviours of danmakus. We
employ three types of generative adversarial networks (GANs) and test Keiki
across three metrics designed to quantify the quality of the generated
danmakus. The time-series GAN and periodic spatial GAN show different yet
competitive performance in terms of the evaluation metrics adopted, their
deviation from human-designed danmakus, and the diversity of generated
danmakus. The preliminary experimental studies presented here showcase that
potential of time-series GANs for sequential content generation in games.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Are you sure?&quot;: Preliminary Insights from Scaling Product Comparisons to Multiple Shops. (arXiv:2107.03256v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chia_P/0/1/0/all/0/1">Patrick John Chia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bingqing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1">Jacopo Tagliabue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03256">
                                    <div class="article-summary-box-inner">
                                        <span>Large eCommerce players introduced comparison tables as a new type of
recommendations. However, building comparisons at scale without pre-existing
training/taxonomy data remains an open challenge, especially within the
operational constraints of shops in the long tail. We present preliminary
results from building a comparison pipeline designed to scale in a multi-shop
scenario: we describe our design choices and run extensive benchmarks on
multiple shops to stress-test it. Finally, we run a small user study on
property selection and conclude by discussing potential improvements and
highlighting the questions that remain to be addressed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diametrical Risk Minimization: Theory and Computations. (arXiv:1910.10844v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Norton_M/0/1/0/all/0/1">Matthew Norton</a>, <a href="http://arxiv.org/find/math/1/au:+Royset_J/0/1/0/all/0/1">Johannes O. Royset</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10844">
                                    <div class="article-summary-box-inner">
                                        <span>The theoretical and empirical performance of Empirical Risk Minimization
(ERM) often suffers when loss functions are poorly behaved with large Lipschitz
moduli and spurious sharp minimizers. We propose and analyze a counterpart to
ERM called Diametrical Risk Minimization (DRM), which accounts for worst-case
empirical risks within neighborhoods in parameter space. DRM has generalization
bounds that are independent of Lipschitz moduli for convex as well as nonconvex
problems and it can be implemented using a practical algorithm based on
stochastic gradient descent. Numerical results illustrate the ability of DRM to
find quality solutions with low generalization error in sharp empirical risk
landscapes from benchmark neural network classification problems with corrupted
labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting with Confidence on Unseen Distributions. (arXiv:2107.03315v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guillory_D/0/1/0/all/0/1">Devin Guillory</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1">Vaishaal Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1">Sayna Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1">Ludwig Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03315">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that the performance of machine learning models can
vary substantially when models are evaluated on data drawn from a distribution
that is close to but different from the training distribution. As a result,
predicting model performance on unseen distributions is an important challenge.
Our work connects techniques from domain adaptation and predictive uncertainty
literature, and allows us to predict model accuracy on challenging unseen
distributions without access to labeled data. In the context of distribution
shift, distributional distances are often used to adapt models and improve
their performance on new domains, however accuracy estimation, or other forms
of predictive uncertainty, are often neglected in these investigations. Through
investigating a wide range of established distributional distances, such as
Frechet distance or Maximum Mean Discrepancy, we determine that they fail to
induce reliable estimates of performance under distribution shift. On the other
hand, we find that the difference of confidences (DoC) of a classifier&#x27;s
predictions successfully estimates the classifier&#x27;s performance change over a
variety of shifts. We specifically investigate the distinction between
synthetic and natural distribution shifts and observe that despite its
simplicity DoC consistently outperforms other quantifications of distributional
difference. $DoC$ reduces predictive error by almost half ($46\%$) on several
realistic and challenging distribution shifts, e.g., on the ImageNet-Vid-Robust
and ImageNet-Rendition datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Extrapolation for Attribute-Enhanced Generation. (arXiv:2107.02968v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Alvin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Madani_A/0/1/0/all/0/1">Ali Madani</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1">Ben Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Naik_N/0/1/0/all/0/1">Nikhil Naik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SelfCF: A Simple Framework for Self-supervised Collaborative Filtering. (arXiv:2107.03019v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1">Aixin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03019">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is widely used to learn an informative latent
representation of a user or item from observed interactions. Existing CF-based
methods commonly adopt negative sampling to discriminate different items. That
is, observed user-item pairs are treated as positive instances; unobserved
pairs are considered as negative instances and are sampled under a defined
distribution for training. Training with negative sampling on large datasets is
computationally expensive. Further, negative items should be carefully sampled
under the defined distribution, in order to avoid selecting an observed
positive item in the training dataset. Unavoidably, some negative items sampled
from the training dataset could be positive in the test set. Recently,
self-supervised learning (SSL) has emerged as a powerful tool to learn a model
without negative samples. In this paper, we propose a self-supervised
collaborative filtering framework (SelfCF), that is specially designed for
recommender scenario with implicit feedback. The main idea of SelfCF is to
augment the output embeddings generated by backbone networks, because it is
infeasible to augment raw input of user/item ids. We propose and study three
output perturbation techniques that can be applied to different types of
backbone networks including both traditional CF models and graph-based models.
By encapsulating two popular recommendation models into the framework, our
experiments on three datasets show that the best performance of our framework
is comparable or better than the supervised counterpart. We also show that
SelfCF can boost up the performance by up to 8.93\% on average, compared with
another self-supervised framework as the baseline. Source codes are available
at: https://github.com/enoche/SelfCF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Modified Drake Equation for Assessing Adversarial Risk to Machine Learning Models. (arXiv:2103.02718v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalin_J/0/1/0/all/0/1">Josh Kalin</a>, <a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1">David Noever</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1">Matthew Ciolino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02718">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models present a risk of adversarial attack when deployed in
production. Quantifying the contributing factors and uncertainties using
empirical measures could assist the industry with assessing the risk of
downloading and deploying common model types. This work proposes modifying the
traditional Drake Equation&#x27;s formalism to estimate the number of potentially
successful adversarial attacks on a deployed model. The Drake Equation is
famously used for parameterizing uncertainties and it has been used in many
research fields outside of its original intentions to estimate the number of
radio-capable extra-terrestrial civilizations. While previous work has outlined
methods for discovering vulnerabilities in public model architectures, the
proposed equation seeks to provide a semi-quantitative benchmark for evaluating
and estimating the potential risk factors for adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Bayesian Specification Inference from Demonstrations. (arXiv:2107.02912v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Ankit Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1">Pritish Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Craven_P/0/1/0/all/0/1">Patrick Craven</a>, <a href="http://arxiv.org/find/cs/1/au:+Landers_K/0/1/0/all/0/1">Kevin Landers</a>, <a href="http://arxiv.org/find/cs/1/au:+Oden_K/0/1/0/all/0/1">Kevin Oden</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_J/0/1/0/all/0/1">Julie Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02912">
                                    <div class="article-summary-box-inner">
                                        <span>When observing task demonstrations, human apprentices are able to identify
whether a given task is executed correctly long before they gain expertise in
actually performing that task. Prior research into learning from demonstrations
(LfD) has failed to capture this notion of the acceptability of a task&#x27;s
execution; meanwhile, temporal logics provide a flexible language for
expressing task specifications. Inspired by this, we present Bayesian
specification inference, a probabilistic model for inferring task specification
as a temporal logic formula. We incorporate methods from probabilistic
programming to define our priors, along with a domain-independent likelihood
function to enable sampling-based inference. We demonstrate the efficacy of our
model for inferring specifications, with over 90% similarity observed between
the inferred specification and the ground truth, both within a synthetic domain
and during a real-world table setting task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving the scalarization issues of Advantage-based Reinforcement Learning Algorithms. (arXiv:2004.04120v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galatolo_F/0/1/0/all/0/1">Federico A. Galatolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cimino_M/0/1/0/all/0/1">Mario G.C.A. Cimino</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaglini_G/0/1/0/all/0/1">Gigliola Vaglini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04120">
                                    <div class="article-summary-box-inner">
                                        <span>In this research, some of the issues that arise from the scalarization of the
multi-objective optimization problem in the Advantage Actor Critic (A2C)
reinforcement learning algorithm are investigated. The paper shows how a naive
scalarization can lead to gradients overlapping. Furthermore, the possibility
that the entropy regularization term can be a source of uncontrolled noise is
discussed. With respect to the above issues, a technique to avoid gradient
overlapping is proposed, while keeping the same loss formulation. Moreover, a
method to avoid the uncontrolled noise, by sampling the actions from
distributions with a desired minimum entropy, is investigated. Pilot
experiments have been carried out to show how the proposed method speeds up the
training. The proposed approach can be applied to any Advantage-based
Reinforcement Learning algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Matrix-Free Approximations of Second-Order Information, with Applications to Pruning and Optimization. (arXiv:2107.03356v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1">Elias Frantar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1">Eldar Kurtic</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03356">
                                    <div class="article-summary-box-inner">
                                        <span>Efficiently approximating local curvature information of the loss function is
a key tool for optimization and compression of deep neural networks. Yet, most
existing methods to approximate second-order information have high
computational or storage costs, which can limit their practicality. In this
work, we investigate matrix-free, linear-time approaches for estimating
Inverse-Hessian Vector Products (IHVPs) for the case when the Hessian can be
approximated as a sum of rank-one matrices, as in the classic approximation of
the Hessian by the empirical Fisher matrix. We propose two new algorithms as
part of a framework called M-FAC: the first algorithm is tailored towards
network compression and can compute the IHVP for dimension $d$, if the Hessian
is given as a sum of $m$ rank-one matrices, using $O(dm^2)$ precomputation,
$O(dm)$ cost for computing the IHVP, and query cost $O(m)$ for any single
element of the inverse Hessian. The second algorithm targets an optimization
setting, where we wish to compute the product between the inverse Hessian,
estimated over a sliding window of optimization steps, and a given gradient
direction, as required for preconditioned SGD. We give an algorithm with cost
$O(dm + m^2)$ for computing the IHVP and $O(dm + m^3)$ for adding or removing
any gradient from the sliding window. These two algorithms yield
state-of-the-art results for network pruning and optimization with lower
computational overhead relative to existing second-order methods.
Implementations are available at [10] and [18].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Mutual Information Estimators for Channel Capacity Learning. (arXiv:2107.03084v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Letizia_N/0/1/0/all/0/1">Nunzio A. Letizia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonello_A/0/1/0/all/0/1">Andrea M. Tonello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03084">
                                    <div class="article-summary-box-inner">
                                        <span>Channel capacity plays a crucial role in the development of modern
communication systems as it represents the maximum rate at which information
can be reliably transmitted over a communication channel. Nevertheless, for the
majority of channels, finding a closed-form capacity expression remains an open
challenge. This is because it requires to carry out two formidable tasks a) the
computation of the mutual information between the channel input and output, and
b) its maximization with respect to the signal distribution at the channel
input. In this paper, we address both tasks. Inspired by implicit generative
models, we propose a novel cooperative framework to automatically learn the
channel capacity, for any type of memory-less channel. In particular, we
firstly develop a new methodology to estimate the mutual information directly
from a discriminator typically deployed to train adversarial networks, referred
to as discriminative mutual information estimator (DIME). Secondly, we include
the discriminator in a cooperative channel capacity learning framework,
referred to as CORTICAL, where a discriminator learns to distinguish between
dependent and independent channel input-output samples while a generator learns
to produce the optimal channel input distribution for which the discriminator
exhibits the best performance. Lastly, we prove that a particular choice of the
cooperative value function solves the channel capacity estimation problem.
Simulation results demonstrate that the proposed method offers high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-VAE: Learning Disentangled View-common and View-peculiar Visual Representations for Multi-view Clustering. (arXiv:2106.11232v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yazhou Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Huayi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_X/0/1/0/all/0/1">Xiaorong Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaofeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Ming Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11232">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view clustering, a long-standing and important research problem,
focuses on mining complementary information from diverse views. However,
existing works often fuse multiple views&#x27; representations or handle clustering
in a common feature space, which may result in their entanglement especially
for visual representations. To address this issue, we present a novel VAE-based
multi-view clustering framework (Multi-VAE) by learning disentangled visual
representations. Concretely, we define a view-common variable and multiple
view-peculiar variables in the generative model. The prior of view-common
variable obeys approximately discrete Gumbel Softmax distribution, which is
introduced to extract the common cluster factor of multiple views. Meanwhile,
the prior of view-peculiar variable follows continuous Gaussian distribution,
which is used to represent each view&#x27;s peculiar visual factors. By controlling
the mutual information capacity to disentangle the view-common and
view-peculiar representations, continuous visual information of multiple views
can be separated so that their common discrete cluster information can be
effectively mined. Experimental results demonstrate that Multi-VAE enjoys the
disentangled and explainable visual representations, while obtaining superior
clustering performance compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly detection and automatic labeling for solar cell quality inspection based on Generative Adversarial Network. (arXiv:2103.03518v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balzategui_J/0/1/0/all/0/1">Julen Balzategui</a>, <a href="http://arxiv.org/find/cs/1/au:+Eciolaza_L/0/1/0/all/0/1">Luka Eciolaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Maestro_Watson_D/0/1/0/all/0/1">Daniel Maestro-Watson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03518">
                                    <div class="article-summary-box-inner">
                                        <span>Quality inspection applications in industry are required to move towards a
zero-defect manufacturing scenario, withnon-destructive inspection and
traceability of 100 % of produced parts. Developing robust fault detection and
classification modelsfrom the start-up of the lines is challenging due to the
difficulty in getting enough representative samples of the faulty patternsand
the need to manually label them. This work presents a methodology to develop a
robust inspection system, targeting thesepeculiarities, in the context of solar
cell manufacturing. The methodology is divided into two phases: In the first
phase, an anomalydetection model based on a Generative Adversarial Network
(GAN) is employed. This model enables the detection and localizationof
anomalous patterns within the solar cells from the beginning, using only
non-defective samples for training and without anymanual labeling involved. In
a second stage, as defective samples arise, the detected anomalies will be used
as automaticallygenerated annotations for the supervised training of a Fully
Convolutional Network that is capable of detecting multiple types offaults. The
experimental results using 1873 EL images of monocrystalline cells show that
(a) the anomaly detection scheme can beused to start detecting features with
very little available data, (b) the anomaly detection may serve as automatic
labeling in order totrain a supervised model, and (c) segmentation and
classification results of supervised models trained with automatic labels
arecomparable to the ones obtained from the models trained with manual labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auxiliary Diagnosing Coronary Stenosis Using Machine Learning. (arXiv:2007.10316v3 [q-bio.TO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_W/0/1/0/all/0/1">Weijun Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+LU_F/0/1/0/all/0/1">Fengyuan LU</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyu Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+LI_E/0/1/0/all/0/1">En LI</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10316">
                                    <div class="article-summary-box-inner">
                                        <span>How to accurately classify and diagnose whether an individual has Coronary
Stenosis (CS) without invasive physical examination? This problem has not been
solved satisfactorily. To this end, the four machine learning (ML) algorithms,
i.e., Boosted Tree (BT), Decision Tree (DT), Logistic Regression (LR) and
Random Forest (RF) are employed in this paper. First, eleven features including
basic information of an individual, symptoms and results of routine physical
examination are selected, as well as one label is specified, indicating whether
an individual suffers from different severity of coronary artery stenosis or
not. On the basis of it, a sample set is constructed. Second, each of these
four ML algorithms learns from the sample set to obtain the corresponding
optimal classified results, respectively. The experimental results show that:
RF performs better than other three algorithms, and the former algorithm
classifies whether an individual has CS with an accuracy of 95.7% (&#x3D;90/94).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Atmospheric Data and Identifying Dynamics: Temporal Data-Driven Modeling of Air Pollutants. (arXiv:2010.06538v2 [stat.AP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rubio_Herrero_J/0/1/0/all/0/1">Javier Rubio-Herrero</a>, <a href="http://arxiv.org/find/stat/1/au:+Marrero_C/0/1/0/all/0/1">Carlos Ortiz Marrero</a>, <a href="http://arxiv.org/find/stat/1/au:+Fan_W/0/1/0/all/0/1">Wai-Tong Louis Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06538">
                                    <div class="article-summary-box-inner">
                                        <span>Atmospheric modeling has recently experienced a surge with the advent of deep
learning. Most of these models, however, predict concentrations of pollutants
following a data-driven approach in which the physical laws that govern their
behaviors and relationships remain hidden. With the aid of real-world air
quality data collected hourly in different stations throughout Madrid, we
present an empirical approach using data-driven techniques with the following
goals: (1) Find parsimonious systems of ordinary differential equations via
sparse identification of nonlinear dynamics (SINDy) that model the
concentration of pollutants and their changes over time; (2) assess the
performance and limitations of our models using stability analysis; (3)
reconstruct the time series of chemical pollutants not measured in certain
stations using delay coordinate embedding results. Our results show that
Akaike&#x27;s Information Criterion can work well in conjunction with best subset
regression as to find an equilibrium between sparsity and goodness of fit. We
also find that, due to the complexity of the chemical system under study,
identifying the dynamics of this system over longer periods of time require
higher levels of data filtering and smoothing. Stability analysis for the
reconstructed ordinary differential equations (ODEs) reveals that more than
half of the physically relevant critical points are saddle points, suggesting
that the system is unstable even under the idealized assumption that all
environmental conditions are constant over time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Architecture Pruning for Transfer Learning. (arXiv:2107.03375v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colombo_N/0/1/0/all/0/1">Nicolo Colombo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03375">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new gradient-based approach for extracting sub-architectures
from a given large model. Contrarily to existing pruning methods, which are
unable to disentangle the network architecture and the corresponding weights,
our architecture-pruning scheme produces transferable new structures that can
be successfully retrained to solve different tasks. We focus on a
transfer-learning setup where architectures can be trained on a large data set
but very few data points are available for fine-tuning them on new tasks. We
define a new gradient-based algorithm that trains architectures of arbitrarily
low complexity independently from the attached weights. Given a search space
defined by an existing large neural model, we reformulate the architecture
search task as a complexity-penalized subset-selection problem and solve it
through a two-temperature relaxation scheme. We provide theoretical convergence
guarantees and validate the proposed transfer-learning strategy on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Representation Models for Text Classification with AutoML Tools. (arXiv:2106.12798v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brandle_S/0/1/0/all/0/1">Sebastian Br&#xe4;ndle</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanussek_M/0/1/0/all/0/1">Marc Hanussek</a>, <a href="http://arxiv.org/find/cs/1/au:+Blohm_M/0/1/0/all/0/1">Matthias Blohm</a>, <a href="http://arxiv.org/find/cs/1/au:+Kintz_M/0/1/0/all/0/1">Maximilien Kintz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12798">
                                    <div class="article-summary-box-inner">
                                        <span>Automated Machine Learning (AutoML) has gained increasing success on tabular
data in recent years. However, processing unstructured data like text is a
challenge and not widely supported by open-source AutoML tools. This work
compares three manually created text representations and text embeddings
automatically created by AutoML tools. Our benchmark includes four popular
open-source AutoML tools and eight datasets for text classification purposes.
The results show that straightforward text representations perform better than
AutoML tools with automatically created text embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An algorithmic view of $\ell_2$ regularization and some path-following algorithms. (arXiv:2107.03322v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1">Yunzhang Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_R/0/1/0/all/0/1">Renxiong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03322">
                                    <div class="article-summary-box-inner">
                                        <span>We establish an equivalence between the $\ell_2$-regularized solution path
for a convex loss function, and the solution of an ordinary differentiable
equation (ODE). Importantly, this equivalence reveals that the solution path
can be viewed as the flow of a hybrid of gradient descent and Newton method
applying to the empirical loss, which is similar to a widely used optimization
technique called trust region method. This provides an interesting algorithmic
view of $\ell_2$ regularization, and is in contrast to the conventional view
that the $\ell_2$ regularization solution path is similar to the gradient flow
of the empirical loss.New path-following algorithms based on homotopy methods
and numerical ODE solvers are proposed to numerically approximate the solution
path. In particular, we consider respectively Newton method and gradient
descent method as the basis algorithm for the homotopy method, and establish
their approximation error rates over the solution path. Importantly, our theory
suggests novel schemes to choose grid points that guarantee an arbitrarily
small suboptimality for the solution path. In terms of computational cost, we
prove that in order to achieve an $\epsilon$-suboptimality for the entire
solution path, the number of Newton steps required for the Newton method is
$\mathcal O(\epsilon^{-1/2})$, while the number of gradient steps required for
the gradient descent method is $\mathcal O\left(\epsilon^{-1}
\ln(\epsilon^{-1})\right)$. Finally, we use $\ell_2$-regularized logistic
regression as an illustrating example to demonstrate the effectiveness of the
proposed path-following algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RISAN: Robust Instance Specific Abstention Network. (arXiv:2107.03090v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalra_B/0/1/0/all/0/1">Bhavya Kalra</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_K/0/1/0/all/0/1">Kulin Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Manwani_N/0/1/0/all/0/1">Naresh Manwani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03090">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose deep architectures for learning instance specific
abstain (reject option) binary classifiers. The proposed approach uses double
sigmoid loss function as described by Kulin Shah and Naresh Manwani in (&quot;Online
Active Learning of Reject Option Classifiers&quot;, AAAI, 2020), as a performance
measure. We show that the double sigmoid loss is classification calibrated. We
also show that the excess risk of 0-d-1 loss is upper bounded by the excess
risk of double sigmoid loss. We derive the generalization error bounds for the
proposed architecture for reject option classifiers. To show the effectiveness
of the proposed approach, we experiment with several real world datasets. We
observe that the proposed approach not only performs comparable to the
state-of-the-art approaches, it is also robust against label noise. We also
provide visualizations to observe the important features learned by the network
corresponding to the abstaining decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combined Global and Local Search for Optimization with Gaussian Process Models. (arXiv:2107.03217v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1">Qun Meng</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Songhao Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Ng_S/0/1/0/all/0/1">Szu Hui Ng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03217">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian process (GP) model based optimization is widely applied in
simulation and machine learning. In general, it first estimates a GP model
based on a few observations from the true response and then employs this model
to guide the search, aiming to quickly locate the global optimum. Despite its
successful applications, it has several limitations that may hinder its broader
usage. First, building an accurate GP model can be difficult and
computationally expensive, especially when the response function is multi-modal
or varies significantly over the design space. Second, even with an appropriate
model, the search process can be trapped in suboptimal regions before moving to
the global optimum due to the excessive effort spent around the current best
solution. In this work, we adopt the Additive Global and Local GP (AGLGP) model
in the optimization framework. The model is rooted in the inducing-points-based
GP sparse approximations and is combined with independent local models in
different regions. With these properties, the AGLGP model is suitable for
multi-modal responses with relatively large data sizes. Based on this AGLGP
model, we propose a Combined Global and Local search for Optimization (CGLO)
algorithm. It first divides the whole design space into disjoint local regions
and identifies a promising region with the global model. Next, a local model in
the selected region is fit to guide detailed search within this region. The
algorithm then switches back to the global step when a good local solution is
found. The global and local natures of CGLO enable it to enjoy the benefits of
both global and local search to efficiently locate the global optimum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Predict Error for MRI Reconstruction. (arXiv:2002.05582v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pezzotti_N/0/1/0/all/0/1">Nicola Pezzotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05582">
                                    <div class="article-summary-box-inner">
                                        <span>In healthcare applications, predictive uncertainty has been used to assess
predictive accuracy. In this paper, we demonstrate that predictive uncertainty
estimated by the current methods does not highly correlate with prediction
error by decomposing the latter into random and systematic errors, and showing
that the former is equivalent to the variance of the random error. In addition,
we observe that current methods unnecessarily compromise performance by
modifying the model and training loss to estimate the target and uncertainty
jointly. We show that estimating them separately without modifications improves
performance. Following this, we propose a novel method that estimates the
target labels and magnitude of the prediction error in two steps. We
demonstrate this method on a large-scale MRI reconstruction task, and achieve
significantly better results than the state-of-the-art uncertainty estimation
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on Components Segmentation Task of Document Photos. (arXiv:2106.08499v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Junior_C/0/1/0/all/0/1">Celso A. M. Lopes Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1">Ricardo B. das Neves Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezerra_B/0/1/0/all/0/1">Byron L. D. Bezerra</a>, <a href="http://arxiv.org/find/cs/1/au:+Toselli_A/0/1/0/all/0/1">Alejandro H. Toselli</a>, <a href="http://arxiv.org/find/cs/1/au:+Impedovo_D/0/1/0/all/0/1">Donato Impedovo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08499">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the short-term competition on Components Segmentation
Task of Document Photos that was prepared in the context of the 16th
International Conference on Document Analysis and Recognition (ICDAR 2021).
This competition aims to bring together researchers working on the filed of
identification document image processing and provides them a suitable benchmark
to compare their techniques on the component segmentation task of document
images. Three challenge tasks were proposed entailing different segmentation
assignments to be performed on a provided dataset. The collected data are from
several types of Brazilian ID documents, whose personal information was
conveniently replaced. There were 16 participants whose results obtained for
some or all the three tasks show different rates for the adopted metrics, like
Dice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning
models were applied by the entrants with diverse strategies to achieve the best
results in each of the tasks. Obtained results show that the current applied
methods for solving one of the proposed tasks (document boundary detection) are
already well stablished. However, for the other two challenge tasks (text zone
and handwritten sign detection) research and development of more robust
approaches are still required to achieve acceptable results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Big Data Information and Nowcasting: Consumption and Investment from Bank Transactions in Turkey. (arXiv:2107.03299v1 [econ.EM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Barlas_A/0/1/0/all/0/1">Ali B. Barlas</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Mert_S/0/1/0/all/0/1">Seda Guler Mert</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Isa_B/0/1/0/all/0/1">Berk Orkun Isa</a> (BBVA Research) <a href="http://arxiv.org/find/econ/1/au:+Ortiz_A/0/1/0/all/0/1">Alvaro Ortiz</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Rodrigo_T/0/1/0/all/0/1">Tomasa Rodrigo</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Soybilgen_B/0/1/0/all/0/1">Baris Soybilgen</a> (Bilgi University), <a href="http://arxiv.org/find/econ/1/au:+Yazgan_E/0/1/0/all/0/1">Ege Yazgan</a> (Bilgi University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03299">
                                    <div class="article-summary-box-inner">
                                        <span>We use the aggregate information from individual-to-firm and firm-to-firm in
Garanti BBVA Bank transactions to mimic domestic private demand. Particularly,
we replicate the quarterly national accounts aggregate consumption and
investment (gross fixed capital formation) and its bigger components (Machinery
and Equipment and Construction) in real time for the case of Turkey. In order
to validate the usefulness of the information derived from these indicators we
test the nowcasting ability of both indicators to nowcast the Turkish GDP using
different nowcasting models. The results are successful and confirm the
usefulness of Consumption and Investment Banking transactions for nowcasting
purposes. The value of the Big data information is more relevant at the
beginning of the nowcasting process, when the traditional hard data information
is scarce. This makes this information specially relevant for those countries
where statistical release lags are longer like the Emerging Markets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Multi-Agent Fitted Q Iteration. (arXiv:2104.09343v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lesage_Landry_A/0/1/0/all/0/1">Antoine Lesage-Landry</a>, <a href="http://arxiv.org/find/cs/1/au:+Callaway_D/0/1/0/all/0/1">Duncan S. Callaway</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09343">
                                    <div class="article-summary-box-inner">
                                        <span>We formulate an efficient approximation for multi-agent batch reinforcement
learning, the approximate multi-agent fitted Q iteration (AMAFQI). We present a
detailed derivation of our approach. We propose an iterative policy search and
show that it yields a greedy policy with respect to multiple approximations of
the centralized, standard Q-function. In each iteration and policy evaluation,
AMAFQI requires a number of computations that scales linearly with the number
of agents whereas the analogous number of computations increase exponentially
for the fitted Q iteration (FQI), one of the most commonly used approaches in
batch reinforcement learning. This property of AMAFQI is fundamental for the
design of a tractable multi-agent approach. We evaluate the performance of
AMAFQI and compare it to FQI in numerical simulations. Numerical examples
illustrate the significant computation time reduction when using AMAFQI instead
of FQI in multi-agent problems and corroborate the similar decision-making
performance of both approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Security of Deepfake Detection. (arXiv:2107.02045v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaoyu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02045">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfakes pose growing challenges to the trust of information on the
Internet. Thus, detecting deepfakes has attracted increasing attentions from
both academia and industry. State-of-the-art deepfake detection methods consist
of two key components, i.e., face extractor and face classifier, which extract
the face region in an image and classify it to be real/fake, respectively.
Existing studies mainly focused on improving the detection performance in
non-adversarial settings, leaving security of deepfake detection in adversarial
settings largely unexplored. In this work, we aim to bridge the gap. In
particular, we perform a systematic measurement study to understand the
security of the state-of-the-art deepfake detection methods in adversarial
settings. We use two large-scale public deepfakes data sources including
FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes
are fake face images; and we train state-of-the-art deepfake detection methods.
These detection methods can achieve 0.94--0.99 accuracies in non-adversarial
settings on these datasets. However, our measurement results uncover multiple
security limitations of the deepfake detection methods in adversarial settings.
First, we find that an attacker can evade a face extractor, i.e., the face
extractor fails to extract the correct face regions, via adding small Gaussian
noise to its deepfake images. Second, we find that a face classifier trained
using deepfakes generated by one method cannot detect deepfakes generated by
another method, i.e., an attacker can evade detection via generating deepfakes
using a new method. Third, we find that an attacker can leverage backdoor
attacks developed by the adversarial machine learning community to evade a face
classifier. Our results highlight that deepfake detection should consider the
adversarial nature of the problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Formal derivation of Mesh Neural Networks with their Forward-Only gradient Propagation. (arXiv:1905.06684v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galatolo_F/0/1/0/all/0/1">Federico A. Galatolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cimino_M/0/1/0/all/0/1">Mario G.C.A. Cimino</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaglini_G/0/1/0/all/0/1">Gigliola Vaglini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.06684">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes the Mesh Neural Network (MNN), a novel architecture which
allows neurons to be connected in any topology, to efficiently route
information. In MNNs, information is propagated between neurons throughout a
state transition function. State and error gradients are then directly computed
from state updates without backward computation. The MNN architecture and the
error propagation schema is formalized and derived in tensor algebra. The
proposed computational model can fully supply a gradient descent process, and
is potentially suitable for very large scale sparse NNs, due to its
expressivity and training efficiency, with respect to NNs based on
back-propagation and computational graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the performance of EEG decoding using anchored-STFT in conjunction with gradient norm adversarial augmentation. (arXiv:2011.14694v3 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Ali_O/0/1/0/all/0/1">Omair Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Saif_ur_Rehman_M/0/1/0/all/0/1">Muhammad Saif-ur-Rehman</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dyck_S/0/1/0/all/0/1">Susanne Dyck</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Glasmachers_T/0/1/0/all/0/1">Tobias Glasmachers</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Iossifidis_I/0/1/0/all/0/1">Ioannis Iossifidis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Klaes_C/0/1/0/all/0/1">Christian Klaes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14694">
                                    <div class="article-summary-box-inner">
                                        <span>Brain-computer interfaces (BCIs) enable direct communication between humans
and machines by translating brain activity into control commands. EEG is one of
the most common sources of neural signals because of its inexpensive and
non-invasive nature. However, interpretation of EEG signals is non-trivial
because EEG signals have a low spatial resolution and are often distorted with
noise and artifacts. Therefore, it is possible that meaningful patterns for
classifying EEG signals are deeply hidden. Nowadays, state-of-the-art
deep-learning algorithms have proven to be quite efficient in learning hidden,
meaningful patterns. However, the performance of the deep learning algorithms
depends upon the quality and the amount of the provided training data. Hence, a
better input formation (feature extraction) technique and a generative model to
produce high-quality data can enable the deep learning algorithms to adapt high
generalization quality. In this study, we proposed a novel input formation
(feature extraction) method in conjunction with a novel deep learning based
generative model to harness new training examples. The feature vectors are
extracted using a modified Short Time Fourier Transform (STFT) called
anchored-STFT. Anchored-STFT, inspired by wavelet transform, tries to minimize
the tradeoff between time and frequency resolution. As a result, it extracts
the inputs (feature vectors) with better time and frequency resolution compared
to the standard STFT. Secondly, we introduced a novel generative adversarial
data augmentation technique called gradient norm adversarial augmentation
(GNAA) for generating more training data. Thirdly, we investigated the
existence and significance of adversarial inputs in EEG data. Our approach
obtained the kappa value of 0.814 for BCI competition II dataset III and 0.755
for BCI competition IV dataset 2b for session-to-session transfer on test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning in Information Criteria-based Feature Selection. (arXiv:2107.02847v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1">Shaohan Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Sahinidis_N/0/1/0/all/0/1">Nikolaos V. Sahinidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_C/0/1/0/all/0/1">Chuanhou Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02847">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the effectiveness of transfer learning based on
Mallows&#x27; Cp. We propose a procedure that combines transfer learning with
Mallows&#x27; Cp (TLCp) and prove that it outperforms the conventional Mallows&#x27; Cp
criterion in terms of accuracy and stability. Our theoretical results indicate
that, for any sample size in the target domain, the proposed TLCp estimator
performs better than the Cp estimator by the mean squared error (MSE) metric in
the case of orthogonal predictors, provided that i) the dissimilarity between
the tasks from source domain and target domain is small, and ii) the procedure
parameters (complexity penalties) are tuned according to certain explicit
rules. Moreover, we show that our transfer learning framework can be extended
to other feature selection criteria, such as the Bayesian information
criterion. By analyzing the solution of the orthogonalized Cp, we identify an
estimator that asymptotically approximates the solution of the Cp criterion in
the case of non-orthogonal predictors. Similar results are obtained for the
non-orthogonal TLCp. Finally, simulation studies and applications with real
data demonstrate the usefulness of the TLCp scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solution of Physics-based Bayesian Inverse Problems with Deep Generative Priors. (arXiv:2107.02926v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Patel_D/0/1/0/all/0/1">Dhruv V Patel</a>, <a href="http://arxiv.org/find/stat/1/au:+Ray_D/0/1/0/all/0/1">Deep Ray</a>, <a href="http://arxiv.org/find/stat/1/au:+Oberai_A/0/1/0/all/0/1">Assad A Oberai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02926">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse problems are notoriously difficult to solve because they can have no
solutions, multiple solutions, or have solutions that vary significantly in
response to small perturbations in measurements. Bayesian inference, which
poses an inverse problem as a stochastic inference problem, addresses these
difficulties and provides quantitative estimates of the inferred field and the
associated uncertainty. However, it is difficult to employ when inferring
vectors of large dimensions, and/or when prior information is available through
previously acquired samples. In this paper, we describe how deep generative
adversarial networks can be used to represent the prior distribution in
Bayesian inference and overcome these challenges. We apply these ideas to
inverse problems that are diverse in terms of the governing physical
principles, sources of prior knowledge, type of measurement, and the extent of
available information about measurement noise. In each case we apply the
proposed approach to infer the most likely solution and quantitative estimates
of uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Harnessing Heterogeneity: Learning from Decomposed Feedback in Bayesian Modeling. (arXiv:2107.03003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilder_B/0/1/0/all/0/1">Bryan Wilder</a>, <a href="http://arxiv.org/find/cs/1/au:+Suen_S/0/1/0/all/0/1">Sze-chuan Suen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1">Bistra Dilkina</a>, <a href="http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1">Milind Tambe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03003">
                                    <div class="article-summary-box-inner">
                                        <span>There is significant interest in learning and optimizing a complex system
composed of multiple sub-components, where these components may be agents or
autonomous sensors. Among the rich literature on this topic, agent-based and
domain-specific simulations can capture complex dynamics and subgroup
interaction, but optimizing over such simulations can be computationally and
algorithmically challenging. Bayesian approaches, such as Gaussian processes
(GPs), can be used to learn a computationally tractable approximation to the
underlying dynamics but typically neglect the detailed information about
subgroups in the complicated system. We attempt to find the best of both worlds
by proposing the idea of decomposed feedback, which captures group-based
heterogeneity and dynamics. We introduce a novel decomposed GP regression to
incorporate the subgroup decomposed feedback. Our modified regression has
provably lower variance -- and thus a more accurate posterior -- compared to
previous approaches; it also allows us to introduce a decomposed GP-UCB
optimization algorithm that leverages subgroup feedback. The Bayesian nature of
our method makes the optimization algorithm trackable with a theoretical
guarantee on convergence and no-regret property. To demonstrate the wide
applicability of this work, we execute our algorithm on two disparate social
problems: infectious disease control in a heterogeneous population and
allocation of distributed weather sensors. Experimental results show that our
new method provides significant improvement compared to the state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic partition of unity networks: clustering based deep approximation. (arXiv:2107.03066v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trask_N/0/1/0/all/0/1">Nat Trask</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulian_M/0/1/0/all/0/1">Mamikon Gulian</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Andy Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kookjin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03066">
                                    <div class="article-summary-box-inner">
                                        <span>Partition of unity networks (POU-Nets) have been shown capable of realizing
algebraic convergence rates for regression and solution of PDEs, but require
empirical tuning of training parameters. We enrich POU-Nets with a Gaussian
noise model to obtain a probabilistic generalization amenable to gradient-based
minimization of a maximum likelihood loss. The resulting architecture provides
spatial representations of both noiseless and noisy data as Gaussian mixtures
with closed form expressions for variance which provides an estimator of local
error. The training process yields remarkably sharp partitions of input space
based upon correlation of function values. This classification of training
points is amenable to a hierarchical refinement strategy that significantly
improves the localization of the regression, allowing for higher-order
polynomial approximation to be utilized. The framework scales more favorably to
large data sets as compared to Gaussian process regression and allows for
spatially varying uncertainty, leveraging the expressive power of deep neural
networks while bypassing expensive training associated with other probabilistic
deep learning methods. Compared to standard deep neural networks, the framework
demonstrates hp-convergence without the use of regularizers to tune the
localization of partitions. We provide benchmarks quantifying performance in
high/low-dimensions, demonstrating that convergence rates depend only on the
latent dimension of data within high-dimensional space. Finally, we introduce a
new open-source data set of PDE-based simulations of a semiconductor device and
perform unsupervised extraction of a physically interpretable reduced-order
basis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Machine Learning for Cybersecurity and Computer Vision: Current Developments and Challenges. (arXiv:2107.02894v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_B/0/1/0/all/0/1">Bowei Xi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02894">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a comprehensive overview of adversarial machine learning focusing
on two application domains, i.e., cybersecurity and computer vision. Research
in adversarial machine learning addresses a significant threat to the wide
application of machine learning techniques -- they are vulnerable to carefully
crafted attacks from malicious adversaries. For example, deep neural networks
fail to correctly classify adversarial images, which are generated by adding
imperceptible perturbations to clean images.We first discuss three main
categories of attacks against machine learning techniques -- poisoning attacks,
evasion attacks, and privacy attacks. Then the corresponding defense approaches
are introduced along with the weakness and limitations of the existing defense
approaches. We notice adversarial samples in cybersecurity and computer vision
are fundamentally different. While adversarial samples in cybersecurity often
have different properties/distributions compared with training data,
adversarial images in computer vision are created with minor input
perturbations. This further complicates the development of robust learning
techniques, because a robust learning technique must withstand different types
of attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling up Continuous-Time Markov Chains Helps Resolve Underspecification. (arXiv:2107.02911v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gotovos_A/0/1/0/all/0/1">Alkis Gotovos</a>, <a href="http://arxiv.org/find/cs/1/au:+Burkholz_R/0/1/0/all/0/1">Rebekka Burkholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Quackenbush_J/0/1/0/all/0/1">John Quackenbush</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1">Stefanie Jegelka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02911">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling the time evolution of discrete sets of items (e.g., genetic
mutations) is a fundamental problem in many biomedical applications. We
approach this problem through the lens of continuous-time Markov chains, and
show that the resulting learning task is generally underspecified in the usual
setting of cross-sectional data. We explore a perhaps surprising remedy:
including a number of additional independent items can help determine time
order, and hence resolve underspecification. This is in sharp contrast to the
common practice of limiting the analysis to a small subset of relevant items,
which is followed largely due to poor scaling of existing methods. To put our
theoretical insight into practice, we develop an approximate likelihood
maximization method for learning continuous-time Markov chains, which can scale
to hundreds of items and is orders of magnitude faster than previous methods.
We demonstrate the effectiveness of our approach on synthetic and real cancer
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trans4E: Link Prediction on Scholarly Knowledge Graphs. (arXiv:2107.03297v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayyeri_M/0/1/0/all/0/1">Mojtaba Nayyeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Cil_G/0/1/0/all/0/1">Gokce Muge Cil</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahdati_S/0/1/0/all/0/1">Sahar Vahdati</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_F/0/1/0/all/0/1">Francesco Osborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahfuzur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Angioni_S/0/1/0/all/0/1">Simone Angioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Salatino_A/0/1/0/all/0/1">Angelo Salatino</a>, <a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1">Diego Reforgiato Recupero</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilyeva_N/0/1/0/all/0/1">Nadezhda Vassilyeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Motta_E/0/1/0/all/0/1">Enrico Motta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1">Jens Lehmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03297">
                                    <div class="article-summary-box-inner">
                                        <span>The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the
quality of AI-based services. In the scholarly domain, KGs describing research
publications typically lack important information, hindering our ability to
analyse and predict research dynamics. In recent years, link prediction
approaches based on Knowledge Graph Embedding models became the first aid for
this issue. In this work, we present Trans4E, a novel embedding model that is
particularly fit for KGs which include N to M relations with N$\gg$M. This is
typical for KGs that categorize a large number of entities (e.g., research
articles, patents, persons) according to a relatively small set of categories.
Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry
DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the
information about Fields of Study (e.g., &#x27;neural networks&#x27;, &#x27;machine learning&#x27;,
&#x27;artificial intelligence&#x27;), and affiliation types (e.g., &#x27;education&#x27;,
&#x27;company&#x27;, &#x27;government&#x27;), improving the scope and accuracy of the resulting
data. We evaluated our approach against alternative solutions on AIDA, MAG, and
four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms
the other models when using low embedding dimensions and obtains competitive
results in high dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Urban Tree Species Classification Using Aerial Imagery. (arXiv:2107.03182v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waters_E/0/1/0/all/0/1">Emily Waters</a>, <a href="http://arxiv.org/find/cs/1/au:+Oghaz_M/0/1/0/all/0/1">Mahdi Maktabdar Oghaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Saheer_L/0/1/0/all/0/1">Lakshmi Babu Saheer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03182">
                                    <div class="article-summary-box-inner">
                                        <span>Urban trees help regulate temperature, reduce energy consumption, improve
urban air quality, reduce wind speeds, and mitigating the urban heat island
effect. Urban trees also play a key role in climate change mitigation and
global warming by capturing and storing atmospheric carbon-dioxide which is the
largest contributor to greenhouse gases. Automated tree detection and species
classification using aerial imagery can be a powerful tool for sustainable
forest and urban tree management. Hence, This study first offers a pipeline for
generating labelled dataset of urban trees using Google Map&#x27;s aerial images and
then investigates how state of the art deep Convolutional Neural Network models
such as VGG and ResNet handle the classification problem of urban tree aerial
images under different parameters. Experimental results show our best model
achieves an average accuracy of 60% over 6 tree species.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cognitive Learning-Aided Multi-Antenna Communications. (arXiv:2010.03131v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Elbir_A/0/1/0/all/0/1">Ahmet M. Elbir</a>, <a href="http://arxiv.org/find/eess/1/au:+Mishra_K/0/1/0/all/0/1">Kumar Vijay Mishra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03131">
                                    <div class="article-summary-box-inner">
                                        <span>Cognitive communications have emerged as a promising solution to enhance,
adapt, and invent new tools and capabilities that transcend conventional
wireless networks. Deep learning (DL) is critical in enabling essential
features of cognitive systems because of its fast prediction performance,
adaptive behavior, and model-free structure. These features are especially
significant for multi-antenna wireless communications systems, which generate
and handle massive data. Multiple antennas may provide multiplexing, diversity,
or antenna gains that, respectively, improve the capacity, bit error rate, or
the signal-to-interference-plus-noise ratio. In practice, multi-antenna
cognitive communications encounter challenges in terms of data complexity and
diversity, hardware complexity, and wireless channel dynamics. The DL-based
solutions tackle these problems at the various stages of communications
processing such as channel estimation, hybrid beamforming, user localization,
and sparse array design. There are research opportunities to address
significant design challenges arising from insufficient data coverage, learning
model complexity, and data transmission overheads. This article provides
synopses of various DL-based methods to impart cognitive behavior to
multi-antenna wireless communications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ADAPT : Awesome Domain Adaptation Python Toolbox. (arXiv:2107.03049v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1">Antoine de Mathelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1">Fran&#xe7;ois Deheeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Guillaume Richard</a>, <a href="http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1">Mathilde Mougeot</a>, <a href="http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1">Nicolas Vayatis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03049">
                                    <div class="article-summary-box-inner">
                                        <span>ADAPT is an open-source python library providing the implementation of
several domain adaptation methods. The library is suited for scikit-learn
estimator object (object which implement fit and predict methods) and
tensorflow models. Most of the implemented methods are developed in an
estimator agnostic fashion, offering various possibilities adapted to multiple
usage. The library offers three modules corresponding to the three principal
strategies of domain adaptation: (i) feature-based containing methods
performing feature transformation; (ii) instance-based with the implementation
of reweighting techniques and (iii) parameter-based proposing methods to adapt
pre-trained models to novel observations. A full documentation is proposed
online https://adapt-python.github.io/adapt/ with gallery of examples. Besides,
the library presents an high test coverage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonmyopic Multifidelity Active Search. (arXiv:2106.06356v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Modiri_A/0/1/0/all/0/1">Arghavan Modiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1">Roman Garnett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06356">
                                    <div class="article-summary-box-inner">
                                        <span>Active search is a learning paradigm where we seek to identify as many
members of a rare, valuable class as possible given a labeling budget. Previous
work on active search has assumed access to a faithful (and expensive) oracle
reporting experimental results. However, some settings offer access to cheaper
surrogates such as computational simulation that may aid in the search. We
propose a model of multifidelity active search, as well as a novel,
computationally efficient policy for this setting that is motivated by
state-of-the-art classical policies. Our policy is nonmyopic and budget aware,
allowing for a dynamic tradeoff between exploration and exploitation. We
evaluate the performance of our solution on real-world datasets and demonstrate
significantly better performance than natural benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Training Instance Selection for Few-Shot Neural Text Generation. (arXiv:2107.03176v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xiaoyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_H/0/1/0/all/0/1">Hui-Syuan Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03176">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretrained language models have led to dramatic improvements in
text generation. Impressive performance can be achieved by finetuning only on a
small number of instances (few-shot setting). Nonetheless, almost all previous
work simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. In this work, we present a study on training
instance selection in few-shot neural text generation. The selection decision
is made based only on the unlabeled data so as to identify the most worthwhile
data points that should be annotated under some budget of labeling cost. Based
on the intuition that the few-shot training instances should be diverse and
representative of the entire data distribution, we propose a simple selection
strategy with K-means clustering. We show that even with the naive
clustering-based approach, the generation models consistently outperform random
sampling on three text generation tasks: data-to-text generation, document
summarization and question generation. We hope that this work will call for
more attention on this largely unexplored area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Detection of Botnet Traffic by features selection and Decision Trees. (arXiv:2107.02896v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Velasco_Mata_J/0/1/0/all/0/1">Javier Velasco-Mata</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Castro_V/0/1/0/all/0/1">V&#xed;ctor Gonz&#xe1;lez-Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidalgo_E/0/1/0/all/0/1">Eduardo Fidalgo</a>, <a href="http://arxiv.org/find/cs/1/au:+Alegre_E/0/1/0/all/0/1">Enrique Alegre</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02896">
                                    <div class="article-summary-box-inner">
                                        <span>Botnets are one of the online threats with the biggest presence, causing
billionaire losses to global economies. Nowadays, the increasing number of
devices connected to the Internet makes it necessary to analyze large amounts
of network traffic data. In this work, we focus on increasing the performance
on botnet traffic classification by selecting those features that further
increase the detection rate. For this purpose we use two feature selection
techniques, Information Gain and Gini Importance, which led to three
pre-selected subsets of five, six and seven features. Then, we evaluate the
three feature subsets along with three models, Decision Tree, Random Forest and
k-Nearest Neighbors. To test the performance of the three feature vectors and
the three models we generate two datasets based on the CTU-13 dataset, namely
QB-CTU13 and EQB-CTU13. We measure the performance as the macro averaged F1
score over the computational time required to classify a sample. The results
show that the highest performance is achieved by Decision Trees using a five
feature set which obtained a mean F1 score of 85% classifying each sample in an
average time of 0.78 microseconds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Methods and Datasets for Group Anomaly Detection From Fundamental Physics. (arXiv:2107.02821v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kasieczka_G/0/1/0/all/0/1">Gregor Kasieczka</a>, <a href="http://arxiv.org/find/stat/1/au:+Nachman_B/0/1/0/all/0/1">Benjamin Nachman</a>, <a href="http://arxiv.org/find/stat/1/au:+Shih_D/0/1/0/all/0/1">David Shih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02821">
                                    <div class="article-summary-box-inner">
                                        <span>The identification of anomalous overdensities in data - group or collective
anomaly detection - is a rich problem with a large number of real world
applications. However, it has received relatively little attention in the
broader ML community, as compared to point anomalies or other types of single
instance outliers. One reason for this is the lack of powerful benchmark
datasets. In this paper, we first explain how, after the Nobel-prize winning
discovery of the Higgs boson, unsupervised group anomaly detection has become a
new frontier of fundamental physics (where the motivation is to find new
particles and forces). Then we propose a realistic synthetic benchmark dataset
(LHCO2020) for the development of group anomaly detection algorithms. Finally,
we compare several existing statistically-sound techniques for unsupervised
group anomaly detection, and demonstrate their performance on the LHCO2020
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bio-Inspired Adversarial Attack Against Deep Neural Networks. (arXiv:2107.02895v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_B/0/1/0/all/0/1">Bowei Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yujie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_F/0/1/0/all/0/1">Fan Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhan Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xinyan Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02895">
                                    <div class="article-summary-box-inner">
                                        <span>The paper develops a new adversarial attack against deep neural networks
(DNN), based on applying bio-inspired design to moving physical objects. To the
best of our knowledge, this is the first work to introduce physical attacks
with a moving object. Instead of following the dominating attack strategy in
the existing literature, i.e., to introduce minor perturbations to a digital
input or a stationary physical object, we show two new successful attack
strategies in this paper. We show by superimposing several patterns onto one
physical object, a DNN becomes confused and picks one of the patterns to assign
a class label. Our experiment with three flapping wing robots demonstrates the
possibility of developing an adversarial camouflage to cause a targeted mistake
by DNN. We also show certain motion can reduce the dependency among consecutive
frames in a video and make an object detector &quot;blind&quot;, i.e., not able to detect
an object exists in the video. Hence in a successful physical attack against
DNN, targeted motion against the system should also be considered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Data Balancing for Unlabeled Satellite Imagery. (arXiv:2107.03227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_E/0/1/0/all/0/1">Erin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1">Anirudh Koul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1">Meher Anand Kasam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03227">
                                    <div class="article-summary-box-inner">
                                        <span>Data imbalance is a ubiquitous problem in machine learning. In large scale
collected and annotated datasets, data imbalance is either mitigated manually
by undersampling frequent classes and oversampling rare classes, or planned for
with imputation and augmentation techniques. In both cases balancing data
requires labels. In other words, only annotated data can be balanced.
Collecting fully annotated datasets is challenging, especially for large scale
satellite systems such as the unlabeled NASA&#x27;s 35 PB Earth Imagery dataset.
Although the NASA Earth Imagery dataset is unlabeled, there are implicit
properties of the data source that we can rely on to hypothesize about its
imbalance, such as distribution of land and water in the case of the Earth&#x27;s
imagery. We present a new iterative method to balance unlabeled data. Our
method utilizes image embeddings as a proxy for image labels that can be used
to balance data, and ultimately when trained increases overall accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN-based Data Augmentation for Chest X-ray Classification. (arXiv:2107.02970v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1">Shobhita Sundaram</a>, <a href="http://arxiv.org/find/eess/1/au:+Hulkund_N/0/1/0/all/0/1">Neha Hulkund</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02970">
                                    <div class="article-summary-box-inner">
                                        <span>A common problem in computer vision -- particularly in medical applications
-- is a lack of sufficiently diverse, large sets of training data. These
datasets often suffer from severe class imbalance. As a result, networks often
overfit and are unable to generalize to novel examples. Generative Adversarial
Networks (GANs) offer a novel method of synthetic data augmentation. In this
work, we evaluate the use of GAN- based data augmentation to artificially
expand the CheXpert dataset of chest radiographs. We compare performance to
traditional augmentation and find that GAN-based augmentation leads to higher
downstream performance for underrepresented classes. Furthermore, we see that
this result is pronounced in low data regimens. This suggests that GAN-based
augmentation a promising area of research to improve network performance when
data collection is prohibitively expensive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlled Caption Generation for Images Through Adversarial Attacks. (arXiv:2107.03050v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aafaq_N/0/1/0/all/0/1">Nayyer Aafaq</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03050">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is found to be vulnerable to adversarial examples. However, its
adversarial susceptibility in image caption generation is under-explored. We
study adversarial examples for vision and language models, which typically
adopt an encoder-decoder framework consisting of two major components: a
Convolutional Neural Network (i.e., CNN) for image feature extraction and a
Recurrent Neural Network (RNN) for caption generation. In particular, we
investigate attacks on the visual encoder&#x27;s hidden layer that is fed to the
subsequent recurrent network. The existing methods either attack the
classification layer of the visual encoder or they back-propagate the gradients
from the language model. In contrast, we propose a GAN-based algorithm for
crafting adversarial examples for neural image captioning that mimics the
internal representation of the CNN such that the resulting deep features of the
input image enable a controlled incorrect caption generation through the
recurrent network. Our contribution provides new insights for understanding
adversarial attacks on vision systems with language component. The proposed
method employs two strategies for a comprehensive evaluation. The first
examines if a neural image captioning system can be misled to output targeted
image captions. The second analyzes the possibility of keywords into the
predicted captions. Experiments show that our algorithm can craft effective
adversarial images based on the CNN hidden layers to fool captioning framework.
Moreover, we discover the proposed attack to be highly transferable. Our work
leads to new robustness implications for neural image captioning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAILS: A Robust Adversarial Immune-inspired Learning System. (arXiv:2107.02840v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindsly_S/0/1/0/all/0/1">Stephen Lindsly</a>, <a href="http://arxiv.org/find/cs/1/au:+Stansbury_C/0/1/0/all/0/1">Cooper Stansbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehemtulla_A/0/1/0/all/0/1">Alnawaz Rehemtulla</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajapakse_I/0/1/0/all/0/1">Indika Rajapakse</a>, <a href="http://arxiv.org/find/cs/1/au:+Hero_A/0/1/0/all/0/1">Alfred Hero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02840">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks against deep neural networks (DNNs) are continuously
evolving, requiring increasingly powerful defense strategies. We develop a
novel adversarial defense framework inspired by the adaptive immune system: the
Robust Adversarial Immune-inspired Learning System (RAILS). Initializing a
population of exemplars that is balanced across classes, RAILS starts from a
uniform label distribution that encourages diversity and debiases a potentially
corrupted initial condition. RAILS implements an evolutionary optimization
process to adjust the label distribution and achieve specificity towards ground
truth. RAILS displays a tradeoff between robustness (diversity) and accuracy
(specificity), providing a new immune-inspired perspective on adversarial
learning. We empirically validate the benefits of RAILS through several
adversarial image classification experiments on MNIST, SVHN, and CIFAR-10
datasets. For the PGD attack, RAILS is found to improve the robustness over
existing methods by &gt;&#x3D; 5.62%, 12.5% and 10.32%, respectively, without
appreciable loss of standard accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nested Counterfactual Identification from Arbitrary Surrogate Experiments. (arXiv:2107.03190v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Correa_J/0/1/0/all/0/1">Juan D Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sanghack Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Bareinboim_E/0/1/0/all/0/1">Elias Bareinboim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03190">
                                    <div class="article-summary-box-inner">
                                        <span>The Ladder of Causation describes three qualitatively different types of
activities an agent may be interested in engaging in, namely, seeing
(observational), doing (interventional), and imagining (counterfactual) (Pearl
and Mackenzie, 2018). The inferential challenge imposed by the causal hierarchy
is that data is collected by an agent observing or intervening in a system
(layers 1 and 2), while its goal may be to understand what would have happened
had it taken a different course of action, contrary to what factually ended up
happening (layer 3). While there exists a solid understanding of the conditions
under which cross-layer inferences are allowed from observations to
interventions, the results are somewhat scarcer when targeting counterfactual
quantities. In this paper, we study the identification of nested
counterfactuals from an arbitrary combination of observations and experiments.
Specifically, building on a more explicit definition of nested counterfactuals,
we prove the counterfactual unnesting theorem (CUT), which allows one to map
arbitrary nested counterfactuals to unnested ones. For instance, applications
in mediation and fairness analysis usually evoke notions of direct, indirect,
and spurious effects, which naturally require nesting. Second, we introduce a
sufficient and necessary graphical condition for counterfactual identification
from an arbitrary combination of observational and experimental distributions.
Lastly, we develop an efficient and complete algorithm for identifying nested
counterfactuals; failure of the algorithm returning an expression for a query
implies it is not identifiable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Contextual Bandits without Regret. (arXiv:2107.03144v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kassraie_P/0/1/0/all/0/1">Parnian Kassraie</a>, <a href="http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03144">
                                    <div class="article-summary-box-inner">
                                        <span>Contextual bandits are a rich model for sequential decision making given side
information, with important applications, e.g., in recommender systems. We
propose novel algorithms for contextual bandits harnessing neural networks to
approximate the unknown reward function. We resolve the open problem of proving
sublinear regret bounds in this setting for general context sequences,
considering both fully-connected and convolutional networks. To this end, we
first analyze NTK-UCB, a kernelized bandit optimization algorithm employing the
Neural Tangent Kernel (NTK), and bound its regret in terms of the NTK maximum
information gain $\gamma_T$, a complexity parameter capturing the difficulty of
learning. Our bounds on $\gamma_T$ for the NTK may be of independent interest.
We then introduce our neural network based algorithm NN-UCB, and show that its
regret closely tracks that of NTK-UCB. Under broad non-parametric assumptions
about the reward function, our approach converges to the optimal policy at a
$\tilde{\mathcal{O}}(T^{-1/2d})$ rate, where $d$ is the dimension of the
context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias-Tolerant Fair Classification. (arXiv:2107.03207v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhidong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03207">
                                    <div class="article-summary-box-inner">
                                        <span>The label bias and selection bias are acknowledged as two reasons in data
that will hinder the fairness of machine-learning outcomes. The label bias
occurs when the labeling decision is disturbed by sensitive features, while the
selection bias occurs when subjective bias exists during the data sampling.
Even worse, models trained on such data can inherit or even intensify the
discrimination. Most algorithmic fairness approaches perform an empirical risk
minimization with predefined fairness constraints, which tends to trade-off
accuracy for fairness. However, such methods would achieve the desired fairness
level with the sacrifice of the benefits (receive positive outcomes) for
individuals affected by the bias. Therefore, we propose a
Bias-TolerantFAirRegularizedLoss (B-FARL), which tries to regain the benefits
using data affected by label bias and selection bias. B-FARL takes the biased
data as input, calls a model that approximates the one trained with fair but
latent data, and thus prevents discrimination without constraints required. In
addition, we show the effective components by decomposing B-FARL, and we
utilize the meta-learning framework for the B-FARL optimization. The
experimental results on real-world datasets show that our method is empirically
effective in improving fairness towards the direction of true but latent
labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Particle Convolution for High Energy Physics. (arXiv:2107.02908v1 [hep-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ph/1/au:+Shimmin_C/0/1/0/all/0/1">Chase Shimmin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02908">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the Particle Convolution Network (PCN), a new type of
equivariant neural network layer suitable for many tasks in jet physics. The
particle convolution layer can be viewed as an extension of Deep Sets and
Energy Flow network architectures, in which the permutation-invariant operator
is promoted to a group convolution. While the PCN can be implemented for
various kinds of symmetries, we consider the specific case of rotation about
the jet axis the $\eta - \phi$ plane. In two standard benchmark tasks, q/g
tagging and top tagging, we show that the rotational PCN (rPCN) achieves
performance comparable to graph networks such as ParticleNet. Moreover, we show
that it is possible to implement an IRC-safe rPCN, which significantly
outperforms existing IRC-safe tagging methods on both tasks. We speculate that
by generalizing the PCN to include additional convolutional symmetries relevant
to jet physics, it may outperform the current state-of-the-art set by graph
networks, while offering a new degree of control over physically-motivated
inductive biases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Immuno-mimetic Deep Neural Networks (Immuno-Net). (arXiv:2107.02842v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindsly_S/0/1/0/all/0/1">Stephen Lindsly</a>, <a href="http://arxiv.org/find/cs/1/au:+Stansbury_C/0/1/0/all/0/1">Cooper Stansbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajapakse_I/0/1/0/all/0/1">Indika Rajapakse</a>, <a href="http://arxiv.org/find/cs/1/au:+Hero_A/0/1/0/all/0/1">Alfred Hero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02842">
                                    <div class="article-summary-box-inner">
                                        <span>Biomimetics has played a key role in the evolution of artificial neural
networks. Thus far, in silico metaphors have been dominated by concepts from
neuroscience and cognitive psychology. In this paper we introduce a different
type of biomimetic model, one that borrows concepts from the immune system, for
designing robust deep neural networks. This immuno-mimetic model leads to a new
computational biology framework for robustification of deep neural networks
against adversarial attacks. Within this Immuno-Net framework we define a
robust adaptive immune-inspired learning system (Immuno-Net RAILS) that
emulates, in silico, the adaptive biological mechanisms of B-cells that are
used to defend a mammalian host against pathogenic attacks. When applied to
image classification tasks on benchmark datasets, we demonstrate that
Immuno-net RAILS results in improvement of as much as 12.5% in adversarial
accuracy of a baseline method, the DkNN-robustified CNN, without appreciable
loss of accuracy on clean data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principles for Evaluation of AI/ML Model Performance and Robustness. (arXiv:2107.02868v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brown_O/0/1/0/all/0/1">Olivia Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Curtis_A/0/1/0/all/0/1">Andrew Curtis</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodwin_J/0/1/0/all/0/1">Justin Goodwin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02868">
                                    <div class="article-summary-box-inner">
                                        <span>The Department of Defense (DoD) has significantly increased its investment in
the design, evaluation, and deployment of Artificial Intelligence and Machine
Learning (AI/ML) capabilities to address national security needs. While there
are numerous AI/ML successes in the academic and commercial sectors, many of
these systems have also been shown to be brittle and nonrobust. In a complex
and ever-changing national security environment, it is vital that the DoD
establish a sound and methodical process to evaluate the performance and
robustness of AI/ML models before these new capabilities are deployed to the
field. This paper reviews the AI/ML development process, highlights common best
practices for AI/ML model evaluation, and makes recommendations to DoD
evaluators to ensure the deployment of robust AI/ML capabilities for national
security needs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed adaptive algorithm based on the asymmetric cost of error functions. (arXiv:2107.03067v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1">Sihai Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1">Qing Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yong Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03067">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a family of novel diffusion adaptive estimation algorithm is
proposed from the asymmetric cost function perspective by combining diffusion
strategy and the linear-linear cost (LLC), quadratic-quadratic cost (QQC), and
linear-exponential cost (LEC), at all distributed network nodes, and named
diffusion LLCLMS (DLLCLMS), diffusion QQCLMS (DQQCLMS), and diffusion LECLMS
(DLECLMS), respectively. Then the stability of mean estimation error and
computational complexity of those three diffusion algorithms are analyzed
theoretically. Finally, several experiment simulation results are designed to
verify the superiority of those three proposed diffusion algorithms.
Experimental simulation results show that DLLCLMS, DQQCLMS, and DLECLMS
algorithms are more robust to the input signal and impulsive noise than the
DSELMS, DRVSSLMS, and DLLAD algorithms. In brief, theoretical analysis and
experiment results show that those proposed DLLCLMS, DQQCLMS, and DLECLMS
algorithms have superior performance when estimating the unknown linear system
under the changeable impulsive noise environments and different types of input
signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Teacher Forcing Network for Semi-Supervised Large Scale Data Streams. (arXiv:2107.02943v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pratama_M/0/1/0/all/0/1">Mahardhika Pratama</a>, <a href="http://arxiv.org/find/cs/1/au:+Zain_C/0/1/0/all/0/1">Choiru Za&#x27;in</a>, <a href="http://arxiv.org/find/cs/1/au:+Lughofer_E/0/1/0/all/0/1">Edwin Lughofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pardede_E/0/1/0/all/0/1">Eric Pardede</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahayu_D/0/1/0/all/0/1">Dwi A. P. Rahayu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02943">
                                    <div class="article-summary-box-inner">
                                        <span>The large-scale data stream problem refers to high-speed information flow
which cannot be processed in scalable manner under a traditional computing
platform. This problem also imposes expensive labelling cost making the
deployment of fully supervised algorithms unfeasible. On the other hand, the
problem of semi-supervised large-scale data streams is little explored in the
literature because most works are designed in the traditional single-node
computing environments while also being fully supervised approaches. This paper
offers Weakly Supervised Scalable Teacher Forcing Network (WeScatterNet) to
cope with the scarcity of labelled samples and the large-scale data streams
simultaneously. WeScatterNet is crafted under distributed computing platform of
Apache Spark with a data-free model fusion strategy for model compression after
parallel computing stage. It features an open network structure to address the
global and local drift problems while integrating a data augmentation,
annotation and auto-correction ($DA^3$) method for handling partially labelled
data streams. The performance of WeScatterNet is numerically evaluated in the
six large-scale data stream problems with only $25\%$ label proportions. It
shows highly competitive performance even if compared with fully supervised
learners with $100\%$ label proportions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1">Danny Tarlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-Level Poisoning Attack Model and Countermeasure for Appliance Consumption Data of Smart Homes. (arXiv:2107.02897v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Billah_M/0/1/0/all/0/1">Mustain Billah</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1">Adnan Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_Z/0/1/0/all/0/1">Ziaur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Galib_S/0/1/0/all/0/1">Syed Md. Galib</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02897">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate building energy prediction is useful in various applications
starting from building energy automation and management to optimal storage
control. However, vulnerabilities should be considered when designing building
energy prediction models, as intelligent attackers can deliberately influence
the model performance using sophisticated attack models. These may consequently
degrade the prediction accuracy, which may affect the efficiency and
performance of the building energy management systems. In this paper, we
investigate the impact of bi-level poisoning attacks on regression models of
energy usage obtained from household appliances. Furthermore, an effective
countermeasure against the poisoning attacks on the prediction model is
proposed in this paper. Attacks and defenses are evaluated on a benchmark
dataset. Experimental results show that an intelligent cyber-attacker can
poison the prediction model to manipulate the decision. However, our proposed
solution successfully ensures defense against such poisoning attacks
effectively compared to other benchmark techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Embedding of Structural and Functional Brain Networks with Graph Neural Networks for Mental Illness Diagnosis. (arXiv:2107.03220v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_Y/0/1/0/all/0/1">Yanqiao Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/q-bio/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03220">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal brain networks characterize complex connectivities among different
brain regions from both structural and functional aspects and provide a new
means for mental disease analysis. Recently, Graph Neural Networks (GNNs) have
become a de facto model for analyzing graph-structured data. However, how to
employ GNNs to extract effective representations from brain networks in
multiple modalities remains rarely explored. Moreover, as brain networks
provide no initial node features, how to design informative node attributes and
leverage edge weights for GNNs to learn is left unsolved. To this end, we
develop a novel multiview GNN for multimodal brain networks. In particular, we
regard each modality as a view for brain networks and employ contrastive
learning for multimodal fusion. Then, we propose a GNN model which takes
advantage of the message passing scheme by propagating messages based on degree
statistics and brain region connectivities. Extensive experiments on two
real-world disease datasets (HIV and Bipolar) demonstrate the effectiveness of
our proposed method over state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Immunization of Pruning Attack in DNN Watermarking Using Constant Weight Code. (arXiv:2107.02961v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuribayashi_M/0/1/0/all/0/1">Minoru Kuribayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasui_T/0/1/0/all/0/1">Tatsuya Yasui</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_A/0/1/0/all/0/1">Asad Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Funabiki_N/0/1/0/all/0/1">Nobuo Funabiki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02961">
                                    <div class="article-summary-box-inner">
                                        <span>To ensure protection of the intellectual property rights of DNN models,
watermarking techniques have been investigated to insert side-information into
the models without seriously degrading the performance of original task. One of
the threats for the DNN watermarking is the pruning attack such that less
important neurons in the model are pruned to make it faster and more compact as
well as to remove the watermark. In this study, we investigate a channel coding
approach to resist the pruning attack. As the channel model is completely
different from conventional models like digital images, it has been an open
problem what kind of encoding method is suitable for DNN watermarking. A novel
encoding approach by using constant weight codes to immunize the effects of
pruning attacks is presented. To the best of our knowledge, this is the first
study that introduces an encoding technique for DNN watermarking to make it
robust against pruning attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the progress of Deep Reinforcement Learning in the real world: aligning domain-agnostic and domain-specific research. (arXiv:2107.03015v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garau_Luis_J/0/1/0/all/0/1">Juan Jose Garau-Luis</a>, <a href="http://arxiv.org/find/cs/1/au:+Crawley_E/0/1/0/all/0/1">Edward Crawley</a>, <a href="http://arxiv.org/find/cs/1/au:+Cameron_B/0/1/0/all/0/1">Bruce Cameron</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03015">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Reinforcement Learning (DRL) is considered a potential framework to
improve many real-world autonomous systems; it has attracted the attention of
multiple and diverse fields. Nevertheless, the successful deployment in the
real world is a test most of DRL models still need to pass. In this work we
focus on this issue by reviewing and evaluating the research efforts from both
domain-agnostic and domain-specific communities. On one hand, we offer a
comprehensive summary of DRL challenges and summarize the different proposals
to mitigate them; this helps identifying five gaps of domain-agnostic research.
On the other hand, from the domain-specific perspective, we discuss different
success stories and argue why other models might fail to be deployed. Finally,
we take up on ways to move forward accounting for both perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Zero to The Hero: A Collaborative Market Aware Recommendation System for Crowd Workers. (arXiv:2107.02890v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shamszare_H/0/1/0/all/0/1">Hamid Shamszare</a>, <a href="http://arxiv.org/find/cs/1/au:+Saremi_R/0/1/0/all/0/1">Razieh Saremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jena_S/0/1/0/all/0/1">Sanam Jena</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02890">
                                    <div class="article-summary-box-inner">
                                        <span>The success of software crowdsourcing depends on active and trustworthy pool
of worker supply. The uncertainty of crowd workers&#x27; behaviors makes it
challenging to predict workers&#x27; success and plan accordingly. In a competitive
crowdsourcing marketplace, competition for success over shared tasks adds
another layer of uncertainty in crowd workers&#x27; decision-making process.
Preliminary analysis on software worker behaviors reveals an alarming task
dropping rate of 82.9%. These factors lead to the need for an automated
recommendation system for CSD workers to improve the visibility and
predictability of their success in the competition. To that end, this paper
proposes a collaborative recommendation system for crowd workers. The proposed
recommendation system method uses five input metrics based on workers&#x27;
collaboration history in the pool, workers&#x27; preferences in taking tasks in
terms of monetary prize and duration, workers&#x27; specialty, and workers&#x27;
proficiency. The proposed method then recommends the most suitable tasks for a
worker to compete on based on workers&#x27; probability of success in the task.
Experimental results on 260 active crowd workers demonstrate that just
following the top three success probabilities of task recommendations, workers
can achieve success up to 86%</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logit-based Uncertainty Measure in Classification. (arXiv:2107.02845v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huiyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1">Diego Klabjan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02845">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new, reliable, and agnostic uncertainty measure for
classification tasks called logit uncertainty. It is based on logit outputs of
neural networks. We in particular show that this new uncertainty measure yields
a superior performance compared to existing uncertainty measures on different
tasks, including out of sample detection and finding erroneous predictions. We
analyze theoretical foundations of the measure and explore a relationship with
high density regions. We also demonstrate how to test uncertainty using
intermediate outputs in training of generative adversarial networks. We propose
two potential ways to utilize logit-based uncertainty in real world
applications, and show that the uncertainty measure outperforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exact Learning Augmented Naive Bayes Classifier. (arXiv:2107.03018v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sugahara_S/0/1/0/all/0/1">Shouta Sugahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueno_M/0/1/0/all/0/1">Maomi Ueno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03018">
                                    <div class="article-summary-box-inner">
                                        <span>Earlier studies have shown that classification accuracies of Bayesian
networks (BNs) obtained by maximizing the conditional log likelihood (CLL) of a
class variable, given the feature variables, were higher than those obtained by
maximizing the marginal likelihood (ML). However, differences between the
performances of the two scores in the earlier studies may be attributed to the
fact that they used approximate learning algorithms, not exact ones. This paper
compares the classification accuracies of BNs with approximate learning using
CLL to those with exact learning using ML. The results demonstrate that the
classification accuracies of BNs obtained by maximizing the ML are higher than
those obtained by maximizing the CLL for large data. However, the results also
demonstrate that the classification accuracies of exact learning BNs using the
ML are much worse than those of other methods when the sample size is small and
the class variable has numerous parents. To resolve the problem, we propose an
exact learning augmented naive Bayes classifier (ANB), which ensures a class
variable with no parents. The proposed method is guaranteed to asymptotically
estimate the identical class posterior to that of the exactly learned BN.
Comparison experiments demonstrated the superior performance of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning. (arXiv:2105.12085v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Mingde Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zichao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yifeng Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range and short-range temporal modeling are two complementary and
crucial aspects of video recognition. Most of the state-of-the-arts focus on
short-range spatio-temporal modeling and then average multiple snippet-level
predictions to yield the final video-level prediction. Thus, their video-level
prediction does not consider spatio-temporal features of how video evolves
along the temporal dimension. In this paper, we introduce a novel Dynamic
Segment Aggregation (DSA) module to capture relationship among snippets. To be
more specific, we attempt to generate a dynamic kernel for a convolutional
operation to aggregate long-range temporal information among adjacent snippets
adaptively. The DSA module is an efficient plug-and-play module and can be
combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform
powerful long-range modeling with minimal overhead. The final video
architecture, coined as DSANet. We conduct extensive experiments on several
video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400,
Something-Something V1 and ActivityNet) to show its superiority. Our proposed
DSA module is shown to benefit various video recognition models significantly.
For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is
improved from 74.9% to 78.2% on Kinetics-400. Codes are available at
https://github.com/whwu95/DSANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis. (arXiv:2107.03298v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hui Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xixin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">Shiyin Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xunying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03298">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a variational auto-encoder based non-autoregressive
text-to-speech (VAENAR-TTS) model. The autoregressive TTS (AR-TTS) models based
on the sequence-to-sequence architecture can generate high-quality speech, but
their sequential decoding process can be time-consuming. Recently,
non-autoregressive TTS (NAR-TTS) models have been shown to be more efficient
with the parallel decoding process. However, these NAR-TTS models rely on
phoneme-level durations to generate a hard alignment between the text and the
spectrogram. Obtaining duration labels, either through forced alignment or
knowledge distillation, is cumbersome. Furthermore, hard alignment based on
phoneme expansion can degrade the naturalness of the synthesized speech. In
contrast, the proposed model of VAENAR-TTS is an end-to-end approach that does
not require phoneme-level durations. The VAENAR-TTS model does not contain
recurrent structures and is completely non-autoregressive in both the training
and inference phases. Based on the VAE architecture, the alignment information
is encoded in the latent variable, and attention-based soft alignment between
the text and the latent variable is used in the decoder to reconstruct the
spectrogram. Experiments show that VAENAR-TTS achieves state-of-the-art
synthesis quality, while the synthesis speed is comparable with other NAR-TTS
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-View Exocentric to Egocentric Video Synthesis. (arXiv:2107.03120v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gaowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1">Hugo Latapie</a>, <a href="http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1">Jason Corso</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yan Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03120">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-view video synthesis task seeks to generate video sequences of one view
from another dramatically different view. In this paper, we investigate the
exocentric (third-person) view to egocentric (first-person) view video
generation task. This is challenging because egocentric view sometimes is
remarkably different from the exocentric view. Thus, transforming the
appearances across the two different views is a non-trivial task. Particularly,
we propose a novel Bi-directional Spatial Temporal Attention Fusion Generative
Adversarial Network (STA-GAN) to learn both spatial and temporal information to
generate egocentric video sequences from the exocentric view. The proposed
STA-GAN consists of three parts: temporal branch, spatial branch, and attention
fusion. First, the temporal and spatial branches generate a sequence of fake
frames and their corresponding features. The fake frames are generated in both
downstream and upstream directions for both temporal and spatial branches.
Next, the generated four different fake frames and their corresponding features
(spatial and temporal branches in two directions) are fed into a novel
multi-generation attention fusion module to produce the final video sequence.
Meanwhile, we also propose a novel temporal and spatial dual-discriminator for
more robust network optimization. Extensive experiments on the Side2Ego and
Top2Ego datasets show that the proposed STA-GAN significantly outperforms the
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeClick: Weakly-Supervised Video Semantic Segmentation with Click Annotations. (arXiv:2107.03088v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peidong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zibin He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiyu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shutao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Maowei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03088">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with tedious per-pixel mask annotating, it is much easier to
annotate data by clicks, which costs only several seconds for an image.
However, applying clicks to learn video semantic segmentation model has not
been explored before. In this work, we propose an effective weakly-supervised
video semantic segmentation pipeline with click annotations, called WeClick,
for saving laborious annotating effort by segmenting an instance of the
semantic class with only a single click. Since detailed semantic information is
not captured by clicks, directly training with click labels leads to poor
segmentation predictions. To mitigate this problem, we design a novel memory
flow knowledge distillation strategy to exploit temporal information (named
memory flow) in abundant unlabeled video frames, by distilling the neighboring
predictions to the target frame via estimated motion. Moreover, we adopt
vanilla knowledge distillation for model compression. In this case, WeClick
learns compact video semantic segmentation models with the low-cost click
annotations during the training phase yet achieves real-time and accurate
models during the inference period. Experimental results on Cityscapes and
Camvid show that WeClick outperforms the state-of-the-art methods, increases
performance by 10.24% mIoU than baseline, and achieves real-time execution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-07">2021-07-07</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning. (arXiv:2107.02759v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Escobar_Grisales_D/0/1/0/all/0/1">Daniel Escobar-Grisales</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasquez_Correa_J/0/1/0/all/0/1">Juan Camilo Vasquez-Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Orozco_Arroyave_J/0/1/0/all/0/1">Juan Rafael Orozco-Arroyave</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02759">
                                    <div class="article-summary-box-inner">
                                        <span>The interest in demographic information retrieval based on text data has
increased in the research community because applications have shown success in
different sectors such as security, marketing, heath-care, and others.
Recognition and identification of demographic traits such as gender, age,
location, or personality based on text data can help to improve different
marketing strategies. For instance it makes it possible to segment and to
personalize offers, thus products and services are exposed to the group of
greatest interest. This type of technology has been discussed widely in
documents from social media. However, the methods have been poorly studied in
data with a more formal structure, where there is no access to emoticons,
mentions, and other linguistic phenomena that are only present in social media.
This paper proposes the use of recurrent and convolutional neural networks, and
a transfer learning strategy for gender recognition in documents that are
written in informal and formal languages. Models are tested in two different
databases consisting of Tweets and call-center conversations. Accuracies of up
to 75\% are achieved for both databases. The results also indicate that it is
possible to transfer the knowledge from a system trained on a specific type of
expressions or idioms such as those typically used in social media into a more
formal type of text data, where the amount of data is more scarce and its
structure is completely different.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An NLG pipeline for a legal expert system: a work in progress. (arXiv:2107.02421v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Listenmaa_I/0/1/0/all/0/1">Inari Listenmaa</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_J/0/1/0/all/0/1">Jason Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_A/0/1/0/all/0/1">Alfred Ang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanafiah_M/0/1/0/all/0/1">Maryam Hanafiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheong_R/0/1/0/all/0/1">Regina Cheong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02421">
                                    <div class="article-summary-box-inner">
                                        <span>We present the NLG component for L4, a prototype domain-specific language
(DSL) for drafting laws and contracts. As a concrete use case, we describe a
pipeline for a legal expert system created from L4 code. The NLG component is
used in two steps. The first step is to create an interview, whose answers are
processed into a query for an automated reasoner. The second step is to render
the answers of the reasoner in natural language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Graph Reasoning for Natural Proof Generation. (arXiv:2107.02418v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changzhi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiangjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chun Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuanbin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaze Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02418">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the problem of reasoning over natural language
statements. Prior neural based approaches do not explicitly consider the
inter-dependency among answers and their proofs. In this paper, we propose
PRobr, a novel approach for joint answer prediction and proof generation. PRobr
defines a joint probabilistic distribution over all possible proof graphs and
answers via an induced graphical model. We then optimize the model using
variational approximation on top of neural textual representation. Experiments
on multiple datasets under diverse settings (fully supervised, few-shot and
zero-shot evaluation) verify the effectiveness of PRobr, e.g., achieving
10%-30% improvement on QA accuracy in few/zero-shot evaluation. Our codes and
models can be found at https://github.com/changzhisun/PRobr/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Named Entity Tagging with Learnable Logical Rules. (arXiv:2107.02282v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiacheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Haibo Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1">Jingbo Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhe Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02282">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of building entity tagging systems by using a few rules
as weak supervision. Previous methods mostly focus on disambiguation entity
types based on contexts and expert-provided rules, while assuming entity spans
are given. In this work, we propose a novel method TALLOR that bootstraps
high-quality logical rules to train a neural tagger in a fully automated
manner. Specifically, we introduce compound rules that are composed from simple
rules to increase the precision of boundary detection and generate more diverse
pseudo labels. We further design a dynamic label selection strategy to ensure
pseudo label quality and therefore avoid overfitting the neural tagger.
Experiments on three datasets demonstrate that our method outperforms other
weakly supervised methods and even rivals a state-of-the-art distantly
supervised tagger with a lexicon of over 2,000 terms when starting from only 20
simple rules. Our method can serve as a tool for rapidly building taggers in
emerging domains and tasks. Case studies show that learned rules can
potentially explain the predicted entities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset. (arXiv:2104.08671v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lucia Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_N/0/1/0/all/0/1">Neel Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1">Brandon R. Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Peter Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1">Daniel E. Ho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08671">
                                    <div class="article-summary-box-inner">
                                        <span>While self-supervised learning has made rapid advances in natural language
processing, it remains unclear when researchers should engage in
resource-intensive domain-specific pretraining (domain pretraining). The law,
puzzlingly, has yielded few documented instances of substantial gains to domain
pretraining in spite of the fact that legal language is widely seen to be
unique. We hypothesize that these existing results stem from the fact that
existing legal NLP tasks are too easy and fail to meet conditions for when
domain pretraining can help. To address this, we first present CaseHOLD (Case
Holdings On Legal Decisions), a new dataset comprised of over 53,000+ multiple
choice questions to identify the relevant holding of a cited case. This dataset
presents a fundamental task to lawyers and is both legally meaningful and
difficult from an NLP perspective (F1 of 0.4 with a BiLSTM baseline). Second,
we assess performance gains on CaseHOLD and existing legal NLP datasets. While
a Transformer architecture (BERT) pretrained on a general corpus (Google Books
and Wikipedia) improves performance, domain pretraining (using corpus of
approximately 3.5M decisions across all courts in the U.S. that is larger than
BERT&#x27;s) with a custom legal vocabulary exhibits the most substantial
performance gains with CaseHOLD (gain of 7.2% on F1, representing a 12%
improvement on BERT) and consistent performance gains across two other legal
tasks. Third, we show that domain pretraining may be warranted when the task
exhibits sufficient similarity to the pretraining corpus: the level of
performance increase in three legal tasks was directly tied to the domain
specificity of the task. Our findings inform when researchers should engage
resource-intensive pretraining and show that Transformer-based architectures,
too, learn embeddings suggestive of distinct legal language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Talk to Action with Accountability: Monitoring the Public Discussion of Policy Makers with Deep Neural Networks and Topic Modelling. (arXiv:2010.08346v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hatonen_V/0/1/0/all/0/1">Vili H&#xe4;t&#xf6;nen</a>, <a href="http://arxiv.org/find/cs/1/au:+Melzer_F/0/1/0/all/0/1">Fiona Melzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08346">
                                    <div class="article-summary-box-inner">
                                        <span>Decades of research on climate have provided a consensus that human activity
has changed the climate and we are currently heading into a climate crisis.
While public discussion and research efforts on climate change mitigation have
increased, potential solutions need to not only be discussed but also
effectively deployed. For preventing mismanagement and holding policy makers
accountable, transparency and degree of information about government processes
have been shown to be crucial. However, currently the quantity of information
about climate change discussions and the range of sources make it increasingly
difficult for the public and civil society to maintain an overview to hold
politicians accountable.

In response, we propose a multi-source topic aggregation system (MuSTAS)
which processes policy makers speech and rhetoric from several publicly
available sources into an easily digestible topic summary. MuSTAS uses novel
multi-source hybrid latent Dirichlet allocation to model topics from a variety
of documents. This topic digest will serve the general public and civil society
in assessing where, how, and when politicians talk about climate and climate
policies, enabling them to hold politicians accountable for their actions to
mitigate climate change and lack thereof.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">David Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1">Adam Santoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1">Matt Botvinick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Schema-based Event Extraction: Literature Review and Current Trends. (arXiv:2107.02126v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hei_Y/0/1/0/all/0/1">Yiming Hei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Rui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_J/0/1/0/all/0/1">Jiawei Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lihong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02126">
                                    <div class="article-summary-box-inner">
                                        <span>Schema-based event extraction is a critical technique to apprehend the
essential content of events promptly. With the rapid development of deep
learning technology, event extraction technology based on deep learning has
become a research hotspot. Numerous methods, datasets, and evaluation metrics
have been proposed in the literature, raising the need for a comprehensive and
updated survey. This paper fills the gap by reviewing the state-of-the-art
approaches, focusing on deep learning-based models. We summarize the task
definition, paradigm, and models of schema-based event extraction and then
discuss each of these in detail. We introduce benchmark datasets that support
tests of predictions and evaluation metrics. A comprehensive comparison between
different techniques is also provided in this survey. Finally, we conclude by
summarizing future research directions facing the research area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ETHOS: an Online Hate Speech Detection Dataset. (arXiv:2006.08328v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mollas_I/0/1/0/all/0/1">Ioannis Mollas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysopoulou_Z/0/1/0/all/0/1">Zoe Chrysopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlos_S/0/1/0/all/0/1">Stamatis Karlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08328">
                                    <div class="article-summary-box-inner">
                                        <span>Online hate speech is a recent problem in our society that is rising at a
steady pace by leveraging the vulnerabilities of the corresponding regimes that
characterise most social media platforms. This phenomenon is primarily fostered
by offensive comments, either during user interaction or in the form of a
posted multimedia context. Nowadays, giant corporations own platforms where
millions of users log in every day, and protection from exposure to similar
phenomena appears to be necessary in order to comply with the corresponding
legislation and maintain a high level of service quality. A robust and reliable
system for detecting and preventing the uploading of relevant content will have
a significant impact on our digitally interconnected society. Several aspects
of our daily lives are undeniably linked to our social profiles, making us
vulnerable to abusive behaviours. As a result, the lack of accurate hate speech
detection mechanisms would severely degrade the overall user experience,
although its erroneous operation would pose many ethical concerns. In this
paper, we present &#x27;ETHOS&#x27;, a textual dataset with two variants: binary and
multi-label, based on YouTube and Reddit comments validated using the
Figure-Eight crowdsourcing platform. Furthermore, we present the annotation
protocol used to create this dataset: an active sampling procedure for
balancing our data in relation to the various aspects defined. Our key
assumption is that, even gaining a small amount of labelled data from such a
time-consuming process, we can guarantee hate speech occurrences in the
examined material.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Ted Pedersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. &#x27;the NCG
task&#x27;) tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article&#x27;s contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.

Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order in the Court: Explainable AI Methods Prone to Disagreement. (arXiv:2105.03287v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neely_M/0/1/0/all/0/1">Michael Neely</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_S/0/1/0/all/0/1">Stefan F. Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1">Maurits J. R. Bleeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03287">
                                    <div class="article-summary-box-inner">
                                        <span>By computing the rank correlation between attention weights and
feature-additive explanation methods, previous analyses either invalidate or
support the role of attention-based explanations as a faithful and plausible
measure of salience. To investigate whether this approach is appropriate, we
compare LIME, Integrated Gradients, DeepLIFT, Grad-SHAP, Deep-SHAP, and
attention-based explanations, applied to two neural architectures trained on
single- and pair-sequence language tasks. In most cases, we find that none of
our chosen methods agree. Based on our empirical observations and theoretical
objections, we conclude that rank correlation does not measure the quality of
feature-additive methods. Practitioners should instead use the numerous and
rigorous diagnostic methods proposed by the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer. (arXiv:2107.02681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zineng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02681">
                                    <div class="article-summary-box-inner">
                                        <span>Since visual perception can give rich information beyond text descriptions
for world understanding, there has been increasing interest in leveraging
visual grounding for language learning. Recently, vokenization has attracted
attention by using the predictions of a text-to-image retrieval model as labels
for language model supervision. Despite its success, the method suffers from
approximation error of using finite image labels and the lack of vocabulary
diversity of a small image-text dataset. To overcome these limitations, we
present VidLanKD, a video-language knowledge distillation method for improving
language understanding. We train a multi-modal teacher model on a video-text
dataset, and then transfer its knowledge to a student language model with a
text dataset. To avoid approximation error, we propose to use different
knowledge distillation objectives. In addition, the use of a large-scale
video-text dataset helps learn diverse and richer vocabularies. In our
experiments, VidLanKD achieves consistent improvements over text-only language
models and vokenization models, on several downstream language understanding
tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world
knowledge, physical reasoning, and temporal reasoning capabilities of our model
by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we
present comprehensive ablation studies as well as visualizations of the learned
text-to-video grounding results of our teacher and student language models. Our
code and models are available at: https://github.com/zinengtang/VidLanKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style. (arXiv:2107.02530v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yuzi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02530">
                                    <div class="article-summary-box-inner">
                                        <span>While recent text to speech (TTS) models perform very well in synthesizing
reading-style (e.g., audiobook) speech, it is still challenging to synthesize
spontaneous-style speech (e.g., podcast or conversation), mainly because of two
reasons: 1) the lack of training data for spontaneous speech; 2) the difficulty
in modeling the filled pauses (um and uh) and diverse rhythms in spontaneous
speech. In this paper, we develop AdaSpeech 3, an adaptive TTS system that
fine-tunes a well-trained reading-style TTS model for spontaneous-style speech.
Specifically, 1) to insert filled pauses (FP) in the text sequence
appropriately, we introduce an FP predictor to the TTS model; 2) to model the
varying rhythms, we introduce a duration predictor based on mixture of experts
(MoE), which contains three experts responsible for the generation of fast,
medium and slow speech respectively, and fine-tune it as well as the pitch
predictor for rhythm adaptation; 3) to adapt to other speaker timbre, we
fine-tune some parameters in the decoder with few speech data. To address the
challenge of lack of training data, we mine a spontaneous speech dataset to
support our research this work and facilitate future research on spontaneous
TTS. Experiments show that AdaSpeech 3 synthesizes speech with natural FP and
rhythms in spontaneous styles, and achieves much better MOS and SMOS scores
than previous adaptive TTS systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Location, Location: Enhancing the Evaluation of Text-to-Speech Synthesis Using the Rapid Prosody Transcription Paradigm. (arXiv:2107.02527v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gutierrez_E/0/1/0/all/0/1">Elijah Gutierrez</a>, <a href="http://arxiv.org/find/eess/1/au:+Oplustil_Gallegos_P/0/1/0/all/0/1">Pilar Oplustil-Gallegos</a>, <a href="http://arxiv.org/find/eess/1/au:+Lai_C/0/1/0/all/0/1">Catherine Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02527">
                                    <div class="article-summary-box-inner">
                                        <span>Text-to-Speech synthesis systems are generally evaluated using Mean Opinion
Score (MOS) tests, where listeners score samples of synthetic speech on a
Likert scale. A major drawback of MOS tests is that they only offer a general
measure of overall quality-i.e., the naturalness of an utterance-and so cannot
tell us where exactly synthesis errors occur. This can make evaluation of the
appropriateness of prosodic variation within utterances inconclusive. To
address this, we propose a novel evaluation method based on the Rapid Prosody
Transcription paradigm. This allows listeners to mark the locations of errors
in an utterance in real-time, providing a probabilistic representation of the
perceptual errors that occur in the synthetic signal. We conduct experiments
that confirm that the fine-grained evaluation can be mapped to system rankings
of standard MOS tests, but the error marking gives a much more comprehensive
assessment of synthesized prosody. In particular, for standard audiobook test
set samples, we see that error marks consistently cluster around words at major
prosodic boundaries indicated by punctuation. However, for question-answer
based stimuli, where we control information structure, we see differences
emerge in the ability of neural TTS systems to generate context-appropriate
prosodic prominence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning for Improving Results on Russian Sentiment Datasets. (arXiv:2107.02499v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golubev_A/0/1/0/all/0/1">Anton Golubev</a>, <a href="http://arxiv.org/find/cs/1/au:+Loukachevitch_N/0/1/0/all/0/1">Natalia Loukachevitch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02499">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we test transfer learning approach on Russian sentiment
benchmark datasets using additional train sample created with distant
supervision technique. We compare several variants of combining additional data
with benchmark train samples. The best results were achieved using three-step
approach of sequential training on general, thematic and original train
samples. For most datasets, the results were improved by more than 3% to the
current state-of-the-art methods. The BERT-NLI model treating sentiment
classification problem as a natural language inference task reached the human
level of sentiment analysis on one of the datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lexical Access Model for Italian -- Modeling human speech processing: identification of words in running speech toward lexical access based on the detection of landmarks and other acoustic cues to features. (arXiv:2107.02720v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Benedetto_M/0/1/0/all/0/1">Maria-Gabriella Di Benedetto</a>, <a href="http://arxiv.org/find/eess/1/au:+Shattuck_Hufnagel_S/0/1/0/all/0/1">Stefanie Shattuck-Hufnagel</a>, <a href="http://arxiv.org/find/eess/1/au:+Choi_J/0/1/0/all/0/1">Jeung-Yoon Choi</a>, <a href="http://arxiv.org/find/eess/1/au:+Nardis_L/0/1/0/all/0/1">Luca De Nardis</a>, <a href="http://arxiv.org/find/eess/1/au:+Arango_J/0/1/0/all/0/1">Javier Arango</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_I/0/1/0/all/0/1">Ian Chan</a>, <a href="http://arxiv.org/find/eess/1/au:+DeCaprio_A/0/1/0/all/0/1">Alec DeCaprio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02720">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling the process that a listener actuates in deriving the words intended
by a speaker requires setting a hypothesis on how lexical items are stored in
memory. This work aims at developing a system that imitates humans when
identifying words in running speech and, in this way, provide a framework to
better understand human speech processing. We build a speech recognizer for
Italian based on the principles of Stevens&#x27; model of Lexical Access in which
words are stored as hierarchical arrangements of distinctive features (Stevens,
K. N. (2002). &quot;Toward a model for lexical access based on acoustic landmarks
and distinctive features,&quot; J. Acoust. Soc. Am., 111(4):1872-1891). Over the
past few decades, the Speech Communication Group at the Massachusetts Institute
of Technology (MIT) developed a speech recognition system for English based on
this approach. Italian will be the first language beyond English to be
explored; the extension to another language provides the opportunity to test
the hypothesis that words are represented in memory as a set of
hierarchically-arranged distinctive features, and reveal which of the
underlying mechanisms may have a language-independent nature. This paper also
introduces a new Lexical Access corpus, the LaMIT database, created and labeled
specifically for this work, that will be provided freely to the speech research
community. Future developments will test the hypothesis that specific acoustic
discontinuities - called landmarks - that serve as cues to features, are
language independent, while other cues may be language-dependent, with powerful
implications for understanding how the human brain recognizes speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empowering NGOs in Countering Online Hate Messages. (arXiv:2107.02472v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yi-Ling Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Tekiroglu_S/0/1/0/all/0/1">Serra Sinem Tekiroglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonelli_S/0/1/0/all/0/1">Sara Tonelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerini_M/0/1/0/all/0/1">Marco Guerini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02472">
                                    <div class="article-summary-box-inner">
                                        <span>Studies on online hate speech have mostly focused on the automated detection
of harmful messages. Little attention has been devoted so far to the
development of effective strategies to fight hate speech, in particular through
the creation of counter-messages. While existing manual scrutiny and
intervention strategies are time-consuming and not scalable, advances in
natural language processing have the potential to provide a systematic approach
to hatred management. In this paper, we introduce a novel ICT platform that NGO
operators can use to monitor and analyze social media data, along with a
counter-narrative suggestion tool. Our platform aims at increasing the
efficiency and effectiveness of operators&#x27; activities against islamophobia. We
test the platform with more than one hundred NGO operators in three countries
through qualitative and quantitative evaluation. Results show that NGOs favor
the platform solution with the suggestion tool, and that the time required to
produce counter-narratives significantly decreases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network. (arXiv:2107.02757v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhibin Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaojie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenchao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02757">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical topic models such as the gamma belief network (GBN) have
delivered promising results in mining multi-layer document representations and
discovering interpretable topic taxonomies. However, they often assume in the
prior that the topics at each layer are independently drawn from the Dirichlet
distribution, ignoring the dependencies between the topics both at the same
layer and across different layers. To relax this assumption, we propose
sawtooth factorial topic embedding guided GBN, a deep generative model of
documents that captures the dependencies and semantic similarities between the
topics in the embedding space. Specifically, both the words and topics are
represented as embedding vectors of the same dimension. The topic matrix at a
layer is factorized into the product of a factor loading matrix and a topic
embedding matrix, the transpose of which is set as the factor loading matrix of
the layer above. Repeating this particular type of factorization, which shares
components between adjacent layers, leads to a structure referred to as
sawtooth factorization. An auto-encoding variational inference network is
constructed to optimize the model parameter via stochastic gradient descent.
Experiments on big corpora show that our models outperform other neural topic
models on extracting deeper interpretable topics and deriving better document
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning. (arXiv:2107.02794v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1">Maxwell Nye</a>, <a href="http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1">Michael Henry Tessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1">Brenden M. Lake</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02794">
                                    <div class="article-summary-box-inner">
                                        <span>Human reasoning can often be understood as an interplay between two systems:
the intuitive and associative (&quot;System 1&quot;) and the deliberative and logical
(&quot;System 2&quot;). Neural sequence models -- which have been increasingly successful
at performing complex, structured tasks -- exhibit the advantages and failure
modes of System 1: they are fast and learn patterns from data, but are often
inconsistent and incoherent. In this work, we seek a lightweight, training-free
means of improving existing System 1-like sequence models by adding System
2-inspired logical reasoning. We explore several variations on this theme in
which candidate generations from a neural sequence model are examined for
logical consistency by a symbolic reasoning module, which can either accept or
reject the generations. Our approach uses neural inference to mediate between
the neural System 1 and the logical System 2. Results in robust story
generation and grounded instruction-following show that this approach can
increase the coherence and accuracy of neurally-based generations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The NiuTrans End-to-End Speech Translation System \\for IWSLT 2021 Offline Task. (arXiv:2107.02444v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoqian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Laohu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Canan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tong Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jingbo Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02444">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the submission of the NiuTrans end-to-end speech
translation system for the IWSLT 2021 offline task, which translates from the
English audio to German text directly without intermediate transcription. We
use the Transformer-based model architecture and enhance it by Conformer,
relative position encoding, and stacked acoustic and textual encoding. To
augment the training data, the English transcriptions are translated to German
translations. Finally, we employ ensemble decoding to integrate the predictions
from several models trained with the different datasets. Combining these
techniques, we achieve 33.84 BLEU points on the MuST-C En-De test set, which
shows the enormous potential of the end-to-end model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Universal Dependency Parsing with Automated Concatenation of Embeddings. (arXiv:2107.02416v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zixia Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02416">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the system used in submission from SHANGHAITECH team to
the IWPT 2021 Shared Task. Our system is a graph-based parser with the
technique of Automated Concatenation of Embeddings (ACE). Because recent work
found that better word representations can be obtained by concatenating
different types of embeddings, we use ACE to automatically find the better
concatenation of embeddings for the task of enhanced universal dependencies.
According to official results averaged on 17 languages, our system ranks 2nd
over 9 teams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Helps Transformers Recognize Conversational Structure? Importance of Context, Punctuation, and Labels in Dialog Act Recognition. (arXiv:2107.02294v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zelasko_P/0/1/0/all/0/1">Piotr &#x17b;elasko</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappagari_R/0/1/0/all/0/1">Raghavendra Pappagari</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehak_N/0/1/0/all/0/1">Najim Dehak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02294">
                                    <div class="article-summary-box-inner">
                                        <span>Dialog acts can be interpreted as the atomic units of a conversation, more
fine-grained than utterances, characterized by a specific communicative
function. The ability to structure a conversational transcript as a sequence of
dialog acts -- dialog act recognition, including the segmentation -- is
critical for understanding dialog. We apply two pre-trained transformer models,
XLNet and Longformer, to this task in English and achieve strong results on
Switchboard Dialog Act and Meeting Recorder Dialog Act corpora with dialog act
segmentation error rates (DSER) of 8.4% and 14.2%. To understand the key
factors affecting dialog act recognition, we perform a comparative analysis of
models trained under different conditions. We find that the inclusion of a
broader conversational context helps disambiguate many dialog act classes,
especially those infrequent in the training data. The presence of punctuation
in the transcripts has a massive effect on the models&#x27; performance, and a
detailed analysis reveals specific segmentation patterns observed in its
absence. Finally, we find that the label set specificity does not affect dialog
act segmentation performance. These findings have significant practical
implications for spoken language understanding applications that depend heavily
on a good-quality segmentation being available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering. (arXiv:2107.02331v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02331">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning promises to alleviate the massive data needs of supervised
machine learning: it has successfully improved sample efficiency by an order of
magnitude on traditional tasks like topic classification and object
recognition. However, we uncover a striking contrast to this promise: across 5
models and 4 datasets on the task of visual question answering, a wide variety
of active learning approaches fail to outperform random selection. To
understand this discrepancy, we profile 8 active learning methods on a
per-example basis, and identify the problem as collective outliers -- groups of
examples that active learning methods prefer to acquire but models fail to
learn (e.g., questions that ask about text in images or require external
knowledge). Through systematic ablation experiments and qualitative
visualizations, we verify that collective outliers are a general phenomenon
responsible for degrading pool-based active learning. Notably, we show that
active learning sample efficiency increases significantly as the number of
collective outliers in the active learning pool decreases. We conclude with a
discussion and prescriptive recommendations for mitigating the effects of these
outliers in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sarcasm Detection: A Comparative Study. (arXiv:2107.02276v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaghoobian_H/0/1/0/all/0/1">Hamed Yaghoobian</a>, <a href="http://arxiv.org/find/cs/1/au:+Arabnia_H/0/1/0/all/0/1">Hamid R. Arabnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_K/0/1/0/all/0/1">Khaled Rasheed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02276">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcasm detection is the task of identifying irony containing utterances in
sentiment-bearing text. However, the figurative and creative nature of sarcasm
poses a great challenge for affective computing systems performing sentiment
analysis. This article compiles and reviews the salient work in the literature
of automatic sarcasm detection. Thus far, three main paradigm shifts have
occurred in the way researchers have approached this task: 1) semi-supervised
pattern extraction to identify implicit sentiment, 2) use of hashtag-based
supervision, and 3) incorporation of context beyond target text. In this
article, we provide a comprehensive review of the datasets, approaches, trends,
and issues in sarcasm and irony detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instant One-Shot Word-Learning for Context-Specific Neural Sequence-to-Sequence Speech Recognition. (arXiv:2107.02268v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1">Christian Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_J/0/1/0/all/0/1">Juan Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuker_S/0/1/0/all/0/1">Sebastian St&#xfc;ker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alexander Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02268">
                                    <div class="article-summary-box-inner">
                                        <span>Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition (ASR). When using appropriate modeling units,
e.g., byte-pair encoded characters, these systems are in principal open
vocabulary systems. In practice, however, they often fail to recognize words
not seen during training, e.g., named entities, numbers or technical terms. To
alleviate this problem we supplement an end-to-end ASR system with a
word/phrase memory and a mechanism to access this memory to recognize the words
and phrases correctly. After the training of the ASR system, and when it has
already been deployed, a relevant word can be added or subtracted instantly
without the need for further training. In this paper we demonstrate that
through this mechanism our system is able to recognize more than 85% of newly
added words that it previously failed to recognize compared to a strong
baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Injecting Knowledge Base Information into End-to-End Joint Entity and Relation Extraction and Coreference Resolution. (arXiv:2107.02286v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verlinden_S/0/1/0/all/0/1">Severine Verlinden</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaporojets_K/0/1/0/all/0/1">Klim Zaporojets</a>, <a href="http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1">Johannes Deleu</a>, <a href="http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1">Thomas Demeester</a>, <a href="http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1">Chris Develder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02286">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a joint information extraction (IE) model, solving named entity
recognition, coreference resolution and relation extraction jointly over the
whole document. In particular, we study how to inject information from a
knowledge base (KB) in such IE model, based on unsupervised entity linking. The
used KB entity representations are learned from either (i) hyperlinked text
documents (Wikipedia), or (ii) a knowledge graph (Wikidata), and appear
complementary in raising IE performance. Representations of corresponding
entity linking (EL) candidates are added to text span representations of the
input document, and we experiment with (i) taking a weighted average of the EL
candidate representations based on their prior (in Wikipedia), and (ii) using
an attention scheme over the EL candidate list. Results demonstrate an increase
of up to 5% F1-score for the evaluated IE tasks on two datasets. Despite a
strong performance of the prior-based model, our quantitative and qualitative
analysis reveals the advantage of using the attention-based approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Experiments with adversarial attacks on text genres. (arXiv:2107.02246v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lepekhin_M/0/1/0/all/0/1">Mikhail Lepekhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharoff_S/0/1/0/all/0/1">Serge Sharoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02246">
                                    <div class="article-summary-box-inner">
                                        <span>Neural models based on pre-trained transformers, such as BERT or XLM-RoBERTa,
demonstrate SOTA results in many NLP tasks, including non-topical
classification, such as genre identification. However, often these approaches
exhibit low reliability to minor alterations of the test texts. A related
probelm concerns topical biases in the training corpus, for example, the
prevalence of words on a specific topic in a specific genre can trick the genre
classifier to recognise any text on this topic in this genre. In order to
mitigate the reliability problem, this paper investigates techniques for
attacking genre classifiers to understand the limitations of the transformer
models and to improve their performance. While simple text attacks, such as
those based on word replacement using keywords extracted by tf-idf, are not
capable of deceiving powerful models like XLM-RoBERTa, we show that
embedding-based algorithms which can replace some of the most &#x60;&#x60;significant&#x27;&#x27;
words with words similar to them, for example, TextFooler, have the ability to
influence model predictions in a significant proportion of cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying negativity factors from social media text corpus using sentiment analysis method. (arXiv:2107.02175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aimal_M/0/1/0/all/0/1">Mohammad Aimal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakhtyar_M/0/1/0/all/0/1">Maheen Bakhtyar</a>, <a href="http://arxiv.org/find/cs/1/au:+Baber_J/0/1/0/all/0/1">Junaid Baber</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakho_S/0/1/0/all/0/1">Sadia Lakho</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammad_U/0/1/0/all/0/1">Umar Mohammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_W/0/1/0/all/0/1">Warda Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Karim_J/0/1/0/all/0/1">Jahanvash Karim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02175">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic sentiment analysis play vital role in decision making. Many
organizations spend a lot of budget to understand their customer satisfaction
by manually going over their feedback/comments or tweets. Automatic sentiment
analysis can give overall picture of the comments received against any event,
product, or activity. Usually, the comments/tweets are classified into two main
classes that are negative or positive. However, the negative comments are too
abstract to understand the basic reason or the context. organizations are
interested to identify the exact reason for the negativity. In this research
study, we hierarchically goes down into negative comments, and link them with
more classes. Tweets are extracted from social media sites such as Twitter and
Facebook. If the sentiment analysis classifies any tweet into negative class,
then we further try to associates that negative comments with more possible
negative classes. Based on expert opinions, the negative comments/tweets are
further classified into 8 classes. Different machine learning algorithms are
evaluated and their accuracy are reported.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Nucleus Recognition Model in Multi-source Images via Pruning. (arXiv:2107.02500v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jiatong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenglu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Can Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Honglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02500">
                                    <div class="article-summary-box-inner">
                                        <span>Ki67 is a significant biomarker in the diagnosis and prognosis of cancer,
whose index can be evaluated by quantifying its expression in Ki67
immunohistochemistry (IHC) stained images. However, quantitative analysis on
multi-source Ki67 images is yet a challenging task in practice due to
cross-domain distribution differences, which result from imaging variation,
staining styles, and lesion types. Many recent studies have made some efforts
on domain generalization (DG), whereas there are still some noteworthy
limitations. Specifically in the case of Ki67 images, learning invariant
representation is at the mercy of the insufficient number of domains and the
cell categories mismatching in different domains. In this paper, we propose a
novel method to improve DG by searching the domain-agnostic subnetwork in a
domain merging scenario. Partial model parameters are iteratively pruned
according to the domain gap, which is caused by the data converting from a
single domain into merged domains during training. In addition, the model is
optimized by fine-tuning on merged domains to eliminate the interference of
class mismatching among various domains. Furthermore, an appropriate
implementation is attained by applying the pruning method to different parts of
the framework. Compared with known DG methods, our method yields excellent
performance in multiclass nucleus recognition of Ki67 IHC images, especially in
the lost category cases. Moreover, our competitive results are also evaluated
on the public dataset over the state-of-the-art DG methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From General to Specific: Online Updating for Blind Super-Resolution. (arXiv:2107.02398v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhengxiong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuwu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02398">
                                    <div class="article-summary-box-inner">
                                        <span>Most deep learning-based super-resolution (SR) methods are not
image-specific: 1) They are exhaustively trained on datasets synthesized by
predefined blur kernels (\eg bicubic), regardless of the domain gap with test
images. 2) Their model weights are fixed during testing, which means that test
images with various degradations are super-resolved by the same set of weights.
However, degradations of real images are various and unknown (\ie blind SR). It
is hard for a single model to perform well in all cases. To address these
issues, we propose an online super-resolution (ONSR) method. It does not rely
on predefined blur kernels and allows the model weights to be updated according
to the degradation of the test image. Specifically, ONSR consists of two
branches, namely internal branch (IB) and external branch (EB). IB could learn
the specific degradation of the given test LR image, and EB could learn to
super resolve images degraded by the learned degradation. In this way, ONSR
could customize a specific model for each test image, and thus could be more
tolerant with various degradations in real applications. Extensive experiments
on both synthesized and real-world images show that ONSR can generate more
visually favorable SR results and achieve state-of-the-art performance in blind
SR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation Alternative Technique: Segmentation Domain Generation. (arXiv:2107.02525v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogoz_A/0/1/0/all/0/1">Ana-Cristina Rogoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Muntean_R/0/1/0/all/0/1">Radu Muntean</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobeli_S/0/1/0/all/0/1">Stefan Cobeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02525">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting objects of interest in images was always a compelling task to
automate. In recent years this task was more and more explored using deep
learning techniques, mostly using region-based convolutional networks. In this
project we propose an alternative semantic segmentation technique making use of
Generative Adversarial Networks. We consider semantic segmentation to be a
domain transfer problem. Thus, we train a feed forward network (FFNN) to
receive as input a seed real image and generate as output its segmentation
mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Circle Kernels into Convolutional Neural Networks. (arXiv:2107.02451v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yixiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hopcroft_J/0/1/0/all/0/1">John E. Hopcroft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02451">
                                    <div class="article-summary-box-inner">
                                        <span>The square kernel is a standard unit for contemporary Convolutional Neural
Networks (CNNs), as it fits well on the tensor computation for the convolution
operation. However, the receptive field in the human visual system is actually
isotropic like a circle. Motivated by this observation, we propose using circle
kernels with isotropic receptive fields for the convolution, and our training
takes approximately equivalent amount of calculation when compared with the
corresponding CNN with square kernels. Our preliminary experiments demonstrate
the rationality of circle kernels. We then propose a kernel boosting strategy
that integrates the circle kernels with square kernels for the training and
inference, and we further let the kernel size/radius be learnable during the
training. Note that we reparameterize the circle kernels or integrated kernels
before the inference, thus taking no extra computation as well as the number of
parameter overhead for the testing. Extensive experiments on several standard
datasets, ImageNet, CIFAR-10 and CIFAR-100, using the circle kernels or
integrated kernels on typical existing CNNs, show that our approach exhibits
highly competitive performance. Specifically, on ImageNet with standard data
augmentation, our approach dramatically boosts the performance of
MobileNetV3-Small by 5.20% top-1 accuracy and 3.39% top-5 accuracy, and boosts
the performance of MobileNetV3-Large by 2.16% top-1 accuracy and 1.18% top-5
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action Localization. (arXiv:2106.14118v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagchi_A/0/1/0/all/0/1">Anurag Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_J/0/1/0/all/0/1">Jazib Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_D/0/1/0/all/0/1">Dolton Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarvadevabhatla_R/0/1/0/all/0/1">Ravi Kiran Sarvadevabhatla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14118">
                                    <div class="article-summary-box-inner">
                                        <span>State of the art architectures for untrimmed video Temporal Action
Localization (TAL) have only considered RGB and Flow modalities, leaving the
information-rich audio modality totally unexploited. Audio fusion has been
explored for the related but arguably easier problem of trimmed (clip-level)
action recognition. However, TAL poses a unique set of challenges. In this
paper, we propose simple but effective fusion-based approaches for TAL. To the
best of our knowledge, our work is the first to jointly consider audio and
video modalities for supervised TAL. We experimentally show that our schemes
consistently improve performance for state of the art video-only TAL
approaches. Specifically, they help achieve new state of the art performance on
large-scale benchmark datasets - ActivityNet-1.3 (54.34 mAP@0.5) and THUMOS14
(57.18 mAP@0.5). Our experiments include ablations involving multiple fusion
schemes, modality combinations and TAL architectures. Our code, models and
associated data will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimizing L1 over L2 norms on the gradient. (arXiv:2101.00809v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wang_C/0/1/0/all/0/1">Chao Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Tao_M/0/1/0/all/0/1">Min Tao</a>, <a href="http://arxiv.org/find/math/1/au:+Chuah_C/0/1/0/all/0/1">Chen-Nee Chuah</a>, <a href="http://arxiv.org/find/math/1/au:+Nagy_J/0/1/0/all/0/1">James Nagy</a>, <a href="http://arxiv.org/find/math/1/au:+Lou_Y/0/1/0/all/0/1">Yifei Lou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00809">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the L1/L2 minimization on the gradient for imaging
applications. Several recent works have demonstrated that L1/L2 is better than
the L1 norm when approximating the L0 norm to promote sparsity. Consequently,
we postulate that applying L1/L2 on the gradient is better than the classic
total variation (the L1 norm on the gradient) to enforce the sparsity of the
image gradient. To verify our hypothesis, we consider a constrained formulation
to reveal empirical evidence on the superiority of L1/L2 over L1 when
recovering piecewise constant signals from low-frequency measurements.
Numerically, we design a specific splitting scheme, under which we can prove
subsequential and global convergence for the alternating direction method of
multipliers (ADMM) under certain conditions. Experimentally, we demonstrate
visible improvements of L1/L2 over L1 and other nonconvex regularizations for
image recovery from low-frequency measurements and two medical applications of
MRI and CT reconstruction. All the numerical results show the efficiency of our
proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Hypo-plastic Left Heart Syndrome in Fetal Ultrasound via Disease-specific Atlas Maps. (arXiv:2107.02643v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Budd_S/0/1/0/all/0/1">Samuel Budd</a>, <a href="http://arxiv.org/find/eess/1/au:+Sinclair_M/0/1/0/all/0/1">Matthew Sinclair</a>, <a href="http://arxiv.org/find/eess/1/au:+Day_T/0/1/0/all/0/1">Thomas Day</a>, <a href="http://arxiv.org/find/eess/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/eess/1/au:+Tan_J/0/1/0/all/0/1">Jeremy Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tianrui Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Matthew_J/0/1/0/all/0/1">Jaqueline Matthew</a>, <a href="http://arxiv.org/find/eess/1/au:+Skelton_E/0/1/0/all/0/1">Emily Skelton</a>, <a href="http://arxiv.org/find/eess/1/au:+Simpson_J/0/1/0/all/0/1">John Simpson</a>, <a href="http://arxiv.org/find/eess/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a>, <a href="http://arxiv.org/find/eess/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Robinson_E/0/1/0/all/0/1">Emma C. Robinson</a>, <a href="http://arxiv.org/find/eess/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02643">
                                    <div class="article-summary-box-inner">
                                        <span>Fetal ultrasound screening during pregnancy plays a vital role in the early
detection of fetal malformations which have potential long-term health impacts.
The level of skill required to diagnose such malformations from live ultrasound
during examination is high and resources for screening are often limited. We
present an interpretable, atlas-learning segmentation method for automatic
diagnosis of Hypo-plastic Left Heart Syndrome (HLHS) from a single &#x60;4 Chamber
Heart&#x27; view image. We propose to extend the recently introduced
Image-and-Spatial Transformer Networks (Atlas-ISTN) into a framework that
enables sensitising atlas generation to disease. In this framework we can
jointly learn image segmentation, registration, atlas construction and disease
prediction while providing a maximum level of clinical interpretability
compared to direct image classification methods. As a result our segmentation
allows diagnoses competitive with expert-derived manual diagnosis and yields an
AUC-ROC of 0.978 (1043 cases for training, 260 for validation and 325 for
testing).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Contrast MRI Super-Resolution via a Multi-Stage Integration Network. (arXiv:2105.08949v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1">Chun-Mei Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_S/0/1/0/all/0/1">Shuhao Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08949">
                                    <div class="article-summary-box-inner">
                                        <span>Super-resolution (SR) plays a crucial role in improving the image quality of
magnetic resonance imaging (MRI). MRI produces multi-contrast images and can
provide a clear display of soft tissues. However, current super-resolution
methods only employ a single contrast, or use a simple multi-contrast fusion
mechanism, ignoring the rich relations among different contrasts, which are
valuable for improving SR. In this work, we propose a multi-stage integration
network (i.e., MINet) for multi-contrast MRI SR, which explicitly models the
dependencies between multi-contrast images at different stages to guide image
SR. In particular, our MINet first learns a hierarchical feature representation
from multiple convolutional stages for each of different-contrast image.
Subsequently, we introduce a multi-stage integration module to mine the
comprehensive relations between the representations of the multi-contrast
images. Specifically, the module matches each representation with all other
features, which are integrated in terms of their similarities to obtain an
enriched representation. Extensive experiments on fastMRI and real-world
clinical datasets demonstrate that 1) our MINet outperforms state-of-the-art
multi-contrast SR methods in terms of various metrics and 2) our multi-stage
integration module is able to excavate complex interactions among
multi-contrast features at different stages, leading to improved target-image
quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Confidence-based Out-of-Distribution Detection: A Comparative Study and Analysis. (arXiv:2107.02568v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berger_C/0/1/0/all/0/1">Christoph Berger</a>, <a href="http://arxiv.org/find/cs/1/au:+Paschali_M/0/1/0/all/0/1">Magdalini Paschali</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamnitsas_K/0/1/0/all/0/1">Konstantinos Kamnitsas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02568">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification models deployed in the real world may receive inputs
outside the intended data distribution. For critical applications such as
clinical decision making, it is important that a model can detect such
out-of-distribution (OOD) inputs and express its uncertainty. In this work, we
assess the capability of various state-of-the-art approaches for
confidence-based OOD detection through a comparative study and in-depth
analysis. First, we leverage a computer vision benchmark to reproduce and
compare multiple OOD detection methods. We then evaluate their capabilities on
the challenging task of disease classification using chest X-rays. Our study
shows that high performance in a computer vision task does not directly
translate to accuracy in a medical imaging task. We analyse factors that affect
performance of the methods between the two tasks. Our results provide useful
insights for developing the next generation of OOD detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepOPG: Improving Orthopantomogram Finding Summarization with Weak Supervision. (arXiv:2103.08290v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_T/0/1/0/all/0/1">Tzu-Ming Harry Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yin-Chih Chelsea Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08290">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical finding summaries from an orthopantomogram, or a dental panoramic
radiograph, have significant potential to improve patient communication and
speed up clinical judgments. While orthopantomogram is a first-line tool for
dental examinations, no existing work has explored the summarization of
findings from it. A finding summary has to find teeth in the imaging study and
label the teeth with several types of past treatments. To tackle the problem,
we developDeepOPG that breaks the summarization process into functional
segmentation and tooth localization, the latter of which is further refined by
a novel dental coherence module. We also leverage weak supervision labels to
improve detection results in a reinforcement learning scenario. Experiments
show high efficacy of DeepOPG on finding summarization, achieving an overall
AUC of 88.2% in detecting six types of findings. The proposed dental coherence
and weak supervision both are shown to improve DeepOPG by adding 5.9% and 0.4%
to AP@IoU&#x3D;0.5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Visual Navigation for Under-Canopy Agricultural Robots. (arXiv:2107.02792v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_A/0/1/0/all/0/1">Arun Narenthiran Sivakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1">Sahil Modi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasparino_M/0/1/0/all/0/1">Mateus Valverde Gasparino</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_C/0/1/0/all/0/1">Che Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasquez_A/0/1/0/all/0/1">Andres Eduardo Baquero Velasquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Saurabh Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02792">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a system for visually guided autonomous navigation of
under-canopy farm robots. Low-cost under-canopy robots can drive between crop
rows under the plant canopy and accomplish tasks that are infeasible for
over-the-canopy drones or larger agricultural equipment. However, autonomously
navigating them under the canopy presents a number of challenges: unreliable
GPS and LiDAR, high cost of sensing, challenging farm terrain, clutter due to
leaves and weeds, and large variability in appearance over the season and
across crop types. We address these challenges by building a modular system
that leverages machine learning for robust and generalizable perception from
monocular RGB images from low-cost cameras, and model predictive control for
accurate control in challenging terrain. Our system, CropFollow, is able to
autonomously drive 485 meters per intervention on average, outperforming a
state-of-the-art LiDAR based system (286 meters per intervention) in extensive
field testing spanning over 25 km.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicate correlation learning for scene graph generation. (arXiv:2107.02713v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1">Leitian Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_L/0/1/0/all/0/1">Li Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Nannan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xianhang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yaosi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenzhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02713">
                                    <div class="article-summary-box-inner">
                                        <span>For a typical Scene Graph Generation (SGG) method, there is often a large gap
in the performance of the predicates&#x27; head classes and tail classes. This
phenomenon is mainly caused by the semantic overlap between different
predicates as well as the long-tailed data distribution. In this paper, a
Predicate Correlation Learning (PCL) method for SGG is proposed to address the
above two problems by taking the correlation between predicates into
consideration. To describe the semantic overlap between strong-correlated
predicate classes, a Predicate Correlation Matrix (PCM) is defined to quantify
the relationship between predicate pairs, which is dynamically updated to
remove the matrix&#x27;s long-tailed bias. In addition, PCM is integrated into a
Predicate Correlation Loss function ($L_{PC}$) to reduce discouraging gradients
of unannotated classes. The proposed method is evaluated on Visual Genome
benchmark, where the performance of the tail classes is significantly improved
when built on the existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-based Adversarial Appearance Learning of Augmented Pedestrians. (arXiv:2107.02673v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strauss_K/0/1/0/all/0/1">Kevin Strauss</a>, <a href="http://arxiv.org/find/cs/1/au:+Savkin_A/0/1/0/all/0/1">Artem Savkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02673">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic data became already an essential component of machine
learning-based perception in the field of autonomous driving. Yet it still
cannot replace real data completely due to the sim2real domain shift. In this
work, we propose a method that leverages the advantages of the augmentation
process and adversarial training to synthesize realistic data for the
pedestrian recognition task. Our approach utilizes an attention mechanism
driven by an adversarial loss to learn domain discrepancies and improve
sim2real adaptation. Our experiments confirm that the proposed adaptation
method is robust to such discrepancies and reveals both visual realism and
semantic consistency. Furthermore, we evaluate our data generation pipeline on
the task of pedestrian recognition and demonstrate that generated data resemble
properties of the real domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Disentangled Representation Implicitly via Transformer for Occluded Person Re-Identification. (arXiv:2107.02380v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1">Mengxi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xinhua Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02380">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (re-ID) under various occlusions has been a
long-standing challenge as person images with different types of occlusions
often suffer from misalignment in image matching and ranking. Most existing
methods tackle this challenge by aligning spatial features of body parts
according to external semantic cues or feature similarities but this alignment
approach is complicated and sensitive to noises. We design DRL-Net, a
disentangled representation learning network that handles occluded re-ID
without requiring strict person image alignment or any additional supervision.
Leveraging transformer architectures, DRL-Net achieves alignment-free re-ID via
global reasoning of local features of occluded person images. It measures image
similarity by automatically disentangling the representation of undefined
semantic components, e.g., human body parts or obstacles, under the guidance of
semantic preference object queries in the transformer. In addition, we design a
decorrelation constraint in the transformer decoder and impose it over object
queries for better focus on different semantic components. To better eliminate
interference from occlusions, we design a contrast feature learning technique
(CFL) for better separation of occlusion features and discriminative ID
features. Extensive experiments over occluded and holistic re-ID benchmarks
(Occluded-DukeMTMC, Market1501 and DukeMTMC) show that the DRL-Net achieves
superior re-ID performance consistently and outperforms the state-of-the-art by
large margins for Occluded-DukeMTMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining EfficientNet and Vision Transformers for Video Deepfake Detection. (arXiv:2107.02612v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Coccomini_D/0/1/0/all/0/1">Davide Coccomini</a>, <a href="http://arxiv.org/find/cs/1/au:+Messina_N/0/1/0/all/0/1">Nicola Messina</a>, <a href="http://arxiv.org/find/cs/1/au:+Gennaro_C/0/1/0/all/0/1">Claudio Gennaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Falchi_F/0/1/0/all/0/1">Fabrizio Falchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02612">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfakes are the result of digital manipulation to obtain credible videos in
order to deceive the viewer. This is done through deep learning techniques
based on autoencoders or GANs that become more accessible and accurate year
after year, resulting in fake videos that are very difficult to distinguish
from real ones. Traditionally, CNN networks have been used to perform deepfake
detection, with the best results obtained using methods based on EfficientNet
B7. In this study, we combine various types of Vision Transformers with a
convolutional EfficientNet B0 used as a feature extractor, obtaining comparable
results with some very recent methods that use Vision Transformers. Differently
from the state-of-the-art approaches, we use neither distillation nor ensemble
methods. The best model achieved an AUC of 0.951 and an F1 score of 88.0%, very
close to the state-of-the-art on the DeepFake Detection Challenge (DFDC).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DocSynth: A Layout Guided Approach for Controllable Document Image Synthesis. (arXiv:2107.02638v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sanket Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1">Umapada Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02638">
                                    <div class="article-summary-box-inner">
                                        <span>Despite significant progress on current state-of-the-art image generation
models, synthesis of document images containing multiple and complex object
layouts is a challenging task. This paper presents a novel approach, called
DocSynth, to automatically synthesize document images based on a given layout.
In this work, given a spatial layout (bounding boxes with object categories) as
a reference by the user, our proposed DocSynth model learns to generate a set
of realistic document images consistent with the defined layout. Also, this
framework has been adapted to this work as a superior baseline model for
creating synthetic document image datasets for augmenting real data during
training for document layout analysis tasks. Different sets of learning
objectives have been also used to improve the model performance.
Quantitatively, we also compare the generated results of our model with real
data using standard evaluation metrics. The results highlight that our model
can successfully generate realistic and diverse document images with multiple
objects. We also present a comprehensive qualitative analysis summary of the
different scopes of synthetic image generation tasks. Lastly, to our knowledge
this is the first work of its kind.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-based Jitter: Improving Visual Recognition on Long-tailed Data with Diversity In Memory. (arXiv:2008.09809v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+yang_Y/0/1/0/all/0/1">Yi yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenhui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yifan Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09809">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers deep visual recognition on long-tailed data. To be
general, we consider two applied scenarios, \ie, deep classification and deep
metric learning. Under the long-tailed data distribution, the majority classes
(\ie, tail classes) only occupy relatively few samples and are prone to lack of
within-class diversity. A radical solution is to augment the tail classes with
higher diversity. To this end, we introduce a simple and reliable method named
Memory-based Jitter (MBJ). We observe that during training, the deep model
constantly changes its parameters after every iteration, yielding the
phenomenon of \emph{weight jitters}. Consequentially, given a same image as the
input, two historical editions of the model generate two different features in
the deeply-embedded space, resulting in \emph{feature jitters}. Using a memory
bank, we collect these (model or feature) jitters across multiple training
iterations and get the so-called Memory-based Jitter. The accumulated jitters
enhance the within-class diversity for the tail classes and consequentially
improves long-tailed visual recognition. With slight modifications, MBJ is
applicable for two fundamental visual recognition tasks, \emph{i.e.}, deep
image classification and deep metric learning (on long-tailed data). Extensive
experiments on five long-tailed classification benchmarks and two deep metric
learning benchmarks demonstrate significant improvement. Moreover, the achieved
performance are on par with the state of the art on both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PillarSegNet: Pillar-based Semantic Grid Map Estimation using Sparse LiDAR Data. (arXiv:2105.04169v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fei_J/0/1/0/all/0/1">Juncong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidenreich_P/0/1/0/all/0/1">Philipp Heidenreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Bieder_F/0/1/0/all/0/1">Frank Bieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiller_C/0/1/0/all/0/1">Christoph Stiller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04169">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic understanding of the surrounding environment is essential for
automated vehicles. The recent publication of the SemanticKITTI dataset
stimulates the research on semantic segmentation of LiDAR point clouds in urban
scenarios. While most existing approaches predict sparse pointwise semantic
classes for the sparse input LiDAR scan, we propose PillarSegNet to be able to
output a dense semantic grid map. In contrast to a previously proposed grid map
method, PillarSegNet uses PointNet to learn features directly from the 3D point
cloud and then conducts 2D semantic segmentation in the top view. To train and
evaluate our approach, we use both sparse and dense ground truth, where the
dense ground truth is obtained from multiple superimposed scans. Experimental
results on the SemanticKITTI dataset show that PillarSegNet achieves a
performance gain of about 10% mIoU over the state-of-the-art grid map method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Multimodal Fusion with TupleInfoNCE. (arXiv:2107.02575v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunze Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1">Qingnan Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Funkhouser_T/0/1/0/all/0/1">Thomas Funkhouser</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_L/0/1/0/all/0/1">Li Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02575">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a method for representation learning of multimodal data
using contrastive losses. A traditional approach is to contrast different
modalities to learn the information shared between them. However, that approach
could fail to learn the complementary synergies between modalities that might
be useful for downstream tasks. Another approach is to concatenate all the
modalities into a tuple and then contrast positive and negative tuple
correspondences. However, that approach could consider only the stronger
modalities while ignoring the weaker ones. To address these issues, we propose
a novel contrastive learning objective, TupleInfoNCE. It contrasts tuples based
not only on positive and negative correspondences but also by composing new
negative tuples using modalities describing different scenes. Training with
these additional negatives encourages the learning model to examine the
correspondences among modalities in the same tuple, ensuring that weak
modalities are not ignored. We provide a theoretical justification based on
mutual information for why this approach works, and we propose a sample
optimization algorithm to generate positive and negative samples to maximize
training efficacy. We find that TupleInfoNCE significantly outperforms the
previous state of the arts on three different downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Xformers: Efficient Attention for Image Classification. (arXiv:2107.02239v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeevan_P/0/1/0/all/0/1">Pranav Jeevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_A/0/1/0/all/0/1">Amit Sethi</a> (Indian Institute of Technology Bombay)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02239">
                                    <div class="article-summary-box-inner">
                                        <span>Linear attention mechanisms provide hope for overcoming the bottleneck of
quadratic complexity which restricts application of transformer models in
vision tasks. We modify the ViT architecture to work on longer sequence data by
replacing the quadratic attention with efficient transformers like Performer,
Linformer and Nystr\&quot;omformer of linear complexity creating Vision X-formers
(ViX). We show that ViX performs better than ViT in image classification
consuming lesser computing resources. We further show that replacing the
embedding linear layer by convolutional layers in ViX further increases their
performance. Our test on recent visions transformer models like LeViT and
Compact Convolutional Transformer (CCT) show that replacing the attention with
Nystr\&quot;omformer or Performer saves GPU usage and memory without deteriorating
performance. Incorporating these changes can democratize transformers by making
them accessible to those with limited data and computing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Feature Information Extraction for Interest Point Detection: A Comprehensive Review. (arXiv:2106.07929v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jing_J/0/1/0/all/0/1">Junfeng Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tian Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changming Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07929">
                                    <div class="article-summary-box-inner">
                                        <span>Interest point detection is one of the most fundamental and critical problems
in computer vision and image processing. In this paper, we carry out a
comprehensive review on image feature information (IFI) extraction techniques
for interest point detection. To systematically introduce how the existing
interest point detection methods extract IFI from an input image, we propose a
taxonomy of the IFI extraction techniques for interest point detection.
According to this taxonomy, we discuss different types of IFI extraction
techniques for interest point detection. Furthermore, we identify the main
unresolved issues related to the existing IFI extraction techniques for
interest point detection and any interest point detection methods that have not
been discussed before. The existing popular datasets and evaluation standards
are provided and the performances for eighteen state-of-the-art approaches are
evaluated and discussed. Moreover, future research directions on IFI extraction
techniques for interest point detection are elaborated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-To-End Data-Dependent Routing in Multi-Path Neural Networks. (arXiv:2107.02450v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tissera_D/0/1/0/all/0/1">Dumindu Tissera</a>, <a href="http://arxiv.org/find/cs/1/au:+Vithanage_K/0/1/0/all/0/1">Kasun Vithanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijessinghe_R/0/1/0/all/0/1">Rukshan Wijessinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_S/0/1/0/all/0/1">Subha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigo_R/0/1/0/all/0/1">Ranga Rodrigo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02450">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are known to give better performance with increased depth due
to their ability to learn more abstract features. Although the deepening of
networks has been well established, there is still room for efficient feature
extraction within a layer which would reduce the need for mere parameter
increment. The conventional widening of networks by having more filters in each
layer introduces a quadratic increment of parameters. Having multiple parallel
convolutional/dense operations in each layer solves this problem, but without
any context-dependent allocation of resources among these operations: the
parallel computations tend to learn similar features making the widening
process less effective. Therefore, we propose the use of multi-path neural
networks with data-dependent resource allocation among parallel computations
within layers, which also lets an input to be routed end-to-end through these
parallel paths. To do this, we first introduce a cross-prediction based
algorithm between parallel tensors of subsequent layers. Second, we further
reduce the routing overhead by introducing feature-dependent cross-connections
between parallel tensors of successive layers. Our multi-path networks show
superior performance to existing widening and adaptive feature extraction, and
even ensembles, and deeper networks at similar complexity in the image
recognition task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label noise in segmentation networks : mitigation must deal with bias. (arXiv:2107.02189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadoury_S/0/1/0/all/0/1">Samuel Kadoury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02189">
                                    <div class="article-summary-box-inner">
                                        <span>Imperfect labels limit the quality of predictions learned by deep neural
networks. This is particularly relevant in medical image segmentation, where
reference annotations are difficult to collect and vary significantly even
across expert annotators. Prior work on mitigating label noise focused on
simple models of mostly uniform noise. In this work, we explore biased and
unbiased errors artificially introduced to brain tumour annotations on MRI
data. We found that supervised and semi-supervised segmentation methods are
robust or fairly robust to unbiased errors but sensitive to biased errors. It
is therefore important to identify the sorts of errors expected in medical
image labels and especially mitigate the biased errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Cervical Whole Slide Image Analysis Framework Based on Multi-scale Semantic and Spatial Deep Features. (arXiv:2106.15113v2 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Shenghua Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiuli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shaoqun Zeng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15113">
                                    <div class="article-summary-box-inner">
                                        <span>Digital gigapixel whole slide image (WSI) is widely used in clinical
diagnosis, and automated WSI analysis is key for computer-aided diagnosis.
Currently, analyzing the integrated descriptor of probabilities or feature maps
from massive local patches encoded by ResNet classifier is the main manner for
WSI-level prediction. Feature representations of the sparse and tiny lesion
cells in cervical slides, however, are still challengeable for the
under-promoted upstream encoders, while the unused spatial representations of
cervical cells are the available features to supply the semantics analysis. As
well as patches sampling with overlap and repetitive processing incur the
inefficiency and the unpredictable side effect. This study designs a novel
inline connection network (InCNet) by enriching the multi-scale connectivity to
build the lightweight model named You Only Look Cytopathology Once (YOLCO) with
the additional supervision of spatial information. The proposed model allows
the input size enlarged to megapixel that can stitch the WSI without any
overlap by the average repeats decreased from $10^3\sim10^4$ to $10^1\sim10^2$
for collecting features and predictions at two scales. Based on Transformer for
classifying the integrated multi-scale multi-task features, the experimental
results appear $0.872$ AUC score better and $2.51\times$ faster than the best
conventional method in WSI classification on multicohort datasets of 2,019
slides from four scanning devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hierarchical Dual Model of Environment- and Place-Specific Utility for Visual Place Recognition. (arXiv:2107.02440v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keetha_N/0/1/0/all/0/1">Nikhil Varma Keetha</a>, <a href="http://arxiv.org/find/cs/1/au:+Milford_M/0/1/0/all/0/1">Michael Milford</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sourav Garg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02440">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Place Recognition (VPR) approaches have typically attempted to match
places by identifying visual cues, image regions or landmarks that have high
&#x60;&#x60;utility&#x27;&#x27; in identifying a specific place. But this concept of utility is not
singular - rather it can take a range of forms. In this paper, we present a
novel approach to deduce two key types of utility for VPR: the utility of
visual cues &#x60;specific&#x27; to an environment, and to a particular place. We employ
contrastive learning principles to estimate both the environment- and
place-specific utility of Vector of Locally Aggregated Descriptors (VLAD)
clusters in an unsupervised manner, which is then used to guide local feature
matching through keypoint selection. By combining these two utility measures,
our approach achieves state-of-the-art performance on three challenging
benchmark datasets, while simultaneously reducing the required storage and
compute time. We provide further analysis demonstrating that unsupervised
cluster selection results in semantically meaningful results, that finer
grained categorization often has higher utility for VPR than high level
semantic categorization (e.g. building, road), and characterise how these two
utility measures vary across different places and environments. Source code is
made publicly available at https://github.com/Nik-V9/HEAPUtil.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatiotemporal Fusion in Remote Sensing. (arXiv:2107.02701v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Albanwan_H/0/1/0/all/0/1">Hessah Albanwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02701">
                                    <div class="article-summary-box-inner">
                                        <span>Remote sensing images and techniques are powerful tools to investigate earth
surface. Data quality is the key to enhance remote sensing applications and
obtaining a clear and noise-free set of data is very difficult in most
situations due to the varying acquisition (e.g., atmosphere and season),
sensor, and platform (e.g., satellite angles and sensor characteristics)
conditions. With the increasing development of satellites, nowadays Terabytes
of remote sensing images can be acquired every day. Therefore, information and
data fusion can be particularly important in the remote sensing community. The
fusion integrates data from various sources acquired asynchronously for
information extraction, analysis, and quality improvement. In this chapter, we
aim to discuss the theory of spatiotemporal fusion by investigating previous
works, in addition to describing the basic concepts and some of its
applications by summarizing our prior and ongoing works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Knowledge-Transfer for Learned Image Reconstruction. (arXiv:2107.02572v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Barbano_R/0/1/0/all/0/1">Riccardo Barbano</a>, <a href="http://arxiv.org/find/eess/1/au:+Kereta_Z/0/1/0/all/0/1">Zeljko Kereta</a>, <a href="http://arxiv.org/find/eess/1/au:+Hauptmann_A/0/1/0/all/0/1">Andreas Hauptmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Arridge_S/0/1/0/all/0/1">Simon R. Arridge</a>, <a href="http://arxiv.org/find/eess/1/au:+Jin_B/0/1/0/all/0/1">Bangti Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02572">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based image reconstruction approaches have demonstrated
impressive empirical performance in many imaging modalities. These approaches
generally require a large amount of high-quality training data, which is often
not available. To circumvent this issue, we develop a novel unsupervised
knowledge-transfer paradigm for learned iterative reconstruction within a
Bayesian framework. The proposed approach learns an iterative reconstruction
network in two phases. The first phase trains a reconstruction network with a
set of ordered pairs comprising of ground truth images and measurement data.
The second phase fine-tunes the pretrained network to the measurement data
without supervision. Furthermore, the framework delivers uncertainty
information over the reconstructed image. We present extensive experimental
results on low-dose and sparse-view computed tomography, showing that the
proposed framework significantly improves reconstruction quality not only
visually, but also quantitatively in terms of PSNR and SSIM, and is competitive
with several state-of-the-art supervised and unsupervised reconstruction
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned Features with Data Augmentation. (arXiv:1904.08084v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nanni_L/0/1/0/all/0/1">L. Nanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahnam_S/0/1/0/all/0/1">S. Brahnam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghidoni_S/0/1/0/all/0/1">S. Ghidoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguolo_G/0/1/0/all/0/1">G. Maguolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.08084">
                                    <div class="article-summary-box-inner">
                                        <span>Bioimage classification plays a crucial role in many biological problems. In
this work, we present a new General Purpose (GenP) ensemble that boosts
performance by combining local features, dense sampling features, and deep
learning approaches. First, we introduce three new methods for data
augmentation based on PCA/DCT; second, we show that different data augmentation
approaches can boost the performance of an ensemble of CNNs; and, finally, we
propose a set of handcrafted/learned descriptors that are highly generalizable.
Each handcrafted descriptor is used to train a different Support Vector Machine
(SVM), and the different SVMs are combined with the ensemble of CNNs. Our
method is evaluated on a diverse set of bioimage classification problems.
Results demonstrate that the proposed GenP bioimage ensemble obtains
state-of-the-art performance without any ad-hoc dataset tuning of parameters
(thus avoiding the risk of overfitting/overtraining).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A new smart-cropping pipeline for prostate segmentation using deep learning networks. (arXiv:2107.02476v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaridis_D/0/1/0/all/0/1">Dimitrios G. Zaridis</a>, <a href="http://arxiv.org/find/eess/1/au:+Mylona_E/0/1/0/all/0/1">Eugenia Mylona</a>, <a href="http://arxiv.org/find/eess/1/au:+Marias_K/0/1/0/all/0/1">Kostas Marias</a>, <a href="http://arxiv.org/find/eess/1/au:+Papanikolaou_N/0/1/0/all/0/1">Nikolaos Papanikolaou</a>, <a href="http://arxiv.org/find/eess/1/au:+Tachos_N/0/1/0/all/0/1">Nikolaos S. Tachos</a>, <a href="http://arxiv.org/find/eess/1/au:+Fotiadis_D/0/1/0/all/0/1">Dimitrios I. Fotiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02476">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate segmentation from magnetic resonance imaging (MRI) is a challenging
task. In recent years, several network architectures have been proposed to
automate this process and alleviate the burden of manual annotation. Although
the performance of these models has achieved promising results, there is still
room for improvement before these models can be used safely and effectively in
clinical practice. One of the major challenges in prostate MR image
segmentation is the presence of class imbalance in the image labels where the
background pixels dominate over the prostate. In the present work we propose a
DL-based pipeline for cropping the region around the prostate from MRI images
to produce a more balanced distribution of the foreground pixels (prostate) and
the background pixels and improve segmentation accuracy. The effect of
DL-cropping for improving the segmentation performance compared to standard
center-cropping is assessed using five popular DL networks for prostate
segmentation, namely U-net, U-net+, Res Unet++, Bridge U-net and Dense U-net.
The proposed smart-cropping outperformed the standard center cropping in terms
of segmentation accuracy for all the evaluated prostate segmentation networks.
In terms of Dice score, the highest improvement was achieved for the U-net+ and
ResU-net++ architectures corresponding to 8.9% and 8%, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Semantic Segmentation of Large-Scale Point Clouds with Random Sampling. (arXiv:2107.02389v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1">Qingyong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Linhai Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosa_S/0/1/0/all/0/1">Stefano Rosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Trigoni_N/0/1/0/all/0/1">Niki Trigoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1">Andrew Markham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02389">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of efficient semantic segmentation of large-scale 3D
point clouds. By relying on expensive sampling techniques or computationally
heavy pre/post-processing steps, most existing approaches are only able to be
trained and operate over small-scale point clouds. In this paper, we introduce
RandLA-Net, an efficient and lightweight neural architecture to directly infer
per-point semantics for large-scale point clouds. The key to our approach is to
use random point sampling instead of more complex point selection approaches.
Although remarkably computation and memory efficient, random sampling can
discard key features by chance. To overcome this, we introduce a novel local
feature aggregation module to progressively increase the receptive field for
each 3D point, thereby effectively preserving geometric details. Comparative
experiments show that our RandLA-Net can process 1 million points in a single
pass up to 200x faster than existing approaches. Moreover, extensive
experiments on five large-scale point cloud datasets, including Semantic3D,
SemanticKITTI, Toronto3D, NPM3D and S3DIS, demonstrate the state-of-the-art
semantic segmentation performance of our RandLA-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Deep Learning Methods for Real-Time Surgical Instrument Segmentation in Laparoscopy. (arXiv:2107.02319v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1">Debesh Jha</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1">Sharib Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>, <a href="http://arxiv.org/find/eess/1/au:+Johansen_D/0/1/0/all/0/1">Dag Johansen</a>, <a href="http://arxiv.org/find/eess/1/au:+Johansen_H/0/1/0/all/0/1">H&#xe5;vard D. Johansen</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02319">
                                    <div class="article-summary-box-inner">
                                        <span>Minimally invasive surgery is a surgical intervention used to examine the
organs inside the abdomen and has been widely used due to its effectiveness
over open surgery. Due to the hardware improvements such as high definition
cameras, this procedure has significantly improved and new software methods
have demonstrated potential for computer-assisted procedures. However, there
exists challenges and requirements to improve detection and tracking of the
position of the instruments during these surgical procedures. To this end, we
evaluate and compare some popular deep learning methods that can be explored
for the automated segmentation of surgical instruments in laparoscopy, an
important step towards tool tracking. Our experimental results exhibit that the
Dual decoder attention network (DDANet) produces a superior result compared to
other recent deep learning methods. DDANet yields a Dice coefficient of 0.8739
and mean intersection-over-union of 0.8183 for the Robust Medical Instrument
Segmentation (ROBUST-MIS) Challenge 2019 dataset, at a real-time speed of
101.36 frames-per-second that is critical for such procedures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S2FGAN: Semantically Aware Interactive Sketch-to-Face Translation. (arXiv:2011.14785v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md Zakir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_S/0/1/0/all/0/1">Shafin Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14785">
                                    <div class="article-summary-box-inner">
                                        <span>Interactive facial image manipulation attempts to edit single and multiple
face attributes using a photo-realistic face and/or semantic mask as input. In
the absence of the photo-realistic image (only sketch/mask available), previous
methods only retrieve the original face but ignore the potential of aiding
model controllability and diversity in the translation process. This paper
proposes a sketch-to-image generation framework called S2FGAN, aiming to
improve users&#x27; ability to interpret and flexibility of face attribute editing
from a simple sketch. The proposed framework modifies the constrained latent
space semantics trained on Generative Adversarial Networks (GANs). We employ
two latent spaces to control the face appearance and adjust the desired
attributes of the generated face. Instead of constraining the translation
process by using a reference image, the users can command the model to retouch
the generated images by involving the semantic information in the generation
process. In this way, our method can manipulate single or multiple face
attributes by only specifying attributes to be changed. Extensive experimental
results on CelebAMask-HQ dataset empirically shows our superior performance and
effectiveness on this task. Our method successfully outperforms
state-of-the-art methods on attribute manipulation by exploiting greater
control of attribute intensity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training. (arXiv:2104.14129v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianfei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lianmin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhewei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dequan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14129">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing size of neural network models has been critical for
improvements in their accuracy, but device memory is not growing at the same
rate. This creates fundamental challenges for training neural networks within
limited memory environments. In this work, we propose ActNN, a memory-efficient
training framework that stores randomly quantized activations for back
propagation. We prove the convergence of ActNN for general network
architectures, and we characterize the impact of quantization on the
convergence via an exact expression for the gradient variance. Using our
theory, we propose novel mixed-precision quantization strategies that exploit
the activation&#x27;s heterogeneity across feature dimensions, samples, and layers.
These techniques can be readily applied to existing dynamic graph frameworks,
such as PyTorch, simply by substituting the layers. We evaluate ActNN on
mainstream computer vision models for classification, detection, and
segmentation tasks. On all these tasks, ActNN compresses the activation to 2
bits on average, with negligible accuracy loss. ActNN reduces the memory
footprint of the activation by 12x, and it enables training with a 6.6x to 14x
larger batch size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VTGAN: Semi-supervised Retinal Image Synthesis and Disease Prediction using Vision Transformers. (arXiv:2104.06757v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamran_S/0/1/0/all/0/1">Sharif Amit Kamran</a>, <a href="http://arxiv.org/find/eess/1/au:+Hossain_K/0/1/0/all/0/1">Khondker Fariha Hossain</a>, <a href="http://arxiv.org/find/eess/1/au:+Tavakkoli_A/0/1/0/all/0/1">Alireza Tavakkoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerbrod_S/0/1/0/all/0/1">Stewart Lee Zuckerbrod</a>, <a href="http://arxiv.org/find/eess/1/au:+Baker_S/0/1/0/all/0/1">Salah A. Baker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06757">
                                    <div class="article-summary-box-inner">
                                        <span>In Fluorescein Angiography (FA), an exogenous dye is injected in the
bloodstream to image the vascular structure of the retina. The injected dye can
cause adverse reactions such as nausea, vomiting, anaphylactic shock, and even
death. In contrast, color fundus imaging is a non-invasive technique used for
photographing the retina but does not have sufficient fidelity for capturing
its vascular structure. The only non-invasive method for capturing retinal
vasculature is optical coherence tomography-angiography (OCTA). However, OCTA
equipment is quite expensive, and stable imaging is limited to small areas on
the retina. In this paper, we propose a novel conditional generative
adversarial network (GAN) capable of simultaneously synthesizing FA images from
fundus photographs while predicting retinal degeneration. The proposed system
has the benefit of addressing the problem of imaging retinal vasculature in a
non-invasive manner as well as predicting the existence of retinal
abnormalities. We use a semi-supervised approach to train our GAN using
multiple weighted losses on different modalities of data. Our experiments
validate that the proposed architecture exceeds recent state-of-the-art
generative networks for fundus-to-angiography synthesis. Moreover, our vision
transformer-based discriminators generalize quite well on out-of-distribution
data sets for retinal disease prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAN++: Towards Efficient and Accurate End-to-End Spotting of Arbitrarily-Shaped Text. (arXiv:2105.00405v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuebo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Ding Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00405">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text detection and recognition have been well explored in the past few
years. Despite the progress, efficient and accurate end-to-end spotting of
arbitrarily-shaped text remains challenging. In this work, we propose an
end-to-end text spotting framework, termed PAN++, which can efficiently detect
and recognize text of arbitrary shapes in natural scenes. PAN++ is based on the
kernel representation that reformulates a text line as a text kernel (central
region) surrounded by peripheral pixels. By systematically comparing with
existing scene text representations, we show that our kernel representation can
not only describe arbitrarily-shaped text but also well distinguish adjacent
text. Moreover, as a pixel-based representation, the kernel representation can
be predicted by a single fully convolutional network, which is very friendly to
real-time applications. Taking the advantages of the kernel representation, we
design a series of components as follows: 1) a computationally efficient
feature enhancement network composed of stacked Feature Pyramid Enhancement
Modules (FPEMs); 2) a lightweight detection head cooperating with Pixel
Aggregation (PA); and 3) an efficient attention-based recognition head with
Masked RoI. Benefiting from the kernel representation and the tailored
components, our method achieves high inference speed while maintaining
competitive accuracy. Extensive experiments show the superiority of our method.
For example, the proposed PAN++ achieves an end-to-end text spotting F-measure
of 64.9 at 29.2 FPS on the Total-Text dataset, which significantly outperforms
the previous best method. Code will be available at: https://git.io/PAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task Transformer Network for Joint MRI Reconstruction and Super-Resolution. (arXiv:2106.06742v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1">Chun-Mei Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1">Yunlu Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06742">
                                    <div class="article-summary-box-inner">
                                        <span>The core problem of Magnetic Resonance Imaging (MRI) is the trade off between
acceleration and image quality. Image reconstruction and super-resolution are
two crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are
designed to perform these tasks separately, ignoring the correlations between
them. In this work, we propose an end-to-end task transformer network
(T$^2$Net) for joint MRI reconstruction and super-resolution, which allows
representations and feature transmission to be shared between multiple task to
achieve higher-quality, super-resolved and motion-artifacts-free images from
highly undersampled and degenerated MRI data. Our framework combines both
reconstruction and super-resolution, divided into two sub-branches, whose
features are expressed as queries and keys. Specifically, we encourage joint
feature learning between the two tasks, thereby transferring accurate task
information. We first use two separate CNN branches to extract task-specific
features. Then, a task transformer module is designed to embed and synthesize
the relevance between the two tasks. Experimental results show that our
multi-task model significantly outperforms advanced sequential methods, both
quantitatively and qualitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUTD-TrafficQA: A Question Answering Benchmark and an Efficient Network for Video Reasoning over Traffic Events. (arXiv:2103.15538v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Li Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">He Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15538">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic event cognition and reasoning in videos is an important task that has
a wide range of applications in intelligent transportation, assisted driving,
and autonomous vehicles. In this paper, we create a novel dataset,
SUTD-TrafficQA (Traffic Question Answering), which takes the form of video QA
based on the collected 10,080 in-the-wild videos and annotated 62,535 QA pairs,
for benchmarking the cognitive capability of causal inference and event
understanding models in complex traffic scenarios. Specifically, we propose 6
challenging reasoning tasks corresponding to various traffic scenarios, so as
to evaluate the reasoning capability over different kinds of complex yet
practical traffic events. Moreover, we propose Eclipse, a novel Efficient
glimpse network via dynamic inference, in order to achieve
computation-efficient and reliable video reasoning. The experiments show that
our method achieves superior performance while reducing the computation cost
significantly. The project page: https://github.com/SUTDCV/SUTD-TrafficQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Red Blood Cell Segmentation with Overlapping Cell Separation and Classification on Imbalanced Dataset. (arXiv:2012.01321v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Naruenatthanaset_K/0/1/0/all/0/1">Korranat Naruenatthanaset</a>, <a href="http://arxiv.org/find/eess/1/au:+Chalidabhongse_T/0/1/0/all/0/1">Thanarat H. Chalidabhongse</a>, <a href="http://arxiv.org/find/eess/1/au:+Palasuwan_D/0/1/0/all/0/1">Duangdao Palasuwan</a>, <a href="http://arxiv.org/find/eess/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/eess/1/au:+Palasuwan_A/0/1/0/all/0/1">Attakorn Palasuwan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01321">
                                    <div class="article-summary-box-inner">
                                        <span>Automated red blood cell (RBC) classification on blood smear images helps
hematologists to analyze RBC lab results in a reduced time and cost. However,
overlapping cells can cause incorrect predicted results, and so they have to be
separated into multiple single RBCs before classifying. To classify multiple
classes with deep learning, imbalance problems are common in medical imaging
because normal samples are always higher than rare disease samples. This paper
presents a new method to segment and classify RBCs from blood smear images,
specifically to tackle cell overlapping and data imbalance problems. Focusing
on overlapping cell separation, our segmentation process first estimates
ellipses to represent RBCs. The method detects the concave points and then
finds the ellipses using directed ellipse fitting. The accuracy from 20 blood
smear images was 0.889. Classification requires balanced training datasets.
However, some RBC types are rare. The imbalance ratio of this dataset was
34.538 for 12 RBC classes from 20,875 individual RBC samples. The use of
machine learning for RBC classification with an imbalanced dataset is hence
more challenging than many other applications. We analyzed techniques to deal
with this problem. The best accuracy and F1-score were 0.921 and 0.8679,
respectively, using EfficientNet-B1 with augmentation. Experimental results
showed that the weight balancing technique with augmentation had the potential
to deal with imbalance problems by improving the F1-score on minority classes,
while data augmentation significantly improved the overall classification
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Local Representation based Mutual Affine-Transfer Network for Photorealistic Stylization. (arXiv:1907.10274v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Ying Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhenzhou Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Hairong Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.10274">
                                    <div class="article-summary-box-inner">
                                        <span>Photorealistic stylization aims to transfer the style of a reference photo
onto a content photo in a natural fashion, such that the stylized image looks
like a real photo taken by a camera. State-of-the-art methods stylize the image
locally within each matched semantic region and are prone to global color
inconsistency across semantic objects/parts, making the stylized image less
photorealistic. To tackle the challenging issues, we propose a non-local
representation scheme, constrained with a mutual affine-transfer network
(NL-MAT). Through a dictionary-based decomposition, NL-MAT is able to
successfully decouple matched non-local representations and color information
of the image pair, such that the context correspondence between the image pair
is incorporated naturally, which largely facilitates local style transfer in a
global-consistent fashion. To the best of our knowledge, this is the first
attempt to address the photorealistic stylization problem with a non-local
representation scheme, such that no additional models or steps for semantic
matching are required during stylization. Experimental results demonstrate that
the proposed method is able to generate photorealistic results with local style
transfer while preserving both the spatial structure and global color
consistency of the content image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The GIST and RIST of Iterative Self-Training for Semi-Supervised Segmentation. (arXiv:2103.17105v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teh_E/0/1/0/all/0/1">Eu Wern Teh</a>, <a href="http://arxiv.org/find/cs/1/au:+DeVries_T/0/1/0/all/0/1">Terrance DeVries</a>, <a href="http://arxiv.org/find/cs/1/au:+Duke_B/0/1/0/all/0/1">Brendan Duke</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1">Ruowei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aarabi_P/0/1/0/all/0/1">Parham Aarabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1">Graham W. Taylor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17105">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the task of semi-supervised semantic segmentation, where we aim
to produce pixel-wise semantic object masks given only a small number of
human-labeled training examples. We focus on iterative self-training methods in
which we explore the behavior of self-training over multiple refinement stages.
We show that iterative self-training leads to performance degradation if done
na\&quot;ively with a fixed ratio of human-labeled to pseudo-labeled training
examples. We propose Greedy Iterative Self-Training (GIST) and Random Iterative
Self-Training (RIST) strategies that alternate between training on either
human-labeled data or pseudo-labeled data at each refinement stage, resulting
in a performance boost rather than degradation. We further show that GIST and
RIST can be combined with existing semi-supervised learning methods to boost
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection. (arXiv:2012.04355v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_Y/0/1/0/all/0/1">Yezhen Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Litany_O/0/1/0/all/0/1">Or Litany</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas J. Guibas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04355">
                                    <div class="article-summary-box-inner">
                                        <span>3D object detection is an important yet demanding task that heavily relies on
difficult to obtain 3D annotations. To reduce the required amount of
supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D
object detection applicable to both indoor and outdoor scenes. We leverage a
teacher-student mutual learning framework to propagate information from the
labeled to the unlabeled train set in the form of pseudo-labels. However, due
to the high task complexity, we observe that the pseudo-labels suffer from
significant noise and are thus not directly usable. To that end, we introduce a
confidence-based filtering mechanism, inspired by FixMatch. We set confidence
thresholds based upon the predicted objectness and class probability to filter
low-quality pseudo-labels. While effective, we observe that these two measures
do not sufficiently capture localization quality. We therefore propose to use
the estimated 3D IoU as a localization metric and set category-aware
self-adjusted thresholds to filter poorly localized proposals. We adopt VoteNet
as our backbone detector on indoor datasets while we use PV-RCNN on the
autonomous driving dataset, KITTI. Our method consistently improves
state-of-the-art methods on both ScanNet and SUN-RGBD benchmarks by significant
margins under all label ratios (including fully labeled setting). For example,
when training using only 10\% labeled data on ScanNet, 3DIoUMatch achieves 7.7%
absolute improvement on mAP@0.25 and 8.5% absolute improvement on mAP@0.5 upon
the prior art. On KITTI, we are the first to demonstrate semi-supervised 3D
object detection and our method surpasses a fully supervised baseline from 1.8%
to 7.6% under different label ratios and categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AE TextSpotter: Learning Visual and Linguistic Representation for Ambiguous Text Spotting. (arXiv:2008.00714v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuebo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1">Xiaozhong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Ding Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00714">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text spotting aims to detect and recognize the entire word or sentence
with multiple characters in natural images. It is still challenging because
ambiguity often occurs when the spacing between characters is large or the
characters are evenly spread in multiple rows and columns, making many visually
plausible groupings of the characters (e.g. &quot;BERLIN&quot; is incorrectly detected as
&quot;BERL&quot; and &quot;IN&quot; in Fig. 1(c)). Unlike previous works that merely employed
visual features for text detection, this work proposes a novel text spotter,
named Ambiguity Eliminating Text Spotter (AE TextSpotter), which learns both
visual and linguistic features to significantly reduce ambiguity in text
detection. The proposed AE TextSpotter has three important benefits. 1) The
linguistic representation is learned together with the visual representation in
a framework. To our knowledge, it is the first time to improve text detection
by using a language model. 2) A carefully designed language module is utilized
to reduce the detection confidence of incorrect text lines, making them easily
pruned in the detection stage. 3) Extensive experiments show that AE
TextSpotter outperforms other state-of-the-art methods by a large margin. For
example, we carefully select a validation set of extremely ambiguous samples
from the IC19-ReCTS dataset, where our approach surpasses other methods by more
than 4%. The code has been released at
https://github.com/whai362/AE_TextSpotter. The image list and evaluation
scripts of the validation set have been released at
https://github.com/whai362/TDA-ReCTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient-CapsNet: Capsule Network with Self-Attention Routing. (arXiv:2101.12491v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1">Francesco Salvetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12491">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks, assisted by architectural design
strategies, make extensive use of data augmentation techniques and layers with
a high number of feature maps to embed object transformations. That is highly
inefficient and for large datasets implies a massive redundancy of features
detectors. Even though capsules networks are still in their infancy, they
constitute a promising solution to extend current convolutional networks and
endow artificial visual perception with a process to encode more efficiently
all feature affine transformations. Indeed, a properly working capsule network
should theoretically achieve higher results with a considerably lower number of
parameters count due to intrinsic capability to generalize to novel viewpoints.
Nevertheless, little attention has been given to this relevant aspect. In this
paper, we investigate the efficiency of capsule networks and, pushing their
capacity to the limits with an extreme architecture with barely 160K
parameters, we prove that the proposed architecture is still able to achieve
state-of-the-art results on three different datasets with only 2% of the
original CapsNet parameters. Moreover, we replace dynamic routing with a novel
non-iterative, highly parallelizable routing algorithm that can easily cope
with a reduced number of capsules. Extensive experimentation with other capsule
implementations has proved the effectiveness of our methodology and the
capability of capsule networks to efficiently embed visual representations more
prone to generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fractional order graph neural network. (arXiv:2001.04026v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chunbo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Peng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_G/0/1/0/all/0/1">Geyong Min</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04026">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes fractional order graph neural networks (FGNNs), optimized
by the approximation strategy to address the challenges of local optimum of
classic and fractional graph neural networks which are specialised at
aggregating information from the feature and adjacent matrices of connected
nodes and their neighbours to solve learning tasks on non-Euclidean data such
as graphs. Meanwhile the approximate calculation of fractional order gradients
also overcomes the high computational complexity of fractional order
derivations. We further prove that such an approximation is feasible and the
FGNN is unbiased towards global optimization solution. Extensive experiments on
citation networks show that FGNN achieves great advantage over baseline models
when selected appropriate fractional order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised learning of MRI tissue properties using MRI physics models. (arXiv:2107.02704v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Varadarajan_D/0/1/0/all/0/1">Divya Varadarajan</a>, <a href="http://arxiv.org/find/eess/1/au:+Bouman_K/0/1/0/all/0/1">Katherine L. Bouman</a>, <a href="http://arxiv.org/find/eess/1/au:+Kouwe_A/0/1/0/all/0/1">Andre van der Kouwe</a>, <a href="http://arxiv.org/find/eess/1/au:+Fischl_B/0/1/0/all/0/1">Bruce Fischl</a>, <a href="http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1">Adrian V. Dalca</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02704">
                                    <div class="article-summary-box-inner">
                                        <span>In neuroimaging, MRI tissue properties characterize underlying neurobiology,
provide quantitative biomarkers for neurological disease detection and
analysis, and can be used to synthesize arbitrary MRI contrasts. Estimating
tissue properties from a single scan session using a protocol available on all
clinical scanners promises to reduce scan time and cost, enable quantitative
analysis in routine clinical scans and provide scan-independent biomarkers of
disease. However, existing tissue properties estimation methods - most often
$\mathbf{T_1}$ relaxation, $\mathbf{T_2^*}$ relaxation, and proton density
($\mathbf{PD}$) - require data from multiple scan sessions and cannot estimate
all properties from a single clinically available MRI protocol such as the
multiecho MRI scan. In addition, the widespread use of non-standard acquisition
parameters across clinical imaging sites require estimation methods that can
generalize across varying scanner parameters. However, existing learning
methods are acquisition protocol specific and cannot estimate from heterogenous
clinical data from different imaging sites. In this work we propose an
unsupervised deep-learning strategy that employs MRI physics to estimate all
three tissue properties from a single multiecho MRI scan session, and
generalizes across varying acquisition parameters. The proposed strategy
optimizes accurate synthesis of new MRI contrasts from estimated latent tissue
properties, enabling unsupervised training, we also employ random acquisition
parameters during training to achieve acquisition generalization. We provide
the first demonstration of estimating all tissue properties from a single
multiecho scan session. We demonstrate improved accuracy and generalizability
for tissue property estimation and MRI synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">David Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1">Adam Santoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1">Matt Botvinick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the Best Pooling Strategy for Visual Semantic Embedding. (arXiv:2011.04305v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiacheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hexiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuning Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04305">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Semantic Embedding (VSE) is a dominant approach for vision-language
retrieval, which aims at learning a deep embedding space such that visual data
are embedded close to their semantic text labels or descriptions. Recent VSE
models use complex methods to better contextualize and aggregate multi-modal
features into holistic embeddings. However, we discover that surprisingly
simple (but carefully selected) global pooling functions (e.g., max pooling)
outperform those complex models, across different feature extractors. Despite
its simplicity and effectiveness, seeking the best pooling function for
different data modality and feature extractor is costly and tedious, especially
when the size of features varies (e.g., text, video). Therefore, we propose a
Generalized Pooling Operator (GPO), which learns to automatically adapt itself
to the best pooling strategy for different features, requiring no manual tuning
while staying effective and efficient. We extend the VSE model using this
proposed GPO and denote it as VSE$\infty$.

Without bells and whistles, VSE$\infty$ outperforms previous VSE methods
significantly on image-text retrieval benchmarks across popular feature
extractors. With a simple adaptation, variants of VSE$\infty$ further
demonstrate its strength by achieving the new state of the art on two
video-text retrieval datasets. Comprehensive experiments and visualizations
confirm that GPO always discovers the best pooling strategy and can be a
plug-and-play feature aggregation module for standard VSE models. Code and
pre-trained models are available at https://vse-infty.github.io.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Human Video Rendering by Learning Dynamic Textures and Rendering-to-Video Translation. (arXiv:2001.04947v3 [cs.GR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weipeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1">Marc Habermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1">Michael Zollhoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernard_F/0/1/0/all/0/1">Florian Bernard</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyeongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04947">
                                    <div class="article-summary-box-inner">
                                        <span>Synthesizing realistic videos of humans using neural networks has been a
popular alternative to the conventional graphics-based rendering pipeline due
to its high efficiency. Existing works typically formulate this as an
image-to-image translation problem in 2D screen space, which leads to artifacts
such as over-smoothing, missing body parts, and temporal instability of
fine-scale detail, such as pose-dependent wrinkles in the clothing. In this
paper, we propose a novel human video synthesis method that approaches these
limiting factors by explicitly disentangling the learning of time-coherent
fine-scale details from the embedding of the human in 2D screen space. More
specifically, our method relies on the combination of two convolutional neural
networks (CNNs). Given the pose information, the first CNN predicts a dynamic
texture map that contains time-coherent high-frequency details, and the second
CNN conditions the generation of the final video on the temporally coherent
output of the first CNN. We demonstrate several applications of our approach,
such as human reenactment and novel view synthesis from monocular video, where
we show significant improvement over the state of the art both qualitatively
and quantitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-time Pose Estimation from Images for Multiple Humanoid Robots. (arXiv:2107.02675v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1">Arash Amini</a>, <a href="http://arxiv.org/find/cs/1/au:+Farazi_H/0/1/0/all/0/1">Hafez Farazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02675">
                                    <div class="article-summary-box-inner">
                                        <span>Pose estimation commonly refers to computer vision methods that recognize
people&#x27;s body postures in images or videos. With recent advancements in deep
learning, we now have compelling models to tackle the problem in real-time.
Since these models are usually designed for human images, one needs to adapt
existing models to work on other creatures, including robots. This paper
examines different state-of-the-art pose estimation models and proposes a
lightweight model that can work in real-time on humanoid robots in the RoboCup
Humanoid League environment. Additionally, we present a novel dataset called
the HumanoidRobotPose dataset. The results of this work have the potential to
enable many advanced behaviors for soccer-playing robots.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation Theoretic Patterns in Multi-Frequency Class Averaging for Three-Dimensional Cryo-Electron Microscopy. (arXiv:1906.01082v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1">Yifeng Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_T/0/1/0/all/0/1">Tingran Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Z/0/1/0/all/0/1">Zhizhen Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.01082">
                                    <div class="article-summary-box-inner">
                                        <span>We develop in this paper a novel intrinsic classification algorithm --
multi-frequency class averaging (MFCA) -- for classifying noisy projection
images obtained from three-dimensional cryo-electron microscopy (cryo-EM) by
the similarity among their viewing directions. This new algorithm leverages
multiple irreducible representations of the unitary group to introduce
additional redundancy into the representation of the optimal in-plane
rotational alignment, extending and outperforming the existing class averaging
algorithm that uses only a single representation. The formal algebraic model
and representation theoretic patterns of the proposed MFCA algorithm extend the
framework of Hadani and Singer to arbitrary irreducible representations of the
unitary group. We conceptually establish the consistency and stability of MFCA
by inspecting the spectral properties of a generalized local parallel transport
operator through the lens of Wigner $D$-matrices. We demonstrate the efficacy
of the proposed algorithm with numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Pneumonia Severity Prediction using Hybrid Convolution-Attention Neural Architectures. (arXiv:2107.02672v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_N/0/1/0/all/0/1">Nam Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_J/0/1/0/all/0/1">J. Morris Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02672">
                                    <div class="article-summary-box-inner">
                                        <span>This study proposed a novel framework for COVID-19 severity prediction, which
is a combination of data-centric and model-centric approaches. First, we
propose a data-centric pre-training for extremely scare data scenarios of the
investigating dataset. Second, we propose two hybrid convolution-attention
neural architectures that leverage the self-attention from Transformer and
Hopfield networks. Our proposed approach achieves significant improvement from
the conventional baseline approach. The best model from our proposed approach
achieves $R^2 &#x3D; 0.85 \pm 0.05$ and Pearson correlation coefficient $\rho &#x3D; 0.92
\pm 0.02$ in geographic extend and $R^2 &#x3D; 0.72 \pm 0.09, \rho &#x3D; 0.85\pm 0.06$
in opacity prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer. (arXiv:2107.02681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zineng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02681">
                                    <div class="article-summary-box-inner">
                                        <span>Since visual perception can give rich information beyond text descriptions
for world understanding, there has been increasing interest in leveraging
visual grounding for language learning. Recently, vokenization has attracted
attention by using the predictions of a text-to-image retrieval model as labels
for language model supervision. Despite its success, the method suffers from
approximation error of using finite image labels and the lack of vocabulary
diversity of a small image-text dataset. To overcome these limitations, we
present VidLanKD, a video-language knowledge distillation method for improving
language understanding. We train a multi-modal teacher model on a video-text
dataset, and then transfer its knowledge to a student language model with a
text dataset. To avoid approximation error, we propose to use different
knowledge distillation objectives. In addition, the use of a large-scale
video-text dataset helps learn diverse and richer vocabularies. In our
experiments, VidLanKD achieves consistent improvements over text-only language
models and vokenization models, on several downstream language understanding
tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world
knowledge, physical reasoning, and temporal reasoning capabilities of our model
by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we
present comprehensive ablation studies as well as visualizations of the learned
text-to-video grounding results of our teacher and student language models. Our
code and models are available at: https://github.com/zinengtang/VidLanKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially private federated deep learning for multi-site medical image segmentation. (arXiv:2107.02586v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/eess/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/eess/1/au:+Remerscheid_N/0/1/0/all/0/1">Nicolas Remerscheid</a>, <a href="http://arxiv.org/find/eess/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/eess/1/au:+Makowski_M/0/1/0/all/0/1">Marcus Makowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02586">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative machine learning techniques such as federated learning (FL)
enable the training of models on effectively larger datasets without data
transfer. Recent initiatives have demonstrated that segmentation models trained
with FL can achieve performance similar to locally trained models. However, FL
is not a fully privacy-preserving technique and privacy-centred attacks can
disclose confidential patient data. Thus, supplementing FL with
privacy-enhancing technologies (PTs) such as differential privacy (DP) is a
requirement for clinical applications in a multi-institutional setting. The
application of PTs to FL in medical imaging and the trade-offs between privacy
guarantees and model utility, the ramifications on training performance and the
susceptibility of the final models to attacks have not yet been conclusively
investigated. Here we demonstrate the first application of differentially
private gradient descent-based FL on the task of semantic segmentation in
computed tomography. We find that high segmentation performance is possible
under strong privacy guarantees with an acceptable training time penalty. We
furthermore demonstrate the first successful gradient-based model inversion
attack on a semantic segmentation model and show that the application of DP
prevents it from divulging sensitive image features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Outliers with Poisson Image Interpolation. (arXiv:2107.02622v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jeremy Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1">Benjamin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Day_T/0/1/0/all/0/1">Thomas Day</a>, <a href="http://arxiv.org/find/cs/1/au:+Simpson_J/0/1/0/all/0/1">John Simpson</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02622">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised learning of every possible pathology is unrealistic for many
primary care applications like health screening. Image anomaly detection
methods that learn normal appearance from only healthy data have shown
promising results recently. We propose an alternative to image
reconstruction-based and image embedding-based methods and propose a new
self-supervised method to tackle pathological anomaly detection. Our approach
originates in the foreign patch interpolation (FPI) strategy that has shown
superior performance on brain MRI and abdominal CT data. We propose to use a
better patch interpolation strategy, Poisson image interpolation (PII), which
makes our method suitable for applications in challenging data regimes. PII
outperforms state-of-the-art methods by a good margin when tested on surrogate
tasks like identifying common lung anomalies in chest X-rays or hypo-plastic
left heart syndrome in prenatal, fetal cardiac ultrasound images. Code
available at https://github.com/jemtan/PII.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection using Edge Computing in Video Surveillance System: Review. (arXiv:2107.02778v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patrikar_D/0/1/0/all/0/1">Devashree R. Patrikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Parate_M/0/1/0/all/0/1">Mayur Rajram Parate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02778">
                                    <div class="article-summary-box-inner">
                                        <span>The current concept of Smart Cities influences urban planners and researchers
to provide modern, secured and sustainable infrastructure and give a decent
quality of life to its residents. To fulfill this need video surveillance
cameras have been deployed to enhance the safety and well-being of the
citizens. Despite technical developments in modern science, abnormal event
detection in surveillance video systems is challenging and requires exhaustive
human efforts. In this paper, we surveyed various methodologies developed to
detect anomalies in intelligent video surveillance. Firstly, we revisit the
surveys on anomaly detection in the last decade. We then present a systematic
categorization of methodologies developed for ease of understanding.
Considering the notion of anomaly depends on context, we identify different
objects-of-interest and publicly available datasets in anomaly detection. Since
anomaly detection is considered a time-critical application of computer vision,
our emphasis is on anomaly detection using edge devices and approaches
explicitly designed for them. Further, we discuss the challenges and
opportunities involved in anomaly detection at the edge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis. (arXiv:2107.02790v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blattmann_A/0/1/0/all/0/1">Andreas Blattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1">Timo Milbich</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorkenwald_M/0/1/0/all/0/1">Michael Dorkenwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1">Bj&#xf6;rn Ommer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02790">
                                    <div class="article-summary-box-inner">
                                        <span>How would a static scene react to a local poke? What are the effects on other
parts of an object if you could locally push it? There will be distinctive
movement, despite evident variations caused by the stochastic nature of our
world. These outcomes are governed by the characteristic kinematics of objects
that dictate their overall motion caused by a local interaction. Conversely,
the movement of an object provides crucial information about its underlying
distinctive kinematics and the interdependencies between its parts. This
two-way relation motivates learning a bijective mapping between object
kinematics and plausible future image sequences. Therefore, we propose iPOKE -
invertible Prediction of Object Kinematics - that, conditioned on an initial
frame and a local poke, allows to sample object kinematics and establishes a
one-to-one correspondence to the corresponding plausible videos, thereby
providing a controlled stochastic video synthesis. In contrast to previous
works, we do not generate arbitrary realistic videos, but provide efficient
control of movements, while still capturing the stochastic nature of our
environment and the diversity of plausible outcomes it entails. Moreover, our
approach can transfer kinematics onto novel object instances and is not
confined to particular object classes. Project page is available at
https://bit.ly/3dJN4Lf</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Foreground-Aware Stylization and Consensus Pseudo-Labeling for Domain Adaptation of First-Person Hand Segmentation. (arXiv:2107.02718v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ohkawa_T/0/1/0/all/0/1">Takehiko Ohkawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Yagi_T/0/1/0/all/0/1">Takuma Yagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_A/0/1/0/all/0/1">Atsushi Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1">Yoshitaka Ushiku</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1">Yoichi Sato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02718">
                                    <div class="article-summary-box-inner">
                                        <span>Hand segmentation is a crucial task in first-person vision. Since
first-person images exhibit strong bias in appearance among different
environments, adapting a pre-trained segmentation model to a new domain is
required in hand segmentation. Here, we focus on appearance gaps for hand
regions and backgrounds separately. We propose (i) foreground-aware image
stylization and (ii) consensus pseudo-labeling for domain adaptation of hand
segmentation. We stylize source images independently for the foreground and
background using target images as style. To resolve the domain shift that the
stylization has not addressed, we apply careful pseudo-labeling by taking a
consensus between the models trained on the source and stylized source images.
We validated our method on domain adaptation of hand segmentation from real and
simulation images. Our method achieved state-of-the-art performance in both
settings. We also demonstrated promising results in challenging multi-target
domain adaptation and domain generalization settings. Code is available at
https://github.com/ut-vision/FgSty-CPL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A deep-learning--based multimodal depth-aware dynamic hand gesture recognition system. (arXiv:2107.02543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1">Hasan Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Morshed_M/0/1/0/all/0/1">Mashrur Mahmud Morshed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md. Kamrul Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02543">
                                    <div class="article-summary-box-inner">
                                        <span>Any spatio-temporal movement or reorientation of the hand, done with the
intention of conveying a specific meaning, can be considered as a hand gesture.
Inputs to hand gesture recognition systems can be in several forms, such as
depth images, monocular RGB, or skeleton joint points. We observe that raw
depth images possess low contrasts in the hand regions of interest (ROI). They
do not highlight important details to learn, such as finger bending information
(whether a finger is overlapping the palm, or another finger). Recently, in
deep-learning--based dynamic hand gesture recognition, researchers are tying to
fuse different input modalities (e.g. RGB or depth images and hand skeleton
joint points) to improve the recognition accuracy. In this paper, we focus on
dynamic hand gesture (DHG) recognition using depth quantized image features and
hand skeleton joint points. In particular, we explore the effect of using
depth-quantized features in Convolutional Neural Network (CNN) and Recurrent
Neural Network (RNN) based multi-modal fusion networks. We find that our method
improves existing results on the SHREC-DHG-14 dataset. Furthermore, using our
method, we show that it is possible to reduce the resolution of the input
images by more than four times and still obtain comparable or better accuracy
to that of the resolutions used in previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth-supervised NeRF: Fewer Views and Faster Training for Free. (arXiv:2107.02791v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Andrew Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02791">
                                    <div class="article-summary-box-inner">
                                        <span>One common failure mode of Neural Radiance Field (NeRF) models is fitting
incorrect geometries when given an insufficient number of input views. We
propose DS-NeRF (Depth-supervised Neural Radiance Fields), a loss for learning
neural radiance fields that takes advantage of readily-available depth
supervision. Our key insight is that sparse depth supervision can be used to
regularize the learned geometry, a crucial component for effectively rendering
novel views using NeRF. We exploit the fact that current NeRF pipelines require
images with known camera poses that are typically estimated by running
structure-from-motion (SFM). Crucially, SFM also produces sparse 3D points that
can be used as &#x60;&#x60;free&quot; depth supervision during training: we simply add a loss
to ensure that depth rendered along rays that intersect these 3D points is
close to the observed depth. We find that DS-NeRF can render more accurate
images given fewer training views while training 2-6x faster. With only two
training views on real-world images, DS-NeRF significantly outperforms NeRF as
well as other sparse-view variants. We show that our loss is compatible with
these NeRF models, demonstrating that depth is a cheap and easily digestible
supervisory signal. Finally, we show that DS-NeRF supports other types of depth
supervision such as scanned depth sensors and RGBD reconstruction outputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-fine Semantic Localization with HD Map for Autonomous Driving in Structural Scenes. (arXiv:2107.02557v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chengcheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Minjie Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Heyang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Pengpeng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_E/0/1/0/all/0/1">Erkang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02557">
                                    <div class="article-summary-box-inner">
                                        <span>Robust and accurate localization is an essential component for robotic
navigation and autonomous driving. The use of cameras for localization with
high definition map (HD Map) provides an affordable localization sensor set.
Existing methods suffer from pose estimation failure due to error prone data
association or initialization with accurate initial pose requirement. In this
paper, we propose a cost-effective vehicle localization system with HD map for
autonomous driving that uses cameras as primary sensors. To this end, we
formulate vision-based localization as a data association problem that maps
visual semantics to landmarks in HD map. Specifically, system initialization is
finished in a coarse to fine manner by combining coarse GPS (Global Positioning
System) measurement and fine pose searching. In tracking stage, vehicle pose is
refined by implicitly aligning the semantic segmentation result between image
and landmarks in HD maps with photometric consistency. Finally, vehicle pose is
computed by pose graph optimization in a sliding window fashion. We evaluate
our method on two datasets and demonstrate that the proposed approach yields
promising localization results in different driving scenarios. Additionally,
our approach is suitable for both monocular camera and multi-cameras that
provides flexibility and improves robustness for the localization system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HybrUR: A Hybrid Physical-Neural Solution for Unsupervised Underwater Image Restoration. (arXiv:2107.02660v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shuaizheng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhengxing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yue Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Min Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Junzhi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02660">
                                    <div class="article-summary-box-inner">
                                        <span>Robust vision restoration for an underwater image remains a challenging
problem. For the lack of aligned underwater-terrestrial image pairs, the
unsupervised method is more suited to this task. However, the pure data-driven
unsupervised method usually has difficulty in achieving realistic color
correction for lack of optical constraint. In this paper, we propose a data-
and physics-driven unsupervised architecture that learns underwater vision
restoration from unpaired underwater-terrestrial images. For sufficient domain
transformation and detail preservation, the underwater degeneration needs to be
explicitly constructed based on the optically unambiguous physics law. Thus, we
employ the Jaffe-McGlamery degradation theory to design the generation models,
and use neural networks to describe the process of underwater degradation.
Furthermore, to overcome the problem of invalid gradient when optimizing the
hybrid physical-neural model, we fully investigate the intrinsic correlation
between the scene depth and the degradation factors for the backscattering
estimation, to improve the restoration performance through physical
constraints. Our experimental results show that the proposed method is able to
perform high-quality restoration for unconstrained underwater images without
any supervision. On multiple benchmarks, we outperform several state-of-the-art
supervised and unsupervised approaches. We also demonstrate that our methods
yield encouraging results on real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation. (arXiv:2107.02655v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbera_G/0/1/0/all/0/1">Giammarco La Barbera</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Boussaid_H/0/1/0/all/0/1">Haithem Boussaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Belucci_B/0/1/0/all/0/1">Bruno Belucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmonte_A/0/1/0/all/0/1">Alessandro Delmonte</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulin_J/0/1/0/all/0/1">Jeanne Goulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarnacki_S/0/1/0/all/0/1">Sabine Sarnacki</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouet_L/0/1/0/all/0/1">Laurence Rouet</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02655">
                                    <div class="article-summary-box-inner">
                                        <span>Due to a high heterogeneity in pose and size and to a limited number of
available data, segmentation of pediatric images is challenging for deep
learning methods. In this work, we propose a new CNN architecture that is pose
and scale invariant thanks to the use of Spatial Transformer Network (STN). Our
architecture is composed of three sequential modules that are estimated
together during training: (i) a regression module to estimate a similarity
matrix to normalize the input image to a reference one; (ii) a differentiable
module to find the region of interest to segment; (iii) a segmentation module,
based on the popular UNet architecture, to delineate the object. Unlike the
original UNet, which strives to learn a complex mapping, including pose and
scale variations, from a finite training dataset, our segmentation module
learns a simpler mapping focusing on images with normalized pose and size.
Furthermore, the use of an automatic bounding box detection through STN allows
saving time and especially memory, while keeping similar performance. We test
the proposed method in kidney and renal tumor segmentation on abdominal
pediatric CT scanners. Results indicate that the estimated STN homogenization
of size and pose accelerates the segmentation (25h), compared to standard
data-augmentation (33h), while obtaining a similar quality for the kidney
(88.01\% of Dice score) and improving the renal tumor delineation (from 85.52\%
to 87.12\%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspectral Pansharpening Based on Improved Deep Image Prior and Residual Reconstruction. (arXiv:2107.02630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1">Wele Gedara Chaminda Bandara</a>, <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02630">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral
image (LR-HSI) with a registered panchromatic image (PAN) to generate an
enhanced HSI with high spectral and spatial resolution. Recently proposed HS
pansharpening methods have obtained remarkable results using deep convolutional
networks (ConvNets), which typically consist of three steps: (1) up-sampling
the LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining
the final fused HSI by adding the outputs from first and second steps. Recent
methods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to
its excellent ability to preserve both spatial and spectral information,
without learning from large data sets. However, we observed that the quality of
up-sampled HSIs can be further improved by introducing an additional
spatial-domain constraint to the conventional spectral-domain energy function.
We define our spatial-domain constraint as the $L_1$ distance between the
predicted PAN image and the actual PAN image. To estimate the PAN image of the
up-sampled HSI, we also propose a learnable spectral response function (SRF).
Moreover, we noticed that the residual image between the up-sampled HSI and the
reference HSI mainly consists of edge information and very fine structures. In
order to accurately estimate fine information, we propose a novel over-complete
network, called HyperKite, which focuses on learning high-level features by
constraining the receptive from increasing in the deep layers. We perform
experiments on three HSI datasets to demonstrate the superiority of our
DIP-HyperKite over the state-of-the-art pansharpening methods. The deployment
codes, pre-trained models, and final fusion outputs of our DIP-HyperKite and
the methods used for the comparisons will be publicly made available at
https://github.com/wgcban/DIP-HyperKite.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth-Aware Multi-Grid Deep Homography Estimation with Contextual Correlation. (arXiv:2107.02524v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Lang Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chunyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_K/0/1/0/all/0/1">Kang Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuaicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02524">
                                    <div class="article-summary-box-inner">
                                        <span>Homography estimation is an important task in computer vision, such as image
stitching, video stabilization, and camera calibration. Traditional homography
estimation methods heavily depend on the quantity and distribution of feature
points, leading to poor robustness in textureless scenes. The learning
solutions, on the contrary, try to learn robust deep features but demonstrate
unsatisfying performance in the scenes of low overlap rates. In this paper, we
address the two problems simultaneously, by designing a contextual correlation
layer, which can capture the long-range correlation on feature maps and
flexibly be bridged in a learning framework. In addition, considering that a
single homography can not represent the complex spatial transformation in
depth-varying images with parallax, we propose to predict multi-grid homography
from global to local. Moreover, we equip our network with depth perception
capability, by introducing a novel depth-aware shape-preserved loss. Extensive
experiments demonstrate the superiority of our method over other
state-of-the-art solutions in the synthetic benchmark dataset and real-world
dataset. The codes and models will be available at
https://github.com/nie-lang/Multi-Grid-Deep-Homogarphy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-aware curriculum federated learning for breast cancer classification. (arXiv:2107.02504v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jimenez_Sanchez_A/0/1/0/all/0/1">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tardy_M/0/1/0/all/0/1">Mickael Tardy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballester_M/0/1/0/all/0/1">Miguel A. Gonz&#xe1;lez Ballester</a>, <a href="http://arxiv.org/find/cs/1/au:+Mateus_D/0/1/0/all/0/1">Diana Mateus</a>, <a href="http://arxiv.org/find/cs/1/au:+Piella_G/0/1/0/all/0/1">Gemma Piella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02504">
                                    <div class="article-summary-box-inner">
                                        <span>For early breast cancer detection, regular screening with mammography imaging
is recommended. Routinary examinations result in datasets with a predominant
amount of negative samples. A potential solution to such class-imbalance is
joining forces across multiple institutions. Developing a collaborative
computer-aided diagnosis system is challenging in different ways. Patient
privacy and regulations need to be carefully respected. Data across
institutions may be acquired from different devices or imaging protocols,
leading to heterogeneous non-IID data. Also, for learning-based methods, new
optimization strategies working on distributed data are required. Recently,
federated learning has emerged as an effective tool for collaborative learning.
In this setting, local models perform computation on their private data to
update the global model. The order and the frequency of local updates influence
the final global model. Hence, the order in which samples are locally presented
to the optimizers plays an important role. In this work, we define a
memory-aware curriculum learning method for the federated setting. Our
curriculum controls the order of the training samples paying special attention
to those that are forgotten after the deployment of the global model. Our
approach is combined with unsupervised domain adaptation to deal with domain
shift while preserving data privacy. We evaluate our method with three clinical
datasets from different vendors. Our results verify the effectiveness of
federated adversarial learning for the multi-site breast cancer classification.
Moreover, we show that our proposed memory-aware curriculum method is
beneficial to further improve classification performance. Our code is publicly
available at: https://github.com/ameliajimenez/curriculum-federated-learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stateless actor-critic for instance segmentation with high-level priors. (arXiv:2107.02600v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hilt_P/0/1/0/all/0/1">Paul Hilt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaziakhmedov_E/0/1/0/all/0/1">Edgar Kaziakhmedov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhide_S/0/1/0/all/0/1">Sourabh Bhide</a>, <a href="http://arxiv.org/find/cs/1/au:+Leptin_M/0/1/0/all/0/1">Maria Leptin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pape_C/0/1/0/all/0/1">Constantin Pape</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreshuk_A/0/1/0/all/0/1">Anna Kreshuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02600">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation is an important computer vision problem which remains
challenging despite impressive recent advances due to deep learning-based
methods. Given sufficient training data, fully supervised methods can yield
excellent performance, but annotation of ground-truth data remains a major
bottleneck, especially for biomedical applications where it has to be performed
by domain experts. The amount of labels required can be drastically reduced by
using rules derived from prior knowledge to guide the segmentation. However,
these rules are in general not differentiable and thus cannot be used with
existing methods. Here, we relax this requirement by using stateless actor
critic reinforcement learning, which enables non-differentiable rewards. We
formulate the instance segmentation problem as graph partitioning and the actor
critic predicts the edge weights driven by the rewards, which are based on the
conformity of segmented instances to high-level priors on object shape,
position or size. The experiments on toy and real datasets demonstrate that we
can achieve excellent performance without any direct supervision based only on
a rich set of priors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Positional Encoding. (arXiv:2107.02561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jianqiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1">Sameera Ramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1">Simon Lucey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02561">
                                    <div class="article-summary-box-inner">
                                        <span>It is well noted that coordinate based MLPs benefit greatly -- in terms of
preserving high-frequency information -- through the encoding of coordinate
positions as an array of Fourier features. Hitherto, the rationale for the
effectiveness of these positional encodings has been solely studied through a
Fourier lens. In this paper, we strive to broaden this understanding by showing
that alternative non-Fourier embedding functions can indeed be used for
positional encoding. Moreover, we show that their performance is entirely
determined by a trade-off between the stable rank of the embedded matrix and
the distance preservation between embedded coordinates. We further establish
that the now ubiquitous Fourier feature mapping of position is a special case
that fulfills these conditions. Consequently, we present a more general theory
to analyze positional encoding in terms of shifted basis functions. To this
end, we develop the necessary theoretical formulae and empirically verify that
our theoretical claims hold in practice. Codes available at
https://github.com/osiriszjq/Rethinking-positional-encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Theory of the Distortion-Perception Tradeoff in Wasserstein Space. (arXiv:2107.02555v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Freirich_D/0/1/0/all/0/1">Dror Freirich</a>, <a href="http://arxiv.org/find/eess/1/au:+Michaeli_T/0/1/0/all/0/1">Tomer Michaeli</a>, <a href="http://arxiv.org/find/eess/1/au:+Meir_R/0/1/0/all/0/1">Ron Meir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02555">
                                    <div class="article-summary-box-inner">
                                        <span>The lower the distortion of an estimator, the more the distribution of its
outputs generally deviates from the distribution of the signals it attempts to
estimate. This phenomenon, known as the perception-distortion tradeoff, has
captured significant attention in image restoration, where it implies that
fidelity to ground truth images comes at the expense of perceptual quality
(deviation from statistics of natural images). However, despite the increasing
popularity of performing comparisons on the perception-distortion plane, there
remains an important open question: what is the minimal distortion that can be
achieved under a given perception constraint? In this paper, we derive a closed
form expression for this distortion-perception (DP) function for the mean
squared-error (MSE) distortion and the Wasserstein-2 perception index. We prove
that the DP function is always quadratic, regardless of the underlying
distribution. This stems from the fact that estimators on the DP curve form a
geodesic in Wasserstein space. In the Gaussian setting, we further provide a
closed form expression for such estimators. For general distributions, we show
how these estimators can be constructed from the estimators at the two extremes
of the tradeoff: The global MSE minimizer, and a minimizer of the MSE under a
perfect perceptual quality constraint. The latter can be obtained as a
stochastic transformation of the former.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point Cloud Registration using Representative Overlapping Points. (arXiv:2107.02583v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lifa Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dongrui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Changwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Rui Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Fernandez_F/0/1/0/all/0/1">Francisco G&#xf3;mez-Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1">Ninghua Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Ziyong Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02583">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud registration is a fundamental task in robotics and computer
vision. Recently, many learning-based point cloud registration methods based on
correspondences have emerged. However, these methods heavily rely on such
correspondences and meet great challenges with partial overlap. In this paper,
we propose ROPNet, a new deep learning model using Representative Overlapping
Points with discriminative features for registration that transforms
partial-to-partial registration into partial-to-complete registration.
Specifically, we propose a context-guided module which uses an encoder to
extract global features for predicting point overlap score. To better find
representative overlapping points, we use the extracted global features for
coarse alignment. Then, we introduce a Transformer to enrich point features and
remove non-representative points based on point overlap score and feature
matching. A similarity matrix is built in a partial-to-complete mode, and
finally, weighted SVD is adopted to estimate a transformation matrix. Extensive
experiments over ModelNet40 using noisy and partially overlapping point clouds
show that the proposed method outperforms traditional and learning-based
methods, achieving state-of-the-art performance. The code is available at
https://github.com/zhulf0804/ROPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighbor-Vote: Improving Monocular 3D Object Detection through Neighbor Distance Voting. (arXiv:2107.02493v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiaomeng Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiajun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhenxun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanyong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jianmin Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02493">
                                    <div class="article-summary-box-inner">
                                        <span>As cameras are increasingly deployed in new application domains such as
autonomous driving, performing 3D object detection on monocular images becomes
an important task for visual scene understanding. Recent advances on monocular
3D object detection mainly rely on the &#x60;&#x60;pseudo-LiDAR&#x27;&#x27; generation, which
performs monocular depth estimation and lifts the 2D pixels to pseudo 3D
points. However, depth estimation from monocular images, due to its poor
accuracy, leads to inevitable position shift of pseudo-LiDAR points within the
object. Therefore, the predicted bounding boxes may suffer from inaccurate
location and deformed shape. In this paper, we present a novel neighbor-voting
method that incorporates neighbor predictions to ameliorate object detection
from severely deformed pseudo-LiDAR point clouds. Specifically, each feature
point around the object forms their own predictions, and then the &#x60;&#x60;consensus&#x27;&#x27;
is achieved through voting. In this way, we can effectively combine the
neighbors&#x27; predictions with local prediction and achieve more accurate 3D
detection. To further enlarge the difference between the foreground region of
interest (ROI) pseudo-LiDAR points and the background points, we also encode
the ROI prediction scores of 2D foreground pixels into the corresponding
pseudo-LiDAR points. We conduct extensive experiments on the KITTI benchmark to
validate the merits of our proposed method. Our results on the bird&#x27;s eye view
detection outperform the state-of-the-art performance by a large margin,
especially for the &#x60;&#x60;hard&#x27;&#x27; level detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FloorLevel-Net: Recognizing Floor-Level Lines with Height-Attention-Guided Multi-task Learning. (arXiv:2107.02462v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Mengyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wei Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chi-Wing Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02462">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to recognize the position and order of the floor-level lines that
divide adjacent building floors can benefit many applications, for example,
urban augmented reality (AR). This work tackles the problem of locating
floor-level lines in street-view images, using a supervised deep learning
approach. Unfortunately, very little data is available for training such a
network $-$ current street-view datasets contain either semantic annotations
that lack geometric attributes, or rectified facades without perspective
priors. To address this issue, we first compile a new dataset and develop a new
data augmentation scheme to synthesize training samples by harassing (i) the
rich semantics of existing rectified facades and (ii) perspective priors of
buildings in diverse street views. Next, we design FloorLevel-Net, a multi-task
learning network that associates explicit features of building facades and
implicit floor-level lines, along with a height-attention mechanism to help
enforce a vertical ordering of floor-level lines. The generated segmentations
are then passed to a second-stage geometry post-processing to exploit
self-constrained geometric priors for plausible and consistent reconstruction
of floor-level lines. Quantitative and qualitative evaluations conducted on
assorted facades in existing datasets and street views from Google demonstrate
the effectiveness of our approach. Also, we present context-aware image overlay
results and show the potentials of our approach in enriching AR-related
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Robustness of Lane Detection Models to Physical-World Adversarial Attacks in Autonomous Driving. (arXiv:2107.02488v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1">Takami Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qi Alfred Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02488">
                                    <div class="article-summary-box-inner">
                                        <span>After the 2017 TuSimple Lane Detection Challenge, its evaluation based on
accuracy and F1 score has become the de facto standard to measure the
performance of lane detection methods. In this work, we conduct the first
large-scale empirical study to evaluate the robustness of state-of-the-art lane
detection methods under physical-world adversarial attacks in autonomous
driving. We evaluate 4 major types of lane detection approaches with the
conventional evaluation and end-to-end evaluation in autonomous driving
scenarios and then discuss the security proprieties of each lane detection
model. We demonstrate that the conventional evaluation fails to reflect the
robustness in end-to-end autonomous driving scenarios. Our results show that
the most robust model on the conventional metrics is the least robust in the
end-to-end evaluation. Although the competition dataset and its metrics have
played a substantial role in developing performant lane detection methods along
with the rapid development of deep neural networks, the conventional evaluation
is becoming obsolete and the gap between the metrics and practicality is
critical. We hope that our study will help the community make further progress
in building a more comprehensive framework to evaluate lane detection models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embracing the Dark Knowledge: Domain Generalization Using Regularized Knowledge Distillation. (arXiv:2107.02629v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yufei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1">Lap-pui Chau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kot_A/0/1/0/all/0/1">Alex C. Kot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02629">
                                    <div class="article-summary-box-inner">
                                        <span>Though convolutional neural networks are widely used in different tasks, lack
of generalization capability in the absence of sufficient and representative
data is one of the challenges that hinder their practical application. In this
paper, we propose a simple, effective, and plug-and-play training strategy
named Knowledge Distillation for Domain Generalization (KDDG) which is built
upon a knowledge distillation framework with the gradient filter as a novel
regularization term. We find that both the &#x60;&#x60;richer dark knowledge&quot; from the
teacher network, as well as the gradient filter we proposed, can reduce the
difficulty of learning the mapping which further improves the generalization
ability of the model. We also conduct experiments extensively to show that our
framework can significantly improve the generalization capability of deep
neural networks in different tasks including image classification,
segmentation, reinforcement learning by comparing our method with existing
state-of-the-art domain generalization techniques. Last but not the least, we
propose to adopt two metrics to analyze our proposed method in order to better
understand how our proposed method benefits the generalization capability of
deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GCN-Based Linkage Prediction for Face Clusteringon Imbalanced Datasets: An Empirical Study. (arXiv:2107.02477v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Huafeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingjian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fangyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hei_G/0/1/0/all/0/1">Guangyue Hei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_R/0/1/0/all/0/1">Rong Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02477">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, benefiting from the expressivepower of Graph Convolutional
Networks (GCNs),significant breakthroughs have been made in faceclustering.
However, rare attention has been paidto GCN-based clustering on imbalanced
data. Al-though imbalance problem has been extensivelystudied, the impact of
imbalanced data on GCN-based linkage prediction task is quite different,which
would cause problems in two aspects: im-balanced linkage labels and biased
graph represen-tations. The problem of imbalanced linkage labelsis similar to
that in image classification task, but thelatter is a particular problem in
GCN-based clus-tering via linkage prediction. Significantly biasedgraph
representations in training can cause catas-trophic overfitting of a GCN model.
To tacklethese problems, we evaluate the feasibility of thoseexisting methods
for imbalanced image classifica-tion problem on graphs with extensive
experiments,and present a new method to alleviate the imbal-anced labels and
also augment graph representa-tions using a Reverse-Imbalance Weighted
Sam-pling (RIWS) strategy, followed with insightfulanalyses and discussions. A
series of imbalancedbenchmark datasets synthesized from MS-Celeb-1M and
DeepFashion will be openly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Independent Encoder for Deep Hierarchical Unsupervised Image-to-Image Translation. (arXiv:2107.02494v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1">Kai Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yinru Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Minqiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02494">
                                    <div class="article-summary-box-inner">
                                        <span>The main challenges of image-to-image (I2I) translation are to make the
translated image realistic and retain as much information from the source
domain as possible. To address this issue, we propose a novel architecture,
termed as IEGAN, which removes the encoder of each network and introduces an
encoder that is independent of other networks. Compared with previous models,
it embodies three advantages of our model: Firstly, it is more directly and
comprehensively to grasp image information since the encoder no longer receives
loss from generator and discriminator. Secondly, the independent encoder allows
each network to focus more on its own goal which makes the translated image
more realistic. Thirdly, the reduction in the number of encoders performs more
unified image representation. However, when the independent encoder applies two
down-sampling blocks, it&#x27;s hard to extract semantic information. To tackle this
problem, we propose deep and shallow information space containing
characteristic and semantic information, which can guide the model to translate
high-quality images under the task with significant shape or texture change. We
compare IEGAN with other previous models, and conduct researches on semantic
information consistency and component ablation at the same time. These
experiments show the superiority and effectiveness of our architecture. Our
code is published on: https://github.com/Elvinky/IEGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VolNet: Estimating Human Body Part Volumes from a Single RGB Image. (arXiv:2107.02259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leinen_F/0/1/0/all/0/1">Fabian Leinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cozzolino_V/0/1/0/all/0/1">Vittorio Cozzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Torsten Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02259">
                                    <div class="article-summary-box-inner">
                                        <span>Human body volume estimation from a single RGB image is a challenging problem
despite minimal attention from the research community. However VolNet, an
architecture leveraging 2D and 3D pose estimation, body part segmentation and
volume regression extracted from a single 2D RGB image combined with the
subject&#x27;s body height can be used to estimate the total body volume. VolNet is
designed to predict the 2D and 3D pose as well as the body part segmentation in
intermediate tasks. We generated a synthetic, large-scale dataset of
photo-realistic images of human bodies with a wide range of body shapes and
realistic poses called SURREALvols. By using Volnet and combining multiple
stacked hourglass networks together with ResNeXt, our model correctly predicted
the volume in ~82% of cases with a 10% tolerance threshold. This is a
considerable improvement compared to state-of-the-art solutions such as BodyNet
with only a ~38% success rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity. (arXiv:2107.02306v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vysogorets_A/0/1/0/all/0/1">Artem Vysogorets</a>, <a href="http://arxiv.org/find/cs/1/au:+Kempe_J/0/1/0/all/0/1">Julia Kempe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02306">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network pruning is a fruitful area of research with surging interest
in high sparsity regimes. Benchmarking in this domain heavily relies on
faithful representation of the sparsity of subnetworks, which has been
traditionally computed as the fraction of removed connections (direct
sparsity). This definition, however, fails to recognize unpruned parameters
that detached from input or output layers of underlying subnetworks,
potentially underestimating actual effective sparsity: the fraction of
inactivated connections. While this effect might be negligible for moderately
pruned networks (up to 10-100 compression rates), we find that it plays an
increasing role for thinner subnetworks, greatly distorting comparison between
different pruning algorithms. For example, we show that effective compression
of a randomly pruned LeNet-300-100 can be orders of magnitude larger than its
direct counterpart, while no discrepancy is ever observed when using SynFlow
for pruning [Tanaka et al., 2020]. In this work, we adopt the lens of effective
sparsity to reevaluate several recent pruning algorithms on common benchmark
architectures (e.g., LeNet-300-100, VGG-19, ResNet-18) and discover that their
absolute and relative performance changes dramatically in this new and more
appropriate framework. To aim for effective, rather than direct, sparsity, we
develop a low-cost extension to most pruning algorithms. Further, equipped with
effective sparsity as a reference frame, we partially reconfirm that random
pruning with appropriate sparsity allocation across layers performs as well or
better than more sophisticated algorithms for pruning at initialization [Su et
al., 2020]. In response to this observation, using a simple analogy of pressure
distribution in coupled cylinders from physics, we design novel layerwise
sparsity quotas that outperform all existing baselines in the context of random
pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A visual introduction to Gaussian Belief Propagation. (arXiv:2107.02308v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ortiz_J/0/1/0/all/0/1">Joseph Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_T/0/1/0/all/0/1">Talfan Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1">Andrew J. Davison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02308">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we present a visual introduction to Gaussian Belief
Propagation (GBP), an approximate probabilistic inference algorithm that
operates by passing messages between the nodes of arbitrarily structured factor
graphs. A special case of loopy belief propagation, GBP updates rely only on
local information and will converge independently of the message schedule. Our
key argument is that, given recent trends in computing hardware, GBP has the
right computational properties to act as a scalable distributed probabilistic
inference framework for future machine learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoReD: Generalizing Fake Media Detection with Continual Representation using Distillation. (arXiv:2107.02408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02408">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, artificial intelligence research has made
tremendous strides, but it still heavily relies on fixed datasets in stationary
environments. Continual learning is a growing field of research that examines
how AI systems can learn sequentially from a continuous stream of linked data
in the same way that biological systems do. Simultaneously, fake media such as
deepfakes and synthetic face images have emerged as significant to current
multimedia technologies. Recently, numerous method has been proposed which can
detect deepfakes with high accuracy. However, they suffer significantly due to
their reliance on fixed datasets in limited evaluation settings. Therefore, in
this work, we apply continuous learning to neural networks&#x27; learning dynamics,
emphasizing its potential to increase data efficiency significantly. We propose
Continual Representation using Distillation (CoReD) method that employs the
concept of Continual Learning (CoL), Representation Learning (ReL), and
Knowledge Distillation (KD). We design CoReD to perform sequential domain
adaptation tasks on new deepfake and GAN-generated synthetic face datasets,
while effectively minimizing the catastrophic forgetting in a teacher-student
model setting. Our extensive experimental results demonstrate that our method
is efficient at domain adaptation to detect low-quality deepfakes videos and
GAN-generated images from several datasets, outperforming the-state-of-art
baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adversarial Training incorporating Forgery Attention for Image Forgery Localization. (arXiv:2107.02434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuo_L/0/1/0/all/0/1">Long Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02434">
                                    <div class="article-summary-box-inner">
                                        <span>Image editing techniques enable people to modify the content of an image
without leaving visual traces and thus may cause serious security risks. Hence
the detection and localization of these forgeries become quite necessary and
challenging. Furthermore, unlike other tasks with extensive data, there is
usually a lack of annotated forged images for training due to annotation
difficulties. In this paper, we propose a self-adversarial training strategy
and a reliable coarse-to-fine network that utilizes a self-attention mechanism
to localize forged regions in forgery images. The self-attention module is
based on a Channel-Wise High Pass Filter block (CW-HPF). CW-HPF leverages
inter-channel relationships of features and extracts noise features by high
pass filters. Based on the CW-HPF, a self-attention mechanism, called forgery
attention, is proposed to capture rich contextual dependencies of intrinsic
inconsistency extracted from tampered regions. Specifically, we append two
types of attention modules on top of CW-HPF respectively to model internal
interdependencies in spatial dimension and external dependencies among
channels. We exploit a coarse-to-fine network to enhance the noise
inconsistency between original and tampered regions. More importantly, to
address the issue of insufficient training data, we design a self-adversarial
training strategy that expands training data dynamically to achieve more robust
performance. Specifically, in each training iteration, we perform adversarial
attacks against our network to generate adversarial examples and train our
model on them. Extensive experimental results demonstrate that our proposed
algorithm steadily outperforms state-of-the-art methods by a clear margin in
different benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UACANet: Uncertainty Augmented Context Attention for Polyp Semgnetaion. (arXiv:2107.02368v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taehun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyemin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Daijin Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02368">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Uncertainty Augmented Context Attention network (UACANet) for
polyp segmentation which consider a uncertain area of the saliency map. We
construct a modified version of U-Net shape network with additional encoder and
decoder and compute a saliency map in each bottom-up stream prediction module
and propagate to the next prediction module. In each prediction module,
previously predicted saliency map is utilized to compute foreground, background
and uncertain area map and we aggregate the feature map with three area maps
for each representation. Then we compute the relation between each
representation and each pixel in the feature map. We conduct experiments on
five popular polyp segmentation benchmarks, Kvasir, CVC-ClinicDB, ETIS,
CVC-ColonDB and CVC-300, and achieve state-of-the-art performance. Especially,
we achieve 76.6% mean Dice on ETIS dataset which is 13.8% improvement compared
to the previous state-of-the-art method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of deep learning-based image super-resolution on binary signal detection. (arXiv:2107.02338v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xiaohui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Kelkar_V/0/1/0/all/0/1">Varun A. Kelkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Granstedt_J/0/1/0/all/0/1">Jason Granstedt</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hua Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Anastasio_M/0/1/0/all/0/1">Mark A. Anastasio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02338">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based image super-resolution (DL-SR) has shown great promise in
medical imaging applications. To date, most of the proposed methods for DL-SR
have only been assessed by use of traditional measures of image quality (IQ)
that are commonly employed in the field of computer vision. However, the impact
of these methods on objective measures of image quality that are relevant to
medical imaging tasks remains largely unexplored. In this study, we investigate
the impact of DL-SR methods on binary signal detection performance. Two popular
DL-SR methods, the super-resolution convolutional neural network (SRCNN) and
the super-resolution generative adversarial network (SRGAN), were trained by
use of simulated medical image data. Binary signal-known-exactly with
background-known-statistically (SKE/BKS) and signal-known-statistically with
background-known-statistically (SKS/BKS) detection tasks were formulated.
Numerical observers, which included a neural network-approximated ideal
observer and common linear numerical observers, were employed to assess the
impact of DL-SR on task performance. The impact of the complexity of the DL-SR
network architectures on task-performance was quantified. In addition, the
utility of DL-SR for improving the task-performance of sub-optimal observers
was investigated. Our numerical experiments confirmed that, as expected, DL-SR
could improve traditional measures of IQ. However, for many of the study
designs considered, the DL-SR methods provided little or no improvement in task
performance and could even degrade it. It was observed that DL-SR could improve
the task-performance of sub-optimal observers under certain conditions. The
presented study highlights the urgent need for the objective assessment of
DL-SR methods and suggests avenues for improving their efficacy in medical
imaging applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Mixture Models with Expectation-Maximization for End-to-end Deep Clustering. (arXiv:2107.02453v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tissera_D/0/1/0/all/0/1">Dumindu Tissera</a>, <a href="http://arxiv.org/find/cs/1/au:+Vithanage_K/0/1/0/all/0/1">Kasun Vithanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijesinghe_R/0/1/0/all/0/1">Rukshan Wijesinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1">Alex Xavier</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasena_S/0/1/0/all/0/1">Sanath Jayasena</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_S/0/1/0/all/0/1">Subha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigo_R/0/1/0/all/0/1">Ranga Rodrigo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02453">
                                    <div class="article-summary-box-inner">
                                        <span>Any clustering algorithm must synchronously learn to model the clusters and
allocate data to those clusters in the absence of labels. Mixture model-based
methods model clusters with pre-defined statistical distributions and allocate
data to those clusters based on the cluster likelihoods. They iteratively
refine those distribution parameters and member assignments following the
Expectation-Maximization (EM) algorithm. However, the cluster representability
of such hand-designed distributions that employ a limited amount of parameters
is not adequate for most real-world clustering tasks. In this paper, we realize
mixture model-based clustering with a neural network where the final layer
neurons, with the aid of an additional transformation, approximate cluster
distribution outputs. The network parameters pose as the parameters of those
distributions. The result is an elegant, much-generalized representation of
clusters than a restricted mixture of hand-designed distributions. We train the
network end-to-end via batch-wise EM iterations where the forward pass acts as
the E-step and the backward pass acts as the M-step. In image clustering, the
mixture-based EM objective can be used as the clustering objective along with
existing representation learning methods. In particular, we show that when
mixture-EM optimization is fused with consistency optimization, it improves the
sole consistency optimization performance in clustering. Our trained networks
outperform single-stage deep clustering methods that still depend on k-means,
with unsupervised classification accuracy of 63.8% in STL10, 58% in CIFAR10,
25.9% in CIFAR100, and 98.9% in MNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Double-Uncertainty Assisted Spatial and Temporal Regularization Weighting for Learning-based Registration. (arXiv:2107.02433v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">Donghuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jiangpeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagadeesan_J/0/1/0/all/0/1">Jayender Jagadeesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wells_W/0/1/0/all/0/1">William Wells III</a>, <a href="http://arxiv.org/find/cs/1/au:+Frisken_S/0/1/0/all/0/1">Sarah Frisken</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kai Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_R/0/1/0/all/0/1">Raymond Kai-yu Tong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02433">
                                    <div class="article-summary-box-inner">
                                        <span>In order to tackle the difficulty associated with the ill-posed nature of the
image registration problem, researchers use regularization to constrain the
solution space. For most learning-based registration approaches, the
regularization usually has a fixed weight and only constrains the spatial
transformation. Such convention has two limitations: (1) The regularization
strength of a specific image pair should be associated with the content of the
images, thus the &#x60;&#x60;one value fits all&#x27;&#x27; scheme is not ideal; (2) Only spatially
regularizing the transformation (but overlooking the temporal consistency of
different estimations) may not be the best strategy to cope with the
ill-posedness. In this study, we propose a mean-teacher based registration
framework. This framework incorporates an additional \textit{temporal
regularization} term by encouraging the teacher model&#x27;s temporal ensemble
prediction to be consistent with that of the student model. At each training
step, it also automatically adjusts the weights of the \textit{spatial
regularization} and the \textit{temporal regularization} by taking account of
the transformation uncertainty and appearance uncertainty derived from the
perturbed teacher model. We perform experiments on multi- and uni-modal
registration tasks, and the results show that our strategy outperforms the
traditional and learning-based benchmark methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NRST: Non-rigid Surface Tracking from Monocular Video. (arXiv:2107.02407v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1">Marc Habermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weipeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhodin_H/0/1/0/all/0/1">Helge Rhodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1">Michael Zollhoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pons_Moll_G/0/1/0/all/0/1">Gerard Pons-Moll</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02407">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an efficient method for non-rigid surface tracking from monocular
RGB videos. Given a video and a template mesh, our algorithm sequentially
registers the template non-rigidly to each frame. We formulate the per-frame
registration as an optimization problem that includes a novel texture term
specifically tailored towards tracking objects with uniform texture but
fine-scale structure, such as the regular micro-structural patterns of fabric.
Our texture term exploits the orientation information in the micro-structures
of the objects, e.g., the yarn patterns of fabrics. This enables us to
accurately track uniformly colored materials that have these high frequency
micro-structures, for which traditional photometric terms are usually less
effective. The results demonstrate the effectiveness of our method on both
general textured non-rigid objects and monochromatic fabrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting Vehicle Detector to Target Domain by Adversarial Prediction Alignment. (arXiv:2107.02411v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koga_Y/0/1/0/all/0/1">Yohei Koga</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyazaki_H/0/1/0/all/0/1">Hiroyuki Miyazaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Shibasaki_R/0/1/0/all/0/1">Ryosuke Shibasaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02411">
                                    <div class="article-summary-box-inner">
                                        <span>While recent advancement of domain adaptation techniques is significant, most
of methods only align a feature extractor and do not adapt a classifier to
target domain, which would be a cause of performance degradation. We propose
novel domain adaptation technique for object detection that aligns prediction
output space. In addition to feature alignment, we aligned predictions of
locations and class confidences of our vehicle detector for satellite images by
adversarial training. The proposed method significantly improved AP score by
over 5%, which shows effectivity of our method for object detection tasks in
satellite images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LightFuse: Lightweight CNN based Dual-exposure Fusion. (arXiv:2107.02299v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadid_Pecht_O/0/1/0/all/0/1">Orly Yadid-Pecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02299">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (DCNN) aided high dynamic range (HDR)
imaging recently received a lot of attention. The quality of DCNN generated HDR
images have overperformed the traditional counterparts. However, DCNN is prone
to be computationally intensive and power-hungry. To address the challenge, we
propose LightFuse, a light-weight CNN-based algorithm for extreme dual-exposure
image fusion, which can be implemented on various embedded computing platforms
with limited power and hardware resources. Two sub-networks are utilized: a
GlobalNet (G) and a DetailNet (D). The goal of G is to learn the global
illumination information on the spatial dimension, whereas D aims to enhance
local details on the channel dimension. Both G and D are based solely on
depthwise convolution (D Conv) and pointwise convolution (P Conv) to reduce
required parameters and computations. Experimental results display that the
proposed technique could generate HDR images with plausible details in
extremely exposed regions. Our PSNR score exceeds the other state-of-the-art
approaches by 1.2 to 1.6 times and achieves 1.4 to 20 times FLOP and parameter
reduction compared with others.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Ensemble Noise-Robust K-fold Cross-Validation Selection Method for Noisy Labels. (arXiv:2107.02347v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalander_M/0/1/0/all/0/1">Marcus Kalander</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chanfei Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Lujia Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02347">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of training robust and accurate deep neural networks
(DNNs) when subject to various proportions of noisy labels. Large-scale
datasets tend to contain mislabeled samples that can be memorized by DNNs,
impeding the performance. With appropriate handling, this degradation can be
alleviated. There are two problems to consider: how to distinguish clean
samples and how to deal with noisy samples. In this paper, we present Ensemble
Noise-robust K-fold Cross-Validation Selection (E-NKCVS) to effectively select
clean samples from noisy data, solving the first problem. For the second
problem, we create a new pseudo label for any sample determined to have an
uncertain or likely corrupt label. E-NKCVS obtains multiple predicted labels
for each sample and the entropy of these labels is used to tune the weight
given to the pseudo label and the given label. Theoretical analysis and
extensive verification of the algorithms in the noisy label setting are
provided. We evaluate our approach on various image and text classification
tasks where the labels have been manually corrupted with different noise
ratios. Additionally, two large real-world noisy datasets are also used,
Clothing-1M and WebVision. E-NKCVS is empirically shown to be highly tolerant
to considerable proportions of label noise and has a consistent improvement
over state-of-the-art methods. Especially on more difficult datasets with
higher noise ratios, we can achieve a significant improvement over the
second-best model. Moreover, our proposed approach can easily be integrated
into existing DNN methods to improve their robustness against label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polarized skylight orientation determination artificial neural network. (arXiv:2107.02328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Huaju Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Hongyang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Ke Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xinbo Lv</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02328">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an artificial neural network to determine orientation
using polarized skylight. This neural network has specific dilated convolution,
which can extract light intensity information of different polarization
directions. Then, the degree of polarization (DOP) and angle of polarization
(AOP) are directly extracted in the network. In addition, the exponential
function encoding of orientation is designed as the network output, which can
better reflect the insect&#x27;s encoding of polarization information, and improve
the accuracy of orientation determination. Finally, training and testing were
conducted on a public polarized skylight navigation dataset, and the
experimental results proved the stability and effectiveness of the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSE Loss with Outlying Label for Imbalanced Classification. (arXiv:2107.02393v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kato_S/0/1/0/all/0/1">Sota Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Hotta_K/0/1/0/all/0/1">Kazuhiro Hotta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02393">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose mean squared error (MSE) loss with outlying label
for class imbalanced classification. Cross entropy (CE) loss, which is widely
used for image recognition, is learned so that the probability value of true
class is closer to one by back propagation. However, for imbalanced datasets,
the learning is insufficient for the classes with a small number of samples.
Therefore, we propose a novel classification method using the MSE loss that can
be learned the relationships of all classes no matter which image is input.
Unlike CE loss, MSE loss is possible to equalize the number of back propagation
for all classes and to learn the feature space considering the relationships
between classes as metric learning. Furthermore, instead of the usual one-hot
teacher label, we use a novel teacher label that takes the number of class
samples into account. This induces the outlying label which depends on the
number of samples in each class, and the class with a small number of samples
has outlying margin in a feature space. It is possible to create the feature
space for separating high-difficulty classes and low-difficulty classes. By the
experiments on imbalanced classification and semantic segmentation, we
confirmed that the proposed method was much improved in comparison with
standard CE loss and conventional methods, even though only the loss and
teacher labels were changed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering. (arXiv:2107.02331v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02331">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning promises to alleviate the massive data needs of supervised
machine learning: it has successfully improved sample efficiency by an order of
magnitude on traditional tasks like topic classification and object
recognition. However, we uncover a striking contrast to this promise: across 5
models and 4 datasets on the task of visual question answering, a wide variety
of active learning approaches fail to outperform random selection. To
understand this discrepancy, we profile 8 active learning methods on a
per-example basis, and identify the problem as collective outliers -- groups of
examples that active learning methods prefer to acquire but models fail to
learn (e.g., questions that ask about text in images or require external
knowledge). Through systematic ablation experiments and qualitative
visualizations, we verify that collective outliers are a general phenomenon
responsible for degrading pool-based active learning. Notably, we show that
active learning sample efficiency increases significantly as the number of
collective outliers in the active learning pool decreases. We conclude with a
discussion and prescriptive recommendations for mitigating the effects of these
outliers in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphological Classification of Galaxies in S-PLUS using an Ensemble of Convolutional Networks. (arXiv:2107.02287v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Cardoso_N/0/1/0/all/0/1">N. M. Cardoso</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Schwarz_G/0/1/0/all/0/1">G. B. O. Schwarz</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Dias_L/0/1/0/all/0/1">L. O. Dias</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bom_C/0/1/0/all/0/1">C. R. Bom</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sodre_L/0/1/0/all/0/1">L. Sodr&#xe9; Jr.</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Oliveira_C/0/1/0/all/0/1">C. Mendes de Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02287">
                                    <div class="article-summary-box-inner">
                                        <span>The universe is composed of galaxies that have diverse shapes. Once the
structure of a galaxy is determined, it is possible to obtain important
information about its formation and evolution. Morphologically classifying
galaxies means cataloging them according to their visual appearance and the
classification is linked to the physical properties of the galaxy. A
morphological classification made through visual inspection is subject to
biases introduced by subjective observations made by human volunteers. For this
reason, systematic, objective and easily reproducible classification of
galaxies has been gaining importance since the astronomer Edwin Hubble created
his famous classification method. In this work, we combine accurate visual
classifications of the Galaxy Zoo project with \emph {Deep Learning} methods.
The goal is to find an efficient technique at human performance level
classification, but in a systematic and automatic way, for classification of
elliptical and spiral galaxies. For this, a neural network model was created
through an Ensemble of four other convolutional models, allowing a greater
accuracy in the classification than what would be obtained with any one
individual. Details of the individual models and improvements made are also
described. The present work is entirely based on the analysis of images (not
parameter tables) from DR1 (www.datalab.noao.edu) of the Southern Photometric
Local Universe Survey (S-PLUS). In terms of classification, we achieved, with
the Ensemble, an accuracy of $\approx 99 \%$ in the test sample (using
pre-trained networks).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-TCL: Semi-Supervised Track Contrastive Representation Learning. (arXiv:2107.02396v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingze Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02396">
                                    <div class="article-summary-box-inner">
                                        <span>Online tracking of multiple objects in videos requires strong capacity of
modeling and matching object appearances. Previous methods for learning
appearance embedding mostly rely on instance-level matching without considering
the temporal continuity provided by videos. We design a new instance-to-track
matching objective to learn appearance embedding that compares a candidate
detection to the embedding of the tracks persisted in the tracker. It enables
us to learn not only from videos labeled with complete tracks, but also
unlabeled or partially labeled videos. We implement this learning objective in
a unified form following the spirit of constrastive loss. Experiments on
multiple object tracking datasets demonstrate that our method can effectively
learning discriminative appearance embeddings in a semi-supervised fashion and
outperform state of the art methods on representative benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation via CycleGAN for Retina Segmentation in Optical Coherence Tomography. (arXiv:2107.02345v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_R/0/1/0/all/0/1">Ricky Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_T/0/1/0/all/0/1">Timothy T. Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_G/0/1/0/all/0/1">Gavin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1">Da Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarunic_M/0/1/0/all/0/1">Marinko V. Sarunic</a>, <a href="http://arxiv.org/find/eess/1/au:+Beg_M/0/1/0/all/0/1">Mirza Faisal Beg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02345">
                                    <div class="article-summary-box-inner">
                                        <span>With the FDA approval of Artificial Intelligence (AI) for point-of-care
clinical diagnoses, model generalizability is of the utmost importance as
clinical decision-making must be domain-agnostic. A method of tackling the
problem is to increase the dataset to include images from a multitude of
domains; while this technique is ideal, the security requirements of medical
data is a major limitation. Additionally, researchers with developed tools
benefit from the addition of open-sourced data, but are limited by the
difference in domains. Herewith, we investigated the implementation of a
Cycle-Consistent Generative Adversarial Networks (CycleGAN) for the domain
adaptation of Optical Coherence Tomography (OCT) volumes. This study was done
in collaboration with the Biomedical Optics Research Group and Functional &amp;
Anatomical Imaging &amp; Shape Analysis Lab at Simon Fraser University. In this
study, we investigated a learning-based approach of adapting the domain of a
publicly available dataset, UK Biobank dataset (UKB). To evaluate the
performance of domain adaptation, we utilized pre-existing retinal layer
segmentation tools developed on a different set of RETOUCH OCT data. This study
provides insight on state-of-the-art tools for domain adaptation compared to
traditional processing techniques as well as a pipeline for adapting publicly
available retinal data to the domains previously used by our collaborators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated age-related macular degeneration area estimation -- first results. (arXiv:2107.02211v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Peciulis_R/0/1/0/all/0/1">Rokas Pe&#x10d;iulis</a>, <a href="http://arxiv.org/find/eess/1/au:+Lukosevicius_M/0/1/0/all/0/1">Mantas Luko&#x161;evi&#x10d;ius</a>, <a href="http://arxiv.org/find/eess/1/au:+Krisciukaitis_A/0/1/0/all/0/1">Algimantas Kri&#x161;&#x10d;iukaitis</a>, <a href="http://arxiv.org/find/eess/1/au:+Petrolis_R/0/1/0/all/0/1">Robertas Petrolis</a>, <a href="http://arxiv.org/find/eess/1/au:+Buteikiene_D/0/1/0/all/0/1">Dovil&#x117; Buteikien&#x117;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02211">
                                    <div class="article-summary-box-inner">
                                        <span>This work aims to research an automatic method for detecting Age-related
Macular Degeneration (AMD) lesions in RGB eye fundus images. For this, we align
invasively obtained eye fundus contrast images (the &quot;golden standard&quot;
diagnostic) to the RGB ones and use them to hand-annotate the lesions. This is
done using our custom-made tool. Using the data, we train and test five
different convolutional neural networks: a custom one to classify healthy and
AMD-affected eye fundi, and four well-known networks: ResNet50, ResNet101,
MobileNetV3, and UNet to segment (localize) the AMD lesions in the affected eye
fundus images. We achieve 93.55% accuracy or 69.71% Dice index as the
preliminary best results in segmentation with MobileNetV3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolution for Re-ranking in Person Re-identification. (arXiv:2107.02220v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weihua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02220">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, deep learning is widely applied to extract features for similarity
computation in person re-identification (re-ID) and have achieved great
success. However, due to the non-overlapping between training and testing IDs,
the difference between the data used for model training and the testing data
makes the performance of learned feature degraded during testing. Hence,
re-ranking is proposed to mitigate this issue and various algorithms have been
developed. However, most of existing re-ranking methods focus on replacing the
Euclidean distance with sophisticated distance metrics, which are not friendly
to downstream tasks and hard to be used for fast retrieval of massive data in
real applications. In this work, we propose a graph-based re-ranking method to
improve learned features while still keeping Euclidean distance as the
similarity metric. Inspired by graph convolution networks, we develop an
operator to propagate features over an appropriate graph. Since graph is the
essential key for the propagation, two important criteria are considered for
designing the graph, and three different graphs are explored accordingly.
Furthermore, a simple yet effective method is proposed to generate a profile
vector for each tracklet in videos, which helps extend our method to video
re-ID. Extensive experiments on three benchmark data sets, e.g., Market-1501,
Duke, and MARS, demonstrate the effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Histogram of Cell Types: Deep Learning for Automated Bone Marrow Cytology. (arXiv:2107.02293v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tayebi_R/0/1/0/all/0/1">Rohollah Moosavi Tayebi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mu_Y/0/1/0/all/0/1">Youqing Mu</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehkharghanian_T/0/1/0/all/0/1">Taher Dehkharghanian</a>, <a href="http://arxiv.org/find/eess/1/au:+Ross_C/0/1/0/all/0/1">Catherine Ross</a>, <a href="http://arxiv.org/find/eess/1/au:+Sur_M/0/1/0/all/0/1">Monalisa Sur</a>, <a href="http://arxiv.org/find/eess/1/au:+Foley_R/0/1/0/all/0/1">Ronan Foley</a>, <a href="http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1">Hamid R. Tizhoosh</a>, <a href="http://arxiv.org/find/eess/1/au:+Campbell_C/0/1/0/all/0/1">Clinton JV Campbell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02293">
                                    <div class="article-summary-box-inner">
                                        <span>Bone marrow cytology is required to make a hematological diagnosis,
influencing critical clinical decision points in hematology. However, bone
marrow cytology is tedious, limited to experienced reference centers and
associated with high inter-observer variability. This may lead to a delayed or
incorrect diagnosis, leaving an unmet need for innovative supporting
technologies. We have developed the first ever end-to-end deep learning-based
technology for automated bone marrow cytology. Starting with a bone marrow
aspirate digital whole slide image, our technology rapidly and automatically
detects suitable regions for cytology, and subsequently identifies and
classifies all bone marrow cells in each region. This collective
cytomorphological information is captured in a novel representation called
Histogram of Cell Types (HCT) quantifying bone marrow cell class probability
distribution and acting as a cytological &quot;patient fingerprint&quot;. The approach
achieves high accuracy in region detection (0.97 accuracy and 0.99 ROC AUC),
and cell detection and cell classification (0.75 mAP, 0.78 F1-score,
Log-average miss rate of 0.31). HCT has potential to revolutionize
hematopathology diagnostic workflows, leading to more cost-effective, accurate
diagnosis and opening the door to precision medicine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransformerFusion: Monocular RGB Scene Reconstruction using Transformers. (arXiv:2107.02191v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bozic_A/0/1/0/all/0/1">Alja&#x17e; Bo&#x17e;i&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Palafox_P/0/1/0/all/0/1">Pablo Palafox</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Angela Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02191">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce TransformerFusion, a transformer-based 3D scene reconstruction
approach. From an input monocular RGB video, the video frames are processed by
a transformer network that fuses the observations into a volumetric feature
grid representing the scene; this feature grid is then decoded into an implicit
3D scene representation. Key to our approach is the transformer architecture
that enables the network to learn to attend to the most relevant image frames
for each 3D location in the scene, supervised only by the scene reconstruction
task. Features are fused in a coarse-to-fine fashion, storing fine-level
features only where needed, requiring lower memory storage and enabling fusion
at interactive rates. The feature grid is then decoded to a higher-resolution
scene reconstruction, using an MLP-based surface occupancy prediction from
interpolated coarse-to-fine 3D features. Our approach results in an accurate
surface reconstruction, outperforming state-of-the-art multi-view stereo depth
estimation methods, fully-convolutional 3D reconstruction approaches, and
approaches using LSTM- or GRU-based recurrent networks for video sequence
fusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Fusion Vision Transformer Fine-Grained Visual Categorization. (arXiv:2107.02341v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaohan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02341">
                                    <div class="article-summary-box-inner">
                                        <span>The core for tackling the fine-grained visual categorization (FGVC) is to
learn subtleyet discriminative features. Most previous works achieve this by
explicitly selecting thediscriminative parts or integrating the attention
mechanism via CNN-based approaches.However, these methods enhance the
computational complexity and make the modeldominated by the regions containing
the most of the objects. Recently, vision trans-former (ViT) has achieved SOTA
performance on general image recognition tasks. Theself-attention mechanism
aggregates and weights the information from all patches to theclassification
token, making it perfectly suitable for FGVC. Nonetheless, the classifi-cation
token in the deep layer pays more attention to the global information,
lackingthe local and low-level features that are essential for FGVC. In this
work, we proposea novel pure transformer-based framework Feature Fusion Vision
Transformer (FFVT)where we aggregate the important tokens from each transformer
layer to compensate thelocal, low-level and middle-level information. We design
a novel token selection mod-ule called mutual attention weight selection (MAWS)
to guide the network effectivelyand efficiently towards selecting
discriminative tokens without introducing extra param-eters. We verify the
effectiveness of FFVT on three benchmarks where FFVT achievesthe
state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor Segmentation and Radiogenomic Classification. (arXiv:2107.02314v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baid_U/0/1/0/all/0/1">Ujjwal Baid</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghodasara_S/0/1/0/all/0/1">Satyam Ghodasara</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1">Michel Bilello</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_S/0/1/0/all/0/1">Suyash Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Calabrese_E/0/1/0/all/0/1">Evan Calabrese</a>, <a href="http://arxiv.org/find/cs/1/au:+Colak_E/0/1/0/all/0/1">Errol Colak</a>, <a href="http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1">Keyvan Farahani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1">Jayashree Kalpathy-Cramer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamura_F/0/1/0/all/0/1">Felipe C. Kitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Pati_S/0/1/0/all/0/1">Sarthak Pati</a>, <a href="http://arxiv.org/find/cs/1/au:+Prevedello_L/0/1/0/all/0/1">Luciano M. Prevedello</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudie_J/0/1/0/all/0/1">Jeffrey D. Rudie</a>, <a href="http://arxiv.org/find/cs/1/au:+Sako_C/0/1/0/all/0/1">Chiharu Sako</a>, <a href="http://arxiv.org/find/cs/1/au:+Shinohara_R/0/1/0/all/0/1">Russell T. Shinohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergquist_T/0/1/0/all/0/1">Timothy Bergquist</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_R/0/1/0/all/0/1">Rong Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Eddy_J/0/1/0/all/0/1">James Eddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Elliott_J/0/1/0/all/0/1">Julia Elliott</a>, <a href="http://arxiv.org/find/cs/1/au:+Reade_W/0/1/0/all/0/1">Walter Reade</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaffter_T/0/1/0/all/0/1">Thomas Schaffter</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Thomas Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jiaxin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Annotators_B/0/1/0/all/0/1">BraTS Annotators</a>, <a href="http://arxiv.org/find/cs/1/au:+Davatzikos_C/0/1/0/all/0/1">Christos Davatzikos</a>, <a href="http://arxiv.org/find/cs/1/au:+Mongan_J/0/1/0/all/0/1">John Mongan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hess_C/0/1/0/all/0/1">Christopher Hess</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Soonmee Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Villanueva_Meyer_J/0/1/0/all/0/1">Javier Villanueva-Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Freymann_J/0/1/0/all/0/1">John B. Freymann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirby_J/0/1/0/all/0/1">Justin S. Kirby</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiestler_B/0/1/0/all/0/1">Benedikt Wiestler</a>, <a href="http://arxiv.org/find/cs/1/au:+Crivellaro_P/0/1/0/all/0/1">Priscila Crivellaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Colen_R/0/1/0/all/0/1">Rivka R.Colen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotrotsou_A/0/1/0/all/0/1">Aikaterini Kotrotsou</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcus_D/0/1/0/all/0/1">Daniel Marcus</a>, <a href="http://arxiv.org/find/cs/1/au:+Milchenko_M/0/1/0/all/0/1">Mikhail Milchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazeri_A/0/1/0/all/0/1">Arash Nazeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathallah_Shaykh_H/0/1/0/all/0/1">Hassan Fathallah-Shaykh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiest_R/0/1/0/all/0/1">Roland Wiest</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakab_A/0/1/0/all/0/1">Andras Jakab</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1">Marc-Andre Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1">Abhishek Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1">Bjoern Menze</a>, <a href="http://arxiv.org/find/cs/1/au:+Flanders_A/0/1/0/all/0/1">Adam E. Flanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1">Spyridon Bakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02314">
                                    <div class="article-summary-box-inner">
                                        <span>The BraTS 2021 challenge celebrates its 10th anniversary and is jointly
organized by the Radiological Society of North America (RSNA), the American
Society of Neuroradiology (ASNR), and the Medical Image Computing and Computer
Assisted Interventions (MICCAI) society. Since its inception, BraTS has been
focusing on being a common benchmarking venue for brain glioma segmentation
algorithms, with well-curated multi-institutional multi-parametric magnetic
resonance imaging (mpMRI) data. Gliomas are the most common primary
malignancies of the central nervous system, with varying degrees of
aggressiveness and prognosis. The RSNA-ASNR-MICCAI BraTS 2021 challenge targets
the evaluation of computational algorithms assessing the same tumor
compartmentalization, as well as the underlying tumor&#x27;s molecular
characterization, in pre-operative baseline mpMRI data from 2,000 patients.
Specifically, the two tasks that BraTS 2021 focuses on are: a) the segmentation
of the histologically distinct brain tumor sub-regions, and b) the
classification of the tumor&#x27;s O[6]-methylguanine-DNA methyltransferase (MGMT)
promoter methylation status. The performance evaluation of all participating
algorithms in BraTS 2021 will be conducted through the Sage Bionetworks Synapse
platform (Task 1) and Kaggle (Task 2), concluding in distributing to the top
ranked participants monetary awards of $60,000 collectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1">Kirill Shevkunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1">Liudmila Prokhorenkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.02445">
                                    <div class="article-summary-box-inner">
                                        <span>Various non-trivial spaces are becoming popular for embedding structured data
such as graphs, texts, or images. Following spherical and hyperbolic spaces,
more general product spaces have been proposed. However, searching for the best
configuration of product space is a resource-intensive procedure, which reduces
the practical applicability of the idea. We generalize the concept of product
space and introduce an overlapping space that does not have the configuration
search problem. The main idea is to allow subsets of coordinates to be shared
between spaces of different types (Euclidean, hyperbolic, spherical). As a
result, parameter optimization automatically learns the optimal configuration.
Additionally, overlapping spaces allow for more compact representations since
their geometry is more complex. Our experiments confirm that overlapping spaces
outperform the competitors in graph embedding tasks. Here, we consider both
distortion setup, where the aim is to preserve distances, and ranking setup,
where the relative order should be preserved. The proposed method effectively
solves the problem and outperforms the competitors in both settings. We also
perform an empirical analysis in a realistic information retrieval task, where
we compare all spaces by incorporating them into DSSM. In this case, the
proposed overlapping space consistently achieves nearly optimal results without
any configuration tuning. This allows for reducing training time, which can be
significant in large-scale applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KATRec: Knowledge Aware aTtentive Sequential Recommendations. (arXiv:2012.03323v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amjadi_M/0/1/0/all/0/1">Mehrnaz Amjadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taheri_S/0/1/0/all/0/1">Seyed Danial Mohseni Taheri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulabandhula_T/0/1/0/all/0/1">Theja Tulabandhula</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Sequential recommendation systems model dynamic preferences of users based on
their historical interactions with platforms. Despite recent progress, modeling
short-term and long-term behavior of users in such systems is nontrivial and
challenging. To address this, we present a solution enhanced by a knowledge
graph called KATRec (Knowledge Aware aTtentive sequential Recommendations).
KATRec learns the short and long-term interests of users by modeling their
sequence of interacted items and leveraging pre-existing side information
through a knowledge graph attention network. Our novel knowledge graph-enhanced
sequential recommender contains item multi-relations at the entity-level and
users&#x27; dynamic sequences at the item-level. KATRec improves item representation
learning by considering higher-order connections and incorporating them in user
preference representation while recommending the next item. Experiments on
three public datasets show that KATRec outperforms state-of-the-art
recommendation models and demonstrates the importance of modeling both temporal
and side information to achieve high-quality recommendations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Ted Pedersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. &#x27;the NCG
task&#x27;) tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article&#x27;s contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.

Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CausalRec: Causal Inference for Visual Debiasing in Visually-Aware Recommendation. (arXiv:2107.02390v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruihong_Q/0/1/0/all/0/1">Qiu Ruihong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_W/0/1/0/all/0/1">Wang Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_C/0/1/0/all/0/1">Chen Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongzhi_Y/0/1/0/all/0/1">Yin Hongzhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_H/0/1/0/all/0/1">Huang Zi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02390">
                                    <div class="article-summary-box-inner">
                                        <span>Visually-aware recommendation on E-commerce platforms aims to leverage visual
information of items to predict a user&#x27;s preference. It is commonly observed
that user&#x27;s attention to visual features does not always reflect the real
preference. Although a user may click and view an item in light of a visual
satisfaction of their expectations, a real purchase does not always occur due
to the unsatisfaction of other essential features (e.g., brand, material,
price). We refer to the reason for such a visually related interaction
deviating from the real preference as a visual bias. Existing visually-aware
models make use of the visual features as a separate collaborative signal
similarly to other features to directly predict the user&#x27;s preference without
considering a potential bias, which gives rise to a visually biased
recommendation. In this paper, we derive a causal graph to identify and analyze
the visual bias of these existing methods. In this causal graph, the visual
feature of an item acts as a mediator, which could introduce a spurious
relationship between the user and the item. To eliminate this spurious
relationship that misleads the prediction of the user&#x27;s real preference, an
intervention and a counterfactual inference are developed over the mediator.
Particularly, the Total Indirect Effect is applied for a debiased prediction
during the testing phase of the model. This causal inference framework is model
agnostic such that it can be integrated into the existing methods. Furthermore,
we propose a debiased visually-aware recommender system, denoted as CausalRec
to effectively retain the supportive significance of the visual information and
remove the visual bias. Extensive experiments are conducted on eight benchmark
datasets, which shows the state-of-the-art performance of CausalRec and the
efficacy of debiasing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network. (arXiv:2107.02757v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhibin Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaojie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenchao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02757">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical topic models such as the gamma belief network (GBN) have
delivered promising results in mining multi-layer document representations and
discovering interpretable topic taxonomies. However, they often assume in the
prior that the topics at each layer are independently drawn from the Dirichlet
distribution, ignoring the dependencies between the topics both at the same
layer and across different layers. To relax this assumption, we propose
sawtooth factorial topic embedding guided GBN, a deep generative model of
documents that captures the dependencies and semantic similarities between the
topics in the embedding space. Specifically, both the words and topics are
represented as embedding vectors of the same dimension. The topic matrix at a
layer is factorized into the product of a factor loading matrix and a topic
embedding matrix, the transpose of which is set as the factor loading matrix of
the layer above. Repeating this particular type of factorization, which shares
components between adjacent layers, leads to a structure referred to as
sawtooth factorization. An auto-encoding variational inference network is
constructed to optimize the model parameter via stochastic gradient descent.
Experiments on big corpora show that our models outperform other neural topic
models on extracting deeper interpretable topics and deriving better document
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the Scope of Using News Articles to Understand Development Patterns of Districts in India. (arXiv:2107.02765v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Mehak Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Saifi_S/0/1/0/all/0/1">Shayan Saifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_K/0/1/0/all/0/1">Konark Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekha_K/0/1/0/all/0/1">Kumari Rekha</a>, <a href="http://arxiv.org/find/cs/1/au:+Seth_A/0/1/0/all/0/1">Aaditeshwar Seth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02765">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding what factors bring about socio-economic development may often
suffer from the streetlight effect, of analyzing the effect of only those
variables that have been measured and are therefore available for analysis. How
do we check whether all worthwhile variables have been instrumented and
considered when building an econometric development model? We attempt to
address this question by building unsupervised learning methods to identify and
rank news articles about diverse events occurring in different districts of
India, that can provide insights about what may have transpired in the
districts. This can help determine whether variables related to these events
are indeed available or not to model the development of these districts. We
also describe several other applications that emerge from this approach, such
as to use news articles to understand why pairs of districts that may have had
similar socio-economic indicators approximately ten years back ended up at
different levels of development currently, and another application that
generates a newsfeed of unusual news articles that do not conform to news
articles about typical districts with a similar socio-economic profile. These
applications outline the need for qualitative data to augment models based on
quantitative data, and are meant to open up research on new ways to mine
information from unstructured qualitative data to understand development.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning. (arXiv:2107.02759v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Escobar_Grisales_D/0/1/0/all/0/1">Daniel Escobar-Grisales</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasquez_Correa_J/0/1/0/all/0/1">Juan Camilo Vasquez-Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Orozco_Arroyave_J/0/1/0/all/0/1">Juan Rafael Orozco-Arroyave</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02759">
                                    <div class="article-summary-box-inner">
                                        <span>The interest in demographic information retrieval based on text data has
increased in the research community because applications have shown success in
different sectors such as security, marketing, heath-care, and others.
Recognition and identification of demographic traits such as gender, age,
location, or personality based on text data can help to improve different
marketing strategies. For instance it makes it possible to segment and to
personalize offers, thus products and services are exposed to the group of
greatest interest. This type of technology has been discussed widely in
documents from social media. However, the methods have been poorly studied in
data with a more formal structure, where there is no access to emoticons,
mentions, and other linguistic phenomena that are only present in social media.
This paper proposes the use of recurrent and convolutional neural networks, and
a transfer learning strategy for gender recognition in documents that are
written in informal and formal languages. Models are tested in two different
databases consisting of Tweets and call-center conversations. Accuracies of up
to 75\% are achieved for both databases. The results also indicate that it is
possible to transfer the knowledge from a system trained on a specific type of
expressions or idioms such as those typically used in social media into a more
formal type of text data, where the amount of data is more scarce and its
structure is completely different.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EVARS-GPR: EVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal Data. (arXiv:2107.02463v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haselbeck_F/0/1/0/all/0/1">Florian Haselbeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimm_D/0/1/0/all/0/1">Dominik G. Grimm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02463">
                                    <div class="article-summary-box-inner">
                                        <span>Time series forecasting is a growing domain with diverse applications.
However, changes of the system behavior over time due to internal or external
influences are challenging. Therefore, predictions of a previously learned
fore-casting model might not be useful anymore. In this paper, we present
EVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal
Data (EVARS-GPR), a novel online algorithm that is able to handle sudden shifts
in the target variable scale of seasonal data. For this purpose, EVARS-GPR
com-bines online change point detection with a refitting of the prediction
model using data augmentation for samples prior to a change point. Our
experiments on sim-ulated data show that EVARS-GPR is applicable for a wide
range of output scale changes. EVARS-GPR has on average a 20.8 % lower RMSE on
different real-world datasets compared to methods with a similar computational
resource con-sumption. Furthermore, we show that our algorithm leads to a
six-fold reduction of the averaged runtime in relation to all comparison
partners with a periodical refitting strategy. In summary, we present a
computationally efficient online fore-casting algorithm for seasonal time
series with changes of the target variable scale and demonstrate its
functionality on simulated as well as real-world data. All code is publicly
available on GitHub: https://github.com/grimmlab/evars-gpr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Visual Attention-Based Transfer Clustering. (arXiv:2107.02415v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunari_A/0/1/0/all/0/1">Akshaykumar Gunari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kudari_S/0/1/0/all/0/1">Shashidhar Veerappa Kudari</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadagadalli_S/0/1/0/all/0/1">Sukanya Nadagadalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Goudnaik_K/0/1/0/all/0/1">Keerthi Goudnaik</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabib_R/0/1/0/all/0/1">Ramesh Ashok Tabib</a>, <a href="http://arxiv.org/find/cs/1/au:+Mudenagudi_U/0/1/0/all/0/1">Uma Mudenagudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamadandi_A/0/1/0/all/0/1">Adarsh Jamadandi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02415">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a methodology to improvise the technique of deep
transfer clustering (DTC) when applied to the less variant data distribution.
Clustering can be considered as the most important unsupervised learning
problem. A simple definition of clustering can be stated as &quot;the process of
organizing objects into groups, whose members are similar in some way&quot;. Image
clustering is a crucial but challenging task in the domain machine learning and
computer vision. We have discussed the clustering of the data collection where
the data is less variant. We have discussed the improvement by using
attention-based classifiers rather than regular classifiers as the initial
feature extractors in the deep transfer clustering. We have enforced the model
to learn only the required region of interest in the images to get the
differentiable and robust features that do not take into account the
background. This paper is the improvement of the existing deep transfer
clustering for less variant data distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NP-DRAW: A Non-Parametric Structured Latent Variable Model for Image Generation. (arXiv:2106.13435v2 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiaohui Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1">Raquel Urtasun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1">Renjie Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13435">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a non-parametric structured latent variable model
for image generation, called NP-DRAW, which sequentially draws on a latent
canvas in a part-by-part fashion and then decodes the image from the canvas.
Our key contributions are as follows. 1) We propose a non-parametric prior
distribution over the appearance of image parts so that the latent variable
&#x60;&#x60;what-to-draw&#x27;&#x27; per step becomes a categorical random variable. This improves
the expressiveness and greatly eases the learning compared to Gaussians used in
the literature. 2) We model the sequential dependency structure of parts via a
Transformer, which is more powerful and easier to train compared to RNNs used
in the literature. 3) We propose an effective heuristic parsing algorithm to
pre-train the prior. Experiments on MNIST, Omniglot, CIFAR-10, and CelebA show
that our method significantly outperforms previous structured image models like
DRAW and AIR and is competitive to other generic generative models. Moreover,
we show that our model&#x27;s inherent compositionality and interpretability bring
significant benefits in the low-data learning regime and latent space editing.
Code is available at https://github.com/ZENGXH/NPDRAW.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphological Classification of Galaxies in S-PLUS using an Ensemble of Convolutional Networks. (arXiv:2107.02287v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Cardoso_N/0/1/0/all/0/1">N. M. Cardoso</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Schwarz_G/0/1/0/all/0/1">G. B. O. Schwarz</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Dias_L/0/1/0/all/0/1">L. O. Dias</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bom_C/0/1/0/all/0/1">C. R. Bom</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sodre_L/0/1/0/all/0/1">L. Sodr&#xe9; Jr.</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Oliveira_C/0/1/0/all/0/1">C. Mendes de Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02287">
                                    <div class="article-summary-box-inner">
                                        <span>The universe is composed of galaxies that have diverse shapes. Once the
structure of a galaxy is determined, it is possible to obtain important
information about its formation and evolution. Morphologically classifying
galaxies means cataloging them according to their visual appearance and the
classification is linked to the physical properties of the galaxy. A
morphological classification made through visual inspection is subject to
biases introduced by subjective observations made by human volunteers. For this
reason, systematic, objective and easily reproducible classification of
galaxies has been gaining importance since the astronomer Edwin Hubble created
his famous classification method. In this work, we combine accurate visual
classifications of the Galaxy Zoo project with \emph {Deep Learning} methods.
The goal is to find an efficient technique at human performance level
classification, but in a systematic and automatic way, for classification of
elliptical and spiral galaxies. For this, a neural network model was created
through an Ensemble of four other convolutional models, allowing a greater
accuracy in the classification than what would be obtained with any one
individual. Details of the individual models and improvements made are also
described. The present work is entirely based on the analysis of images (not
parameter tables) from DR1 (www.datalab.noao.edu) of the Southern Photometric
Local Universe Survey (S-PLUS). In terms of classification, we achieved, with
the Ensemble, an accuracy of $\approx 99 \%$ in the test sample (using
pre-trained networks).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-Sample Lower Bounds for Learning Parity with Noise. (arXiv:2107.02320v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sumegha Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K. Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengda Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Raz_R/0/1/0/all/0/1">Ran Raz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02320">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we show, for the well-studied problem of learning parity under
noise, where a learner tries to learn $x&#x3D;(x_1,\ldots,x_n) \in \{0,1\}^n$ from a
stream of random linear equations over $\mathrm{F}_2$ that are correct with
probability $\frac{1}{2}+\varepsilon$ and flipped with probability
$\frac{1}{2}-\varepsilon$, that any learning algorithm requires either a memory
of size $\Omega(n^2/\varepsilon)$ or an exponential number of samples.

In fact, we study memory-sample lower bounds for a large class of learning
problems, as characterized by [GRT&#x27;18], when the samples are noisy. A matrix
$M: A \times X \rightarrow \{-1,1\}$ corresponds to the following learning
problem with error parameter $\varepsilon$: an unknown element $x \in X$ is
chosen uniformly at random. A learner tries to learn $x$ from a stream of
samples, $(a_1, b_1), (a_2, b_2) \ldots$, where for every $i$, $a_i \in A$ is
chosen uniformly at random and $b_i &#x3D; M(a_i,x)$ with probability
$1/2+\varepsilon$ and $b_i &#x3D; -M(a_i,x)$ with probability $1/2-\varepsilon$
($0&lt;\varepsilon&lt; \frac{1}{2}$). Assume that $k,\ell, r$ are such that any
submatrix of $M$ of at least $2^{-k} \cdot |A|$ rows and at least $2^{-\ell}
\cdot |X|$ columns, has a bias of at most $2^{-r}$. We show that any learning
algorithm for the learning problem corresponding to $M$, with error, requires
either a memory of size at least $\Omega\left(\frac{k \cdot \ell}{\varepsilon}
\right)$, or at least $2^{\Omega(r)}$ samples. In particular, this shows that
for a large class of learning problems, same as those in [GRT&#x27;18], any learning
algorithm requires either a memory of size at least $\Omega\left(\frac{(\log
|X|) \cdot (\log |A|)}{\varepsilon}\right)$ or an exponential number of noisy
samples.

Our proof is based on adapting the arguments in [Raz&#x27;17,GRT&#x27;18] to the noisy
case.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Mixture Models with Expectation-Maximization for End-to-end Deep Clustering. (arXiv:2107.02453v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tissera_D/0/1/0/all/0/1">Dumindu Tissera</a>, <a href="http://arxiv.org/find/cs/1/au:+Vithanage_K/0/1/0/all/0/1">Kasun Vithanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijesinghe_R/0/1/0/all/0/1">Rukshan Wijesinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1">Alex Xavier</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasena_S/0/1/0/all/0/1">Sanath Jayasena</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_S/0/1/0/all/0/1">Subha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigo_R/0/1/0/all/0/1">Ranga Rodrigo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02453">
                                    <div class="article-summary-box-inner">
                                        <span>Any clustering algorithm must synchronously learn to model the clusters and
allocate data to those clusters in the absence of labels. Mixture model-based
methods model clusters with pre-defined statistical distributions and allocate
data to those clusters based on the cluster likelihoods. They iteratively
refine those distribution parameters and member assignments following the
Expectation-Maximization (EM) algorithm. However, the cluster representability
of such hand-designed distributions that employ a limited amount of parameters
is not adequate for most real-world clustering tasks. In this paper, we realize
mixture model-based clustering with a neural network where the final layer
neurons, with the aid of an additional transformation, approximate cluster
distribution outputs. The network parameters pose as the parameters of those
distributions. The result is an elegant, much-generalized representation of
clusters than a restricted mixture of hand-designed distributions. We train the
network end-to-end via batch-wise EM iterations where the forward pass acts as
the E-step and the backward pass acts as the M-step. In image clustering, the
mixture-based EM objective can be used as the clustering objective along with
existing representation learning methods. In particular, we show that when
mixture-EM optimization is fused with consistency optimization, it improves the
sole consistency optimization performance in clustering. Our trained networks
outperform single-stage deep clustering methods that still depend on k-means,
with unsupervised classification accuracy of 63.8% in STL10, 58% in CIFAR10,
25.9% in CIFAR100, and 98.9% in MNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LipBaB: Computing exact Lipschitz constant of ReLU networks. (arXiv:2105.05495v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhowmick_A/0/1/0/all/0/1">Aritra Bhowmick</a>, <a href="http://arxiv.org/find/cs/1/au:+DSouza_M/0/1/0/all/0/1">Meenakshi D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghavan_G/0/1/0/all/0/1">G. Srinivasa Raghavan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05495">
                                    <div class="article-summary-box-inner">
                                        <span>The Lipschitz constant of neural networks plays an important role in several
contexts of deep learning ranging from robustness certification and
regularization to stability analysis of systems with neural network
controllers. Obtaining tight bounds of the Lipschitz constant is therefore
important. We introduce LipBaB, a branch and bound framework to compute
certified bounds of the local Lipschitz constant of deep neural networks with
ReLU activation functions up to any desired precision. We achieve this by
bounding the norm of the Jacobians, corresponding to different activation
patterns of the network caused within the input domain. Our algorithm can
provide provably exact computation of the Lipschitz constant for any p-norm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotics of Network Embeddings Learned via Subsampling. (arXiv:2107.02363v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Davison_A/0/1/0/all/0/1">Andrew Davison</a>, <a href="http://arxiv.org/find/stat/1/au:+Austern_M/0/1/0/all/0/1">Morgane Austern</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02363">
                                    <div class="article-summary-box-inner">
                                        <span>Network data are ubiquitous in modern machine learning, with tasks of
interest including node classification, node clustering and link prediction. A
frequent approach begins by learning an Euclidean embedding of the network, to
which algorithms developed for vector-valued data are applied. For large
networks, embeddings are learned using stochastic gradient methods where the
sub-sampling scheme can be freely chosen. Despite the strong empirical
performance of such methods, they are not well understood theoretically. Our
work encapsulates representation methods using a subsampling approach, such as
node2vec, into a single unifying framework. We prove, under the assumption that
the graph is exchangeable, that the distribution of the learned embedding
vectors asymptotically decouples. Moreover, we characterize the asymptotic
distribution and provided rates of convergence, in terms of the latent
parameters, which includes the choice of loss function and the embedding
dimension. This provides a theoretical foundation to understand what the
embedding vectors represent and how well these methods perform on downstream
tasks. Notably, we observe that typically used loss functions may lead to
shortcomings, such as a lack of Fisher consistency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Miao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liangqiong Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Praveer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1">Jayashree Kalpathy-Cramer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel L. Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02375">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is an emerging research paradigm for enabling
collaboratively training deep learning models without sharing patient data.
However, the data from different institutions are usually heterogeneous across
institutions, which may reduce the performance of models trained using
federated learning. In this study, we propose a novel heterogeneity-aware
federated learning method, SplitAVG, to overcome the performance drops from
data heterogeneity in federated learning. Unlike previous federated methods
that require complex heuristic training or hyper parameter tuning, our SplitAVG
leverages the simple network split and feature map concatenation strategies to
encourage the federated model training an unbiased estimator of the target data
distribution. We compare SplitAVG with seven state-of-the-art federated
learning methods, using centrally hosted training data as the baseline on a
suite of both synthetic and real-world federated datasets. We find that the
performance of models trained using all the comparison federated learning
methods degraded significantly with the increasing degrees of data
heterogeneity. In contrast, SplitAVG method achieves comparable results to the
baseline method under all heterogeneous settings, that it achieves 96.2% of the
accuracy and 110.4% of the mean absolute error obtained by the baseline in a
diabetic retinopathy binary classification dataset and a bone age prediction
dataset, respectively, on highly heterogeneous data partitions. We conclude
that SplitAVG method can effectively overcome the performance drops from
variability in data distributions across institutions. Experimental results
also show that SplitAVG can be adapted to different base networks and
generalized to various types of medical imaging tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fractional order graph neural network. (arXiv:2001.04026v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chunbo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Peng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_G/0/1/0/all/0/1">Geyong Min</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04026">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes fractional order graph neural networks (FGNNs), optimized
by the approximation strategy to address the challenges of local optimum of
classic and fractional graph neural networks which are specialised at
aggregating information from the feature and adjacent matrices of connected
nodes and their neighbours to solve learning tasks on non-Euclidean data such
as graphs. Meanwhile the approximate calculation of fractional order gradients
also overcomes the high computational complexity of fractional order
derivations. We further prove that such an approximation is feasible and the
FGNN is unbiased towards global optimization solution. Extensive experiments on
citation networks show that FGNN achieves great advantage over baseline models
when selected appropriate fractional order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variance Reduction for Matrix Computations with Applications to Gaussian Processes. (arXiv:2106.14565v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mathur_A/0/1/0/all/0/1">Anant Mathur</a>, <a href="http://arxiv.org/find/stat/1/au:+Moka_S/0/1/0/all/0/1">Sarat Moka</a>, <a href="http://arxiv.org/find/stat/1/au:+Botev_Z/0/1/0/all/0/1">Zdravko Botev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14565">
                                    <div class="article-summary-box-inner">
                                        <span>In addition to recent developments in computing speed and memory,
methodological advances have contributed to significant gains in the
performance of stochastic simulation. In this paper, we focus on variance
reduction for matrix computations via matrix factorization. We provide insights
into existing variance reduction methods for estimating the entries of large
matrices. Popular methods do not exploit the reduction in variance that is
possible when the matrix is factorized. We show how computing the square root
factorization of the matrix can achieve in some important cases arbitrarily
better stochastic performance. In addition, we propose a factorized estimator
for the trace of a product of matrices and numerically demonstrate that the
estimator can be up to 1,000 times more efficient on certain problems of
estimating the log-likelihood of a Gaussian process. Additionally, we provide a
new estimator of the log-determinant of a positive semi-definite matrix where
the log-determinant is treated as a normalizing constant of a probability
density.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ADMM for Efficient Deep Learning with Global Convergence. (arXiv:1905.13611v4 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wang_J/0/1/0/all/0/1">Junxiang Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Yu_F/0/1/0/all/0/1">Fuxun Yu</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1">Xiang Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13611">
                                    <div class="article-summary-box-inner">
                                        <span>Alternating Direction Method of Multipliers (ADMM) has been used successfully
in many conventional machine learning applications and is considered to be a
useful alternative to Stochastic Gradient Descent (SGD) as a deep learning
optimizer. However, as an emerging domain, several challenges remain, including
1) The lack of global convergence guarantees, 2) Slow convergence towards
solutions, and 3) Cubic time complexity with regard to feature dimensions. In
this paper, we propose a novel optimization framework for deep learning via
ADMM (dlADMM) to address these challenges simultaneously. The parameters in
each layer are updated backward and then forward so that the parameter
information in each layer is exchanged efficiently. The time complexity is
reduced from cubic to quadratic in (latent) feature dimensions via a dedicated
algorithm design for subproblems that enhances them utilizing iterative
quadratic approximations and backtracking. Finally, we provide the first proof
of global convergence for an ADMM-based method (dlADMM) in a deep neural
network problem under mild conditions. Experiments on benchmark datasets
demonstrated that our proposed dlADMM algorithm outperforms most of the
comparison methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Algorithm Execution: Estimating Computable Properties of Black-box Functions Using Mutual Information. (arXiv:2104.09460v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Neiswanger_W/0/1/0/all/0/1">Willie Neiswanger</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_K/0/1/0/all/0/1">Ke Alexander Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09460">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world problems, we want to infer some property of an expensive
black-box function $f$, given a budget of $T$ function evaluations. One example
is budget constrained global optimization of $f$, for which Bayesian
optimization is a popular method. Other properties of interest include local
optima, level sets, integrals, or graph-structured information induced by $f$.
Often, we can find an algorithm $\mathcal{A}$ to compute the desired property,
but it may require far more than $T$ queries to execute. Given such an
$\mathcal{A}$, and a prior distribution over $f$, we refer to the problem of
inferring the output of $\mathcal{A}$ using $T$ evaluations as Bayesian
Algorithm Execution (BAX). To tackle this problem, we present a procedure,
InfoBAX, that sequentially chooses queries that maximize mutual information
with respect to the algorithm&#x27;s output. Applying this to Dijkstra&#x27;s algorithm,
for instance, we infer shortest paths in synthetic and real-world graphs with
black-box edge costs. Using evolution strategies, we yield variants of Bayesian
optimization that target local, rather than global, optima. On these problems,
InfoBAX uses up to 500 times fewer queries to $f$ than required by the original
algorithm. Our method is closely connected to other Bayesian optimal
experimental design procedures such as entropy search methods and optimal
sensor placement using Gaussian processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning optimal multigrid smoothers via neural networks. (arXiv:2102.12071v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_R/0/1/0/all/0/1">Ru Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Li_R/0/1/0/all/0/1">Ruipeng Li</a>, <a href="http://arxiv.org/find/math/1/au:+Xi_Y/0/1/0/all/0/1">Yuanzhe Xi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12071">
                                    <div class="article-summary-box-inner">
                                        <span>Multigrid methods are one of the most efficient techniques for solving linear
systems arising from Partial Differential Equations (PDEs) and graph Laplacians
from machine learning applications. One of the key components of multigrid is
smoothing, which aims at reducing high-frequency errors on each grid level.
However, finding optimal smoothing algorithms is problem-dependent and can
impose challenges for many problems. In this paper, we propose an efficient
adaptive framework for learning optimized smoothers from operator stencils in
the form of convolutional neural networks (CNNs). The CNNs are trained on
small-scale problems from a given type of PDEs based on a supervised loss
function derived from multigrid convergence theories, and can be applied to
large-scale problems of the same class of PDEs. Numerical results on
anisotropic rotated Laplacian problems demonstrate improved convergence rates
and solution time compared with classical hand-crafted relaxation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order in the Court: Explainable AI Methods Prone to Disagreement. (arXiv:2105.03287v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neely_M/0/1/0/all/0/1">Michael Neely</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_S/0/1/0/all/0/1">Stefan F. Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1">Maurits J. R. Bleeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03287">
                                    <div class="article-summary-box-inner">
                                        <span>By computing the rank correlation between attention weights and
feature-additive explanation methods, previous analyses either invalidate or
support the role of attention-based explanations as a faithful and plausible
measure of salience. To investigate whether this approach is appropriate, we
compare LIME, Integrated Gradients, DeepLIFT, Grad-SHAP, Deep-SHAP, and
attention-based explanations, applied to two neural architectures trained on
single- and pair-sequence language tasks. In most cases, we find that none of
our chosen methods agree. Based on our empirical observations and theoretical
objections, we conclude that rank correlation does not measure the quality of
feature-additive methods. Practitioners should instead use the numerous and
rigorous diagnostic methods proposed by the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Fusion for Deep Learning on Transport Mode Detection: A Case Study. (arXiv:2106.05876v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreau_H/0/1/0/all/0/1">Hugues Moreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilev_A/0/1/0/all/0/1">Andr&#xe9;a Vassilev</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liming Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05876">
                                    <div class="article-summary-box-inner">
                                        <span>In Transport Mode Detection, a great diversity of methodologies exist
according to the choice made on sensors, preprocessing, model used, etc. In
this domain, the comparisons between each option are not always complete.
Experiments on a public, real-life dataset are led here to evaluate carefully
each of the choices that were made, with a specific emphasis on data fusion
methods. Our most surprising finding is that none of the methods we implemented
from the literature is better than a simple late fusion. Two important
decisions are the choice of a sensor and the choice of a representation for the
data: we found that using 2D convolutions on spectrograms with a logarithmic
axis for the frequencies was better than 1-dimensional temporal
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Computing. (arXiv:2107.02744v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gangal_A/0/1/0/all/0/1">Ayushe Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Peeyush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1">Sunita Kumari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Aditya Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02744">
                                    <div class="article-summary-box-inner">
                                        <span>This chapter aims to provide next-level understanding of the problems of the
world and the solutions available to those problems, which lie very well within
the domain of neural computing, and at the same time are intelligent in their
approach, to invoke a sense of innovation among the educationalists,
researchers, academic professionals, students and people concerned, by
highlighting the work done by major researchers and innovators in this field
and thus, encouraging the readers to develop newer and more advanced techniques
for the same. By means of this chapter, the societal problems are discussed and
various solutions are also given by means of the theories presented and
researches done so far. Different types of neural networks discovered so far
and applications of some of those neural networks are focused on, apart from
their theoretical understanding, the working and core concepts involved in the
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1">Kirill Shevkunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1">Liudmila Prokhorenkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.02445">
                                    <div class="article-summary-box-inner">
                                        <span>Various non-trivial spaces are becoming popular for embedding structured data
such as graphs, texts, or images. Following spherical and hyperbolic spaces,
more general product spaces have been proposed. However, searching for the best
configuration of product space is a resource-intensive procedure, which reduces
the practical applicability of the idea. We generalize the concept of product
space and introduce an overlapping space that does not have the configuration
search problem. The main idea is to allow subsets of coordinates to be shared
between spaces of different types (Euclidean, hyperbolic, spherical). As a
result, parameter optimization automatically learns the optimal configuration.
Additionally, overlapping spaces allow for more compact representations since
their geometry is more complex. Our experiments confirm that overlapping spaces
outperform the competitors in graph embedding tasks. Here, we consider both
distortion setup, where the aim is to preserve distances, and ranking setup,
where the relative order should be preserved. The proposed method effectively
solves the problem and outperforms the competitors in both settings. We also
perform an empirical analysis in a realistic information retrieval task, where
we compare all spaces by incorporating them into DSSM. In this case, the
proposed overlapping space consistently achieves nearly optimal results without
any configuration tuning. This allows for reducing training time, which can be
significant in large-scale applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-based vs Model-free Adaptive Control of a MAV under Wind Gust. (arXiv:2101.12501v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaffre_T/0/1/0/all/0/1">Thomas Chaffre</a>, <a href="http://arxiv.org/find/cs/1/au:+Moras_J/0/1/0/all/0/1">Julien Moras</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_Hon_Tong_A/0/1/0/all/0/1">Adrien Chan-Hon-Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzat_J/0/1/0/all/0/1">Julien Marzat</a>, <a href="http://arxiv.org/find/cs/1/au:+Sammut_K/0/1/0/all/0/1">Karl Sammut</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenadec_G/0/1/0/all/0/1">Gilles Le Chenadec</a>, <a href="http://arxiv.org/find/cs/1/au:+Clement_B/0/1/0/all/0/1">Benoit Clement</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12501">
                                    <div class="article-summary-box-inner">
                                        <span>Navigation problems under unknown varying conditions are among the most
important and well-studied problems in the control field. Classic model-based
adaptive control methods can be applied only when a convenient model of the
plant or environment is provided. Recent model-free adaptive control methods
aim at removing this dependency by learning the physical characteristics of the
plant and/or process directly from sensor feedback. Although there have been
prior attempts at improving these techniques, it remains an open question as to
whether it is possible to cope with real-world uncertainties in a control
system that is fully based on either paradigm. We propose a conceptually simple
learning-based approach composed of a full state feedback controller, tuned
robustly by a deep reinforcement learning framework based on the Soft
Actor-Critic algorithm. We compare it, in realistic simulations, to a
model-free controller that uses the same deep reinforcement learning framework
for the control of a micro aerial vehicle under wind gust. The results indicate
the great potential of learning-based adaptive control methods in modern
dynamical systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Losses and Solution Caching for Predict-and-Optimize. (arXiv:2011.05354v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mulamba_M/0/1/0/all/0/1">Maxime Mulamba</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandi_J/0/1/0/all/0/1">Jayanta Mandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Diligenti_M/0/1/0/all/0/1">Michelangelo Diligenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombardi_M/0/1/0/all/0/1">Michele Lombardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucarey_V/0/1/0/all/0/1">Victor Bucarey</a>, <a href="http://arxiv.org/find/cs/1/au:+Guns_T/0/1/0/all/0/1">Tias Guns</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05354">
                                    <div class="article-summary-box-inner">
                                        <span>Many decision-making processes involve solving a combinatorial optimization
problem with uncertain input that can be estimated from historic data.
Recently, problems in this class have been successfully addressed via
end-to-end learning approaches, which rely on solving one optimization problem
for each training instance at every epoch. In this context, we provide two
distinct contributions. First, we use a Noise Contrastive approach to motivate
a family of surrogate loss functions, based on viewing non-optimal solutions as
negative examples. Second, we address a major bottleneck of all
predict-and-optimize approaches, i.e. the need to frequently recompute optimal
solutions at training time. This is done via a solver-agnostic solution caching
scheme, and by replacing optimization calls with a lookup in the solution
cache. The method is formally based on an inner approximation of the feasible
space and, combined with a cache lookup strategy, provides a controllable
trade-off between training time and accuracy of the loss approximation. We
empirically show that even a very slow growth rate is enough to match the
quality of state-of-the-art methods, at a fraction of the computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advanced Graph and Sequence Neural Networks for Molecular Property Prediction and Drug Discovery. (arXiv:2012.01981v3 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Wang_Z/0/1/0/all/0/1">Zhengyang Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xu_Z/0/1/0/all/0/1">Zhao Xu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xie_Y/0/1/0/all/0/1">Yaochen Xie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1">Limei Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cai_L/0/1/0/all/0/1">Lei Cai</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Qi_Q/0/1/0/all/0/1">Qi Qi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yuan_Z/0/1/0/all/0/1">Zhuoning Yuan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01981">
                                    <div class="article-summary-box-inner">
                                        <span>Properties of molecules are indicative of their functions and thus are useful
in many applications. With the advances of deep learning methods, computational
approaches for predicting molecular properties are gaining increasing momentum.
However, there lacks customized and advanced methods and comprehensive tools
for this task currently. Here we develop a suite of comprehensive machine
learning methods and tools spanning different computational models, molecular
representations, and loss functions for molecular property prediction and drug
discovery. Specifically, we represent molecules as both graphs and sequences.
Built on these representations, we develop novel deep models for learning from
molecular graphs and sequences. In order to learn effectively from highly
imbalanced datasets, we develop advanced loss functions that optimize areas
under precision-recall curves. Altogether, our work not only serves as a
comprehensive tool, but also contributes towards developing novel and advanced
graph and sequence learning methodologies. Results on both online and offline
antibiotics discovery and molecular property prediction tasks show that our
methods achieve consistent improvements over prior methods. In particular, our
methods achieve #1 ranking in terms of both ROC-AUC and PRC-AUC on the AI Cures
Open Challenge for drug discovery related to COVID-19. Our software is released
as part of the MoleculeX library under AdvProp.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification with Rejection Based on Cost-sensitive Classification. (arXiv:2010.11748v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Charoenphakdee_N/0/1/0/all/0/1">Nontawat Charoenphakdee</a>, <a href="http://arxiv.org/find/stat/1/au:+Cui_Z/0/1/0/all/0/1">Zhenghang Cui</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1">Yivan Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11748">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of classification with rejection is to avoid risky misclassification
in error-critical applications such as medical diagnosis and product
inspection. In this paper, based on the relationship between classification
with rejection and cost-sensitive classification, we propose a novel method of
classification with rejection by learning an ensemble of cost-sensitive
classifiers, which satisfies all the following properties: (i) it can avoid
estimating class-posterior probabilities, resulting in improved classification
accuracy, (ii) it allows a flexible choice of losses including non-convex ones,
(iii) it does not require complicated modifications when using different
losses, (iv) it is applicable to both binary and multiclass cases, and (v) it
is theoretically justifiable for any classification-calibrated loss.
Experimental results demonstrate the usefulness of our proposed approach in
clean-labeled, noisy-labeled, and positive-unlabeled classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Treutlein_J/0/1/0/all/0/1">Johannes Treutlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1">Michael Dennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1">Caspar Oesterheld</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06613">
                                    <div class="article-summary-box-inner">
                                        <span>In many coordination problems, independently reasoning humans are able to
discover mutually compatible policies. In contrast, independently trained
self-play policies are often mutually incompatible. Zero-shot coordination
(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement
learning to address this fundamental issue. Prior work approaches the ZSC
problem by assuming players can agree on a shared learning algorithm but not on
labels for actions and observations, and proposes other-play as an optimal
solution. However, until now, this &quot;label-free&quot; problem has only been
informally defined. We formalize this setting as the label-free coordination
(LFC) problem by defining the label-free coordination game. We show that
other-play is not an optimal solution to the LFC problem as it fails to
consistently break ties between incompatible maximizers of the other-play
objective. We introduce an extension of the algorithm, other-play with
tie-breaking, and prove that it is optimal in the LFC problem and an
equilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the
ZSC setting aims to prevent, we conclude that the LFC problem does not reflect
the aims of ZSC. To address this, we introduce an alternative informal
operationalization of ZSC as a starting point for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Ted Pedersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. &#x27;the NCG
task&#x27;) tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article&#x27;s contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.

Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepOPG: Improving Orthopantomogram Finding Summarization with Weak Supervision. (arXiv:2103.08290v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_T/0/1/0/all/0/1">Tzu-Ming Harry Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yin-Chih Chelsea Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08290">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical finding summaries from an orthopantomogram, or a dental panoramic
radiograph, have significant potential to improve patient communication and
speed up clinical judgments. While orthopantomogram is a first-line tool for
dental examinations, no existing work has explored the summarization of
findings from it. A finding summary has to find teeth in the imaging study and
label the teeth with several types of past treatments. To tackle the problem,
we developDeepOPG that breaks the summarization process into functional
segmentation and tooth localization, the latter of which is further refined by
a novel dental coherence module. We also leverage weak supervision labels to
improve detection results in a reinforcement learning scenario. Experiments
show high efficacy of DeepOPG on finding summarization, achieving an overall
AUC of 88.2% in detecting six types of findings. The proposed dental coherence
and weak supervision both are shown to improve DeepOPG by adding 5.9% and 0.4%
to AP@IoU&#x3D;0.5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive machine learning for protein engineering. (arXiv:2106.05466v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Hie_B/0/1/0/all/0/1">Brian L. Hie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_K/0/1/0/all/0/1">Kevin K. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05466">
                                    <div class="article-summary-box-inner">
                                        <span>Machine-learning models that learn from data to predict how protein sequence
encodes function are emerging as a useful protein engineering tool. However,
when using these models to suggest new protein designs, one must deal with the
vast combinatorial complexity of protein sequences. Here, we review how to use
a sequence-to-function machine-learning surrogate model to select sequences for
experimental measurement. First, we discuss how to select sequences through a
single round of machine-learning optimization. Then, we discuss sequential
optimization, where the goal is to discover optimized sequences and improve the
model across multiple rounds of training, optimization, and experimental
measurement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Size-Invariant Graph Representations for Graph Classification Extrapolations. (arXiv:2103.05045v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1">Beatrice Bevilacqua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yangze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1">Bruno Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05045">
                                    <div class="article-summary-box-inner">
                                        <span>In general, graph representation learning methods assume that the train and
test data come from the same distribution. In this work we consider an
underexplored area of an otherwise rapidly developing field of graph
representation learning: The task of out-of-distribution (OOD) graph
classification, where train and test data have different distributions, with
test data unavailable during training. Our work shows it is possible to use a
causal model to learn approximately invariant representations that better
extrapolate between train and test data. Finally, we conclude with synthetic
and real-world dataset experiments showcasing the benefits of representations
that are invariant to train/test distribution shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surrogate Model Based Hyperparameter Tuning for Deep Learning with SPOT. (arXiv:2105.14625v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bartz_Beielstein_T/0/1/0/all/0/1">Thomas Bartz-Beielstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehbach_F/0/1/0/all/0/1">Frederik Rehbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1">Amrita Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaefferer_M/0/1/0/all/0/1">Martin Zaefferer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14625">
                                    <div class="article-summary-box-inner">
                                        <span>A surrogate model based hyperparameter tuning approach for deep learning is
presented. This article demonstrates how the architecture-level parameters
(hyperparameters) of deep learning models that were implemented in
Keras/tensorflow can be optimized. The implementation of the tuning procedure
is 100% accessible from R, the software environment for statistical computing.
With a few lines of code, existing R packages (tfruns and SPOT) can be combined
to perform hyperparameter tuning. An elementary hyperparameter tuning task
(neural network and the MNIST data) is used to exemplify this approach</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maximizing Ensemble Diversity in Deep Q-Learning. (arXiv:2006.13823v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheikh_H/0/1/0/all/0/1">Hassam Ullah Sheikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Phielipp_M/0/1/0/all/0/1">Mariano Phielipp</a>, <a href="http://arxiv.org/find/cs/1/au:+Boloni_L/0/1/0/all/0/1">Ladislau B&#xf6;l&#xf6;ni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.13823">
                                    <div class="article-summary-box-inner">
                                        <span>The classic DQN algorithm is limited by the overestimation bias of the
learned Q-function. Subsequent algorithms have proposed techniques to reduce
this problem, without fully eliminating it. Recently, the Maxmin and Ensemble
Q-learning algorithms have used different estimates provided by the ensembles
of learners to reduce the overestimation bias. Unfortunately, these learners
can converge to the same point in the parametric or representation space,
falling back to the classic single neural network DQN. In this paper, we
describe a regularization technique to maximize ensemble diversity in these
algorithms. We propose and compare five regularization functions inspired from
economics theory and consensus optimization. We show that the regularized
approach significantly outperforms the Maxmin and Ensemble Q-learning
algorithms as well as non-ensemble baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Graph Disentanglement. (arXiv:2103.07295v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenfeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jian Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07295">
                                    <div class="article-summary-box-inner">
                                        <span>A real-world graph has a complex topological structure, which is often formed
by the interaction of different latent factors. Disentanglement of these latent
factors can effectively improve the robustness and expressiveness of node
representation of graph. However, most existing methods lack consideration of
the intrinsic differences in relations between nodes caused by factor
entanglement. In this paper, we propose an Adversarial Disentangled Graph
Convolutional Network (ADGCN) for disentangled graph representation learning.
Specifically, a component-specific aggregation approach is proposed to achieve
micro-disentanglement by inferring latent components that caused the links
between nodes. On the basis of micro-disentanglement, we further propose a
macro-disentanglement adversarial regularizer to improve the separability among
component distributions, thus restricting the interdependence among components.
Additionally, to reveal the topological graph structure, a diversity-preserving
node sampling approach is proposed, by which the graph structure can be
progressively refined in a way of local structure awareness. The experimental
results on various real-world graph data verify that our ADGCN obtains more
favorable performance over currently available alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeadCache: Regret-Optimal Caching in Networks. (arXiv:2009.08228v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paria_D/0/1/0/all/0/1">Debjit Paria</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1">Abhishek Sinha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08228">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a set-valued online prediction problem in the context of network
caching. Assume that multiple users are connected to several caches via a
bipartite network. At any time slot, each user requests an arbitrary file
chosen from a large catalog. A user&#x27;s request at a slot is met if the requested
file is cached in at least one of the caches connected to the user. Our
objective is to predict, prefetch, and optimally distribute the files on the
caches to maximize the total number of cache hits in an online setting. The
problem is non-trivial due to the non-convex and non-smooth nature of the
objective function. In this paper, we propose $\texttt{LeadCache}$ - an online
caching policy based on the Follow-the-Perturbed-Leader paradigm. We show that
the policy is regret-optimal up to a factor of $\tilde{O}(n^{3/8}),$ where $n$
is the number of users. We design two efficient implementations of the
$\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based
on Madow&#x27;s sampling, each of which makes precisely one call to an LP-solver per
iteration. With a Strong-Law-type assumption, we show that the total number of
file fetches under $\texttt{LeadCache}$ remains almost surely finite over an
infinite horizon. Finally, we derive a tight regret lower bound using results
from graph coloring. We conclude that the learning-based $\texttt{LeadCache}$
policy decisively outperforms the known caching policies both theoretically and
empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">David Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1">Adam Santoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1">Matt Botvinick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games. (arXiv:2103.01955v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Chao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Velu_A/0/1/0/all/0/1">Akash Velu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinitsky_E/0/1/0/all/0/1">Eugene Vinitsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayen_A/0/1/0/all/0/1">Alexandre Bayen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01955">
                                    <div class="article-summary-box-inner">
                                        <span>Proximal Policy Optimization (PPO) is a popular on-policy reinforcement
learning algorithm but is significantly less utilized than off-policy learning
algorithms in multi-agent settings. This is often due the belief that on-policy
methods are significantly less sample efficient than their off-policy
counterparts in multi-agent problems. In this work, we investigate Multi-Agent
PPO (MAPPO), a variant of PPO which is specialized for multi-agent settings.
Using a 1-GPU desktop, we show that MAPPO achieves surprisingly strong
performance in three popular multi-agent testbeds: the particle-world
environments, the Starcraft multi-agent challenge, and the Hanabi challenge,
with minimal hyperparameter tuning and without any domain-specific algorithmic
modifications or architectures. In the majority of environments, we find that
compared to off-policy baselines, MAPPO achieves strong results while
exhibiting comparable sample efficiency. Finally, through ablation studies, we
present the implementation and algorithmic factors which are most influential
to MAPPO&#x27;s practical performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy Forecasting in Smart Grid Systems: A Review of the State-of-the-art Techniques. (arXiv:2011.12598v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaur_D/0/1/0/all/0/1">Devinder Kaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Shama Naz Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_M/0/1/0/all/0/1">Md. Apel Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">ZhaoYang Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12598">
                                    <div class="article-summary-box-inner">
                                        <span>Energy forecasting has a vital role to play in smart grid (SG) systems
involving various applications such as demand-side management, load shedding,
and optimum dispatch. Managing efficient forecasting while ensuring the least
possible prediction error is one of the main challenges posed in the grid
today, considering the uncertainty and granularity in SG data. This paper
presents a comprehensive and application-oriented review of state-of-the-art
forecasting methods for SG systems along with recent developments in
probabilistic deep learning (PDL) considering different models and
architectures. Traditional point forecasting methods including statistical,
machine learning (ML), and deep learning (DL) are extensively investigated in
terms of their applicability to energy forecasting. In addition, the
significance of hybrid and data pre-processing techniques to support
forecasting performance is also studied. A comparative case study using the
Victorian electricity consumption and American electric power (AEP) datasets is
conducted to analyze the performance of point and probabilistic forecasting
methods. The analysis demonstrates higher accuracy of the long-short term
memory (LSTM) models with appropriate hyper-parameter tuning among point
forecasting methods especially when sample sizes are larger and involve
nonlinear patterns with long sequences. Furthermore, Bayesian bidirectional
LSTM (BLSTM) as a probabilistic method exhibit the highest accuracy in terms of
least pinball score and root mean square error (RMSE).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Inference with Corrupted Data: Measurement Error, Missing Values, Discretization, and Differential Privacy. (arXiv:2107.02780v1 [econ.EM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Agarwal_A/0/1/0/all/0/1">Anish Agarwal</a>, <a href="http://arxiv.org/find/econ/1/au:+Singh_R/0/1/0/all/0/1">Rahul Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02780">
                                    <div class="article-summary-box-inner">
                                        <span>Even the most carefully curated economic data sets have variables that are
noisy, missing, discretized, or privatized. The standard workflow for empirical
research involves data cleaning followed by data analysis that typically
ignores the bias and variance consequences of data cleaning. We formulate a
semiparametric model for causal inference with corrupted data to encompass both
data cleaning and data analysis. We propose a new end-to-end procedure for data
cleaning, estimation, and inference with data cleaning-adjusted confidence
intervals. We prove root-n consistency, Gaussian approximation, and
semiparametric efficiency for our estimator of the causal parameter by finite
sample arguments. Our key assumption is that the true covariates are
approximately low rank. In our analysis, we provide nonasymptotic theoretical
contributions to matrix completion, statistical learning, and semiparametric
statistics. We verify the coverage of the data cleaning-adjusted confidence
intervals in simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-informed regularization and structure preservation for learning stable reduced models from data with operator inference. (arXiv:2107.02597v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sawant_N/0/1/0/all/0/1">Nihar Sawant</a>, <a href="http://arxiv.org/find/math/1/au:+Kramer_B/0/1/0/all/0/1">Boris Kramer</a>, <a href="http://arxiv.org/find/math/1/au:+Peherstorfer_B/0/1/0/all/0/1">Benjamin Peherstorfer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02597">
                                    <div class="article-summary-box-inner">
                                        <span>Operator inference learns low-dimensional dynamical-system models with
polynomial nonlinear terms from trajectories of high-dimensional physical
systems (non-intrusive model reduction). This work focuses on the large class
of physical systems that can be well described by models with quadratic
nonlinear terms and proposes a regularizer for operator inference that induces
a stability bias onto quadratic models. The proposed regularizer is physics
informed in the sense that it penalizes quadratic terms with large norms and so
explicitly leverages the quadratic model form that is given by the underlying
physics. This means that the proposed approach judiciously learns from data and
physical insights combined, rather than from either data or physics alone.
Additionally, a formulation of operator inference is proposed that enforces
model constraints for preserving structure such as symmetry and definiteness in
the linear terms. Numerical results demonstrate that models learned with
operator inference and the proposed regularizer and structure preservation are
accurate and stable even in cases where using no regularization or Tikhonov
regularization leads to models that are unstable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Explanations in Sequential Decision Making Under Uncertainty. (arXiv:2107.02776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsirtsis_S/0/1/0/all/0/1">Stratis Tsirtsis</a>, <a href="http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1">Abir De</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1">Manuel Gomez-Rodriguez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02776">
                                    <div class="article-summary-box-inner">
                                        <span>Methods to find counterfactual explanations have predominantly focused on one
step decision making processes. In this work, we initiate the development of
methods to find counterfactual explanations for decision making processes in
which multiple, dependent actions are taken sequentially over time. We start by
formally characterizing a sequence of actions and states using finite horizon
Markov decision processes and the Gumbel-Max structural causal model. Building
upon this characterization, we formally state the problem of finding
counterfactual explanations for sequential decision making processes. In our
problem formulation, the counterfactual explanation specifies an alternative
sequence of actions differing in at most k actions from the observed sequence
that could have led the observed process realization to a better outcome. Then,
we introduce a polynomial time algorithm based on dynamic programming to build
a counterfactual policy that is guaranteed to always provide the optimal
counterfactual explanation on every possible realization of the counterfactual
environment dynamics. We validate our algorithm using both synthetic and real
data from cognitive behavioral therapy and show that the counterfactual
explanations our algorithm finds can provide valuable insights to enhance
sequential decision making under uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A deep-learning--based multimodal depth-aware dynamic hand gesture recognition system. (arXiv:2107.02543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1">Hasan Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Morshed_M/0/1/0/all/0/1">Mashrur Mahmud Morshed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md. Kamrul Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02543">
                                    <div class="article-summary-box-inner">
                                        <span>Any spatio-temporal movement or reorientation of the hand, done with the
intention of conveying a specific meaning, can be considered as a hand gesture.
Inputs to hand gesture recognition systems can be in several forms, such as
depth images, monocular RGB, or skeleton joint points. We observe that raw
depth images possess low contrasts in the hand regions of interest (ROI). They
do not highlight important details to learn, such as finger bending information
(whether a finger is overlapping the palm, or another finger). Recently, in
deep-learning--based dynamic hand gesture recognition, researchers are tying to
fuse different input modalities (e.g. RGB or depth images and hand skeleton
joint points) to improve the recognition accuracy. In this paper, we focus on
dynamic hand gesture (DHG) recognition using depth quantized image features and
hand skeleton joint points. In particular, we explore the effect of using
depth-quantized features in Convolutional Neural Network (CNN) and Recurrent
Neural Network (RNN) based multi-modal fusion networks. We find that our method
improves existing results on the SHREC-DHG-14 dataset. Furthermore, using our
method, we show that it is possible to reduce the resolution of the input
images by more than four times and still obtain comparable or better accuracy
to that of the resolutions used in previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer. (arXiv:2107.02681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zineng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02681">
                                    <div class="article-summary-box-inner">
                                        <span>Since visual perception can give rich information beyond text descriptions
for world understanding, there has been increasing interest in leveraging
visual grounding for language learning. Recently, vokenization has attracted
attention by using the predictions of a text-to-image retrieval model as labels
for language model supervision. Despite its success, the method suffers from
approximation error of using finite image labels and the lack of vocabulary
diversity of a small image-text dataset. To overcome these limitations, we
present VidLanKD, a video-language knowledge distillation method for improving
language understanding. We train a multi-modal teacher model on a video-text
dataset, and then transfer its knowledge to a student language model with a
text dataset. To avoid approximation error, we propose to use different
knowledge distillation objectives. In addition, the use of a large-scale
video-text dataset helps learn diverse and richer vocabularies. In our
experiments, VidLanKD achieves consistent improvements over text-only language
models and vokenization models, on several downstream language understanding
tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world
knowledge, physical reasoning, and temporal reasoning capabilities of our model
by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we
present comprehensive ablation studies as well as visualizations of the learned
text-to-video grounding results of our teacher and student language models. Our
code and models are available at: https://github.com/zinengtang/VidLanKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspectral Pansharpening Based on Improved Deep Image Prior and Residual Reconstruction. (arXiv:2107.02630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1">Wele Gedara Chaminda Bandara</a>, <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02630">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral
image (LR-HSI) with a registered panchromatic image (PAN) to generate an
enhanced HSI with high spectral and spatial resolution. Recently proposed HS
pansharpening methods have obtained remarkable results using deep convolutional
networks (ConvNets), which typically consist of three steps: (1) up-sampling
the LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining
the final fused HSI by adding the outputs from first and second steps. Recent
methods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to
its excellent ability to preserve both spatial and spectral information,
without learning from large data sets. However, we observed that the quality of
up-sampled HSIs can be further improved by introducing an additional
spatial-domain constraint to the conventional spectral-domain energy function.
We define our spatial-domain constraint as the $L_1$ distance between the
predicted PAN image and the actual PAN image. To estimate the PAN image of the
up-sampled HSI, we also propose a learnable spectral response function (SRF).
Moreover, we noticed that the residual image between the up-sampled HSI and the
reference HSI mainly consists of edge information and very fine structures. In
order to accurately estimate fine information, we propose a novel over-complete
network, called HyperKite, which focuses on learning high-level features by
constraining the receptive from increasing in the deep layers. We perform
experiments on three HSI datasets to demonstrate the superiority of our
DIP-HyperKite over the state-of-the-art pansharpening methods. The deployment
codes, pre-trained models, and final fusion outputs of our DIP-HyperKite and
the methods used for the comparisons will be publicly made available at
https://github.com/wgcban/DIP-HyperKite.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Total Nitrogen Estimation in Agricultural Soils via Aerial Multispectral Imaging and LIBS. (arXiv:2107.02355v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hossen_M/0/1/0/all/0/1">Md Abir Hossen</a>, <a href="http://arxiv.org/find/eess/1/au:+Diwaka_P/0/1/0/all/0/1">Prasoon K Diwaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Ragi_S/0/1/0/all/0/1">Shankarachary Ragi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02355">
                                    <div class="article-summary-box-inner">
                                        <span>Measuring soil health indicators is an important and challenging task that
affects farmers&#x27; decisions on timing, placement, and quantity of fertilizers
applied in the farms. Most existing methods to measure soil health indicators
(SHIs) are in-lab wet chemistry or spectroscopy-based methods, which require
significant human input and effort, time-consuming, costly, and are
low-throughput in nature. To address this challenge, we develop an artificial
intelligence (AI)-driven near real-time unmanned aerial vehicle (UAV)-based
multispectral sensing (UMS) solution to estimate total nitrogen (TN) of the
soil, an important macro-nutrient or SHI that directly affects the crop health.
Accurate prediction of soil TN can significantly increase crop yield through
informed decision making on the timing of seed planting, and fertilizer
quantity and timing. We train two machine learning models including multi-layer
perceptron and support vector machine to predict the soil nitrogen using a
suite of data classes including multispectral characteristics of the soil and
crops in red, near-infrared, and green spectral bands, computed vegetation
indices, and environmental variables including air temperature and relative
humidity. To generate the ground-truth data or the training data for the
machine learning models, we measure the total nitrogen of the soil samples
(collected from a farm) using laser-induced breakdown spectroscopy (LIBS).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Risk bounds when learning infinitely many response functions by ordinary linear regression. (arXiv:2006.09223v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Plassier_V/0/1/0/all/0/1">Vincent Plassier</a>, <a href="http://arxiv.org/find/stat/1/au:+Portier_F/0/1/0/all/0/1">Fran&#xe7;ois Portier</a>, <a href="http://arxiv.org/find/stat/1/au:+Segers_J/0/1/0/all/0/1">Johan Segers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09223">
                                    <div class="article-summary-box-inner">
                                        <span>Consider the problem of learning a large number of response functions
simultaneously based on the same input variables. The training data consist of
a single independent random sample of the input variables drawn from a common
distribution together with the associated responses. The input variables are
mapped into a high-dimensional linear space, called the feature space, and the
response functions are modelled as linear functionals of the mapped features,
with coefficients calibrated via ordinary least squares. We provide convergence
guarantees on the worst-case excess prediction risk by controlling the
convergence rate of the excess risk uniformly in the response function. The
dimension of the feature map is allowed to tend to infinity with the sample
size. The collection of response functions, although potentially infinite, is
supposed to have a finite Vapnik-Chervonenkis dimension. The bound derived can
be applied when building multiple surrogate models in a reasonable computing
time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Testing With Reusable Adversarial Agents. (arXiv:1910.13645v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1">Xin Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Arechiga_N/0/1/0/all/0/1">Nikos Ar&#xe9;chiga</a>, <a href="http://arxiv.org/find/cs/1/au:+Best_A/0/1/0/all/0/1">Andrew Best</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1">Jyotirmoy Deshmukh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.13645">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous systems such as self-driving cars and general-purpose robots are
safety-critical systems that operate in highly uncertain and dynamic
environments. We propose an interactive multi-agent framework where the
system-under-design is modeled as an ego agent and its environment is modeled
by a number of adversarial (ado) agents. For example, a self-driving car is an
ego agent whose behavior is influenced by ado agents such as pedestrians,
bicyclists, traffic lights, road geometry etc. Given a logical specification of
the correct behavior of the ego agent, and a set of constraints that encode
reasonable adversarial behavior, our framework reduces the adversarial testing
problem to the problem of synthesizing controllers for (constrained) ado agents
that cause the ego agent to violate its specifications. Specifically, we
explore the use of tabular and deep reinforcement learning approaches for
synthesizing adversarial agents. We show that ado agents trained in this
fashion are better than traditional falsification or testing techniques because
they can generalize to ego agents and environments that differ from the
original ego agent. We demonstrate the efficacy of our technique on two
real-world case studies from the domain of self-driving cars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training. (arXiv:2104.14129v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianfei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lianmin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhewei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dequan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14129">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing size of neural network models has been critical for
improvements in their accuracy, but device memory is not growing at the same
rate. This creates fundamental challenges for training neural networks within
limited memory environments. In this work, we propose ActNN, a memory-efficient
training framework that stores randomly quantized activations for back
propagation. We prove the convergence of ActNN for general network
architectures, and we characterize the impact of quantization on the
convergence via an exact expression for the gradient variance. Using our
theory, we propose novel mixed-precision quantization strategies that exploit
the activation&#x27;s heterogeneity across feature dimensions, samples, and layers.
These techniques can be readily applied to existing dynamic graph frameworks,
such as PyTorch, simply by substituting the layers. We evaluate ActNN on
mainstream computer vision models for classification, detection, and
segmentation tasks. On all these tasks, ActNN compresses the activation to 2
bits on average, with negligible accuracy loss. ActNN reduces the memory
footprint of the activation by 12x, and it enables training with a 6.6x to 14x
larger batch size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Strict Generalisation Benefit for Equivariant Models. (arXiv:2102.10333v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Elesedy_B/0/1/0/all/0/1">Bryn Elesedy</a>, <a href="http://arxiv.org/find/stat/1/au:+Zaidi_S/0/1/0/all/0/1">Sheheryar Zaidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10333">
                                    <div class="article-summary-box-inner">
                                        <span>It is widely believed that engineering a model to be invariant/equivariant
improves generalisation. Despite the growing popularity of this approach, a
precise characterisation of the generalisation benefit is lacking. By
considering the simplest case of linear models, this paper provides the first
provably non-zero improvement in generalisation for invariant/equivariant
models when the target distribution is invariant/equivariant with respect to a
compact group. Moreover, our work reveals an interesting relationship between
generalisation, the number of training examples and properties of the group
action. Our results rest on an observation of the structure of function spaces
under averaging operators which, along with its consequences for feature
averaging, may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven reduced order modeling of environmental hydrodynamics using deep autoencoders and neural ODEs. (arXiv:2107.02784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Sourav Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivera_Casillas_P/0/1/0/all/0/1">Peter Rivera-Casillas</a>, <a href="http://arxiv.org/find/cs/1/au:+Cecil_O/0/1/0/all/0/1">Orie M. Cecil</a>, <a href="http://arxiv.org/find/cs/1/au:+Farthing_M/0/1/0/all/0/1">Matthew W. Farthing</a>, <a href="http://arxiv.org/find/cs/1/au:+Perracchione_E/0/1/0/all/0/1">Emma Perracchione</a>, <a href="http://arxiv.org/find/cs/1/au:+Putti_M/0/1/0/all/0/1">Mario Putti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02784">
                                    <div class="article-summary-box-inner">
                                        <span>Model reduction for fluid flow simulation continues to be of great interest
across a number of scientific and engineering fields. In a previous work
[arXiv:2104.13962], we explored the use of Neural Ordinary Differential
Equations (NODE) as a non-intrusive method for propagating the latent-space
dynamics in reduced order models. Here, we investigate employing deep
autoencoders for discovering the reduced basis representation, the dynamics of
which are then approximated by NODE. The ability of deep autoencoders to
represent the latent-space is compared to the traditional proper orthogonal
decomposition (POD) approach, again in conjunction with NODE for capturing the
dynamics. Additionally, we compare their behavior with two classical
non-intrusive methods based on POD and radial basis function interpolation as
well as dynamic mode decomposition. The test problems we consider include
incompressible flow around a cylinder as well as a real-world application of
shallow water hydrodynamics in an estuarine system. Our findings indicate that
deep autoencoders can leverage nonlinear manifold learning to achieve a highly
efficient compression of spatial information and define a latent-space that
appears to be more suitable for capturing the temporal dynamics through the
NODE framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An $\ell_p$ theory of PCA and spectral clustering. (arXiv:2006.14062v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Abbe_E/0/1/0/all/0/1">Emmanuel Abbe</a>, <a href="http://arxiv.org/find/math/1/au:+Fan_J/0/1/0/all/0/1">Jianqing Fan</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_K/0/1/0/all/0/1">Kaizheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14062">
                                    <div class="article-summary-box-inner">
                                        <span>Principal Component Analysis (PCA) is a powerful tool in statistics and
machine learning. While existing study of PCA focuses on the recovery of
principal components and their associated eigenvalues, there are few precise
characterizations of individual principal component scores that yield
low-dimensional embedding of samples. That hinders the analysis of various
spectral methods. In this paper, we first develop an $\ell_p$ perturbation
theory for a hollowed version of PCA in Hilbert spaces which provably improves
upon the vanilla PCA in the presence of heteroscedastic noises. Through a novel
$\ell_p$ analysis of eigenvectors, we investigate entrywise behaviors of
principal component score vectors and show that they can be approximated by
linear functionals of the Gram matrix in $\ell_p$ norm, which includes $\ell_2$
and $\ell_\infty$ as special examples. For sub-Gaussian mixture models, the
choice of $p$ giving optimal bounds depends on the signal-to-noise ratio, which
further yields optimality guarantees for spectral clustering. For contextual
community detection, the $\ell_p$ theory leads to a simple spectral algorithm
that achieves the information threshold for exact recovery. These also provide
optimal recovery results for Gaussian mixture and stochastic block models as
special cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Experts&#x27; Opinions in Machine Learning Tasks. (arXiv:2008.04216v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Habibi_J/0/1/0/all/0/1">Jafar Habibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazelinia_A/0/1/0/all/0/1">Amir Fazelinia</a>, <a href="http://arxiv.org/find/cs/1/au:+Annamoradnejad_I/0/1/0/all/0/1">Issa Annamoradnejad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04216">
                                    <div class="article-summary-box-inner">
                                        <span>In machine learning tasks, especially in the tasks of prediction, scientists
tend to rely solely on available historical data and disregard unproven
insights, such as experts&#x27; opinions, polls, and betting odds. In this paper, we
propose a general three-step framework for utilizing experts&#x27; insights in
machine learning tasks and build four concrete models for a sports game
prediction case study. For the case study, we have chosen the task of
predicting NCAA Men&#x27;s Basketball games, which has been the focus of a group of
Kaggle competitions in recent years. Results highly suggest that the good
performance and high scores of the past models are a result of chance, and not
because of a good-performing and stable model. Furthermore, our proposed models
can achieve more steady results with lower log loss average (best at 0.489)
compared to the top solutions of the 2019 competition (&gt;0.503), and reach the
top 1%, 10% and 1% in the 2017, 2018 and 2019 leaderboards, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Model-Driven Engineering Approach to Machine Learning and Software Modeling. (arXiv:2107.02689v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1">Armin Moin</a>, <a href="http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1">Atta Badii</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02689">
                                    <div class="article-summary-box-inner">
                                        <span>Models are used in both the Software Engineering (SE) and the Artificial
Intelligence (AI) communities. In the former case, models of software, which
may specify the software system architecture on different levels of abstraction
could be used in various stages of the Software Development Life-Cycle (SDLC),
from early conceptualization and design, to verification, implementation,
testing and evolution. However, in the latter case, i.e., AI, models may
provide smart capabilities, such as prediction and decision making support. For
instance, in Machine Learning (ML), which is the most popular sub-discipline of
AI at the present time, mathematical models may learn useful patterns in the
observed data instances and can become capable of making better predictions or
recommendations in the future. The goal of this work is to create synergy by
bringing models in the said communities together and proposing a holistic
approach. We illustrate how software models can become capable of producing or
dealing with data analytics and ML models. The main focus is on the Internet of
Things (IoT) and smart Cyber-Physical Systems (CPS) use cases, where both ML
and model-driven (model-based) SE play a key role. In particular, we implement
the proposed approach in an open source prototype and validate it using two use
cases from the IoT/CPS domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LTL2Action: Generalizing LTL Instructions for Multi-Task RL. (arXiv:2102.06858v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaezipoor_P/0/1/0/all/0/1">Pashootan Vaezipoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Andrew Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Icarte_R/0/1/0/all/0/1">Rodrigo Toro Icarte</a>, <a href="http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1">Sheila McIlraith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06858">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of teaching a deep reinforcement learning (RL) agent
to follow instructions in multi-task environments. Instructions are expressed
in a well-known formal language -- linear temporal logic (LTL) -- and can
specify a diversity of complex, temporally extended behaviours, including
conditionals and alternative realizations. Our proposed learning approach
exploits the compositional syntax and the semantics of LTL, enabling our RL
agent to learn task-conditioned policies that generalize to new instructions,
not observed during training. To reduce the overhead of learning LTL semantics,
we introduce an environment-agnostic LTL pretraining scheme which improves
sample-efficiency in downstream environments. Experiments on discrete and
continuous domains target combinatorial task sets of up to $\sim10^{39}$ unique
tasks and demonstrate the strength of our approach in learning to solve
(unseen) tasks, given LTL instructions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation. (arXiv:2107.02655v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbera_G/0/1/0/all/0/1">Giammarco La Barbera</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Boussaid_H/0/1/0/all/0/1">Haithem Boussaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Belucci_B/0/1/0/all/0/1">Bruno Belucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmonte_A/0/1/0/all/0/1">Alessandro Delmonte</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulin_J/0/1/0/all/0/1">Jeanne Goulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarnacki_S/0/1/0/all/0/1">Sabine Sarnacki</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouet_L/0/1/0/all/0/1">Laurence Rouet</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02655">
                                    <div class="article-summary-box-inner">
                                        <span>Due to a high heterogeneity in pose and size and to a limited number of
available data, segmentation of pediatric images is challenging for deep
learning methods. In this work, we propose a new CNN architecture that is pose
and scale invariant thanks to the use of Spatial Transformer Network (STN). Our
architecture is composed of three sequential modules that are estimated
together during training: (i) a regression module to estimate a similarity
matrix to normalize the input image to a reference one; (ii) a differentiable
module to find the region of interest to segment; (iii) a segmentation module,
based on the popular UNet architecture, to delineate the object. Unlike the
original UNet, which strives to learn a complex mapping, including pose and
scale variations, from a finite training dataset, our segmentation module
learns a simpler mapping focusing on images with normalized pose and size.
Furthermore, the use of an automatic bounding box detection through STN allows
saving time and especially memory, while keeping similar performance. We test
the proposed method in kidney and renal tumor segmentation on abdominal
pediatric CT scanners. Results indicate that the estimated STN homogenization
of size and pose accelerates the segmentation (25h), compared to standard
data-augmentation (33h), while obtaining a similar quality for the kidney
(88.01\% of Dice score) and improving the renal tumor delineation (from 85.52\%
to 87.12\%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamical System Parameter Identification using Deep Recurrent Cell Networks. (arXiv:2107.02427v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akagunduz_E/0/1/0/all/0/1">Erdem Akag&#xfc;nd&#xfc;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Cifdaloz_O/0/1/0/all/0/1">Oguzhan Cifdaloz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02427">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the parameter identification problem in
dynamical systems through a deep learning approach. Focusing mainly on
second-order, linear time-invariant dynamical systems, the topic of damping
factor identification is studied. By utilizing a six-layer deep neural network
with different recurrent cells, namely GRUs, LSTMs or BiLSTMs; and by feeding
input-output sequence pairs captured from a dynamical system simulator, we
search for an effective deep recurrent architecture in order to resolve damping
factor identification problem. Our study results show that, although previously
not utilized for this task in the literature, bidirectional gated recurrent
cells (BiLSTMs) provide better parameter identification results when compared
to unidirectional gated recurrent memory cells such as GRUs and LSTM. Thus,
indicating that an input-output sequence pair of finite length, collected from
a dynamical system and when observed anachronistically, may carry information
in both time directions for prediction of a dynamical systems parameter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DriveML: An R Package for Driverless Machine Learning. (arXiv:2005.00478v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Putatunda_S/0/1/0/all/0/1">Sayan Putatunda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1">Dayananda Ubrangala</a>, <a href="http://arxiv.org/find/cs/1/au:+Rama_K/0/1/0/all/0/1">Kiran Rama</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1">Ravi Kondapalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00478">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the concept of automated machine learning has become very
popular. Automated Machine Learning (AutoML) mainly refers to the automated
methods for model selection and hyper-parameter optimization of various
algorithms such as random forests, gradient boosting, neural networks, etc. In
this paper, we introduce a new package i.e. DriveML for automated machine
learning. DriveML helps in implementing some of the pillars of an automated
machine learning pipeline such as automated data preparation, feature
engineering, model building and model explanation by running the function
instead of writing lengthy R codes. The DriveML package is available in CRAN.
We compare the DriveML package with other relevant packages in CRAN/Github and
find that DriveML performs the best across different parameters. We also
provide an illustration by applying the DriveML package with default
configuration on a real world dataset. Overall, the main benefits of DriveML
are in development time savings, reduce developer&#x27;s errors, optimal tuning of
machine learning models and reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dirichlet Energy Constrained Learning for Deep Graph Neural Networks. (arXiv:2107.02392v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaixiong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1">Daochen Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Rui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Li Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Soo-Hyun Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02392">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) integrate deep architectures and topological
structure modeling in an effective way. However, the performance of existing
GNNs would decrease significantly when they stack many layers, because of the
over-smoothing issue. Node embeddings tend to converge to similar vectors when
GNNs keep recursively aggregating the representations of neighbors. To enable
deep GNNs, several methods have been explored recently. But they are developed
from either techniques in convolutional neural networks or heuristic
strategies. There is no generalizable and theoretical principle to guide the
design of deep GNNs. To this end, we analyze the bottleneck of deep GNNs by
leveraging the Dirichlet energy of node embeddings, and propose a generalizable
principle to guide the training of deep GNNs. Based on it, a novel deep GNN
framework -- EGNN is designed. It could provide lower and upper constraints in
terms of Dirichlet energy at each layer to avoid over-smoothing. Experimental
results demonstrate that EGNN achieves state-of-the-art performance by using
deep layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Annealing Formulation for Binary Neural Networks. (arXiv:2107.02751v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Sasdelli_M/0/1/0/all/0/1">Michele Sasdelli</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chin_T/0/1/0/all/0/1">Tat-Jun Chin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02751">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum annealing is a promising paradigm for building practical quantum
computers. Compared to other approaches, quantum annealing technology has been
scaled up to a larger number of qubits. On the other hand, deep learning has
been profoundly successful in pushing the boundaries of AI. It is thus natural
to investigate potentially game changing technologies such as quantum annealers
to augment the capabilities of deep learning. In this work, we explore binary
neural networks, which are lightweight yet powerful models typically intended
for resource constrained devices. Departing from current training regimes for
binary networks that smooth/approximate the activation functions to make the
network differentiable, we devise a quadratic unconstrained binary optimization
formulation for the training problem. While the problem is intractable, i.e.,
the cost to estimate the binary weights scales exponentially with network size,
we show how the problem can be optimized directly on a quantum annealer,
thereby opening up to the potential gains of quantum computing. We
experimentally validated our formulation via simulation and testing on an
actual quantum annealer (D-Wave Advantage), the latter to the extent allowable
by the capacity of current technology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Off-Policy Evaluation Approach for General Value Function. (arXiv:2107.02711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tengyu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingbin Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02711">
                                    <div class="article-summary-box-inner">
                                        <span>General Value Function (GVF) is a powerful tool to represent both the {\em
predictive} and {\em retrospective} knowledge in reinforcement learning (RL).
In practice, often multiple interrelated GVFs need to be evaluated jointly with
pre-collected off-policy samples. In the literature, the gradient temporal
difference (GTD) learning method has been adopted to evaluate GVFs in the
off-policy setting, but such an approach may suffer from a large estimation
error even if the function approximation class is sufficiently expressive.
Moreover, none of the previous work have formally established the convergence
guarantee to the ground truth GVFs under the function approximation settings.
In this paper, we address both issues through the lens of a class of GVFs with
causal filtering, which cover a wide range of RL applications such as reward
variance, value gradient, cost in anomaly detection, stationary distribution
gradient, etc. We propose a new algorithm called GenTD for off-policy GVFs
evaluation and show that GenTD learns multiple interrelated multi-dimensional
GVFs as efficiently as a single canonical scalar value function. We further
show that unlike GTD, the learned GVFs by GenTD are guaranteed to converge to
the ground truth GVFs as long as the function approximation power is
sufficiently large. To our best knowledge, GenTD is the first off-policy GVF
evaluation algorithm that has global optimality guarantee.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ML-Quadrat &amp; DriotData: A Model-Driven Engineering Tool and a Low-Code Platform for Smart IoT Services. (arXiv:2107.02692v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1">Armin Moin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mituca_A/0/1/0/all/0/1">Andrei Mituca</a>, <a href="http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1">Atta Badii</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02692">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present the novel early tool prototype of ML-Quadrat, which
is an open source research prototype, based on the Eclipse Modeling Framework
(EMF) and the state of the art in the literature of Model-Driven Software
Engineering (MDSE) for smart Cyber-Physical Systems (CPS) and the Internet of
Things (IoT). Its envisioned users are mostly software developers, who might
not have deep knowledge and skills in the heterogeneous IoT platforms and the
diverse Artificial Intelligence (AI) technologies, specifically regarding Data
Analytics and Machine Learning (DAML). ML-Quadrat is released under the terms
of the Apache 2.0 license on Github: https://github.com/arminmoin/ML-Quadrat.
Additionally, the novel early tool prototype of DriotData, a Low-Code platform
targeting citizen data scientists and citizen/end-user software developers is
demonstrated. DriotData exploits and adopts ML-Quadrat and offers an extended
version of it as a web-based service to companies, especially Small- and
Medium-Sized Enterprises (SME). A basic web-based demo of the Minimum Viable
Product (MVP) of DriotData is already available. Finally, a short video
demonstrating the tools is available on YouTube: https://youtu.be/YCNFfhmy_JY.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prioritized training on points that are learnable, worth learning, and not yet learned. (arXiv:2107.02565v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1">S&#xf6;ren Mindermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Razzak_M/0/1/0/all/0/1">Muhammed Razzak</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Winnie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirsch_A/0/1/0/all/0/1">Andreas Kirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1">Mrinank Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Morisot_A/0/1/0/all/0/1">Adrien Morisot</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Aidan N. Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1">Sebastian Farquhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1">Jan Brauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02565">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Goldilocks Selection, a technique for faster model training
which selects a sequence of training points that are &quot;just right&quot;. We propose
an information-theoretic acquisition function -- the reducible validation loss
-- and compute it with a small proxy model -- GoldiProx -- to efficiently
choose training points that maximize information about a validation set. We
show that the &quot;hard&quot; (e.g. high loss) points usually selected in the
optimization literature are typically noisy, while the &quot;easy&quot; (e.g. low noise)
samples often prioritized for curriculum learning confer less information.
Further, points with uncertain labels, typically targeted by active learning,
tend to be less relevant to the task. In contrast, Goldilocks Selection chooses
points that are &quot;just right&quot; and empirically outperforms the above approaches.
Moreover, the selected sequence can transfer to other architectures;
practitioners can share and reuse it without the need to recreate it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedFog: Network-Aware Optimization of Federated Learning over Wireless Fog-Cloud Systems. (arXiv:2107.02755v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Van-Dinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzinotas_S/0/1/0/all/0/1">Symeon Chatzinotas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ottersten_B/0/1/0/all/0/1">Bjorn Ottersten</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1">Trung Q. Duong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02755">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is capable of performing large distributed machine
learning tasks across multiple edge users by periodically aggregating trained
local parameters. To address key challenges of enabling FL over a wireless
fog-cloud system (e.g., non-i.i.d. data, users&#x27; heterogeneity), we first
propose an efficient FL algorithm (called FedFog) to perform the local
aggregation of gradient parameters at fog servers and global training update at
the cloud. Next, we employ FedFog in wireless fog-cloud systems by
investigating a novel network-aware FL optimization problem that strikes the
balance between the global loss and completion time. An iterative algorithm is
then developed to obtain a precise measurement of the system performance, which
helps design an efficient stopping criteria to output an appropriate number of
global rounds. To mitigate the straggler effect, we propose a flexible user
aggregation strategy that trains fast users first to obtain a certain level of
accuracy before allowing slow users to join the global training updates.
Extensive numerical results using several real-world FL tasks are provided to
verify the theoretical convergence of FedFog. We also show that the proposed
co-design of FL and communication is essential to substantially improve
resource utilization while achieving comparable accuracy of the learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DTGAN: Differential Private Training for Tabular GANs. (arXiv:2107.02521v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kunar_A/0/1/0/all/0/1">Aditya Kunar</a>, <a href="http://arxiv.org/find/cs/1/au:+Birke_R/0/1/0/all/0/1">Robert Birke</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lydia Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zilong Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02521">
                                    <div class="article-summary-box-inner">
                                        <span>Tabular generative adversarial networks (TGAN) have recently emerged to cater
to the need of synthesizing tabular data -- the most widely used data format.
While synthetic tabular data offers the advantage of complying with privacy
regulations, there still exists a risk of privacy leakage via inference attacks
due to interpolating the properties of real data during training. Differential
private (DP) training algorithms provide theoretical guarantees for training
machine learning models by injecting statistical noise to prevent privacy
leaks. However, the challenges of applying DP on TGAN are to determine the most
optimal framework (i.e., PATE/DP-SGD) and neural network (i.e.,
Generator/Discriminator)to inject noise such that the data utility is well
maintained under a given privacy guarantee. In this paper, we propose DTGAN, a
novel conditional Wasserstein tabular GAN that comes in two variants DTGAN_G
and DTGAN_D, for providing a detailed comparison of tabular GANs trained using
DP-SGD for the generator vs discriminator, respectively. We elicit the privacy
analysis associated with training the generator with complex loss functions
(i.e., classification and information losses) needed for high quality tabular
data synthesis. Additionally, we rigorously evaluate the theoretical privacy
guarantees offered by DP empirically against membership and attribute inference
attacks. Our results on 3 datasets show that the DP-SGD framework is superior
to PATE and that a DP discriminator is more optimal for training convergence.
Thus, we find (i) DTGAN_D is capable of maintaining the highest data utility
across 4 ML models by up to 18% in terms of the average precision score for a
strict privacy budget, epsilon &#x3D; 1, as compared to the prior studies and (ii)
DP effectively prevents privacy loss against inference attacks by restricting
the success probability of membership attacks to be close to 50%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Generalization of Graph Autoencoders with Adversarial Training. (arXiv:2107.02658v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+huang_T/0/1/0/all/0/1">Tianjin huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_Y/0/1/0/all/0/1">Yulong Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1">Vlado Menkovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02658">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is an approach for increasing model&#x27;s resilience against
adversarial perturbations. Such approaches have been demonstrated to result in
models with feature representations that generalize better. However, limited
works have been done on adversarial training of models on graph data. In this
paper, we raise such a question { does adversarial training improve the
generalization of graph representations. We formulate L2 and L1 versions of
adversarial training in two powerful node embedding methods: graph autoencoder
(GAE) and variational graph autoencoder (VGAE). We conduct extensive
experiments on three main applications, i.e. link prediction, node clustering,
graph anomaly detection of GAE and VGAE, and demonstrate that both L2 and L1
adversarial training boost the generalization of GAE and VGAE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Dataset Complexity Matters for Model Explainers?. (arXiv:2107.02661v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_J/0/1/0/all/0/1">Jos&#xe9; Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ra&#xed;ssa Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Alves_R/0/1/0/all/0/1">Ronnie Alves</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02661">
                                    <div class="article-summary-box-inner">
                                        <span>Strategies based on Explainable Artificial Intelligence - XAI have emerged in
computing to promote a better understanding of predictions made by black box
models. Most XAI-based tools used today explain these types of models,
generating attribute rankings aimed at explaining the same, that is, the
analysis of Attribute Importance. There is no consensus on which XAI tool
generates a general rank of explainability, for this reason, several proposals
for tools have emerged (Ciu, Dalex, Eli5, Lofo, Shap and Skater). Here, we
present an experimental benchmark of explainable AI techniques capable of
producing model-agnostic global explainability ranks based on tabular data
related to different problems. Seeking to answer questions such as &quot;Are the
explanations generated by the different tools the same, similar or different?&quot;
and &quot;How does data complexity play along model explainability?&quot;. The results
from the construction of 82 computational models and 592 ranks give us some
light on the other side of the problem of explainability: dataset complexity!</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning. (arXiv:2107.02729v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Biwei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chaochao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Magliacane_S/0/1/0/all/0/1">Sara Magliacane</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02729">
                                    <div class="article-summary-box-inner">
                                        <span>Most approaches in reinforcement learning (RL) are data-hungry and specific
to fixed environments. In this paper, we propose a principled framework for
adaptive RL, called AdaRL, that adapts reliably to changes across domains.
Specifically, we construct a generative environment model for the structural
relationships among variables in the system and embed the changes in a compact
way, which provides a clear and interpretable picture for locating what and
where the changes are and how to adapt. Based on the environment model, we
characterize a minimal set of representations, including both domain-specific
factors and domain-shared state representations, that suffice for reliable and
low-cost transfer. Moreover, we show that by explicitly leveraging a compact
representation to encode changes, we can adapt the policy with only a few
samples without further policy optimization in the target domain. We illustrate
the efficacy of AdaRL through a series of experiments that allow for changes in
different components of Cartpole and Atari games.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early Recognition of Ball Catching Success in Clinical Trials with RNN-Based Predictive Classification. (arXiv:2107.02442v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lang_J/0/1/0/all/0/1">Jana Lang</a>, <a href="http://arxiv.org/find/cs/1/au:+Giese_M/0/1/0/all/0/1">Martin A. Giese</a>, <a href="http://arxiv.org/find/cs/1/au:+Synofzik_M/0/1/0/all/0/1">Matthis Synofzik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilg_W/0/1/0/all/0/1">Winfried Ilg</a>, <a href="http://arxiv.org/find/cs/1/au:+Otte_S/0/1/0/all/0/1">Sebastian Otte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02442">
                                    <div class="article-summary-box-inner">
                                        <span>Motor disturbances can affect the interaction with dynamic objects, such as
catching a ball. A classification of clinical catching trials might give
insight into the existence of pathological alterations in the relation of arm
and ball movements. Accurate, but also early decisions are required to classify
a catching attempt before the catcher&#x27;s first ball contact. To obtain
clinically valuable results, a significant decision confidence of at least 75%
is required. Hence, three competing objectives have to be optimized at the same
time: accuracy, earliness and decision-making confidence. Here we propose a
coupled classification and prediction approach for early time series
classification: a predictive, generative recurrent neural network (RNN)
forecasts the next data points of ball trajectories based on already available
observations; a discriminative RNN continuously generates classification
guesses based on the available data points and the unrolled sequence
predictions. We compare our approach, which we refer to as predictive
sequential classification (PSC), to state-of-the-art sequence learners,
including various RNN and temporal convolutional network (TCN) architectures.
On this hard real-world task we can consistently demonstrate the superiority of
PSC over all other models in terms of accuracy and confidence with respect to
earliness of recognition. Specifically, PSC is able to confidently classify the
success of catching trials as early as 123 milliseconds before the first ball
contact. We conclude that PSC is a promising approach for early time series
classification, when accurate and confident decisions are required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Informed Graph Learning for Robust Fault Location in Distribution Systems. (arXiv:2107.02275v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenting Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deka_D/0/1/0/all/0/1">Deepjyoti Deka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02275">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid growth of distributed energy resources potentially increases power
grid instability. One promising strategy is to employ data in power grids to
efficiently respond to abnormal events (e.g., faults) by detection and
location. Unfortunately, most existing works lack physical interpretation and
are vulnerable to the practical challenges: sparse observation, insufficient
labeled datasets, and stochastic environment. We propose a physics-informed
graph learning framework of two stages to handle these challenges when locating
faults. Stage- I focuses on informing a graph neural network (GNN) with the
geometrical structure of power grids; stage-II employs the physical similarity
of labeled and unlabeled data samples to improve the location accuracy. We
provide a random walk-based the underpinning of designing our GNNs to address
the challenge of sparse observation and augment the correct prediction
probability. We compare our approach with three baselines in the IEEE 123-node
benchmark system, showing that the proposed method outperforms the others by
significant margins, especially when label rates are low. Also, we validate the
robustness of our algorithms to out-of-distribution-data (ODD) due to topology
changes and load variations. Additionally, we adapt our graph learning
framework to the IEEE 37-node test feeder and show high location performance
with the proposed training strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Bandits on General Graphs. (arXiv:2107.02772v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maiti_A/0/1/0/all/0/1">Aurghya Maiti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1">Vineet Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_G/0/1/0/all/0/1">Gaurav Sinha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02772">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of determining the best intervention in a Causal
Bayesian Network (CBN) specified only by its causal graph. We model this as a
stochastic multi-armed bandit (MAB) problem with side-information, where the
interventions correspond to the arms of the bandit instance. First, we propose
a simple regret minimization algorithm that takes as input a semi-Markovian
causal graph with atomic interventions and possibly unobservable variables, and
achieves $\tilde{O}(\sqrt{M/T})$ expected simple regret, where $M$ is dependent
on the input CBN and could be very small compared to the number of arms. We
also show that this is almost optimal for CBNs described by causal graphs
having an $n$-ary tree structure. Our simple regret minimization results, both
upper and lower bound, subsume previous results in the literature, which
assumed additional structural restrictions on the input causal graph. In
particular, our results indicate that the simple regret guarantee of our
proposed algorithm can only be improved by considering more nuanced structural
restrictions on the causal graph. Next, we propose a cumulative regret
minimization algorithm that takes as input a general causal graph with all
observable nodes and atomic interventions and performs better than the optimal
MAB algorithm that does not take causal side-information into account. We also
experimentally compare both our algorithms with the best known algorithms in
the literature. To the best of our knowledge, this work gives the first simple
and cumulative regret minimization algorithms for CBNs with general causal
graphs under atomic interventions and having unobserved confounders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Methods for Joint Optimization of Beamforming and Fronthaul Quantization in Cloud Radio Access Networks. (arXiv:2107.02520v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yu_D/0/1/0/all/0/1">Daesung Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1">Hoon Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1">Seok-Hwan Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Hong_S/0/1/0/all/0/1">Seung-Eun Hong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02520">
                                    <div class="article-summary-box-inner">
                                        <span>Cooperative beamforming across access points (APs) and fronthaul quantization
strategies are essential for cloud radio access network (C-RAN) systems. The
nonconvexity of the C-RAN optimization problems, which is stemmed from per-AP
power and fronthaul capacity constraints, requires high computational
complexity for executing iterative algorithms. To resolve this issue, we
investigate a deep learning approach where the optimization module is replaced
with a well-trained deep neural network (DNN). An efficient learning solution
is proposed which constructs a DNN to produce a low-dimensional representation
of optimal beamforming and quantization strategies. Numerical results validate
the advantages of the proposed learning solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEANN: Speeding up Kernel-Density Estimation using Approximate Nearest Neighbor Search. (arXiv:2107.02736v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karppa_M/0/1/0/all/0/1">Matti Karppa</a>, <a href="http://arxiv.org/find/cs/1/au:+Aumuller_M/0/1/0/all/0/1">Martin Aum&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1">Rasmus Pagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02736">
                                    <div class="article-summary-box-inner">
                                        <span>Kernel Density Estimation (KDE) is a nonparametric method for estimating the
shape of a density function, given a set of samples from the distribution.
Recently, locality-sensitive hashing, originally proposed as a tool for nearest
neighbor search, has been shown to enable fast KDE data structures. However,
these approaches do not take advantage of the many other advances that have
been made in algorithms for nearest neighbor algorithms. We present an
algorithm called Density Estimation from Approximate Nearest Neighbors (DEANN)
where we apply Approximate Nearest Neighbor (ANN) algorithms as a black box
subroutine to compute an unbiased KDE. The idea is to find points that have a
large contribution to the KDE using ANN, compute their contribution exactly,
and approximate the remainder with Random Sampling (RS). We present a
theoretical argument that supports the idea that an ANN subroutine can speed up
the evaluation. Furthermore, we provide a C++ implementation with a Python
interface that can make use of an arbitrary ANN implementation as a subroutine
for KDE evaluation. We show empirically that our implementation outperforms
state of the art implementations in all high dimensional datasets we
considered, and matches the performance of RS in cases where the ANN yield no
gains in performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The QR decomposition for radial neural networks. (arXiv:2107.02550v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganev_I/0/1/0/all/0/1">Iordan Ganev</a>, <a href="http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1">Robin Walters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02550">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a theoretical framework for neural networks in terms of the
representation theory of quivers, thus revealing symmetries of the parameter
space of neural networks. An exploitation of these symmetries leads to a model
compression algorithm for radial neural networks based on an analogue of the QR
decomposition. A projected version of backpropogation on the original model
matches usual backpropogation on the compressed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy and Thermal-aware Resource Management of Cloud Data Centres: A Taxonomy and Future Directions. (arXiv:2107.02342v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ilager_S/0/1/0/all/0/1">Shashikant Ilager</a>, <a href="http://arxiv.org/find/cs/1/au:+Buyya_R/0/1/0/all/0/1">Rajkumar Buyya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02342">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the existing resource management approaches in Cloud
Data Centres for energy and thermal efficiency. It identifies the need for
integrated computing and cooling systems management and learning-based
solutions in resource management systems. A taxonomy on energy and thermal
efficient resource management in data centres is proposed based on an in-depth
analysis of the literature. Furthermore, a detailed survey on existing
approaches is conducted according to the taxonomy and recent advancements
including machine learning-based resource management approaches and cooling
management technologies are discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Universal Dependency Parsing with Automated Concatenation of Embeddings. (arXiv:2107.02416v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zixia Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02416">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the system used in submission from SHANGHAITECH team to
the IWPT 2021 Shared Task. Our system is a graph-based parser with the
technique of Automated Concatenation of Embeddings (ACE). Because recent work
found that better word representations can be obtained by concatenating
different types of embeddings, we use ACE to automatically find the better
concatenation of embeddings for the task of enhanced universal dependencies.
According to official results averaged on 17 languages, our system ranks 2nd
over 9 teams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style. (arXiv:2107.02530v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yuzi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02530">
                                    <div class="article-summary-box-inner">
                                        <span>While recent text to speech (TTS) models perform very well in synthesizing
reading-style (e.g., audiobook) speech, it is still challenging to synthesize
spontaneous-style speech (e.g., podcast or conversation), mainly because of two
reasons: 1) the lack of training data for spontaneous speech; 2) the difficulty
in modeling the filled pauses (um and uh) and diverse rhythms in spontaneous
speech. In this paper, we develop AdaSpeech 3, an adaptive TTS system that
fine-tunes a well-trained reading-style TTS model for spontaneous-style speech.
Specifically, 1) to insert filled pauses (FP) in the text sequence
appropriately, we introduce an FP predictor to the TTS model; 2) to model the
varying rhythms, we introduce a duration predictor based on mixture of experts
(MoE), which contains three experts responsible for the generation of fast,
medium and slow speech respectively, and fine-tune it as well as the pitch
predictor for rhythm adaptation; 3) to adapt to other speaker timbre, we
fine-tune some parameters in the decoder with few speech data. To address the
challenge of lack of training data, we mine a spontaneous speech dataset to
support our research this work and facilitate future research on spontaneous
TTS. Experiments show that AdaSpeech 3 synthesizes speech with natural FP and
rhythms in spontaneous styles, and achieves much better MOS and SMOS scores
than previous adaptive TTS systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity. (arXiv:2107.02306v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vysogorets_A/0/1/0/all/0/1">Artem Vysogorets</a>, <a href="http://arxiv.org/find/cs/1/au:+Kempe_J/0/1/0/all/0/1">Julia Kempe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02306">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network pruning is a fruitful area of research with surging interest
in high sparsity regimes. Benchmarking in this domain heavily relies on
faithful representation of the sparsity of subnetworks, which has been
traditionally computed as the fraction of removed connections (direct
sparsity). This definition, however, fails to recognize unpruned parameters
that detached from input or output layers of underlying subnetworks,
potentially underestimating actual effective sparsity: the fraction of
inactivated connections. While this effect might be negligible for moderately
pruned networks (up to 10-100 compression rates), we find that it plays an
increasing role for thinner subnetworks, greatly distorting comparison between
different pruning algorithms. For example, we show that effective compression
of a randomly pruned LeNet-300-100 can be orders of magnitude larger than its
direct counterpart, while no discrepancy is ever observed when using SynFlow
for pruning [Tanaka et al., 2020]. In this work, we adopt the lens of effective
sparsity to reevaluate several recent pruning algorithms on common benchmark
architectures (e.g., LeNet-300-100, VGG-19, ResNet-18) and discover that their
absolute and relative performance changes dramatically in this new and more
appropriate framework. To aim for effective, rather than direct, sparsity, we
develop a low-cost extension to most pruning algorithms. Further, equipped with
effective sparsity as a reference frame, we partially reconfirm that random
pruning with appropriate sparsity allocation across layers performs as well or
better than more sophisticated algorithms for pruning at initialization [Su et
al., 2020]. In response to this observation, using a simple analogy of pressure
distribution in coupled cylinders from physics, we design novel layerwise
sparsity quotas that outperform all existing baselines in the context of random
pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Evaluation of Machine Learning and Deep Learning Models for Drought Prediction using Weather Data. (arXiv:2107.02517v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiayun Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02517">
                                    <div class="article-summary-box-inner">
                                        <span>Drought is a serious natural disaster that has a long duration and a wide
range of influence. To decrease the drought-caused losses, drought prediction
is the basis of making the corresponding drought prevention and disaster
reduction measures. While this problem has been studied in the literature, it
remains unknown whether drought can be precisely predicted or not with machine
learning models using weather data. To answer this question, a real-world
public dataset is leveraged in this study and different drought levels are
predicted using the last 90 days of 18 meteorological indicators as the
predictors. In a comprehensive approach, 16 machine learning models and 16 deep
learning models are evaluated and compared. The results show no single model
can achieve the best performance for all evaluation metrics simultaneously,
which indicates the drought prediction problem is still challenging. As
benchmarks for further studies, the code and results are publicly available in
a Github repository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equivariant bifurcation, quadratic equivariants, and symmetry breaking for the standard representation of $S_n$. (arXiv:2107.02422v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arjevani_Y/0/1/0/all/0/1">Yossi Arjevani</a>, <a href="http://arxiv.org/find/cs/1/au:+Field_M/0/1/0/all/0/1">Michael Field</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02422">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by questions originating from the study of a class of shallow
student-teacher neural networks, methods are developed for the analysis of
spurious minima in classes of gradient equivariant dynamics related to neural
nets. In the symmetric case, methods depend on the generic equivariant
bifurcation theory of irreducible representations of the symmetric group on $n$
symbols, $S_n$; in particular, the standard representation of $S_n$. It is
shown that spurious minima do not arise from spontaneous symmetry breaking but
rather through a complex deformation of the landscape geometry that can be
encoded by a generic $S_n$-equivariant bifurcation. We describe minimal models
for forced symmetry breaking that give a lower bound on the dynamic complexity
involved in the creation of spurious minima when there is no symmetry. Results
on generic bifurcation when there are quadratic equivariants are also proved;
this work extends and clarifies results of Ihrig &amp; Golubitsky and Chossat,
Lauterback &amp; Melbourne on the instability of solutions when there are quadratic
equivariants.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating subgroup disparity using epistemic uncertainty in mammography. (arXiv:2107.02716v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Charles Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemay_A/0/1/0/all/0/1">Andreanne Lemay</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoebel_K/0/1/0/all/0/1">Katharina Hoebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1">Jayashree Kalpathy-Cramer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02716">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning (ML) continue to be integrated into healthcare systems
that affect clinical decision making, new strategies will need to be
incorporated in order to effectively detect and evaluate subgroup disparities
to ensure accountability and generalizability in clinical workflows. In this
paper, we explore how epistemic uncertainty can be used to evaluate disparity
in patient demographics (race) and data acquisition (scanner) subgroups for
breast density assessment on a dataset of 108,190 mammograms collected from 33
clinical sites. Our results show that even if aggregate performance is
comparable, the choice of uncertainty quantification metric can significantly
the subgroup level. We hope this analysis can promote further work on how
uncertainty can be leveraged to increase transparency of machine learning
applications for clinical deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weighted Gaussian Process Bandits for Non-stationary Environments. (arXiv:2107.02371v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuntian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xingyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Baekjin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1">Ness Shroff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02371">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we consider the Gaussian process (GP) bandit optimization
problem in a non-stationary environment. To capture external changes, the
black-box function is allowed to be time-varying within a reproducing kernel
Hilbert space (RKHS). To this end, we develop WGP-UCB, a novel UCB-type
algorithm based on weighted Gaussian process regression. A key challenge is how
to cope with infinite-dimensional feature maps. To that end, we leverage kernel
approximation techniques to prove a sublinear regret bound, which is the first
(frequentist) sublinear regret guarantee on weighted time-varying bandits with
general nonlinear rewards. This result generalizes both non-stationary linear
bandits and standard GP-UCB algorithms. Further, a novel concentration
inequality is achieved for weighted Gaussian process regression with general
weights. We also provide universal upper bounds and weight-dependent upper
bounds for weighted maximum information gains. These results are potentially of
independent interest for applications such as news ranking and adaptive
pricing, where weights can be adopted to capture the importance or quality of
data. Finally, we conduct experiments to highlight the favorable gains of the
proposed algorithm in many cases when compared to existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially private federated deep learning for multi-site medical image segmentation. (arXiv:2107.02586v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/eess/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/eess/1/au:+Remerscheid_N/0/1/0/all/0/1">Nicolas Remerscheid</a>, <a href="http://arxiv.org/find/eess/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/eess/1/au:+Makowski_M/0/1/0/all/0/1">Marcus Makowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02586">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative machine learning techniques such as federated learning (FL)
enable the training of models on effectively larger datasets without data
transfer. Recent initiatives have demonstrated that segmentation models trained
with FL can achieve performance similar to locally trained models. However, FL
is not a fully privacy-preserving technique and privacy-centred attacks can
disclose confidential patient data. Thus, supplementing FL with
privacy-enhancing technologies (PTs) such as differential privacy (DP) is a
requirement for clinical applications in a multi-institutional setting. The
application of PTs to FL in medical imaging and the trade-offs between privacy
guarantees and model utility, the ramifications on training performance and the
susceptibility of the final models to attacks have not yet been conclusively
investigated. Here we demonstrate the first application of differentially
private gradient descent-based FL on the task of semantic segmentation in
computed tomography. We find that high segmentation performance is possible
under strong privacy guarantees with an acceptable training time penalty. We
furthermore demonstrate the first successful gradient-based model inversion
attack on a semantic segmentation model and show that the application of DP
prevents it from divulging sensitive image features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Text-to-Image Synthesis Using Contrastive Learning. (arXiv:2107.02423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiulong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1">Martin Takac</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunderraman_R/0/1/0/all/0/1">Rajshekhar Sunderraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02423">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of text-to-image synthesis is to generate a visually realistic image
that matches a given text description. In practice, the captions annotated by
humans for the same image have large variance in terms of contents and the
choice of words. The linguistic discrepancy between the captions of the
identical image leads to the synthetic images deviating from the ground truth.
To address this issue, we propose a contrastive learning approach to improve
the quality and enhance the semantic consistency of synthetic images. In the
pre-training stage, we utilize the contrastive learning approach to learn the
consistent textual representations for the captions corresponding to the same
image. Furthermore, in the following stage of GAN training, we employ the
contrastive learning method to enhance the consistency between the generated
images from the captions related to the same image. We evaluate our approach
over two popular text-to-image synthesis models, AttnGAN and DM-GAN, on
datasets CUB and COCO, respectively. Experimental results have shown that our
approach can effectively improve the quality of synthetic images in terms of
three metrics: IS, FID and R-precision. Especially, on the challenging COCO
dataset, our approach boosts the FID significantly by 29.60% over AttnGAn and
by 21.96% over DM-GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Level Graph Contrastive Learning. (arXiv:2107.02639v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_P/0/1/0/all/0/1">Pengpeng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1">Jianhua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_F/0/1/0/all/0/1">Feihu Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guohua Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02639">
                                    <div class="article-summary-box-inner">
                                        <span>Graph representation learning has attracted a surge of interest recently,
whose target at learning discriminant embedding for each node in the graph.
Most of these representation methods focus on supervised learning and heavily
depend on label information. However, annotating graphs are expensive to obtain
in the real world, especially in specialized domains (i.e. biology), as it
needs the annotator to have the domain knowledge to label the graph. To
approach this problem, self-supervised learning provides a feasible solution
for graph representation learning. In this paper, we propose a Multi-Level
Graph Contrastive Learning (MLGCL) framework for learning robust representation
of graph data by contrasting space views of graphs. Specifically, we introduce
a novel contrastive view - topological and feature space views. The original
graph is first-order approximation structure and contains uncertainty or error,
while the $k$NN graph generated by encoding features preserves high-order
proximity. Thus $k$NN graph generated by encoding features not only provide a
complementary view, but is more suitable to GNN encoder to extract discriminant
representation. Furthermore, we develop a multi-level contrastive mode to
preserve the local similarity and semantic similarity of graph-structured data
simultaneously. Extensive experiments indicate MLGCL achieves promising results
compared with the existing state-of-the-art graph representation learning
methods on seven datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Reinforcement Learning for Heuristic Planning. (arXiv:2107.02603v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1">Ricardo Luna Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonetti_M/0/1/0/all/0/1">Matteo Leonetti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02603">
                                    <div class="article-summary-box-inner">
                                        <span>In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of
tasks to prepare for and learn faster in new, unseen, but related tasks. The
training tasks are usually hand-crafted to be representative of the expected
distribution of test tasks and hence all used in training. We show that given a
set of training tasks, learning can be both faster and more effective (leading
to better performance in the test tasks), if the training tasks are
appropriately selected. We propose a task selection algorithm,
Information-Theoretic Task Selection (ITTS), based on information theory, which
optimizes the set of tasks used for training in meta-RL, irrespectively of how
they are generated. The algorithm establishes which training tasks are both
sufficiently relevant for the test tasks, and different enough from one
another. We reproduce different meta-RL experiments from the literature and
show that ITTS improves the final performance in all of them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Histogram of Cell Types: Deep Learning for Automated Bone Marrow Cytology. (arXiv:2107.02293v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tayebi_R/0/1/0/all/0/1">Rohollah Moosavi Tayebi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mu_Y/0/1/0/all/0/1">Youqing Mu</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehkharghanian_T/0/1/0/all/0/1">Taher Dehkharghanian</a>, <a href="http://arxiv.org/find/eess/1/au:+Ross_C/0/1/0/all/0/1">Catherine Ross</a>, <a href="http://arxiv.org/find/eess/1/au:+Sur_M/0/1/0/all/0/1">Monalisa Sur</a>, <a href="http://arxiv.org/find/eess/1/au:+Foley_R/0/1/0/all/0/1">Ronan Foley</a>, <a href="http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1">Hamid R. Tizhoosh</a>, <a href="http://arxiv.org/find/eess/1/au:+Campbell_C/0/1/0/all/0/1">Clinton JV Campbell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02293">
                                    <div class="article-summary-box-inner">
                                        <span>Bone marrow cytology is required to make a hematological diagnosis,
influencing critical clinical decision points in hematology. However, bone
marrow cytology is tedious, limited to experienced reference centers and
associated with high inter-observer variability. This may lead to a delayed or
incorrect diagnosis, leaving an unmet need for innovative supporting
technologies. We have developed the first ever end-to-end deep learning-based
technology for automated bone marrow cytology. Starting with a bone marrow
aspirate digital whole slide image, our technology rapidly and automatically
detects suitable regions for cytology, and subsequently identifies and
classifies all bone marrow cells in each region. This collective
cytomorphological information is captured in a novel representation called
Histogram of Cell Types (HCT) quantifying bone marrow cell class probability
distribution and acting as a cytological &quot;patient fingerprint&quot;. The approach
achieves high accuracy in region detection (0.97 accuracy and 0.99 ROC AUC),
and cell detection and cell classification (0.75 mAP, 0.78 F1-score,
Log-average miss rate of 0.31). HCT has potential to revolutionize
hematopathology diagnostic workflows, leading to more cost-effective, accurate
diagnosis and opening the door to precision medicine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Remote sensing, AI and innovative prediction methods for adapting cities to the impacts of the climate change. (arXiv:2107.02693v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sirmacek_B/0/1/0/all/0/1">Beril Sirmacek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02693">
                                    <div class="article-summary-box-inner">
                                        <span>Urban areas are not only one of the biggest contributors to climate change,
but also they are one of the most vulnerable areas with high populations who
would together experience the negative impacts. In this paper, I address some
of the opportunities brought by satellite remote sensing imaging and artificial
intelligence (AI) in order to measure climate adaptation of cities
automatically. I propose an AI-based framework which might be useful for
extracting indicators from remote sensing images and might help with predictive
estimation of future states of these climate adaptation related indicators.
When such models become more robust and used in real-life applications, they
might help decision makers and early responders to choose the best actions to
sustain the wellbeing of society, natural resources and biodiversity. I
underline that this is an open field and an ongoing research for many
scientists, therefore I offer an in depth discussion on the challenges and
limitations of AI-based methods and the predictive estimation models in
general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label noise in segmentation networks : mitigation must deal with bias. (arXiv:2107.02189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadoury_S/0/1/0/all/0/1">Samuel Kadoury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02189">
                                    <div class="article-summary-box-inner">
                                        <span>Imperfect labels limit the quality of predictions learned by deep neural
networks. This is particularly relevant in medical image segmentation, where
reference annotations are difficult to collect and vary significantly even
across expert annotators. Prior work on mitigating label noise focused on
simple models of mostly uniform noise. In this work, we explore biased and
unbiased errors artificially introduced to brain tumour annotations on MRI
data. We found that supervised and semi-supervised segmentation methods are
robust or fairly robust to unbiased errors but sensitive to biased errors. It
is therefore important to identify the sorts of errors expected in medical
image labels and especially mitigate the biased errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometric convergence of elliptical slice sampling. (arXiv:2105.03308v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Natarovskii_V/0/1/0/all/0/1">Viacheslav Natarovskii</a>, <a href="http://arxiv.org/find/stat/1/au:+Rudolf_D/0/1/0/all/0/1">Daniel Rudolf</a>, <a href="http://arxiv.org/find/stat/1/au:+Sprungk_B/0/1/0/all/0/1">Bj&#xf6;rn Sprungk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03308">
                                    <div class="article-summary-box-inner">
                                        <span>For Bayesian learning, given likelihood function and Gaussian prior, the
elliptical slice sampler, introduced by Murray, Adams and MacKay 2010, provides
a tool for the construction of a Markov chain for approximate sampling of the
underlying posterior distribution. Besides of its wide applicability and
simplicity its main feature is that no tuning is necessary. Under weak
regularity assumptions on the posterior density we show that the corresponding
Markov chain is geometrically ergodic and therefore yield qualitative
convergence guarantees. We illustrate our result for Gaussian posteriors as
they appear in Gaussian process regression, as well as in a setting of a
multi-modal distribution. Remarkably, our numerical experiments indicate a
dimension-independent performance of elliptical slice sampling even in
situations where our ergodicity result does not apply.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Hypo-plastic Left Heart Syndrome in Fetal Ultrasound via Disease-specific Atlas Maps. (arXiv:2107.02643v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Budd_S/0/1/0/all/0/1">Samuel Budd</a>, <a href="http://arxiv.org/find/eess/1/au:+Sinclair_M/0/1/0/all/0/1">Matthew Sinclair</a>, <a href="http://arxiv.org/find/eess/1/au:+Day_T/0/1/0/all/0/1">Thomas Day</a>, <a href="http://arxiv.org/find/eess/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/eess/1/au:+Tan_J/0/1/0/all/0/1">Jeremy Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tianrui Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Matthew_J/0/1/0/all/0/1">Jaqueline Matthew</a>, <a href="http://arxiv.org/find/eess/1/au:+Skelton_E/0/1/0/all/0/1">Emily Skelton</a>, <a href="http://arxiv.org/find/eess/1/au:+Simpson_J/0/1/0/all/0/1">John Simpson</a>, <a href="http://arxiv.org/find/eess/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a>, <a href="http://arxiv.org/find/eess/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Robinson_E/0/1/0/all/0/1">Emma C. Robinson</a>, <a href="http://arxiv.org/find/eess/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02643">
                                    <div class="article-summary-box-inner">
                                        <span>Fetal ultrasound screening during pregnancy plays a vital role in the early
detection of fetal malformations which have potential long-term health impacts.
The level of skill required to diagnose such malformations from live ultrasound
during examination is high and resources for screening are often limited. We
present an interpretable, atlas-learning segmentation method for automatic
diagnosis of Hypo-plastic Left Heart Syndrome (HLHS) from a single &#x60;4 Chamber
Heart&#x27; view image. We propose to extend the recently introduced
Image-and-Spatial Transformer Networks (Atlas-ISTN) into a framework that
enables sensitising atlas generation to disease. In this framework we can
jointly learn image segmentation, registration, atlas construction and disease
prediction while providing a maximum level of clinical interpretability
compared to direct image classification methods. As a result our segmentation
allows diagnoses competitive with expert-derived manual diagnosis and yields an
AUC-ROC of 0.978 (1043 cases for training, 260 for validation and 325 for
testing).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A new smart-cropping pipeline for prostate segmentation using deep learning networks. (arXiv:2107.02476v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaridis_D/0/1/0/all/0/1">Dimitrios G. Zaridis</a>, <a href="http://arxiv.org/find/eess/1/au:+Mylona_E/0/1/0/all/0/1">Eugenia Mylona</a>, <a href="http://arxiv.org/find/eess/1/au:+Marias_K/0/1/0/all/0/1">Kostas Marias</a>, <a href="http://arxiv.org/find/eess/1/au:+Papanikolaou_N/0/1/0/all/0/1">Nikolaos Papanikolaou</a>, <a href="http://arxiv.org/find/eess/1/au:+Tachos_N/0/1/0/all/0/1">Nikolaos S. Tachos</a>, <a href="http://arxiv.org/find/eess/1/au:+Fotiadis_D/0/1/0/all/0/1">Dimitrios I. Fotiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02476">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate segmentation from magnetic resonance imaging (MRI) is a challenging
task. In recent years, several network architectures have been proposed to
automate this process and alleviate the burden of manual annotation. Although
the performance of these models has achieved promising results, there is still
room for improvement before these models can be used safely and effectively in
clinical practice. One of the major challenges in prostate MR image
segmentation is the presence of class imbalance in the image labels where the
background pixels dominate over the prostate. In the present work we propose a
DL-based pipeline for cropping the region around the prostate from MRI images
to produce a more balanced distribution of the foreground pixels (prostate) and
the background pixels and improve segmentation accuracy. The effect of
DL-cropping for improving the segmentation performance compared to standard
center-cropping is assessed using five popular DL networks for prostate
segmentation, namely U-net, U-net+, Res Unet++, Bridge U-net and Dense U-net.
The proposed smart-cropping outperformed the standard center cropping in terms
of segmentation accuracy for all the evaluated prostate segmentation networks.
In terms of Dice score, the highest improvement was achieved for the U-net+ and
ResU-net++ architectures corresponding to 8.9% and 8%, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Critical Nodes in Temporal Networks by Dynamic Graph Convolutional Networks. (arXiv:2106.10419v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_E/0/1/0/all/0/1">En-Yu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun-Lin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hong-Liang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Duan-Bing Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10419">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world systems can be expressed in temporal networks with nodes
playing far different roles in structure and function and edges representing
the relationships between nodes. Identifying critical nodes can help us control
the spread of public opinions or epidemics, predict leading figures in
academia, conduct advertisements for various commodities, and so on. However,
it is rather difficult to identify critical nodes because the network structure
changes over time in temporal networks. In this paper, considering the sequence
topological information of temporal networks, a novel and effective learning
framework based on the combination of special GCNs and RNNs is proposed to
identify nodes with the best spreading ability. The effectiveness of the
approach is evaluated by weighted Susceptible-Infected-Recovered model.
Experimental results on four real-world temporal networks demonstrate that the
proposed method outperforms both traditional and deep learning benchmark
methods in terms of the Kendall $\tau$ coefficient and top $k$ hit rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parametric Complexity Bounds for Approximating PDEs with Neural Networks. (arXiv:2103.02138v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marwah_T/0/1/0/all/0/1">Tanya Marwah</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02138">
                                    <div class="article-summary-box-inner">
                                        <span>Recent experiments have shown that deep networks can approximate solutions to
high-dimensional PDEs, seemingly escaping the curse of dimensionality. However,
questions regarding the theoretical basis for such approximations, including
the required network size, remain open. In this paper, we investigate the
representational power of neural networks for approximating solutions to linear
elliptic PDEs with Dirichlet boundary conditions. We prove that when a PDE&#x27;s
coefficients are representable by small neural networks, the parameters
required to approximate its solution scale polynomially with the input
dimension $d$ and proportionally to the parameter counts of the coefficient
networks. To this we end, we develop a proof technique that simulates gradient
descent (in an appropriate Hilbert space) by growing a neural network
architecture whose iterates each participate as sub-networks in their (slightly
larger) successors, and converge to the solution of the PDE. We bound the size
of the solution, showing a polynomial dependence on $d$ and no dependence on
the volume of the domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning an Explicit Hyperparameter Prediction Policy Conditioned on Tasks. (arXiv:2107.02378v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1">Jun Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zongben Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02378">
                                    <div class="article-summary-box-inner">
                                        <span>Meta learning has attracted much attention recently in machine learning
community. Contrary to conventional machine learning aiming to learn inherent
prediction rules to predict labels for new query data, meta learning aims to
learn the learning methodology for machine learning from observed tasks, so as
to generalize to new query tasks by leveraging the meta-learned learning
methodology. In this study, we interpret such learning methodology as learning
an explicit hyperparameter prediction policy shared by all training tasks.
Specifically, this policy is represented as a parameterized function called
meta-learner, mapping from a training/test task to its suitable hyperparameter
setting, extracted from a pre-specified function set called meta learning
machine. Such setting guarantees that the meta-learned learning methodology is
able to flexibly fit diverse query tasks, instead of only obtaining fixed
hyperparameters by many current meta learning methods, with less adaptability
to query task&#x27;s variations. Such understanding of meta learning also makes it
easily succeed from traditional learning theory for analyzing its
generalization bounds with general losses/tasks/models. The theory naturally
leads to some feasible controlling strategies for ameliorating the quality of
the extracted meta-learner, verified to be able to finely ameliorate its
generalization capability in some typical meta learning applications, including
few-shot regression, few-shot classification and domain generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network. (arXiv:2107.02757v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhibin Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaojie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenchao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02757">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical topic models such as the gamma belief network (GBN) have
delivered promising results in mining multi-layer document representations and
discovering interpretable topic taxonomies. However, they often assume in the
prior that the topics at each layer are independently drawn from the Dirichlet
distribution, ignoring the dependencies between the topics both at the same
layer and across different layers. To relax this assumption, we propose
sawtooth factorial topic embedding guided GBN, a deep generative model of
documents that captures the dependencies and semantic similarities between the
topics in the embedding space. Specifically, both the words and topics are
represented as embedding vectors of the same dimension. The topic matrix at a
layer is factorized into the product of a factor loading matrix and a topic
embedding matrix, the transpose of which is set as the factor loading matrix of
the layer above. Repeating this particular type of factorization, which shares
components between adjacent layers, leads to a structure referred to as
sawtooth factorization. An auto-encoding variational inference network is
constructed to optimize the model parameter via stochastic gradient descent.
Experiments on big corpora show that our models outperform other neural topic
models on extracting deeper interpretable topics and deriving better document
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-Objective Approach for Sustainable Generative Audio Models. (arXiv:2107.02621v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Douwes_C/0/1/0/all/0/1">Constance Douwes</a>, <a href="http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1">Philippe Esling</a>, <a href="http://arxiv.org/find/cs/1/au:+Briot_J/0/1/0/all/0/1">Jean-Pierre Briot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02621">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the deep learning community has largely focused on the
accuracy of deep generative models, resulting in impressive improvements in
several research fields. However, this scientific race for quality comes at a
tremendous computational cost, which incurs vast energy consumption and
greenhouse gas emissions. If the current exponential growth of computational
consumption persists, Artificial Intelligence (AI) will sadly become a
considerable contributor to global warming.

At the heart of this problem are the measures that we use as a scientific
community to evaluate our work. Currently, researchers in the field of AI judge
scientific works mostly based on the improvement in accuracy, log-likelihood,
reconstruction or opinion scores, all of which entirely obliterates the actual
computational cost of generative models.

In this paper, we introduce the idea of relying on a multi-objective measure
based on Pareto optimality, which simultaneously integrates the models
accuracy, as well as the environmental impact of their training. By applying
this measure on the current state-of-the-art in generative audio models, we
show that this measure drastically changes the perceived significance of the
results in the field, encouraging optimal training techniques and resource
allocation. We hope that this type of measure will be widely adopted, in order
to help the community to better evaluate the significance of their work, while
bringing computational cost -- and in fine carbon emissions -- in the spotlight
of AI research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effectiveness of MPC-friendly Softmax Replacement. (arXiv:2011.11202v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_M/0/1/0/all/0/1">Marcel Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1">Ke Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11202">
                                    <div class="article-summary-box-inner">
                                        <span>Softmax is widely used in deep learning to map some representation to a
probability distribution. As it is based on exp/log functions that are
relatively expensive in multi-party computation, Mohassel and Zhang (2017)
proposed a simpler replacement based on ReLU to be used in secure computation.
However, we could not reproduce the accuracy they reported for training on
MNIST with three fully connected layers. Later works (e.g., Wagh et al., 2019
and 2021) used the softmax replacement not for computing the output probability
distribution but for approximating the gradient in back-propagation. In this
work, we analyze the two uses of the replacement and compare them to softmax,
both in terms of accuracy and cost in multi-party computation. We found that
the replacement only provides a significant speed-up for a one-layer network
while it always reduces accuracy, sometimes significantly. Thus we conclude
that its usefulness is limited and one should use the original softmax function
instead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of On-Chip Interconnect on In-Memory Acceleration of Deep Neural Networks. (arXiv:2107.02358v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishnan_G/0/1/0/all/0/1">Gokul Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_S/0/1/0/all/0/1">Sumit K. Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_C/0/1/0/all/0/1">Chaitali Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1">Jae-sun Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogras_U/0/1/0/all/0/1">Umit Y. Ogras</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yu Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02358">
                                    <div class="article-summary-box-inner">
                                        <span>With the widespread use of Deep Neural Networks (DNNs), machine learning
algorithms have evolved in two diverse directions -- one with ever-increasing
connection density for better accuracy and the other with more compact sizing
for energy efficiency. The increase in connection density increases on-chip
data movement, which makes efficient on-chip communication a critical function
of the DNN accelerator. The contribution of this work is threefold. First, we
illustrate that the point-to-point (P2P)-based interconnect is incapable of
handling a high volume of on-chip data movement for DNNs. Second, we evaluate
P2P and network-on-chip (NoC) interconnect (with a regular topology such as a
mesh) for SRAM- and ReRAM-based in-memory computing (IMC) architectures for a
range of DNNs. This analysis shows the necessity for the optimal interconnect
choice for an IMC DNN accelerator. Finally, we perform an experimental
evaluation for different DNNs to empirically obtain the performance of the IMC
architecture with both NoC-tree and NoC-mesh. We conclude that, at the tile
level, NoC-tree is appropriate for compact DNNs employed at the edge, and
NoC-mesh is necessary to accelerate DNNs with high connection density.
Furthermore, we propose a technique to determine the optimal choice of
interconnect for any given DNN. In this technique, we use analytical models of
NoC to evaluate end-to-end communication latency of any given DNN. We
demonstrate that the interconnect optimization in the IMC architecture results
in up to 6$\times$ improvement in energy-delay-area product for VGG-19
inference compared to the state-of-the-art ReRAM-based IMC architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Midwifery Learning and Forecasting: Predicting Content Demand with User-Generated Logs. (arXiv:2107.02480v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guitart_A/0/1/0/all/0/1">Anna Guitart</a>, <a href="http://arxiv.org/find/stat/1/au:+Rio_A/0/1/0/all/0/1">Ana Fern&#xe1;ndez del R&#xed;o</a>, <a href="http://arxiv.org/find/stat/1/au:+Perianez_A/0/1/0/all/0/1">&#xc1;frica Peri&#xe1;&#xf1;ez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02480">
                                    <div class="article-summary-box-inner">
                                        <span>Every day, 800 women and 6,700 newborns die from complications related to
pregnancy or childbirth. A well-trained midwife can prevent most of these
maternal and newborn deaths. Data science models together with logs generated
by users of online learning applications for midwives can help to improve their
learning competencies. The goal is to use these rich behavioral data to push
digital learning towards personalized content and to provide an adaptive
learning journey. In this work, we evaluate various forecasting methods to
determine the interest of future users on the different kind of contents
available in the app, broken down by profession and region.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study of COVID-19 Infodemic. (arXiv:2106.11702v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Ye Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyi Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1">Carolina Scarton</a>, <a href="http://arxiv.org/find/cs/1/au:+Aker_A/0/1/0/all/0/1">Ahmet Aker</a>, <a href="http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1">Kalina Bontcheva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11702">
                                    <div class="article-summary-box-inner">
                                        <span>The spreading COVID-19 misinformation over social media already draws the
attention of many researchers. According to Google Scholar, about 26000
COVID-19 related misinformation studies have been published to date. Most of
these studies focusing on 1) detect and/or 2) analysing the characteristics of
COVID-19 related misinformation. However, the study of the social behaviours
related to misinformation is often neglected. In this paper, we introduce a
fine-grained annotated misinformation tweets dataset including social
behaviours annotation (e.g. comment or question to the misinformation). The
dataset not only allows social behaviours analysis but also suitable for both
evidence-based or non-evidence-based misinformation classification task. In
addition, we introduce leave claim out validation in our experiments and
demonstrate the misinformation classification performance could be
significantly different when applying to real-world unseen misinformation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAP-RAM: A Charge-Domain In-Memory Computing 6T-SRAM for Accurate and Precision-Programmable CNN Inference. (arXiv:2107.02388v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhanghao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Sheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaiyuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02388">
                                    <div class="article-summary-box-inner">
                                        <span>A compact, accurate, and bitwidth-programmable in-memory computing (IMC)
static random-access memory (SRAM) macro, named CAP-RAM, is presented for
energy-efficient convolutional neural network (CNN) inference. It leverages a
novel charge-domain multiply-and-accumulate (MAC) mechanism and circuitry to
achieve superior linearity under process variations compared to conventional
IMC designs. The adopted semi-parallel architecture efficiently stores filters
from multiple CNN layers by sharing eight standard 6T SRAM cells with one
charge-domain MAC circuit. Moreover, up to six levels of bit-width of weights
with two encoding schemes and eight levels of input activations are supported.
A 7-bit charge-injection SAR (ciSAR) analog-to-digital converter (ADC) getting
rid of sample and hold (S&amp;H) and input/reference buffers further improves the
overall energy efficiency and throughput. A 65-nm prototype validates the
excellent linearity and computing accuracy of CAP-RAM. A single 512x128 macro
stores a complete pruned and quantized CNN model to achieve 98.8% inference
accuracy on the MNIST data set and 89.0% on the CIFAR-10 data set, with a
573.4-giga operations per second (GOPS) peak throughput and a 49.4-tera
operations per second (TOPS)/W energy efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Talk to Action with Accountability: Monitoring the Public Discussion of Policy Makers with Deep Neural Networks and Topic Modelling. (arXiv:2010.08346v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hatonen_V/0/1/0/all/0/1">Vili H&#xe4;t&#xf6;nen</a>, <a href="http://arxiv.org/find/cs/1/au:+Melzer_F/0/1/0/all/0/1">Fiona Melzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08346">
                                    <div class="article-summary-box-inner">
                                        <span>Decades of research on climate have provided a consensus that human activity
has changed the climate and we are currently heading into a climate crisis.
While public discussion and research efforts on climate change mitigation have
increased, potential solutions need to not only be discussed but also
effectively deployed. For preventing mismanagement and holding policy makers
accountable, transparency and degree of information about government processes
have been shown to be crucial. However, currently the quantity of information
about climate change discussions and the range of sources make it increasingly
difficult for the public and civil society to maintain an overview to hold
politicians accountable.

In response, we propose a multi-source topic aggregation system (MuSTAS)
which processes policy makers speech and rhetoric from several publicly
available sources into an easily digestible topic summary. MuSTAS uses novel
multi-source hybrid latent Dirichlet allocation to model topics from a variety
of documents. This topic digest will serve the general public and civil society
in assessing where, how, and when politicians talk about climate and climate
policies, enabling them to hold politicians accountable for their actions to
mitigate climate change and lack thereof.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiating through the Fr\&#x27;echet Mean. (arXiv:2003.00335v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lou_A/0/1/0/all/0/1">Aaron Lou</a>, <a href="http://arxiv.org/find/stat/1/au:+Katsman_I/0/1/0/all/0/1">Isay Katsman</a>, <a href="http://arxiv.org/find/stat/1/au:+Jiang_Q/0/1/0/all/0/1">Qingxuan Jiang</a>, <a href="http://arxiv.org/find/stat/1/au:+Belongie_S/0/1/0/all/0/1">Serge Belongie</a>, <a href="http://arxiv.org/find/stat/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>, <a href="http://arxiv.org/find/stat/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00335">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep representation learning on Riemannian manifolds
extend classical deep learning operations to better capture the geometry of the
manifold. One possible extension is the Fr\&#x27;echet mean, the generalization of
the Euclidean mean; however, it has been difficult to apply because it lacks a
closed form with an easily computable derivative. In this paper, we show how to
differentiate through the Fr\&#x27;echet mean for arbitrary Riemannian manifolds.
Then, focusing on hyperbolic space, we derive explicit gradient expressions and
a fast, accurate, and hyperparameter-free Fr\&#x27;echet mean solver. This fully
integrates the Fr\&#x27;echet mean into the hyperbolic neural network pipeline. To
demonstrate this integration, we present two case studies. First, we apply our
Fr\&#x27;echet mean to the existing Hyperbolic Graph Convolutional Network,
replacing its projected aggregation to obtain state-of-the-art results on
datasets with high hyperbolicity. Second, to demonstrate the Fr\&#x27;echet mean&#x27;s
capacity to generalize Euclidean neural network operations, we develop a
hyperbolic batch normalization method that gives an improvement parallel to the
one observed in the Euclidean setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Scale Model Predictive Control with Neural Networks and Primal Active Sets. (arXiv:1910.10835v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Steven W. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Atanasov_N/0/1/0/all/0/1">Nikolay Atanasov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vijay Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Morari_M/0/1/0/all/0/1">Manfred Morari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10835">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents an explicit-implicit procedure to compute a model
predictive control (MPC) law with guarantees on recursive feasibility and
asymptotic stability. The approach combines an offline-trained fully-connected
neural network with an online primal active set solver. The neural network
provides a control input initialization while the primal active set method
ensures recursive feasibility and asymptotic stability. The neural network is
trained with a primal-dual loss function, aiming to generate control sequences
that are primal feasible and meet a desired level of suboptimality. Since the
neural network alone does not guarantee constraint satisfaction, its output is
used to warm start the primal active set method online. We demonstrate that
this approach scales to large problems with thousands of optimization
variables, which are challenging for current approaches. Our method achieves a
2x reduction in online inference time compared to the best method in a
benchmark suite of different solver and initialization strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Lipschitz Certification for Generative Models. (arXiv:2107.02732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Matt Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02732">
                                    <div class="article-summary-box-inner">
                                        <span>We present a scalable technique for upper bounding the Lipschitz constant of
generative models. We relate this quantity to the maximal norm over the set of
attainable vector-Jacobian products of a given generative model. We approximate
this set by layerwise convex approximations using zonotopes. Our approach
generalizes and improves upon prior work using zonotope transformers and we
extend to Lipschitz estimation of neural networks with large output dimension.
This provides efficient and tight bounds on small networks and can scale to
generative models on VAE and DCGAN architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Inverse QSAR Method Based on Linear Regression and Integer Programming. (arXiv:2107.02381v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jianshen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Azam_N/0/1/0/all/0/1">Naveed Ahmed Azam</a>, <a href="http://arxiv.org/find/cs/1/au:+Haraguchi_K/0/1/0/all/0/1">Kazuya Haraguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagamochi_H/0/1/0/all/0/1">Hiroshi Nagamochi</a>, <a href="http://arxiv.org/find/cs/1/au:+Akutsu_T/0/1/0/all/0/1">Tatsuya Akutsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02381">
                                    <div class="article-summary-box-inner">
                                        <span>Recently a novel framework has been proposed for designing the molecular
structure of chemical compounds using both artificial neural networks (ANNs)
and mixed integer linear programming (MILP). In the framework, we first define
a feature vector $f(C)$ of a chemical graph $C$ and construct an ANN that maps
$x&#x3D;f(C)$ to a predicted value $\eta(x)$ of a chemical property $\pi$ to $C$.
After this, we formulate an MILP that simulates the computation process of
$f(C)$ from $C$ and that of $\eta(x)$ from $x$. Given a target value $y^*$ of
the chemical property $\pi$, we infer a chemical graph $C^\dagger$ such that
$\eta(f(C^\dagger))&#x3D;y^*$ by solving the MILP. In this paper, we use linear
regression to construct a prediction function $\eta$ instead of ANNs. For this,
we derive an MILP formulation that simulates the computation process of a
prediction function by linear regression. The results of computational
experiments suggest our method can infer chemical graphs with around up to 50
non-hydrogen atoms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A visual introduction to Gaussian Belief Propagation. (arXiv:2107.02308v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ortiz_J/0/1/0/all/0/1">Joseph Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_T/0/1/0/all/0/1">Talfan Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1">Andrew J. Davison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02308">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we present a visual introduction to Gaussian Belief
Propagation (GBP), an approximate probabilistic inference algorithm that
operates by passing messages between the nodes of arbitrarily structured factor
graphs. A special case of loopy belief propagation, GBP updates rely only on
local information and will converge independently of the message schedule. Our
key argument is that, given recent trends in computing hardware, GBP has the
right computational properties to act as a scalable distributed probabilistic
inference framework for future machine learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic uncertainties and where to find them. (arXiv:2107.02526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farina_F/0/1/0/all/0/1">Francesco Farina</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1">Lawrence Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+Richmond_N/0/1/0/all/0/1">Nicola J Richmond</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02526">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a framework for uncertainty estimation that both describes and
extends many existing methods. We consider typical hyperparameters involved in
classical training as random variables and marginalise them out to capture
various sources of uncertainty in the parameter space. We investigate which
forms and combinations of marginalisation are most useful from a practical
point of view on standard benchmarking data sets. Moreover, we discuss how some
marginalisations may produce reliable estimates of uncertainty without the need
for extensive hyperparameter tuning and/or large-scale ensembling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Positional Encoding. (arXiv:2107.02561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jianqiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1">Sameera Ramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1">Simon Lucey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02561">
                                    <div class="article-summary-box-inner">
                                        <span>It is well noted that coordinate based MLPs benefit greatly -- in terms of
preserving high-frequency information -- through the encoding of coordinate
positions as an array of Fourier features. Hitherto, the rationale for the
effectiveness of these positional encodings has been solely studied through a
Fourier lens. In this paper, we strive to broaden this understanding by showing
that alternative non-Fourier embedding functions can indeed be used for
positional encoding. Moreover, we show that their performance is entirely
determined by a trade-off between the stable rank of the embedded matrix and
the distance preservation between embedded coordinates. We further establish
that the now ubiquitous Fourier feature mapping of position is a special case
that fulfills these conditions. Consequently, we present a more general theory
to analyze positional encoding in terms of shifted basis functions. To this
end, we develop the necessary theoretical formulae and empirically verify that
our theoretical claims hold in practice. Codes available at
https://github.com/osiriszjq/Rethinking-positional-encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Structure of Microstructure Measures. (arXiv:2107.02283v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Zhu_L/0/1/0/all/0/1">Liao Zhu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Sun_N/0/1/0/all/0/1">Ningning Sun</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wells_M/0/1/0/all/0/1">Martin T. Wells</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02283">
                                    <div class="article-summary-box-inner">
                                        <span>This paper builds the clustering model of measures of market microstructure
features which are popular in predicting the stock returns. In a 10-second time
frequency, we study the clustering structure of different measures to find out
the best ones for predicting. In this way, we can predict more accurately with
a limited number of predictors, which removes the noise and makes the model
more interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shell Language Processing: Unix command parsing for Machine Learning. (arXiv:2107.02438v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trizna_D/0/1/0/all/0/1">Dmitrijs Trizna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02438">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we present a Shell Language Preprocessing (SLP) library,
which implements tokenization and encoding directed on the parsing of Unix and
Linux shell commands. We describe the rationale behind the need for a new
approach with specific examples when conventional Natural Language Processing
(NLP) pipelines fail. Furthermore, we evaluate our methodology on a security
classification task against widely accepted information and communications
technology (ICT) tokenization techniques and achieve significant improvement of
an F1-score from 0.392 to 0.874.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Garbage In, Garbage Out&quot; Revisited: What Do Machine Learning Application Papers Report About Human-Labeled Training Data?. (arXiv:2107.02278v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_R/0/1/0/all/0/1">R. Stuart Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Cope_D/0/1/0/all/0/1">Dominique Cope</a>, <a href="http://arxiv.org/find/cs/1/au:+Ip_J/0/1/0/all/0/1">Jamie Ip</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotosh_M/0/1/0/all/0/1">Marsha Lotosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Aayush Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1">Jenny Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Rebekah Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02278">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised machine learning, in which models are automatically derived from
labeled training data, is only as good as the quality of that data. This study
builds on prior work that investigated to what extent &#x27;best practices&#x27; around
labeling training data were followed in applied ML publications within a single
domain (social media platforms). In this paper, we expand by studying
publications that apply supervised ML in a far broader spectrum of disciplines,
focusing on human-labeled data. We report to what extent a random sample of ML
application papers across disciplines give specific details about whether best
practices were followed, while acknowledging that a greater range of
application fields necessarily produces greater diversity of labeling and
annotation methods. Because much of machine learning research and education
only focuses on what is done once a &quot;ground truth&quot; or &quot;gold standard&quot; of
training data is available, it is especially relevant to discuss issues around
the equally-important aspect of whether such data is reliable in the first
place. This determination becomes increasingly complex when applied to a
variety of specialized fields, as labeling can range from a task requiring
little-to-no background knowledge to one that must be performed by someone with
career expertise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Agents that Listen: High-Throughput Reinforcement Learning with Multiple Sensory Systems. (arXiv:2107.02195v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1">Shashank Hegde</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanervisto_A/0/1/0/all/0/1">Anssi Kanervisto</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrenko_A/0/1/0/all/0/1">Aleksei Petrenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02195">
                                    <div class="article-summary-box-inner">
                                        <span>Humans and other intelligent animals evolved highly sophisticated perception
systems that combine multiple sensory modalities. On the other hand,
state-of-the-art artificial agents rely mostly on visual inputs or structured
low-dimensional observations provided by instrumented environments. Learning to
act based on combined visual and auditory inputs is still a new topic of
research that has not been explored beyond simple scenarios. To facilitate
progress in this area we introduce a new version of VizDoom simulator to create
a highly efficient learning environment that provides raw audio observations.
We study the performance of different model architectures in a series of tasks
that require the agent to recognize sounds and execute instructions given in
natural language. Finally, we train our agent to play the full game of Doom and
find that it can consistently defeat a traditional vision-based adversary. We
are currently in the process of merging the augmented simulator with the main
ViZDoom code repository. Video demonstrations and experiment code can be found
at https://sites.google.com/view/sound-rl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Attention as Intrinsic Regularization for Bimanual Multi-Object Manipulation. (arXiv:2106.05907v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1">Pingcheng Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05907">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of solving complex bimanual robot manipulation tasks
on multiple objects with sparse rewards. Such complex tasks can be decomposed
into sub-tasks that are accomplishable by different robots concurrently or
sequentially for better efficiency. While previous reinforcement learning
approaches primarily focus on modeling the compositionality of sub-tasks, two
fundamental issues are largely ignored particularly when learning cooperative
strategies for two robots: (i) domination, i.e., one robot may try to solve a
task by itself and leaves the other idle; (ii) conflict, i.e., one robot can
easily interrupt another&#x27;s workspace when executing different sub-tasks
simultaneously. To tackle these two issues, we propose a novel technique called
disentangled attention, which provides an intrinsic regularization for two
robots to focus on separate sub-tasks and objects. We evaluate our method on
four bimanual manipulation tasks. Experimental results show that our proposed
intrinsic regularization successfully avoids domination and reduces conflicts
for the policies, which leads to significantly more effective cooperative
strategies than all the baselines. Our project page with videos is at
https://mehooz.github.io/bimanual-attention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Benchmarks for Learning on Non-Homophilous Graphs. (arXiv:2104.01404v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1">Derek Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiuyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_F/0/1/0/all/0/1">Felix Hohne</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01404">
                                    <div class="article-summary-box-inner">
                                        <span>Much data with graph structures satisfy the principle of homophily, meaning
that connected nodes tend to be similar with respect to a specific attribute.
As such, ubiquitous datasets for graph machine learning tasks have generally
been highly homophilous, rewarding methods that leverage homophily as an
inductive bias. Recent work has pointed out this particular focus, as new
non-homophilous datasets have been introduced and graph representation learning
models better suited for low-homophily settings have been developed. However,
these datasets are small and poorly suited to truly testing the effectiveness
of new methods in non-homophilous settings. We present a series of improved
graph datasets with node label relationships that do not satisfy the homophily
principle. Along with this, we introduce a new measure of the presence or
absence of homophily that is better suited than existing measures in different
regimes. We benchmark a range of simple methods and graph neural networks
across our proposed datasets, drawing new insights for further research. Data
and codes can be found at https://github.com/CUAI/Non-Homophily-Benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">InfoNCE is a variational autoencoder. (arXiv:2107.02495v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1">Laurence Aitchison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02495">
                                    <div class="article-summary-box-inner">
                                        <span>We show that a popular self-supervised learning method, InfoNCE, is a special
case of a new family of unsupervised learning methods, the self-supervised
variational autoencoder (SSVAE). SSVAEs circumvent the usual VAE requirement to
reconstruct the data by using a carefully chosen implicit decoder. The InfoNCE
objective was motivated as a simplified parametric mutual information
estimator. Under one choice of prior, the SSVAE objective (i.e. the ELBO) is
exactly equal to the mutual information (up to constants). Under an alternative
choice of prior, the SSVAE objective is exactly equal to the simplified
parametric mutual information estimator used in InfoNCE (up to constants).
Importantly, the use of simplified parametric mutual information estimators is
believed to be critical to obtain good high-level representations, and the
SSVAE framework naturally provides a principled justification for using prior
information to choose these estimators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Visual Navigation for Under-Canopy Agricultural Robots. (arXiv:2107.02792v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_A/0/1/0/all/0/1">Arun Narenthiran Sivakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1">Sahil Modi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasparino_M/0/1/0/all/0/1">Mateus Valverde Gasparino</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_C/0/1/0/all/0/1">Che Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasquez_A/0/1/0/all/0/1">Andres Eduardo Baquero Velasquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Saurabh Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02792">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a system for visually guided autonomous navigation of
under-canopy farm robots. Low-cost under-canopy robots can drive between crop
rows under the plant canopy and accomplish tasks that are infeasible for
over-the-canopy drones or larger agricultural equipment. However, autonomously
navigating them under the canopy presents a number of challenges: unreliable
GPS and LiDAR, high cost of sensing, challenging farm terrain, clutter due to
leaves and weeds, and large variability in appearance over the season and
across crop types. We address these challenges by building a modular system
that leverages machine learning for robust and generalizable perception from
monocular RGB images from low-cost cameras, and model predictive control for
accurate control in challenging terrain. Our system, CropFollow, is able to
autonomously drive 485 meters per intervention on average, outperforming a
state-of-the-art LiDAR based system (286 meters per intervention) in extensive
field testing spanning over 25 km.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Xformers: Efficient Attention for Image Classification. (arXiv:2107.02239v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeevan_P/0/1/0/all/0/1">Pranav Jeevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_A/0/1/0/all/0/1">Amit Sethi</a> (Indian Institute of Technology Bombay)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02239">
                                    <div class="article-summary-box-inner">
                                        <span>Linear attention mechanisms provide hope for overcoming the bottleneck of
quadratic complexity which restricts application of transformer models in
vision tasks. We modify the ViT architecture to work on longer sequence data by
replacing the quadratic attention with efficient transformers like Performer,
Linformer and Nystr\&quot;omformer of linear complexity creating Vision X-formers
(ViX). We show that ViX performs better than ViT in image classification
consuming lesser computing resources. We further show that replacing the
embedding linear layer by convolutional layers in ViX further increases their
performance. Our test on recent visions transformer models like LeViT and
Compact Convolutional Transformer (CCT) show that replacing the attention with
Nystr\&quot;omformer or Performer saves GPU usage and memory without deteriorating
performance. Incorporating these changes can democratize transformers by making
them accessible to those with limited data and computing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ETHOS: an Online Hate Speech Detection Dataset. (arXiv:2006.08328v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mollas_I/0/1/0/all/0/1">Ioannis Mollas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysopoulou_Z/0/1/0/all/0/1">Zoe Chrysopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlos_S/0/1/0/all/0/1">Stamatis Karlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08328">
                                    <div class="article-summary-box-inner">
                                        <span>Online hate speech is a recent problem in our society that is rising at a
steady pace by leveraging the vulnerabilities of the corresponding regimes that
characterise most social media platforms. This phenomenon is primarily fostered
by offensive comments, either during user interaction or in the form of a
posted multimedia context. Nowadays, giant corporations own platforms where
millions of users log in every day, and protection from exposure to similar
phenomena appears to be necessary in order to comply with the corresponding
legislation and maintain a high level of service quality. A robust and reliable
system for detecting and preventing the uploading of relevant content will have
a significant impact on our digitally interconnected society. Several aspects
of our daily lives are undeniably linked to our social profiles, making us
vulnerable to abusive behaviours. As a result, the lack of accurate hate speech
detection mechanisms would severely degrade the overall user experience,
although its erroneous operation would pose many ethical concerns. In this
paper, we present &#x27;ETHOS&#x27;, a textual dataset with two variants: binary and
multi-label, based on YouTube and Reddit comments validated using the
Figure-Eight crowdsourcing platform. Furthermore, we present the annotation
protocol used to create this dataset: an active sampling procedure for
balancing our data in relation to the various aspects defined. Our key
assumption is that, even gaining a small amount of labelled data from such a
time-consuming process, we can guarantee hate speech occurrences in the
examined material.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization by design: Shortcuts to Generalization in Deep Learning. (arXiv:2107.02253v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taborsky_P/0/1/0/all/0/1">Petr Taborsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_L/0/1/0/all/0/1">Lars Kai Hansen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02253">
                                    <div class="article-summary-box-inner">
                                        <span>We take a geometrical viewpoint and present a unifying view on supervised
deep learning with the Bregman divergence loss function - this entails frequent
classification and prediction tasks. Motivated by simulations we suggest that
there is principally no implicit bias of vanilla stochastic gradient descent
training of deep models towards &quot;simpler&quot; functions. Instead, we show that good
generalization may be instigated by bounded spectral products over layers
leading to a novel geometric regularizer. It is revealed that in deep enough
models such a regularizer enables both, extreme accuracy and generalization, to
be reached. We associate popular regularization techniques like weight decay,
drop out, batch normalization, and early stopping with this perspective. Backed
up by theory we further demonstrate that &quot;generalization by design&quot; is
practically possible and that good generalization may be encoded into the
structure of the network. We design two such easy-to-use structural
regularizers that insert an additional \textit{generalization layer} into a
model architecture, one with a skip connection and another one with drop-out.
We verify our theoretical results in experiments on various feedforward and
convolutional architectures, including ResNets, and datasets (MNIST, CIFAR10,
synthetic data). We believe this work opens up new avenues of research towards
better generalizing architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAGE: Intrusion Alert-driven Attack Graph Extractor. (arXiv:2107.02783v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nadeem_A/0/1/0/all/0/1">Azqa Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1">Sicco Verwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Moskal_S/0/1/0/all/0/1">Stephen Moskal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shanchieh Jay Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02783">
                                    <div class="article-summary-box-inner">
                                        <span>Attack graphs (AG) are used to assess pathways availed by cyber adversaries
to penetrate a network. State-of-the-art approaches for AG generation focus
mostly on deriving dependencies between system vulnerabilities based on network
scans and expert knowledge. In real-world operations however, it is costly and
ineffective to rely on constant vulnerability scanning and expert-crafted AGs.
We propose to automatically learn AGs based on actions observed through
intrusion alerts, without prior expert knowledge. Specifically, we develop an
unsupervised sequence learning system, SAGE, that leverages the temporal and
probabilistic dependence between alerts in a suffix-based probabilistic
deterministic finite automaton (S-PDFA) -- a model that accentuates infrequent
severe alerts and summarizes paths leading to them. AGs are then derived from
the S-PDFA. Tested with intrusion alerts collected through Collegiate
Penetration Testing Competition, SAGE produces AGs that reflect the strategies
used by participating teams. The resulting AGs are succinct, interpretable, and
enable analysts to derive actionable insights, e.g., attackers tend to follow
shorter paths after they have discovered a longer one.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned Features with Data Augmentation. (arXiv:1904.08084v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nanni_L/0/1/0/all/0/1">L. Nanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahnam_S/0/1/0/all/0/1">S. Brahnam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghidoni_S/0/1/0/all/0/1">S. Ghidoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguolo_G/0/1/0/all/0/1">G. Maguolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.08084">
                                    <div class="article-summary-box-inner">
                                        <span>Bioimage classification plays a crucial role in many biological problems. In
this work, we present a new General Purpose (GenP) ensemble that boosts
performance by combining local features, dense sampling features, and deep
learning approaches. First, we introduce three new methods for data
augmentation based on PCA/DCT; second, we show that different data augmentation
approaches can boost the performance of an ensemble of CNNs; and, finally, we
propose a set of handcrafted/learned descriptors that are highly generalizable.
Each handcrafted descriptor is used to train a different Support Vector Machine
(SVM), and the different SVMs are combined with the ensemble of CNNs. Our
method is evaluated on a diverse set of bioimage classification problems.
Results demonstrate that the proposed GenP bioimage ensemble obtains
state-of-the-art performance without any ad-hoc dataset tuning of parameters
(thus avoiding the risk of overfitting/overtraining).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dueling Bandits with Team Comparisons. (arXiv:2107.02738v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1">Lee Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_Kraepelin_U/0/1/0/all/0/1">Ulrike Schmidt-Kraepelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02738">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the dueling teams problem, a new online-learning setting in
which the learner observes noisy comparisons of disjoint pairs of $k$-sized
teams from a universe of $n$ players. The goal of the learner is to minimize
the number of duels required to identify, with high probability, a Condorcet
winning team, i.e., a team which wins against any other disjoint team (with
probability at least $1/2$). Noisy comparisons are linked to a total order on
the teams. We formalize our model by building upon the dueling bandits setting
(Yue et al.2012) and provide several algorithms, both for stochastic and
deterministic settings. For the stochastic setting, we provide a reduction to
the classical dueling bandits setting, yielding an algorithm that identifies a
Condorcet winning team within $\mathcal{O}((n + k \log (k)) \frac{\max(\log\log
n, \log k)}{\Delta^2})$ duels, where $\Delta$ is a gap parameter. For
deterministic feedback, we additionally present a gap-independent algorithm
that identifies a Condorcet winning team within $\mathcal{O}(nk\log(k)+k^5)$
duels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning. (arXiv:2107.02794v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1">Maxwell Nye</a>, <a href="http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1">Michael Henry Tessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1">Brenden M. Lake</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02794">
                                    <div class="article-summary-box-inner">
                                        <span>Human reasoning can often be understood as an interplay between two systems:
the intuitive and associative (&quot;System 1&quot;) and the deliberative and logical
(&quot;System 2&quot;). Neural sequence models -- which have been increasingly successful
at performing complex, structured tasks -- exhibit the advantages and failure
modes of System 1: they are fast and learn patterns from data, but are often
inconsistent and incoherent. In this work, we seek a lightweight, training-free
means of improving existing System 1-like sequence models by adding System
2-inspired logical reasoning. We explore several variations on this theme in
which candidate generations from a neural sequence model are examined for
logical consistency by a symbolic reasoning module, which can either accept or
reject the generations. Our approach uses neural inference to mediate between
the neural System 1 and the logical System 2. Results in robust story
generation and grounded instruction-following show that this approach can
increase the coherence and accuracy of neurally-based generations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Ensemble Noise-Robust K-fold Cross-Validation Selection Method for Noisy Labels. (arXiv:2107.02347v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalander_M/0/1/0/all/0/1">Marcus Kalander</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chanfei Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Lujia Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02347">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of training robust and accurate deep neural networks
(DNNs) when subject to various proportions of noisy labels. Large-scale
datasets tend to contain mislabeled samples that can be memorized by DNNs,
impeding the performance. With appropriate handling, this degradation can be
alleviated. There are two problems to consider: how to distinguish clean
samples and how to deal with noisy samples. In this paper, we present Ensemble
Noise-robust K-fold Cross-Validation Selection (E-NKCVS) to effectively select
clean samples from noisy data, solving the first problem. For the second
problem, we create a new pseudo label for any sample determined to have an
uncertain or likely corrupt label. E-NKCVS obtains multiple predicted labels
for each sample and the entropy of these labels is used to tune the weight
given to the pseudo label and the given label. Theoretical analysis and
extensive verification of the algorithms in the noisy label setting are
provided. We evaluate our approach on various image and text classification
tasks where the labels have been manually corrupted with different noise
ratios. Additionally, two large real-world noisy datasets are also used,
Clothing-1M and WebVision. E-NKCVS is empirically shown to be highly tolerant
to considerable proportions of label noise and has a consistent improvement
over state-of-the-art methods. Especially on more difficult datasets with
higher noise ratios, we can achieve a significant improvement over the
second-best model. Moreover, our proposed approach can easily be integrated
into existing DNN methods to improve their robustness against label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-training with noisy student model and semi-supervised loss function for dcase 2021 challenge task 4. (arXiv:2107.02569v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Nam Kyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hong Kook Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02569">
                                    <div class="article-summary-box-inner">
                                        <span>This report proposes a polyphonic sound event detection (SED) method for the
DCASE 2021 Challenge Task 4. The proposed SED model consists of two stages: a
mean-teacher model for providing target labels regarding weakly labeled or
unlabeled data and a self-training-based noisy student model for predicting
strong labels for sound events. The mean-teacher model, which is based on the
residual convolutional recurrent neural network (RCRNN) for the teacher and
student model, is first trained using all the training data from a weakly
labeled dataset, an unlabeled dataset, and a strongly labeled synthetic
dataset. Then, the trained mean-teacher model predicts the strong label to each
of the weakly labeled and unlabeled datasets, which is brought to the noisy
student model in the second stage of the proposed SED model. Here, the
structure of the noisy student model is identical to the RCRNN-based student
model of the mean-teacher model in the first stage. Then, it is self-trained by
adding feature noises, such as time-frequency shift, mixup, SpecAugment, and
dropout-based model noise. In addition, a semi-supervised loss function is
applied to train the noisy student model, which acts as label noise injection.
The performance of the proposed SED model is evaluated on the validation set of
the DCASE 2021 Challenge Task 4, and then, several ensemble models that combine
five-fold validation models with different hyperparameters of the
semi-supervised loss function are finally selected as our final models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Un-/Semi-Supervised Machine Learning for MDSE of the Real-World CPS/IoT Applications. (arXiv:2107.02690v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1">Armin Moin</a>, <a href="http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1">Atta Badii</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02690">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel approach to support domain-specific
Model-Driven Software Engineering (MDSE) for the real-world use-case scenarios
of smart Cyber-Physical Systems (CPS) and the Internet of Things (IoT). We
argue that the majority of available data in the nature for Artificial
Intelligence (AI), specifically Machine Learning (ML) are unlabeled. Hence,
unsupervised and/or semi-supervised ML approaches are the practical choices.
However, prior work in the literature of MDSE has considered supervised ML
approaches, which only work with labeled training data. Our proposed approach
is fully implemented and integrated with an existing state-of-the-art MDSE tool
to serve the CPS/IoT domain. Moreover, we validate the proposed approach using
a portion of the open data of the REFIT reference dataset for the smart energy
systems domain. Our model-to-code transformations (code generators) provide the
full source code of the desired IoT services out of the model instances in an
automated manner. Currently, we generate the source code in Java and Python.
The Python code is responsible for the ML functionalities and uses the APIs of
several ML libraries and frameworks, namely Scikit-Learn, Keras and TensorFlow.
For unsupervised and semi-supervised learning, the APIs of Scikit-Learn are
deployed. In addition to the pure MDSE approach, where certain ML methods,
e.g., K-Means, Mini-Batch K-Means, DB-SCAN, Spectral Clustering, Gaussian
Mixture Model, Self-Training, Label Propagation and Label Spreading are
supported, a more flexible, hybrid approach is also enabled to support the
practitioner in deploying a pre-trained ML model with any arbitrary
architecture and learning algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Network Approximation With Accuracy Independent of Number of Neurons. (arXiv:2107.02397v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zuowei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02397">
                                    <div class="article-summary-box-inner">
                                        <span>This paper develops simple feed-forward neural networks that achieve the
universal approximation property for all continuous functions with a fixed
finite number of neurons. These neural networks are simple because they are
designed with a simple and computable continuous activation function $\sigma$
leveraging a triangular-wave function and a softsign function. We prove that
$\sigma$-activated networks with width $36d(2d+1)$ and depth $11$ can
approximate any continuous function on a $d$-dimensioanl hypercube within an
arbitrarily small error. Hence, for supervised learning and its related
regression problems, the hypothesis space generated by these networks with a
size not smaller than $36d(2d+1)\times 11$ is dense in the space of continuous
functions. Furthermore, classification functions arising from image and signal
classification are in the hypothesis space generated by $\sigma$-activated
networks with width $36d(2d+1)$ and depth $12$, when there exist pairwise
disjoint closed bounded subsets of $\mathbb{R}^d$ such that the samples of the
same class are located in the same subset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Variational Conditional Sampling with Normalizing Flows. (arXiv:2107.02474v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Moens_V/0/1/0/all/0/1">Vincent Moens</a>, <a href="http://arxiv.org/find/stat/1/au:+Sootla_A/0/1/0/all/0/1">Aivar Sootla</a>, <a href="http://arxiv.org/find/stat/1/au:+Ammar_H/0/1/0/all/0/1">Haitham Bou Ammar</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02474">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for conditional sampling with normalizing flows when only
part of an observation is available. We rely on the following fact: if the
flow&#x27;s domain can be partitioned in such a way that the flow restrictions to
subdomains keep the bijectivity property, a lower bound to the conditioning
variable log-probability can be derived. Simulation from the variational
conditional flow then amends to solving an equality constraint. Our
contribution is three-fold: a) we provide detailed insights on the choice of
variational distributions; b) we propose how to partition the input space of
the flow to preserve bijectivity property; c) we propose a set of methods to
optimise the variational distribution in specific cases. Through extensive
experiments, we show that our sampling method can be applied with success to
invertible residual networks for inference and classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation Alternative Technique: Segmentation Domain Generation. (arXiv:2107.02525v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogoz_A/0/1/0/all/0/1">Ana-Cristina Rogoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Muntean_R/0/1/0/all/0/1">Radu Muntean</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobeli_S/0/1/0/all/0/1">Stefan Cobeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02525">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting objects of interest in images was always a compelling task to
automate. In recent years this task was more and more explored using deep
learning techniques, mostly using region-based convolutional networks. In this
project we propose an alternative semantic segmentation technique making use of
Generative Adversarial Networks. We consider semantic segmentation to be a
domain transfer problem. Thus, we train a feed forward network (FFNN) to
receive as input a seed real image and generate as output its segmentation
mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering. (arXiv:2107.02331v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02331">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning promises to alleviate the massive data needs of supervised
machine learning: it has successfully improved sample efficiency by an order of
magnitude on traditional tasks like topic classification and object
recognition. However, we uncover a striking contrast to this promise: across 5
models and 4 datasets on the task of visual question answering, a wide variety
of active learning approaches fail to outperform random selection. To
understand this discrepancy, we profile 8 active learning methods on a
per-example basis, and identify the problem as collective outliers -- groups of
examples that active learning methods prefer to acquire but models fail to
learn (e.g., questions that ask about text in images or require external
knowledge). Through systematic ablation experiments and qualitative
visualizations, we verify that collective outliers are a general phenomenon
responsible for degrading pool-based active learning. Notably, we show that
active learning sample efficiency increases significantly as the number of
collective outliers in the active learning pool decreases. We conclude with a
discussion and prescriptive recommendations for mitigating the effects of these
outliers in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete-Valued Neural Communication. (arXiv:2107.02367v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dianbo_Liu_D/0/1/0/all/0/1">Dianbo Liu Dianbo_Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1">Alex Lamb</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1">Kenji Kawaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1">Anirudh Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1">Michael Curtis Mozer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02367">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has advanced from fully connected architectures to structured
models organized into components, e.g., the transformer composed of positional
elements, modular architectures divided into slots, and graph neural nets made
up of nodes. In structured models, an interesting question is how to conduct
dynamic and possibly sparse communication among the separate components. Here,
we explore the hypothesis that restricting the transmitted information among
components to discrete representations is a beneficial bottleneck. The
motivating intuition is human language in which communication occurs through
discrete symbols. Even though individuals have different understandings of what
a &#x60;&#x60;&quot;cat&quot; is based on their specific experiences, the shared discrete token
makes it possible for communication among individuals to be unimpeded by
individual differences in internal representation. To discretize the values of
concepts dynamically communicated among specialist components, we extend the
quantization mechanism from the Vector-Quantized Variational Autoencoder to
multi-headed discretization with shared codebooks and use it for
discrete-valued neural communication (DVNC). Our experiments show that DVNC
substantially improves systematic generalization in a variety of architectures
-- transformers, modular architectures, and graph neural networks. We also show
that the DVNC is robust to the choice of hyperparameters, making the method
very useful in practice. Moreover, we establish a theoretical justification of
our discretization process, proving that it has the ability to increase noise
robustness and reduce the underlying dimensionality of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth-supervised NeRF: Fewer Views and Faster Training for Free. (arXiv:2107.02791v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Andrew Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02791">
                                    <div class="article-summary-box-inner">
                                        <span>One common failure mode of Neural Radiance Field (NeRF) models is fitting
incorrect geometries when given an insufficient number of input views. We
propose DS-NeRF (Depth-supervised Neural Radiance Fields), a loss for learning
neural radiance fields that takes advantage of readily-available depth
supervision. Our key insight is that sparse depth supervision can be used to
regularize the learned geometry, a crucial component for effectively rendering
novel views using NeRF. We exploit the fact that current NeRF pipelines require
images with known camera poses that are typically estimated by running
structure-from-motion (SFM). Crucially, SFM also produces sparse 3D points that
can be used as &#x60;&#x60;free&quot; depth supervision during training: we simply add a loss
to ensure that depth rendered along rays that intersect these 3D points is
close to the observed depth. We find that DS-NeRF can render more accurate
images given fewer training views while training 2-6x faster. With only two
training views on real-world images, DS-NeRF significantly outperforms NeRF as
well as other sparse-view variants. We show that our loss is compatible with
these NeRF models, demonstrating that depth is a cheap and easily digestible
supervisory signal. Finally, we show that DS-NeRF supports other types of depth
supervision such as scanned depth sensors and RGBD reconstruction outputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GradDiv: Adversarial Robustness of Randomized Neural Networks via Gradient Diversity Regularization. (arXiv:2107.02425v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungyoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoki Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaewook Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02425">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is vulnerable to adversarial examples. Many defenses based on
randomized neural networks have been proposed to solve the problem, but fail to
achieve robustness against attacks using proxy gradients such as the
Expectation over Transformation (EOT) attack. We investigate the effect of the
adversarial attacks using proxy gradients on randomized neural networks and
demonstrate that it highly relies on the directional distribution of the loss
gradients of the randomized neural network. We show in particular that proxy
gradients are less effective when the gradients are more scattered. To this
end, we propose Gradient Diversity (GradDiv) regularizations that minimize the
concentration of the gradients to build a robust randomized neural network. Our
experiments on MNIST, CIFAR10, and STL10 show that our proposed GradDiv
regularizations improve the adversarial robustness of randomized neural
networks against a variety of state-of-the-art attack methods. Moreover, our
method efficiently reduces the transferability among sample models of
randomized neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Clinical Context for User-Centered Explainability: A Diabetes Use Case. (arXiv:2107.02359v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chari_S/0/1/0/all/0/1">Shruthi Chari</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_P/0/1/0/all/0/1">Prithwish Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghalwash_M/0/1/0/all/0/1">Mohamed Ghalwash</a>, <a href="http://arxiv.org/find/cs/1/au:+Seneviratne_O/0/1/0/all/0/1">Oshani Seneviratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Eyigoz_E/0/1/0/all/0/1">Elif K. Eyigoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gruen_D/0/1/0/all/0/1">Daniel M. Gruen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Ching-Hua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_P/0/1/0/all/0/1">Pablo Meyer Rojas</a>, <a href="http://arxiv.org/find/cs/1/au:+McGuinness_D/0/1/0/all/0/1">Deborah L. McGuinness</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02359">
                                    <div class="article-summary-box-inner">
                                        <span>Academic advances of AI models in high-precision domains, like healthcare,
need to be made explainable in order to enhance real-world adoption. Our past
studies and ongoing interactions indicate that medical experts can use AI
systems with greater trust if there are ways to connect the model inferences
about patients to explanations that are tied back to the context of use.
Specifically, risk prediction is a complex problem of diagnostic and
interventional importance to clinicians wherein they consult different sources
to make decisions. To enable the adoption of the ever improving AI risk
prediction models in practice, we have begun to explore techniques to
contextualize such models along three dimensions of interest: the patients&#x27;
clinical state, AI predictions about their risk of complications, and
algorithmic explanations supporting the predictions. We validate the importance
of these dimensions by implementing a proof-of-concept (POC) in type-2 diabetes
(T2DM) use case where we assess the risk of chronic kidney disease (CKD) - a
common T2DM comorbidity. Within the POC, we include risk prediction models for
CKD, post-hoc explainers of the predictions, and other natural-language modules
which operationalize domain knowledge and CPGs to provide context. With primary
care physicians (PCP) as our end-users, we present our initial results and
clinician feedback in this paper. Our POC approach covers multiple knowledge
sources and clinical scenarios, blends knowledge to explain data and
predictions to PCPs, and received an enthusiastic response from our medical
expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Nonparametric Modelling for Model-Free Reinforcement Learning in LTE-LAA and Wi-Fi Coexistence. (arXiv:2107.02431v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shih_P/0/1/0/all/0/1">Po-Kan Shih</a>, <a href="http://arxiv.org/find/cs/1/au:+Moraffah_B/0/1/0/all/0/1">Bahman Moraffah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02431">
                                    <div class="article-summary-box-inner">
                                        <span>With the arrival of next generation wireless communication, a growing number
of new applications like internet of things, autonomous driving systems, and
drone are crowding the unlicensed spectrum. Licensed network such as the
long-term evolution (LTE) also comes to the unlicensed spectrum for better
providing high-capacity contents with low cost. However, LTE was not designed
to share resources with others. Previous solutions usually work on fixed
scenarios. This work features a Nonparametric Bayesian reinforcement learning
algorithm to cope with the coexistence between Wi-Fi and LTE licensed assisted
access (LTE-LAA) agents in 5 GHz unlicensed spectrum. The coexistence problem
is modeled as a decentralized partially-observable Markov decision process
(Dec-POMDP) and Bayesian inference is adopted for policy learning with
nonparametric prior to accommodate the uncertainty of policy for different
agents. A fairness measure is introduced in the reward function to encourage
fair sharing between agents. Variational inference for posterior model
approximation is considered to make the algorithm computationally efficient.
Simulation results demonstrate that this algorithm can reach high value with
compact policy representations in few learning iterations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning. (arXiv:2107.02339v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kaiqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1">Harold Soh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02339">
                                    <div class="article-summary-box-inner">
                                        <span>This work focuses on learning useful and robust deep world models using
multiple, possibly unreliable, sensors. We find that current methods do not
sufficiently encourage a shared representation between modalities; this can
cause poor performance on downstream tasks and over-reliance on specific
sensors. As a solution, we contribute a new multi-modal deep latent state-space
model, trained using a mutual information lower-bound. The key innovation is a
specially-designed density ratio estimator that encourages consistency between
the latent codes of each modality. We tasked our method to learn policies (in a
self-supervised manner) on multi-modal Natural MuJoCo benchmarks and a
challenging Table Wiping task. Experiments show our method significantly
outperforms state-of-the-art deep reinforcement learning methods, particularly
in the presence of missing observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physical Interaction as Communication: Learning Robot Objectives Online from Human Corrections. (arXiv:2107.02349v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Losey_D/0/1/0/all/0/1">Dylan P. Losey</a>, <a href="http://arxiv.org/find/cs/1/au:+Bajcsy_A/0/1/0/all/0/1">Andrea Bajcsy</a>, <a href="http://arxiv.org/find/cs/1/au:+OMalley_M/0/1/0/all/0/1">Marcia K. O&#x27;Malley</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca D. Dragan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02349">
                                    <div class="article-summary-box-inner">
                                        <span>When a robot performs a task next to a human, physical interaction is
inevitable: the human might push, pull, twist, or guide the robot. The
state-of-the-art treats these interactions as disturbances that the robot
should reject or avoid. At best, these robots respond safely while the human
interacts; but after the human lets go, these robots simply return to their
original behavior. We recognize that physical human-robot interaction (pHRI) is
often intentional -- the human intervenes on purpose because the robot is not
doing the task correctly. In this paper, we argue that when pHRI is intentional
it is also informative: the robot can leverage interactions to learn how it
should complete the rest of its current task even after the person lets go. We
formalize pHRI as a dynamical system, where the human has in mind an objective
function they want the robot to optimize, but the robot does not get direct
access to the parameters of this objective -- they are internal to the human.
Within our proposed framework human interactions become observations about the
true objective. We introduce approximations to learn from and respond to pHRI
in real-time. We recognize that not all human corrections are perfect: often
users interact with the robot noisily, and so we improve the efficiency of
robot learning from pHRI by reducing unintended learning. Finally, we conduct
simulations and user studies on a robotic manipulator to compare our proposed
approach to the state-of-the-art. Our results indicate that learning from pHRI
leads to better task performance and improved human satisfaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoReD: Generalizing Fake Media Detection with Continual Representation using Distillation. (arXiv:2107.02408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02408">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, artificial intelligence research has made
tremendous strides, but it still heavily relies on fixed datasets in stationary
environments. Continual learning is a growing field of research that examines
how AI systems can learn sequentially from a continuous stream of linked data
in the same way that biological systems do. Simultaneously, fake media such as
deepfakes and synthetic face images have emerged as significant to current
multimedia technologies. Recently, numerous method has been proposed which can
detect deepfakes with high accuracy. However, they suffer significantly due to
their reliance on fixed datasets in limited evaluation settings. Therefore, in
this work, we apply continuous learning to neural networks&#x27; learning dynamics,
emphasizing its potential to increase data efficiency significantly. We propose
Continual Representation using Distillation (CoReD) method that employs the
concept of Continual Learning (CoL), Representation Learning (ReL), and
Knowledge Distillation (KD). We design CoReD to perform sequential domain
adaptation tasks on new deepfake and GAN-generated synthetic face datasets,
while effectively minimizing the catastrophic forgetting in a teacher-student
model setting. Our extensive experimental results demonstrate that our method
is efficient at domain adaptation to detect low-quality deepfakes videos and
GAN-generated images from several datasets, outperforming the-state-of-art
baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Short Note on the Relationship of Information Gain and Eluder Dimension. (arXiv:2107.02377v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaixuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02377">
                                    <div class="article-summary-box-inner">
                                        <span>Eluder dimension and information gain are two widely used methods of
complexity measures in bandit and reinforcement learning. Eluder dimension was
originally proposed as a general complexity measure of function classes, but
the common examples of where it is known to be small are function spaces
(vector spaces). In these cases, the primary tool to upper bound the eluder
dimension is the elliptic potential lemma. Interestingly, the elliptic
potential lemma also features prominently in the analysis of linear
bandits/reinforcement learning and their nonparametric generalization, the
information gain. We show that this is not a coincidence -- eluder dimension
and information gain are equivalent in a precise sense for reproducing kernel
Hilbert spaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepDDS: deep graph neural network with attention mechanism to predict synergistic drug combinations. (arXiv:2107.02467v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">J. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">X. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">S. Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">L. Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu%2A_H/0/1/0/all/0/1">H. Liu*</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02467">
                                    <div class="article-summary-box-inner">
                                        <span>Drug combination therapy has become a increasingly promising method in the
treatment of cancer. However, the number of possible drug combinations is so
huge that it is hard to screen synergistic drug combinations through wet-lab
experiments. Therefore, computational screening has become an important way to
prioritize drug combinations. Graph neural network have recently shown
remarkable performance in the prediction of compound-protein interactions, but
it has not been applied to the screening of drug combinations. In this paper,
we proposed a deep learning model based on graph neural networks and attention
mechanism to identify drug combinations that can effectively inhibit the
viability of specific cancer cells. The feature embeddings of drug molecule
structure and gene expression profiles were taken as input to multi-layer
feedforward neural network to identify the synergistic drug combinations. We
compared DeepDDS with classical machine learning methods and other deep
learning-based methods on benchmark data set, and the leave-one-out
experimental results showed that DeepDDS achieved better performance than
competitive methods. Also, on an independent test set released by well-known
pharmaceutical enterprise AstraZeneca, DeepDDS was superior to competitive
methods by more than 16\% predictive precision. Furthermore, we explored the
interpretability of the graph attention network, and found the correlation
matrix of atomic features revealed important chemical substructures of drugs.
We believed that DeepDDS is an effective tool that prioritized synergistic drug
combinations for further wet-lab experiment validation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instant One-Shot Word-Learning for Context-Specific Neural Sequence-to-Sequence Speech Recognition. (arXiv:2107.02268v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1">Christian Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_J/0/1/0/all/0/1">Juan Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuker_S/0/1/0/all/0/1">Sebastian St&#xfc;ker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alexander Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02268">
                                    <div class="article-summary-box-inner">
                                        <span>Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition (ASR). When using appropriate modeling units,
e.g., byte-pair encoded characters, these systems are in principal open
vocabulary systems. In practice, however, they often fail to recognize words
not seen during training, e.g., named entities, numbers or technical terms. To
alleviate this problem we supplement an end-to-end ASR system with a
word/phrase memory and a mechanism to access this memory to recognize the words
and phrases correctly. After the training of the ASR system, and when it has
already been deployed, a relevant word can be added or subtracted instantly
without the need for further training. In this paper we demonstrate that
through this mechanism our system is able to recognize more than 85% of newly
added words that it previously failed to recognize compared to a strong
baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VolNet: Estimating Human Body Part Volumes from a Single RGB Image. (arXiv:2107.02259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leinen_F/0/1/0/all/0/1">Fabian Leinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cozzolino_V/0/1/0/all/0/1">Vittorio Cozzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Torsten Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02259">
                                    <div class="article-summary-box-inner">
                                        <span>Human body volume estimation from a single RGB image is a challenging problem
despite minimal attention from the research community. However VolNet, an
architecture leveraging 2D and 3D pose estimation, body part segmentation and
volume regression extracted from a single 2D RGB image combined with the
subject&#x27;s body height can be used to estimate the total body volume. VolNet is
designed to predict the 2D and 3D pose as well as the body part segmentation in
intermediate tasks. We generated a synthetic, large-scale dataset of
photo-realistic images of human bodies with a wide range of body shapes and
realistic poses called SURREALvols. By using Volnet and combining multiple
stacked hourglass networks together with ResNeXt, our model correctly predicted
the volume in ~82% of cases with a 10% tolerance threshold. This is a
considerable improvement compared to state-of-the-art solutions such as BodyNet
with only a ~38% success rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation via CycleGAN for Retina Segmentation in Optical Coherence Tomography. (arXiv:2107.02345v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_R/0/1/0/all/0/1">Ricky Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_T/0/1/0/all/0/1">Timothy T. Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_G/0/1/0/all/0/1">Gavin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1">Da Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarunic_M/0/1/0/all/0/1">Marinko V. Sarunic</a>, <a href="http://arxiv.org/find/eess/1/au:+Beg_M/0/1/0/all/0/1">Mirza Faisal Beg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02345">
                                    <div class="article-summary-box-inner">
                                        <span>With the FDA approval of Artificial Intelligence (AI) for point-of-care
clinical diagnoses, model generalizability is of the utmost importance as
clinical decision-making must be domain-agnostic. A method of tackling the
problem is to increase the dataset to include images from a multitude of
domains; while this technique is ideal, the security requirements of medical
data is a major limitation. Additionally, researchers with developed tools
benefit from the addition of open-sourced data, but are limited by the
difference in domains. Herewith, we investigated the implementation of a
Cycle-Consistent Generative Adversarial Networks (CycleGAN) for the domain
adaptation of Optical Coherence Tomography (OCT) volumes. This study was done
in collaboration with the Biomedical Optics Research Group and Functional &amp;
Anatomical Imaging &amp; Shape Analysis Lab at Simon Fraser University. In this
study, we investigated a learning-based approach of adapting the domain of a
publicly available dataset, UK Biobank dataset (UKB). To evaluate the
performance of domain adaptation, we utilized pre-existing retinal layer
segmentation tools developed on a different set of RETOUCH OCT data. This study
provides insight on state-of-the-art tools for domain adaptation compared to
traditional processing techniques as well as a pipeline for adapting publicly
available retinal data to the domains previously used by our collaborators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Explainable Artificial Intelligence in Manufacturing. (arXiv:2107.02295v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sofianidis_G/0/1/0/all/0/1">Georgios Sofianidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozanec_J/0/1/0/all/0/1">Jo&#x17e;e M. Ro&#x17e;anec</a>, <a href="http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1">Dunja Mladeni&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyriazis_D/0/1/0/all/0/1">Dimosthenis Kyriazis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02295">
                                    <div class="article-summary-box-inner">
                                        <span>The implementation of Artificial Intelligence (AI) systems in the
manufacturing domain enables higher production efficiency, outstanding
performance, and safer operations, leveraging powerful tools such as deep
learning and reinforcement learning techniques. Despite the high accuracy of
these models, they are mostly considered black boxes: they are unintelligible
to the human. Opaqueness affects trust in the system, a factor that is critical
in the context of decision-making. We present an overview of Explainable
Artificial Intelligence (XAI) techniques as a means of boosting the
transparency of models. We analyze different metrics to evaluate these
techniques and describe several application scenarios in the manufacturing
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination. (arXiv:2107.02237v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">Dylan J. Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1">Akshay Krishnamurthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02237">
                                    <div class="article-summary-box-inner">
                                        <span>A recurring theme in statistical learning, online learning, and beyond is
that faster convergence rates are possible for problems with low noise, often
quantified by the performance of the best hypothesis; such results are known as
first-order or small-loss guarantees. While first-order guarantees are
relatively well understood in statistical and online learning, adapting to low
noise in contextual bandits (and more broadly, decision making) presents major
algorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy,
Langford, Luo, and Schapire asked whether first-order guarantees are even
possible for contextual bandits and -- if so -- whether they can be attained by
efficient algorithms. We give a resolution to this question by providing an
optimal and efficient reduction from contextual bandits to online regression
with the logarithmic (or, cross-entropy) loss. Our algorithm is simple and
practical, readily accommodates rich function classes, and requires no
distributional assumptions beyond realizability. In a large-scale empirical
evaluation, we find that our approach typically outperforms comparable
non-first-order methods.

On the technical side, we show that the logarithmic loss and an
information-theoretic quantity called the triangular discrimination play a
fundamental role in obtaining first-order guarantees, and we combine this
observation with new refinements to the regression oracle reduction framework
of Foster and Rakhlin. The use of triangular discrimination yields novel
results even for the classical statistical learning model, and we anticipate
that it will find broader use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effects of Smart Traffic Signal Control on Air Quality. (arXiv:2107.02361v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fazzini_P/0/1/0/all/0/1">Paolo Fazzini</a>, <a href="http://arxiv.org/find/cs/1/au:+Torre_M/0/1/0/all/0/1">Marco Torre</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizza_V/0/1/0/all/0/1">Valeria Rizza</a>, <a href="http://arxiv.org/find/cs/1/au:+Petracchini_F/0/1/0/all/0/1">Francesco Petracchini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02361">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive traffic signal control (ATSC) in urban traffic networks poses a
challenging task due to the complicated dynamics arising in traffic systems. In
recent years, several approaches based on multi-agent deep reinforcement
learning (MARL) have been studied experimentally. These approaches propose
distributed techniques in which each signalized intersection is seen as an
agent in a stochastic game whose purpose is to optimize the flow of vehicles in
its vicinity. In this setting, the systems evolves towards an equilibrium among
the agents that shows beneficial for the whole traffic network. A recently
developed multi-agent variant of the well-established advantage actor-critic
(A2C) algorithm, called MA2C (multi-agent A2C) exploits the promising idea of
some communication among the agents. In this view,the agents share their
strategies with other neighbor agents, thereby stabilizing the learning process
even when the agents grow in number and variety. We experimented MA2C in two
traffic networks located in Bologna (Italy) and found that its action
translates into a significant decrease of the amount of pollutants released
into the environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Learning-Based Particle-in-Cell Method for Plasma Simulations. (arXiv:2107.02232v1 [physics.plasm-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Aguilar_X/0/1/0/all/0/1">Xavier Aguilar</a>, <a href="http://arxiv.org/find/physics/1/au:+Markidis_S/0/1/0/all/0/1">Stefano Markidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02232">
                                    <div class="article-summary-box-inner">
                                        <span>We design and develop a new Particle-in-Cell (PIC) method for plasma
simulations using Deep-Learning (DL) to calculate the electric field from the
electron phase space. We train a Multilayer Perceptron (MLP) and a
Convolutional Neural Network (CNN) to solve the two-stream instability test. We
verify that the DL-based MLP PIC method produces the correct results using the
two-stream instability: the DL-based PIC provides the expected growth rate of
the two-stream instability. The DL-based PIC does not conserve the total energy
and momentum. However, the DL-based PIC method is stable against the cold-beam
instability, affecting traditional PIC methods. This work shows that
integrating DL technologies into traditional computational methods is a viable
approach for developing next-generation PIC algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransformerFusion: Monocular RGB Scene Reconstruction using Transformers. (arXiv:2107.02191v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bozic_A/0/1/0/all/0/1">Alja&#x17e; Bo&#x17e;i&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Palafox_P/0/1/0/all/0/1">Pablo Palafox</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Angela Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02191">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce TransformerFusion, a transformer-based 3D scene reconstruction
approach. From an input monocular RGB video, the video frames are processed by
a transformer network that fuses the observations into a volumetric feature
grid representing the scene; this feature grid is then decoded into an implicit
3D scene representation. Key to our approach is the transformer architecture
that enables the network to learn to attend to the most relevant image frames
for each 3D location in the scene, supervised only by the scene reconstruction
task. Features are fused in a coarse-to-fine fashion, storing fine-level
features only where needed, requiring lower memory storage and enabling fusion
at interactive rates. The feature grid is then decoded to a higher-resolution
scene reconstruction, using an MLP-based surface occupancy prediction from
interpolated coarse-to-fine 3D features. Our approach results in an accurate
surface reconstruction, outperforming state-of-the-art multi-view stereo depth
estimation methods, fully-convolutional 3D reconstruction approaches, and
approaches using LSTM- or GRU-based recurrent networks for video sequence
fusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sarcasm Detection: A Comparative Study. (arXiv:2107.02276v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaghoobian_H/0/1/0/all/0/1">Hamed Yaghoobian</a>, <a href="http://arxiv.org/find/cs/1/au:+Arabnia_H/0/1/0/all/0/1">Hamid R. Arabnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_K/0/1/0/all/0/1">Khaled Rasheed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02276">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcasm detection is the task of identifying irony containing utterances in
sentiment-bearing text. However, the figurative and creative nature of sarcasm
poses a great challenge for affective computing systems performing sentiment
analysis. This article compiles and reviews the salient work in the literature
of automatic sarcasm detection. Thus far, three main paradigm shifts have
occurred in the way researchers have approached this task: 1) semi-supervised
pattern extraction to identify implicit sentiment, 2) use of hashtag-based
supervision, and 3) incorporation of context beyond target text. In this
article, we provide a comprehensive review of the datasets, approaches, trends,
and issues in sarcasm and irony detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-optimal inference in adaptive linear regression. (arXiv:2107.02266v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Khamaru_K/0/1/0/all/0/1">Koulik Khamaru</a>, <a href="http://arxiv.org/find/math/1/au:+Deshpande_Y/0/1/0/all/0/1">Yash Deshpande</a>, <a href="http://arxiv.org/find/math/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a>, <a href="http://arxiv.org/find/math/1/au:+Wainwright_M/0/1/0/all/0/1">Martin J. Wainwright</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02266">
                                    <div class="article-summary-box-inner">
                                        <span>When data is collected in an adaptive manner, even simple methods like
ordinary least squares can exhibit non-normal asymptotic behavior. As an
undesirable consequence, hypothesis tests and confidence intervals based on
asymptotic normality can lead to erroneous results. We propose an online
debiasing estimator to correct these distributional anomalies in least squares
estimation. Our proposed method takes advantage of the covariance structure
present in the dataset and provides sharper estimates in directions for which
more information has accrued. We establish an asymptotic normality property for
our proposed online debiasing estimator under mild conditions on the data
collection process, and provide asymptotically exact confidence intervals. We
additionally prove a minimax lower bound for the adaptive linear regression
problem, thereby providing a baseline by which to compare estimators. There are
various conditions under which our proposed estimator achieves the minimax
lower bound up to logarithmic factors. We demonstrate the usefulness of our
theory via applications to multi-armed bandit, autoregressive time series
estimation, and active learning with exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Featurized Density Ratio Estimation. (arXiv:2107.02212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1">Kristy Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1">Madeline Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02212">
                                    <div class="article-summary-box-inner">
                                        <span>Density ratio estimation serves as an important technique in the unsupervised
machine learning toolbox. However, such ratios are difficult to estimate for
complex, high-dimensional data, particularly when the densities of interest are
sufficiently different. In our work, we propose to leverage an invertible
generative model to map the two distributions into a common feature space prior
to estimation. This featurization brings the densities closer together in
latent space, sidestepping pathological scenarios where the learned density
ratios in input space can be arbitrarily inaccurate. At the same time, the
invertibility of our feature map guarantees that the ratios computed in feature
space are equivalent to those in input space. Empirically, we demonstrate the
efficacy of our approach in a variety of downstream tasks that require access
to accurate density ratios such as mutual information estimation, targeted
sampling in deep generative models, and classification with data augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comparison of LSTM and GRU networks for learning symbolic sequences. (arXiv:2107.02248v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cahuantzi_R/0/1/0/all/0/1">Roberto Cahuantzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinye Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttel_S/0/1/0/all/0/1">Stefan G&#xfc;ttel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02248">
                                    <div class="article-summary-box-inner">
                                        <span>We explore relations between the hyper-parameters of a recurrent neural
network (RNN) and the complexity of string sequences it is able to memorize. We
compare long short-term memory (LSTM) networks and gated recurrent units
(GRUs). We find that an increase of RNN depth does not necessarily result in
better memorization capability when the training time is constrained. Our
results also indicate that the learning rate and the number of units per layer
are among the most important hyper-parameters to be tuned. Generally, GRUs
outperform LSTM networks on low complexity sequences while on high complexity
sequences LSTMs perform better.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dueling Bandits with Adversarial Sleeping. (arXiv:2107.02274v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1">Aadirupa Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaillard_P/0/1/0/all/0/1">Pierre Gaillard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02274">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the problem of sleeping dueling bandits with stochastic
preferences and adversarial availabilities (DB-SPAA). In almost all dueling
bandit applications, the decision space often changes over time; eg, retail
store management, online shopping, restaurant recommendation, search engine
optimization, etc. Surprisingly, this &#x60;sleeping aspect&#x27; of dueling bandits has
never been studied in the literature. Like dueling bandits, the goal is to
compete with the best arm by sequentially querying the preference feedback of
item pairs. The non-triviality however results due to the non-stationary item
spaces that allow any arbitrary subsets items to go unavailable every round.
The goal is to find an optimal &#x60;no-regret&#x27; policy that can identify the best
available item at each round, as opposed to the standard &#x60;fixed best-arm regret
objective&#x27; of dueling bandits. We first derive an instance-specific lower bound
for DB-SPAA $\Omega( \sum_{i &#x3D;1}^{K-1}\sum_{j&#x3D;i+1}^K \frac{\log
T}{\Delta(i,j)})$, where $K$ is the number of items and $\Delta(i,j)$ is the
gap between items $i$ and $j$. This indicates that the sleeping problem with
preference feedback is inherently more difficult than that for classical
multi-armed bandits (MAB). We then propose two algorithms, with near optimal
regret guarantees. Our results are corroborated empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-learning Amidst Heterogeneity and Ambiguity. (arXiv:2107.02228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Go_K/0/1/0/all/0/1">Kyeongryeol Go</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Seyoung Yun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02228">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning aims to learn a model that can handle multiple tasks generated
from an unknown but shared distribution. However, typical meta-learning
algorithms have assumed the tasks to be similar such that a single meta-learner
is sufficient to aggregate the variations in all aspects. In addition, there
has been less consideration on uncertainty when limited information is given as
context. In this paper, we devise a novel meta-learning framework, called
Meta-learning Amidst Heterogeneity and Ambiguity (MAHA), that outperforms
previous works in terms of prediction based on its ability on task
identification. By extensively conducting several experiments in regression and
classification, we demonstrate the validity of our model, which turns out to be
robust to both task heterogeneity and ambiguity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCEL0 for 2D Single Molecule Localization in Fluorescence Microscopy. (arXiv:2107.02281v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cascarano_P/0/1/0/all/0/1">Pasquale Cascarano</a>, <a href="http://arxiv.org/find/cs/1/au:+Comes_M/0/1/0/all/0/1">Maria Colomba Comes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_A/0/1/0/all/0/1">Andrea Sebastiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mencattini_A/0/1/0/all/0/1">Arianna Mencattini</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccolomini_E/0/1/0/all/0/1">Elena Loli Piccolomini</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinelli_E/0/1/0/all/0/1">Eugenio Martinelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02281">
                                    <div class="article-summary-box-inner">
                                        <span>In fluorescence microscopy, Single Molecule Localization Microscopy (SMLM)
techniques aim at localizing with high precision high density fluorescent
molecules by stochastically activating and imaging small subsets of blinking
emitters. Super Resolution (SR) plays an important role in this field since it
allows to go beyond the intrinsic light diffraction limit. In this work, we
propose a deep learning-based algorithm for precise molecule localization of
high density frames acquired by SMLM techniques whose $\ell_{2}$-based loss
function is regularized by positivity and $\ell_{0}$-based constraints. The
$\ell_{0}$ is relaxed through its Continuous Exact $\ell_{0}$ (CEL0)
counterpart. The arising approach, named DeepCEL0, is parameter-free, more
flexible, faster and provides more precise molecule localization maps if
compared to the other state-of-the-art methods. We validate our approach on
both simulated and real fluorescence microscopy data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Weak Supervision. (arXiv:2107.02233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cachay_S/0/1/0/all/0/1">Salva R&#xfc;hling Cachay</a>, <a href="http://arxiv.org/find/cs/1/au:+Boecking_B/0/1/0/all/0/1">Benedikt Boecking</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1">Artur Dubrawski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02233">
                                    <div class="article-summary-box-inner">
                                        <span>Aggregating multiple sources of weak supervision (WS) can ease the
data-labeling bottleneck prevalent in many machine learning applications, by
replacing the tedious manual collection of ground truth labels. Current state
of the art approaches that do not use any labeled training data, however,
require two separate modeling steps: Learning a probabilistic latent variable
model based on the WS sources -- making assumptions that rarely hold in
practice -- followed by downstream model training. Importantly, the first step
of modeling does not consider the performance of the downstream model. To
address these caveats we propose an end-to-end approach for directly learning
the downstream model by maximizing its agreement with probabilistic labels
generated by reparameterizing previous probabilistic posteriors with a neural
network. Our results show improved performance over prior work in terms of end
model performance on downstream test sets, as well as in terms of improved
robustness to dependencies among weak supervision sources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated age-related macular degeneration area estimation -- first results. (arXiv:2107.02211v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Peciulis_R/0/1/0/all/0/1">Rokas Pe&#x10d;iulis</a>, <a href="http://arxiv.org/find/eess/1/au:+Lukosevicius_M/0/1/0/all/0/1">Mantas Luko&#x161;evi&#x10d;ius</a>, <a href="http://arxiv.org/find/eess/1/au:+Krisciukaitis_A/0/1/0/all/0/1">Algimantas Kri&#x161;&#x10d;iukaitis</a>, <a href="http://arxiv.org/find/eess/1/au:+Petrolis_R/0/1/0/all/0/1">Robertas Petrolis</a>, <a href="http://arxiv.org/find/eess/1/au:+Buteikiene_D/0/1/0/all/0/1">Dovil&#x117; Buteikien&#x117;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02211">
                                    <div class="article-summary-box-inner">
                                        <span>This work aims to research an automatic method for detecting Age-related
Macular Degeneration (AMD) lesions in RGB eye fundus images. For this, we align
invasively obtained eye fundus contrast images (the &quot;golden standard&quot;
diagnostic) to the RGB ones and use them to hand-annotate the lesions. This is
done using our custom-made tool. Using the data, we train and test five
different convolutional neural networks: a custom one to classify healthy and
AMD-affected eye fundi, and four well-known networks: ResNet50, ResNet101,
MobileNetV3, and UNet to segment (localize) the AMD lesions in the affected eye
fundus images. We achieve 93.55% accuracy or 69.71% Dice index as the
preliminary best results in segmentation with MobileNetV3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoReD: Generalizing Fake Media Detection with Continual Representation using Distillation. (arXiv:2107.02408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02408">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, artificial intelligence research has made
tremendous strides, but it still heavily relies on fixed datasets in stationary
environments. Continual learning is a growing field of research that examines
how AI systems can learn sequentially from a continuous stream of linked data
in the same way that biological systems do. Simultaneously, fake media such as
deepfakes and synthetic face images have emerged as significant to current
multimedia technologies. Recently, numerous method has been proposed which can
detect deepfakes with high accuracy. However, they suffer significantly due to
their reliance on fixed datasets in limited evaluation settings. Therefore, in
this work, we apply continuous learning to neural networks&#x27; learning dynamics,
emphasizing its potential to increase data efficiency significantly. We propose
Continual Representation using Distillation (CoReD) method that employs the
concept of Continual Learning (CoL), Representation Learning (ReL), and
Knowledge Distillation (KD). We design CoReD to perform sequential domain
adaptation tasks on new deepfake and GAN-generated synthetic face datasets,
while effectively minimizing the catastrophic forgetting in a teacher-student
model setting. Our extensive experimental results demonstrate that our method
is efficient at domain adaptation to detect low-quality deepfakes videos and
GAN-generated images from several datasets, outperforming the-state-of-art
baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action Localization. (arXiv:2106.14118v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagchi_A/0/1/0/all/0/1">Anurag Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_J/0/1/0/all/0/1">Jazib Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_D/0/1/0/all/0/1">Dolton Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarvadevabhatla_R/0/1/0/all/0/1">Ravi Kiran Sarvadevabhatla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14118">
                                    <div class="article-summary-box-inner">
                                        <span>State of the art architectures for untrimmed video Temporal Action
Localization (TAL) have only considered RGB and Flow modalities, leaving the
information-rich audio modality totally unexploited. Audio fusion has been
explored for the related but arguably easier problem of trimmed (clip-level)
action recognition. However, TAL poses a unique set of challenges. In this
paper, we propose simple but effective fusion-based approaches for TAL. To the
best of our knowledge, our work is the first to jointly consider audio and
video modalities for supervised TAL. We experimentally show that our schemes
consistently improve performance for state of the art video-only TAL
approaches. Specifically, they help achieve new state of the art performance on
large-scale benchmark datasets - ActivityNet-1.3 (54.34 mAP@0.5) and THUMOS14
(57.18 mAP@0.5). Our experiments include ablations involving multiple fusion
schemes, modality combinations and TAL architectures. Our code, models and
associated data will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adversarial Training incorporating Forgery Attention for Image Forgery Localization. (arXiv:2107.02434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuo_L/0/1/0/all/0/1">Long Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02434">
                                    <div class="article-summary-box-inner">
                                        <span>Image editing techniques enable people to modify the content of an image
without leaving visual traces and thus may cause serious security risks. Hence
the detection and localization of these forgeries become quite necessary and
challenging. Furthermore, unlike other tasks with extensive data, there is
usually a lack of annotated forged images for training due to annotation
difficulties. In this paper, we propose a self-adversarial training strategy
and a reliable coarse-to-fine network that utilizes a self-attention mechanism
to localize forged regions in forgery images. The self-attention module is
based on a Channel-Wise High Pass Filter block (CW-HPF). CW-HPF leverages
inter-channel relationships of features and extracts noise features by high
pass filters. Based on the CW-HPF, a self-attention mechanism, called forgery
attention, is proposed to capture rich contextual dependencies of intrinsic
inconsistency extracted from tampered regions. Specifically, we append two
types of attention modules on top of CW-HPF respectively to model internal
interdependencies in spatial dimension and external dependencies among
channels. We exploit a coarse-to-fine network to enhance the noise
inconsistency between original and tampered regions. More importantly, to
address the issue of insufficient training data, we design a self-adversarial
training strategy that expands training data dynamically to achieve more robust
performance. Specifically, in each training iteration, we perform adversarial
attacks against our network to generate adversarial examples and train our
model on them. Extensive experimental results demonstrate that our proposed
algorithm steadily outperforms state-of-the-art methods by a clear margin in
different benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-06">2021-07-06</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polyphone Disambiguition in Mandarin Chinese with Semi-Supervised Learning. (arXiv:2102.00621v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Congyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00621">
                                    <div class="article-summary-box-inner">
                                        <span>The majority of Chinese characters are monophonic, while a special group of
characters, called polyphonic characters, have multiple pronunciations. As a
prerequisite of performing speech-related generative tasks, the correct
pronunciation must be identified among several candidates. This process is
called Polyphone Disambiguation. Although the problem has been well explored
with both knowledge-based and learning-based approaches, it remains challenging
due to the lack of publicly available labeled datasets and the irregular nature
of polyphone in Mandarin Chinese. In this paper, we propose a novel
semi-supervised learning (SSL) framework for Mandarin Chinese polyphone
disambiguation that can potentially leverage unlimited unlabeled text data. We
explore the effect of various proxy labeling strategies including
entropy-thresholding and lexicon-based labeling. Qualitative and quantitative
experiments demonstrate that our method achieves state-of-the-art performance.
In addition, we publish a novel dataset specifically for the polyphone
disambiguation task to promote further researches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Few-Shot Learning with Frozen Language Models. (arXiv:2106.13884v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsimpoukelli_M/0/1/0/all/0/1">Maria Tsimpoukelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1">Jacob Menick</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabi_S/0/1/0/all/0/1">Serkan Cabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1">S. M. Ali Eslami</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1">Oriol Vinyals</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13884">
                                    <div class="article-summary-box-inner">
                                        <span>When trained at sufficient scale, auto-regressive language models exhibit the
notable ability to learn a new language task after being prompted with just a
few examples. Here, we present a simple, yet effective, approach for
transferring this few-shot learning ability to a multimodal setting (vision and
language). Using aligned image and caption data, we train a vision encoder to
represent each image as a sequence of continuous embeddings, such that a
pre-trained, frozen language model prompted with this prefix generates the
appropriate caption. The resulting system is a multimodal few-shot learner,
with the surprising ability to learn a variety of new tasks when conditioned on
examples, represented as a sequence of multiple interleaved image and text
embeddings. We demonstrate that it can rapidly learn words for new objects and
novel visual categories, do visual question-answering with only a handful of
examples, and make use of outside knowledge, by measuring a single model on a
variety of established and new benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning. (arXiv:2005.08081v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fenglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xuancheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guangxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xu Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08081">
                                    <div class="article-summary-box-inner">
                                        <span>In sequence-to-sequence learning, the decoder relies on the attention
mechanism to efficiently extract information from the encoder. While it is
common practice to draw information from only the last encoder layer, recent
work has proposed to use representations from different encoder layers for
diversified levels of information. Nonetheless, the decoder still obtains only
a single view of the source sequences, which might lead to insufficient
training of the encoder layer stack due to the hierarchy bypassing problem. In
this work, we propose layer-wise cross-view decoding, where for each decoder
layer, together with the representations from the last encoder layer, which
serve as a global view, those from other encoder layers are supplemented for a
stereoscopic view of the source sequences. Systematic experiments show that we
successfully address the hierarchy bypassing problem and substantially improve
the performance of sequence-to-sequence learning with deep representations on
diverse tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thank you BART! Rewarding Pre-Trained Models Improves Formality Style Transfer. (arXiv:2105.06947v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lai_H/0/1/0/all/0/1">Huiyuan Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Toral_A/0/1/0/all/0/1">Antonio Toral</a>, <a href="http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1">Malvina Nissim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06947">
                                    <div class="article-summary-box-inner">
                                        <span>Scarcity of parallel data causes formality style transfer models to have
scarce success in preserving content. We show that fine-tuning pre-trained
language (GPT-2) and sequence-to-sequence (BART) models boosts content
preservation, and that this is possible even with limited amounts of parallel
data. Augmenting these models with rewards that target style and content -- the
two core aspects of the task -- we achieve a new state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Ackermannian lower bound for the Petri nets reachability problem. (arXiv:2105.08551v2 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lasota_S/0/1/0/all/0/1">S&#x142;awomir Lasota</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08551">
                                    <div class="article-summary-box-inner">
                                        <span>Petri nets, equivalently presentable as vector addition systems with states,
are an established model of concurrency with widespread applications. The
reachability problem, where we ask whether from a given initial configuration
there exists a sequence of valid execution steps reaching a given final
configuration, is the central algorithmic problem for this model. The
complexity of the problem has remained, until recently, one of the hardest open
questions in verification of concurrent systems. A first upper bound has been
provided only in 2015 by Leroux and Schmitz, then refined by the same authors
to non-primitive recursive Ackermannian upper bound in 2019. The exponential
space lower bound, shown by Lipton already in 1976, remained the only known for
over 40 years until a breakthrough non-elementary lower bound by
Czerwi{\&#x27;n}ski, Lasota, Lazic, Leroux and Mazowiecki in 2019. Finally, a
matching Ackermannian lower bound announced this year by Czerwi{\&#x27;n}ski and
Orlikowski, and independently by Leroux, established the complexity of the
problem.

Our contribution is an improvement of the former construction, making it
conceptually simpler and more direct. On the way we improve the lower bound for
vector addition systems with states in fixed dimension (or, equivalently, Petri
nets with fixed number of places): while Czerwi{\&#x27;n}ski and Orlikowski prove
$F_k$-hardness (hardness for $k$th level in Grzegorczyk Hierarchy) in dimension
$6k$, and Leroux in dimension $4k+5$, our simplified construction yields
$F_k$-hardness already in dimension $3k+2$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contradiction Detection in Persian Text. (arXiv:2107.01987v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahimi_Z/0/1/0/all/0/1">Zeinab Rahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+ShamsFard_M/0/1/0/all/0/1">Mehrnoush ShamsFard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01987">
                                    <div class="article-summary-box-inner">
                                        <span>Detection of semantic contradictory sentences is one of the most challenging
and fundamental issues for NLP applications such as recognition of textual
entailments. Contradiction in this study includes different types of semantic
confrontation, such as conflict and antonymy. Due to lack of sufficient data to
apply precise machine learning and specifically deep learning methods to
Persian and other low resource languages, rule-based approaches that can
function similarly to these systems will be of a great interest. Also recently,
emergence of new methods such as transfer learning, has opened up the
possibility of deep learning for low-resource languages. Considering two above
points, in this study, along with a simple rule-base baseline, a novel
rule-base system for identifying semantic contradiction along with a Bert base
deep contradiction detection system for Persian texts have been introduced. The
rule base system has used frequent rule mining method to extract appropriate
contradiction rules using a development set. Extracted rules are tested for
different categories of contradictory sentences. In this system the maximum
f-measure among contradiction categories is obtained for negation about 90% and
the average F-measure of system for all classes is about 76% which outperforms
other algorithms on Persian texts. On the other hand, because of medium
performance of rule base system for some categories of contradiction, we use a
Bert base deep learning system using our translated dataset; with average
F-measure of 73. Our hybrid system has f-measure of about 80.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MasakhaNER: Named Entity Recognition for African Languages. (arXiv:2103.11811v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1">David Ifeoluwa Adelani</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbott_J/0/1/0/all/0/1">Jade Abbott</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Dsouza_D/0/1/0/all/0/1">Daniel D&#x27;souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1">Julia Kreutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lignos_C/0/1/0/all/0/1">Constantine Lignos</a>, <a href="http://arxiv.org/find/cs/1/au:+Palen_Michel_C/0/1/0/all/0/1">Chester Palen-Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Buzaaba_H/0/1/0/all/0/1">Happy Buzaaba</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijhwani_S/0/1/0/all/0/1">Shruti Rijhwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayhew_S/0/1/0/all/0/1">Stephen Mayhew</a>, <a href="http://arxiv.org/find/cs/1/au:+Azime_I/0/1/0/all/0/1">Israel Abebe Azime</a>, <a href="http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1">Shamsuddeen Muhammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Emezue_C/0/1/0/all/0/1">Chris Chinenye Emezue</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakatumba_Nabende_J/0/1/0/all/0/1">Joyce Nakatumba-Nabende</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogayo_P/0/1/0/all/0/1">Perez Ogayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Aremu_A/0/1/0/all/0/1">Anuoluwapo Aremu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gitau_C/0/1/0/all/0/1">Catherine Gitau</a>, <a href="http://arxiv.org/find/cs/1/au:+Mbaye_D/0/1/0/all/0/1">Derguene Mbaye</a>, <a href="http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1">Jesujoba Alabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yimam_S/0/1/0/all/0/1">Seid Muhie Yimam</a>, <a href="http://arxiv.org/find/cs/1/au:+Gwadabe_T/0/1/0/all/0/1">Tajuddeen Gwadabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ezeani_I/0/1/0/all/0/1">Ignatius Ezeani</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyongabo_R/0/1/0/all/0/1">Rubungo Andre Niyongabo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukiibi_J/0/1/0/all/0/1">Jonathan Mukiibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Otiende_V/0/1/0/all/0/1">Verrah Otiende</a>, <a href="http://arxiv.org/find/cs/1/au:+Orife_I/0/1/0/all/0/1">Iroro Orife</a>, <a href="http://arxiv.org/find/cs/1/au:+David_D/0/1/0/all/0/1">Davis David</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngom_S/0/1/0/all/0/1">Samba Ngom</a>, <a href="http://arxiv.org/find/cs/1/au:+Adewumi_T/0/1/0/all/0/1">Tosin Adewumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rayson_P/0/1/0/all/0/1">Paul Rayson</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeyemi_M/0/1/0/all/0/1">Mofetoluwa Adeyemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Muriuki_G/0/1/0/all/0/1">Gerald Muriuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Anebi_E/0/1/0/all/0/1">Emmanuel Anebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chukwuneke_C/0/1/0/all/0/1">Chiamaka Chukwuneke</a>, <a href="http://arxiv.org/find/cs/1/au:+Odu_N/0/1/0/all/0/1">Nkiruka Odu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wairagala_E/0/1/0/all/0/1">Eric Peter Wairagala</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyerinde_S/0/1/0/all/0/1">Samuel Oyerinde</a>, <a href="http://arxiv.org/find/cs/1/au:+Siro_C/0/1/0/all/0/1">Clemencia Siro</a>, <a href="http://arxiv.org/find/cs/1/au:+Bateesa_T/0/1/0/all/0/1">Tobius Saul Bateesa</a>, <a href="http://arxiv.org/find/cs/1/au:+Oloyede_T/0/1/0/all/0/1">Temilola Oloyede</a>, <a href="http://arxiv.org/find/cs/1/au:+Wambui_Y/0/1/0/all/0/1">Yvonne Wambui</a>, <a href="http://arxiv.org/find/cs/1/au:+Akinode_V/0/1/0/all/0/1">Victor Akinode</a>, <a href="http://arxiv.org/find/cs/1/au:+Nabagereka_D/0/1/0/all/0/1">Deborah Nabagereka</a>, <a href="http://arxiv.org/find/cs/1/au:+Katusiime_M/0/1/0/all/0/1">Maurice Katusiime</a>, <a href="http://arxiv.org/find/cs/1/au:+Awokoya_A/0/1/0/all/0/1">Ayodele Awokoya</a>, et al. (15 additional authors not shown)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11811">
                                    <div class="article-summary-box-inner">
                                        <span>We take a step towards addressing the under-representation of the African
continent in NLP research by creating the first large publicly available
high-quality dataset for named entity recognition (NER) in ten African
languages, bringing together a variety of stakeholders. We detail
characteristics of the languages to help researchers understand the challenges
that these languages pose for NER. We analyze our datasets and conduct an
extensive empirical evaluation of state-of-the-art methods across both
supervised and transfer learning settings. We release the data, code, and
models in order to inspire future research on African NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark. (arXiv:2106.08087v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mosha Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chuanqi Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1">Zhen Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaozhuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1">Xin Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kangping Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chuanqi Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mosha Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1">Luo Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1">Yuan Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_G/0/1/0/all/0/1">Guotong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1">Zhifang Sui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_H/0/1/0/all/0/1">Hui Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zheng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linfeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zan_H/0/1/0/all/0/1">Hongying Zan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kunli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1">Buzhou Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingcai Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08087">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial Intelligence (AI), along with the recent progress in biomedical
language understanding, is gradually changing medical practice. With the
development of biomedical language understanding benchmarks, AI applications
are widely used in the medical field. However, most benchmarks are limited to
English, which makes it challenging to replicate many of the successes in
English for other languages. To facilitate research in this direction, we
collect real-world biomedical data and present the first Chinese Biomedical
Language Understanding Evaluation (CBLUE) benchmark: a collection of natural
language understanding tasks including named entity recognition, information
extraction, clinical diagnosis normalization, single-sentence/sentence-pair
classification, and an associated online platform for model evaluation,
comparison, and analysis. To establish evaluation on these tasks, we report
empirical results with the current 11 pre-trained Chinese models, and
experimental results show that state-of-the-art neural models perform by far
worse than the human ceiling. Our benchmark is released at
\url{https://tianchi.aliyun.com/dataset/dataDetail?dataId&#x3D;95414&amp;lang&#x3D;en-us}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech SIMCLR: Combining Contrastive and Reconstruction Objective for Self-supervised Speech Representation Learning. (arXiv:2010.13991v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Dongwei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wubo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Miao Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1">Wei Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiangang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13991">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised visual pretraining has shown significant progress recently.
Among those methods, SimCLR greatly advanced the state of the art in
self-supervised and semi-supervised learning on ImageNet. The input feature
representations for speech and visual tasks are both continuous, so it is
natural to consider applying similar objective on speech representation
learning. In this paper, we propose Speech SimCLR, a new self-supervised
objective for speech representation learning. During training, Speech SimCLR
applies augmentation on raw speech and its spectrogram. Its objective is the
combination of contrastive loss that maximizes agreement between differently
augmented samples in the latent space and reconstruction loss of input
representation. The proposed method achieved competitive results on speech
emotion recognition and speech recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knodle: Modular Weakly Supervised Learning with PyTorch. (arXiv:2104.11557v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sedova_A/0/1/0/all/0/1">Anastasiia Sedova</a>, <a href="http://arxiv.org/find/cs/1/au:+Stephan_A/0/1/0/all/0/1">Andreas Stephan</a>, <a href="http://arxiv.org/find/cs/1/au:+Speranskaya_M/0/1/0/all/0/1">Marina Speranskaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11557">
                                    <div class="article-summary-box-inner">
                                        <span>Strategies for improving the training and prediction quality of weakly
supervised machine learning models vary in how much they are tailored to a
specific task or integrated with a specific model architecture. In this work,
we introduce Knodle, a software framework that treats weak data annotations,
deep learning models, and methods for improving weakly supervised training as
separate, modular components. This modularization gives the training process
access to fine-grained information such as data set characteristics, matches of
heuristic rules, or elements of the deep learning model ultimately used for
prediction. Hence, our framework can encompass a wide range of training methods
for improving weak supervision, ranging from methods that only look at
correlations of rules and output classes (independently of the machine learning
model trained with the resulting labels), to those that harness the interplay
of neural networks and weakly labeled data. We illustrate the benchmarking
potential of the framework with a performance comparison of several reference
implementations on a selection of datasets that are already available in
Knodle.

The framework is published as an open-source Python package knodle and
available at https://github.com/knodle/knodle.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Fluent Query Reformulations with Text-to-Text Transformers and Reinforcement Learning. (arXiv:2012.10033v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jerry Zikun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoran Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10033">
                                    <div class="article-summary-box-inner">
                                        <span>Query reformulation aims to alter noisy or ambiguous text sequences into
coherent ones closer to natural language questions. This is to prevent errors
from propagating in a client-facing pipeline and promote better communication
with users. Besides, it is crucial to maintain performance in downstream
environments like question answering when rephrased queries are given as input.
We show that under the previous framework (AQA), attempts to alter RL
algorithms do not bring significant benefits to either reward acquisition or
sequence fluency. Instead, we leverage a query-reformulating text-to-text
transformer (QRT5) and apply policy-based RL algorithms to further nudge this
reformulator and obtain better answers downstream by generating
reward-acquiring query trajectories. QRT5 shows better sample efficiency in RL
to achieve the same level of QA performance as the previous approach. It can
generate reformulations with more readability based on query well-formedness
evaluations and can generalize to out-of-sample data. Our framework is
demonstrated to be flexible, allowing reward signals to be sourced from
different downstream environments such as intent classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1">Patrick Lumban Tobing</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1">Tomoki Toda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09858">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a low-latency real-time (LLRT) non-parallel voice
conversion (VC) framework based on cyclic variational autoencoder (CycleVAE)
and multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a
robust non-parallel multispeaker spectral model, which utilizes a
speaker-independent latent space and a speaker-dependent code to generate
reconstructed/converted spectral features given the spectral features of an
input speaker. On the other hand, MWDLP is an efficient and a high-quality
neural vocoder that can handle multispeaker data and generate speech waveform
for LLRT applications with CPU. To accommodate LLRT constraint with CPU, we
propose a novel CycleVAE framework that utilizes mel-spectrogram as spectral
features and is built with a sparse network architecture. Further, to improve
the modeling performance, we also propose a novel fine-tuning procedure that
refines the frame-rate CycleVAE network by utilizing the waveform loss from the
MWDLP network. The experimental results demonstrate that the proposed framework
achieves high-performance VC, while allowing for LLRT usage with a single-core
of $2.1$--$2.7$ GHz CPU on a real-time factor of $0.87$--$0.95$, including
input/output, feature extraction, on a frame shift of $10$ ms, a window length
of $27.5$ ms, and $2$ lookup frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SASICM A Multi-Task Benchmark For Subtext Recognition. (arXiv:2106.06944v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hua Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_F/0/1/0/all/0/1">Feng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+An_J/0/1/0/all/0/1">Junyi An</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Weikang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1">Furao Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06944">
                                    <div class="article-summary-box-inner">
                                        <span>Subtext is a kind of deep semantics which can be acquired after one or more
rounds of expression transformation. As a popular way of expressing one&#x27;s
intentions, it is well worth studying. In this paper, we try to make computers
understand whether there is a subtext by means of machine learning. We build a
Chinese dataset whose source data comes from the popular social media (e.g.
Weibo, Netease Music, Zhihu, and Bilibili). In addition, we also build a
baseline model called SASICM to deal with subtext recognition. The F1 score of
SASICMg, whose pretrained model is GloVe, is as high as 64.37%, which is 3.97%
higher than that of BERT based model, 12.7% higher than that of traditional
methods on average, including support vector machine, logistic regression
classifier, maximum entropy classifier, naive bayes classifier and decision
tree and 2.39% higher than that of the state-of-the-art, including MARIN and
BTM. The F1 score of SASICMBERT, whose pretrained model is BERT, is 65.12%,
which is 0.75% higher than that of SASICMg. The accuracy rates of SASICMg and
SASICMBERT are 71.16% and 70.76%, respectively, which can compete with those of
other methods which are mentioned before.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Re-Evaluating GermEval17 Using German Pre-Trained Language Models. (arXiv:2102.12330v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1">M. A&#xdf;enmacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Corvonato_A/0/1/0/all/0/1">A. Corvonato</a>, <a href="http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1">C. Heumann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12330">
                                    <div class="article-summary-box-inner">
                                        <span>The lack of a commonly used benchmark data set (collection) such as
(Super-)GLUE (Wang et al., 2018, 2019) for the evaluation of non-English
pre-trained language models is a severe shortcoming of current English-centric
NLP-research. It concentrates a large part of the research on English,
neglecting the uncertainty when transferring conclusions found for the English
language to other languages. We evaluate the performance of the German and
multilingual BERT-based models currently available via the huggingface
transformers library on the four tasks of the GermEval17 workshop. We compare
them to pre-BERT architectures (Wojatzki et al., 2017; Schmitt et al., 2018;
Attia et al., 2018) as well as to an ELMo-based architecture (Biesialska et
al., 2020) and a BERT-based approach (Guhr et al., 2020). The observed
improvements are put in relation to those for similar tasks and similar models
(pre-BERT vs. BERT-based) for the English language in order to draw tentative
conclusions about whether the observed improvements are transferable to German
or potentially other related languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1">Patrick Lumban Tobing</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1">Tomoki Toda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09856">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel high-fidelity and low-latency universal neural
vocoder framework based on multiband WaveRNN with data-driven linear prediction
for discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN
architecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit
with a relatively large size of hidden units is utilized, while the multiband
modeling is deployed to achieve real-time low-latency usage. A novel technique
for data-driven linear prediction (LP) with discrete waveform modeling is
proposed, where the LP coefficients are estimated in a data-driven manner.
Moreover, a novel loss function using short-time Fourier transform (STFT) for
discrete waveform modeling with Gumbel approximation is also proposed. The
experimental results demonstrate that the proposed MWDLP framework generates
high-fidelity synthetic speech for seen and unseen speakers and/or language on
300 speakers training data including clean and noisy/reverberant conditions,
where the number of training utterances is limited to 60 per speaker, while
allowing for real-time low-latency processing using a single core of $\sim\!$
2.1--2.7 GHz CPU with $\sim\!$ 0.57--0.64 real-time factor including
input/output and feature extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The DCU-EPFL Enhanced Dependency Parser at the IWPT 2021 Shared Task. (arXiv:2107.01982v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barry_J/0/1/0/all/0/1">James Barry</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadshahi_A/0/1/0/all/0/1">Alireza Mohammadshahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_J/0/1/0/all/0/1">Joachim Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_J/0/1/0/all/0/1">Jennifer Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1">James Henderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01982">
                                    <div class="article-summary-box-inner">
                                        <span>We describe the DCU-EPFL submission to the IWPT 2021 Shared Task on Parsing
into Enhanced Universal Dependencies. The task involves parsing Enhanced UD
graphs, which are an extension of the basic dependency trees designed to be
more facilitative towards representing semantic structure. Evaluation is
carried out on 29 treebanks in 17 languages and participants are required to
parse the data from each language starting from raw strings. Our approach uses
the Stanza pipeline to preprocess the text files, XLMRoBERTa to obtain
contextualized token representations, and an edge-scoring and labeling model to
predict the enhanced graph. Finally, we run a post-processing script to ensure
all of our outputs are valid Enhanced UD graphs. Our system places 6th out of 9
participants with a coarse Enhanced Labeled Attachment Score (ELAS) of 83.57.
We carry out additional post-deadline experiments which include using Trankit
for pre-processing, XLM-RoBERTa-LARGE, treebank concatenation, and multitask
learning between a basic and an enhanced dependency parser. All of these
modifications improve our initial score and our final system has a coarse ELAS
of 88.04.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RiddleSense: Reasoning about Riddle Questions Featuring Linguistic Creativity and Commonsense Knowledge. (arXiv:2101.00376v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bill Yuchen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yichi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dong-Ho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00376">
                                    <div class="article-summary-box-inner">
                                        <span>Question: I have five fingers but I am not alive. What am I? Answer: a glove.
Answering such a riddle-style question is a challenging cognitive process, in
that it requires complex commonsense reasoning abilities, an understanding of
figurative language, and counterfactual reasoning skills, which are all
important abilities for advanced natural language understanding (NLU). However,
there are currently no dedicated datasets aiming to test these abilities.
Herein, we present RiddleSense, a new multiple-choice question answering task,
which comes with the first large dataset (5.7k examples) for answering
riddle-style commonsense questions. We systematically evaluate a wide range of
models over the challenge, and point out that there is a large gap between the
best-supervised model and human performance -- suggesting intriguing future
research in the direction of higher-order commonsense reasoning and linguistic
creativity towards building advanced NLU systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vietnamese Complaint Detection on E-Commerce Websites. (arXiv:2104.11969v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Nhung Thi-Hong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_P/0/1/0/all/0/1">Phuong Phan-Dieu Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1">Luan Thanh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11969">
                                    <div class="article-summary-box-inner">
                                        <span>Customer product reviews play a role in improving the quality of products and
services for business organizations or their brands. Complaining is an attitude
that expresses dissatisfaction with an event or a product not meeting customer
expectations. In this paper, we build a Open-domain Complaint Detection dataset
(UIT-ViOCD), including 5,485 human-annotated reviews on four categories about
product reviews on e-commerce sites. After the data collection phase, we
proceed to the annotation task and achieve the inter-annotator agreement Am of
87%. Then, we present an extensive methodology for the research purposes and
achieve 92.16% by F1-score for identifying complaints. With the results, in the
future, we aim to build a system for open-domain complaint detection in
E-commerce websites.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling. (arXiv:2107.01875v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1">Lanqing Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kaitao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Duocai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Nevin L. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01875">
                                    <div class="article-summary-box-inner">
                                        <span>Rap generation, which aims to produce lyrics and corresponding singing beats,
needs to model both rhymes and rhythms. Previous works for rap generation
focused on rhyming lyrics but ignored rhythmic beats, which are important for
rap performance. In this paper, we develop DeepRapper, a Transformer-based rap
generation system that can model both rhymes and rhythms. Since there is no
available rap dataset with rhythmic beats, we develop a data mining pipeline to
collect a large-scale rap dataset, which includes a large number of rap songs
with aligned lyrics and rhythmic beats. Second, we design a Transformer-based
autoregressive language model which carefully models rhymes and rhythms.
Specifically, we generate lyrics in the reverse order with rhyme representation
and constraint for rhyme enhancement and insert a beat symbol into lyrics for
rhythm/beat modeling. To our knowledge, DeepRapper is the first system to
generate rap with both rhymes and rhythms. Both objective and subjective
evaluations demonstrate that DeepRapper generates creative and high-quality
raps with rhymes and rhythms. Code will be released on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation for Sentiment Analysis Using Increased Intraclass Separation. (arXiv:2107.01598v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rostami_M/0/1/0/all/0/1">Mohammad Rostami</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01598">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis is a costly yet necessary task for enterprises to study
the opinions of their customers to improve their products and to determine
optimal marketing strategies. Due to the existence of a wide range of domains
across different products and services, cross-domain sentiment analysis methods
have received significant attention. These methods mitigate the domain gap
between different applications by training cross-domain generalizable
classifiers which help to relax the need for data annotation for each domain.
Most existing methods focus on learning domain-agnostic representations that
are invariant with respect to both the source and the target domains. As a
result, a classifier that is trained using the source domain annotated data
would generalize well in a related target domain. We introduce a new domain
adaptation method which induces large margins between different classes in an
embedding space. This embedding space is trained to be domain-agnostic by
matching the data distributions across the domains. Large intraclass margins in
the source domain help to reduce the effect of &quot;domain shift&quot; on the classifier
performance in the target domain. Theoretical and empirical analysis are
provided to demonstrate that the proposed method is effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiERU: Bidirectional Emotional Recurrent Unit for Conversational Sentiment Analysis. (arXiv:2006.00492v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shaoxiong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.00492">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis in conversations has gained increasing attention in recent
years for the growing amount of applications it can serve, e.g., sentiment
analysis, recommender systems, and human-robot interaction. The main difference
between conversational sentiment analysis and single sentence sentiment
analysis is the existence of context information which may influence the
sentiment of an utterance in a dialogue. How to effectively encode contextual
information in dialogues, however, remains a challenge. Existing approaches
employ complicated deep learning structures to distinguish different parties in
a conversation and then model the context information. In this paper, we
propose a fast, compact and parameter-efficient party-ignorant framework named
bidirectional emotional recurrent unit for conversational sentiment analysis.
In our system, a generalized neural tensor block followed by a two-channel
classifier is designed to perform context compositionality and sentiment
classification, respectively. Extensive experiments on three standard datasets
demonstrate that our model outperforms the state of the art in most cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Data Augmentation Approaches for NLP. (arXiv:2105.03075v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Steven Y. Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1">Soroush Vosoughi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1">Teruko Mitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03075">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation has recently seen increased interest in NLP due to more
work in low-resource domains, new tasks, and the popularity of large-scale
neural networks that require large amounts of training data. Despite this
recent upsurge, this area is still relatively underexplored, perhaps due to the
challenges posed by the discrete nature of language data. In this paper, we
present a comprehensive and unifying survey of data augmentation for NLP by
summarizing the literature in a structured manner. We first introduce and
motivate data augmentation for NLP, and then discuss major methodologically
representative approaches. Next, we highlight techniques that are used for
popular NLP applications and tasks. We conclude by outlining current challenges
and directions for future research. Overall, our paper aims to clarify the
landscape of existing literature in data augmentation for NLP and motivate
additional work in this area. We also present a GitHub repository with a paper
list that will be continuously updated at
https://github.com/styfeng/DataAug4NLP</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Doing Good or Doing Right? Exploring the Weakness of Commonsense Causal Reasoning Models. (arXiv:2107.01791v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1">Mingyue Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yinglin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01791">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained language models (PLM) achieve surprising performance on the Choice
of Plausible Alternatives (COPA) task. However, whether PLMs have truly
acquired the ability of causal reasoning remains a question. In this paper, we
investigate the problem of semantic similarity bias and reveal the
vulnerability of current COPA models by certain attacks. Previous solutions
that tackle the superficial cues of unbalanced token distribution still
encounter the same problem of semantic bias, even more seriously due to the
utilization of more training data. We mitigate this problem by simply adding a
regularization loss and experimental results show that this solution not only
improves the model&#x27;s generalization ability, but also assists the models to
perform more robustly on a challenging dataset, BCOPA-CE, which has unbiased
token distribution and is more difficult for models to distinguish cause and
effect.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FFCI: A Framework for Interpretable Automatic Evaluation of Summarization. (arXiv:2011.13662v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1">Fajri Koto</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1">Timothy Baldwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lau_J/0/1/0/all/0/1">Jey Han Lau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13662">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose FFCI, a framework for fine-grained summarization
evaluation that comprises four elements: faithfulness (degree of factual
consistency with the source), focus (precision of summary content relative to
the reference), coverage (recall of summary content relative to the reference),
and inter-sentential coherence (document fluency between adjacent sentences).
We construct a novel dataset for focus, coverage, and inter-sentential
coherence, and develop automatic methods for evaluating each of the four
dimensions of FFCI based on cross-comparison of evaluation metrics and
model-based evaluation methods, including question answering (QA) approaches,
STS, next-sentence prediction (NSP), and scores derived from 19 pre-trained
language models. We then apply the developed metrics in evaluating a broad
range of summarization models across two datasets, with some surprising
findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR. (arXiv:2105.14779v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussein_A/0/1/0/all/0/1">Amir Hussein</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelali_A/0/1/0/all/0/1">Ahmed Abdelali</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14779">
                                    <div class="article-summary-box-inner">
                                        <span>With the advent of globalization, there is an increasing demand for
multilingual automatic speech recognition (ASR), handling language and
dialectal variation of spoken content. Recent studies show its efficacy over
monolingual systems. In this study, we design a large multilingual end-to-end
ASR using self-attention based conformer architecture. We trained the system
using Arabic (Ar), English (En) and French (Fr) languages. We evaluate the
system performance handling: (i) monolingual (Ar, En and Fr); (ii)
multi-dialectal (Modern Standard Arabic, along with dialectal variation such as
Egyptian and Moroccan); (iii) code-switching -- cross-lingual (Ar-En/Fr) and
dialectal (MSA-Egyptian dialect) test cases, and compare with current
state-of-the-art systems. Furthermore, we investigate the influence of
different embedding/character representations including character vs
word-piece; shared vs distinct input symbol per language. Our findings
demonstrate the strength of such a model by outperforming state-of-the-art
monolingual dialectal Arabic and code-switching Arabic ASR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Interpretation of Softmax Cross-Entropy and Negative Sampling: With Case Study for Knowledge Graph Embedding. (arXiv:2106.07250v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamigaito_H/0/1/0/all/0/1">Hidetaka Kamigaito</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1">Katsuhiko Hayashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07250">
                                    <div class="article-summary-box-inner">
                                        <span>In knowledge graph embedding, the theoretical relationship between the
softmax cross-entropy and negative sampling loss functions has not been
investigated. This makes it difficult to fairly compare the results of the two
different loss functions. We attempted to solve this problem by using the
Bregman divergence to provide a unified interpretation of the softmax
cross-entropy and negative sampling loss functions. Under this interpretation,
we can derive theoretical findings for fair comparison. Experimental results on
the FB15k-237 and WN18RR datasets show that the theoretical findings are valid
in practical settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Neural Coreference Resolution Revisited: A Simple yet Effective Baseline. (arXiv:2107.01700v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1">Tuan Manh Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Trung Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Doo Soon Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01700">
                                    <div class="article-summary-box-inner">
                                        <span>Since the first end-to-end neural coreference resolution model was
introduced, many extensions to the model have been proposed, ranging from using
higher-order inference to directly optimizing evaluation metrics using
reinforcement learning. Despite improving the coreference resolution
performance by a large margin, these extensions add a lot of extra complexity
to the original model. Motivated by this observation and the recent advances in
pre-trained Transformer language models, we propose a simple yet effective
baseline for coreference resolution. Our model is a simplified version of the
original neural coreference resolution model, however, it achieves impressive
performance, outperforming all recent extended works on the public English
OntoNotes benchmark. Our work provides evidence for the necessity of carefully
justifying the complexity of existing or newly proposed models, as introducing
a conceptual or practical simplification to an existing model can still yield
competitive results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal Transformer-Based Neural Correction Models for Automatic Speech Recognition. (arXiv:2107.01569v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1">Tomohiro Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Masumura_R/0/1/0/all/0/1">Ryo Masumura</a>, <a href="http://arxiv.org/find/cs/1/au:+Ihori_M/0/1/0/all/0/1">Mana Ihori</a>, <a href="http://arxiv.org/find/cs/1/au:+Takashima_A/0/1/0/all/0/1">Akihiko Takashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Moriya_T/0/1/0/all/0/1">Takafumi Moriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashihara_T/0/1/0/all/0/1">Takanori Ashihara</a>, <a href="http://arxiv.org/find/cs/1/au:+Orihashi_S/0/1/0/all/0/1">Shota Orihashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Makishima_N/0/1/0/all/0/1">Naoki Makishima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01569">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a cross-modal transformer-based neural correction models that
refines the output of an automatic speech recognition (ASR) system so as to
exclude ASR errors. Generally, neural correction models are composed of
encoder-decoder networks, which can directly model sequence-to-sequence mapping
problems. The most successful method is to use both input speech and its ASR
output text as the input contexts for the encoder-decoder networks. However,
the conventional method cannot take into account the relationships between
these two different modal inputs because the input contexts are separately
encoded for each modal. To effectively leverage the correlated information
between the two different modal inputs, our proposed models encode two
different contexts jointly on the basis of cross-modal self-attention using a
transformer. We expect that cross-modal self-attention can effectively capture
the relationships between two different modals for refining ASR hypotheses. We
also introduce a shallow fusion technique to efficiently integrate the
first-pass ASR model and our proposed neural correction model. Experiments on
Japanese natural language ASR tasks demonstrated that our proposed models
achieve better ASR performance than conventional neural correction models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Neural Diarization for Unlimited Numbers of Speakers Using Global and Local Attractors. (arXiv:2107.01545v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Horiguchi_S/0/1/0/all/0/1">Shota Horiguchi</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/eess/1/au:+Garcia_P/0/1/0/all/0/1">Paola Garcia</a>, <a href="http://arxiv.org/find/eess/1/au:+Xue_Y/0/1/0/all/0/1">Yawen Xue</a>, <a href="http://arxiv.org/find/eess/1/au:+Takashima_Y/0/1/0/all/0/1">Yuki Takashima</a>, <a href="http://arxiv.org/find/eess/1/au:+Kawaguchi_Y/0/1/0/all/0/1">Yohei Kawaguchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01545">
                                    <div class="article-summary-box-inner">
                                        <span>Attractor-based end-to-end diarization is achieving comparable accuracy to
the carefully tuned conventional clustering-based methods on challenging
datasets. However, the main drawback is that it cannot deal with the case where
the number of speakers is larger than the one observed during training. This is
because its speaker counting relies on supervised learning. In this work, we
introduce an unsupervised clustering process embedded in the attractor-based
end-to-end diarization. We first split a sequence of frame-wise embeddings into
short subsequences and then perform attractor-based diarization for each
subsequence. Given subsequence-wise diarization results, inter-subsequence
speaker correspondence is obtained by unsupervised clustering of the vectors
computed from the attractors from all the subsequences. This makes it possible
to produce diarization results of a large number of speakers for the whole
recording even if the number of output speakers for each subsequence is
limited. Experimental results showed that our method could produce accurate
diarization results of an unseen number of speakers. Our method achieved 11.84
%, 28.33 %, and 19.49 % on the CALLHOME, DIHARD II, and DIHARD III datasets,
respectively, each of which is better than the conventional end-to-end
diarization methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Knowledge-Enhanced Text Generation. (arXiv:2010.04389v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wenhao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenguang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zaitang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiting Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04389">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of text generation is to make machines express in human language. It
is one of the most important yet challenging tasks in natural language
processing (NLP). Since 2014, various neural encoder-decoder models pioneered
by Seq2Seq have been proposed to achieve the goal by learning to map input text
to output text. However, the input text alone often provides limited knowledge
to generate the desired output, so the performance of text generation is still
far from satisfaction in many real-world scenarios. To address this issue,
researchers have considered incorporating various forms of knowledge beyond the
input text into the generation models. This research direction is known as
knowledge-enhanced text generation. In this survey, we present a comprehensive
review of the research on knowledge enhanced text generation over the past five
years. The main content includes two parts: (i) general methods and
architectures for integrating knowledge into text generation; (ii) specific
techniques and applications according to different forms of knowledge data.
This survey can have broad audiences, researchers and practitioners, in
academia and industry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CasEE: A Joint Learning Framework with Cascade Decoding for Overlapping Event Extraction. (arXiv:2107.01583v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_J/0/1/0/all/0/1">Jiawei Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bowen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hei_Y/0/1/0/all/0/1">Yiming Hei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lihong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tingwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hongbo Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01583">
                                    <div class="article-summary-box-inner">
                                        <span>Event extraction (EE) is a crucial information extraction task that aims to
extract event information in texts. Most existing methods assume that events
appear in sentences without overlaps, which are not applicable to the
complicated overlapping event extraction. This work systematically studies the
realistic event overlapping problem, where a word may serve as triggers with
several types or arguments with different roles. To tackle the above problem,
we propose a novel joint learning framework with cascade decoding for
overlapping event extraction, termed as CasEE. Particularly, CasEE sequentially
performs type detection, trigger extraction and argument extraction, where the
overlapped targets are extracted separately conditioned on the specific former
prediction. All the subtasks are jointly learned in a framework to capture
dependencies among the subtasks. The evaluation on a public event extraction
benchmark FewFC demonstrates that CasEE achieves significant improvements on
overlapping event extraction over previous competitive methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IITP at WAT 2021: System description for English-Hindi Multimodal Translation Task. (arXiv:2107.01656v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gain_B/0/1/0/all/0/1">Baban Gain</a>, <a href="http://arxiv.org/find/cs/1/au:+Bandyopadhyay_D/0/1/0/all/0/1">Dibyanayan Bandyopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Ekbal_A/0/1/0/all/0/1">Asif Ekbal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01656">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Machine Translation (NMT) is a predominant machine translation
technology nowadays because of its end-to-end trainable flexibility. However,
NMT still struggles to translate properly in low-resource settings specifically
on distant language pairs. One way to overcome this is to use the information
from other modalities if available. The idea is that despite differences in
languages, both the source and target language speakers see the same thing and
the visual representation of both the source and target is the same, which can
positively assist the system. Multimodal information can help the NMT system to
improve the translation by removing ambiguity on some phrases or words. We
participate in the 8th Workshop on Asian Translation (WAT - 2021) for
English-Hindi multimodal translation task and achieve 42.47 and 37.50 BLEU
points for Evaluation and Challenge subset, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Careful: Seeking Semantic-related Knowledge for Open-domain Commonsense Question Answering. (arXiv:2107.01592v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1">Luxi Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yue Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuqiang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01592">
                                    <div class="article-summary-box-inner">
                                        <span>It is prevalent to utilize external knowledge to help machine answer
questions that need background commonsense, which faces a problem that
unlimited knowledge will transmit noisy and misleading information. Towards the
issue of introducing related knowledge, we propose a semantic-driven
knowledge-aware QA framework, which controls the knowledge injection in a
coarse-to-careful fashion. We devise a tailoring strategy to filter extracted
knowledge under monitoring of the coarse semantic of question on the knowledge
extraction stage. And we develop a semantic-aware knowledge fetching module
that engages structural knowledge information and fuses proper knowledge
according to the careful semantic of questions in a hierarchical way.
Experiments demonstrate that the proposed approach promotes the performance on
the CommonsenseQA dataset comparing with strong baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Autoregressive Modeling for Joint End-to-End Multi-Talker Overlapped Speech Recognition and Speaker Attribute Estimation. (arXiv:2107.01549v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Masumura_R/0/1/0/all/0/1">Ryo Masumura</a>, <a href="http://arxiv.org/find/cs/1/au:+Okamura_D/0/1/0/all/0/1">Daiki Okamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Makishima_N/0/1/0/all/0/1">Naoki Makishima</a>, <a href="http://arxiv.org/find/cs/1/au:+Ihori_M/0/1/0/all/0/1">Mana Ihori</a>, <a href="http://arxiv.org/find/cs/1/au:+Takashima_A/0/1/0/all/0/1">Akihiko Takashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1">Tomohiro Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Orihashi_S/0/1/0/all/0/1">Shota Orihashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01549">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a novel modeling method for single-channel
multi-talker overlapped automatic speech recognition (ASR) systems. Fully
neural network based end-to-end models have dramatically improved the
performance of multi-taker overlapped ASR tasks. One promising approach for
end-to-end modeling is autoregressive modeling with serialized output training
in which transcriptions of multiple speakers are recursively generated one
after another. This enables us to naturally capture relationships between
speakers. However, the conventional modeling method cannot explicitly take into
account the speaker attributes of individual utterances such as gender and age
information. In fact, the performance deteriorates when each speaker is the
same gender or is close in age. To address this problem, we propose unified
autoregressive modeling for joint end-to-end multi-talker overlapped ASR and
speaker attribute estimation. Our key idea is to handle gender and age
estimation tasks within the unified autoregressive modeling. In the proposed
method, transformer-based autoregressive model recursively generates not only
textual tokens but also attribute tokens of each speaker. This enables us to
effectively utilize speaker attributes for improving multi-talker overlapped
ASR. Experiments on Japanese multi-talker overlapped ASR tasks demonstrate the
effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-Oriented Multimodal Machine Comprehension: Task, Dataset and Model. (arXiv:2107.01571v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiqi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fenglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1">Shen Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Helin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1">Wei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01571">
                                    <div class="article-summary-box-inner">
                                        <span>While Machine Comprehension (MC) has attracted extensive research interests
in recent years, existing approaches mainly belong to the category of Machine
Reading Comprehension task which mines textual inputs (paragraphs and
questions) to predict the answers (choices or text spans). However, there are a
lot of MC tasks that accept audio input in addition to the textual input, e.g.
English listening comprehension test. In this paper, we target the problem of
Audio-Oriented Multimodal Machine Comprehension, and its goal is to answer
questions based on the given audio and textual information. To solve this
problem, we propose a Dynamic Inter- and Intra-modality Attention (DIIA) model
to effectively fuse the two modalities (audio and textual). DIIA can work as an
independent component and thus be easily integrated into existing MC models.
Moreover, we further develop a Multimodal Knowledge Distillation (MKD) module
to enable our multimodal MC model to accurately predict the answers based only
on either the text or the audio. As a result, the proposed approach can handle
various tasks including: Audio-Oriented Multimodal Machine Comprehension,
Machine Reading Comprehension and Machine Listening Comprehension, in a single
model, making fair comparisons possible between our model and the existing
unimodal MC models. Experimental results and analysis prove the effectiveness
of the proposed approaches. First, the proposed DIIA boosts the baseline models
by up to 21.08% in terms of accuracy; Second, under the unimodal scenarios, the
MKD module allows our multimodal MC model to significantly outperform the
unimodal models by up to 18.87%, which are trained and tested with only audio
or textual data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relaxed Attention: A Simple Method to Boost Performance of End-to-End Automatic Speech Recognition. (arXiv:2107.01275v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lohrenz_T/0/1/0/all/0/1">Timo Lohrenz</a>, <a href="http://arxiv.org/find/eess/1/au:+Schwarz_P/0/1/0/all/0/1">Patrick Schwarz</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1">Zhengyang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Fingscheidt_T/0/1/0/all/0/1">Tim Fingscheidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01275">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, attention-based encoder-decoder (AED) models have shown high
performance for end-to-end automatic speech recognition (ASR) across several
tasks. Addressing overconfidence in such models, in this paper we introduce the
concept of relaxed attention, which is a simple gradual injection of a uniform
distribution to the encoder-decoder attention weights during training that is
easily implemented with two lines of code. We investigate the effect of relaxed
attention across different AED model architectures and two prominent ASR tasks,
Wall Street Journal (WSJ) and Librispeech. We found that transformers trained
with relaxed attention outperform the standard baseline models consistently
during decoding with external language models. On WSJ, we set a new benchmark
for transformer-based end-to-end speech recognition with a word error rate of
3.65%, outperforming state of the art (4.20%) by 13.1% relative, while
introducing only a single hyperparameter. Upon acceptance, models will be
published on github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scarecrow: A Framework for Scrutinizing Machine Text. (arXiv:2107.01294v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1">Yao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Forbes_M/0/1/0/all/0/1">Maxwell Forbes</a>, <a href="http://arxiv.org/find/cs/1/au:+Koncel_Kedziorski_R/0/1/0/all/0/1">Rik Koncel-Kedziorski</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A.Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01294">
                                    <div class="article-summary-box-inner">
                                        <span>Modern neural text generation systems can produce remarkably fluent and
grammatical texts. While earlier language models suffered from repetition and
syntactic errors, the errors made by contemporary models are often semantic,
narrative, or discourse failures.

To facilitate research of these complex error types, we introduce a new
structured, crowdsourced error annotation schema called Scarecrow. The error
categories used in Scarecrow -- such as redundancy, commonsense errors, and
incoherence -- were identified by combining expert analysis with several pilot
rounds of ontology-free crowd annotation to arrive at a schema which covers the
error phenomena found in real machine generated text.

We use Scarecrow to collect 13k annotations of 1.3k human and machine
generate paragraphs of English language news text, amounting to over 41k spans
each labeled with its error category, severity, a natural language explanation,
and antecedent span (where relevant). We collect annotations for text generated
by state-of-the-art systems with varying known performance levels, from GPT-2
Small through the largest GPT-3. We isolate several factors for detailed
analysis, including parameter count, training data, and decoding technique. Our
results show both expected and surprising differences across these settings.
These findings demonstrate the value of Scarecrow annotations in the assessment
of current and future text generation systems. We release our complete
annotation toolkit and dataset at https://yao-dou.github.io/scarecrow/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Arabic Code-Switching Speech Recognition using Monolingual Data. (arXiv:2107.01573v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussein_A/0/1/0/all/0/1">Amir Hussein</a>, <a href="http://arxiv.org/find/cs/1/au:+Hifny_Y/0/1/0/all/0/1">Yasser Hifny</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01573">
                                    <div class="article-summary-box-inner">
                                        <span>Code-switching in automatic speech recognition (ASR) is an important
challenge due to globalization. Recent research in multilingual ASR shows
potential improvement over monolingual systems. We study key issues related to
multilingual modeling for ASR through a series of large-scale ASR experiments.
Our innovative framework deploys a multi-graph approach in the weighted finite
state transducers (WFST) framework. We compare our WFST decoding strategies
with a transformer sequence to sequence system trained on the same data. Given
a code-switching scenario between Arabic and English languages, our results
show that the WFST decoding approaches were more suitable for the
intersentential code-switching datasets. In addition, the transformer system
performed better for intrasentential code-switching task. With this study, we
release an artificially generated development and test sets, along with
ecological code-switching test set, to benchmark the ASR performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN. (arXiv:2107.01366v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaabouni_R/0/1/0/all/0/1">Rahma Chaabouni</a>, <a href="http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1">Roberto Dess&#xec;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01366">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their practical success, modern seq2seq architectures are unable to
generalize systematically on several SCAN tasks. Hence, it is not clear if
SCAN-style compositional generalization is useful in realistic NLP tasks. In
this work, we study the benefit that such compositionality brings about to
several machine translation tasks. We present several focused modifications of
Transformer that greatly improve generalization capabilities on SCAN and select
one that remains on par with a vanilla Transformer on a standard machine
translation (MT) task. Next, we study its performance in low-resource settings
and on a newly introduced distribution-shifted English-French translation task.
Overall, we find that improvements of a SCAN-capable model do not directly
transfer to the resource-rich MT setup. In contrast, in the low-resource setup,
general modifications lead to an improvement of up to 13.1% BLEU score w.r.t. a
vanilla Transformer. Similarly, an improvement of 14% in an accuracy-based
metric is achieved in the introduced compositional English-French translation
task. This provides experimental evidence that the compositional generalization
assessed in SCAN is particularly useful in resource-starved and domain-shifted
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks. (arXiv:2107.01431v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jinghui Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yining Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jianheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01431">
                                    <div class="article-summary-box-inner">
                                        <span>Previous math word problem solvers following the encoder-decoder paradigm
fail to explicitly incorporate essential math symbolic constraints, leading to
unexplainable and unreasonable predictions. Herein, we propose Neural-Symbolic
Solver (NS-Solver) to explicitly and seamlessly incorporate different levels of
symbolic constraints by auxiliary tasks. Our NS-Solver consists of a problem
reader to encode problems, a programmer to generate symbolic equations, and a
symbolic executor to obtain answers. Along with target expression supervision,
our solver is also optimized via 4 new auxiliary objectives to enforce
different symbolic reasoning: a) self-supervised number prediction task
predicting both number quantity and number locations; b) commonsense constant
prediction task predicting what prior knowledge (e.g. how many legs a chicken
has) is required; c) program consistency checker computing the semantic loss
between predicted equation and target equation to ensure reasonable equation
mapping; d) duality exploiting task exploiting the quasi duality between
symbolic equation generation and problem&#x27;s part-of-speech generation to enhance
the understanding ability of a solver. Besides, to provide a more realistic and
challenging benchmark for developing a universal and scalable solver, we also
construct a new large-scale MWP benchmark CM17K consisting of 4 kinds of MWPs
(arithmetic, one-unknown linear, one-unknown non-linear, equation set) with
more than 17K samples. Extensive experiments on Math23K and our CM17k
demonstrate the superiority of our NS-Solver compared to state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Persian-WSD-Corpus: A Sense Annotated Corpus for Persian All-words Word Sense Disambiguation. (arXiv:2107.01540v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rouhizadeh_H/0/1/0/all/0/1">Hossein Rouhizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamsfard_M/0/1/0/all/0/1">Mehrnoush Shamsfard</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajalli_V/0/1/0/all/0/1">Vahideh Tajalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouhziadeh_M/0/1/0/all/0/1">Masoud Rouhziadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01540">
                                    <div class="article-summary-box-inner">
                                        <span>Word Sense Disambiguation (WSD) is a long-standing task in Natural Language
Processing(NLP) that aims to automatically identify the most relevant meaning
of the words in a given context. Developing standard WSD test collections can
be mentioned as an important prerequisite for developing and evaluating
different WSD systems in the language of interest. Although many WSD test
collections have been developed for a variety of languages, no standard
All-words WSD benchmark is available for Persian. In this paper, we address
this shortage for the Persian language by introducing SBU-WSD-Corpus, as the
first standard test set for the Persian All-words WSD task. SBU-WSD-Corpus is
manually annotated with senses from the Persian WordNet (FarsNet) sense
inventory. To this end, three annotators used SAMP (a tool for sense annotation
based on FarsNet lexical graph) to perform the annotation task. SBU-WSD-Corpus
consists of 19 Persian documents in different domains such as Sports, Science,
Arts, etc. It includes 5892 content words of Persian running text and 3371
manually sense annotated words (2073 nouns, 566 verbs, 610 adjectives, and 122
adverbs). Providing baselines for future studies on the Persian All-words WSD
task, we evaluate several WSD models on SBU-WSD-Corpus. The corpus is publicly
available at https://github.com/hrouhizadeh/SBU-WSD-Corpus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Few-Shot Learning with Frozen Language Models. (arXiv:2106.13884v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsimpoukelli_M/0/1/0/all/0/1">Maria Tsimpoukelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1">Jacob Menick</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabi_S/0/1/0/all/0/1">Serkan Cabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1">S. M. Ali Eslami</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1">Oriol Vinyals</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13884">
                                    <div class="article-summary-box-inner">
                                        <span>When trained at sufficient scale, auto-regressive language models exhibit the
notable ability to learn a new language task after being prompted with just a
few examples. Here, we present a simple, yet effective, approach for
transferring this few-shot learning ability to a multimodal setting (vision and
language). Using aligned image and caption data, we train a vision encoder to
represent each image as a sequence of continuous embeddings, such that a
pre-trained, frozen language model prompted with this prefix generates the
appropriate caption. The resulting system is a multimodal few-shot learner,
with the surprising ability to learn a variety of new tasks when conditioned on
examples, represented as a sequence of multiple interleaved image and text
embeddings. We demonstrate that it can rapidly learn words for new objects and
novel visual categories, do visual question-answering with only a handful of
examples, and make use of outside knowledge, by measuring a single model on a
variety of established and new benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning equipped web based disease prediction and recommender system. (arXiv:2106.02813v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajora_H/0/1/0/all/0/1">Harish Rajora</a>, <a href="http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1">Narinder Singh Punn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02813">
                                    <div class="article-summary-box-inner">
                                        <span>Worldwide, several cases go undiagnosed due to poor healthcare support in
remote areas. In this context, a centralized system is needed for effective
monitoring and analysis of the medical records. A web-based patient diagnostic
system is a central platform to store the medical history and predict the
possible disease based on the current symptoms experienced by a patient to
ensure faster and accurate diagnosis. Early disease prediction can help the
users determine the severity of the disease and take quick action. The proposed
web-based disease prediction system utilizes machine learning based
classification techniques on a data set acquired from the National Centre of
Disease Control (NCDC). $K$-nearest neighbor (K-NN), random forest and naive
bayes classification approaches are utilized and an ensemble voting algorithm
is also proposed where each classifier is assigned weights dynamically based on
the prediction confidence. The proposed system is also equipped with a
recommendation scheme to recommend the type of tests based on the existing
symptoms of the patient, so that necessary precautions can be taken. A
centralized database ensures that the medical data is preserved and there is
transparency in the system. The tampering into the system is prevented by
giving the no &quot;updation&quot; rights once the diagnosis is created.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers. (arXiv:2106.13122v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morrison_K/0/1/0/all/0/1">Katelyn Morrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilby_B/0/1/0/all/0/1">Benjamin Gilby</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipchak_C/0/1/0/all/0/1">Colton Lipchak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattioli_A/0/1/0/all/0/1">Adam Mattioli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovashka_A/0/1/0/all/0/1">Adriana Kovashka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13122">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, vision transformers and MLP-based models have been developed in
order to address some of the prevalent weaknesses in convolutional neural
networks. Due to the novelty of transformers being used in this domain along
with the self-attention mechanism, it remains unclear to what degree these
architectures are robust to corruptions. Despite some works proposing that data
augmentation remains essential for a model to be robust against corruptions, we
propose to explore the impact that the architecture has on corruption
robustness. We find that vision transformer architectures are inherently more
robust to corruptions than the ResNet-50 and MLP-Mixers. We also find that
vision transformers with 5 times fewer parameters than a ResNet-50 have more
shape bias. Our code is available to reproduce.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A More Compact Object Detector Head Network with Feature Enhancement and Relational Reasoning. (arXiv:2106.14475v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xiangshi Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tengfei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sham_C/0/1/0/all/0/1">Chiu-Wing Sham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14475">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling implicit feature interaction patterns is of significant importance
to object detection tasks. However, in the two-stage detectors, due to the
excessive use of hand-crafted components, it is very difficult to reason about
the implicit relationship of the instance features. To tackle this problem, we
analyze three different levels of feature interaction relationships, namely,
the dependency relationship between the cropped local features and global
features, the feature autocorrelation within the instance, and the
cross-correlation relationship between the instances. To this end, we propose a
more compact object detector head network (CODH), which can not only preserve
global context information and condense the information density, but also
allows instance-wise feature enhancement and relational reasoning in a larger
matrix space. Without bells and whistles, our method can effectively improve
the detection performance while significantly reducing the parameters of the
model, e.g., with our method, the parameters of the head network is 0.6 times
smaller than the state-of-the-art Cascade R-CNN, yet the performance boost is
1.3% on COCO test-dev. Without losing generality, we can also build a more
lighter head network for other multi-stage detectors by assembling our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NP-DRAW: A Non-Parametric Structured Latent Variable Model for Image Generation. (arXiv:2106.13435v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiaohui Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1">Raquel Urtasun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1">Renjie Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13435">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a non-parametric structured latent variable model
for image generation, called NP-DRAW, which sequentially draws on a latent
canvas in a part-by-part fashion and then decodes the image from the canvas.
Our key contributions are as follows. 1) We propose a non-parametric prior
distribution over the appearance of image parts so that the latent variable
&#x60;&#x60;what-to-draw&#x27;&#x27; per step becomes a categorical random variable. This improves
the expressiveness and greatly eases the learning compared to Gaussians used in
the literature. 2) We model the sequential dependency structure of parts via a
Transformer, which is more powerful and easier to train compared to RNNs used
in the literature. 3) We propose an effective heuristic parsing algorithm to
pre-train the prior. Experiments on MNIST, Omniglot, CIFAR-10, and CelebA show
that our method significantly outperforms previous structured image models like
DRAW and AIR and is competitive to other generic generative models. Moreover,
we show that our model&#x27;s inherent compositionality and interpretability bring
significant benefits in the low-data learning regime and latent space editing.
Code is available at https://github.com/ZENGXH/NPDRAW.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CompConv: A Compact Convolution Module for Efficient Feature Learning. (arXiv:2106.10486v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yujun Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10486">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) have achieved remarkable success in
various computer vision tasks but rely on tremendous computational cost. To
solve this problem, existing approaches either compress well-trained
large-scale models or learn lightweight models with carefully designed network
structures. In this work, we make a close study of the convolution operator,
which is the basic unit used in CNNs, to reduce its computing load. In
particular, we propose a compact convolution module, called CompConv, to
facilitate efficient feature learning. With the divide-and-conquer strategy,
CompConv is able to save a great many computations as well as parameters to
produce a certain dimensional feature map. Furthermore, CompConv discreetly
integrates the input features into the outputs to efficiently inherit the input
information. More importantly, the novel CompConv is a plug-and-play module
that can be directly applied to modern CNN structures to replace the vanilla
convolution layers without further effort. Extensive experimental results
suggest that CompConv can adequately compress the benchmark CNN structures yet
barely sacrifice the performance, surpassing other competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alex Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1">Safa Cicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02994">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for inferring dense depth maps from images and sparse
depth measurements by leveraging synthetic data to learn the association of
sparse point clouds with dense natural shapes, and using the image as evidence
to validate the predicted depth map. Our learned prior for natural shapes uses
only sparse depth as input, not images, so the method is not affected by the
covariate shift when attempting to transfer learned models from synthetic data
to real ones. This allows us to use abundant synthetic data with ground truth
to learn the most difficult component of the reconstruction process, which is
topology estimation, and use the image to refine the prediction based on
photometric evidence. Our approach uses fewer parameters than previous methods,
yet, achieves the state of the art on both indoor and outdoor benchmark
datasets. Code available at:
https://github.com/alexklwong/learning-topology-synthetic-data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Feature Pyramid Networks for Object Detection. (arXiv:2012.00779v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingjian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Changbin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00779">
                                    <div class="article-summary-box-inner">
                                        <span>Feature pyramid network (FPN) is a critical component in modern object
detection frameworks. The performance gain in most of the existing FPN variants
is mainly attributed to the increase of computational burden. An attempt to
enhance the FPN is enriching the spatial information by expanding the receptive
fields, which is promising to largely improve the detection accuracy. In this
paper, we first investigate how expanding the receptive fields affect the
accuracy and computational costs of FPN. We explore a baseline model called
inception FPN in which each lateral connection contains convolution filters
with different kernel sizes. Moreover, we point out that not all objects need
such a complicated calculation and propose a new dynamic FPN (DyFPN). The
output features of DyFPN will be calculated by using the adaptively selected
branch according to a dynamic gating operation. Therefore, the proposed method
can provide a more efficient dynamic inference for achieving a better trade-off
between accuracy and computational cost. Extensive experiments conducted on
MS-COCO benchmark demonstrate that the proposed DyFPN significantly improves
performance with the optimal allocation of computation resources. For instance,
replacing inception FPN with DyFPN reduces about 40% of its FLOPs while
maintaining similar high performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Rotation-Invariant Framework for Deep Point Cloud Analysis. (arXiv:2003.07238v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xianzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruihui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangyong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chi-Wing Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng-Ann Heng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.07238">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, many deep neural networks were designed to process 3D point clouds,
but a common drawback is that rotation invariance is not ensured, leading to
poor generalization to arbitrary orientations. In this paper, we introduce a
new low-level purely rotation-invariant representation to replace common 3D
Cartesian coordinates as the network inputs. Also, we present a network
architecture to embed these representations into features, encoding local
relations between points and their neighbors, and the global shape structure.
To alleviate inevitable global information loss caused by the
rotation-invariant representations, we further introduce a region relation
convolution to encode local and non-local information. We evaluate our method
on multiple point cloud analysis tasks, including shape classification, part
segmentation, and shape retrieval. Experimental results show that our method
achieves consistent, and also the best performance, on inputs at arbitrary
orientations, compared with the state-of-the-arts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Adversarial Patch Analysis and Certified Defense against Crowd Counting. (arXiv:2104.10868v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaoqing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Binghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10868">
                                    <div class="article-summary-box-inner">
                                        <span>Crowd counting has drawn much attention due to its importance in
safety-critical surveillance systems. Especially, deep neural network (DNN)
methods have significantly reduced estimation errors for crowd counting
missions. Recent studies have demonstrated that DNNs are vulnerable to
adversarial attacks, i.e., normal images with human-imperceptible perturbations
could mislead DNNs to make false predictions. In this work, we propose a robust
attack strategy called Adversarial Patch Attack with Momentum (APAM) to
systematically evaluate the robustness of crowd counting models, where the
attacker&#x27;s goal is to create an adversarial perturbation that severely degrades
their performances, thus leading to public safety accidents (e.g., stampede
accidents). Especially, the proposed attack leverages the extreme-density
background information of input images to generate robust adversarial patches
via a series of transformations (e.g., interpolation, rotation, etc.). We
observe that by perturbing less than 6\% of image pixels, our attacks severely
degrade the performance of crowd counting systems, both digitally and
physically. To better enhance the adversarial robustness of crowd counting
models, we propose the first regression model-based Randomized Ablation (RA),
which is more sufficient than Adversarial Training (ADT) (Mean Absolute Error
of RA is 5 lower than ADT on clean samples and 30 lower than ADT on adversarial
examples). Extensive experiments on five crowd counting models demonstrate the
effectiveness and generality of the proposed method. Code is available at
\url{https://github.com/harrywuhust2022/Adv-Crowd-analysis}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Learning Object Detection Method for an Efficient Clusters Initialization. (arXiv:2104.13634v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Couturier_R/0/1/0/all/0/1">Rapha&#xeb;l Couturier</a>, <a href="http://arxiv.org/find/cs/1/au:+Noura_H/0/1/0/all/0/1">Hassan N. Noura</a>, <a href="http://arxiv.org/find/cs/1/au:+Salman_O/0/1/0/all/0/1">Ola Salman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sider_A/0/1/0/all/0/1">Abderrahmane Sider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13634">
                                    <div class="article-summary-box-inner">
                                        <span>Clustering is an unsupervised machine learning method grouping data samples
into clusters of similar objects. In practice, clustering has been used in
numerous applications such as banking customers profiling, document retrieval,
image segmentation, and e-commerce recommendation engines. However, the
existing clustering techniques present significant limitations, from which is
the dependability of their stability on the initialization parameters (e.g.
number of clusters, centroids). Different solutions were presented in the
literature to overcome this limitation (i.e. internal and external validation
metrics). However, these solutions require high computational complexity and
memory consumption, especially when dealing with big data. In this paper, we
apply the recent object detection Deep Learning (DL) model, named YOLO-v5, to
detect the initial clustering parameters such as the number of clusters with
their sizes and centroids. Mainly, the proposed solution consists of adding a
DL-based initialization phase making the clustering algorithms free of
initialization. Two model solutions are provided in this work, one for isolated
clusters and the other one for overlapping clusters. The features of the
incoming dataset determine which model to use. Moreover, The results show that
the proposed solution can provide near-optimal clusters initialization
parameters with low computational and resources overhead compared to existing
solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Deformable Image Registration with Convolutional Neural Network. (arXiv:2106.12673v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mok_T/0/1/0/all/0/1">Tony C. W. Mok</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_A/0/1/0/all/0/1">Albert C. S. Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12673">
                                    <div class="article-summary-box-inner">
                                        <span>Recent deep learning-based methods have shown promising results and runtime
advantages in deformable image registration. However, analyzing the effects of
hyperparameters and searching for optimal regularization parameters prove to be
too prohibitive in deep learning-based methods. This is because it involves
training a substantial number of separate models with distinct hyperparameter
values. In this paper, we propose a conditional image registration method and a
new self-supervised learning paradigm for deep deformable image registration.
By learning the conditional features that are correlated with the
regularization hyperparameter, we demonstrate that optimal solutions with
arbitrary hyperparameters can be captured by a single deep convolutional neural
network. In addition, the smoothness of the resulting deformation field can be
manipulated with arbitrary strength of smoothness regularization during
inference. Extensive experiments on a large-scale brain MRI dataset show that
our proposed method enables the precise control of the smoothness of the
deformation field without sacrificing the runtime advantage or registration
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptive YOLO for One-Stage Cross-Domain Detection. (arXiv:2106.13939v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shizhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuo_H/0/1/0/all/0/1">Hongya Tuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_Z/0/1/0/all/0/1">Zhongliang Jing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13939">
                                    <div class="article-summary-box-inner">
                                        <span>Domain shift is a major challenge for object detectors to generalize well to
real world applications. Emerging techniques of domain adaptation for two-stage
detectors help to tackle this problem. However, two-stage detectors are not the
first choice for industrial applications due to its long time consumption. In
this paper, a novel Domain Adaptive YOLO (DA-YOLO) is proposed to improve
cross-domain performance for one-stage detectors. Image level features
alignment is used to strictly match for local features like texture, and
loosely match for global features like illumination. Multi-scale instance level
features alignment is presented to reduce instance domain shift effectively ,
such as variations in object appearance and viewpoint. A consensus
regularization to these domain classifiers is employed to help the network
generate domain-invariant detections. We evaluate our proposed method on
popular datasets like Cityscapes, KITTI, SIM10K and etc.. The results
demonstrate significant improvement when tested under different cross-domain
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptation of Object Detectors: A Survey. (arXiv:2105.13502v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oza_P/0/1/0/all/0/1">Poojan Oza</a>, <a href="http://arxiv.org/find/cs/1/au:+Sindagi_V/0/1/0/all/0/1">Vishwanath A. Sindagi</a>, <a href="http://arxiv.org/find/cs/1/au:+VS_V/0/1/0/all/0/1">Vibashan VS</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13502">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep learning have led to the development of accurate and
efficient models for various computer vision applications such as
classification, segmentation, and detection. However, learning highly accurate
models relies on the availability of large-scale annotated datasets. Due to
this, model performance drops drastically when evaluated on label-scarce
datasets having visually distinct images, termed as domain adaptation problem.
There is a plethora of works to adapt classification and segmentation models to
label-scarce target datasets through unsupervised domain adaptation.
Considering that detection is a fundamental task in computer vision, many
recent works have focused on developing novel domain adaptive detection
techniques. Here, we describe in detail the domain adaptation problem for
detection and present an extensive survey of the various methods. Furthermore,
we highlight strategies proposed and the associated shortcomings. Subsequently,
we identify multiple aspects of the problem that are most promising for future
research. We believe that this survey shall be valuable to the pattern
recognition experts working in the fields of computer vision, biometrics,
medical imaging, and autonomous navigation by introducing them to the problem,
and familiarizing them with the current status of the progress while providing
promising directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANDA: A deep generative adversarial network predicts the spatial distribution of nanoparticles in tumor pixelly. (arXiv:2012.12561v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jiulou Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1">Yuxia Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Shouju Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12561">
                                    <div class="article-summary-box-inner">
                                        <span>Intratumoral nanoparticles (NPs) distribution is critical for the success of
nanomedicine in imaging and treatment, but computational models to describe the
NPs distribution remain unavailable due to the complex tumor-nano interactions.
Here, we develop a Generative Adversarial Network for Distribution Analysis
(GANDA) to describe and conditionally generates the intratumoral quantum dots
(QDs) distribution after i.v. injection. This deep generative model is trained
automatically by 27 775 patches of tumor vessels and cell nuclei decomposed
from whole-slide images of 4T1 breast cancer sections. The GANDA model can
conditionally generate images of intratumoral QDs distribution under the
constraint of given tumor vessels and cell nuclei channels with the same
spatial resolution (pixels-to-pixels), minimal loss (mean squared error, MSE &#x3D;
1.871) and excellent reliability (intraclass correlation, ICC &#x3D; 0.94).
Quantitative analysis of QDs extravasation distance (ICC &#x3D; 0.95) and subarea
distribution (ICC &#x3D; 0.99) is allowed on the generated images without knowing
the real QDs distribution. We believe this deep generative model may provide
opportunities to investigate how influencing factors affect NPs distribution in
individual tumors and guide nanomedicine optimization for molecular imaging and
personalized treatment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. (arXiv:2006.12655v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1">Cassidy Laidlaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12655">
                                    <div class="article-summary-box-inner">
                                        <span>A key challenge in adversarial robustness is the lack of a precise
mathematical characterization of human perception, used in the very definition
of adversarial attacks that are imperceptible to human eyes. Most current
attacks and defenses try to avoid this issue by considering restrictive
adversarial threat models such as those bounded by $L_2$ or $L_\infty$
distance, spatial perturbations, etc. However, models that are robust against
any of these restrictive threat models are still fragile against other threat
models. To resolve this issue, we propose adversarial training against the set
of all imperceptible adversarial examples, approximated using deep neural
networks. We call this threat model the neural perceptual threat model (NPTM);
it includes adversarial examples with a bounded neural perceptual distance (a
neural network-based approximation of the true perceptual distance) to natural
images. Through an extensive perceptual study, we show that the neural
perceptual distance correlates well with human judgements of perceptibility of
adversarial examples, validating our threat model.

Under the NPTM, we develop novel perceptual adversarial attacks and defenses.
Because the NPTM is very broad, we find that Perceptual Adversarial Training
(PAT) against a perceptual attack gives robustness against many other types of
adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five
diverse adversarial attacks. We find that PAT achieves state-of-the-art
robustness against the union of these five attacks, more than doubling the
accuracy over the next best model, without training against any of them. That
is, PAT generalizes well to unforeseen perturbation types. This is vital in
sensitive applications where a particular threat model cannot be assumed, and
to the best of our knowledge, PAT is the first adversarial training defense
with this property.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PVTv2: Improved Baselines with Pyramid Vision Transformer. (arXiv:2106.13797v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kaitao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Ding Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13797">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer recently has shown encouraging progresses in computer vision. In
this work, we present new baselines by improving the original Pyramid Vision
Transformer (abbreviated as PVTv1) by adding three designs, including (1)
overlapping patch embedding, (2) convolutional feed-forward networks, and (3)
linear complexity attention layers.

With these modifications, our PVTv2 significantly improves PVTv1 on three
tasks e.g., classification, detection, and segmentation. Moreover, PVTv2
achieves comparable or better performances than recent works such as Swin
Transformer. We hope this work will facilitate state-of-the-art Transformer
researches in computer vision. Code is available at
https://github.com/whai362/PVT .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Full interpretable machine learning in 2D with inline coordinates. (arXiv:2106.07568v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovalerchuk_B/0/1/0/all/0/1">Boris Kovalerchuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1">Hoang Phan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07568">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposed a new methodology for machine learning in 2-dimensional
space (2-D ML) in inline coordinates. It is a full machine learning approach
that does not require to deal with n-dimensional data in n-dimensional space.
It allows discovering n-D patterns in 2-D space without loss of n-D information
using graph representations of n-D data in 2-D. Specifically, it can be done
with the inline based coordinates in different modifications, including static
and dynamic ones. The classification and regression algorithms based on these
inline coordinates were introduced. A successful case study based on a
benchmark data demonstrated the feasibility of the approach. This approach
helps to consolidate further a whole new area of full 2-D machine learning as a
promising ML methodology. It has advantages of abilities to involve actively
the end-users into the discovering of models and their justification. Another
advantage is providing interpretable ML models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WoodScape: A multi-task, multi-camera fisheye dataset for autonomous driving. (arXiv:1905.01489v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yogamani_S/0/1/0/all/0/1">Senthil Yogamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_C/0/1/0/all/0/1">Ciaran Hughes</a>, <a href="http://arxiv.org/find/cs/1/au:+Horgan_J/0/1/0/all/0/1">Jonathan Horgan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sistu_G/0/1/0/all/0/1">Ganesh Sistu</a>, <a href="http://arxiv.org/find/cs/1/au:+Varley_P/0/1/0/all/0/1">Padraig Varley</a>, <a href="http://arxiv.org/find/cs/1/au:+ODea_D/0/1/0/all/0/1">Derek O&#x27;Dea</a>, <a href="http://arxiv.org/find/cs/1/au:+Uricar_M/0/1/0/all/0/1">Michal Uricar</a>, <a href="http://arxiv.org/find/cs/1/au:+Milz_S/0/1/0/all/0/1">Stefan Milz</a>, <a href="http://arxiv.org/find/cs/1/au:+Simon_M/0/1/0/all/0/1">Martin Simon</a>, <a href="http://arxiv.org/find/cs/1/au:+Amende_K/0/1/0/all/0/1">Karl Amende</a>, <a href="http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1">Christian Witt</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashed_H/0/1/0/all/0/1">Hazem Rashed</a>, <a href="http://arxiv.org/find/cs/1/au:+Chennupati_S/0/1/0/all/0/1">Sumanth Chennupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayak_S/0/1/0/all/0/1">Sanjaya Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansoor_S/0/1/0/all/0/1">Saquib Mansoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Perroton_X/0/1/0/all/0/1">Xavier Perroton</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1">Patrick Perez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.01489">
                                    <div class="article-summary-box-inner">
                                        <span>Fisheye cameras are commonly employed for obtaining a large field of view in
surveillance, augmented reality and in particular automotive applications. In
spite of their prevalence, there are few public datasets for detailed
evaluation of computer vision algorithms on fisheye images. We release the
first extensive fisheye automotive dataset, WoodScape, named after Robert Wood
who invented the fisheye camera in 1906. WoodScape comprises of four surround
view cameras and nine tasks including segmentation, depth estimation, 3D
bounding box detection and soiling detection. Semantic annotation of 40 classes
at the instance level is provided for over 10,000 images and annotation for
other tasks are provided for over 100,000 images. With WoodScape, we would like
to encourage the community to adapt computer vision models for fisheye camera
instead of using naive rectification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PixSet : An Opportunity for 3D Computer Vision to Go Beyond Point Clouds With a Full-Waveform LiDAR Dataset. (arXiv:2102.12010v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deziel_J/0/1/0/all/0/1">Jean-Luc D&#xe9;ziel</a>, <a href="http://arxiv.org/find/cs/1/au:+Merriaux_P/0/1/0/all/0/1">Pierre Merriaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Tremblay_F/0/1/0/all/0/1">Francis Tremblay</a>, <a href="http://arxiv.org/find/cs/1/au:+Lessard_D/0/1/0/all/0/1">Dave Lessard</a>, <a href="http://arxiv.org/find/cs/1/au:+Plourde_D/0/1/0/all/0/1">Dominique Plourde</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanguennec_J/0/1/0/all/0/1">Julien Stanguennec</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulet_P/0/1/0/all/0/1">Pierre Goulet</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivier_P/0/1/0/all/0/1">Pierre Olivier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12010">
                                    <div class="article-summary-box-inner">
                                        <span>Leddar PixSet is a new publicly available dataset (dataset.leddartech.com)
for autonomous driving research and development. One key novelty of this
dataset is the presence of full-waveform data from the Leddar Pixell sensor, a
solid-state flash LiDAR. Full-waveform data has been shown to improve the
performance of perception algorithms in airborne applications but is yet to be
demonstrated for terrestrial applications such as autonomous driving. The
PixSet dataset contains approximately 29k frames from 97 sequences recorded in
high-density urban areas, using a set of various sensors (cameras, LiDARs,
radar, IMU, etc.) Each frame has been manually annotated with 3D bounding
boxes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Body Meshes as Points. (arXiv:2105.02467v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dongdong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liew_J/0/1/0/all/0/1">Jun Hao Liew</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_X/0/1/0/all/0/1">Xuecheng Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02467">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the challenging multi-person 3D body mesh estimation task in this
work. Existing methods are mostly two-stage based--one stage for person
localization and the other stage for individual body mesh estimation, leading
to redundant pipelines with high computation cost and degraded performance for
complex scenes (e.g., occluded person instances). In this work, we present a
single-stage model, Body Meshes as Points (BMP), to simplify the pipeline and
lift both efficiency and performance. In particular, BMP adopts a new method
that represents multiple person instances as points in the spatial-depth space
where each point is associated with one body mesh. Hinging on such
representations, BMP can directly predict body meshes for multiple persons in a
single stage by concurrently localizing person instance points and estimating
the corresponding body meshes. To better reason about depth ordering of all the
persons within the same scene, BMP designs a simple yet effective
inter-instance ordinal depth loss to obtain depth-coherent body mesh
estimation. BMP also introduces a novel keypoint-aware augmentation to enhance
model robustness to occluded person instances. Comprehensive experiments on
benchmarks Panoptic, MuPoTS-3D and 3DPW clearly demonstrate the
state-of-the-art efficiency of BMP for multi-person body mesh estimation,
together with outstanding accuracy. Code can be found at:
https://github.com/jfzhang95/BMP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UCSL : A Machine Learning Expectation-Maximization framework for Unsupervised Clustering driven by Supervised Learning. (arXiv:2107.01988v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Louiset_R/0/1/0/all/0/1">Robin Louiset</a>, <a href="http://arxiv.org/find/stat/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/stat/1/au:+Dufumier_B/0/1/0/all/0/1">Benoit Dufumier</a>, <a href="http://arxiv.org/find/stat/1/au:+Houenou_J/0/1/0/all/0/1">Josselin Houenou</a>, <a href="http://arxiv.org/find/stat/1/au:+Grigis_A/0/1/0/all/0/1">Antoine Grigis</a>, <a href="http://arxiv.org/find/stat/1/au:+Duchesnay_E/0/1/0/all/0/1">Edouard Duchesnay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01988">
                                    <div class="article-summary-box-inner">
                                        <span>Subtype Discovery consists in finding interpretable and consistent sub-parts
of a dataset, which are also relevant to a certain supervised task. From a
mathematical point of view, this can be defined as a clustering task driven by
supervised learning in order to uncover subgroups in line with the supervised
prediction. In this paper, we propose a general Expectation-Maximization
ensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised
Learning). Our method is generic, it can integrate any clustering method and
can be driven by both binary classification and regression. We propose to
construct a non-linear model by merging multiple linear estimators, one per
cluster. Each hyperplane is estimated so that it correctly discriminates - or
predict - only one cluster. We use SVC or Logistic Regression for
classification and SVR for regression. Furthermore, to perform cluster analysis
within a more suitable space, we also propose a dimension-reduction algorithm
that projects the data onto an orthonormal space relevant to the supervised
task. We analyze the robustness and generalization capability of our algorithm
using synthetic and experimental datasets. In particular, we validate its
ability to identify suitable consistent sub-types by conducting a
psychiatric-diseases cluster analysis with known ground-truth labels. The gain
of the proposed method over previous state-of-the-art techniques is about +1.9
points in terms of balanced accuracy. Finally, we make codes and examples
available in a scikit-learn-compatible Python package at
https://github.com/neurospin-projects/2021_rlouiset_ucsl</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection With Partitioning Overfitting Autoencoder Ensembles. (arXiv:2009.02755v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lorbeer_B/0/1/0/all/0/1">Boris Lorbeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Botler_M/0/1/0/all/0/1">Max Botler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.02755">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose POTATOES (Partitioning OverfiTting AuTOencoder
EnSemble), a new method for unsupervised outlier detection (UOD). More
precisely, given any autoencoder for UOD, this technique can be used to improve
its accuracy while at the same time removing the burden of tuning its
regularization. The idea is to not regularize at all, but to rather randomly
partition the data into sufficiently many equally sized parts, overfit each
part with its own autoencoder, and to use the maximum over all autoencoder
reconstruction errors as the anomaly score. We apply our model to various
realistic datasets and show that if the set of inliers is dense enough, our
method indeed improves the UOD performance of a given autoencoder
significantly. For reproducibility, the code is made available on github so the
reader can recreate the results in this paper as well as apply the method to
other autoencoders and datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Endo-Depth-and-Motion: Reconstruction and Tracking in Endoscopic Videos using Depth Networks and Photometric Constraints. (arXiv:2103.16525v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Recasens_D/0/1/0/all/0/1">David Recasens</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamarca_J/0/1/0/all/0/1">Jos&#xe9; Lamarca</a>, <a href="http://arxiv.org/find/cs/1/au:+Facil_J/0/1/0/all/0/1">Jos&#xe9; M. F&#xe1;cil</a>, <a href="http://arxiv.org/find/cs/1/au:+Montiel_J/0/1/0/all/0/1">J. M. M. Montiel</a>, <a href="http://arxiv.org/find/cs/1/au:+Civera_J/0/1/0/all/0/1">Javier Civera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16525">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating a scene reconstruction and the camera motion from in-body videos
is challenging due to several factors, e.g. the deformation of in-body cavities
or the lack of texture. In this paper we present Endo-Depth-and-Motion, a
pipeline that estimates the 6-degrees-of-freedom camera pose and dense 3D scene
models from monocular endoscopic videos. Our approach leverages recent advances
in self-supervised depth networks to generate pseudo-RGBD frames, then tracks
the camera pose using photometric residuals and fuses the registered depth maps
in a volumetric representation. We present an extensive experimental evaluation
in the public dataset Hamlyn, showing high-quality results and comparisons
against relevant baselines. We also release all models and code for future
comparisons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Contrastive Self-supervised Learning for Image Classification. (arXiv:2107.01776v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhiwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongtao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hongxiang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01776">
                                    <div class="article-summary-box-inner">
                                        <span>For artificial learning systems, continual learning over time from a stream
of data is essential. The burgeoning studies on supervised continual learning
have achieved great progress, while the study of catastrophic forgetting in
unsupervised learning is still blank. Among unsupervised learning methods,
self-supervise learning method shows tremendous potential on visual
representation without any labeled data at scale. To improve the visual
representation of self-supervised learning, larger and more varied data is
needed. In the real world, unlabeled data is generated at all times. This
circumstance provides a huge advantage for the learning of the self-supervised
method. However, in the current paradigm, packing previous data and current
data together and training it again is a waste of time and resources. Thus, a
continual self-supervised learning method is badly needed. In this paper, we
make the first attempt to implement the continual contrastive self-supervised
learning by proposing a rehearsal method, which keeps a few exemplars from the
previous data. Instead of directly combining saved exemplars with the current
data set for training, we leverage self-supervised knowledge distillation to
transfer contrastive information among previous data to the current network by
mimicking similarity score distribution inferred by the old network over a set
of saved exemplars. Moreover, we build an extra sample queue to assist the
network to distinguish between previous and current data and prevent mutual
interference while learning their own feature representation. Experimental
results show that our method performs well on CIFAR100 and ImageNet-Sub.
Compared with self-supervised baselines, which learning tasks one by one
without taking any technique, we improve the image classification top-1
accuracy by 1.60% on CIFAR100 and 2.86% on ImageNet-Sub under 10 incremental
steps setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisualWordGrid: Information Extraction From Scanned Documents Using A Multimodal Approach. (arXiv:2010.02358v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kerroumi_M/0/1/0/all/0/1">Mohamed Kerroumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sayem_O/0/1/0/all/0/1">Othmane Sayem</a>, <a href="http://arxiv.org/find/cs/1/au:+Shabou_A/0/1/0/all/0/1">Aymen Shabou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02358">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel approach for scanned document representation to perform
field extraction. It allows the simultaneous encoding of the textual, visual
and layout information in a 3-axis tensor used as an input to a segmentation
model. We improve the recent Chargrid and Wordgrid \cite{chargrid} models in
several ways, first by taking into account the visual modality, then by
boosting its robustness in regards to small datasets while keeping the
inference time low. Our approach is tested on public and private document-image
datasets, showing higher performances compared to the recent state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faster-LTN: a neuro-symbolic, end-to-end object detection architecture. (arXiv:2107.01877v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Manigrasso_F/0/1/0/all/0/1">Francesco Manigrasso</a>, <a href="http://arxiv.org/find/cs/1/au:+Miro_F/0/1/0/all/0/1">Filomeno Davide Miro</a>, <a href="http://arxiv.org/find/cs/1/au:+Morra_L/0/1/0/all/0/1">Lia Morra</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamberti_F/0/1/0/all/0/1">Fabrizio Lamberti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01877">
                                    <div class="article-summary-box-inner">
                                        <span>The detection of semantic relationships between objects represented in an
image is one of the fundamental challenges in image interpretation.
Neural-Symbolic techniques, such as Logic Tensor Networks (LTNs), allow the
combination of semantic knowledge representation and reasoning with the ability
to efficiently learn from examples typical of neural networks. We here propose
Faster-LTN, an object detector composed of a convolutional backbone and an LTN.
To the best of our knowledge, this is the first attempt to combine both
frameworks in an end-to-end training setting. This architecture is trained by
optimizing a grounded theory which combines labelled examples with prior
knowledge, in the form of logical axioms. Experimental comparisons show
competitive performance with respect to the traditional Faster R-CNN
architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unknown Presentation Attack Detection against Rational Attackers. (arXiv:2010.01592v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khodabakhsh_A/0/1/0/all/0/1">Ali Khodabakhsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_Z/0/1/0/all/0/1">Zahid Akhtar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01592">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the impressive progress in the field of presentation attack detection
and multimedia forensics over the last decade, these systems are still
vulnerable to attacks in real-life settings. Some of the challenges for
existing solutions are the detection of unknown attacks, the ability to perform
in adversarial settings, few-shot learning, and explainability. In this study,
these limitations are approached by reliance on a game-theoretic view for
modeling the interactions between the attacker and the detector. Consequently,
a new optimization criterion is proposed and a set of requirements are defined
for improving the performance of these systems in real-life settings.
Furthermore, a novel detection technique is proposed using generator-based
feature sets that are not biased towards any specific attack species. To
further optimize the performance on known attacks, a new loss function coined
categorical margin maximization loss (C-marmax) is proposed which gradually
improves the performance against the most powerful attack. The proposed
approach provides a more balanced performance across known and unknown attacks
and achieves state-of-the-art performance in known and unknown attack detection
cases against rational attackers. Lastly, the few-shot learning potential of
the proposed approach is studied as well as its ability to provide pixel-level
explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Part2Word: Learning Joint Embedding of Point Clouds and Text by Matching Parts to Words. (arXiv:2107.01872v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chuan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bojian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhizhong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01872">
                                    <div class="article-summary-box-inner">
                                        <span>It is important to learn joint embedding for 3D shapes and text in different
shape understanding tasks, such as shape-text matching, retrieval, and shape
captioning. Current multi-view based methods learn a mapping from multiple
rendered views to text. However, these methods can not analyze 3D shapes well
due to the self-occlusion and limitation of learning manifolds. To resolve this
issue, we propose a method to learn joint embedding of point clouds and text by
matching parts from shapes to words from sentences in a common space.
Specifically, we first learn segmentation prior to segment point clouds into
parts. Then, we map parts and words into an optimized space, where the parts
and words can be matched with each other. In the optimized space, we represent
a part by aggregating features of all points within the part, while
representing each word with its context information, where we train our network
to minimize the triplet ranking loss. Moreover, we also introduce cross-modal
attention to capture the relationship of part-word in this matching procedure,
which enhances joint embedding learning. Our experimental results outperform
the state-of-the-art in multi-modal retrieval under the widely used benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise Sensitivity-Based Energy Efficient and Robust Adversary Detection in Neural Networks. (arXiv:2101.01543v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sterneck_R/0/1/0/all/0/1">Rachel Sterneck</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Abhishek Moitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1">Priyadarshini Panda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01543">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved remarkable performance in computer vision,
however they are vulnerable to adversarial examples. Adversarial examples are
inputs that have been carefully perturbed to fool classifier networks, while
appearing unchanged to humans. Based on prior works on detecting adversaries,
we propose a structured methodology of augmenting a deep neural network (DNN)
with a detector subnetwork. We use $\textit{Adversarial Noise Sensitivity}$
(ANS), a novel metric for measuring the adversarial gradient contribution of
different intermediate layers of a network. Based on the ANS value, we append a
detector to the most sensitive layer. In prior works, more complex detectors
were added to a DNN, increasing the inference computational cost of the model.
In contrast, our structured and strategic addition of a detector to a DNN
reduces the complexity of the model while making the overall network
adversarially resilient. Through comprehensive white-box and black-box
experiments on MNIST, CIFAR-10, and CIFAR-100, we show that our method improves
state-of-the-art detector robustness against adversarial examples. Furthermore,
we validate the energy efficiency of our proposed adversarial detection
methodology through an extensive energy analysis on various hardware scalable
CMOS accelerator platforms. We also demonstrate the effects of quantization on
our detector-appended networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Audiovisual Synthesis via Exemplar Autoencoders. (arXiv:2001.04463v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Aayush Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04463">
                                    <div class="article-summary-box-inner">
                                        <span>We present an unsupervised approach that converts the input speech of any
individual into audiovisual streams of potentially-infinitely many output
speakers. Our approach builds on simple autoencoders that project out-of-sample
data onto the distribution of the training set. We use Exemplar Autoencoders to
learn the voice, stylistic prosody, and visual appearance of a specific target
exemplar speech. In contrast to existing methods, the proposed approach can be
easily extended to an arbitrarily large number of speakers and styles using
only 3 minutes of target audio-video data, without requiring {\em any} training
data for the input speaker. To do so, we learn audiovisual bottleneck
representations that capture the structured linguistic content of speech. We
outperform prior approaches on both audio and video synthesis, and provide
extensive qualitative analysis on our project page --
https://www.cs.cmu.edu/~exemplar-ae/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer in Transformer. (arXiv:2103.00112v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">An Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1">Enhua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00112">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer is a new kind of neural architecture which encodes the input data
as powerful features via the attention mechanism. Basically, the visual
transformers first divide the input images into several local patches and then
calculate both representations and their relationship. Since natural images are
of high complexity with abundant detail and color information, the granularity
of the patch dividing is not fine enough for excavating features of objects in
different scales and locations. In this paper, we point out that the attention
inside these local patches are also essential for building visual transformers
with high performance and we explore a new architecture, namely, Transformer iN
Transformer (TNT). Specifically, we regard the local patches (e.g.,
16$\times$16) as &quot;visual sentences&quot; and present to further divide them into
smaller patches (e.g., 4$\times$4) as &quot;visual words&quot;. The attention of each
word will be calculated with other words in the given visual sentence with
negligible computational costs. Features of both words and sentences will be
aggregated to enhance the representation ability. Experiments on several
benchmarks demonstrate the effectiveness of the proposed TNT architecture,
e.g., we achieve an $81.5%$ top-1 accuracy on the ImageNet, which is about
$1.7%$ higher than that of the state-of-the-art visual transformer with similar
computational cost. The PyTorch code is available at
https://github.com/huawei-noah/CV-Backbones/tree/master/tnt_pytorch, and the
MindSpore code is at
https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/TNT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Activity Segmentation by Joint Representation Learning and Online Clustering. (arXiv:2105.13353v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sateesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Haresh_S/0/1/0/all/0/1">Sanjay Haresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Awais Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Konin_A/0/1/0/all/0/1">Andrey Konin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zia_M/0/1/0/all/0/1">M. Zeeshan Zia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_Q/0/1/0/all/0/1">Quoc-Huy Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13353">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach for unsupervised activity segmentation, which
uses video frame clustering as a pretext task and simultaneously performs
representation learning and online clustering. This is in contrast with prior
works where representation learning and clustering are often performed
sequentially. We leverage temporal information in videos by employing temporal
optimal transport and temporal coherence loss. In particular, we incorporate a
temporal regularization term into the standard optimal transport module, which
preserves the temporal order of the activity, yielding the temporal optimal
transport module for computing pseudo-label cluster assignments. Next, the
temporal coherence loss encourages neighboring video frames to be mapped to
nearby points while distant video frames are mapped to farther away points in
the embedding space. The combination of these two components results in
effective representations for unsupervised activity segmentation. Furthermore,
previous methods require storing learned features for the entire dataset before
clustering them in an offline manner, whereas our approach processes one
mini-batch at a time in an online manner. Extensive evaluations on three public
datasets, i.e. 50-Salads, YouTube Instructions, and Breakfast, and our dataset,
i.e., Desktop Assembly, show that our approach performs on par or better than
previous methods for unsupervised activity segmentation, despite having
significantly less memory constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image-to-Image Translation: Methods and Applications. (arXiv:2101.08629v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yingxue Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jianxin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08629">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-image translation (I2I) aims to transfer images from a source domain
to a target domain while preserving the content representations. I2I has drawn
increasing attention and made tremendous progress in recent years because of
its wide range of applications in many computer vision and image processing
problems, such as image synthesis, segmentation, style transfer, restoration,
and pose estimation. In this paper, we provide an overview of the I2I works
developed in recent years. We will analyze the key techniques of the existing
I2I works and clarify the main progress the community has made. Additionally,
we will elaborate on the effect of I2I on the research and industry community
and point out remaining challenges in related fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraspME -- Grasp Manifold Estimator. (arXiv:2107.01836v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hager_J/0/1/0/all/0/1">Janik Hager</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_R/0/1/0/all/0/1">Ruben Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Toussaint_M/0/1/0/all/0/1">Marc Toussaint</a>, <a href="http://arxiv.org/find/cs/1/au:+Mainprice_J/0/1/0/all/0/1">Jim Mainprice</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01836">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a Grasp Manifold Estimator (GraspME) to detect
grasp affordances for objects directly in 2D camera images. To perform
manipulation tasks autonomously it is crucial for robots to have such
graspability models of the surrounding objects. Grasp manifolds have the
advantage of providing continuously infinitely many grasps, which is not the
case when using other grasp representations such as predefined grasp points.
For instance, this property can be leveraged in motion optimization to define
goal sets as implicit surface constraints in the robot configuration space. In
this work, we restrict ourselves to the case of estimating possible
end-effector positions directly from 2D camera images. To this extend, we
define grasp manifolds via a set of key points and locate them in images using
a Mask R-CNN backbone. Using learned features allows generalizing to different
view angles, with potentially noisy images, and objects that were not part of
the training set. We rely on simulation data only and perform experiments on
simple and complex objects, including unseen ones. Our framework achieves an
inference speed of 11.5 fps on a GPU, an average precision for keypoint
estimation of 94.5% and a mean pixel distance of only 1.29. This shows that we
can estimate the objects very well via bounding boxes and segmentation masks as
well as approximate the correct grasp manifold&#x27;s keypoint coordinates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in Computed Tomography. (arXiv:2105.14711v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1">Yang Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Ce Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hui_Y/0/1/0/all/0/1">Yuan Hui</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_S/0/1/0/all/0/1">Shiwei Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_M/0/1/0/all/0/1">Mengke Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Quan_Q/0/1/0/all/0/1">Quan Quan</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1">Shuxin Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hao_Y/0/1/0/all/0/1">You Hao</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1">Pengbo Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_H/0/1/0/all/0/1">Honghu Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_C/0/1/0/all/0/1">Chunpeng Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1">Xinbao Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1">S. Kevin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14711">
                                    <div class="article-summary-box-inner">
                                        <span>Spine-related diseases have high morbidity and cause a huge burden of social
cost. Spine imaging is an essential tool for noninvasively visualizing and
assessing spinal pathology. Segmenting vertebrae in computed tomography (CT)
images is the basis of quantitative medical image analysis for clinical
diagnosis and surgery planning of spine diseases. Current publicly available
annotated datasets on spinal vertebrae are small in size. Due to the lack of a
large-scale annotated spine image dataset, the mainstream deep learning-based
segmentation methods, which are data-driven, are heavily restricted. In this
paper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated
from multiple sources for vertebra segmentation, which contains 1,005 CT
volumes with over 11,100 labeled vertebrae belonging to different spinal
conditions. Based on this dataset, we conduct several spinal vertebrae
segmentation experiments to set the first benchmark. We believe that this
large-scale dataset will facilitate further research in many spine-related
image analysis tasks, including but not limited to vertebrae segmentation,
labeling, 3D spine reconstruction from biplanar radiographs, image
super-resolution, and enhancement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Segmentation, Compression and Reconstruction from Edge Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v10 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10762">
                                    <div class="article-summary-box-inner">
                                        <span>Random field and random cluster theory are used to describe certain
mathematical results concerning the probability distribution of image pixel
intensities characterized as generic $2D$ integer arrays. The size of the
smallest bounded region within an image is estimated for segmenting an image,
from which, the equilibrium distribution of intensities can be recovered. From
the estimated bounded regions, properties of the sub-optimal and equilibrium
distributions of intensities are derived, which leads to an image compression
methodology whereby only slightly more than half of all pixels are required for
a worst-case reconstruction of the original image. A custom deep belief network
and heuristic allows for the unsupervised segmentation, detection and
localization of objects in an image. An example illustrates the mathematical
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Better Compression with Deep Pre-Editing. (arXiv:2002.00113v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Talebi_H/0/1/0/all/0/1">Hossein Talebi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kelly_D/0/1/0/all/0/1">Damien Kelly</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_X/0/1/0/all/0/1">Xiyang Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Dorado_I/0/1/0/all/0/1">Ignacio Garcia Dorado</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_F/0/1/0/all/0/1">Feng Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>, <a href="http://arxiv.org/find/eess/1/au:+Elad_M/0/1/0/all/0/1">Michael Elad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00113">
                                    <div class="article-summary-box-inner">
                                        <span>Could we compress images via standard codecs while avoiding visible
artifacts? The answer is obvious -- this is doable as long as the bit budget is
generous enough. What if the allocated bit-rate for compression is
insufficient? Then unfortunately, artifacts are a fact of life. Many attempts
were made over the years to fight this phenomenon, with various degrees of
success. In this work we aim to break the unholy connection between bit-rate
and image quality, and propose a way to circumvent compression artifacts by
pre-editing the incoming image and modifying its content to fit the given bits.
We design this editing operation as a learned convolutional neural network, and
formulate an optimization problem for its training. Our loss takes into account
a proximity between the original image and the edited one, a bit-budget penalty
over the proposed image, and a no-reference image quality measure for forcing
the outcome to be visually pleasing. The proposed approach is demonstrated on
the popular JPEG compression, showing savings in bits and/or improvements in
visual quality, obtained with intricate editing effects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Object Contour Points and Semantics for Instance Segmentation. (arXiv:2008.00460v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mai Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00460">
                                    <div class="article-summary-box-inner">
                                        <span>The attributes of object contours has great significance for instance
segmentation task. However, most of the current popular deep neural networks do
not pay much attention to the object edge information. Inspired by the human
annotation process when making instance segmentation datasets, in this paper,
we propose Mask Point R-CNN aiming at promoting the neural network&#x27;s attention
to the object boundary. Specifically, we innovatively extend the original human
keypoint detection task to the contour point detection of any object. Based on
this analogy, we present an contour point detection auxiliary task to Mask
R-CNN, which can boost the gradient flow between different tasks by effectively
using feature fusion strategies and multi-task joint training. As a
consequence, the model will be more sensitive to the edges of the object and
can capture more geometric features. Quantitatively, the experimental results
show that our approach outperforms vanilla Mask R-CNN by 3.8\% on Cityscapes
dataset and 0.8\% on COCO dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extended Few-Shot Learning: Exploiting Existing Resources for Novel Tasks. (arXiv:2012.07176v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Esfandiarpoor_R/0/1/0/all/0/1">Reza Esfandiarpoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_A/0/1/0/all/0/1">Amy Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajabdollahi_M/0/1/0/all/0/1">Mohsen Hajabdollahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1">Stephen H. Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07176">
                                    <div class="article-summary-box-inner">
                                        <span>In many practical few-shot learning problems, even though labeled examples
are scarce, there are abundant auxiliary datasets that potentially contain
useful information. We propose the problem of extended few-shot learning to
study these scenarios. We then introduce a framework to address the challenges
of efficiently selecting and effectively using auxiliary data in few-shot image
classification. Given a large auxiliary dataset and a notion of semantic
similarity among classes, we automatically select pseudo shots, which are
labeled examples from other classes related to the target task. We show that
naive approaches, such as (1) modeling these additional examples the same as
the target task examples or (2) using them to learn features via transfer
learning, only increase accuracy by a modest amount. Instead, we propose a
masking module that adjusts the features of auxiliary data to be more similar
to those of the target classes. We show that this masking module performs
better than naively modeling the support examples and transfer learning by 4.68
and 6.03 percentage points, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Domain Invariant Representations for Generalizable Person Re-Identification. (arXiv:2103.15890v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi-Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Da Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhen Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tieniu Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15890">
                                    <div class="article-summary-box-inner">
                                        <span>Generalizable person Re-Identification (ReID) has attracted growing attention
in recent computer vision community. In this work, we construct a structural
causal model among identity labels, identity-specific factors (clothes/shoes
color etc), and domain-specific factors (background, viewpoints etc). According
to the causal analysis, we propose a novel Domain Invariant Representation
Learning for generalizable person Re-Identification (DIR-ReID) framework.
Specifically, we first propose to disentangle the identity-specific and
domain-specific feature spaces, based on which we propose an effective
algorithmic implementation for backdoor adjustment, essentially serving as a
causal intervention towards the SCM. Extensive experiments have been conducted,
showing that DIR-ReID outperforms state-of-the-art methods on large-scale
domain generalization ReID benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Predictability of Pruning Across Scales. (arXiv:2006.10621v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenfeld_J/0/1/0/all/0/1">Jonathan S. Rosenfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1">Jonathan Frankle</a>, <a href="http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1">Michael Carbin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shavit_N/0/1/0/all/0/1">Nir Shavit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10621">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the error of iteratively magnitude-pruned networks empirically
follows a scaling law with interpretable coefficients that depend on the
architecture and task. We functionally approximate the error of the pruned
networks, showing it is predictable in terms of an invariant tying width,
depth, and pruning level, such that networks of vastly different pruned
densities are interchangeable. We demonstrate the accuracy of this
approximation over orders of magnitude in depth, width, dataset size, and
density. We show that the functional form holds (generalizes) for large scale
data (e.g., ImageNet) and architectures (e.g., ResNets). As neural networks
become ever larger and costlier to train, our findings suggest a framework for
reasoning conceptually and analytically about a standard method for
unstructured pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Repurposing GANs for One-shot Semantic Part Segmentation. (arXiv:2103.04379v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tritrong_N/0/1/0/all/0/1">Nontawat Tritrong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rewatbowornwong_P/0/1/0/all/0/1">Pitchaporn Rewatbowornwong</a>, <a href="http://arxiv.org/find/cs/1/au:+Suwajanakorn_S/0/1/0/all/0/1">Supasorn Suwajanakorn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04379">
                                    <div class="article-summary-box-inner">
                                        <span>While GANs have shown success in realistic image generation, the idea of
using GANs for other tasks unrelated to synthesis is underexplored. Do GANs
learn meaningful structural parts of objects during their attempt to reproduce
those objects? In this work, we test this hypothesis and propose a simple and
effective approach based on GANs for semantic part segmentation that requires
as few as one label example along with an unlabeled dataset. Our key idea is to
leverage a trained GAN to extract pixel-wise representation from the input
image and use it as feature vectors for a segmentation network. Our experiments
demonstrate that GANs representation is &quot;readily discriminative&quot; and produces
surprisingly good results that are comparable to those from supervised
baselines trained with significantly more labels. We believe this novel
repurposing of GANs underlies a new class of unsupervised representation
learning that is applicable to many other tasks. More results are available at
https://repurposegans.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 detection using deep convolutional neural networks and binary-differential-algorithm-based feature selection on X-ray images. (arXiv:2104.07279v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Iraji_M/0/1/0/all/0/1">Mohammad Saber Iraji</a>, <a href="http://arxiv.org/find/eess/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1">Mohammad-Reza Feizi-Derakhshi</a>, <a href="http://arxiv.org/find/eess/1/au:+Tanha_J/0/1/0/all/0/1">Jafar Tanha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07279">
                                    <div class="article-summary-box-inner">
                                        <span>The new Coronavirus is spreading rapidly, and it has taken the lives of many
people so far. The virus has destructive effects on the human lung, and early
detection is very important. Deep Convolution neural networks are such powerful
tools in classifying images. Therefore, in this paper, a hybrid approach based
on a deep network is presented. Feature vectors were extracted by applying a
deep convolution neural network on the images, and useful features were
selected by the binary differential meta-heuristic algorithm. These optimized
features were given to the SVM classifier. A database consisting of three
categories of images such as COVID-19, pneumonia, and healthy included in 1092
X-ray samples was considered. The proposed method achieved an accuracy of
99.43%, a sensitivity of 99.16%, and a specificity of 99.57%. Our results
demonstrate that the suggested approach is better than recent studies on
COVID-19 detection with X-ray images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OPA: Object Placement Assessment Dataset. (arXiv:2107.01889v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiangtong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1">Li Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liqing Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01889">
                                    <div class="article-summary-box-inner">
                                        <span>Image composition aims to generate realistic composite image by inserting an
object from one image into another background image, where the placement (e.g.,
location, size, occlusion) of inserted object may be unreasonable, which would
significantly degrade the quality of the composite image. Although some works
attempted to learn object placement to create realistic composite images, they
did not focus on assessing the plausibility of object placement. In this paper,
we focus on object placement assessment task, which verifies whether a
composite image is plausible in terms of the object placement. To accomplish
this task, we construct the first Object Placement Assessment (OPA) dataset
consisting of composite images and their rationality labels. Dataset is
available at https://github.com/bcmi/Object-Placement-Assessment-Dataset-OPA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AtrialGeneral: Domain Generalization for Left Atrial Segmentation of Multi-Center LGE MRIs. (arXiv:2106.08727v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zimmer_V/0/1/0/all/0/1">Veronika A. Zimmer</a>, <a href="http://arxiv.org/find/eess/1/au:+Schnabel_J/0/1/0/all/0/1">Julia A. Schnabel</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhuang_X/0/1/0/all/0/1">Xiahai Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08727">
                                    <div class="article-summary-box-inner">
                                        <span>Left atrial (LA) segmentation from late gadolinium enhanced magnetic
resonance imaging (LGE MRI) is a crucial step needed for planning the treatment
of atrial fibrillation. However, automatic LA segmentation from LGE MRI is
still challenging, due to the poor image quality, high variability in LA
shapes, and unclear LA boundary. Though deep learning-based methods can provide
promising LA segmentation results, they often generalize poorly to unseen
domains, such as data from different scanners and/or sites. In this work, we
collect 210 LGE MRIs from different centers with different levels of image
quality. To evaluate the domain generalization ability of models on the LA
segmentation task, we employ four commonly used semantic segmentation networks
for the LA segmentation from multi-center LGE MRIs. Besides, we investigate
three domain generalization strategies, i.e., histogram matching, mutual
information based disentangled representation, and random style transfer, where
a simple histogram matching is proved to be most effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Data Pipelines through the Process Lens: a Reference Model forComputer Vision. (arXiv:2107.01824v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balayn_A/0/1/0/all/0/1">Agathe Balayn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulynych_B/0/1/0/all/0/1">Bogdan Kulynych</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerses_S/0/1/0/all/0/1">Seda Guerses</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01824">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers have identified datasets used for training computer vision (CV)
models as an important source of hazardous outcomes, and continue to examine
popular CV datasets to expose their harms. These works tend to treat datasets
as objects, or focus on particular steps in data production pipelines. We argue
here that we could further systematize our analysis of harms by examining CV
data pipelines through a process-oriented lens that captures the creation, the
evolution and use of these datasets. As a step towards cultivating a
process-oriented lens, we embarked on an empirical study of CV data pipelines
informed by the field of method engineering. We present here a preliminary
result: a reference model of CV data pipelines. Besides exploring the questions
that this endeavor raises, we discuss how the process lens could support
researchers in discovering understudied issues, and could help practitioners in
making their processes more transparent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On The Distribution of Penultimate Activations of Classification Networks. (arXiv:2107.01900v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minkyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yoonho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1">Suha Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01900">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies probability distributions ofpenultimate activations of
classification networks.We show that, when a classification network istrained
with the cross-entropy loss, its final classi-fication layer forms
aGenerative-Discriminativepairwith a generative classifier based on a
specificdistribution of penultimate activations. More im-portantly, the
distribution is parameterized by theweights of the final fully-connected layer,
and canbe considered as a generative model that synthe-sizes the penultimate
activations without feedinginput data. We empirically demonstrate that
thisgenerative model enables stable knowledge dis-tillation in the presence of
domain shift, and cantransfer knowledge from a classifier to
variationalautoencoders and generative adversarial networksfor
class-conditional image generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-view Graph Learning by Joint Modeling of Consistency and Inconsistency. (arXiv:2008.10208v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Youwei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chang-Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10208">
                                    <div class="article-summary-box-inner">
                                        <span>Graph learning has emerged as a promising technique for multi-view clustering
with its ability to learn a unified and robust graph from multiple views.
However, existing graph learning methods mostly focus on the multi-view
consistency issue, yet often neglect the inconsistency across multiple views,
which makes them vulnerable to possibly low-quality or noisy datasets. To
overcome this limitation, we propose a new multi-view graph learning framework,
which for the first time simultaneously and explicitly models multi-view
consistency and multi-view inconsistency in a unified objective function,
through which the consistent and inconsistent parts of each single-view graph
as well as the unified graph that fuses the consistent parts can be iteratively
learned. Though optimizing the objective function is NP-hard, we design a
highly efficient optimization algorithm which is able to obtain an approximate
solution with linear time complexity in the number of edges in the unified
graph. Furthermore, our multi-view graph learning approach can be applied to
both similarity graphs and dissimilarity graphs, which lead to two graph
fusion-based variants in our framework. Experiments on twelve multi-view
datasets have demonstrated the robustness and efficiency of the proposed
approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FINT: Field-aware INTeraction Neural Network For CTR Prediction. (arXiv:2107.01999v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhishan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guohui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1">Dawei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01999">
                                    <div class="article-summary-box-inner">
                                        <span>As a critical component for online advertising and marking, click-through
rate (CTR) prediction has draw lots of attentions from both industry and
academia field. Recently, the deep learning has become the mainstream
methodological choice for CTR. Despite of sustainable efforts have been made,
existing approaches still pose several challenges. On the one hand, high-order
interaction between the features is under-explored. On the other hand,
high-order interactions may neglect the semantic information from the low-order
fields. In this paper, we proposed a novel prediction method, named FINT, that
employs the Field-aware INTeraction layer which captures high-order feature
interactions while retaining the low-order field information. To empirically
investigate the effectiveness and robustness of the FINT, we perform extensive
experiments on the three realistic databases: KDD2012, Criteo and Avazu. The
obtained results demonstrate that the FINT can significantly improve the
performance compared to the existing methods, without increasing the amount of
computation required. Moreover, the proposed method brought about 2.72\%
increase to the advertising revenue of a big online video app through A/B
testing. To better promote the research in CTR field, we will release our code
as well as reference implementation of those baseline models in the final
version.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Model for Fingerprint Authentication and Presentation Attack Detection. (arXiv:2104.03255v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Popli_A/0/1/0/all/0/1">Additya Popli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tandon_S/0/1/0/all/0/1">Saraansh Tandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelsma_J/0/1/0/all/0/1">Joshua J. Engelsma</a>, <a href="http://arxiv.org/find/cs/1/au:+Onoe_N/0/1/0/all/0/1">Naoyuki Onoe</a>, <a href="http://arxiv.org/find/cs/1/au:+Okubo_A/0/1/0/all/0/1">Atsushi Okubo</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_A/0/1/0/all/0/1">Anoop Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03255">
                                    <div class="article-summary-box-inner">
                                        <span>Typical fingerprint recognition systems are comprised of a spoof detection
module and a subsequent recognition module, running one after the other. In
this paper, we reformulate the workings of a typical fingerprint recognition
system. In particular, we posit that both spoof detection and fingerprint
recognition are correlated tasks. Therefore, rather than performing the two
tasks separately, we propose a joint model for spoof detection and matching to
simultaneously perform both tasks without compromising the accuracy of either
task. We demonstrate the capability of our joint model to obtain an
authentication accuracy (1:1 matching) of TAR &#x3D; 100% @ FAR &#x3D; 0.1% on the FVC
2006 DB2A dataset while achieving a spoof detection ACE of 1.44% on the LiveDet
2015 dataset, both maintaining the performance of stand-alone methods. In
practice, this reduces the time and memory requirements of the fingerprint
recognition system by 50% and 40%, respectively; a significant advantage for
recognition systems running on resource-constrained devices and communication
channels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Contrastive Learning with Hard Negative Sampling for Self-supervised Point Cloud Learning. (arXiv:2107.01886v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1">Bi&#x27;an Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01886">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds have attracted increasing attention as a natural representation
of 3D shapes. Significant progress has been made in developing methods for
point cloud analysis, which often requires costly human annotation as
supervision in practice. To address this issue, we propose a novel
self-contrastive learning for self-supervised point cloud representation
learning, aiming to capture both local geometric patterns and nonlocal semantic
primitives based on the nonlocal self-similarity of point clouds. The
contributions are two-fold: on the one hand, instead of contrasting among
different point clouds as commonly employed in contrastive learning, we exploit
self-similar point cloud patches within a single point cloud as positive
samples and otherwise negative ones to facilitate the task of contrastive
learning. Such self-contrastive learning is well aligned with the emerging
paradigm of self-supervised learning for point cloud analysis. On the other
hand, we actively learn hard negative samples that are close to positive
samples in the representation space for discriminative feature learning, which
are sampled conditional on each anchor patch leveraging on the degree of
self-similarity. Experimental results show that the proposed method achieves
state-of-the-art performance on widely used benchmark datasets for
self-supervised point cloud segmentation and transfer learning for
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Styleformer: Transformer based Generative Adversarial Networks with Style Vector. (arXiv:2106.07023v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jeeseung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Younggeun Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07023">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Styleformer, which is a style-based generator for GAN
architecture, but a convolution-free transformer-based generator. In our paper,
we explain how a transformer can generate high-quality images, overcoming the
disadvantage that convolution operations are difficult to capture global
features in an image. Furthermore, we change the demodulation of StyleGAN2 and
modify the existing transformer structure (e.g., residual connection, layer
normalization) to create a strong style-based generator with a convolution-free
structure. We also make Styleformer lighter by applying Linformer, enabling
Styleformer to generate higher resolution images and result in improvements in
terms of speed and memory. We experiment with the low-resolution image dataset
such as CIFAR-10, as well as the high-resolution image dataset like
LSUN-church. Styleformer records FID 2.82 and IS 9.94 on CIFAR-10, a benchmark
dataset, which is comparable performance to the current state-of-the-art and
outperforms all GAN-based generative models, including StyleGAN2-ADA with fewer
parameters on the unconditional setting. We also both achieve new
state-of-the-art with FID 15.17, IS 11.01, and FID 3.66, respectively on STL-10
and CelebA. We release our code at
https://github.com/Jeeseung-Park/Styleformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-View Correlation Distillation for Incremental Object Detection. (arXiv:2107.01787v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Dongbao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01787">
                                    <div class="article-summary-box-inner">
                                        <span>In real applications, new object classes often emerge after the detection
model has been trained on a prepared dataset with fixed classes. Due to the
storage burden and the privacy of old data, sometimes it is impractical to
train the model from scratch with both old and new data. Fine-tuning the old
model with only new data will lead to a well-known phenomenon of catastrophic
forgetting, which severely degrades the performance of modern object detectors.
In this paper, we propose a novel \textbf{M}ulti-\textbf{V}iew
\textbf{C}orrelation \textbf{D}istillation (MVCD) based incremental object
detection method, which explores the correlations in the feature space of the
two-stage object detector (Faster R-CNN). To better transfer the knowledge
learned from the old classes and maintain the ability to learn new classes, we
design correlation distillation losses from channel-wise, point-wise and
instance-wise views to regularize the learning of the incremental model. A new
metric named Stability-Plasticity-mAP is proposed to better evaluate both the
stability for old classes and the plasticity for new classes in incremental
object detection. The extensive experiments conducted on VOC2007 and COCO
demonstrate that MVCD can effectively learn to detect objects of new classes
and mitigate the problem of catastrophic forgetting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Geometric Factors in Model Learning and Inference for Object Detection and Instance Segmentation. (arXiv:2005.03572v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhaohui Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Ping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_D/0/1/0/all/0/1">Dongwei Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_R/0/1/0/all/0/1">Rongguang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1">Qinghua Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1">Wangmeng Zuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03572">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based object detection and instance segmentation have achieved
unprecedented progress. In this paper, we propose Complete-IoU (CIoU) loss and
Cluster-NMS for enhancing geometric factors in both bounding box regression and
Non-Maximum Suppression (NMS), leading to notable gains of average precision
(AP) and average recall (AR), without the sacrifice of inference efficiency. In
particular, we consider three geometric factors, i.e., overlap area, normalized
central point distance and aspect ratio, which are crucial for measuring
bounding box regression in object detection and instance segmentation. The
three geometric factors are then incorporated into CIoU loss for better
distinguishing difficult regression cases. The training of deep models using
CIoU loss results in consistent AP and AR improvements in comparison to widely
adopted $\ell_n$-norm loss and IoU-based loss. Furthermore, we propose
Cluster-NMS, where NMS during inference is done by implicitly clustering
detected boxes and usually requires less iterations. Cluster-NMS is very
efficient due to its pure GPU implementation, and geometric factors can be
incorporated to improve both AP and AR. In the experiments, CIoU loss and
Cluster-NMS have been applied to state-of-the-art instance segmentation (e.g.,
YOLACT and BlendMask-RT), and object detection (e.g., YOLO v3, SSD and Faster
R-CNN) models. Taking YOLACT on MS COCO as an example, our method achieves
performance gains as +1.7 AP and +6.2 AR$_{100}$ for object detection, and +0.9
AP and +3.5 AR$_{100}$ for instance segmentation, with 27.1 FPS on one NVIDIA
GTX 1080Ti GPU. All the source code and trained models are available at
https://github.com/Zzh-tju/CIoU</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphXCOVID: Explainable Deep Graph Diffusion Pseudo-Labelling for Identifying COVID-19 on Chest X-rays. (arXiv:2010.00378v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1">Angelica I Aviles-Rivero</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellars_P/0/1/0/all/0/1">Philip Sellars</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Sch&#xf6;nlieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadakis_N/0/1/0/all/0/1">Nicolas Papadakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00378">
                                    <div class="article-summary-box-inner">
                                        <span>Can one learn to diagnose COVID-19 under extreme minimal supervision? Since
the outbreak of the novel COVID-19 there has been a rush for developing
Artificial Intelligence techniques for expert-level disease identification on
Chest X-ray data. In particular, the use of deep supervised learning has become
the go-to paradigm. However, the performance of such models is heavily
dependent on the availability of a large and representative labelled dataset.
The creation of which is a heavily expensive and time consuming task, and
especially imposes a great challenge for a novel disease. Semi-supervised
learning has shown the ability to match the incredible performance of
supervised models whilst requiring a small fraction of the labelled examples.
This makes the semi-supervised paradigm an attractive option for identifying
COVID-19. In this work, we introduce a graph based deep semi-supervised
framework for classifying COVID-19 from chest X-rays. Our framework introduces
an optimisation model for graph diffusion that reinforces the natural relation
among the tiny labelled set and the vast unlabelled data. We then connect the
diffusion prediction output as pseudo-labels that are used in an iterative
scheme in a deep net. We demonstrate, through our experiments, that our model
is able to outperform the current leading supervised model with a tiny fraction
of the labelled examples. Finally, we provide attention maps to accommodate the
radiologist&#x27;s mental model, better fitting their perceptual and cognitive
abilities. These visualisation aims to assist the radiologist in judging
whether the diagnostic is correct or not, and in consequence to accelerate the
decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Least Squares Normalized Cross Correlation. (arXiv:1810.04320v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woodford_O/0/1/0/all/0/1">Oliver J. Woodford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1810.04320">
                                    <div class="article-summary-box-inner">
                                        <span>Direct methods are widely used for alignment of models to images, due to
their accuracy, since they minimize errors in the domain of measurement noise.
They have leveraged least squares minimizations, for simple, efficient,
variational optimization, since the seminal 1981 work of Lucas &amp; Kanade, and
normalized cross correlation (NCC), for robustness to intensity variations,
since at least 1972. Despite the complementary benefits of these two well known
methods, they have not been effectively combined to address local variations in
intensity. Many ad-hoc NCC frameworks, sub-optimal least squares methods and
image transformation approaches have thus been proposed instead, each with
their own limitations. This work shows that a least squares optimization of NCC
without approximation is not only possible, but straightforward and efficient.
A robust, locally normalized formulation is introduced to mitigate local
intensity variations and partial occlusions. Finally, sparse features with
oriented patches are proposed for further efficiency. The resulting framework
is simple to implement, computationally efficient and robust to local intensity
variations. It is evaluated on the image alignment problem, showing
improvements in both convergence rate and computation time over existing
lighting invariant methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images. (arXiv:1905.10488v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cha_S/0/1/0/all/0/1">Sungmin Cha</a>, <a href="http://arxiv.org/find/eess/1/au:+Park_T/0/1/0/all/0/1">Taeeon Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_B/0/1/0/all/0/1">Byeongjoon Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Baek_J/0/1/0/all/0/1">Jongduk Baek</a>, <a href="http://arxiv.org/find/eess/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10488">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle a challenging blind image denoising problem, in which only single
distinct noisy images are available for training a denoiser, and no information
about noise is known, except for it being zero-mean, additive, and independent
of the clean image. In such a setting, which often occurs in practice, it is
not possible to train a denoiser with the standard discriminative training or
with the recently developed Noise2Noise (N2N) training; the former requires the
underlying clean image for the given noisy image, and the latter requires two
independently realized noisy image pair for a clean image. To that end, we
propose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise)
method that first learns a generative model that can 1) simulate the noise in
the given noisy images and 2) generate a rough, noisy estimates of the clean
images, then 3) iteratively trains a denoiser with subsequently synthesized
noisy image pairs (as in N2N), obtained from the generative model. In results,
we show the denoiser trained with our GAN2GAN achieves an impressive denoising
performance on both synthetic and real-world datasets for the blind denoising
setting; it almost approaches the performance of the standard
discriminatively-trained or N2N-trained models that have more information than
ours, and it significantly outperforms the recent baseline for the same
setting, \textit{e.g.}, Noise2Void, and a more conventional yet strong one,
BM3D. The official code of our method is available at
https://github.com/csm9493/GAN2GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Relate Depth and Semantics for Unsupervised Domain Adaptation. (arXiv:2105.07830v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Suman Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Obukhov_A/0/1/0/all/0/1">Anton Obukhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudel_D/0/1/0/all/0/1">Danda Pani Paudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanakis_M/0/1/0/all/0/1">Menelaos Kanakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuhua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1">Stamatios Georgoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07830">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for encoding visual task relationships to improve
model performance in an Unsupervised Domain Adaptation (UDA) setting. Semantic
segmentation and monocular depth estimation are shown to be complementary
tasks; in a multi-task learning setting, a proper encoding of their
relationships can further improve performance on both tasks. Motivated by this
observation, we propose a novel Cross-Task Relation Layer (CTRL), which encodes
task dependencies between the semantic and depth predictions. To capture the
cross-task relationships, we propose a neural network architecture that
contains task-specific and cross-task refinement heads. Furthermore, we propose
an Iterative Self-Learning (ISL) training scheme, which exploits semantic
pseudo-labels to provide extra supervision on the target domain. We
experimentally observe improvements in both tasks&#x27; performance because the
complementary information present in these tasks is better captured.
Specifically, we show that: (1) our approach improves performance on all tasks
when they are complementary and mutually dependent; (2) the CTRL helps to
improve both semantic segmentation and depth estimation tasks performance in
the challenging UDA setting; (3) the proposed ISL training scheme further
improves the semantic segmentation performance. The implementation is available
at https://github.com/susaha/ctrl-uda.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaze Estimation with an Ensemble of Four Architectures. (arXiv:2107.01980v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1">Xin Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Jiabei Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiajun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yunjia Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zhilong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Shiguang Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01980">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a method for gaze estimation according to face images. We
train several gaze estimators adopting four different network architectures,
including an architecture designed for gaze estimation (i.e.,iTracker-MHSA) and
three originally designed for general computer vision tasks(i.e., BoTNet,
HRNet, ResNeSt). Then, we select the best six estimators and ensemble their
predictions through a linear combination. The method ranks the first on the
leader-board of ETH-XGaze Competition, achieving an average angular error of
$3.11^{\circ}$ on the ETH-XGaze test set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure by Architecture: Disentangled Representations without Regularization. (arXiv:2006.07796v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1">Felix Leeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanzillotta_G/0/1/0/all/0/1">Guilia Lanzillotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Annadani_Y/0/1/0/all/0/1">Yashas Annadani</a>, <a href="http://arxiv.org/find/cs/1/au:+Besserve_M/0/1/0/all/0/1">Michel Besserve</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07796">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of self-supervised structured representation learning
using autoencoders for generative modeling. Unlike most methods which rely on
matching an arbitrary, relatively unstructured, prior distribution for
sampling, we propose a sampling technique that relies solely on the
independence of latent variables, thereby avoiding the trade-off between
reconstruction quality and generative performance inherent to VAEs. We design a
novel autoencoder architecture capable of learning a structured representation
without the need for aggressive regularization. Our structural decoders learn a
hierarchy of latent variables, akin to structural causal models, thereby
ordering the information without any additional regularization. We demonstrate
how these models learn a representation that improves results in a variety of
downstream tasks including generation, disentanglement, and extrapolation using
several challenging and natural image datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quality-Aware Memory Network for Interactive Volumetric Image Segmentation. (arXiv:2106.10686v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianfei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liulei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bredell_G/0/1/0/all/0/1">Gustav Bredell</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianwu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1">Ender Konukoglu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10686">
                                    <div class="article-summary-box-inner">
                                        <span>Despite recent progress of automatic medical image segmentation techniques,
fully automatic results usually fail to meet the clinical use and typically
require further refinement. In this work, we propose a quality-aware memory
network for interactive segmentation of 3D medical images. Provided by user
guidance on an arbitrary slice, an interaction network is firstly employed to
obtain an initial 2D segmentation. The quality-aware memory network
subsequently propagates the initial segmentation estimation bidirectionally
over the entire volume. Subsequent refinement based on additional user guidance
on other slices can be incorporated in the same manner. To further facilitate
interactive segmentation, a quality assessment module is introduced to suggest
the next slice to segment based on the current segmentation quality of each
slice. The proposed network has two appealing characteristics: 1) The
memory-augmented network offers the ability to quickly encode past segmentation
information, which will be retrieved for the segmentation of other slices; 2)
The quality assessment module enables the model to directly estimate the
qualities of segmentation predictions, which allows an active learning paradigm
where users preferentially label the lowest-quality slice for multi-round
refinement. The proposed network leads to a robust interactive segmentation
engine, which can generalize well to various types of user annotations (e.g.,
scribbles, boxes). Experimental results on various medical datasets demonstrate
the superiority of our approach in comparison with existing techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D Skeleton Based Person Re-Identification. (arXiv:2009.03671v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_H/0/1/0/all/0/1">Haocong Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Siqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiping Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xinwang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03671">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (Re-ID) via gait features within 3D skeleton
sequences is a newly-emerging topic with several advantages. Existing solutions
either rely on hand-crafted descriptors or supervised gait representation
learning. This paper proposes a self-supervised gait encoding approach that can
leverage unlabeled skeleton data to learn gait representations for person
Re-ID. Specifically, we first create self-supervision by learning to
reconstruct unlabeled skeleton sequences reversely, which involves richer
high-level semantics to obtain better gait representations. Other pretext tasks
are also explored to further improve self-supervised learning. Second, inspired
by the fact that motion&#x27;s continuity endows adjacent skeletons in one skeleton
sequence and temporally consecutive skeleton sequences with higher correlations
(referred as locality in 3D skeleton data), we propose a locality-aware
attention mechanism and a locality-aware contrastive learning scheme, which aim
to preserve locality-awareness on intra-sequence level and inter-sequence level
respectively during self-supervised learning. Last, with context vectors
learned by our locality-aware attention mechanism and contrastive learning
scheme, a novel feature named Constrastive Attention-based Gait Encodings
(CAGEs) is designed to represent gait effectively. Empirical evaluations show
that our approach significantly outperforms skeleton-based counterparts by
15-40% Rank-1 accuracy, and it even achieves superior performance to numerous
multi-modal methods with extra RGB or depth information. Our codes are
available at https://github.com/Kali-Hac/Locality-Awareness-SGE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning. (arXiv:2105.15134v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zixin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15134">
                                    <div class="article-summary-box-inner">
                                        <span>How can neural networks trained by contrastive learning extract features from
the unlabeled data? Why does contrastive learning usually need much stronger
data augmentations than supervised learning to ensure good representations?
These questions involve both the optimization and statistical aspects of deep
learning, but can hardly be answered by analyzing supervised learning, where
the target functions are the highest pursuit. Indeed, in self-supervised
learning, it is inevitable to relate to the optimization/generalization of
neural networks to how they can encode the latent structures in the data, which
we refer to as the feature learning process.

In this work, we formally study how contrastive learning learns the feature
representations for neural networks by analyzing its feature learning process.
We consider the case where our data are comprised of two types of features: the
more semantically aligned sparse features which we want to learn from, and the
other dense features we want to avoid. Theoretically, we prove that contrastive
learning using $\mathbf{ReLU}$ networks provably learns the desired sparse
features if proper augmentations are adopted. We present an underlying
principle called $\textbf{feature decoupling}$ to explain the effects of
augmentations, where we theoretically characterize how augmentations can reduce
the correlations of dense features between positive samples while keeping the
correlations of sparse features intact, thereby forcing the neural networks to
learn from the self-supervision of sparse features. Empirically, we verified
that the feature decoupling principle matches the underlying mechanism of
contrastive learning in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ray-ONet: Efficient 3D Reconstruction From A Single RGB Image. (arXiv:2107.01899v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bian_W/0/1/0/all/0/1">Wenjing Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zirui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kejie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Prisacariu_V/0/1/0/all/0/1">Victor Adrian Prisacariu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01899">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Ray-ONet to reconstruct detailed 3D models from monocular images
efficiently. By predicting a series of occupancy probabilities along a ray that
is back-projected from a pixel in the camera coordinate, our method Ray-ONet
improves the reconstruction accuracy in comparison with Occupancy Networks
(ONet), while reducing the network inference complexity to O($N^2$). As a
result, Ray-ONet achieves state-of-the-art performance on the ShapeNet
benchmark with more than 20$\times$ speed-up at $128^3$ resolution and
maintains a similar memory footprint during inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bag of Instances Aggregation Boosts Self-supervised Learning. (arXiv:2107.01691v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haohang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1">Jiemin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaopeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lingxi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinggang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wenrui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hongkai Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01691">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-supervised learning have experienced remarkable
progress, especially for contrastive learning based methods, which regard each
image as well as its augmentations as an individual class and try to
distinguish them from all other images. However, due to the large quantity of
exemplars, this kind of pretext task intrinsically suffers from slow
convergence and is hard for optimization. This is especially true for small
scale models, which we find the performance drops dramatically comparing with
its supervised counterpart. In this paper, we propose a simple but effective
distillation strategy for unsupervised learning. The highlight is that the
relationship among similar samples counts and can be seamlessly transferred to
the student to boost the performance. Our method, termed as BINGO, which is
short for \textbf{B}ag of \textbf{I}nsta\textbf{N}ces
a\textbf{G}gregati\textbf{O}n, targets at transferring the relationship learned
by the teacher to the student. Here bag of instances indicates a set of similar
samples constructed by the teacher and are grouped within a bag, and the goal
of distillation is to aggregate compact representations over the student with
respect to instances in a bag. Notably, BINGO achieves new state-of-the-art
performance on small scale models, \emph{i.e.}, 65.5% and 68.9% top-1
accuracies with linear evaluation on ImageNet, using ResNet-18 and ResNet-34 as
backbone, respectively, surpassing baselines (52.5% and 57.4% top-1 accuracies)
by a significant margin. The code will be available at
\url{https://github.com/haohang96/bingo}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sensor-invariant Fingerprint ROI Segmentation Using Recurrent Adversarial Learning. (arXiv:2107.01361v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_I/0/1/0/all/0/1">Indu Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Utkarsh_A/0/1/0/all/0/1">Ayush Utkarsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_R/0/1/0/all/0/1">Riya Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod K Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dantcheva_A/0/1/0/all/0/1">Antitza Dantcheva</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Sumantra Dutta Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalra_P/0/1/0/all/0/1">Prem Kumar Kalra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01361">
                                    <div class="article-summary-box-inner">
                                        <span>A fingerprint region of interest (roi) segmentation algorithm is designed to
separate the foreground fingerprint from the background noise. All the learning
based state-of-the-art fingerprint roi segmentation algorithms proposed in the
literature are benchmarked on scenarios when both training and testing
databases consist of fingerprint images acquired from the same sensors.
However, when testing is conducted on a different sensor, the segmentation
performance obtained is often unsatisfactory. As a result, every time a new
fingerprint sensor is used for testing, the fingerprint roi segmentation model
needs to be re-trained with the fingerprint image acquired from the new sensor
and its corresponding manually marked ROI. Manually marking fingerprint ROI is
expensive because firstly, it is time consuming and more importantly, requires
domain expertise. In order to save the human effort in generating annotations
required by state-of-the-art, we propose a fingerprint roi segmentation model
which aligns the features of fingerprint images derived from the unseen sensor
such that they are similar to the ones obtained from the fingerprints whose
ground truth roi masks are available for training. Specifically, we propose a
recurrent adversarial learning based feature alignment network that helps the
fingerprint roi segmentation model to learn sensor-invariant features.
Consequently, sensor-invariant features learnt by the proposed roi segmentation
model help it to achieve improved segmentation performance on fingerprints
acquired from the new sensor. Experiments on publicly available FVC databases
demonstrate the efficacy of the proposed work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Model for Inferring a Spatial Road Lane Network Graph using Self-Supervision. (arXiv:2107.01784v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1">Robin Karlsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1">David Robert Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_S/0/1/0/all/0/1">Simon Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1">Kazuya Takeda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01784">
                                    <div class="article-summary-box-inner">
                                        <span>Interconnected road lanes are a central concept for navigating urban roads.
Currently, most autonomous vehicles rely on preconstructed lane maps as
designing an algorithmic model is difficult. However, the generation and
maintenance of such maps is costly and hinders large-scale adoption of
autonomous vehicle technology. This paper presents the first self-supervised
learning method to train a model to infer a spatially grounded lane-level road
network graph based on a dense segmented representation of the road scene
generated from onboard sensors. A formal road lane network model is presented
and proves that any structured road scene can be represented by a directed
acyclic graph of at most depth three while retaining the notion of intersection
regions, and that this is the most compressed representation. The formal model
is implemented by a hybrid neural and search-based model, utilizing a novel
barrier function loss formulation for robust learning from partial labels.
Experiments are conducted for all common road intersection layouts. Results
show that the model can generalize to new road layouts, unlike previous
approaches, demonstrating its potential for real-world application as a
practical learning-based lane-level map generator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imaging dynamics beneath turbid media via parallelized single-photon detection. (arXiv:2107.01422v1 [physics.optics])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Xu_S/0/1/0/all/0/1">Shiqi Xu</a>, <a href="http://arxiv.org/find/physics/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_W/0/1/0/all/0/1">Wenhui Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Jonsson_J/0/1/0/all/0/1">Joakim Jonsson</a>, <a href="http://arxiv.org/find/physics/1/au:+Qian_R/0/1/0/all/0/1">Ruobing Qian</a>, <a href="http://arxiv.org/find/physics/1/au:+Konda_P/0/1/0/all/0/1">Pavan Chandra Konda</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhou_K/0/1/0/all/0/1">Kevin C. Zhou</a>, <a href="http://arxiv.org/find/physics/1/au:+Dai_Q/0/1/0/all/0/1">Qionghai Dai</a>, <a href="http://arxiv.org/find/physics/1/au:+Wang_H/0/1/0/all/0/1">Haoqian Wang</a>, <a href="http://arxiv.org/find/physics/1/au:+Berrocal_E/0/1/0/all/0/1">Edouard Berrocal</a>, <a href="http://arxiv.org/find/physics/1/au:+Horstmeyer_R/0/1/0/all/0/1">Roarke Horstmeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01422">
                                    <div class="article-summary-box-inner">
                                        <span>Noninvasive optical imaging through dynamic scattering media has numerous
important biomedical applications but still remains a challenging task. While
standard methods aim to form images based upon optical absorption or
fluorescent emission, it is also well-established that the temporal correlation
of scattered coherent light diffuses through tissue much like optical
intensity. Few works to date, however, have aimed to experimentally measure and
process such data to demonstrate deep-tissue imaging of decorrelation dynamics.
In this work, we take advantage of a single-photon avalanche diode (SPAD) array
camera, with over one thousand detectors, to simultaneously detect speckle
fluctuations at the single-photon level from 12 different phantom tissue
surface locations delivered via a customized fiber bundle array. We then apply
a deep neural network to convert the acquired single-photon measurements into
video of scattering dynamics beneath rapidly decorrelating liquid tissue
phantoms. We demonstrate the ability to record video of dynamic events
occurring 5-8 mm beneath a decorrelating tissue phantom with mm-scale
resolution and at a 2.5-10 Hz frame rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pulmonary Vessel Segmentation based on Orthogonal Fused U-Net++ of Chest CT Images. (arXiv:2107.01502v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xinglong Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_N/0/1/0/all/0/1">Ning Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01502">
                                    <div class="article-summary-box-inner">
                                        <span>Pulmonary vessel segmentation is important for clinical diagnosis of
pulmonary diseases, while is also challenging due to the complicated structure.
In this work, we present an effective framework and refinement process of
pulmonary vessel segmentation from chest computed tomographic (CT) images. The
key to our approach is a 2.5D segmentation network applied from three
orthogonal axes, which presents a robust and fully automated pulmonary vessel
segmentation result with lower network complexity and memory usage compared to
3D networks. The slice radius is introduced to convolve the adjacent
information of the center slice and the multi-planar fusion optimizes the
presentation of intra- and inter- slice features. Besides, the tree-like
structure of the pulmonary vessel is extracted in the post-processing process,
which is used for segmentation refining and pruning. In the evaluation
experiments, three fusion methods are tested and the most promising one is
compared with the state-of-the-art 2D and 3D structures on 300 cases of lung
images randomly selected from LIDC dataset. Our method outperforms other
network structures by a large margin and achieves by far the highest average
DICE score of 0.9272 and precision of 0.9310, as per our knowledge from the
pulmonary vessel segmentation models available in the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Uncertainty Guided Noise-aware Preprocessing Of Fingerprints. (arXiv:2107.01248v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_I/0/1/0/all/0/1">Indu Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Utkarsh_A/0/1/0/all/0/1">Ayush Utkarsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_R/0/1/0/all/0/1">Riya Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod K Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dantcheva_A/0/1/0/all/0/1">Antitza Dantcheva</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Sumantra Dutta Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalra_P/0/1/0/all/0/1">Prem Kumar Kalra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01248">
                                    <div class="article-summary-box-inner">
                                        <span>The effectiveness of fingerprint-based authentication systems on good quality
fingerprints is established long back. However, the performance of standard
fingerprint matching systems on noisy and poor quality fingerprints is far from
satisfactory. Towards this, we propose a data uncertainty-based framework which
enables the state-of-the-art fingerprint preprocessing models to quantify noise
present in the input image and identify fingerprint regions with background
noise and poor ridge clarity. Quantification of noise helps the model two
folds: firstly, it makes the objective function adaptive to the noise in a
particular input fingerprint and consequently, helps to achieve robust
performance on noisy and distorted fingerprint regions. Secondly, it provides a
noise variance map which indicates noisy pixels in the input fingerprint image.
The predicted noise variance map enables the end-users to understand erroneous
predictions due to noise present in the input image. Extensive experimental
evaluation on 13 publicly available fingerprint databases, across different
architectural choices and two fingerprint processing tasks demonstrate
effectiveness of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Better Adversarial Synthesis of Human Images from Text. (arXiv:2107.01869v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Briq_R/0/1/0/all/0/1">Rania Briq</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochar_P/0/1/0/all/0/1">Pratika Kochar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01869">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an approach that generates multiple 3D human meshes from
text. The human shapes are represented by 3D meshes based on the SMPL model.
The model&#x27;s performance is evaluated on the COCO dataset, which contains
challenging human shapes and intricate interactions between individuals. The
model is able to capture the dynamics of the scene and the interactions between
individuals based on text. We further show how using such a shape as input to
image synthesis frameworks helps to constrain the network to synthesize humans
with realistic human shapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Custom Deep Neural Network for 3D Covid Chest CT-scan Classification. (arXiv:2107.01456v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Trinh_Q/0/1/0/all/0/1">Quoc Huy Trinh</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_M/0/1/0/all/0/1">Minh Van Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01456">
                                    <div class="article-summary-box-inner">
                                        <span>3D CT-scan base on chest is one of the controversial topisc of the researcher
nowadays. There are many tasks to diagnose the disease through CT-scan images,
include Covid19. In this paper, we propose a method that custom and combine
Deep Neural Network to classify the series of 3D CT-scans chest images. In our
methods, we experiment with 2 backbones is DenseNet 121 and ResNet 101. In this
proposal, we separate the experiment into 2 tasks, one is for 2 backbones
combination of ResNet and DenseNet, one is for DenseNet backbones combination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VinDr-RibCXR: A Benchmark Dataset for Automatic Segmentation and Labeling of Individual Ribs on Chest X-rays. (arXiv:2107.01327v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_H/0/1/0/all/0/1">Hoang C. Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Le_T/0/1/0/all/0/1">Tung T. Le</a>, <a href="http://arxiv.org/find/eess/1/au:+Pham_H/0/1/0/all/0/1">Hieu H. Pham</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_H/0/1/0/all/0/1">Ha Q. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01327">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new benchmark dataset, namely VinDr-RibCXR, for automatic
segmentation and labeling of individual ribs from chest X-ray (CXR) scans. The
VinDr-RibCXR contains 245 CXRs with corresponding ground truth annotations
provided by human experts. A set of state-of-the-art segmentation models are
trained on 196 images from the VinDr-RibCXR to segment and label 20 individual
ribs. Our best performing model obtains a Dice score of 0.834 (95% CI,
0.810--0.853) on an independent test set of 49 images. Our study, therefore,
serves as a proof of concept and baseline performance for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Similarity-Aware Fusion Network for 3D Semantic Segmentation. (arXiv:2107.01579v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Linqing Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01579">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a similarity-aware fusion network (SAFNet) to
adaptively fuse 2D images and 3D point clouds for 3D semantic segmentation.
Existing fusion-based methods achieve remarkable performances by integrating
information from multiple modalities. However, they heavily rely on the
correspondence between 2D pixels and 3D points by projection and can only
perform the information fusion in a fixed manner, and thus their performances
cannot be easily migrated to a more realistic scenario where the collected data
often lack strict pair-wise features for prediction. To address this, we employ
a late fusion strategy where we first learn the geometric and contextual
similarities between the input and back-projected (from 2D pixels) point clouds
and utilize them to guide the fusion of two modalities to further exploit
complementary information. Specifically, we employ a geometric similarity
module (GSM) to directly compare the spatial coordinate distributions of
pair-wise 3D neighborhoods, and a contextual similarity module (CSM) to
aggregate and compare spatial contextual information of corresponding central
points. The two proposed modules can effectively measure how much image
features can help predictions, enabling the network to adaptively adjust the
contributions of two modalities to the final prediction of each point.
Experimental results on the ScanNetV2 benchmark demonstrate that SAFNet
significantly outperforms existing state-of-the-art fusion-based approaches
across various data integrity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative Cases and Vaticinating the Probability of Maturation to ARDS using Posteroanterior Chest X-Rays. (arXiv:2107.01392v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kumar_P/0/1/0/all/0/1">Peeyush Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Gangal_A/0/1/0/all/0/1">Ayushe Gangal</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumari_S/0/1/0/all/0/1">Sunita Kumari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01392">
                                    <div class="article-summary-box-inner">
                                        <span>Coronavirus is a large virus family consisting of diverse viruses, some of
which disseminate among mammals and others cause sickness among humans.
COVID-19 is highly contagious and is rapidly spreading, rendering its early
diagnosis of preeminent status. Researchers, medical specialists and
organizations all over the globe have been working tirelessly to combat this
virus and help in its containment. In this paper, a novel neural network called
WisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays.
The WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is
a two-layered convolutional Neural Network (CNN), which takes chest x-ray
images as input. Both layers of the proposed neural network consist of a number
of neural networks each. The dataset used for this study consists of chest
x-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on
GitHub, and the chest x-ray images of healthy lungs and lungs affected by viral
and bacterial pneumonia were obtained from Kaggle. The network not only
pinpoints the presence of COVID-19, but also gives the probability of the
disease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus,
predicting the progression of the disease in the COVID-19 positive patients.
The network also slender the occurrences of false negative cases by employing a
high threshold value, thus aids in curbing the spread of the disease and gives
an accuracy of 100% for successfully predicting COVID-19 among the chest x-rays
of patients affected with COVID-19, bacterial and viral pneumonia.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Hierarchical Graph Neural Networks for Image Clustering. (arXiv:2107.01319v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1">Yifan Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tianjun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1">David Wipf Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01319">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a hierarchical graph neural network (GNN) model that learns how to
cluster a set of images into an unknown number of identities using a training
set of images annotated with labels belonging to a disjoint set of identities.
Our hierarchical GNN uses a novel approach to merge connected components
predicted at each level of the hierarchy to form a new graph at the next level.
Unlike fully unsupervised hierarchical clustering, the choice of grouping and
complexity criteria stems naturally from supervision in the training set. The
resulting method, Hi-LANDER, achieves an average of 54% improvement in F-score
and 8% increase in Normalized Mutual Information (NMI) relative to current
GNN-based clustering algorithms. Additionally, state-of-the-art GNN-based
methods rely on separate models to predict linkage probabilities and node
densities as intermediate steps of the clustering process. In contrast, our
unified framework achieves a seven-fold decrease in computational cost. We
release our training and inference code at
https://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable cardiac synthesis via disentangled anatomy arithmetic. (arXiv:2107.01748v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thermos_S/0/1/0/all/0/1">Spyridon Thermos</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+ONeil_A/0/1/0/all/0/1">Alison O&#x27;Neil</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsaftaris_S/0/1/0/all/0/1">Sotirios A. Tsaftaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01748">
                                    <div class="article-summary-box-inner">
                                        <span>Acquiring annotated data at scale with rare diseases or conditions remains a
challenge. It would be extremely useful to have a method that controllably
synthesizes images that can correct such underrepresentation. Assuming a proper
latent representation, the idea of a &quot;latent vector arithmetic&quot; could offer the
means of achieving such synthesis. A proper representation must encode the
fidelity of the input data, preserve invariance and equivariance, and permit
arithmetic operations. Motivated by the ability to disentangle images into
spatial anatomy (tensor) factors and accompanying imaging (vector)
representations, we propose a framework termed &quot;disentangled anatomy
arithmetic&quot;, in which a generative model learns to combine anatomical factors
of different input images such that when they are re-entangled with the desired
imaging modality (e.g. MRI), plausible new cardiac images are created with the
target characteristics. To encourage a realistic combination of anatomy factors
after the arithmetic step, we propose a localized noise injection network that
precedes the generator. Our model is used to generate realistic images,
pathology labels, and segmentation masks that are used to augment the existing
datasets and subsequently improve post-hoc classification and segmentation
tasks. Code is publicly available at https://github.com/vios-s/DAA-GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A study of CNN capacity applied to Left Venticle Segmentation in Cardiac MRI. (arXiv:2107.01318v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Toledo_M/0/1/0/all/0/1">Marcelo Toledo</a>, <a href="http://arxiv.org/find/eess/1/au:+Lima_D/0/1/0/all/0/1">Daniel Lima</a>, <a href="http://arxiv.org/find/eess/1/au:+Krieger_J/0/1/0/all/0/1">Jos&#xe9; Krieger</a>, <a href="http://arxiv.org/find/eess/1/au:+Gutierrez_M/0/1/0/all/0/1">Marco Gutierrez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01318">
                                    <div class="article-summary-box-inner">
                                        <span>CNN (Convolutional Neural Network) models have been successfully used for
segmentation of the left ventricle (LV) in cardiac MRI (Magnetic Resonance
Imaging), providing clinical measurements.In practice, two questions arise with
deployment of CNNs: 1) when is it better to use a shallow model instead of a
deeper one? 2) how the size of a dataset might change the network performance?
We propose a framework to answer them, by experimenting with deep and shallow
versions of three U-Net families, trained from scratch in six subsets varying
from 100 to 10,000 images, different network sizes, learning rates and
regularization values. 1620 models were evaluated using 5-foldcross-validation
by loss and DICE. The results indicate that: sample size affects performance
more than architecture or hyper-parameters; in small samples the performance is
more sensitive to hyper-parameters than architecture; the performance
difference between shallow and deeper networks is not the same across families.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A contextual analysis of multi-layer perceptron models in classifying hand-written digits and letters: limited resources. (arXiv:2107.01782v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pricope_T/0/1/0/all/0/1">Tidor-Vlad Pricope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01782">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying hand-written digits and letters has taken a big leap with the
introduction of ConvNets. However, on very constrained hardware the time
necessary to train such models would be high. Our main contribution is twofold.
First, we extensively test an end-to-end vanilla neural network (MLP) approach
in pure numpy without any pre-processing or feature extraction done beforehand.
Second, we show that basic data mining operations can significantly improve the
performance of the models in terms of computational time, without sacrificing
much accuracy. We illustrate our claims on a simpler variant of the Extended
MNIST dataset, called Balanced EMNIST dataset. Our experiments show that,
without any data mining, we get increased generalization performance when using
more hidden layers and regularization techniques, the best model achieving
84.83% accuracy on a test dataset. Using dimensionality reduction done by PCA
we were able to increase that figure to 85.08% with only 10% of the original
feature space, reducing the memory size needed by 64%. Finally, adding methods
to remove possibly harmful training samples like deviation from the mean helped
us to still achieve over 84% test accuracy but with only 32.8% of the original
memory size for the training set. This compares favorably to the majority of
literature results obtained through similar architectures. Although this
approach gets outshined by state-of-the-art models, it does scale to some
(AlexNet, VGGNet) trained on 50% of the same dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Time Series Forecasting: An Image-driven Approach. (arXiv:2107.01273v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Naftali Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_S/0/1/0/all/0/1">Srijan Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhen Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1">Tucker Balch</a>, <a href="http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1">Manuela Veloso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01273">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address time-series forecasting as a computer vision task.
We capture input data as an image and train a model to produce the subsequent
image. This approach results in predicting distributions as opposed to
pointwise values. To assess the robustness and quality of our approach, we
examine various datasets and multiple evaluation metrics. Our experiments show
that our forecasting tool is effective for cyclic data but somewhat less for
irregular data such as stock prices. Importantly, when using image-based
evaluation metrics, we find our method to outperform various baselines,
including ARIMA, and a numerical variation of our deep learning approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drone Detection Using Convolutional Neural Networks. (arXiv:2107.01435v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_F/0/1/0/all/0/1">Fatemeh Mahdavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajabi_R/0/1/0/all/0/1">Roozbeh Rajabi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01435">
                                    <div class="article-summary-box-inner">
                                        <span>In image processing, it is essential to detect and track air targets,
especially UAVs. In this paper, we detect the flying drone using a fisheye
camera. In the field of diagnosis and classification of objects, there are
always many problems that prevent the development of rapid and significant
progress in this area. During the previous decades, a couple of advanced
classification methods such as convolutional neural networks and support vector
machines have been developed. In this study, the drone was detected using three
methods of classification of convolutional neural network (CNN), support vector
machine (SVM), and nearest neighbor. The outcomes show that CNN, SVM, and
nearest neighbor have total accuracy of 95%, 88%, and 80%, respectively.
Compared with other classifiers with the same experimental conditions, the
accuracy of the convolutional neural network classifier is satisfactory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cognitive Visual Commonsense Reasoning Using Dynamic Working Memory. (arXiv:2107.01671v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xuejiao Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01671">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Commonsense Reasoning (VCR) predicts an answer with corresponding
rationale, given a question-image input. VCR is a recently introduced visual
scene understanding task with a wide range of applications, including visual
question answering, automated vehicle systems, and clinical decision support.
Previous approaches to solving the VCR task generally rely on pre-training or
exploiting memory with long dependency relationship encoded models. However,
these approaches suffer from a lack of generalizability and prior knowledge. In
this paper we propose a dynamic working memory based cognitive VCR network,
which stores accumulated commonsense between sentences to provide prior
knowledge for inference. Extensive experiments show that the proposed model
yields significant improvements over existing methods on the benchmark VCR
dataset. Moreover, the proposed model provides intuitive interpretation into
visual commonsense reasoning. A Python implementation of our mechanism is
publicly available at https://github.com/tanjatang/DMVCR</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPI-GAN: Towards Single-Pixel Imaging through Generative Adversarial Network. (arXiv:2107.01330v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1">Nazmul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1">Nazanin Rahnavard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01330">
                                    <div class="article-summary-box-inner">
                                        <span>Single-pixel imaging is a novel imaging scheme that has gained popularity due
to its huge computational gain and potential for a low-cost alternative to
imaging beyond the visible spectrum. The traditional reconstruction methods
struggle to produce a clear recovery when one limits the number of illumination
patterns from a spatial light modulator. As a remedy, several
deep-learning-based solutions have been proposed which lack good generalization
ability due to the architectural setup and loss functions. In this paper, we
propose a generative adversarial network-based reconstruction framework for
single-pixel imaging, referred to as SPI-GAN. Our method can reconstruct images
with 17.92 dB PSNR and 0.487 SSIM, even if the sampling ratio drops to 5%. This
facilitates much faster reconstruction making our method suitable for
single-pixel video. Furthermore, our ResNet-like architecture for the generator
leads to useful representation learning that allows us to reconstruct
completely unseen objects. The experimental results demonstrate that SPI-GAN
achieves significant performance gain, e.g. near 3dB PSNR gain, over the
current state-of-the-art method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from scarce information: using synthetic data to classify Roman fine ware pottery. (arXiv:2107.01401v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jareno_S/0/1/0/all/0/1">Santos J. N&#xfa;&#xf1;ez Jare&#xf1;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Helden_D/0/1/0/all/0/1">Dani&#xeb;l P. van Helden</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirkes_E/0/1/0/all/0/1">Evgeny M. Mirkes</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1">Ivan Y. Tyukin</a>, <a href="http://arxiv.org/find/cs/1/au:+Allison_P/0/1/0/all/0/1">Penelope M. Allison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01401">
                                    <div class="article-summary-box-inner">
                                        <span>In this article we consider a version of the challenging problem of learning
from datasets whose size is too limited to allow generalisation beyond the
training set. To address the challenge we propose to use a transfer learning
approach whereby the model is first trained on a synthetic dataset replicating
features of the original objects. In this study the objects were smartphone
photographs of near-complete Roman terra sigillata pottery vessels from the
collection of the Museum of London. Taking the replicated features from
published profile drawings of pottery forms allowed the integration of expert
knowledge into the process through our synthetic data generator. After this
first initial training the model was fine-tuned with data from photographs of
real vessels. We show, through exhaustive experiments across several popular
deep learning architectures, different test priors, and considering the impact
of the photograph viewpoint and excessive damage to the vessels, that the
proposed hybrid approach enables the creation of classifiers with appropriate
generalisation performance. This performance is significantly better than that
of classifiers trained exclusively on the original data which shows the promise
of the approach to alleviate the fundamental issue of learning from small
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-Rate: An Automated Framework for Segmentation of COVID-19 Lesions from Chest CT Scans. (arXiv:2107.01527v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Enshaei_N/0/1/0/all/0/1">Nastaran Enshaei</a>, <a href="http://arxiv.org/find/eess/1/au:+Oikonomou_A/0/1/0/all/0/1">Anastasia Oikonomou</a>, <a href="http://arxiv.org/find/eess/1/au:+Rafiee_M/0/1/0/all/0/1">Moezedin Javad Rafiee</a>, <a href="http://arxiv.org/find/eess/1/au:+Afshar_P/0/1/0/all/0/1">Parnian Afshar</a>, <a href="http://arxiv.org/find/eess/1/au:+Heidarian_S/0/1/0/all/0/1">Shahin Heidarian</a>, <a href="http://arxiv.org/find/eess/1/au:+Mohammadi_A/0/1/0/all/0/1">Arash Mohammadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Plataniotis_K/0/1/0/all/0/1">Konstantinos N. Plataniotis</a>, <a href="http://arxiv.org/find/eess/1/au:+Naderkhani_F/0/1/0/all/0/1">Farnoosh Naderkhani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01527">
                                    <div class="article-summary-box-inner">
                                        <span>Novel Coronavirus disease (COVID-19) is a highly contagious respiratory
infection that has had devastating effects on the world. Recently, new COVID-19
variants are emerging making the situation more challenging and threatening.
Evaluation and quantification of COVID-19 lung abnormalities based on chest
Computed Tomography (CT) scans can help determining the disease stage,
efficiently allocating limited healthcare resources, and making informed
treatment decisions. During pandemic era, however, visual assessment and
quantification of COVID-19 lung lesions by expert radiologists become expensive
and prone to error, which raises an urgent quest to develop practical
autonomous solutions. In this context, first, the paper introduces an open
access COVID-19 CT segmentation dataset containing 433 CT images from 82
patients that have been annotated by an expert radiologist. Second, a Deep
Neural Network (DNN)-based framework is proposed, referred to as the
COVID-Rate, that autonomously segments lung abnormalities associated with
COVID-19 from chest CT scans. Performance of the proposed COVID-Rate framework
is evaluated through several experiments based on the introduced and external
datasets. The results show a dice score of 0:802 and specificity and
sensitivity of 0:997 and 0:832, respectively. Furthermore, the results indicate
that the COVID-Rate model can efficiently segment COVID-19 lesions in both 2D
CT images and whole lung volumes. Results on the external dataset illustrate
generalization capabilities of the COVID-Rate model to CT images obtained from
a different scanner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SM-SGE: A Self-Supervised Multi-Scale Skeleton Graph Encoding Framework for Person Re-Identification. (arXiv:2107.01903v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_H/0/1/0/all/0/1">Haocong Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiping Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01903">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification via 3D skeletons is an emerging topic with great
potential in security-critical applications. Existing methods typically learn
body and motion features from the body-joint trajectory, whereas they lack a
systematic way to model body structure and underlying relations of body
components beyond the scale of body joints. In this paper, we for the first
time propose a Self-supervised Multi-scale Skeleton Graph Encoding (SM-SGE)
framework that comprehensively models human body, component relations, and
skeleton dynamics from unlabeled skeleton graphs of various scales to learn an
effective skeleton representation for person Re-ID. Specifically, we first
devise multi-scale skeleton graphs with coarse-to-fine human body partitions,
which enables us to model body structure and skeleton dynamics at multiple
levels. Second, to mine inherent correlations between body components in
skeletal motion, we propose a multi-scale graph relation network to learn
structural relations between adjacent body-component nodes and collaborative
relations among nodes of different scales, so as to capture more discriminative
skeleton graph features. Last, we propose a novel multi-scale skeleton
reconstruction mechanism to enable our framework to encode skeleton dynamics
and high-level semantics from unlabeled skeleton graphs, which encourages
learning a discriminative skeleton representation for person Re-ID. Extensive
experiments show that SM-SGE outperforms most state-of-the-art skeleton-based
methods. We further demonstrate its effectiveness on 3D skeleton data estimated
from large-scale RGB videos. Our codes are open at
https://github.com/Kali-Hac/SM-SGE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth Quality-Inspired Feature Manipulation for Efficient RGB-D Salient Object Detection. (arXiv:2107.01779v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1">Ge-Peng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1">Keren Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qijun Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01779">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-D salient object detection (SOD) recently has attracted increasing
research interest by benefiting conventional RGB SOD with extra depth
information. However, existing RGB-D SOD models often fail to perform well in
terms of both efficiency and accuracy, which hinders their potential
applications on mobile devices and real-world problems. An underlying challenge
is that the model accuracy usually degrades when the model is simplified to
have few parameters. To tackle this dilemma and also inspired by the fact that
depth quality is a key factor influencing the accuracy, we propose a novel
depth quality-inspired feature manipulation (DQFM) process, which is efficient
itself and can serve as a gating mechanism for filtering depth features to
greatly boost the accuracy. DQFM resorts to the alignment of low-level RGB and
depth features, as well as holistic attention of the depth stream to explicitly
control and enhance cross-modal fusion. We embed DQFM to obtain an efficient
light-weight model called DFM-Net, where we also design a tailored depth
backbone and a two-stage decoder for further efficiency consideration.
Extensive experimental results demonstrate that our DFM-Net achieves
state-of-the-art accuracy when comparing to existing non-efficient models, and
meanwhile runs at 140ms on CPU (2.2$\times$ faster than the prior fastest
efficient model) with only $\sim$8.5Mb model size (14.9% of the prior
lightest). Our code will be made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Web-Scale Generic Object Detection at Microsoft Bing. (arXiv:2107.01814v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Stephen Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Saurajit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Phadke_U/0/1/0/all/0/1">Unmesh Phadke</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tingting Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Junwon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yada_R/0/1/0/all/0/1">Ravi Theja Yada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01814">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present Generic Object Detection (GenOD), one of the
largest object detection systems deployed to a web-scale general visual search
engine that can detect over 900 categories for all Microsoft Bing Visual Search
queries in near real-time. It acts as a fundamental visual query understanding
service that provides object-centric information and shows gains in multiple
production scenarios, improving upon domain-specific models. We discuss the
challenges of collecting data, training, deploying and updating such a
large-scale object detection model with multiple dependencies. We discuss a
data collection pipeline that reduces per-bounding box labeling cost by 81.5%
and latency by 61.2% while improving on annotation quality. We show that GenOD
can improve weighted average precision by over 20% compared to multiple
domain-specific models. We also improve the model update agility by nearly 2
times with the proposed disjoint detector training compared to joint
fine-tuning. Finally we demonstrate how GenOD benefits visual search
applications by significantly improving object-level search relevance by 54.9%
and user engagement by 59.9%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-VIT: Classification of COVID-19 from CT chest images based on vision transformer models. (arXiv:2107.01682v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gao_X/0/1/0/all/0/1">Xiaohong Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Qian_Y/0/1/0/all/0/1">Yu Qian</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_A/0/1/0/all/0/1">Alice Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01682">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is responding to the MIA-COV19 challenge to classify COVID from
non-COVID based on CT lung images. The COVID-19 virus has devastated the world
in the last eighteen months by infecting more than 182 million people and
causing over 3.9 million deaths. The overarching aim is to predict the
diagnosis of the COVID-19 virus from chest radiographs, through the development
of explainable vision transformer deep learning techniques, leading to
population screening in a more rapid, accurate and transparent way. In this
competition, there are 5381 three-dimensional (3D) datasets in total, including
1552 for training, 374 for evaluation and 3455 for testing. While most of the
data volumes are in axial view, there are a number of subjects&#x27; data are in
coronal or sagittal views with 1 or 2 slices are in axial view. Hence, while 3D
data based classification is investigated, in this competition, 2D images
remains the main focus. Two deep learning methods are studied, which are vision
transformer (ViT) based on attention models and DenseNet that is built upon
conventional convolutional neural network (CNN). Initial evaluation results
based on validation datasets whereby the ground truth is known indicate that
ViT performs better than DenseNet with F1 scores being 0.76 and 0.72
respectively. Codes are available at GitHub at
.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demiguise Attack: Crafting Invisible Semantic Adversarial Perturbations with Perceptual Similarity. (arXiv:2107.01396v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yajie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shangbo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_S/0/1/0/all/0/1">Shengang Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yu-an Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanxin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01396">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have been found to be vulnerable to adversarial
examples. Adversarial examples are malicious images with visually imperceptible
perturbations. While these carefully crafted perturbations restricted with
tight $\Lp$ norm bounds are small, they are still easily perceivable by humans.
These perturbations also have limited success rates when attacking black-box
models or models with defenses like noise reduction filters. To solve these
problems, we propose Demiguise Attack, crafting &#x60;&#x60;unrestricted&#x27;&#x27; perturbations
with Perceptual Similarity. Specifically, we can create powerful and
photorealistic adversarial examples by manipulating semantic information based
on Perceptual Similarity. Adversarial examples we generate are friendly to the
human visual system (HVS), although the perturbations are of large magnitudes.
We extend widely-used attacks with our approach, enhancing adversarial
effectiveness impressively while contributing to imperceptibility. Extensive
experiments show that the proposed method not only outperforms various
state-of-the-art attacks in terms of fooling rate, transferability, and
robustness against defenses but can also improve attacks effectively. In
addition, we also notice that our implementation can simulate illumination and
contrast changes that occur in real-world scenarios, which will contribute to
exposing the blind spots of DNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Disaster Image Dataset and Characteristics Analysis using Attention Model. (arXiv:2107.01284v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niloy_F/0/1/0/all/0/1">Fahim Faisal Niloy</a>, <a href="http://arxiv.org/find/cs/1/au:+Arif/0/1/0/all/0/1">Arif</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayem_A/0/1/0/all/0/1">Abu Bakar Siddik Nayem</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_A/0/1/0/all/0/1">Anis Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_O/0/1/0/all/0/1">Ovi Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1">M. Ashraful Amin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Amin Ahsan Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaber_M/0/1/0/all/0/1">Moinul Islam Zaber</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1">AKM Mahbubur Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01284">
                                    <div class="article-summary-box-inner">
                                        <span>The advancement of deep learning technology has enabled us to develop systems
that outperform any other classification technique. However, success of any
empirical system depends on the quality and diversity of the data available to
train the proposed system. In this research, we have carefully accumulated a
relatively challenging dataset that contains images collected from various
sources for three different disasters: fire, water and land. Besides this, we
have also collected images for various damaged infrastructure due to natural or
man made calamities and damaged human due to war or accidents. We have also
accumulated image data for a class named non-damage that contains images with
no such disaster or sign of damage in them. There are 13,720 manually annotated
images in this dataset, each image is annotated by three individuals. We are
also providing discriminating image class information annotated manually with
bounding box for a set of 200 test images. Images are collected from different
news portals, social media, and standard datasets made available by other
researchers. A three layer attention model (TLAM) is trained and average five
fold validation accuracy of 95.88% is achieved. Moreover, on the 200 unseen
test images this accuracy is 96.48%. We also generate and compare attention
maps for these test images to determine the characteristics of the trained
attention model. Our dataset is available at
https://niloy193.github.io/Disaster-Dataset</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct Measure Matching for Crowd Counting. (arXiv:2107.01558v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1">Xiaopeng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhiheng Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xing Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yunfeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaowei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yihong Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01558">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional crowd counting approaches usually use Gaussian assumption to
generate pseudo density ground truth, which suffers from problems like
inaccurate estimation of the Gaussian kernel sizes. In this paper, we propose a
new measure-based counting approach to regress the predicted density maps to
the scattered point-annotated ground truth directly. First, crowd counting is
formulated as a measure matching problem. Second, we derive a semi-balanced
form of Sinkhorn divergence, based on which a Sinkhorn counting loss is
designed for measure matching. Third, we propose a self-supervised mechanism by
devising a Sinkhorn scale consistency loss to resist scale changes. Finally, an
efficient optimization method is provided to minimize the overall loss
function. Extensive experiments on four challenging crowd counting datasets
namely ShanghaiTech, UCF-QNRF, JHU++, and NWPU have validated the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CT Image Harmonization for Enhancing Radiomics Studies. (arXiv:2107.01337v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Selim_M/0/1/0/all/0/1">Md Selim</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Fei_B/0/1/0/all/0/1">Baowei Fei</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_G/0/1/0/all/0/1">Guo-Qiang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Jin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01337">
                                    <div class="article-summary-box-inner">
                                        <span>While remarkable advances have been made in Computed Tomography (CT),
capturing CT images with non-standardized protocols causes low reproducibility
regarding radiomic features, forming a barrier on CT image analysis in a large
scale. RadiomicGAN is developed to effectively mitigate the discrepancy caused
by using non-standard reconstruction kernels. RadiomicGAN consists of hybrid
neural blocks including both pre-trained and trainable layers adopted to learn
radiomic feature distributions efficiently. A novel training approach, called
Dynamic Window-based Training, has been developed to smoothly transform the
pre-trained model to the medical imaging domain. Model performance evaluated
using 1401 radiomic features show that RadiomicGAN clearly outperforms the
state-of-art image standardization models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSPNet: Scale Selection Pyramid Network for Tiny Person Detection from UAV Images. (arXiv:2107.01548v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Mingbo Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuiwang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuchao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feiyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qijun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Li Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01548">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing demand for search and rescue, it is highly demanded to
detect objects of interest in large-scale images captured by Unmanned Aerial
Vehicles (UAVs), which is quite challenging due to extremely small scales of
objects. Most existing methods employed Feature Pyramid Network (FPN) to enrich
shallow layers&#x27; features by combing deep layers&#x27; contextual features. However,
under the limitation of the inconsistency in gradient computation across
different layers, the shallow layers in FPN are not fully exploited to detect
tiny objects. In this paper, we propose a Scale Selection Pyramid network
(SSPNet) for tiny person detection, which consists of three components: Context
Attention Module (CAM), Scale Enhancement Module (SEM), and Scale Selection
Module (SSM). CAM takes account of context information to produce hierarchical
attention heatmaps. SEM highlights features of specific scales at different
layers, leading the detector to focus on objects of specific scales instead of
vast backgrounds. SSM exploits adjacent layers&#x27; relationships to fulfill
suitable feature sharing between deep layers and shallow layers, thereby
avoiding the inconsistency in gradient computation across different layers.
Besides, we propose a Weighted Negative Sampling (WNS) strategy to guide the
detector to select more representative samples. Experiments on the TinyPerson
benchmark show that our method outperforms other state-of-the-art (SOTA)
detectors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scene-aware Learning Network for Radar Object Detection. (arXiv:2107.01469v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zangwei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1">Xiangyu Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincentelli_A/0/1/0/all/0/1">Alberto Sangiovanni Vincentelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01469">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection is essential to safe autonomous or assisted driving.
Previous works usually utilize RGB images or LiDAR point clouds to identify and
localize multiple objects in self-driving. However, cameras tend to fail in bad
driving conditions, e.g. bad weather or weak lighting, while LiDAR scanners are
too expensive to get widely deployed in commercial applications. Radar has been
drawing more and more attention due to its robustness and low cost. In this
paper, we propose a scene-aware radar learning framework for accurate and
robust object detection. First, the learning framework contains branches
conditioning on the scene category of the radar sequence; with each branch
optimized for a specific type of scene. Second, three different 3D
autoencoder-based architectures are proposed for radar object detection and
ensemble learning is performed over the different architectures to further
boost the final performance. Third, we propose novel scene-aware sequence mix
augmentation (SceneMix) and scene-specific post-processing to generate more
robust detection results. In the ROD2021 Challenge, we achieved a final result
of average precision of 75.0% and an average recall of 81.0%. Moreover, in the
parking lot scene, our framework ranks first with an average precision of 97.8%
and an average recall of 98.6%, which demonstrates the effectiveness of our
framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Edge-Aware Interactive Colorization against Color-Bleeding Effects. (arXiv:2107.01619v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1">Eungyeup Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sanghyeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jeonghoon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Somi Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_C/0/1/0/all/0/1">Choonghyun Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01619">
                                    <div class="article-summary-box-inner">
                                        <span>Deep image colorization networks often suffer from the color-bleeding
artifact, a problematic color spreading near the boundaries between adjacent
objects. The color-bleeding artifacts debase the reality of generated outputs,
limiting the applicability of colorization models on a practical application.
Although previous approaches have tackled this problem in an automatic manner,
they often generate imperfect outputs because their enhancements are available
only in limited cases, such as having a high contrast of gray-scale value in an
input image. Instead, leveraging user interactions would be a promising
approach, since it can help the edge correction in the desired regions. In this
paper, we propose a novel edge-enhancing framework for the regions of interest,
by utilizing user scribbles that indicate where to enhance. Our method requires
minimal user effort to obtain satisfactory enhancements. Experimental results
on various datasets demonstrate that our interactive approach has outstanding
performance in improving color-bleeding artifacts against the existing
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EAR-NET: Error Attention Refining Network For Retinal Vessel Segmentation. (arXiv:2107.01351v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_X/0/1/0/all/0/1">Xiaohan Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01351">
                                    <div class="article-summary-box-inner">
                                        <span>The precise detection of blood vessels in retinal images is crucial to the
early diagnosis of the retinal vascular diseases, e.g., diabetic, hypertensive
and solar retinopathies. Existing works often fail in predicting the abnormal
areas, e.g, sudden brighter and darker areas and are inclined to predict a
pixel to background due to the significant class imbalance, leading to high
accuracy and specificity while low sensitivity. To that end, we propose a novel
error attention refining network (ERA-Net) that is capable of learning and
predicting the potential false predictions in a two-stage manner for effective
retinal vessel segmentation. The proposed ERA-Net in the refine stage drives
the model to focus on and refine the segmentation errors produced in the
initial training stage. To achieve this, unlike most previous attention
approaches that run in an unsupervised manner, we introduce a novel error
attention mechanism which considers the differences between the ground truth
and the initial segmentation masks as the ground truth to supervise the
attention map learning. Experimental results demonstrate that our method
achieves state-of-the-art performance on two common retinal blood vessel
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust End-to-End Offline Chinese Handwriting Text Page Spotter with Text Kernel. (arXiv:2107.01547v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yanwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_H/0/1/0/all/0/1">Haixu Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fazheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01547">
                                    <div class="article-summary-box-inner">
                                        <span>Offline Chinese handwriting text recognition is a long-standing research
topic in the field of pattern recognition. In previous studies, text detection
and recognition are separated, which leads to the fact that text recognition is
highly dependent on the detection results. In this paper, we propose a robust
end-to-end Chinese text page spotter framework. It unifies text detection and
text recognition with text kernel that integrates global text feature
information to optimize the recognition from multiple scales, which reduces the
dependence of detection and improves the robustness of the system. Our method
achieves state-of-the-art results on the CASIA-HWDB2.0-2.2 dataset and
ICDAR-2013 competition dataset. Without any language model, the correct rates
are 99.12% and 94.27% for line-level recognition, and 99.03% and 94.20% for
page-level recognition, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CInC Flow: Characterizable Invertible 3x3 Convolution. (arXiv:2107.01358v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagar_S/0/1/0/all/0/1">Sandeep Nagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dufraisse_M/0/1/0/all/0/1">Marius Dufraisse</a>, <a href="http://arxiv.org/find/cs/1/au:+Varma_G/0/1/0/all/0/1">Girish Varma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01358">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are an essential alternative to GANs for generative
modelling, which can be optimized directly on the maximum likelihood of the
dataset. They also allow computation of the exact latent vector corresponding
to an image since they are composed of invertible transformations. However, the
requirement of invertibility of the transformation prevents standard and
expressive neural network models such as CNNs from being directly used.
Emergent convolutions were proposed to construct an invertible 3$\times$3 CNN
layer using a pair of masked CNN layers, making them inefficient. We study
conditions such that 3$\times$3 CNNs are invertible, allowing them to construct
expressive normalizing flows. We derive necessary and sufficient conditions on
a padded CNN for it to be invertible. Our conditions for invertibility are
simple, can easily be maintained during the training process. Since we require
only a single CNN layer for every effective invertible CNN layer, our approach
is more efficient than emerging convolutions. We also proposed a coupling
method, Quad-coupling. We benchmark our approach and show similar performance
results to emergent convolutions while improving the model&#x27;s efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network. (arXiv:2107.01349v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jong-Yeong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dong-Wan Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01349">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning has been a major problem in the deep learning community,
where the main challenge is how to effectively learn a series of newly arriving
tasks without forgetting the knowledge of previous tasks. Initiated by Learning
without Forgetting (LwF), many of the existing works report that knowledge
distillation is effective to preserve the previous knowledge, and hence they
commonly use a soft label for the old task, namely a knowledge distillation
(KD) loss, together with a class label for the new task, namely a cross entropy
(CE) loss, to form a composite loss for a single neural network. However, this
approach suffers from learning the knowledge by a CE loss as a KD loss often
more strongly influences the objective function when they are in a competitive
situation within a single network. This could be a critical problem
particularly in a class incremental scenario, where the knowledge across tasks
as well as within the new task, both of which can only be acquired by a CE
loss, is essentially learned due to the existence of a unified classifier. In
this paper, we propose a novel continual learning method, called
Split-and-Bridge, which can successfully address the above problem by partially
splitting a neural network into two partitions for training the new task
separated from the old task and re-connecting them for learning the knowledge
across tasks. In our thorough experimental analysis, our Split-and-Bridge
method outperforms the state-of-the-art competitors in KD-based continual
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Vision Transformers via Fine-Grained Manifold Distillation. (arXiv:2107.01378v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_D/0/1/0/all/0/1">Ding Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01378">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the model compression problem of vision transformers.
Benefit from the self-attention module, transformer architectures have shown
extraordinary performance on many computer vision tasks. Although the network
performance is boosted, transformers are often required more computational
resources including memory usage and the inference complexity. Compared with
the existing knowledge distillation approaches, we propose to excavate useful
information from the teacher transformer through the relationship between
images and the divided patches. We then explore an efficient fine-grained
manifold distillation approach that simultaneously calculates cross-images,
cross-patch, and random-selected manifolds in teacher and student models.
Experimental results conducted on several benchmarks demonstrate the
superiority of the proposed algorithm for distilling portable transformer
models with higher performance. For example, our approach achieves 75.06% Top-1
accuracy on the ImageNet-1k dataset for training a DeiT-Tiny model, which
outperforms other ViT distillation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FINT: Field-aware INTeraction Neural Network For CTR Prediction. (arXiv:2107.01999v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhishan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guohui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1">Dawei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01999">
                                    <div class="article-summary-box-inner">
                                        <span>As a critical component for online advertising and marking, click-through
rate (CTR) prediction has draw lots of attentions from both industry and
academia field. Recently, the deep learning has become the mainstream
methodological choice for CTR. Despite of sustainable efforts have been made,
existing approaches still pose several challenges. On the one hand, high-order
interaction between the features is under-explored. On the other hand,
high-order interactions may neglect the semantic information from the low-order
fields. In this paper, we proposed a novel prediction method, named FINT, that
employs the Field-aware INTeraction layer which captures high-order feature
interactions while retaining the low-order field information. To empirically
investigate the effectiveness and robustness of the FINT, we perform extensive
experiments on the three realistic databases: KDD2012, Criteo and Avazu. The
obtained results demonstrate that the FINT can significantly improve the
performance compared to the existing methods, without increasing the amount of
computation required. Moreover, the proposed method brought about 2.72\%
increase to the advertising revenue of a big online video app through A/B
testing. To better promote the research in CTR field, we will release our code
as well as reference implementation of those baseline models in the final
version.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NOTE: Solution for KDD-CUP 2021 WikiKG90M-LSC. (arXiv:2107.01892v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1">Weiyue Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zeyang Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1">Hui Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Siming Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhengjie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yunsheng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shikun Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeyu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01892">
                                    <div class="article-summary-box-inner">
                                        <span>WikiKG90M in KDD Cup 2021 is a large encyclopedic knowledge graph, which
could benefit various downstream applications such as question answering and
recommender systems. Participants are invited to complete the knowledge graph
by predicting missing triplets. Recent representation learning methods have
achieved great success on standard datasets like FB15k-237. Thus, we train the
advanced algorithms in different domains to learn the triplets, including OTE,
QuatE, RotatE and TransE. Significantly, we modified OTE into NOTE (short for
Norm-OTE) for better performance. Besides, we use both the DeepWalk and the
post-smoothing technique to capture the graph structure for supplementation. In
addition to the representations, we also use various statistical probabilities
among the head entities, the relations and the tail entities for the final
prediction. Experimental results show that the ensemble of state-of-the-art
representation learning methods could draw on each others strengths. And we
develop feature engineering from validation candidates for further
improvements. Please note that we apply the same strategy on the test set for
final inference. And these features may not be practical in the real world when
considering ranking against all the entities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing Viewpoint Diversity in Search Results Using Ranking Fairness Metrics. (arXiv:2010.14531v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Draws_T/0/1/0/all/0/1">Tim Draws</a>, <a href="http://arxiv.org/find/cs/1/au:+Tintarev_N/0/1/0/all/0/1">Nava Tintarev</a>, <a href="http://arxiv.org/find/cs/1/au:+Gadiraju_U/0/1/0/all/0/1">Ujwal Gadiraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Bozzon_A/0/1/0/all/0/1">Alessandro Bozzon</a>, <a href="http://arxiv.org/find/cs/1/au:+Timmermans_B/0/1/0/all/0/1">Benjamin Timmermans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14531">
                                    <div class="article-summary-box-inner">
                                        <span>The way pages are ranked in search results influences whether the users of
search engines are exposed to more homogeneous, or rather to more diverse
viewpoints. However, this viewpoint diversity is not trivial to assess. In this
paper we use existing and novel ranking fairness metrics to evaluate viewpoint
diversity in search result rankings. We conduct a controlled simulation study
that shows how ranking fairness metrics can be used for viewpoint diversity,
how their outcome should be interpreted, and which metric is most suitable
depending on the situation. This paper lays out important ground work for
future research to measure and assess viewpoint diversity in real search result
rankings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attribute-aware Explainable Complementary Clothing Recommendation. (arXiv:2107.01655v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01655">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling mix-and-match relationships among fashion items has become
increasingly demanding yet challenging for modern E-commerce recommender
systems. When performing clothes matching, most existing approaches leverage
the latent visual features extracted from fashion item images for compatibility
modelling, which lacks explainability of generated matching results and can
hardly convince users of the recommendations. Though recent methods start to
incorporate pre-defined attribute information (e.g., colour, style, length,
etc.) for learning item representations and improving the model
interpretability, their utilisation of attribute information is still mainly
reserved for enhancing the learned item representations and generating
explanations via post-processing. As a result, this creates a severe bottleneck
when we are trying to advance the recommendation accuracy and generating
fine-grained explanations since the explicit attributes have only loose
connections to the actual recommendation process. This work aims to tackle the
explainability challenge in fashion recommendation tasks by proposing a novel
Attribute-aware Fashion Recommender (AFRec). Specifically, AFRec recommender
assesses the outfit compatibility by explicitly leveraging the extracted
attribute-level representations from each item&#x27;s visual feature. The attributes
serve as the bridge between two fashion items, where we quantify the affinity
of a pair of items through the learned compatibility between their attributes.
Extensive experiments have demonstrated that, by making full use of the
explicit attributes in the recommendation process, AFRec is able to achieve
state-of-the-art recommendation accuracy and generate intuitive explanations at
the same time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Complex Users&#x27; Preferences for Recommender Systems. (arXiv:2107.01529v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yakhchi_S/0/1/0/all/0/1">Shahpar Yakhchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01529">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems (RSs) have emerged as very useful tools to help customers
with their decision-making process, find items of their interest, and alleviate
the information overload problem. There are two different lines of approaches
in RSs: (1) general recommenders with the main goal of discovering long-term
users&#x27; preferences, and (2) sequential recommenders with the main focus of
capturing short-term users&#x27; preferences in a session of user-item interaction
(here, a session refers to a record of purchasing multiple items in one
shopping event). While considering short-term users&#x27; preferences may satisfy
their current needs and interests, long-term users&#x27; preferences provide users
with the items that they may interact with, eventually. In this thesis, we
first focus on improving the performance of general RSs. Most of the existing
general RSs tend to exploit the users&#x27; rating patterns on common items to
detect similar users. The data sparsity problem (i.e. the lack of available
information) is one of the major challenges for the current general RSs, and
they may fail to have any recommendations when there are no common items of
interest among users. We call this problem data sparsity with no feedback on
common items (DSW-n-FCI). To overcome this problem, we propose a
personality-based RS in which similar users are identified based on the
similarity of their personality traits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Representation Learning for Session-based Recommendation. (arXiv:2107.01516v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1">Sai Mitheran</a>, <a href="http://arxiv.org/find/cs/1/au:+Java_A/0/1/0/all/0/1">Abhinav Java</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1">Surya Kant Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_A/0/1/0/all/0/1">Arshad Shaikh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01516">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based recommendation systems suggest relevant items to users by
modeling user behavior and preferences using short-term anonymous sessions.
Existing methods leverage Graph Neural Networks (GNNs) that propagate and
aggregate information from neighboring nodes i.e., local message passing. Such
graph-based architectures have representational limits, as a single sub-graph
is susceptible to overfit the sequential dependencies instead of accounting for
complex transitions between items in different sessions. We propose using a
Transformer in combination with a target attentive GNN, which allows richer
Representation Learning. Our experimental results and ablation show that our
proposed method outperforms the existing methods on real-world benchmark
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering Interpretable Machine Learning Models in Parallel Coordinates. (arXiv:2106.07474v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovalerchuk_B/0/1/0/all/0/1">Boris Kovalerchuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayes_D/0/1/0/all/0/1">Dustin Hayes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07474">
                                    <div class="article-summary-box-inner">
                                        <span>This paper contributes to interpretable machine learning via visual knowledge
discovery in parallel coordinates. The concepts of hypercubes and hyper-blocks
are used as easily understandable by end-users in the visual form in parallel
coordinates. The Hyper algorithm for classification with mixed and pure
hyper-blocks (HBs) is proposed to discover hyper-blocks interactively and
automatically in individual, multiple, overlapping, and non-overlapping
setting. The combination of hyper-blocks with linguistic description of visual
patterns is presented too. It is shown that Hyper models generalize decision
trees. The Hyper algorithm was tested on the benchmark data from UCI ML
repository. It allowed discovering pure and mixed HBs with all data and then
with 10-fold cross validation. The links between hyper-blocks, dimension
reduction and visualization are established. Major benefits of hyper-block
technology and the Hyper algorithm are in their ability to discover and observe
hyper-blocks by end-users including side by side visualizations making patterns
visible for all classes. Another advantage of sets of HBs relative to the
decision trees is the ability to avoid both data overgeneralization and
overfitting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Recovery of Issue-Commit Links Leveraging Both Textual and Non-textual Data. (arXiv:2107.01894v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazrae_P/0/1/0/all/0/1">Pooya Rostami Mazrae</a>, <a href="http://arxiv.org/find/cs/1/au:+Izadi_M/0/1/0/all/0/1">Maliheh Izadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Heydarnoori_A/0/1/0/all/0/1">Abbas Heydarnoori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01894">
                                    <div class="article-summary-box-inner">
                                        <span>An issue documents discussions around required changes in issue-tracking
systems, while a commit contains the change itself in the version control
systems. Recovering links between issues and commits can facilitate many
software evolution tasks such as bug localization, and software documentation.
A previous study on over half a million issues from GitHub reports only about
42.2% of issues are manually linked by developers to their pertinent commits.
Automating the linking of commit-issue pairs can contribute to the improvement
of the said tasks. By far, current state-of-the-art approaches for automated
commit-issue linking suffer from low precision, leading to unreliable results,
sometimes to the point that imposes human supervision on the predicted links.
The low performance gets even more severe when there is a lack of textual
information in either commits or issues. Current approaches are also proven
computationally expensive.

We propose Hybrid-Linker to overcome such limitations by exploiting two
information channels; (1) a non-textual-based component that operates on
non-textual, automatically recorded information of the commit-issue pairs to
predict a link, and (2) a textual-based one which does the same using textual
information of the commit-issue pairs. Then, combining the results from the two
classifiers, Hybrid-Linker makes the final prediction. Thus, every time one
component falls short in predicting a link, the other component fills the gap
and improves the results. We evaluate Hybrid-Linker against competing
approaches, namely FRLink and DeepLink on a dataset of 12 projects.
Hybrid-Linker achieves 90.1%, 87.8%, and 88.9% based on recall, precision, and
F-measure, respectively. It also outperforms FRLink and DeepLink by 31.3%, and
41.3%, regarding the F-measure. Moreover, Hybrid-Linker exhibits extensive
improvements in terms of performance as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptation of Object Detectors: A Survey. (arXiv:2105.13502v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oza_P/0/1/0/all/0/1">Poojan Oza</a>, <a href="http://arxiv.org/find/cs/1/au:+Sindagi_V/0/1/0/all/0/1">Vishwanath A. Sindagi</a>, <a href="http://arxiv.org/find/cs/1/au:+VS_V/0/1/0/all/0/1">Vibashan VS</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13502">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep learning have led to the development of accurate and
efficient models for various computer vision applications such as
classification, segmentation, and detection. However, learning highly accurate
models relies on the availability of large-scale annotated datasets. Due to
this, model performance drops drastically when evaluated on label-scarce
datasets having visually distinct images, termed as domain adaptation problem.
There is a plethora of works to adapt classification and segmentation models to
label-scarce target datasets through unsupervised domain adaptation.
Considering that detection is a fundamental task in computer vision, many
recent works have focused on developing novel domain adaptive detection
techniques. Here, we describe in detail the domain adaptation problem for
detection and present an extensive survey of the various methods. Furthermore,
we highlight strategies proposed and the associated shortcomings. Subsequently,
we identify multiple aspects of the problem that are most promising for future
research. We believe that this survey shall be valuable to the pattern
recognition experts working in the fields of computer vision, biometrics,
medical imaging, and autonomous navigation by introducing them to the problem,
and familiarizing them with the current status of the progress while providing
promising directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auxiliary-Classifier GAN for Malware Analysis. (arXiv:2107.01620v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagaraju_R/0/1/0/all/0/1">Rakesh Nagaraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1">Mark Stamp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01620">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GAN) are a class of powerful machine
learning techniques, where both a generative and discriminative model are
trained simultaneously. GANs have been used, for example, to successfully
generate &quot;deep fake&quot; images. A recent trend in malware research consists of
treating executables as images and employing image-based analysis techniques.
In this research, we generate fake malware images using auxiliary classifier
GANs (AC-GAN), and we consider the effectiveness of various techniques for
classifying the resulting images. Our results indicate that the resulting
multiclass classification problem is challenging, yet we can obtain strong
results when restricting the problem to distinguishing between real and fake
samples. While the AC-GAN generated images often appear to be very similar to
real malware images, we conclude that from a deep learning perspective, the
AC-GAN generated samples do not rise to the level of deep fake malware images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Online Convex Optimization in the Presence of Outliers. (arXiv:2107.01881v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Erven_T/0/1/0/all/0/1">Tim van Erven</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachs_S/0/1/0/all/0/1">Sarah Sachs</a>, <a href="http://arxiv.org/find/cs/1/au:+Koolen_W/0/1/0/all/0/1">Wouter M. Koolen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotlowski_W/0/1/0/all/0/1">Wojciech Kot&#x142;owski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01881">
                                    <div class="article-summary-box-inner">
                                        <span>We consider online convex optimization when a number k of data points are
outliers that may be corrupted. We model this by introducing the notion of
robust regret, which measures the regret only on rounds that are not outliers.
The aim for the learner is to achieve small robust regret, without knowing
where the outliers are. If the outliers are chosen adversarially, we show that
a simple filtering strategy on extreme gradients incurs O(k) additive overhead
compared to the usual regret bounds, and that this is unimprovable, which means
that k needs to be sublinear in the number of rounds. We further ask which
additional assumptions would allow for a linear number of outliers. It turns
out that the usual benign cases of independently, identically distributed
(i.i.d.) observations or strongly convex losses are not sufficient. However,
combining i.i.d. observations with the assumption that outliers are those
observations that are in an extreme quantile of the distribution, does lead to
sublinear robust regret, even though the expected number of outliers is linear.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Last-Iterate Convergence Rate of Optimistic Mirror Descent in Stochastic Variational Inequalities. (arXiv:2107.01906v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Azizian_W/0/1/0/all/0/1">Wa&#xef;ss Azizian</a>, <a href="http://arxiv.org/find/math/1/au:+Iutzeler_F/0/1/0/all/0/1">Franck Iutzeler</a>, <a href="http://arxiv.org/find/math/1/au:+Malick_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Malick</a>, <a href="http://arxiv.org/find/math/1/au:+Mertikopoulos_P/0/1/0/all/0/1">Panayotis Mertikopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01906">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we analyze the local convergence rate of optimistic mirror
descent methods in stochastic variational inequalities, a class of optimization
problems with important applications to learning theory and machine learning.
Our analysis reveals an intricate relation between the algorithm&#x27;s rate of
convergence and the local geometry induced by the method&#x27;s underlying Bregman
function. We quantify this relation by means of the Legendre exponent, a notion
that we introduce to measure the growth rate of the Bregman divergence relative
to the ambient norm near a solution. We show that this exponent determines both
the optimal step-size policy of the algorithm and the optimal rates attained,
explaining in this way the differences observed for some popular Bregman
functions (Euclidean projection, negative entropy, fractional power, etc.).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Knowledge from Ensembles of Acoustic Models for Joint CTC-Attention End-to-End Speech Recognition. (arXiv:2005.09310v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas Lane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09310">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation has been widely used to compress existing deep
learning models while preserving the performance on a wide range of
applications. In the specific context of Automatic Speech Recognition (ASR),
distillation from ensembles of acoustic models has recently shown promising
results in increasing recognition performance. In this paper, we propose an
extension of multi-teacher distillation methods to joint CTC-attention
end-to-end ASR systems. We also introduce three novel distillation strategies.
The core intuition behind them is to integrate the error rate metric to the
teacher selection rather than solely focusing on the observed losses. In this
way, we directly distill and optimize the student toward the relevant metric
for speech recognition. We evaluate these strategies under a selection of
training procedures on different datasets (TIMIT, Librispeech, Common Voice)
and various languages (English, French, Italian). In particular,
state-of-the-art error rates are reported on the Common Voice French, Italian
and TIMIT datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alex Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1">Safa Cicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02994">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for inferring dense depth maps from images and sparse
depth measurements by leveraging synthetic data to learn the association of
sparse point clouds with dense natural shapes, and using the image as evidence
to validate the predicted depth map. Our learned prior for natural shapes uses
only sparse depth as input, not images, so the method is not affected by the
covariate shift when attempting to transfer learned models from synthetic data
to real ones. This allows us to use abundant synthetic data with ground truth
to learn the most difficult component of the reconstruction process, which is
topology estimation, and use the image to refine the prediction based on
photometric evidence. Our approach uses fewer parameters than previous methods,
yet, achieves the state of the art on both indoor and outdoor benchmark
datasets. Code available at:
https://github.com/alexklwong/learning-topology-synthetic-data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN2GAN: Generative Noise Learning for Blind Denoising with Single Noisy Images. (arXiv:1905.10488v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cha_S/0/1/0/all/0/1">Sungmin Cha</a>, <a href="http://arxiv.org/find/eess/1/au:+Park_T/0/1/0/all/0/1">Taeeon Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_B/0/1/0/all/0/1">Byeongjoon Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Baek_J/0/1/0/all/0/1">Jongduk Baek</a>, <a href="http://arxiv.org/find/eess/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10488">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle a challenging blind image denoising problem, in which only single
distinct noisy images are available for training a denoiser, and no information
about noise is known, except for it being zero-mean, additive, and independent
of the clean image. In such a setting, which often occurs in practice, it is
not possible to train a denoiser with the standard discriminative training or
with the recently developed Noise2Noise (N2N) training; the former requires the
underlying clean image for the given noisy image, and the latter requires two
independently realized noisy image pair for a clean image. To that end, we
propose GAN2GAN (Generated-Artificial-Noise to Generated-Artificial-Noise)
method that first learns a generative model that can 1) simulate the noise in
the given noisy images and 2) generate a rough, noisy estimates of the clean
images, then 3) iteratively trains a denoiser with subsequently synthesized
noisy image pairs (as in N2N), obtained from the generative model. In results,
we show the denoiser trained with our GAN2GAN achieves an impressive denoising
performance on both synthetic and real-world datasets for the blind denoising
setting; it almost approaches the performance of the standard
discriminatively-trained or N2N-trained models that have more information than
ours, and it significantly outperforms the recent baseline for the same
setting, \textit{e.g.}, Noise2Void, and a more conventional yet strong one,
BM3D. The official code of our method is available at
https://github.com/csm9493/GAN2GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Endo-Depth-and-Motion: Reconstruction and Tracking in Endoscopic Videos using Depth Networks and Photometric Constraints. (arXiv:2103.16525v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Recasens_D/0/1/0/all/0/1">David Recasens</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamarca_J/0/1/0/all/0/1">Jos&#xe9; Lamarca</a>, <a href="http://arxiv.org/find/cs/1/au:+Facil_J/0/1/0/all/0/1">Jos&#xe9; M. F&#xe1;cil</a>, <a href="http://arxiv.org/find/cs/1/au:+Montiel_J/0/1/0/all/0/1">J. M. M. Montiel</a>, <a href="http://arxiv.org/find/cs/1/au:+Civera_J/0/1/0/all/0/1">Javier Civera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16525">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating a scene reconstruction and the camera motion from in-body videos
is challenging due to several factors, e.g. the deformation of in-body cavities
or the lack of texture. In this paper we present Endo-Depth-and-Motion, a
pipeline that estimates the 6-degrees-of-freedom camera pose and dense 3D scene
models from monocular endoscopic videos. Our approach leverages recent advances
in self-supervised depth networks to generate pseudo-RGBD frames, then tracks
the camera pose using photometric residuals and fuses the registered depth maps
in a volumetric representation. We present an extensive experimental evaluation
in the public dataset Hamlyn, showing high-quality results and comparisons
against relevant baselines. We also release all models and code for future
comparisons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Dynamic Regret in Exp-Concave Online Learning. (arXiv:2104.11824v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baby_D/0/1/0/all/0/1">Dheeraj Baby</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Xiang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11824">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of the Zinkevich (2003)-style dynamic regret
minimization in online learning with exp-concave losses. We show that whenever
improper learning is allowed, a Strongly Adaptive online learner achieves the
dynamic regret of $\tilde O^*(n^{1/3}C_n^{2/3} \vee 1)$ where $C_n$ is the
total variation (a.k.a. path length) of the an arbitrary sequence of
comparators that may not be known to the learner ahead of time. Achieving this
rate was highly nontrivial even for squared losses in 1D where the best known
upper bound was $O(\sqrt{nC_n} \vee \log n)$ (Yuan and Lamperski, 2019). Our
new proof techniques make elegant use of the intricate structures of the primal
and dual variables imposed by the KKT conditions and could be of independent
interest. Finally, we apply our results to the classical statistical problem of
locally adaptive non-parametric regression (Mammen, 1991; Donoho and Johnstone,
1998) and obtain a stronger and more flexible algorithm that do not require any
statistical assumptions or any hyperparameter tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Model for Inferring a Spatial Road Lane Network Graph using Self-Supervision. (arXiv:2107.01784v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1">Robin Karlsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1">David Robert Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Thompson_S/0/1/0/all/0/1">Simon Thompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1">Kazuya Takeda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01784">
                                    <div class="article-summary-box-inner">
                                        <span>Interconnected road lanes are a central concept for navigating urban roads.
Currently, most autonomous vehicles rely on preconstructed lane maps as
designing an algorithmic model is difficult. However, the generation and
maintenance of such maps is costly and hinders large-scale adoption of
autonomous vehicle technology. This paper presents the first self-supervised
learning method to train a model to infer a spatially grounded lane-level road
network graph based on a dense segmented representation of the road scene
generated from onboard sensors. A formal road lane network model is presented
and proves that any structured road scene can be represented by a directed
acyclic graph of at most depth three while retaining the notion of intersection
regions, and that this is the most compressed representation. The formal model
is implemented by a hybrid neural and search-based model, utilizing a novel
barrier function loss formulation for robust learning from partial labels.
Experiments are conducted for all common road intersection layouts. Results
show that the model can generalize to new road layouts, unlike previous
approaches, demonstrating its potential for real-world application as a
practical learning-based lane-level map generator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polymorphic dynamic programming by algebraic shortcut fusion. (arXiv:2107.01752v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Little_M/0/1/0/all/0/1">Max A. Little</a>, <a href="http://arxiv.org/find/cs/1/au:+Kayas_U/0/1/0/all/0/1">Ugur Kayas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01752">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic programming (DP) is a broadly applicable algorithmic design paradigm
for the efficient, exact solution of otherwise intractable, combinatorial
problems. However, the design of such algorithms is often presented informally
in an ad-hoc manner, and as a result is often difficult to apply correctly. In
this paper, we present a rigorous algebraic formalism for systematically
deriving novel DP algorithms, either from existing DP algorithms or from simple
functional recurrences. These derivations lead to algorithms which are provably
correct and polymorphic over any semiring, which means that they can be applied
to the full scope of combinatorial problems expressible in terms of semirings.
This includes, for example: optimization, optimal probability and Viterbi
decoding, probabilistic marginalization, logical inference, fuzzy sets,
differentiable softmax, and relational and provenance queries. The approach,
building on many ideas from the existing literature on constructive
algorithmics, exploits generic properties of (semiring) polymorphic functions,
tupling and formal sums (lifting), and algebraic simplifications arising from
constraint algebras. We demonstrate the effectiveness of this formalism for
some example applications arising in signal processing, bioinformatics and
reliability engineering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Predictability of Pruning Across Scales. (arXiv:2006.10621v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenfeld_J/0/1/0/all/0/1">Jonathan S. Rosenfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1">Jonathan Frankle</a>, <a href="http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1">Michael Carbin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shavit_N/0/1/0/all/0/1">Nir Shavit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10621">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the error of iteratively magnitude-pruned networks empirically
follows a scaling law with interpretable coefficients that depend on the
architecture and task. We functionally approximate the error of the pruned
networks, showing it is predictable in terms of an invariant tying width,
depth, and pruning level, such that networks of vastly different pruned
densities are interchangeable. We demonstrate the accuracy of this
approximation over orders of magnitude in depth, width, dataset size, and
density. We show that the functional form holds (generalizes) for large scale
data (e.g., ImageNet) and architectures (e.g., ResNets). As neural networks
become ever larger and costlier to train, our findings suggest a framework for
reasoning conceptually and analytically about a standard method for
unstructured pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning. (arXiv:2103.06326v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1">Samarth Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandlekar_A/0/1/0/all/0/1">Ajay Mandlekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1">Animesh Garg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06326">
                                    <div class="article-summary-box-inner">
                                        <span>Offline reinforcement learning proposes to learn policies from large
collected datasets without interacting with the physical environment. These
algorithms have made it possible to learn useful skills from data that can then
be deployed in the environment in real-world settings where interactions may be
costly or dangerous, such as autonomous driving or factories. However, current
algorithms overfit to the dataset they are trained on and exhibit poor
out-of-distribution generalization to the environment when deployed. In this
paper, we study the effectiveness of performing data augmentations on the state
space, and study 7 different augmentation schemes and how they behave with
existing offline RL algorithms. We then combine the best data performing
augmentation scheme with a state-of-the-art Q-learning technique, and improve
the function approximation of the Q-networks by smoothening out the learned
state-action space. We experimentally show that using this Surprisingly Simple
Self-Supervision technique in RL (S4RL), we significantly improve over the
current state-of-the-art algorithms on offline robot learning environments such
as MetaWorld [1] and RoboSuite [2,3], and benchmark datasets such as D4RL [4].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The MineRL BASALT Competition on Learning from Human Feedback. (arXiv:2107.01969v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Rohin Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Wild_C/0/1/0/all/0/1">Cody Wild</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Steven H. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Alex_N/0/1/0/all/0/1">Neel Alex</a>, <a href="http://arxiv.org/find/cs/1/au:+Houghton_B/0/1/0/all/0/1">Brandon Houghton</a>, <a href="http://arxiv.org/find/cs/1/au:+Guss_W/0/1/0/all/0/1">William Guss</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1">Sharada Mohanty</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanervisto_A/0/1/0/all/0/1">Anssi Kanervisto</a>, <a href="http://arxiv.org/find/cs/1/au:+Milani_S/0/1/0/all/0/1">Stephanie Milani</a>, <a href="http://arxiv.org/find/cs/1/au:+Topin_N/0/1/0/all/0/1">Nicholay Topin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1">Stuart Russell</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca Dragan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01969">
                                    <div class="article-summary-box-inner">
                                        <span>The last decade has seen a significant increase of interest in deep learning
research, with many public successes that have demonstrated its potential. As
such, these systems are now being incorporated into commercial products. With
this comes an additional challenge: how can we build AI systems that solve
tasks where there is not a crisp, well-defined specification? While multiple
solutions have been proposed, in this competition we focus on one in
particular: learning from human feedback. Rather than training AI systems using
a predefined reward function or using a labeled dataset with a predefined set
of categories, we instead train the AI system using a learning signal derived
from some form of human feedback, which can evolve over time as the
understanding of the task changes, or as the capabilities of the AI system
improve.

The MineRL BASALT competition aims to spur forward research on this important
class of techniques. We design a suite of four tasks in Minecraft for which we
expect it will be hard to write down hardcoded reward functions. These tasks
are defined by a paragraph of natural language: for example, &quot;create a
waterfall and take a scenic picture of it&quot;, with additional clarifying details.
Participants must train a separate agent for each task, using any method they
want. Agents are then evaluated by humans who have read the task description.
To help participants get started, we provide a dataset of human demonstrations
on each of the four tasks, as well as an imitation learning baseline that
leverages these demonstrations.

Our hope is that this competition will improve our ability to build AI
systems that do what their designers intend them to do, even when the intent
cannot be easily formalized. Besides allowing AI to solve more tasks, this can
also enable more effective regulation of AI systems, as well as making progress
on the value alignment problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing ROC Curves with a Sort-Based Surrogate Loss Function for Binary Classification and Changepoint Detection. (arXiv:2107.01285v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hillman_J/0/1/0/all/0/1">Jonathan Hillman</a>, <a href="http://arxiv.org/find/stat/1/au:+Hocking_T/0/1/0/all/0/1">Toby Dylan Hocking</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01285">
                                    <div class="article-summary-box-inner">
                                        <span>Receiver Operating Characteristic (ROC) curves are plots of true positive
rate versus false positive rate which are useful for evaluating binary
classification models, but difficult to use for learning since the Area Under
the Curve (AUC) is non-convex. ROC curves can also be used in other problems
that have false positive and true positive rates such as changepoint detection.
We show that in this more general context, the ROC curve can have loops, points
with highly sub-optimal error rates, and AUC greater than one. This observation
motivates a new optimization objective: rather than maximizing the AUC, we
would like a monotonic ROC curve with AUC&#x3D;1 that avoids points with large
values for Min(FP,FN). We propose a convex relaxation of this objective that
results in a new surrogate loss function called the AUM, short for Area Under
Min(FP, FN). Whereas previous loss functions are based on summing over all
labeled examples or pairs, the AUM requires a sort and a sum over the sequence
of points on the ROC curve. We show that AUM directional derivatives can be
efficiently computed and used in a gradient descent learning algorithm. In our
empirical study of supervised binary classification and changepoint detection
problems, we show that our new AUM minimization learning algorithm results in
improved AUC and comparable speed relative to previous baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automating Generative Deep Learning for Artistic Purposes: Challenges and Opportunities. (arXiv:2107.01858v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berns_S/0/1/0/all/0/1">Sebastian Berns</a>, <a href="http://arxiv.org/find/cs/1/au:+Broad_T/0/1/0/all/0/1">Terence Broad</a>, <a href="http://arxiv.org/find/cs/1/au:+Guckelsberger_C/0/1/0/all/0/1">Christian Guckelsberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Colton_S/0/1/0/all/0/1">Simon Colton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01858">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for automating generative deep learning with a
specific focus on artistic applications. The framework provides opportunities
to hand over creative responsibilities to a generative system as targets for
automation. For the definition of targets, we adopt core concepts from
automated machine learning and an analysis of generative deep learning
pipelines, both in standard and artistic settings. To motivate the framework,
we argue that automation aligns well with the goal of increasing the creative
responsibility of a generative system, a central theme in computational
creativity research. We understand automation as the challenge of granting a
generative system more creative autonomy, by framing the interaction between
the user and the system as a co-creative process. The development of the
framework is informed by our analysis of the relationship between automation
and creative autonomy. An illustrative example shows how the framework can give
inspiration and guidance in the process of handing over creative
responsibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BinarizedAttack: Structural Poisoning Attacks to Graph-based Anomaly Detection. (arXiv:2106.09989v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yulin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yuni Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kaifa Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiapu Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Mingquan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jian Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09989">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based Anomaly Detection (GAD) is becoming prevalent due to the powerful
representation abilities of graphs as well as recent advances in graph mining
techniques. These GAD tools, however, expose a new attacking surface,
ironically due to their unique advantage of being able to exploit the relations
among data. That is, attackers now can manipulate those relations (i.e., the
structure of the graph) to allow some target nodes to evade detection. In this
paper, we exploit this vulnerability by designing a new type of targeted
structural poisoning attacks to a representative regression-based GAD system
termed OddBall. Specially, we formulate the attack against OddBall as a
bi-level optimization problem, where the key technical challenge is to
efficiently solve the problem in a discrete domain. We propose a novel attack
method termed BinarizedAttack based on gradient descent. Comparing to prior
arts, BinarizedAttack can better use the gradient information, making it
particularly suitable for solving combinatorial optimization problems.
Furthermore, we investigate the attack transferability of BinarizedAttack by
employing it to attack other representation-learning-based GAD systems. Our
comprehensive experiments demonstrate that BinarizedAttack is very effective in
enabling target nodes to evade graph-based anomaly detection tools with limited
attackers&#x27; budget, and in the black-box transfer attack setting,
BinarizedAttack is also tested effective and in particular, can significantly
change the node embeddings learned by the GAD systems. Our research thus opens
the door to studying a new type of attack against security analytic tools that
rely on graph data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zeroth-Order Supervised Policy Improvement. (arXiv:2006.06600v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Ziping Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yuhang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Meng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Jiechao Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06600">
                                    <div class="article-summary-box-inner">
                                        <span>Policy gradient (PG) algorithms have been widely used in reinforcement
learning (RL). However, PG algorithms rely on exploiting the value function
being learned with the first-order update locally, which results in limited
sample efficiency. In this work, we propose an alternative method called
Zeroth-Order Supervised Policy Improvement (ZOSPI). ZOSPI exploits the
estimated value function $Q$ globally while preserving the local exploitation
of the PG methods based on zeroth-order policy optimization. This learning
paradigm follows Q-learning but overcomes the difficulty of efficiently
operating argmax in continuous action space. It finds max-valued action within
a small number of samples. The policy learning of ZOSPI has two steps: First,
it samples actions and evaluates those actions with a learned value estimator,
and then it learns to perform the action with the highest value through
supervised learning. We further demonstrate such a supervised learning
framework can learn multi-modal policies. Experiments show that ZOSPI achieves
competitive results on the continuous control benchmarks with a remarkable
sample efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. (arXiv:2006.12655v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laidlaw_C/0/1/0/all/0/1">Cassidy Laidlaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_S/0/1/0/all/0/1">Sahil Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12655">
                                    <div class="article-summary-box-inner">
                                        <span>A key challenge in adversarial robustness is the lack of a precise
mathematical characterization of human perception, used in the very definition
of adversarial attacks that are imperceptible to human eyes. Most current
attacks and defenses try to avoid this issue by considering restrictive
adversarial threat models such as those bounded by $L_2$ or $L_\infty$
distance, spatial perturbations, etc. However, models that are robust against
any of these restrictive threat models are still fragile against other threat
models. To resolve this issue, we propose adversarial training against the set
of all imperceptible adversarial examples, approximated using deep neural
networks. We call this threat model the neural perceptual threat model (NPTM);
it includes adversarial examples with a bounded neural perceptual distance (a
neural network-based approximation of the true perceptual distance) to natural
images. Through an extensive perceptual study, we show that the neural
perceptual distance correlates well with human judgements of perceptibility of
adversarial examples, validating our threat model.

Under the NPTM, we develop novel perceptual adversarial attacks and defenses.
Because the NPTM is very broad, we find that Perceptual Adversarial Training
(PAT) against a perceptual attack gives robustness against many other types of
adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five
diverse adversarial attacks. We find that PAT achieves state-of-the-art
robustness against the union of these five attacks, more than doubling the
accuracy over the next best model, without training against any of them. That
is, PAT generalizes well to unforeseen perturbation types. This is vital in
sensitive applications where a particular threat model cannot be assumed, and
to the best of our knowledge, PAT is the first adversarial training defense
with this property.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure by Architecture: Disentangled Representations without Regularization. (arXiv:2006.07796v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1">Felix Leeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanzillotta_G/0/1/0/all/0/1">Guilia Lanzillotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Annadani_Y/0/1/0/all/0/1">Yashas Annadani</a>, <a href="http://arxiv.org/find/cs/1/au:+Besserve_M/0/1/0/all/0/1">Michel Besserve</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07796">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of self-supervised structured representation learning
using autoencoders for generative modeling. Unlike most methods which rely on
matching an arbitrary, relatively unstructured, prior distribution for
sampling, we propose a sampling technique that relies solely on the
independence of latent variables, thereby avoiding the trade-off between
reconstruction quality and generative performance inherent to VAEs. We design a
novel autoencoder architecture capable of learning a structured representation
without the need for aggressive regularization. Our structural decoders learn a
hierarchy of latent variables, akin to structural causal models, thereby
ordering the information without any additional regularization. We demonstrate
how these models learn a representation that improves results in a variety of
downstream tasks including generation, disentanglement, and extrapolation using
several challenging and natural image datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Graph Neural Network Expressivity via Subgraph Isomorphism Counting. (arXiv:2006.09252v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bouritsas_G/0/1/0/all/0/1">Giorgos Bouritsas</a>, <a href="http://arxiv.org/find/cs/1/au:+Frasca_F/0/1/0/all/0/1">Fabrizio Frasca</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1">Michael M. Bronstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09252">
                                    <div class="article-summary-box-inner">
                                        <span>While Graph Neural Networks (GNNs) have achieved remarkable results in a
variety of applications, recent studies exposed important shortcomings in their
ability to capture the structure of the underlying graph. It has been shown
that the expressive power of standard GNNs is bounded by the Weisfeiler-Leman
(WL) graph isomorphism test, from which they inherit proven limitations such as
the inability to detect and count graph substructures. On the other hand, there
is significant empirical evidence, e.g. in network science and bioinformatics,
that substructures are often intimately related to downstream tasks. To this
end, we propose &quot;Graph Substructure Networks&quot; (GSN), a topologically-aware
message passing scheme based on substructure encoding. We theoretically analyse
the expressive power of our architecture, showing that it is strictly more
expressive than the WL test, and provide sufficient conditions for
universality. Importantly, we do not attempt to adhere to the WL hierarchy;
this allows us to retain multiple attractive properties of standard GNNs such
as locality and linear network complexity, while being able to disambiguate
even hard instances of graph isomorphism. We perform an extensive experimental
evaluation on graph classification and regression tasks and obtain
state-of-the-art results in diverse real-world settings including molecular
graphs and social networks. The code is publicly available at
https://github.com/gbouritsas/graph-substructure-networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variance-Dependent Best Arm Identification. (arXiv:2106.10417v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pinyan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chao Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaojin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10417">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of identifying the best arm in a stochastic multi-armed
bandit game. Given a set of $n$ arms indexed from $1$ to $n$, each arm $i$ is
associated with an unknown reward distribution supported on $[0,1]$ with mean
$\theta_i$ and variance $\sigma_i^2$. Assume $\theta_1 &gt; \theta_2 \geq \cdots
\geq\theta_n$. We propose an adaptive algorithm which explores the gaps and
variances of the rewards of the arms and makes future decisions based on the
gathered information using a novel approach called \textit{grouped median
elimination}. The proposed algorithm guarantees to output the best arm with
probability $(1-\delta)$ and uses at most $O \left(\sum_{i &#x3D; 1}^n
\left(\frac{\sigma_i^2}{\Delta_i^2} + \frac{1}{\Delta_i}\right)(\ln \delta^{-1}
+ \ln \ln \Delta_i^{-1})\right)$ samples, where $\Delta_i$ ($i \geq 2$) denotes
the reward gap between arm $i$ and the best arm and we define $\Delta_1 &#x3D;
\Delta_2$. This achieves a significant advantage over the variance-independent
algorithms in some favorable scenarios and is the first result that removes the
extra $\ln n$ factor on the best arm compared with the state-of-the-art. We
further show that $\Omega \left( \sum_{i &#x3D; 1}^n \left(
\frac{\sigma_i^2}{\Delta_i^2} + \frac{1}{\Delta_i} \right) \ln \delta^{-1}
\right)$ samples are necessary for an algorithm to achieve the same goal,
thereby illustrating that our algorithm is optimal up to doubly logarithmic
terms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Fidelity and Low-Latency Universal Neural Vocoder based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling. (arXiv:2105.09856v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1">Patrick Lumban Tobing</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1">Tomoki Toda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09856">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel high-fidelity and low-latency universal neural
vocoder framework based on multiband WaveRNN with data-driven linear prediction
for discrete waveform modeling (MWDLP). MWDLP employs a coarse-fine bit WaveRNN
architecture for 10-bit mu-law waveform modeling. A sparse gated recurrent unit
with a relatively large size of hidden units is utilized, while the multiband
modeling is deployed to achieve real-time low-latency usage. A novel technique
for data-driven linear prediction (LP) with discrete waveform modeling is
proposed, where the LP coefficients are estimated in a data-driven manner.
Moreover, a novel loss function using short-time Fourier transform (STFT) for
discrete waveform modeling with Gumbel approximation is also proposed. The
experimental results demonstrate that the proposed MWDLP framework generates
high-fidelity synthetic speech for seen and unseen speakers and/or language on
300 speakers training data including clean and noisy/reverberant conditions,
where the number of training utterances is limited to 60 per speaker, while
allowing for real-time low-latency processing using a single core of $\sim\!$
2.1--2.7 GHz CPU with $\sim\!$ 0.57--0.64 real-time factor including
input/output and feature extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Template-Based Graph Clustering. (arXiv:2107.01994v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Riva_M/0/1/0/all/0/1">Mateus Riva</a>, <a href="http://arxiv.org/find/stat/1/au:+Yger_F/0/1/0/all/0/1">Florian Yger</a>, <a href="http://arxiv.org/find/stat/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/stat/1/au:+Cesar_R/0/1/0/all/0/1">Roberto M. Cesar Jr.</a>, <a href="http://arxiv.org/find/stat/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01994">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel graph clustering method guided by additional information
on the underlying structure of the clusters (or communities). The problem is
formulated as the matching of a graph to a template with smaller dimension,
hence matching $n$ vertices of the observed graph (to be clustered) to the $k$
vertices of a template graph, using its edges as support information, and
relaxed on the set of orthonormal matrices in order to find a $k$ dimensional
embedding. With relevant priors that encode the density of the clusters and
their relationships, our method outperforms classical methods, especially for
challenging cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Restless Bandits: Tackling Interval Uncertainty with Deep Reinforcement Learning. (arXiv:2107.01689v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Killian_J/0/1/0/all/0/1">Jackson A. Killian</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lily Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Biswas_A/0/1/0/all/0/1">Arpita Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1">Milind Tambe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01689">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Robust Restless Bandits, a challenging generalization of
restless multi-arm bandits (RMAB). RMABs have been widely studied for
intervention planning with limited resources. However, most works make the
unrealistic assumption that the transition dynamics are known perfectly,
restricting the applicability of existing methods to real-world scenarios. To
make RMABs more useful in settings with uncertain dynamics: (i) We introduce
the Robust RMAB problem and develop solutions for a minimax regret objective
when transitions are given by interval uncertainties; (ii) We develop a double
oracle algorithm for solving Robust RMABs and demonstrate its effectiveness on
three experimental domains; (iii) To enable our double oracle approach, we
introduce RMABPPO, a novel deep reinforcement learning algorithm for solving
RMABs. RMABPPO hinges on learning an auxiliary &quot;$\lambda$-network&quot; that allows
each arm&#x27;s learning to decouple, greatly reducing sample complexity required
for training; (iv) Under minimax regret, the adversary in the double oracle
approach is notoriously difficult to implement due to non-stationarity. To
address this, we formulate the adversary oracle as a multi-agent reinforcement
learning problem and solve it with a multi-agent extension of RMABPPO, which
may be of independent interest as the first known algorithm for this setting.
Code is available at https://github.com/killian-34/RobustRMAB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarially Robust Kernel Smoothing. (arXiv:2102.08474v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jia-Jie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouridi_C/0/1/0/all/0/1">Christina Kouridi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nemmour_Y/0/1/0/all/0/1">Yassine Nemmour</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08474">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the adversarially robust kernel smoothing (ARKS) algorithm,
combining kernel smoothing, robust optimization, and adversarial training for
robust learning. Our methods are motivated by the convex analysis perspective
of distributionally robust optimization based on probability metrics, such as
the Wasserstein distance and the maximum mean discrepancy. We adapt the
integral operator using supremal convolution in convex analysis to form a novel
function majorant used for enforcing robustness. Our method is simple in form
and applies to general loss functions and machine learning models. Furthermore,
we report experiments with general machine learning models, such as deep neural
networks, to demonstrate that ARKS performs competitively with the
state-of-the-art methods based on the Wasserstein distance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Repurposing GANs for One-shot Semantic Part Segmentation. (arXiv:2103.04379v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tritrong_N/0/1/0/all/0/1">Nontawat Tritrong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rewatbowornwong_P/0/1/0/all/0/1">Pitchaporn Rewatbowornwong</a>, <a href="http://arxiv.org/find/cs/1/au:+Suwajanakorn_S/0/1/0/all/0/1">Supasorn Suwajanakorn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04379">
                                    <div class="article-summary-box-inner">
                                        <span>While GANs have shown success in realistic image generation, the idea of
using GANs for other tasks unrelated to synthesis is underexplored. Do GANs
learn meaningful structural parts of objects during their attempt to reproduce
those objects? In this work, we test this hypothesis and propose a simple and
effective approach based on GANs for semantic part segmentation that requires
as few as one label example along with an unlabeled dataset. Our key idea is to
leverage a trained GAN to extract pixel-wise representation from the input
image and use it as feature vectors for a segmentation network. Our experiments
demonstrate that GANs representation is &quot;readily discriminative&quot; and produces
surprisingly good results that are comparable to those from supervised
baselines trained with significantly more labels. We believe this novel
repurposing of GANs underlies a new class of unsupervised representation
learning that is applicable to many other tasks. More results are available at
https://repurposegans.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation for Sentiment Analysis Using Increased Intraclass Separation. (arXiv:2107.01598v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rostami_M/0/1/0/all/0/1">Mohammad Rostami</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01598">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis is a costly yet necessary task for enterprises to study
the opinions of their customers to improve their products and to determine
optimal marketing strategies. Due to the existence of a wide range of domains
across different products and services, cross-domain sentiment analysis methods
have received significant attention. These methods mitigate the domain gap
between different applications by training cross-domain generalizable
classifiers which help to relax the need for data annotation for each domain.
Most existing methods focus on learning domain-agnostic representations that
are invariant with respect to both the source and the target domains. As a
result, a classifier that is trained using the source domain annotated data
would generalize well in a related target domain. We introduce a new domain
adaptation method which induces large margins between different classes in an
embedding space. This embedding space is trained to be domain-agnostic by
matching the data distributions across the domains. Large intraclass margins in
the source domain help to reduce the effect of &quot;domain shift&quot; on the classifier
performance in the target domain. Theoretical and empirical analysis are
provided to demonstrate that the proposed method is effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal Transformer-Based Neural Correction Models for Automatic Speech Recognition. (arXiv:2107.01569v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1">Tomohiro Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Masumura_R/0/1/0/all/0/1">Ryo Masumura</a>, <a href="http://arxiv.org/find/cs/1/au:+Ihori_M/0/1/0/all/0/1">Mana Ihori</a>, <a href="http://arxiv.org/find/cs/1/au:+Takashima_A/0/1/0/all/0/1">Akihiko Takashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Moriya_T/0/1/0/all/0/1">Takafumi Moriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashihara_T/0/1/0/all/0/1">Takanori Ashihara</a>, <a href="http://arxiv.org/find/cs/1/au:+Orihashi_S/0/1/0/all/0/1">Shota Orihashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Makishima_N/0/1/0/all/0/1">Naoki Makishima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01569">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a cross-modal transformer-based neural correction models that
refines the output of an automatic speech recognition (ASR) system so as to
exclude ASR errors. Generally, neural correction models are composed of
encoder-decoder networks, which can directly model sequence-to-sequence mapping
problems. The most successful method is to use both input speech and its ASR
output text as the input contexts for the encoder-decoder networks. However,
the conventional method cannot take into account the relationships between
these two different modal inputs because the input contexts are separately
encoded for each modal. To effectively leverage the correlated information
between the two different modal inputs, our proposed models encode two
different contexts jointly on the basis of cross-modal self-attention using a
transformer. We expect that cross-modal self-attention can effectively capture
the relationships between two different modals for refining ASR hypotheses. We
also introduce a shallow fusion technique to efficiently integrate the
first-pass ASR model and our proposed neural correction model. Experiments on
Japanese natural language ASR tasks demonstrated that our proposed models
achieve better ASR performance than conventional neural correction models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Rate Learning in Stochastic First Price Bidding. (arXiv:2107.01835v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Achddou_J/0/1/0/all/0/1">Juliette Achddou</a> (PSL, DI-ENS, VALDA ), <a href="http://arxiv.org/find/cs/1/au:+Cappe_O/0/1/0/all/0/1">Olivier Capp&#xe9;</a> (LTCI, VALDA ), <a href="http://arxiv.org/find/cs/1/au:+Garivier_A/0/1/0/all/0/1">Aur&#xe9;lien Garivier</a> (UMPA-ENSL)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01835">
                                    <div class="article-summary-box-inner">
                                        <span>First-price auctions have largely replaced traditional bidding approaches
based on Vickrey auctions in programmatic advertising. As far as learning is
concerned, first-price auctions are more challenging because the optimal
bidding strategy does not only depend on the value of the item but also
requires some knowledge of the other bids. They have already given rise to
several works in sequential learning, many of which consider models for which
the value of the buyer or the opponents&#x27; maximal bid is chosen in an
adversarial manner. Even in the simplest settings, this gives rise to
algorithms whose regret grows as $\sqrt{T}$ with respect to the time horizon
$T$. Focusing on the case where the buyer plays against a stationary stochastic
environment, we show how to achieve significantly lower regret: when the
opponents&#x27; maximal bid distribution is known we provide an algorithm whose
regret can be as low as $\log^2(T)$; in the case where the distribution must be
learnt sequentially, a generalization of this algorithm can achieve $T^{1/3+
\epsilon}$ regret, for any $\epsilon&gt;0$. To obtain these results, we introduce
two novel ideas that can be of interest in their own right. First, by
transposing results obtained in the posted price setting, we provide conditions
under which the first-price biding utility is locally quadratic around its
optimum. Second, we leverage the observation that, on small sub-intervals, the
concentration of the variations of the empirical distribution function may be
controlled more accurately than by using the classical
Dvoretzky-Kiefer-Wolfowitz inequality. Numerical simulations confirm that our
algorithms converge much faster than alternatives proposed in the literature
for various bid distributions, including for bids collected on an actual
programmatic advertising platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Fluent Query Reformulations with Text-to-Text Transformers and Reinforcement Learning. (arXiv:2012.10033v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jerry Zikun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoran Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10033">
                                    <div class="article-summary-box-inner">
                                        <span>Query reformulation aims to alter noisy or ambiguous text sequences into
coherent ones closer to natural language questions. This is to prevent errors
from propagating in a client-facing pipeline and promote better communication
with users. Besides, it is crucial to maintain performance in downstream
environments like question answering when rephrased queries are given as input.
We show that under the previous framework (AQA), attempts to alter RL
algorithms do not bring significant benefits to either reward acquisition or
sequence fluency. Instead, we leverage a query-reformulating text-to-text
transformer (QRT5) and apply policy-based RL algorithms to further nudge this
reformulator and obtain better answers downstream by generating
reward-acquiring query trajectories. QRT5 shows better sample efficiency in RL
to achieve the same level of QA performance as the previous approach. It can
generate reformulations with more readability based on query well-formedness
evaluations and can generalize to out-of-sample data. Our framework is
demonstrated to be flexible, allowing reward signals to be sourced from
different downstream environments such as intent classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHORING: Design Provable Conditional High-Order Interaction Network via Symbolic Testing. (arXiv:2107.01326v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1">Xing Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Ruofan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jinyu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_K/0/1/0/all/0/1">Kai Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xiaofu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shuai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1">Leilei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_T/0/1/0/all/0/1">Tao Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yuan Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01326">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning provides a promising way to extract effective representations
from raw data in an end-to-end fashion and has proven its effectiveness in
various domains such as computer vision, natural language processing, etc.
However, in domains such as content/product recommendation and risk management,
where sequence of event data is the most used raw data form and experts derived
features are more commonly used, deep learning models struggle to dominate the
game. In this paper, we propose a symbolic testing framework that helps to
answer the question of what kinds of expert-derived features could be learned
by a neural network. Inspired by this testing framework, we introduce an
efficient architecture named SHORING, which contains two components:
\textit{event network} and \textit{sequence network}. The \textit{event}
network learns arbitrarily yet efficiently high-order \textit{event-level}
embeddings via a provable reparameterization trick, the \textit{sequence}
network aggregates from sequence of \textit{event-level} embeddings. We argue
that SHORING is capable of learning certain standard symbolic expressions which
the standard multi-head self-attention network fails to learn, and conduct
comprehensive experiments and ablation studies on four synthetic datasets and
three real-world datasets. The results show that SHORING empirically
outperforms the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian decision-making under misspecified priors with applications to meta-learning. (arXiv:2107.01509v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1">Max Simchowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tosh_C/0/1/0/all/0/1">Christopher Tosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1">Akshay Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1">Daniel Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1">Thodoris Lykouris</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1">Miroslav Dud&#xed;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Schapire_R/0/1/0/all/0/1">Robert E. Schapire</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01509">
                                    <div class="article-summary-box-inner">
                                        <span>Thompson sampling and other Bayesian sequential decision-making algorithms
are among the most popular approaches to tackle explore/exploit trade-offs in
(contextual) bandits. The choice of prior in these algorithms offers
flexibility to encode domain knowledge but can also lead to poor performance
when misspecified. In this paper, we demonstrate that performance degrades
gracefully with misspecification. We prove that the expected reward accrued by
Thompson sampling (TS) with a misspecified prior differs by at most
$\tilde{\mathcal{O}}(H^2 \epsilon)$ from TS with a well specified prior, where
$\epsilon$ is the total-variation distance between priors and $H$ is the
learning horizon. Our bound does not require the prior to have any parametric
form. For priors with bounded support, our bound is independent of the
cardinality or structure of the action space, and we show that it is tight up
to universal constants in the worst case.

Building on our sensitivity analysis, we establish generic PAC guarantees for
algorithms in the recently studied Bayesian meta-learning setting and derive
corollaries for various families of priors. Our results generalize along two
axes: (1) they apply to a broader family of Bayesian decision-making
algorithms, including a Monte-Carlo implementation of the knowledge gradient
algorithm (KG), and (2) they apply to Bayesian POMDPs, the most general
Bayesian decision-making setting, encompassing contextual bandits as a special
case. Through numerical simulations, we illustrate how prior misspecification
and the deployment of one-step look-ahead (as in KG) can impact the convergence
of meta-learning in multi-armed and contextual bandits with structured and
correlated priors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Uniformly Consistent Estimator of non-Gaussian Causal Effects Under the k-Triangle-Faithfulness Assumption. (arXiv:2107.01333v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Shuyan Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Spirtes_P/0/1/0/all/0/1">Peter Spirtes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01333">
                                    <div class="article-summary-box-inner">
                                        <span>Kalisch and B\&quot;{u}hlmann (2007) showed that for linear Gaussian models, under
the Causal Markov Assumption, the Strong Causal Faithfulness Assumption, and
the assumption of causal sufficiency, the PC algorithm is a uniformly
consistent estimator of the Markov Equivalence Class of the true causal DAG for
linear Gaussian models; it follows from this that for the identifiable causal
effects in the Markov Equivalence Class, there are uniformly consistent
estimators of causal effects as well. The $k$-Triangle-Faithfulness Assumption
is a strictly weaker assumption that avoids some implausible implications of
the Strong Causal Faithfulness Assumption and also allows for uniformly
consistent estimates of Markov Equivalence Classes (in a weakened sense), and
of identifiable causal effects. However, both of these assumptions are
restricted to linear Gaussian models. We propose the Generalized $k$-Triangle
Faithfulness, which can be applied to any smooth distribution. In addition,
under the Generalized $k$-Triangle Faithfulness Assumption, we describe the
Edge Estimation Algorithm that provides uniformly consistent estimates of
causal effects in some cases (and otherwise outputs &quot;can&#x27;t tell&quot;), and the
\textit{Very Conservative }$SGS$ Algorithm that (in a slightly weaker sense) is
a uniformly consistent estimator of the Markov equivalence class of the true
DAG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Faults during Automatic Screwdriving: A Dataset and Use Case of Anomaly Detection for Automatic Screwdriving. (arXiv:2107.01955v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leporowski_B/0/1/0/all/0/1">B&#x142;a&#x17c;ej Leporowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Tola_D/0/1/0/all/0/1">Daniella Tola</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_C/0/1/0/all/0/1">Casper Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01955">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting faults in manufacturing applications can be difficult, especially
if each fault model is to be engineered by hand. Data-driven approaches, using
Machine Learning (ML) for detecting faults have recently gained increasing
interest, where a ML model can be trained on a set of data from a manufacturing
process. In this paper, we present a use case of using ML models for detecting
faults during automated screwdriving operations, and introduce a new dataset
containing fully monitored and registered data from a Universal Robot and
OnRobot screwdriver during both normal and anomalous operations. We illustrate,
with the use of two time-series ML models, how to detect faults in an automated
screwdriving application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Debiased Representation via Disentangled Feature Augmentation. (arXiv:2107.01372v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1">Eungyeup Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jungsoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juyoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jihyeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01372">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification models tend to make decisions based on peripheral
attributes of data items that have strong correlation with a target variable
(i.e., dataset bias). These biased models suffer from the poor generalization
capability when evaluated on unbiased datasets. Existing approaches for
debiasing often identify and emphasize those samples with no such correlation
(i.e., bias-conflicting) without defining the bias type in advance. However,
such bias-conflicting samples are significantly scarce in biased datasets,
limiting the debiasing capability of these approaches. This paper first
presents an empirical analysis revealing that training with &quot;diverse&quot;
bias-conflicting samples beyond a given training set is crucial for debiasing
as well as the generalization capability. Based on this observation, we propose
a novel feature-level data augmentation technique in order to synthesize
diverse bias-conflicting samples. To this end, our method learns the
disentangled representation of (1) the intrinsic attributes (i.e., those
inherently defining a certain class) and (2) bias attributes (i.e., peripheral
attributes causing the bias), from a large number of bias-aligned samples, the
bias attributes of which have strong correlation with the target variable.
Using the disentangled representation, we synthesize bias-conflicting samples
that contain the diverse intrinsic attributes of bias-aligned samples by
swapping their latent features. By utilizing these diversified bias-conflicting
features during the training, our approach achieves superior classification
accuracy and debiasing results against the existing baselines on both synthetic
as well as real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring a Handwriting Programming Language for Educational Robots. (arXiv:2105.04963v2 [cs.PL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+El_Hamamsy_L/0/1/0/all/0/1">Laila El-Hamamsy</a>, <a href="http://arxiv.org/find/cs/1/au:+Papaspyros_V/0/1/0/all/0/1">Vaios Papaspyros</a>, <a href="http://arxiv.org/find/cs/1/au:+Kangur_T/0/1/0/all/0/1">Taavet Kangur</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathex_L/0/1/0/all/0/1">Laura Mathex</a>, <a href="http://arxiv.org/find/cs/1/au:+Giang_C/0/1/0/all/0/1">Christian Giang</a>, <a href="http://arxiv.org/find/cs/1/au:+Skweres_M/0/1/0/all/0/1">Melissa Skweres</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruno_B/0/1/0/all/0/1">Barbara Bruno</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondada_F/0/1/0/all/0/1">Francesco Mondada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04963">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, introducing computer science and educational robots in compulsory
education has received increasing attention. However, the use of screens in
classrooms is often met with resistance, especially in primary school. To
address this issue, this study presents the development of a handwriting-based
programming language for educational robots. Aiming to align better with
existing classroom practices, it allows students to program a robot by drawing
symbols with ordinary pens and paper. Regular smartphones are leveraged to
process the hand-drawn instructions using computer vision and machine learning
algorithms, and send the commands to the robot for execution. To align with the
local computer science curriculum, an appropriate playground and scaffolded
learning tasks were designed. The system was evaluated in a preliminary test
with eight teachers, developers and educational researchers. While the
participants pointed out that some technical aspects could be improved, they
also acknowledged the potential of the approach to make computer science
education in primary school more accessible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-view Graph Learning by Joint Modeling of Consistency and Inconsistency. (arXiv:2008.10208v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Youwei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chang-Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10208">
                                    <div class="article-summary-box-inner">
                                        <span>Graph learning has emerged as a promising technique for multi-view clustering
with its ability to learn a unified and robust graph from multiple views.
However, existing graph learning methods mostly focus on the multi-view
consistency issue, yet often neglect the inconsistency across multiple views,
which makes them vulnerable to possibly low-quality or noisy datasets. To
overcome this limitation, we propose a new multi-view graph learning framework,
which for the first time simultaneously and explicitly models multi-view
consistency and multi-view inconsistency in a unified objective function,
through which the consistent and inconsistent parts of each single-view graph
as well as the unified graph that fuses the consistent parts can be iteratively
learned. Though optimizing the objective function is NP-hard, we design a
highly efficient optimization algorithm which is able to obtain an approximate
solution with linear time complexity in the number of edges in the unified
graph. Furthermore, our multi-view graph learning approach can be applied to
both similarity graphs and dissimilarity graphs, which lead to two graph
fusion-based variants in our framework. Experiments on twelve multi-view
datasets have demonstrated the robustness and efficiency of the proposed
approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Implicit Bias for Adaptive Optimization Algorithms on Homogeneous Neural Networks. (arXiv:2012.06244v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bohan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Qi Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06244">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their overwhelming capacity to overfit, deep neural networks trained
by specific optimization algorithms tend to generalize well to unseen data.
Recently, researchers explained it by investigating the implicit regularization
effect of optimization algorithms. A remarkable progress is the work (Lyu&amp;Li,
2019), which proves gradient descent (GD) maximizes the margin of homogeneous
deep neural networks. Except GD, adaptive algorithms such as AdaGrad, RMSProp
and Adam are popular owing to their rapid training process. However,
theoretical guarantee for the generalization of adaptive optimization
algorithms is still lacking. In this paper, we study the implicit
regularization of adaptive optimization algorithms when they are optimizing the
logistic loss on homogeneous deep neural networks. We prove that adaptive
algorithms that adopt exponential moving average strategy in conditioner (such
as Adam and RMSProp) can maximize the margin of the neural network, while
AdaGrad that directly sums historical squared gradients in conditioner can not.
It indicates superiority on generalization of exponential moving average
strategy in the design of the conditioner. Technically, we provide a unified
framework to analyze convergent direction of adaptive optimization algorithms
by constructing novel adaptive gradient flow and surrogate margin. Our
experiments can well support the theoretical findings on convergent direction
of adaptive optimization algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certifiably Robust Interpretation via Renyi Differential Privacy. (arXiv:2107.01561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Ao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1">Lirong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01561">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the recent discovery that the interpretation maps of CNNs could
easily be manipulated by adversarial attacks against network interpretability,
we study the problem of interpretation robustness from a new perspective of
\Renyi differential privacy (RDP). The advantages of our Renyi-Robust-Smooth
(RDP-based interpretation method) are three-folds. First, it can offer provable
and certifiable top-$k$ robustness. That is, the top-$k$ important attributions
of the interpretation map are provably robust under any input perturbation with
bounded $\ell_d$-norm (for any $d\geq 1$, including $d &#x3D; \infty$). Second, our
proposed method offers $\sim10\%$ better experimental robustness than existing
approaches in terms of the top-$k$ attributions. Remarkably, the accuracy of
Renyi-Robust-Smooth also outperforms existing approaches. Third, our method can
provide a smooth tradeoff between robustness and computational efficiency.
Experimentally, its top-$k$ attributions are {\em twice} more robust than
existing approaches when the computational resources are highly constrained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Rigorous Interpretations: a Formalisation of Feature Attribution. (arXiv:2104.12437v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Afchar_D/0/1/0/all/0/1">Darius Afchar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennequin_R/0/1/0/all/0/1">Romain Hennequin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1">Vincent Guigue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12437">
                                    <div class="article-summary-box-inner">
                                        <span>Feature attribution is often loosely presented as the process of selecting a
subset of relevant features as a rationale of a prediction. Task-dependent by
nature, precise definitions of &quot;relevance&quot; encountered in the literature are
however not always consistent. This lack of clarity stems from the fact that we
usually do not have access to any notion of ground-truth attribution and from a
more general debate on what good interpretations are. In this paper we propose
to formalise feature selection/attribution based on the concept of relaxed
functional dependence. In particular, we extend our notions to the
instance-wise setting and derive necessary properties for candidate selection
solutions, while leaving room for task-dependence. By computing ground-truth
attributions on synthetic datasets, we evaluate many state-of-the-art
attribution methods and show that, even when optimised, some fail to verify the
proposed properties and provide wrong solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Knowledge-Enhanced Text Generation. (arXiv:2010.04389v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wenhao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenguang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zaitang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiting Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qingyun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04389">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of text generation is to make machines express in human language. It
is one of the most important yet challenging tasks in natural language
processing (NLP). Since 2014, various neural encoder-decoder models pioneered
by Seq2Seq have been proposed to achieve the goal by learning to map input text
to output text. However, the input text alone often provides limited knowledge
to generate the desired output, so the performance of text generation is still
far from satisfaction in many real-world scenarios. To address this issue,
researchers have considered incorporating various forms of knowledge beyond the
input text into the generation models. This research direction is known as
knowledge-enhanced text generation. In this survey, we present a comprehensive
review of the research on knowledge enhanced text generation over the past five
years. The main content includes two parts: (i) general methods and
architectures for integrating knowledge into text generation; (ii) specific
techniques and applications according to different forms of knowledge data.
This survey can have broad audiences, researchers and practitioners, in
academia and industry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WoodScape: A multi-task, multi-camera fisheye dataset for autonomous driving. (arXiv:1905.01489v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yogamani_S/0/1/0/all/0/1">Senthil Yogamani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_C/0/1/0/all/0/1">Ciaran Hughes</a>, <a href="http://arxiv.org/find/cs/1/au:+Horgan_J/0/1/0/all/0/1">Jonathan Horgan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sistu_G/0/1/0/all/0/1">Ganesh Sistu</a>, <a href="http://arxiv.org/find/cs/1/au:+Varley_P/0/1/0/all/0/1">Padraig Varley</a>, <a href="http://arxiv.org/find/cs/1/au:+ODea_D/0/1/0/all/0/1">Derek O&#x27;Dea</a>, <a href="http://arxiv.org/find/cs/1/au:+Uricar_M/0/1/0/all/0/1">Michal Uricar</a>, <a href="http://arxiv.org/find/cs/1/au:+Milz_S/0/1/0/all/0/1">Stefan Milz</a>, <a href="http://arxiv.org/find/cs/1/au:+Simon_M/0/1/0/all/0/1">Martin Simon</a>, <a href="http://arxiv.org/find/cs/1/au:+Amende_K/0/1/0/all/0/1">Karl Amende</a>, <a href="http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1">Christian Witt</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashed_H/0/1/0/all/0/1">Hazem Rashed</a>, <a href="http://arxiv.org/find/cs/1/au:+Chennupati_S/0/1/0/all/0/1">Sumanth Chennupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Nayak_S/0/1/0/all/0/1">Sanjaya Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansoor_S/0/1/0/all/0/1">Saquib Mansoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Perroton_X/0/1/0/all/0/1">Xavier Perroton</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1">Patrick Perez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.01489">
                                    <div class="article-summary-box-inner">
                                        <span>Fisheye cameras are commonly employed for obtaining a large field of view in
surveillance, augmented reality and in particular automotive applications. In
spite of their prevalence, there are few public datasets for detailed
evaluation of computer vision algorithms on fisheye images. We release the
first extensive fisheye automotive dataset, WoodScape, named after Robert Wood
who invented the fisheye camera in 1906. WoodScape comprises of four surround
view cameras and nine tasks including segmentation, depth estimation, 3D
bounding box detection and soiling detection. Semantic annotation of 40 classes
at the instance level is provided for over 10,000 images and annotation for
other tasks are provided for over 100,000 images. With WoodScape, we would like
to encourage the community to adapt computer vision models for fisheye camera
instead of using naive rectification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Short-term probabilistic photovoltaic power forecast based on deep convolutional long short-term memory network and kernel density estimation. (arXiv:2107.01343v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_M/0/1/0/all/0/1">Mingliang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xinyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1">Zhenhua Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jinfu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Daren Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01343">
                                    <div class="article-summary-box-inner">
                                        <span>Solar energy is a clean and renewable energy. Photovoltaic (PV) power is an
important way to utilize solar energy. Accurate PV power forecast is crucial to
the large-scale application of PV power and the stability of electricity grid.
This paper proposes a novel method for short-term photovoltaic power forecast
using deep convolutional long short-term memory (ConvLSTM) network and kernel
density estimation (KDE). In the proposed method, ConvLSTM is used to forecast
the future photovoltaic power and KDE is used for estimating the joint
probabilistic density function and giving the probabilistic confidence
interval. Experiments in an actual photovoltaic power station verify the
effectiveness of the proposed method. Comparison experiments with convolutional
neural network (CNN) and long short-term memory network (LSTM)shows that
ConvLSTM can combine the advantages of both CNN and LSTM and significantly
outperform CNN and LSTM in terms of forecast accuracy. Through further
comparison with other five conventional methods including multilayer perceptron
(MLP), support vector regression (SVR), extreme learning machine (ELM),
classification and regression tree (CART) and gradient boosting decision tree
(GBDT), ConvLSTM can significantly improve the forecast accuracy by more than
20% for most of the five methods and the superiorities of ConvLSTM are further
verified.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A convolutional neural network for prestack fracture detection. (arXiv:2107.01466v1 [physics.geo-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Yuan_Z/0/1/0/all/0/1">Zhenyu Yuan</a>, <a href="http://arxiv.org/find/physics/1/au:+Jiang_Y/0/1/0/all/0/1">Yuxin Jiang</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Huang_H/0/1/0/all/0/1">Handong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01466">
                                    <div class="article-summary-box-inner">
                                        <span>Fractures are widely developed in hydrocarbon reservoirs and constitute the
accumulation spaces and transport channels of oil and gas. Fracture detection
is a fundamental task for reservoir characterization. From prestack seismic
gathers, anisotropic analysis and inversion were commonly applied to
characterize the dominant orientations and relative intensities of fractures.
However, the existing methods were mostly based on the vertical aligned facture
hypothesis, it is impossible for them to recognize fracture dip. Furthermore,
it is difficult or impractical for existing methods to attain the real fracture
densities. Based on data-driven deep learning, this paper designed a
convolutional neural network to perform prestack fracture detection.
Capitalizing on the connections between seismic responses and fracture
parameters, a suitable azimuth dataset was firstly generated through fracture
effective medium modeling and anisotropic plane wave analyzing. Then a
multi-input and multi-output convolutional neural network was constructed to
simultaneously detect fracture density, dip and strike azimuth. The application
on a practical survey validated the effectiveness of the proposed CNN model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partition and Code: learning how to compress graphs. (arXiv:2107.01952v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bouritsas_G/0/1/0/all/0/1">Giorgos Bouritsas</a>, <a href="http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1">Andreas Loukas</a>, <a href="http://arxiv.org/find/cs/1/au:+Karalias_N/0/1/0/all/0/1">Nikolaos Karalias</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1">Michael M. Bronstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01952">
                                    <div class="article-summary-box-inner">
                                        <span>Can we use machine learning to compress graph data? The absence of ordering
in graphs poses a significant challenge to conventional compression algorithms,
limiting their attainable gains as well as their ability to discover relevant
patterns. On the other hand, most graph compression approaches rely on
domain-dependent handcrafted representations and cannot adapt to different
underlying graph distributions. This work aims to establish the necessary
principles a lossless graph compression method should follow to approach the
entropy storage lower bound. Instead of making rigid assumptions about the
graph distribution, we formulate the compressor as a probabilistic model that
can be learned from data and generalise to unseen instances. Our &quot;Partition and
Code&quot; framework entails three steps: first, a partitioning algorithm decomposes
the graph into elementary structures, then these are mapped to the elements of
a small dictionary on which we learn a probability distribution, and finally,
an entropy encoder translates the representation into bits. All three steps are
parametric and can be trained with gradient descent. We theoretically compare
the compression quality of several graph encodings and prove, under mild
conditions, a total ordering of their expected description lengths. Moreover,
we show that, under the same conditions, PnC achieves compression gains w.r.t.
the baselines that grow either linearly or quadratically with the number of
vertices. Our algorithms are quantitatively evaluated on diverse real-world
networks obtaining significant performance improvements with respect to
different families of non-parametric and parametric graph compressors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why is Pruning at Initialization Immune to Reinitializing and Shuffling?. (arXiv:2107.01808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sahib Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rosanne Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01808">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies assessing the efficacy of pruning neural networks methods
uncovered a surprising finding: when conducting ablation studies on existing
pruning-at-initialization methods, namely SNIP, GraSP, SynFlow, and magnitude
pruning, performances of these methods remain unchanged and sometimes even
improve when randomly shuffling the mask positions within each layer (Layerwise
Shuffling) or sampling new initial weight values (Reinit), while keeping
pruning masks the same. We attempt to understand the reason behind such network
immunity towards weight/mask modifications, by studying layer-wise statistics
before and after randomization operations. We found that under each of the
pruning-at-initialization methods, the distribution of unpruned weights changed
minimally with randomization operations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imputation-Free Learning from Incomplete Observations. (arXiv:2107.01983v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qitong Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Amason_J/0/1/0/all/0/1">Joshua D. Amason</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1">Siyang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1">Ricardo Henao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadziahmetovic_M/0/1/0/all/0/1">Majda Hadziahmetovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pajic_M/0/1/0/all/0/1">Miroslav Pajic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01983">
                                    <div class="article-summary-box-inner">
                                        <span>Although recent works have developed methods that can generate estimations
(or imputations) of the missing entries in a dataset to facilitate downstream
analysis, most depend on assumptions that may not align with real-world
applications and could suffer from poor performance in subsequent tasks. This
is particularly true if the data have large missingness rates or a small
population. More importantly, the imputation error could be propagated into the
prediction step that follows, causing the gradients used to train the
prediction models to be biased. Consequently, in this work, we introduce the
importance guided stochastic gradient descent (IGSGD) method to train
multilayer perceptrons (MLPs) and long short-term memories (LSTMs) to directly
perform inference from inputs containing missing values without imputation.
Specifically, we employ reinforcement learning (RL) to adjust the gradients
used to train the models via back-propagation. This not only reduces bias but
allows the model to exploit the underlying information behind missingness
patterns. We test the proposed approach on real-world time-series (i.e.,
MIMIC-III), tabular data obtained from an eye clinic, and a standard dataset
(i.e., MNIST), where our imputation-free predictions outperform the traditional
two-step imputation-based predictions using state-of-the-art imputation
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning in nonatomic games, Part I: Finite action spaces and population games. (arXiv:2107.01595v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hadikhanloo_S/0/1/0/all/0/1">Saeed Hadikhanloo</a>, <a href="http://arxiv.org/find/cs/1/au:+Laraki_R/0/1/0/all/0/1">Rida Laraki</a>, <a href="http://arxiv.org/find/cs/1/au:+Mertikopoulos_P/0/1/0/all/0/1">Panayotis Mertikopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorin_S/0/1/0/all/0/1">Sylvain Sorin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01595">
                                    <div class="article-summary-box-inner">
                                        <span>We examine the long-run behavior of a wide range of dynamics for learning in
nonatomic games, in both discrete and continuous time. The class of dynamics
under consideration includes fictitious play and its regularized variants, the
best-reply dynamics (again, possibly regularized), as well as the dynamics of
dual averaging / &quot;follow the regularized leader&quot; (which themselves include as
special cases the replicator dynamics and Friedman&#x27;s projection dynamics). Our
analysis concerns both the actual trajectory of play and its time-average, and
we cover potential and monotone games, as well as games with an evolutionarily
stable state (global or otherwise). We focus exclusively on games with finite
action spaces; nonatomic games with continuous action spaces are treated in
detail in Part II of this paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Robustness of Probabilistic Network Embedding for Link Prediction. (arXiv:2107.01936v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1">Bo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lijffijt_J/0/1/0/all/0/1">Jefrey Lijffijt</a>, <a href="http://arxiv.org/find/cs/1/au:+Bie_T/0/1/0/all/0/1">Tijl De Bie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01936">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s networked society, many real-world problems can be formalized as
predicting links in networks, such as Facebook friendship suggestions,
e-commerce recommendations, and the prediction of scientific collaborations in
citation networks. Increasingly often, link prediction problem is tackled by
means of network embedding methods, owing to their state-of-the-art
performance. However, these methods lack transparency when compared to simpler
baselines, and as a result their robustness against adversarial attacks is a
possible point of concern: could one or a few small adversarial modifications
to the network have a large impact on the link prediction performance when
using a network embedding model? Prior research has already investigated
adversarial robustness for network embedding models, focused on classification
at the node and graph level. Robustness with respect to the link prediction
downstream task, on the other hand, has been explored much less.

This paper contributes to filling this gap, by studying adversarial
robustness of Conditional Network Embedding (CNE), a state-of-the-art
probabilistic network embedding model, for link prediction. More specifically,
given CNE and a network, we measure the sensitivity of the link predictions of
the model to small adversarial perturbations of the network, namely changes of
the link status of a node pair. Thus, our approach allows one to identify the
links and non-links in the network that are most vulnerable to such
perturbations, for further investigation by an analyst. We analyze the
characteristics of the most and least sensitive perturbations, and empirically
confirm that our approach not only succeeds in identifying the most vulnerable
links and non-links, but also that it does so in a time-efficient manner thanks
to an effective approximation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepRapper: Neural Rap Generation with Rhyme and Rhythm Modeling. (arXiv:2107.01875v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1">Lanqing Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kaitao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Duocai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Nevin L. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01875">
                                    <div class="article-summary-box-inner">
                                        <span>Rap generation, which aims to produce lyrics and corresponding singing beats,
needs to model both rhymes and rhythms. Previous works for rap generation
focused on rhyming lyrics but ignored rhythmic beats, which are important for
rap performance. In this paper, we develop DeepRapper, a Transformer-based rap
generation system that can model both rhymes and rhythms. Since there is no
available rap dataset with rhythmic beats, we develop a data mining pipeline to
collect a large-scale rap dataset, which includes a large number of rap songs
with aligned lyrics and rhythmic beats. Second, we design a Transformer-based
autoregressive language model which carefully models rhymes and rhythms.
Specifically, we generate lyrics in the reverse order with rhyme representation
and constraint for rhyme enhancement and insert a beat symbol into lyrics for
rhythm/beat modeling. To our knowledge, DeepRapper is the first system to
generate rap with both rhymes and rhythms. Both objective and subjective
evaluations demonstrate that DeepRapper generates creative and high-quality
raps with rhymes and rhythms. Code will be released on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pool of Experts: Realtime Querying Specialized Knowledge in Massive Neural Networks. (arXiv:2107.01354v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hakbin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dong-Wan Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01354">
                                    <div class="article-summary-box-inner">
                                        <span>In spite of the great success of deep learning technologies, training and
delivery of a practically serviceable model is still a highly time-consuming
process. Furthermore, a resulting model is usually too generic and heavyweight,
and hence essentially goes through another expensive model compression phase to
fit in a resource-limited device like embedded systems. Inspired by the fact
that a machine learning task specifically requested by mobile users is often
much simpler than it is supported by a massive generic model, this paper
proposes a framework, called Pool of Experts (PoE), that instantly builds a
lightweight and task-specific model without any training process. For a
realtime model querying service, PoE first extracts a pool of primitive
components, called experts, from a well-trained and sufficiently generic
network by exploiting a novel conditional knowledge distillation method, and
then performs our train-free knowledge consolidation to quickly combine
necessary experts into a lightweight network for a target task. Thanks to this
train-free property, in our thorough empirical study, PoE can build a fairly
accurate yet compact model in a realtime manner, whereas it takes a few minutes
per query for the other training methods to achieve a similar level of the
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poisoning Attack against Estimating from Pairwise Comparisons. (arXiv:2107.01854v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Ke Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qianqian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Jinshan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaochun Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01854">
                                    <div class="article-summary-box-inner">
                                        <span>As pairwise ranking becomes broadly employed for elections, sports
competitions, recommendations, and so on, attackers have strong motivation and
incentives to manipulate the ranking list. They could inject malicious
comparisons into the training data to fool the victim. Such a technique is
called poisoning attack in regression and classification tasks. In this paper,
to the best of our knowledge, we initiate the first systematic investigation of
data poisoning attacks on pairwise ranking algorithms, which can be formalized
as the dynamic and static games between the ranker and the attacker and can be
modeled as certain kinds of integer programming problems. To break the
computational hurdle of the underlying integer programming problems, we
reformulate them into the distributionally robust optimization (DRO) problems,
which are computationally tractable. Based on such DRO formulations, we propose
two efficient poisoning attack algorithms and establish the associated
theoretical guarantees. The effectiveness of the suggested poisoning attack
strategies is demonstrated by a series of toy simulations and several real data
experiments. These experimental results show that the proposed methods can
significantly reduce the performance of the ranker in the sense that the
correlation between the true ranking list and the aggregated results can be
decreased dramatically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maximum Entropy Weighted Independent Set Pooling for Graph Neural Networks. (arXiv:2107.01410v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nouranizadeh_A/0/1/0/all/0/1">Amirhossein Nouranizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Matinkia_M/0/1/0/all/0/1">Mohammadjavad Matinkia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmati_M/0/1/0/all/0/1">Mohammad Rahmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Safabakhsh_R/0/1/0/all/0/1">Reza Safabakhsh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01410">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel pooling layer for graph neural networks
based on maximizing the mutual information between the pooled graph and the
input graph. Since the maximum mutual information is difficult to compute, we
employ the Shannon capacity of a graph as an inductive bias to our pooling
method. More precisely, we show that the input graph to the pooling layer can
be viewed as a representation of a noisy communication channel. For such a
channel, sending the symbols belonging to an independent set of the graph
yields a reliable and error-free transmission of information. We show that
reaching the maximum mutual information is equivalent to finding a maximum
weight independent set of the graph where the weights convey entropy contents.
Through this communication theoretic standpoint, we provide a distinct
perspective for posing the problem of graph pooling as maximizing the
information transmission rate across a noisy communication channel, implemented
by a graph neural network. We evaluate our method, referred to as Maximum
Entropy Weighted Independent Set Pooling (MEWISPool), on graph classification
tasks and the combinatorial optimization problem of the maximum independent
set. Empirical results demonstrate that our method achieves the
state-of-the-art and competitive results on graph classification tasks and the
maximum independent set problem in several benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Average-Case Communication Complexity of Statistical Problems. (arXiv:2107.01335v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rashtchian_C/0/1/0/all/0/1">Cyrus Rashtchian</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1">Peng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hanlin Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01335">
                                    <div class="article-summary-box-inner">
                                        <span>We study statistical problems, such as planted clique, its variants, and
sparse principal component analysis in the context of average-case
communication complexity. Our motivation is to understand the
statistical-computational trade-offs in streaming, sketching, and query-based
models. Communication complexity is the main tool for proving lower bounds in
these models, yet many prior results do not hold in an average-case setting. We
provide a general reduction method that preserves the input distribution for
problems involving a random graph or matrix with planted structure. Then, we
derive two-party and multi-party communication lower bounds for detecting or
finding planted cliques, bipartite cliques, and related problems. As a
consequence, we obtain new bounds on the query complexity in the edge-probe,
vector-matrix-vector, matrix-vector, linear sketching, and
$\mathbb{F}_2$-sketching models. Many of these results are nearly tight, and we
use our techniques to provide simple proofs of some known lower bounds for the
edge-probe model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphXCOVID: Explainable Deep Graph Diffusion Pseudo-Labelling for Identifying COVID-19 on Chest X-rays. (arXiv:2010.00378v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1">Angelica I Aviles-Rivero</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellars_P/0/1/0/all/0/1">Philip Sellars</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Sch&#xf6;nlieb</a>, <a href="http://arxiv.org/find/cs/1/au:+Papadakis_N/0/1/0/all/0/1">Nicolas Papadakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00378">
                                    <div class="article-summary-box-inner">
                                        <span>Can one learn to diagnose COVID-19 under extreme minimal supervision? Since
the outbreak of the novel COVID-19 there has been a rush for developing
Artificial Intelligence techniques for expert-level disease identification on
Chest X-ray data. In particular, the use of deep supervised learning has become
the go-to paradigm. However, the performance of such models is heavily
dependent on the availability of a large and representative labelled dataset.
The creation of which is a heavily expensive and time consuming task, and
especially imposes a great challenge for a novel disease. Semi-supervised
learning has shown the ability to match the incredible performance of
supervised models whilst requiring a small fraction of the labelled examples.
This makes the semi-supervised paradigm an attractive option for identifying
COVID-19. In this work, we introduce a graph based deep semi-supervised
framework for classifying COVID-19 from chest X-rays. Our framework introduces
an optimisation model for graph diffusion that reinforces the natural relation
among the tiny labelled set and the vast unlabelled data. We then connect the
diffusion prediction output as pseudo-labels that are used in an iterative
scheme in a deep net. We demonstrate, through our experiments, that our model
is able to outperform the current leading supervised model with a tiny fraction
of the labelled examples. Finally, we provide attention maps to accommodate the
radiologist&#x27;s mental model, better fitting their perceptual and cognitive
abilities. These visualisation aims to assist the radiologist in judging
whether the diagnostic is correct or not, and in consequence to accelerate the
decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Slope and generalization properties of neural networks. (arXiv:2107.01473v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Johansson_A/0/1/0/all/0/1">Anton Johansson</a>, <a href="http://arxiv.org/find/stat/1/au:+Engsner_N/0/1/0/all/0/1">Niklas Engsner</a>, <a href="http://arxiv.org/find/stat/1/au:+Strannegaard_C/0/1/0/all/0/1">Claes Stranneg&#xe5;rd</a>, <a href="http://arxiv.org/find/stat/1/au:+Mostad_P/0/1/0/all/0/1">Petter Mostad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01473">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are very successful tools in for example advanced
classification. From a statistical point of view, fitting a neural network may
be seen as a kind of regression, where we seek a function from the input space
to a space of classification probabilities that follows the &quot;general&quot; shape of
the data, but avoids overfitting by avoiding memorization of individual data
points. In statistics, this can be done by controlling the geometric complexity
of the regression function. We propose to do something similar when fitting
neural networks by controlling the slope of the network.

After defining the slope and discussing some of its theoretical properties,
we go on to show empirically in examples, using ReLU networks, that the
distribution of the slope of a well-trained neural network classifier is
generally independent of the width of the layers in a fully connected network,
and that the mean of the distribution only has a weak dependence on the model
architecture in general. The slope is of similar size throughout the relevant
volume, and varies smoothly. It also behaves as predicted in rescaling
examples. We discuss possible applications of the slope concept, such as using
it as a part of the loss function or stopping criterion during network
training, or ranking data sets in terms of their complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Few-Shot Learning with Frozen Language Models. (arXiv:2106.13884v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsimpoukelli_M/0/1/0/all/0/1">Maria Tsimpoukelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1">Jacob Menick</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabi_S/0/1/0/all/0/1">Serkan Cabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1">S. M. Ali Eslami</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1">Oriol Vinyals</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13884">
                                    <div class="article-summary-box-inner">
                                        <span>When trained at sufficient scale, auto-regressive language models exhibit the
notable ability to learn a new language task after being prompted with just a
few examples. Here, we present a simple, yet effective, approach for
transferring this few-shot learning ability to a multimodal setting (vision and
language). Using aligned image and caption data, we train a vision encoder to
represent each image as a sequence of continuous embeddings, such that a
pre-trained, frozen language model prompted with this prefix generates the
appropriate caption. The resulting system is a multimodal few-shot learner,
with the surprising ability to learn a variety of new tasks when conditioned on
examples, represented as a sequence of multiple interleaved image and text
embeddings. We demonstrate that it can rapidly learn words for new objects and
novel visual categories, do visual question-answering with only a handful of
examples, and make use of outside knowledge, by measuring a single model on a
variety of established and new benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaL: Adaptive Gradient Transformation Contributes to Convergences and Generalizations. (arXiv:2107.01525v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1">Weidong Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hongbo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_Q/0/1/0/all/0/1">Qi Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1">Tijin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yuanqing Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_W/0/1/0/all/0/1">Weipeng Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01525">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive optimization methods have been widely used in deep learning. They
scale the learning rates adaptively according to the past gradient, which has
been shown to be effective to accelerate the convergence. However, they suffer
from poor generalization performance compared with SGD. Recent studies point
that smoothing exponential gradient noise leads to generalization degeneration
phenomenon. Inspired by this, we propose AdaL, with a transformation on the
original gradient. AdaL accelerates the convergence by amplifying the gradient
in the early stage, as well as dampens the oscillation and stabilizes the
optimization by shrinking the gradient later. Such modification alleviates the
smoothness of gradient noise, which produces better generalization performance.
We have theoretically proved the convergence of AdaL and demonstrated its
effectiveness on several benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prescient teleoperation of humanoid robots. (arXiv:2107.01281v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Penco_L/0/1/0/all/0/1">Luigi Penco</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouret_J/0/1/0/all/0/1">Jean-Baptiste Mouret</a>, <a href="http://arxiv.org/find/cs/1/au:+Ivaldi_S/0/1/0/all/0/1">Serena Ivaldi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01281">
                                    <div class="article-summary-box-inner">
                                        <span>Humanoid robots could be versatile and intuitive human avatars that operate
remotely in inaccessible places: the robot could reproduce in the remote
location the movements of an operator equipped with a wearable motion capture
device while sending visual feedback to the operator. While substantial
progress has been made on transferring (&quot;retargeting&quot;) human motions to
humanoid robots, a major problem preventing the deployment of such systems in
real applications is the presence of communication delays between the human
input and the feedback from the robot: even a few hundred milliseconds of delay
can irreversibly disturb the operator, let alone a few seconds. To overcome
these delays, we introduce a system in which a humanoid robot executes commands
before it actually receives them, so that the visual feedback appears to be
synchronized to the operator, whereas the robot executed the commands in the
past. To do so, the robot continuously predicts future commands by querying a
machine learning model that is trained on past trajectories and conditioned on
the last received commands. In our experiments, an operator was able to
successfully control a humanoid robot (32 degrees of freedom) with stochastic
delays up to 2 seconds in several whole-body manipulation tasks, including
reaching different targets, picking up, and placing a box at distinct
locations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recent Theoretical Advances in Non-Convex Optimization. (arXiv:2012.06188v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Danilova_M/0/1/0/all/0/1">Marina Danilova</a>, <a href="http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1">Pavel Dvurechensky</a>, <a href="http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1">Alexander Gasnikov</a>, <a href="http://arxiv.org/find/math/1/au:+Gorbunov_E/0/1/0/all/0/1">Eduard Gorbunov</a>, <a href="http://arxiv.org/find/math/1/au:+Guminov_S/0/1/0/all/0/1">Sergey Guminov</a>, <a href="http://arxiv.org/find/math/1/au:+Kamzolov_D/0/1/0/all/0/1">Dmitry Kamzolov</a>, <a href="http://arxiv.org/find/math/1/au:+Shibaev_I/0/1/0/all/0/1">Innokentiy Shibaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06188">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by recent increased interest in optimization algorithms for
non-convex optimization in application to training deep neural networks and
other optimization problems in data analysis, we give an overview of recent
theoretical results on global performance guarantees of optimization algorithms
for non-convex optimization. We start with classical arguments showing that
general non-convex problems could not be solved efficiently in a reasonable
time. Then we give a list of problems that can be solved efficiently to find
the global minimizer by exploiting the structure of the problem as much as it
is possible. Another way to deal with non-convexity is to relax the goal from
finding the global minimum to finding a stationary point or a local minimum.
For this setting, we first present known results for the convergence rates of
deterministic first-order methods, which are then followed by a general
theoretical analysis of optimal stochastic and randomized gradient schemes, and
an overview of the stochastic first-order methods. After that, we discuss quite
general classes of non-convex problems, such as minimization of
$\alpha$-weakly-quasi-convex functions and functions that satisfy
Polyak--Lojasiewicz condition, which still allow obtaining theoretical
convergence guarantees of first-order methods. Then we consider higher-order
and zeroth-order/derivative-free methods and their convergence rates for
non-convex optimization problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Cost Functions for Optimal Transport. (arXiv:2002.09650v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shaojun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haodong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaojing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Haomin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.09650">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse optimal transport (OT) refers to the problem of learning the cost
function for OT from observed transport plan or its samples. In this paper, we
derive an unconstrained convex optimization formulation of the inverse OT
problem, which can be further augmented by any customizable regularization. We
provide a comprehensive characterization of the properties of inverse OT,
including uniqueness of solutions. We also develop two numerical algorithms,
one is a fast matrix scaling method based on the Sinkhorn-Knopp algorithm for
discrete OT, and the other one is a learning based algorithm that parameterizes
the cost function as a deep neural network for continuous OT. The novel
framework proposed in the work avoids repeatedly solving a forward OT in each
iteration which has been a thorny computational bottleneck for the bi-level
optimization in existing inverse OT approaches. Numerical results demonstrate
promising efficiency and accuracy advantages of the proposed algorithms over
existing state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Relate Depth and Semantics for Unsupervised Domain Adaptation. (arXiv:2105.07830v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Suman Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Obukhov_A/0/1/0/all/0/1">Anton Obukhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudel_D/0/1/0/all/0/1">Danda Pani Paudel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanakis_M/0/1/0/all/0/1">Menelaos Kanakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuhua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1">Stamatios Georgoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07830">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for encoding visual task relationships to improve
model performance in an Unsupervised Domain Adaptation (UDA) setting. Semantic
segmentation and monocular depth estimation are shown to be complementary
tasks; in a multi-task learning setting, a proper encoding of their
relationships can further improve performance on both tasks. Motivated by this
observation, we propose a novel Cross-Task Relation Layer (CTRL), which encodes
task dependencies between the semantic and depth predictions. To capture the
cross-task relationships, we propose a neural network architecture that
contains task-specific and cross-task refinement heads. Furthermore, we propose
an Iterative Self-Learning (ISL) training scheme, which exploits semantic
pseudo-labels to provide extra supervision on the target domain. We
experimentally observe improvements in both tasks&#x27; performance because the
complementary information present in these tasks is better captured.
Specifically, we show that: (1) our approach improves performance on all tasks
when they are complementary and mutually dependent; (2) the CTRL helps to
improve both semantic segmentation and depth estimation tasks performance in
the challenging UDA setting; (3) the proposed ISL training scheme further
improves the semantic segmentation performance. The implementation is available
at https://github.com/susaha/ctrl-uda.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bag of Tricks for Node Classification with Graph Neural Networks. (arXiv:2103.13355v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yangkun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiarui Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1">David Wipf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13355">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past few years, graph neural networks (GNN) and label
propagation-based methods have made significant progress in addressing node
classification tasks on graphs. However, in addition to their reliance on
elaborate architectures and algorithms, there are several key technical details
that are frequently overlooked, and yet nonetheless can play a vital role in
achieving satisfactory performance. In this paper, we first summarize a series
of existing tricks-of-the-trade, and then propose several new ones related to
label usage, loss function formulation, and model design that can significantly
improve various GNN architectures. We empirically evaluate their impact on
final node classification accuracy by conducting ablation studies and
demonstrate consistently-improved performance, often to an extent that
outweighs the gains from more dramatic changes in the underlying GNN
architecture. Notably, many of the top-ranked models on the Open Graph
Benchmark (OGB) leaderboard and KDDCUP 2021 Large-Scale Challenge MAG240M-LSC
benefit from these techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainability via Interactivity? Supporting Nonexperts&#x27; Sensemaking of Pretrained CNN by Interacting with Their Daily Surroundings. (arXiv:2107.01996v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+An_P/0/1/0/all/0/1">Pengcheng An</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01996">
                                    <div class="article-summary-box-inner">
                                        <span>Current research on Explainable AI (XAI) heavily targets on expert users
(data scientists or AI developers). However, increasing importance has been
argued for making AI more understandable to nonexperts, who are expected to
leverage AI techniques, but have limited knowledge about AI. We present a
mobile application to support nonexperts to interactively make sense of
Convolutional Neural Networks (CNN); it allows users to play with a pretrained
CNN by taking pictures of their surrounding objects. We use an up-to-date XAI
technique (Class Activation Map) to intuitively visualize the model&#x27;s decision
(the most important image regions that lead to a certain result). Deployed in a
university course, this playful learning tool was found to support design
students to gain vivid understandings about the capabilities and limitations of
pretrained CNNs in real-world environments. Concrete examples of students&#x27;
playful explorations are reported to characterize their sensemaking processes
reflecting different depths of thought.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Information-Theoretic Approach for Automatically Determining the Number of States when Aggregating Markov Chains. (arXiv:2107.01799v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sledge_I/0/1/0/all/0/1">Isaac J. Sledge</a>, <a href="http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1">Jose C. Principe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01799">
                                    <div class="article-summary-box-inner">
                                        <span>A fundamental problem when aggregating Markov chains is the specification of
the number of state groups. Too few state groups may fail to sufficiently
capture the pertinent dynamics of the original, high-order Markov chain. Too
many state groups may lead to a non-parsimonious, reduced-order Markov chain
whose complexity rivals that of the original. In this paper, we show that an
augmented value-of-information-based approach to aggregating Markov chains
facilitates the determination of the number of state groups. The optimal
state-group count coincides with the case where the complexity of the
reduced-order chain is balanced against the mutual dependence between the
original- and reduced-order chain dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent structure blockmodels for Bayesian spectral graph clustering. (arXiv:2107.01734v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Passino_F/0/1/0/all/0/1">Francesco Sanna Passino</a>, <a href="http://arxiv.org/find/stat/1/au:+Heard_N/0/1/0/all/0/1">Nicholas A. Heard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01734">
                                    <div class="article-summary-box-inner">
                                        <span>Spectral embedding of network adjacency matrices often produces node
representations living approximately around low-dimensional submanifold
structures. In particular, hidden substructure is expected to arise when the
graph is generated from a latent position model. Furthermore, the presence of
communities within the network might generate community-specific submanifold
structures in the embedding, but this is not explicitly accounted for in most
statistical models for networks. In this article, a class of models called
latent structure block models (LSBM) is proposed to address such scenarios,
allowing for graph clustering when community-specific one dimensional manifold
structure is present. LSBMs focus on a specific class of latent space model,
the random dot product graph (RDPG), and assign a latent submanifold to the
latent positions of each community. A Bayesian model for the embeddings arising
from LSBMs is discussed, and shown to have a good performance on simulated and
real world network data. The model is able to correctly recover the underlying
communities living in a one-dimensional manifold, even when the parametric form
of the underlying curves is unknown, achieving remarkable results on a variety
of real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autoencoding Slow Representations for Semi-supervised Data Efficient Regression. (arXiv:2012.06279v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Struckmeier_O/0/1/0/all/0/1">Oliver Struckmeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_K/0/1/0/all/0/1">Kshitij Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1">Ville Kyrki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06279">
                                    <div class="article-summary-box-inner">
                                        <span>The slowness principle is a concept inspired by the visual cortex of the
brain. It postulates that the underlying generative factors of a quickly
varying sensory signal change on a slower time scale. Unsupervised learning of
intermediate representations utilizing abundant unlabeled sensory data can be
leveraged to perform data-efficient supervised downstream regression. In this
paper, we propose a general formulation of slowness for unsupervised
representation learning adding a slowness regularization term to the estimate
lower bound of the beta-VAE to encourage temporal similarity in observation and
latent space. Within this framework we compare existing slowness regularization
terms such as the L1 and L2 loss used in existing end-to-end methods, the
SlowVAE and propose a new term based on Brownian motion. We empirically
evaluate these slowness regularization terms with respect to their downstream
task performance and data efficiency. We find that slow representations lead to
equal or better downstream task performance and data efficiency in different
experiment domains when compared to representations without slowness
regularization. Finally, we discuss how the Frechet Inception Distance (FID),
traditionally used to determine the generative capabilities of GANs, can serve
as a measure to predict the performance of pre-trained Autoencoder model in a
supervised downstream task and accelerate hyperparameter search.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Oracle Lower Bounds for Stochastic Gradient Sampling Algorithms. (arXiv:2002.00291v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1">Peter L. Bartlett</a>, <a href="http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1">Philip M. Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00291">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of sampling from a strongly log-concave density in
$\mathbb{R}^d$, and prove an information theoretic lower bound on the number of
stochastic gradient queries of the log density needed. Several popular sampling
algorithms (including many Markov chain Monte Carlo methods) operate by using
stochastic gradients of the log density to generate a sample; our results
establish an information theoretic limit for all these algorithms.

We show that for every algorithm, there exists a well-conditioned strongly
log-concave target density for which the distribution of points generated by
the algorithm would be at least $\varepsilon$ away from the target in total
variation distance if the number of gradient queries is less than
$\Omega(\sigma^2 d/\varepsilon^2)$, where $\sigma^2 d$ is the variance of the
stochastic gradient. Our lower bound follows by combining the ideas of Le Cam
deficiency routinely used in the comparison of statistical experiments along
with standard information theoretic tools used in lower bounding Bayes risk
functions. To the best of our knowledge our results provide the first
nontrivial dimension-dependent lower bound for this problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Does the Task Landscape Affect MAML Performance?. (arXiv:2010.14672v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Collins_L/0/1/0/all/0/1">Liam Collins</a>, <a href="http://arxiv.org/find/cs/1/au:+Mokhtari_A/0/1/0/all/0/1">Aryan Mokhtari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14672">
                                    <div class="article-summary-box-inner">
                                        <span>Model-Agnostic Meta-Learning (MAML) has become increasingly popular for
training models that can quickly adapt to new tasks via one or few stochastic
gradient descent steps. However, the MAML objective is significantly more
difficult to optimize compared to standard Empirical Risk Minimization (ERM),
and little is understood about how much MAML improves over ERM in terms of the
fast adaptability of their solutions in various scenarios. We analytically
address this issue in a linear regression setting consisting of a mixture of
easy and hard tasks, where hardness is related to the condition number of the
task&#x27;s loss function. Specifically, we prove that in order for MAML to achieve
substantial gain over ERM, (i) there must be some discrepancy in hardness among
the tasks, and (ii) the optimal solutions of the hard tasks must be closely
packed with the center far from the center of the easy tasks optimal solutions.
We also give numerical and analytical results suggesting that these insights
also apply to two-layer neural networks. Finally, we provide few-shot image
classification experiments that support our insights for when MAML should be
used and emphasize the importance of training MAML on hard tasks in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GANDA: A deep generative adversarial network predicts the spatial distribution of nanoparticles in tumor pixelly. (arXiv:2012.12561v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jiulou Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1">Yuxia Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Shouju Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12561">
                                    <div class="article-summary-box-inner">
                                        <span>Intratumoral nanoparticles (NPs) distribution is critical for the success of
nanomedicine in imaging and treatment, but computational models to describe the
NPs distribution remain unavailable due to the complex tumor-nano interactions.
Here, we develop a Generative Adversarial Network for Distribution Analysis
(GANDA) to describe and conditionally generates the intratumoral quantum dots
(QDs) distribution after i.v. injection. This deep generative model is trained
automatically by 27 775 patches of tumor vessels and cell nuclei decomposed
from whole-slide images of 4T1 breast cancer sections. The GANDA model can
conditionally generate images of intratumoral QDs distribution under the
constraint of given tumor vessels and cell nuclei channels with the same
spatial resolution (pixels-to-pixels), minimal loss (mean squared error, MSE &#x3D;
1.871) and excellent reliability (intraclass correlation, ICC &#x3D; 0.94).
Quantitative analysis of QDs extravasation distance (ICC &#x3D; 0.95) and subarea
distribution (ICC &#x3D; 0.99) is allowed on the generated images without knowing
the real QDs distribution. We believe this deep generative model may provide
opportunities to investigate how influencing factors affect NPs distribution in
individual tumors and guide nanomedicine optimization for molecular imaging and
personalized treatment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unknown Presentation Attack Detection against Rational Attackers. (arXiv:2010.01592v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khodabakhsh_A/0/1/0/all/0/1">Ali Khodabakhsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_Z/0/1/0/all/0/1">Zahid Akhtar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01592">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the impressive progress in the field of presentation attack detection
and multimedia forensics over the last decade, these systems are still
vulnerable to attacks in real-life settings. Some of the challenges for
existing solutions are the detection of unknown attacks, the ability to perform
in adversarial settings, few-shot learning, and explainability. In this study,
these limitations are approached by reliance on a game-theoretic view for
modeling the interactions between the attacker and the detector. Consequently,
a new optimization criterion is proposed and a set of requirements are defined
for improving the performance of these systems in real-life settings.
Furthermore, a novel detection technique is proposed using generator-based
feature sets that are not biased towards any specific attack species. To
further optimize the performance on known attacks, a new loss function coined
categorical margin maximization loss (C-marmax) is proposed which gradually
improves the performance against the most powerful attack. The proposed
approach provides a more balanced performance across known and unknown attacks
and achieves state-of-the-art performance in known and unknown attack detection
cases against rational attackers. Lastly, the few-shot learning potential of
the proposed approach is studied as well as its ability to provide pixel-level
explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Least Restriction for Offline Reinforcement Learning. (arXiv:2107.01757v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1">Zizhou Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01757">
                                    <div class="article-summary-box-inner">
                                        <span>Many practical applications of reinforcement learning (RL) constrain the
agent to learn from a fixed offline dataset of logged interactions, which has
already been gathered, without offering further possibility for data
collection. However, commonly used off-policy RL algorithms, such as the Deep Q
Network and the Deep Deterministic Policy Gradient, are incapable of learning
without data correlated to the distribution under the current policy, making
them ineffective for this offline setting. As the first step towards useful
offline RL algorithms, we analysis the reason of instability in standard
off-policy RL algorithms. It is due to the bootstrapping error. The key to
avoiding this error, is ensuring that the agent&#x27;s action space does not go out
of the fixed offline dataset. Based on our consideration, a creative offline RL
framework, the Least Restriction (LR), is proposed in this paper. The LR
regards selecting an action as taking a sample from the probability
distribution. It merely set a little limit for action selection, which not only
avoid the action being out of the offline dataset but also remove all the
unreasonable restrictions in earlier approaches (e.g. Batch-Constrained Deep
Q-Learning). In the further, we will demonstrate that the LR, is able to learn
robustly from different offline datasets, including random and suboptimal
demonstrations, on a range of practical control tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Fraud Detection in E-Commerce: A Research Agenda. (arXiv:2107.01979v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tax_N/0/1/0/all/0/1">Niek Tax</a>, <a href="http://arxiv.org/find/cs/1/au:+Vries_K/0/1/0/all/0/1">Kees Jan de Vries</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1">Mathijs de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dosoula_N/0/1/0/all/0/1">Nikoleta Dosoula</a>, <a href="http://arxiv.org/find/cs/1/au:+Akker_B/0/1/0/all/0/1">Bram van den Akker</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">Jon Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Thuong_O/0/1/0/all/0/1">Olivier Thuong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernardi_L/0/1/0/all/0/1">Lucas Bernardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01979">
                                    <div class="article-summary-box-inner">
                                        <span>Fraud detection and prevention play an important part in ensuring the
sustained operation of any e-commerce business. Machine learning (ML) often
plays an important role in these anti-fraud operations, but the organizational
context in which these ML models operate cannot be ignored. In this paper, we
take an organization-centric view on the topic of fraud detection by
formulating an operational model of the anti-fraud departments in e-commerce
organizations. We derive 6 research topics and 12 practical challenges for
fraud detection from this operational model. We summarize the state of the
literature for each research topic, discuss potential solutions to the
practical challenges, and identify 22 open research challenges.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence. (arXiv:2103.15990v3 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rex Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramli_A/0/1/0/all/0/1">Albara Ah Ramli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanle Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_E/0/1/0/all/0/1">Esha Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Henricson_E/0/1/0/all/0/1">Erik Henricson</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15990">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of the internet of things (IoT) and artificial
intelligence (AI) technologies, human activity recognition (HAR) has been
applied in a variety of domains such as security and surveillance, human-robot
interaction, and entertainment. Even though a number of surveys and review
papers have been published, there is a lack of HAR overview papers focusing on
healthcare applications that use wearable sensors. Therefore, we fill in the
gap by presenting this overview paper. In particular, we present our projects
to illustrate the system design of HAR applications for healthcare. Our
projects include early mobility identification of human activities for
intensive care unit (ICU) patients and gait analysis of Duchenne muscular
dystrophy (DMD) patients. We cover essential components of designing HAR
systems including sensor factors (e.g., type, number, and placement location),
AI model selection (e.g., classical machine learning models versus deep
learning models), and feature engineering. In addition, we highlight the
challenges of such healthcare-oriented HAR systems and propose several research
opportunities for both the medical and the computer science community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Domain Invariant Representations for Generalizable Person Re-Identification. (arXiv:2103.15890v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi-Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanlin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Da Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zhen Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tieniu Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15890">
                                    <div class="article-summary-box-inner">
                                        <span>Generalizable person Re-Identification (ReID) has attracted growing attention
in recent computer vision community. In this work, we construct a structural
causal model among identity labels, identity-specific factors (clothes/shoes
color etc), and domain-specific factors (background, viewpoints etc). According
to the causal analysis, we propose a novel Domain Invariant Representation
Learning for generalizable person Re-Identification (DIR-ReID) framework.
Specifically, we first propose to disentangle the identity-specific and
domain-specific feature spaces, based on which we propose an effective
algorithmic implementation for backdoor adjustment, essentially serving as a
causal intervention towards the SCM. Extensive experiments have been conducted,
showing that DIR-ReID outperforms state-of-the-art methods on large-scale
domain generalization ReID benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Two-step Surface-based 3D Deep Learning Pipeline for Segmentation of Intracranial Aneurysms. (arXiv:2006.16161v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1">Xi Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xia_D/0/1/0/all/0/1">Ding Xia</a>, <a href="http://arxiv.org/find/eess/1/au:+Kin_T/0/1/0/all/0/1">Taichi Kin</a>, <a href="http://arxiv.org/find/eess/1/au:+Igarashi_T/0/1/0/all/0/1">Takeo Igarashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16161">
                                    <div class="article-summary-box-inner">
                                        <span>The exact shape of intracranial aneurysms is critical in medical diagnosis
and surgical planning. While voxel-based deep learning frameworks have been
proposed for this segmentation task, their performance remains limited. In this
study, we offer a two-step surface-based deep learning pipeline that achieves
significantly higher performance. Our proposed model takes a surface model of
entire principal brain arteries containing aneurysms as input and returns
aneurysms surfaces as output. A user first generates a surface model by
manually specifying multiple thresholds for time-of-flight magnetic resonance
angiography images. The system then samples small surface fragments from the
entire brain arteries and classifies the surface fragments according to whether
aneurysms are present using a point-based deep learning network (PointNet++).
Finally, the system applies surface segmentation (SO-Net) to surface fragments
containing aneurysms. We conduct a direct comparison of segmentation
performance by counting voxels between the proposed surface-based framework and
the existing voxel-based method, in which our framework achieves a much higher
dice similarity coefficient score (72%) than the prior approach (46%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Android Malware Category and Family Detection and Identification using Machine Learning. (arXiv:2107.01927v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fiky_A/0/1/0/all/0/1">Ahmed Hashem El Fiky</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenawy_A/0/1/0/all/0/1">Ayman El Shenawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Madkour_M/0/1/0/all/0/1">Mohamed Ashraf Madkour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01927">
                                    <div class="article-summary-box-inner">
                                        <span>Android malware is one of the most dangerous threats on the internet, and
it&#x27;s been on the rise for several years. Despite significant efforts in
detecting and classifying android malware from innocuous android applications,
there is still a long way to go. As a result, there is a need to provide a
basic understanding of the behavior displayed by the most common Android
malware categories and families. Each Android malware family and category has a
distinct objective. As a result, it has impacted every corporate area,
including healthcare, banking, transportation, government, and e-commerce. In
this paper, we presented two machine-learning approaches for Dynamic Analysis
of Android Malware: one for detecting and identifying Android Malware
Categories and the other for detecting and identifying Android Malware
Families, which was accomplished by analyzing a massive malware dataset with 14
prominent malware categories and 180 prominent malware families of
CCCS-CIC-AndMal2020 dataset on Dynamic Layers. Our approach achieves in Android
Malware Category detection more than 96 % accurate and achieves in Android
Malware Family detection more than 99% accurate. Our approach provides a method
for high-accuracy Dynamic Analysis of Android Malware while also shortening the
time required to analyze smartphone malware.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Exhaustive Learning Using Gaussian Mixture Generative Adversarial Networks. (arXiv:2106.14344v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jun Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Mohammad Al Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14344">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised learning, while deployed in real-life scenarios, often encounters
instances of unknown classes. Conventional algorithms for training a supervised
learning model do not provide an option to detect such instances, so they
miss-classify such instances with 100% probability. Open Set Recognition (OSR)
and Non-Exhaustive Learning (NEL) are potential solutions to overcome this
problem. Most existing methods of OSR first classify members of existing
classes and then identify instances of new classes. However, many of the
existing methods of OSR only makes a binary decision, i.e., they only identify
the existence of the unknown class. Hence, such methods cannot distinguish test
instances belonging to incremental unseen classes. On the other hand, the
majority of NEL methods often make a parametric assumption over the data
distribution, which either fail to return good results, due to the reason that
real-life complex datasets may not follow a well-known data distribution. In
this paper, we propose a new online non-exhaustive learning model, namely,
Non-Exhaustive Gaussian Mixture Generative Adversarial Networks (NE-GM-GAN) to
address these issues. Our proposed model synthesizes Gaussian mixture based
latent representation over a deep generative model, such as GAN, for
incremental detection of instances of emerging classes in the test data.
Extensive experimental results on several benchmark datasets show that
NE-GM-GAN significantly outperforms the state-of-the-art methods in detecting
instances of novel classes in streaming data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Winning at Any Cost -- Infringing the Cartel Prohibition With Reinforcement Learning. (arXiv:2107.01856v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schlechtinger_M/0/1/0/all/0/1">Michael Schlechtinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kosack_D/0/1/0/all/0/1">Damaris Kosack</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Fetzer_T/0/1/0/all/0/1">Thomas Fetzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01856">
                                    <div class="article-summary-box-inner">
                                        <span>Pricing decisions are increasingly made by AI. Thanks to their ability to
train with live market data while making decisions on the fly, deep
reinforcement learning algorithms are especially effective in taking such
pricing decisions. In e-commerce scenarios, multiple reinforcement learning
agents can set prices based on their competitor&#x27;s prices. Therefore, research
states that agents might end up in a state of collusion in the long run. To
further analyze this issue, we build a scenario that is based on a modified
version of a prisoner&#x27;s dilemma where three agents play the game of rock paper
scissors. Our results indicate that the action selection can be dissected into
specific stages, establishing the possibility to develop collusion prevention
systems that are able to recognize situations which might lead to a collusion
between competitors. We furthermore provide evidence for a situation where
agents are capable of performing a tacit cooperation strategy without being
explicitly trained to do so.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory and attention in deep learning. (arXiv:2107.01390v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hung Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01390">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligence necessitates memory. Without memory, humans fail to perform
various nontrivial tasks such as reading novels, playing games or solving
maths. As the ultimate goal of machine learning is to derive intelligent
systems that learn and act automatically just like human, memory construction
for machine is inevitable. Artificial neural networks model neurons and
synapses in the brain by interconnecting computational units via weights, which
is a typical class of machine learning algorithms that resembles memory
structure. Their descendants with more complicated modeling techniques (a.k.a
deep learning) have been successfully applied to many practical problems and
demonstrated the importance of memory in the learning process of machinery
systems. Recent progresses on modeling memory in deep learning have revolved
around external memory constructions, which are highly inspired by
computational Turing models and biological neuronal systems. Attention
mechanisms are derived to support acquisition and retention operations on the
external memory. Despite the lack of theoretical foundations, these approaches
have shown promises to help machinery systems reach a higher level of
intelligence. The aim of this thesis is to advance the understanding on memory
and attention in deep learning. Its contributions include: (i) presenting a
collection of taxonomies for memory, (ii) constructing new memory-augmented
neural networks (MANNs) that support multiple control and memory units, (iii)
introducing variability via memory in sequential generative models, (iv)
searching for optimal writing operations to maximise the memorisation capacity
in slot-based memory networks, and (v) simulating the Universal Turing Machine
via Neural Stored-program Memory-a new kind of external memory for neural
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relaxed Attention: A Simple Method to Boost Performance of End-to-End Automatic Speech Recognition. (arXiv:2107.01275v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lohrenz_T/0/1/0/all/0/1">Timo Lohrenz</a>, <a href="http://arxiv.org/find/eess/1/au:+Schwarz_P/0/1/0/all/0/1">Patrick Schwarz</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1">Zhengyang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Fingscheidt_T/0/1/0/all/0/1">Tim Fingscheidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01275">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, attention-based encoder-decoder (AED) models have shown high
performance for end-to-end automatic speech recognition (ASR) across several
tasks. Addressing overconfidence in such models, in this paper we introduce the
concept of relaxed attention, which is a simple gradual injection of a uniform
distribution to the encoder-decoder attention weights during training that is
easily implemented with two lines of code. We investigate the effect of relaxed
attention across different AED model architectures and two prominent ASR tasks,
Wall Street Journal (WSJ) and Librispeech. We found that transformers trained
with relaxed attention outperform the standard baseline models consistently
during decoding with external language models. On WSJ, we set a new benchmark
for transformer-based end-to-end speech recognition with a word error rate of
3.65%, outperforming state of the art (4.20%) by 13.1% relative, while
introducing only a single hyperparameter. Upon acceptance, models will be
published on github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WisdomNet: Prognosis of COVID-19 with Slender Prospect of False Negative Cases and Vaticinating the Probability of Maturation to ARDS using Posteroanterior Chest X-Rays. (arXiv:2107.01392v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kumar_P/0/1/0/all/0/1">Peeyush Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Gangal_A/0/1/0/all/0/1">Ayushe Gangal</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumari_S/0/1/0/all/0/1">Sunita Kumari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01392">
                                    <div class="article-summary-box-inner">
                                        <span>Coronavirus is a large virus family consisting of diverse viruses, some of
which disseminate among mammals and others cause sickness among humans.
COVID-19 is highly contagious and is rapidly spreading, rendering its early
diagnosis of preeminent status. Researchers, medical specialists and
organizations all over the globe have been working tirelessly to combat this
virus and help in its containment. In this paper, a novel neural network called
WisdomNet has been proposed, for the diagnosis of COVID-19 using chest X-rays.
The WisdomNet uses the concept of Wisdom of Crowds as its founding idea. It is
a two-layered convolutional Neural Network (CNN), which takes chest x-ray
images as input. Both layers of the proposed neural network consist of a number
of neural networks each. The dataset used for this study consists of chest
x-ray images of COVID-19 positive patients, compiled and shared by Dr. Cohen on
GitHub, and the chest x-ray images of healthy lungs and lungs affected by viral
and bacterial pneumonia were obtained from Kaggle. The network not only
pinpoints the presence of COVID-19, but also gives the probability of the
disease maturing into Acute Respiratory Distress Syndrome (ARDS). Thus,
predicting the progression of the disease in the COVID-19 positive patients.
The network also slender the occurrences of false negative cases by employing a
high threshold value, thus aids in curbing the spread of the disease and gives
an accuracy of 100% for successfully predicting COVID-19 among the chest x-rays
of patients affected with COVID-19, bacterial and viral pneumonia.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UCSL : A Machine Learning Expectation-Maximization framework for Unsupervised Clustering driven by Supervised Learning. (arXiv:2107.01988v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Louiset_R/0/1/0/all/0/1">Robin Louiset</a>, <a href="http://arxiv.org/find/stat/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/stat/1/au:+Dufumier_B/0/1/0/all/0/1">Benoit Dufumier</a>, <a href="http://arxiv.org/find/stat/1/au:+Houenou_J/0/1/0/all/0/1">Josselin Houenou</a>, <a href="http://arxiv.org/find/stat/1/au:+Grigis_A/0/1/0/all/0/1">Antoine Grigis</a>, <a href="http://arxiv.org/find/stat/1/au:+Duchesnay_E/0/1/0/all/0/1">Edouard Duchesnay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01988">
                                    <div class="article-summary-box-inner">
                                        <span>Subtype Discovery consists in finding interpretable and consistent sub-parts
of a dataset, which are also relevant to a certain supervised task. From a
mathematical point of view, this can be defined as a clustering task driven by
supervised learning in order to uncover subgroups in line with the supervised
prediction. In this paper, we propose a general Expectation-Maximization
ensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised
Learning). Our method is generic, it can integrate any clustering method and
can be driven by both binary classification and regression. We propose to
construct a non-linear model by merging multiple linear estimators, one per
cluster. Each hyperplane is estimated so that it correctly discriminates - or
predict - only one cluster. We use SVC or Logistic Regression for
classification and SVR for regression. Furthermore, to perform cluster analysis
within a more suitable space, we also propose a dimension-reduction algorithm
that projects the data onto an orthonormal space relevant to the supervised
task. We analyze the robustness and generalization capability of our algorithm
using synthetic and experimental datasets. In particular, we validate its
ability to identify suitable consistent sub-types by conducting a
psychiatric-diseases cluster analysis with known ground-truth labels. The gain
of the proposed method over previous state-of-the-art techniques is about +1.9
points in terms of balanced accuracy. Finally, we make codes and examples
available in a scikit-learn-compatible Python package at
https://github.com/neurospin-projects/2021_rlouiset_ucsl</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Bayesian Networks through Birkhoff Polytope: A Relaxation Method. (arXiv:2107.01658v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dallakyan_A/0/1/0/all/0/1">Aramayis Dallakyan</a>, <a href="http://arxiv.org/find/stat/1/au:+Pourahmadi_M/0/1/0/all/0/1">Mohsen Pourahmadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01658">
                                    <div class="article-summary-box-inner">
                                        <span>We establish a novel framework for learning a directed acyclic graph (DAG)
when data are generated from a Gaussian, linear structural equation model. It
consists of two parts: (1) introduce a permutation matrix as a new parameter
within a regularized Gaussian log-likelihood to represent variable ordering;
and (2) given the ordering, estimate the DAG structure through sparse Cholesky
factor of the inverse covariance matrix. For permutation matrix estimation, we
propose a relaxation technique that avoids the NP-hard combinatorial problem of
order estimation. Given an ordering, a sparse Cholesky factor is estimated
using a cyclic coordinatewise descent algorithm which decouples row-wise. Our
framework recovers DAGs without the need for an expensive verification of the
acyclicity constraint or enumeration of possible parent sets. We establish
numerical convergence of the algorithm, and consistency of the Cholesky factor
estimator when the order of variables is known. Through several simulated and
macro-economic datasets, we study the scope and performance of the proposed
methodology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Self-Supervised Gait Encoding Approach with Locality-Awareness for 3D Skeleton Based Person Re-Identification. (arXiv:2009.03671v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_H/0/1/0/all/0/1">Haocong Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Siqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiping Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xinwang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03671">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (Re-ID) via gait features within 3D skeleton
sequences is a newly-emerging topic with several advantages. Existing solutions
either rely on hand-crafted descriptors or supervised gait representation
learning. This paper proposes a self-supervised gait encoding approach that can
leverage unlabeled skeleton data to learn gait representations for person
Re-ID. Specifically, we first create self-supervision by learning to
reconstruct unlabeled skeleton sequences reversely, which involves richer
high-level semantics to obtain better gait representations. Other pretext tasks
are also explored to further improve self-supervised learning. Second, inspired
by the fact that motion&#x27;s continuity endows adjacent skeletons in one skeleton
sequence and temporally consecutive skeleton sequences with higher correlations
(referred as locality in 3D skeleton data), we propose a locality-aware
attention mechanism and a locality-aware contrastive learning scheme, which aim
to preserve locality-awareness on intra-sequence level and inter-sequence level
respectively during self-supervised learning. Last, with context vectors
learned by our locality-aware attention mechanism and contrastive learning
scheme, a novel feature named Constrastive Attention-based Gait Encodings
(CAGEs) is designed to represent gait effectively. Empirical evaluations show
that our approach significantly outperforms skeleton-based counterparts by
15-40% Rank-1 accuracy, and it even achieves superior performance to numerous
multi-modal methods with extra RGB or depth information. Our codes are
available at https://github.com/Kali-Hac/Locality-Awareness-SGE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mava: a research framework for distributed multi-agent reinforcement learning. (arXiv:2107.01460v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pretorius_A/0/1/0/all/0/1">Arnu Pretorius</a>, <a href="http://arxiv.org/find/cs/1/au:+Tessera_K/0/1/0/all/0/1">Kale-ab Tessera</a>, <a href="http://arxiv.org/find/cs/1/au:+Smit_A/0/1/0/all/0/1">Andries P. Smit</a>, <a href="http://arxiv.org/find/cs/1/au:+Formanek_C/0/1/0/all/0/1">Claude Formanek</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimbly_S/0/1/0/all/0/1">St John Grimbly</a>, <a href="http://arxiv.org/find/cs/1/au:+Eloff_K/0/1/0/all/0/1">Kevin Eloff</a>, <a href="http://arxiv.org/find/cs/1/au:+Danisa_S/0/1/0/all/0/1">Siphelele Danisa</a>, <a href="http://arxiv.org/find/cs/1/au:+Francis_L/0/1/0/all/0/1">Lawrence Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Shock_J/0/1/0/all/0/1">Jonathan Shock</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1">Herman Kamper</a>, <a href="http://arxiv.org/find/cs/1/au:+Brink_W/0/1/0/all/0/1">Willie Brink</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelbrecht_H/0/1/0/all/0/1">Herman Engelbrecht</a>, <a href="http://arxiv.org/find/cs/1/au:+Laterre_A/0/1/0/all/0/1">Alexandre Laterre</a>, <a href="http://arxiv.org/find/cs/1/au:+Beguir_K/0/1/0/all/0/1">Karim Beguir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01460">
                                    <div class="article-summary-box-inner">
                                        <span>Breakthrough advances in reinforcement learning (RL) research have led to a
surge in the development and application of RL. To support the field and its
rapid growth, several frameworks have emerged that aim to help the community
more easily build effective and scalable agents. However, very few of these
frameworks exclusively support multi-agent RL (MARL), an increasingly active
field in itself, concerned with decentralised decision-making problems. In this
work, we attempt to fill this gap by presenting Mava: a research framework
specifically designed for building scalable MARL systems. Mava provides useful
components, abstractions, utilities and tools for MARL and allows for simple
scaling for multi-process system training and execution, while providing a high
level of flexibility and composability. Mava is built on top of DeepMind&#x27;s Acme
\citep{hoffman2020acme}, and therefore integrates with, and greatly benefits
from, a wide range of already existing single-agent RL components made
available in Acme. Several MARL baseline systems have already been implemented
in Mava. These implementations serve as examples showcasing Mava&#x27;s reusable
features, such as interchangeable system architectures, communication and
mixing modules. Furthermore, these implementations allow existing MARL
algorithms to be easily reproduced and extended. We provide experimental
results for these implementations on a wide range of multi-agent environments
and highlight the benefits of distributed system training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Isotonic Data Augmentation for Knowledge Distillation. (arXiv:2107.01412v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1">Wanyun Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Sen Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01412">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation uses both real hard labels and soft labels predicted
by teacher models as supervision. Intuitively, we expect the soft labels and
hard labels to be concordant w.r.t. their orders of probabilities. However, we
found {\it critical order violations} between hard labels and soft labels in
augmented samples. For example, for an augmented sample $x&#x3D;0.7*panda+0.3*cat$,
we expect the order of meaningful soft labels to be
$P_\text{soft}(panda|x)&gt;P_\text{soft}(cat|x)&gt;P_\text{soft}(other|x)$. But real
soft labels usually violate the order, e.g.
$P_\text{soft}(tiger|x)&gt;P_\text{soft}(panda|x)&gt;P_\text{soft}(cat|x)$. We
attribute this to the unsatisfactory generalization ability of the teacher,
which leads to the prediction error of augmented samples. Empirically, we found
the violations are common and injure the knowledge transfer.In this paper, we
introduce order restrictions to data augmentation for knowledge distillation,
which is denoted as isotonic data augmentation (IDA). We use isotonic
regression (IR) -- a classic technique from statistics -- to eliminate the
order violations. We show that IDA can be modeled as a tree-structured IR
problem. We thereby adapt the classical IRT-BIN algorithm for optimal solutions
with $O(c \log c)$ time complexity, where $c$ is the number of labels. In order
to further reduce the time complexity, we also \cwy{propose} a GPU-friendly
approximation with linear time complexity. We have verified on variant datasets
and data augmentation techniques that our proposed IDA algorithms effectively
increases the accuracy of knowledge distillation by eliminating the rank
violations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Representation Learning for Session-based Recommendation. (arXiv:2107.01516v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mitheran_S/0/1/0/all/0/1">Sai Mitheran</a>, <a href="http://arxiv.org/find/cs/1/au:+Java_A/0/1/0/all/0/1">Abhinav Java</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1">Surya Kant Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_A/0/1/0/all/0/1">Arshad Shaikh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01516">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based recommendation systems suggest relevant items to users by
modeling user behavior and preferences using short-term anonymous sessions.
Existing methods leverage Graph Neural Networks (GNNs) that propagate and
aggregate information from neighboring nodes i.e., local message passing. Such
graph-based architectures have representational limits, as a single sub-graph
is susceptible to overfit the sequential dependencies instead of accounting for
complex transitions between items in different sessions. We propose using a
Transformer in combination with a target attentive GNN, which allows richer
Representation Learning. Our experimental results and ablation show that our
proposed method outperforms the existing methods on real-world benchmark
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Efficiency of Various Deep Transfer Learning Models in Glitch Waveform Detection in Gravitational-Wave Data. (arXiv:2107.01863v1 [gr-qc])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/gr-qc/1/au:+Mesuga_R/0/1/0/all/0/1">Reymond Mesuga</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Bayanay_B/0/1/0/all/0/1">Brian James Bayanay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01863">
                                    <div class="article-summary-box-inner">
                                        <span>LIGO is considered the most sensitive and complicated gravitational
experiment ever built. Its main objective is to detect the gravitational wave
from the strongest events in the universe by observing if the length of its
4-kilometer arms change by a distance 10,000 times smaller than the diameter of
a proton. Due to its sensitivity, LIGO is prone to the disturbance of external
noises which affects the data being collected to detect the gravitational wave.
These noises are commonly called by the LIGO community as glitches. The
objective of this study is to evaluate the effeciency of various deep trasnfer
learning models namely VGG19, ResNet50V2, VGG16 and ResNet101 to detect glitch
waveform in gravitational wave data. The accuracy achieved by the said models
are 98.98%, 98.35%, 97.56% and 94.73% respectively. Even though the models
achieved fairly high accuracy, it is observed that all of the model suffered
from the lack of data for certain classes which is the main concern found in
the experiment</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Critical Connectivity Radius for Randomly-Generated, High Dimensional Data Points. (arXiv:1602.03822v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1602.03822">
                                    <div class="article-summary-box-inner">
                                        <span>We use random geometric graphs to describe clusters of higher dimensional
data points which are bijectively mapped to a (possibly) lower dimensional
space where an equivalent random cluster model is used to calculate the
expected number of modes to be found when separating the data of a multi-modal
data set into distinct clusters. Furthermore, as a function of the expected
number of modes and the number of data points in the sample, an upper bound on
a given distance measure is found such that data points have the greatest
correlation if their mutual distances from a common center is less than or
equal to the calculated bound. Anomalies are exposed, which lie outside of the
union of all regularized clusters of data points. Finally, similarly to finding
a hyperplane which can be shifted along its normal to expose the maximal
distance between binary classes, it is shown that the union of regularized
clusters can be used to define a hyperplane which can be shifted by a certain
amount to separate the data into binary classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition. (arXiv:2107.01269v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Moritz_N/0/1/0/all/0/1">Niko Moritz</a>, <a href="http://arxiv.org/find/eess/1/au:+Hori_T/0/1/0/all/0/1">Takaaki Hori</a>, <a href="http://arxiv.org/find/eess/1/au:+Roux_J/0/1/0/all/0/1">Jonathan Le Roux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01269">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based end-to-end automatic speech recognition (ASR) systems have
recently demonstrated state-of-the-art results for numerous tasks. However, the
application of self-attention and attention-based encoder-decoder models
remains challenging for streaming ASR, where each word must be recognized
shortly after it was spoken. In this work, we present the dual
causal/non-causal self-attention (DCN) architecture, which in contrast to
restricted self-attention prevents the overall context to grow beyond the
look-ahead of a single layer when used in a deep architecture. DCN is compared
to chunk-based and restricted self-attention using streaming transformer and
conformer architectures, showing improved ASR performance over restricted
self-attention and competitive ASR results compared to chunk-based
self-attention, while providing the advantage of frame-synchronous processing.
Combined with triggered attention, the proposed streaming end-to-end ASR
systems obtained state-of-the-art results on the LibriSpeech, HKUST, and
Switchboard ASR tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Malware Evolution Detection. (arXiv:2107.01627v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tupadha_L/0/1/0/all/0/1">Lolitha Sresta Tupadha</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1">Mark Stamp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01627">
                                    <div class="article-summary-box-inner">
                                        <span>Malware evolves over time and antivirus must adapt to such evolution. Hence,
it is critical to detect those points in time where malware has evolved so that
appropriate countermeasures can be undertaken. In this research, we perform a
variety of experiments on a significant number of malware families to determine
when malware evolution is likely to have occurred. All of the evolution
detection techniques that we consider are based on machine learning and can be
fully automated -- in particular, no reverse engineering or other
labor-intensive manual analysis is required. Specifically, we consider analysis
based on hidden Markov models (HMM) and the word embedding techniques HMM2Vec
and Word2Vec.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Local Convergence Theory for Mildly Over-Parameterized Two-Layer Neural Network. (arXiv:2102.02410v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1">Rong Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chi Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02410">
                                    <div class="article-summary-box-inner">
                                        <span>While over-parameterization is widely believed to be crucial for the success
of optimization for the neural networks, most existing theories on
over-parameterization do not fully explain the reason -- they either work in
the Neural Tangent Kernel regime where neurons don&#x27;t move much, or require an
enormous number of neurons. In practice, when the data is generated using a
teacher neural network, even mildly over-parameterized neural networks can
achieve 0 loss and recover the directions of teacher neurons. In this paper we
develop a local convergence theory for mildly over-parameterized two-layer
neural net. We show that as long as the loss is already lower than a threshold
(polynomial in relevant parameters), all student neurons in an
over-parameterized two-layer neural network will converge to one of teacher
neurons, and the loss will go to 0. Our result holds for any number of student
neurons as long as it is at least as large as the number of teacher neurons,
and our convergence rate is independent of the number of student neurons. A key
component of our analysis is the new characterization of local optimization
landscape -- we show the gradient satisfies a special case of Lojasiewicz
property which is different from local strong convexity or PL conditions used
in previous work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Aware Model-Based Reinforcement Learning with Application to Autonomous Driving. (arXiv:2106.12194v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingda Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1">Chen Lv</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12194">
                                    <div class="article-summary-box-inner">
                                        <span>To further improve the learning efficiency and performance of reinforcement
learning (RL), in this paper we propose a novel uncertainty-aware model-based
RL (UA-MBRL) framework, and then implement and validate it in autonomous
driving under various task scenarios. First, an action-conditioned ensemble
model with the ability of uncertainty assessment is established as the virtual
environment model. Then, a novel uncertainty-aware model-based RL framework is
developed based on the adaptive truncation approach, providing virtual
interactions between the agent and environment model, and improving RL&#x27;s
training efficiency and performance. The developed algorithms are then
implemented in end-to-end autonomous vehicle control tasks, validated and
compared with state-of-the-art methods under various driving scenarios. The
validation results suggest that the proposed UA-MBRL method surpasses the
existing model-based and model-free RL approaches, in terms of learning
efficiency and achieved performance. The results also demonstrate the good
ability of the proposed method with respect to the adaptiveness and robustness,
under various autonomous driving scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smoothed Differential Privacy. (arXiv:2107.01559v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Ao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1">Lirong Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01559">
                                    <div class="article-summary-box-inner">
                                        <span>Differential privacy (DP) is a widely-accepted and widely-applied notion of
privacy based on worst-case analysis. Often, DP classifies most mechanisms
without external noise as non-private [Dwork et al., 2014], and external
noises, such as Gaussian noise or Laplacian noise [Dwork et al., 2006], are
introduced to improve privacy. In many real-world applications, however, adding
external noise is undesirable and sometimes prohibited. For example,
presidential elections often require a deterministic rule to be used [Liu et
al., 2020], and small noises can lead to dramatic decreases in the prediction
accuracy of deep neural networks, especially the underrepresented classes
[Bagdasaryan et al., 2019].

In this paper, we propose a natural extension and relaxation of DP following
the worst average-case idea behind the celebrated smoothed analysis [Spielman
and Teng, 2004]. Our notion, the smoothed DP, can effectively measure the
privacy leakage of mechanisms without external noises under realistic settings.

We prove several strong properties of the smoothed DP, including
composability, robustness to post-processing and etc. We proved that any
discrete mechanism with sampling procedures is more private than what DP
predicts. In comparison, many continuous mechanisms with sampling procedures
are still non-private under smoothed DP. Experimentally, we first verified that
the discrete sampling mechanisms are private in real-world elections. Then, we
apply the smoothed DP notion on quantized gradient descent, which indicates
some neural networks can be private without adding any extra noises. We believe
that these results contribute to the theoretical foundation of realistic
privacy measures beyond worst-case analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single Model for Influenza Forecasting of Multiple Countries by Multi-task Learning. (arXiv:2107.01760v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murayama_T/0/1/0/all/0/1">Taichi Murayama</a>, <a href="http://arxiv.org/find/cs/1/au:+Wakamiya_S/0/1/0/all/0/1">Shoko Wakamiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Aramaki_E/0/1/0/all/0/1">Eiji Aramaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01760">
                                    <div class="article-summary-box-inner">
                                        <span>The accurate forecasting of infectious epidemic diseases such as influenza is
a crucial task undertaken by medical institutions. Although numerous flu
forecasting methods and models based mainly on historical flu activity data and
online user-generated contents have been proposed in previous studies, no flu
forecasting model targeting multiple countries using two types of data exists
at present. Our paper leverages multi-task learning to tackle the challenge of
building one flu forecasting model targeting multiple countries; each country
as each task. Also, to develop the flu prediction model with higher
performance, we solved two issues; finding suitable search queries, which are
part of the user-generated contents, and how to leverage search queries
efficiently in the model creation. For the first issue, we propose the transfer
approaches from English to other languages. For the second issue, we propose a
novel flu forecasting model that takes advantage of search queries using an
attention mechanism and extend the model to a multi-task model for multiple
countries&#x27; flu forecasts. Experiments on forecasting flu epidemics in five
countries demonstrate that our model significantly improved the performance by
leveraging the search queries and multi-task learning compared to the
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XOmiVAE: an interpretable deep learning model for cancer classification using high-dimensional omics data. (arXiv:2105.12807v2 [q-bio.GN] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Withnell_E/0/1/0/all/0/1">Eloise Withnell</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyu Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sun_K/0/1/0/all/0/1">Kai Sun</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12807">
                                    <div class="article-summary-box-inner">
                                        <span>The lack of explainability is one of the most prominent disadvantages of deep
learning applications in omics. This &quot;black box&quot; problem can undermine the
credibility and limit the practical implementation of biomedical deep learning
models. Here we present XOmiVAE, a variational autoencoder (VAE) based
interpretable deep learning model for cancer classification using
high-dimensional omics data. XOmiVAE is capable of revealing the contribution
of each gene and latent dimension for each classification prediction, and the
correlation between each gene and each latent dimension. It is also
demonstrated that XOmiVAE can explain not only the supervised classification
but the unsupervised clustering results from the deep learning network. To the
best of our knowledge, XOmiVAE is one of the first activation level-based
interpretable deep learning models explaining novel clusters generated by VAE.
The explainable results generated by XOmiVAE were validated by both the
performance of downstream tasks and the biomedical knowledge. In our
experiments, XOmiVAE explanations of deep learning based cancer classification
and clustering aligned with current domain knowledge including biological
annotation and academic literature, which shows great potential for novel
biomedical knowledge discovery from deep learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Full interpretable machine learning in 2D with inline coordinates. (arXiv:2106.07568v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovalerchuk_B/0/1/0/all/0/1">Boris Kovalerchuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_H/0/1/0/all/0/1">Hoang Phan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07568">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposed a new methodology for machine learning in 2-dimensional
space (2-D ML) in inline coordinates. It is a full machine learning approach
that does not require to deal with n-dimensional data in n-dimensional space.
It allows discovering n-D patterns in 2-D space without loss of n-D information
using graph representations of n-D data in 2-D. Specifically, it can be done
with the inline based coordinates in different modifications, including static
and dynamic ones. The classification and regression algorithms based on these
inline coordinates were introduced. A successful case study based on a
benchmark data demonstrated the feasibility of the approach. This approach
helps to consolidate further a whole new area of full 2-D machine learning as a
promising ML methodology. It has advantages of abilities to involve actively
the end-users into the discovering of models and their justification. Another
advantage is providing interpretable ML models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection With Partitioning Overfitting Autoencoder Ensembles. (arXiv:2009.02755v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lorbeer_B/0/1/0/all/0/1">Boris Lorbeer</a>, <a href="http://arxiv.org/find/cs/1/au:+Botler_M/0/1/0/all/0/1">Max Botler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.02755">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose POTATOES (Partitioning OverfiTting AuTOencoder
EnSemble), a new method for unsupervised outlier detection (UOD). More
precisely, given any autoencoder for UOD, this technique can be used to improve
its accuracy while at the same time removing the burden of tuning its
regularization. The idea is to not regularize at all, but to rather randomly
partition the data into sufficiently many equally sized parts, overfit each
part with its own autoencoder, and to use the maximum over all autoencoder
reconstruction errors as the anomaly score. We apply our model to various
realistic datasets and show that if the set of inliers is dense enough, our
method indeed improves the UOD performance of a given autoencoder
significantly. For reproducibility, the code is made available on github so the
reader can recreate the results in this paper as well as apply the method to
other autoencoders and datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exact Backpropagation in Binary Weighted Networks with Group Weight Transformations. (arXiv:2107.01400v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shulman_Y/0/1/0/all/0/1">Yaniv Shulman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01400">
                                    <div class="article-summary-box-inner">
                                        <span>Quantization based model compression serves as high performing and fast
approach for inference that yields highly compressed models compared to their
full-precision floating point counterparts. The most extreme quantization is a
1-bit representation of parameters such that they have only two possible
values, typically -1(0) or +1. Models that constrain the weights to binary
values enable efficient implementation of the ubiquitous dot product by
additions only without requiring floating point multiplications which is
beneficial for resources constrained inference. The main contribution of this
work is the introduction of a method to smooth the combinatorial problem of
determining a binary vector of weights to minimize the expected loss for a
given objective by means of empirical risk minimization with backpropagation.
This is achieved by approximating a multivariate binary state over the weights
utilizing a deterministic and differentiable transformation of real-valued
continuous parameters. The proposed method adds little overhead in training,
can be readily applied without any substantial modifications to the original
architecture, does not introduce additional saturating non-linearities or
auxiliary losses, and does not prohibit applying other methods for binarizing
the activations. It is demonstrated that contrary to common assertions made in
the literature, binary weighted networks can train well with the same standard
optimization techniques and similar hyperparameters settings as their
full-precision counterparts, namely momentum SGD with large learning rates and
$L_2$ regularization. The source code is publicly available at
https://bitbucket.org/YanivShu/binary_weighted_networks_public</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Granular Sound Synthesis. (arXiv:2008.01393v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bitton_A/0/1/0/all/0/1">Adrien Bitton</a>, <a href="http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1">Philippe Esling</a>, <a href="http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1">Tatsuya Harada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01393">
                                    <div class="article-summary-box-inner">
                                        <span>Granular sound synthesis is a popular audio generation technique based on
rearranging sequences of small waveform windows. In order to control the
synthesis, all grains in a given corpus are analyzed through a set of acoustic
descriptors. This provides a representation reflecting some form of local
similarities across the grains. However, the quality of this grain space is
bound by that of the descriptors. Its traversal is not continuously invertible
to signal and does not render any structured temporality.

We demonstrate that generative neural networks can implement granular
synthesis while alleviating most of its shortcomings. We efficiently replace
its audio descriptor basis by a probabilistic latent space learned with a
Variational Auto-Encoder. In this setting the learned grain space is
invertible, meaning that we can continuously synthesize sound when traversing
its dimensions. It also implies that original grains are not stored for
synthesis. Another major advantage of our approach is to learn structured paths
inside this latent space by training a higher-level temporal embedding over
arranged grain sequences.

The model can be applied to many types of libraries, including pitched notes
or unpitched drums and environmental noises. We report experiments on the
common granular synthesis processes as well as novel ones such as conditional
sampling and morphing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN. (arXiv:2107.01366v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaabouni_R/0/1/0/all/0/1">Rahma Chaabouni</a>, <a href="http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1">Roberto Dess&#xec;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01366">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their practical success, modern seq2seq architectures are unable to
generalize systematically on several SCAN tasks. Hence, it is not clear if
SCAN-style compositional generalization is useful in realistic NLP tasks. In
this work, we study the benefit that such compositionality brings about to
several machine translation tasks. We present several focused modifications of
Transformer that greatly improve generalization capabilities on SCAN and select
one that remains on par with a vanilla Transformer on a standard machine
translation (MT) task. Next, we study its performance in low-resource settings
and on a newly introduced distribution-shifted English-French translation task.
Overall, we find that improvements of a SCAN-capable model do not directly
transfer to the resource-rich MT setup. In contrast, in the low-resource setup,
general modifications lead to an improvement of up to 13.1% BLEU score w.r.t. a
vanilla Transformer. Similarly, an improvement of 14% in an accuracy-based
metric is achieved in the introduced compositional English-French translation
task. This provides experimental evidence that the compositional generalization
assessed in SCAN is particularly useful in resource-starved and domain-shifted
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisualWordGrid: Information Extraction From Scanned Documents Using A Multimodal Approach. (arXiv:2010.02358v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kerroumi_M/0/1/0/all/0/1">Mohamed Kerroumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sayem_O/0/1/0/all/0/1">Othmane Sayem</a>, <a href="http://arxiv.org/find/cs/1/au:+Shabou_A/0/1/0/all/0/1">Aymen Shabou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02358">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel approach for scanned document representation to perform
field extraction. It allows the simultaneous encoding of the textual, visual
and layout information in a 3-axis tensor used as an input to a segmentation
model. We improve the recent Chargrid and Wordgrid \cite{chargrid} models in
several ways, first by taking into account the visual modality, then by
boosting its robustness in regards to small datasets while keeping the
inference time low. Our approach is tested on public and private document-image
datasets, showing higher performances compared to the recent state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Evidential Deep Learning Uncertainties with Graph-based Clustering to Detect Anomalies. (arXiv:2107.01557v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sandeep Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowdur_J/0/1/0/all/0/1">Jaya Shradha Fowdur</a>, <a href="http://arxiv.org/find/cs/1/au:+Gawlikowski_J/0/1/0/all/0/1">Jakob Gawlikowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Medina_D/0/1/0/all/0/1">Daniel Medina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01557">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding and representing traffic patterns are key to detecting
anomalies in the maritime domain. To this end, we propose a novel graph-based
traffic representation and association scheme to cluster trajectories of
vessels using automatic identification system (AIS) data. We utilize the
(un)clustered data to train a recurrent neural network (RNN)-based evidential
regression model, which can predict a vessel&#x27;s trajectory at future timesteps
with its corresponding prediction uncertainty. This paper proposes the usage of
a deep learning (DL)-based uncertainty estimation in detecting maritime
anomalies, such as unusual vessel maneuvering. Furthermore, we utilize the
evidential deep learning classifiers to detect unusual turns of vessels and the
loss of AIS signal using predicted class probabilities with associated
uncertainties. Our experimental results suggest that using graph-based
clustered data improves the ability of the DL models to learn the
temporal-spatial correlation of data and associated uncertainties. Using
different AIS datasets and experiments, we demonstrate that the estimated
prediction uncertainty yields fundamental information for the detection of
traffic anomalies in the maritime and, possibly in other domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatiotemporal convolutional network for time-series prediction and causal inference. (arXiv:2107.01353v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Luonan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01353">
                                    <div class="article-summary-box-inner">
                                        <span>Making predictions in a robust way is not easy for nonlinear systems. In this
work, a neural network computing framework, i.e., a spatiotemporal
convolutional network (STCN), was developed to efficiently and accurately
render a multistep-ahead prediction of a time series by employing a
spatial-temporal information (STI) transformation. The STCN combines the
advantages of both the temporal convolutional network (TCN) and the STI
equation, which maps the high-dimensional/spatial data to the future temporal
values of a target variable, thus naturally providing the prediction of the
target variable. From the observed variables, the STCN also infers the causal
factors of the target variable in the sense of Granger causality, which are in
turn selected as effective spatial information to improve the prediction
robustness. The STCN was successfully applied to both benchmark systems and
real-world datasets, all of which show superior and robust performance in
multistep-ahead prediction, even when the data were perturbed by noise. From
both theoretical and computational viewpoints, the STCN has great potential in
practical applications in artificial intelligence (AI) or machine learning
fields as a model-free method based only on the observed data, and also opens a
new way to explore the observed high-dimensional data in a dynamical manner for
machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Multi-Mini-Batch: An Efficient Training Approach to Federated Learning in Non-IID Environments. (arXiv:2011.07006v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nasirigerdeh_R/0/1/0/all/0/1">Reza Nasirigerdeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakhtiari_M/0/1/0/all/0/1">Mohammad Bakhtiari</a>, <a href="http://arxiv.org/find/cs/1/au:+Torkzadehmahani_R/0/1/0/all/0/1">Reihaneh Torkzadehmahani</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayat_A/0/1/0/all/0/1">Amirhossein Bayat</a>, <a href="http://arxiv.org/find/cs/1/au:+List_M/0/1/0/all/0/1">Markus List</a>, <a href="http://arxiv.org/find/cs/1/au:+Blumenthal_D/0/1/0/all/0/1">David B. Blumenthal</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumbach_J/0/1/0/all/0/1">Jan Baumbach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07006">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has faced performance and network communication
challenges, especially in the environments where the data is not independent
and identically distributed (IID) across the clients. To address the former
challenge, we introduce the federated-centralized concordance property and show
that the federated single-mini-batch training approach can achieve comparable
performance as the corresponding centralized training in the Non-IID
environments. To deal with the latter, we present the federated
multi-mini-batch approach and illustrate that it can establish a trade-off
between the performance and communication efficiency and outperforms federated
averaging in the Non-IID settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Efficient Reinforcement Learning via Model-Ensemble Exploration and Exploitation. (arXiv:2107.01825v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Li Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1">Zhicheng An</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wanpeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1">Dijun Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01825">
                                    <div class="article-summary-box-inner">
                                        <span>Model-based deep reinforcement learning has achieved success in various
domains that require high sample efficiencies, such as Go and robotics.
However, there are some remaining issues, such as planning efficient
explorations to learn more accurate dynamic models, evaluating the uncertainty
of the learned models, and more rational utilization of models. To mitigate
these issues, we present MEEE, a model-ensemble method that consists of
optimistic exploration and weighted exploitation. During exploration, unlike
prior methods directly selecting the optimal action that maximizes the expected
accumulative return, our agent first generates a set of action candidates and
then seeks out the optimal action that takes both expected return and future
observation novelty into account. During exploitation, different discounted
weights are assigned to imagined transition tuples according to their model
uncertainty respectively, which will prevent model predictive error propagation
in agent training. Experiments on several challenging continuous control
benchmark tasks demonstrated that our approach outperforms other model-free and
model-based state-of-the-art methods, especially in sample complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Distributional Programs for Relational Autocompletion. (arXiv:2001.08603v5 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nitesh_K/0/1/0/all/0/1">Kumar Nitesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ondrej_K/0/1/0/all/0/1">Kuzelka Ondrej</a>, <a href="http://arxiv.org/find/cs/1/au:+Luc_D/0/1/0/all/0/1">De Raedt Luc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.08603">
                                    <div class="article-summary-box-inner">
                                        <span>Relational autocompletion is the problem of automatically filling out some
missing values in multi-relational data. We tackle this problem within the
probabilistic logic programming framework of Distributional Clauses (DC), which
supports both discrete and continuous probability distributions. Within this
framework, we introduce DiceML { an approach to learn both the structure and
the parameters of DC programs from relational data (with possibly missing
data). To realize this, DiceML integrates statistical modeling and
distributional clauses with rule learning. The distinguishing features of
DiceML are that it 1) tackles autocompletion in relational data, 2) learns
distributional clauses extended with statistical models, 3) deals with both
discrete and continuous distributions, 4) can exploit background knowledge, and
5) uses an expectation-maximization based algorithm to cope with missing data.
The empirical results show the promise of the approach, even when there is
missing data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse Linear Networks with a Fixed Butterfly Structure: Theory and Practice. (arXiv:2007.08864v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ailon_N/0/1/0/all/0/1">Nir Ailon</a>, <a href="http://arxiv.org/find/cs/1/au:+Leibovich_O/0/1/0/all/0/1">Omer Leibovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1">Vineet Nair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08864">
                                    <div class="article-summary-box-inner">
                                        <span>A butterfly network consists of logarithmically many layers, each with a
linear number of non-zero weights (pre-specified). The fast
Johnson-Lindenstrauss transform (FJLT) can be represented as a butterfly
network followed by a projection onto a random subset of the coordinates.
Moreover, a random matrix based on FJLT with high probability approximates the
action of any matrix on a vector. Motivated by these facts, we propose to
replace a dense linear layer in any neural network by an architecture based on
the butterfly network. The proposed architecture significantly improves upon
the quadratic number of weights required in a standard dense layer to nearly
linear with little compromise in expressibility of the resulting operator. In a
collection of wide variety of experiments, including supervised prediction on
both the NLP and vision data, we show that this not only produces results that
match and at times outperform existing well-known architectures, but it also
offers faster training and prediction in deployment. To understand the
optimization problems posed by neural networks with a butterfly network, we
also study the optimization landscape of the encoder-decoder network, where the
encoder is replaced by a butterfly network followed by a dense linear layer in
smaller dimension. Theoretical result presented in the paper explains why the
training speed and outcome are not compromised by our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Typology of Data Anomalies. (arXiv:2107.01615v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Foorthuis_R/0/1/0/all/0/1">Ralph Foorthuis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01615">
                                    <div class="article-summary-box-inner">
                                        <span>Anomalies are cases that are in some way unusual and do not appear to fit the
general patterns present in the dataset. Several conceptualizations exist to
distinguish between different types of anomalies. However, these are either too
specific to be generally applicable or so abstract that they neither provide
concrete insight into the nature of anomaly types nor facilitate the functional
evaluation of anomaly detection algorithms. With the recent criticism on &#x27;black
box&#x27; algorithms and analytics it has become clear that this is an undesirable
situation. This paper therefore introduces a general typology of anomalies that
offers a clear and tangible definition of the different types of anomalies in
datasets. The typology also facilitates the evaluation of the functional
capabilities of anomaly detection algorithms and as a framework assists in
analyzing the conceptual levels of data, patterns and anomalies. Finally, it
serves as an analytical tool for studying anomaly types from other typologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S-TRIGGER: Continual State Representation Learning via Self-Triggered Generative Replay. (arXiv:1902.09434v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caselles_Dupre_H/0/1/0/all/0/1">Hugo Caselles-Dupr&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Ortiz_M/0/1/0/all/0/1">Michael Garcia-Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Filliat_D/0/1/0/all/0/1">David Filliat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.09434">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of building a state representation model for control,
in a continual learning setting. As the environment changes, the aim is to
efficiently compress the sensory state&#x27;s information without losing past
knowledge, and then use Reinforcement Learning on the resulting features for
efficient policy learning. To this end, we propose S-TRIGGER, a general method
for Continual State Representation Learning applicable to Variational
Auto-Encoders and its many variants. The method is based on Generative Replay,
i.e. the use of generated samples to maintain past knowledge. It comes along
with a statistically sound method for environment change detection, which
self-triggers the Generative Replay. Our experiments on VAEs show that
S-TRIGGER learns state representations that allows fast and high-performing
Reinforcement Learning, while avoiding catastrophic forgetting. The resulting
system is capable of autonomously learning new information without using past
data and with a bounded system size. Code for our experiments is attached in
Appendix.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A contextual analysis of multi-layer perceptron models in classifying hand-written digits and letters: limited resources. (arXiv:2107.01782v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pricope_T/0/1/0/all/0/1">Tidor-Vlad Pricope</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01782">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying hand-written digits and letters has taken a big leap with the
introduction of ConvNets. However, on very constrained hardware the time
necessary to train such models would be high. Our main contribution is twofold.
First, we extensively test an end-to-end vanilla neural network (MLP) approach
in pure numpy without any pre-processing or feature extraction done beforehand.
Second, we show that basic data mining operations can significantly improve the
performance of the models in terms of computational time, without sacrificing
much accuracy. We illustrate our claims on a simpler variant of the Extended
MNIST dataset, called Balanced EMNIST dataset. Our experiments show that,
without any data mining, we get increased generalization performance when using
more hidden layers and regularization techniques, the best model achieving
84.83% accuracy on a test dataset. Using dimensionality reduction done by PCA
we were able to increase that figure to 85.08% with only 10% of the original
feature space, reducing the memory size needed by 64%. Finally, adding methods
to remove possibly harmful training samples like deviation from the mean helped
us to still achieve over 84% test accuracy but with only 32.8% of the original
memory size for the training set. This compares favorably to the majority of
literature results obtained through similar architectures. Although this
approach gets outshined by state-of-the-art models, it does scale to some
(AlexNet, VGGNet) trained on 50% of the same dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework for Evaluating the Cybersecurity Risk of Real World, Machine Learning Production Systems. (arXiv:2107.01806v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bitton_R/0/1/0/all/0/1">Ron Bitton</a>, <a href="http://arxiv.org/find/cs/1/au:+Maman_N/0/1/0/all/0/1">Nadav Maman</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_I/0/1/0/all/0/1">Inderjeet Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Momiyama_S/0/1/0/all/0/1">Satoru Momiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1">Yuval Elovici</a>, <a href="http://arxiv.org/find/cs/1/au:+Shabtai_A/0/1/0/all/0/1">Asaf Shabtai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01806">
                                    <div class="article-summary-box-inner">
                                        <span>Although cyberattacks on machine learning (ML) production systems can be
destructive, many industry practitioners are ill equipped, lacking tactical and
strategic tools that would allow them to analyze, detect, protect against, and
respond to cyberattacks targeting their ML-based systems. In this paper, we
take a significant step toward securing ML production systems by integrating
these systems and their vulnerabilities into cybersecurity risk assessment
frameworks. Specifically, we performed a comprehensive threat analysis of ML
production systems and developed an extension to the MulVAL attack graph
generation and analysis framework to incorporate cyberattacks on ML production
systems. Using the proposed extension, security practitioners can apply attack
graph analysis methods in environments that include ML components, thus
providing security experts with a practical tool for evaluating the impact and
quantifying the risk of a cyberattack targeting an ML production system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained Motion Planning Networks X. (arXiv:2010.08707v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qureshi_A/0/1/0/all/0/1">Ahmed H. Qureshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jiangeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Baig_A/0/1/0/all/0/1">Asfiya Baig</a>, <a href="http://arxiv.org/find/cs/1/au:+Yip_M/0/1/0/all/0/1">Michael C. Yip</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08707">
                                    <div class="article-summary-box-inner">
                                        <span>Constrained motion planning is a challenging field of research, aiming for
computationally efficient methods that can find a collision-free path on the
constraint manifolds between a given start and goal configuration. These
planning problems come up surprisingly frequently, such as in robot
manipulation for performing daily life assistive tasks. However, few solutions
to constrained motion planning are available, and those that exist struggle
with high computational time complexity in finding a path solution on the
manifolds. To address this challenge, we present Constrained Motion Planning
Networks X (CoMPNetX). It is a neural planning approach, comprising a
conditional deep neural generator and discriminator with neural gradients-based
fast projection operator. We also introduce neural task and scene
representations conditioned on which the CoMPNetX generates implicit manifold
configurations to turbo-charge any underlying classical planner such as
Sampling-based Motion Planning methods for quickly solving complex constrained
planning tasks. We show that our method finds path solutions with high success
rates and lower computation times than state-of-the-art traditional
path-finding tools on various challenging scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Representation Learning on Graphs: A Mutual Information Perspective. (arXiv:2107.01475v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Binghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiayi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hai Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01475">
                                    <div class="article-summary-box-inner">
                                        <span>Learning with graphs has attracted significant attention recently. Existing
representation learning methods on graphs have achieved state-of-the-art
performance on various graph-related tasks such as node classification, link
prediction, etc. However, we observe that these methods could leak serious
private information. For instance, one can accurately infer the links (or node
identity) in a graph from a node classifier (or link predictor) trained on the
learnt node representations by existing methods. To address the issue, we
propose a privacy-preserving representation learning framework on graphs from
the \emph{mutual information} perspective. Specifically, our framework includes
a primary learning task and a privacy protection task, and we consider node
classification and link prediction as the two tasks of interest. Our goal is to
learn node representations such that they can be used to achieve high
performance for the primary learning task, while obtaining performance for the
privacy protection task close to random guessing. We formally formulate our
goal via mutual information objectives. However, it is intractable to compute
mutual information in practice. Then, we derive tractable variational bounds
for the mutual information terms, where each bound can be parameterized via a
neural network. Next, we train these parameterized neural networks to
approximate the true mutual information and learn privacy-preserving node
representations. We finally evaluate our framework on various graph datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rayleigh-Gauss-Newton optimization with enhanced sampling for variational Monte Carlo. (arXiv:2106.10558v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Webber_R/0/1/0/all/0/1">Robert J. Webber</a>, <a href="http://arxiv.org/find/stat/1/au:+Lindsey_M/0/1/0/all/0/1">Michael Lindsey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10558">
                                    <div class="article-summary-box-inner">
                                        <span>Variational Monte Carlo (VMC) is an approach for computing ground-state
wavefunctions that has recently become more powerful due to the introduction of
neural network-based wavefunction parametrizations. However, efficiently
training neural wavefunctions to converge to an energy minimum remains a
difficult problem. In this work, we analyze optimization and sampling methods
used in VMC and introduce alterations to improve their performance. First,
based on theoretical convergence analysis in a noiseless setting, we motivate a
new optimizer that we call the Rayleigh-Gauss-Newton method, which can improve
upon gradient descent and natural gradient descent to achieve superlinear
convergence with little added computational cost. Second, in order to realize
this favorable comparison in the presence of stochastic noise, we analyze the
effect of sampling error on VMC parameter updates and experimentally
demonstrate that it can be reduced by the parallel tempering method. In
particular, we demonstrate that RGN can be made robust to energy spikes that
occur when new regions of configuration space become available to the sampler
over the course of optimization. Finally, putting theory into practice, we
apply our enhanced optimization and sampling methods to the transverse-field
Ising and XXZ models on large lattices, yielding ground-state energy estimates
with remarkably high accuracy after just 200-500 parameter updates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Interpretation of Softmax Cross-Entropy and Negative Sampling: With Case Study for Knowledge Graph Embedding. (arXiv:2106.07250v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamigaito_H/0/1/0/all/0/1">Hidetaka Kamigaito</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_K/0/1/0/all/0/1">Katsuhiko Hayashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07250">
                                    <div class="article-summary-box-inner">
                                        <span>In knowledge graph embedding, the theoretical relationship between the
softmax cross-entropy and negative sampling loss functions has not been
investigated. This makes it difficult to fairly compare the results of the two
different loss functions. We attempted to solve this problem by using the
Bregman divergence to provide a unified interpretation of the softmax
cross-entropy and negative sampling loss functions. Under this interpretation,
we can derive theoretical findings for fair comparison. Experimental results on
the FB15k-237 and WN18RR datasets show that the theoretical findings are valid
in practical settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Machine Learning Problems. (arXiv:2107.01238v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_S/0/1/0/all/0/1">Sunny Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_P/0/1/0/all/0/1">Pranav Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Pakuwal_I/0/1/0/all/0/1">Ishan Pakuwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kafle_P/0/1/0/all/0/1">Prabhakar Kafle</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1">Nikhil Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynch_J/0/1/0/all/0/1">Jayson Lynch</a>, <a href="http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1">Iddo Drori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01238">
                                    <div class="article-summary-box-inner">
                                        <span>Can a machine learn Machine Learning? This work trains a machine learning
model to solve machine learning problems from a University undergraduate level
course. We generate a new training set of questions and answers consisting of
course exercises, homework, and quiz questions from MIT&#x27;s 6.036 Introduction to
Machine Learning course and train a machine learning model to answer these
questions. Our system demonstrates an overall accuracy of 96% for open-response
questions and 97% for multiple-choice questions, compared with MIT students&#x27;
average of 93%, achieving grade A performance in the course, all in real-time.
Questions cover all 12 topics taught in the course, excluding coding questions
or questions with images. Topics include: (i) basic machine learning
principles; (ii) perceptrons; (iii) feature extraction and selection; (iv)
logistic regression; (v) regression; (vi) neural networks; (vii) advanced
neural networks; (viii) convolutional neural networks; (ix) recurrent neural
networks; (x) state machines and MDPs; (xi) reinforcement learning; and (xii)
decision trees. Our system uses Transformer models within an encoder-decoder
architecture with graph and tree representations. An important aspect of our
approach is a data-augmentation scheme for generating new example problems. We
also train a machine learning model to generate problem hints. Thus, our system
automatically generates new questions across topics, answers both open-response
questions and multiple-choice questions, classifies problems, and generates
problem hints, pushing the envelope of AI for STEM education.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BAGUA: Scaling up Distributed Learning with System Relaxations. (arXiv:2107.01499v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gan_S/0/1/0/all/0/1">Shaoduo Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1">Xiangru Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1">Jianbin Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chengjun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Hongmei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengzhuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xianghong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tengxu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiawei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Binhang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01499">
                                    <div class="article-summary-box-inner">
                                        <span>Recently years have witnessed a growing list of systems for distributed
data-parallel training. Existing systems largely fit into two paradigms, i.e.,
parameter server and MPI-style collective operations. On the algorithmic side,
researchers have proposed a wide range of techniques to lower the communication
via system relaxations: quantization, decentralization, and communication
delay. However, most, if not all, existing systems only rely on standard
synchronous and asynchronous stochastic gradient (SG) based optimization,
therefore, cannot take advantage of all possible optimizations that the machine
learning community has been developing recently. Given this emerging gap
between the current landscapes of systems and theory, we build BAGUA, a
communication framework whose design goal is to provide a system abstraction
that is both flexible and modular to support state-of-the-art system relaxation
techniques of distributed training. Powered by the new system design, BAGUA has
a great ability to implement and extend various state-of-the-art distributed
learning algorithms. In a production cluster with up to 16 machines (128 GPUs),
BAGUA can outperform PyTorch-DDP, Horovod and BytePS in the end-to-end training
time by a significant margin (up to 1.95 times) across a diverse range of
tasks. Moreover, we conduct a rigorous tradeoff exploration showing that
different algorithms and system relaxations achieve the best performance over
different network conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Truncated Marginal Neural Ratio Estimation. (arXiv:2107.01214v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Miller_B/0/1/0/all/0/1">Benjamin Kurt Miller</a>, <a href="http://arxiv.org/find/stat/1/au:+Cole_A/0/1/0/all/0/1">Alex Cole</a>, <a href="http://arxiv.org/find/stat/1/au:+Forre_P/0/1/0/all/0/1">Patrick Forr&#xe9;</a>, <a href="http://arxiv.org/find/stat/1/au:+Louppe_G/0/1/0/all/0/1">Gilles Louppe</a>, <a href="http://arxiv.org/find/stat/1/au:+Weniger_C/0/1/0/all/0/1">Christoph Weniger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01214">
                                    <div class="article-summary-box-inner">
                                        <span>Parametric stochastic simulators are ubiquitous in science, often featuring
high-dimensional input parameters and/or an intractable likelihood. Performing
Bayesian parameter inference in this context can be challenging. We present a
neural simulator-based inference algorithm which simultaneously offers
simulation efficiency and fast empirical posterior testability, which is unique
among modern algorithms. Our approach is simulation efficient by simultaneously
estimating low-dimensional marginal posteriors instead of the joint posterior
and by proposing simulations targeted to an observation of interest via a prior
suitably truncated by an indicator function. Furthermore, by estimating a
locally amortized posterior our algorithm enables efficient empirical tests of
the robustness of the inference results. Such tests are important for
sanity-checking inference in real-world applications, which do not feature a
known ground truth. We perform experiments on a marginalized version of the
simulation-based inference benchmark and two complex and narrow posteriors,
highlighting the simulator efficiency of our algorithm as well as the quality
of the estimated marginal posteriors. Implementation on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 detection using deep convolutional neural networks and binary-differential-algorithm-based feature selection on X-ray images. (arXiv:2104.07279v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Iraji_M/0/1/0/all/0/1">Mohammad Saber Iraji</a>, <a href="http://arxiv.org/find/eess/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1">Mohammad-Reza Feizi-Derakhshi</a>, <a href="http://arxiv.org/find/eess/1/au:+Tanha_J/0/1/0/all/0/1">Jafar Tanha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07279">
                                    <div class="article-summary-box-inner">
                                        <span>The new Coronavirus is spreading rapidly, and it has taken the lives of many
people so far. The virus has destructive effects on the human lung, and early
detection is very important. Deep Convolution neural networks are such powerful
tools in classifying images. Therefore, in this paper, a hybrid approach based
on a deep network is presented. Feature vectors were extracted by applying a
deep convolution neural network on the images, and useful features were
selected by the binary differential meta-heuristic algorithm. These optimized
features were given to the SVM classifier. A database consisting of three
categories of images such as COVID-19, pneumonia, and healthy included in 1092
X-ray samples was considered. The proposed method achieved an accuracy of
99.43%, a sensitivity of 99.16%, and a specificity of 99.57%. Our results
demonstrate that the suggested approach is better than recent studies on
COVID-19 detection with X-ray images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Data Augmentation Approaches for NLP. (arXiv:2105.03075v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Steven Y. Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vosoughi_S/0/1/0/all/0/1">Soroush Vosoughi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1">Teruko Mitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03075">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation has recently seen increased interest in NLP due to more
work in low-resource domains, new tasks, and the popularity of large-scale
neural networks that require large amounts of training data. Despite this
recent upsurge, this area is still relatively underexplored, perhaps due to the
challenges posed by the discrete nature of language data. In this paper, we
present a comprehensive and unifying survey of data augmentation for NLP by
summarizing the literature in a structured manner. We first introduce and
motivate data augmentation for NLP, and then discuss major methodologically
representative approaches. Next, we highlight techniques that are used for
popular NLP applications and tasks. We conclude by outlining current challenges
and directions for future research. Overall, our paper aims to clarify the
landscape of existing literature in data augmentation for NLP and motivate
additional work in this area. We also present a GitHub repository with a paper
list that will be continuously updated at
https://github.com/styfeng/DataAug4NLP</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-parametric Differentially Private Confidence Intervals for the Median. (arXiv:2106.10333v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drechsler_J/0/1/0/all/0/1">Joerg Drechsler</a>, <a href="http://arxiv.org/find/cs/1/au:+Globus_Harris_I/0/1/0/all/0/1">Ira Globus-Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+McMillan_A/0/1/0/all/0/1">Audra McMillan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarathy_J/0/1/0/all/0/1">Jayshree Sarathy</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1">Adam Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10333">
                                    <div class="article-summary-box-inner">
                                        <span>Differential privacy is a restriction on data processing algorithms that
provides strong confidentiality guarantees for individual records in the data.
However, research on proper statistical inference, that is, research on
properly quantifying the uncertainty of the (noisy) sample estimate regarding
the true value in the population, is currently still limited. This paper
proposes and evaluates several strategies to compute valid differentially
private confidence intervals for the median. Instead of computing a
differentially private point estimate and deriving its uncertainty, we directly
estimate the interval bounds and discuss why this approach is superior if
ensuring privacy is important. We also illustrate that addressing both sources
of uncertainty--the error from sampling and the error from protecting the
output--simultaneously should be preferred over simpler approaches that
incorporate the uncertainty in a sequential fashion. We evaluate the
performance of the different algorithms under various parameter settings in
extensive simulation studies and demonstrate how the findings could be applied
in practical settings using data from the 1940 Decennial Census.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Corruption Robustness: Inductive Biases in Vision Transformers and MLP-Mixers. (arXiv:2106.13122v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morrison_K/0/1/0/all/0/1">Katelyn Morrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilby_B/0/1/0/all/0/1">Benjamin Gilby</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipchak_C/0/1/0/all/0/1">Colton Lipchak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattioli_A/0/1/0/all/0/1">Adam Mattioli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovashka_A/0/1/0/all/0/1">Adriana Kovashka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13122">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, vision transformers and MLP-based models have been developed in
order to address some of the prevalent weaknesses in convolutional neural
networks. Due to the novelty of transformers being used in this domain along
with the self-attention mechanism, it remains unclear to what degree these
architectures are robust to corruptions. Despite some works proposing that data
augmentation remains essential for a model to be robust against corruptions, we
propose to explore the impact that the architecture has on corruption
robustness. We find that vision transformer architectures are inherently more
robust to corruptions than the ResNet-50 and MLP-Mixers. We also find that
vision transformers with 5 times fewer parameters than a ResNet-50 have more
shape bias. Our code is available to reproduce.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bit More Bayesian: Domain-Invariant Learning with Uncertainty. (arXiv:2105.04030v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1">Zehao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jiayi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhen_X/0/1/0/all/0/1">Xiantong Zhen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G. M. Snoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04030">
                                    <div class="article-summary-box-inner">
                                        <span>Domain generalization is challenging due to the domain shift and the
uncertainty caused by the inaccessibility of target domain data. In this paper,
we address both challenges with a probabilistic framework based on variational
Bayesian inference, by incorporating uncertainty into neural network weights.
We couple domain invariance in a probabilistic formula with the variational
Bayesian inference. This enables us to explore domain-invariant learning in a
principled way. Specifically, we derive domain-invariant representations and
classifiers, which are jointly established in a two-layer Bayesian neural
network. We empirically demonstrate the effectiveness of our proposal on four
widely used cross-domain visual recognition benchmarks. Ablation studies
validate the synergistic benefits of our Bayesian treatment when jointly
learning domain-invariant representations and classifiers for domain
generalization. Further, our method consistently delivers state-of-the-art mean
accuracy on all benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Annotating Motion Primitives for Simplifying Action Search in Reinforcement Learning. (arXiv:2102.12017v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sledge_I/0/1/0/all/0/1">Isaac J. Sledge</a>, <a href="http://arxiv.org/find/cs/1/au:+Bryner_D/0/1/0/all/0/1">Darshan W. Bryner</a>, <a href="http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1">Jose C. Principe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12017">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning in large-scale environments is challenging due to the
many possible actions that can be taken in specific situations. We have
previously developed a means of constraining, and hence speeding up, the search
process through the use of motion primitives; motion primitives are sequences
of pre-specified actions taken across a state series. As a byproduct of this
work, we have found that if the motion primitives&#x27; motions and actions are
labeled, then the search can be sped up further. Since motion primitives may
initially lack such details, we propose a theoretically viewpoint-insensitive
and speed-insensitive means of automatically annotating the underlying motions
and actions. We do this through a differential-geometric, spatio-temporal
kinematics descriptor, which analyzes how the poses of entities in two motion
sequences change over time. We use this descriptor in conjunction with a
weighted-nearest-neighbor classifier to label the primitives using a limited
set of training examples. In our experiments, we achieve high motion and action
annotation rates for human-action-derived primitives with as few as one
training sample. We also demonstrate that reinforcement learning using
accurately labeled trajectories leads to high-performing policies more quickly
than standard reinforcement learning techniques. This is partly because motion
primitives encode prior domain knowledge and preempt the need to re-discover
that knowledge during training. It is also because agents can leverage the
labels to systematically ignore action classes that do not facilitate task
objectives, thereby reducing the action space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Layer-Wise Cross-View Decoding for Sequence-to-Sequence Learning. (arXiv:2005.08081v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fenglin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xuancheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guangxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xu Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08081">
                                    <div class="article-summary-box-inner">
                                        <span>In sequence-to-sequence learning, the decoder relies on the attention
mechanism to efficiently extract information from the encoder. While it is
common practice to draw information from only the last encoder layer, recent
work has proposed to use representations from different encoder layers for
diversified levels of information. Nonetheless, the decoder still obtains only
a single view of the source sequences, which might lead to insufficient
training of the encoder layer stack due to the hierarchy bypassing problem. In
this work, we propose layer-wise cross-view decoding, where for each decoder
layer, together with the representations from the last encoder layer, which
serve as a global view, those from other encoder layers are supplemented for a
stereoscopic view of the source sequences. Systematic experiments show that we
successfully address the hierarchy bypassing problem and substantially improve
the performance of sequence-to-sequence learning with deep representations on
diverse tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Constrained Optimization in Differentiable Neural Architecture Search. (arXiv:2106.11655v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maile_K/0/1/0/all/0/1">Kaitlin Maile</a>, <a href="http://arxiv.org/find/cs/1/au:+Lecarpentier_E/0/1/0/all/0/1">Erwan Lecarpentier</a>, <a href="http://arxiv.org/find/cs/1/au:+Luga_H/0/1/0/all/0/1">Herv&#xe9; Luga</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1">Dennis G. Wilson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11655">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable Architecture Search (DARTS) is a recently proposed neural
architecture search (NAS) method based on a differentiable relaxation. Due to
its success, numerous variants analyzing and improving parts of the DARTS
framework have recently been proposed. By considering the problem as a
constrained bilevel optimization, we propose and analyze three improvements to
architectural weight competition, update scheduling, and regularization towards
discretization. First, we introduce a new approach to the activation of
architecture weights, which prevents confounding competition within an edge and
allows for fair comparison across edges to aid in discretization. Next, we
propose a dynamic schedule based on per-minibatch network information to make
architecture updates more informed. Finally, we consider two regularizations,
based on proximity to discretization and the Alternating Directions Method of
Multipliers (ADMM) algorithm, to promote early discretization. Our results show
that this new activation scheme reduces final architecture size and the
regularizations improve reliability in search results while maintaining
comparable performance to state-of-the-art in NAS, especially when used with
our new dynamic informed schedule.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scale Mixtures of Neural Network Gaussian Processes. (arXiv:2107.01408v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1">Hyungi Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Yun_E/0/1/0/all/0/1">Eunggu Yun</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1">Hongseok Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01408">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have revealed that infinitely-wide feed-forward or recurrent
neural networks of any architecture correspond to Gaussian processes referred
to as $\mathrm{NNGP}$. While these works have extended the class of neural
networks converging to Gaussian processes significantly, however, there has
been little focus on broadening the class of stochastic processes that such
neural networks converge to. In this work, inspired by the scale mixture of
Gaussian random variables, we propose the scale mixture of $\mathrm{NNGP}$ for
which we introduce a prior distribution on the scale of the last-layer
parameters. We show that simply introducing a scale prior on the last-layer
parameters can turn infinitely-wide neural networks of any architecture into a
richer class of stochastic processes. Especially, with certain scale priors, we
obtain heavy-tailed stochastic processes, and we recover Student&#x27;s $t$
processes in the case of inverse gamma priors. We further analyze the
distributions of the neural networks initialized with our prior setting and
trained with gradient descents and obtain similar results as for
$\mathrm{NNGP}$. We present a practical posterior-inference algorithm for the
scale mixture of $\mathrm{NNGP}$ and empirically demonstrate its usefulness on
regression and classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiERU: Bidirectional Emotional Recurrent Unit for Conversational Sentiment Analysis. (arXiv:2006.00492v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1">Wei Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shaoxiong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.00492">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis in conversations has gained increasing attention in recent
years for the growing amount of applications it can serve, e.g., sentiment
analysis, recommender systems, and human-robot interaction. The main difference
between conversational sentiment analysis and single sentence sentiment
analysis is the existence of context information which may influence the
sentiment of an utterance in a dialogue. How to effectively encode contextual
information in dialogues, however, remains a challenge. Existing approaches
employ complicated deep learning structures to distinguish different parties in
a conversation and then model the context information. In this paper, we
propose a fast, compact and parameter-efficient party-ignorant framework named
bidirectional emotional recurrent unit for conversational sentiment analysis.
In our system, a generalized neural tensor block followed by a two-channel
classifier is designed to perform context compositionality and sentiment
classification, respectively. Extensive experiments on three standard datasets
demonstrate that our model outperforms the state of the art in most cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Examining average and discounted reward optimality criteria in reinforcement learning. (arXiv:2107.01348v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dewanto_V/0/1/0/all/0/1">Vektor Dewanto</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1">Marcus Gallagher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01348">
                                    <div class="article-summary-box-inner">
                                        <span>In reinforcement learning (RL), the goal is to obtain an optimal policy, for
which the optimality criterion is fundamentally important. Two major optimality
criteria are average and discounted rewards, where the later is typically
considered as an approximation to the former. While the discounted reward is
more popular, it is problematic to apply in environments that have no natural
notion of discounting. This motivates us to revisit a) the progression of
optimality criteria in dynamic programming, b) justification for and
complication of an artificial discount factor, and c) benefits of directly
maximizing the average reward. Our contributions include a thorough examination
of the relationship between average and discounted rewards, as well as a
discussion of their pros and cons in RL. We emphasize that average-reward RL
methods possess the ingredient and mechanism for developing the general
discounting-free optimality criterion (Veinott, 1969) in RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Novel Policy Seeking with Constrained Optimization. (arXiv:2005.10696v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhenghao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10696">
                                    <div class="article-summary-box-inner">
                                        <span>In problem-solving, we humans can come up with multiple novel solutions to
the same problem. However, reinforcement learning algorithms can only produce a
set of monotonous policies that maximize the cumulative reward but lack
diversity and novelty. In this work, we address the problem of generating novel
policies in reinforcement learning tasks. Instead of following the
multi-objective framework used in existing methods, we propose to rethink the
problem under a novel perspective of constrained optimization. We first
introduce a new metric to evaluate the difference between policies and then
design two practical novel policy generation methods following the new
perspective. The two proposed methods, namely the Constrained Task Novel
Bisector (CTNB) and the Interior Policy Differentiation (IPD), are derived from
the feasible direction method and the interior point method commonly known in
the constrained optimization literature. Experimental comparisons on the MuJoCo
control suite show our methods can achieve substantial improvement over
previous novelty-seeking methods in terms of both the novelty of policies and
their performances in the primal task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autoencoder based Randomized Learning of Feedforward Neural Networks for Regression. (arXiv:2107.01711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Grzegorz Dudek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01711">
                                    <div class="article-summary-box-inner">
                                        <span>Feedforward neural networks are widely used as universal predictive models to
fit data distribution. Common gradient-based learning, however, suffers from
many drawbacks making the training process ineffective and time-consuming.
Alternative randomized learning does not use gradients but selects hidden node
parameters randomly. This makes the training process extremely fast. However,
the problem in randomized learning is how to determine the random parameters. A
recently proposed method uses autoencoders for unsupervised parameter learning.
This method showed superior performance on classification tasks. In this work,
we apply this method to regression problems, and, finding that it has some
drawbacks, we show how to improve it. We propose a learning method of
autoencoders that controls the produced random weights. We also propose how to
determine the biases of hidden nodes. We empirically compare autoencoder based
learning with other randomized learning methods proposed recently for
regression and find that despite the proposed improvement of the autoencoder
based learning, it does not outperform its competitors in fitting accuracy.
Moreover, the method is much more complex than its competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning. (arXiv:2107.01264v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dann_C/0/1/0/all/0/1">Christoph Dann</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinov_T/0/1/0/all/0/1">Teodor V. Marinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohri_M/0/1/0/all/0/1">Mehryar Mohri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmert_J/0/1/0/all/0/1">Julian Zimmert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01264">
                                    <div class="article-summary-box-inner">
                                        <span>We provide improved gap-dependent regret bounds for reinforcement learning in
finite episodic Markov decision processes. Compared to prior work, our bounds
depend on alternative definitions of gaps. These definitions are based on the
insight that, in order to achieve a favorable regret, an algorithm does not
need to learn how to behave optimally in states that are not reached by an
optimal policy. We prove tighter upper regret bounds for optimistic algorithms
and accompany them with new information-theoretic lower bounds for a large
class of MDPs. Our results show that optimistic algorithms can not achieve the
information-theoretic lower bounds even in deterministic MDPs unless there is a
unique optimal policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EasyFL: A Low-code Federated Learning Platform For Dummies. (arXiv:2105.07603v2 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Weiming Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_X/0/1/0/all/0/1">Xin Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuai Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07603">
                                    <div class="article-summary-box-inner">
                                        <span>Academia and industry have developed several platforms to support the popular
privacy-preserving distributed learning method -- Federated Learning (FL).
However, these platforms are complex to use and require a deep understanding of
FL, which imposes high barriers to entry for beginners, limits the productivity
of researchers, and compromises deployment efficiency. In this paper, we
propose the first low-code FL platform, EasyFL, to enable users with various
levels of expertise to experiment and prototype FL applications with little
coding. We achieve this goal while ensuring great flexibility and extensibility
for customization by unifying simple API design, modular design, and granular
training flow abstraction. With only a few lines of code, EasyFL empowers them
with many out-of-the-box functionalities to accelerate experimentation and
deployment. These practical functionalities are heterogeneity simulation,
comprehensive tracking, distributed training optimization, and seamless
deployment. They are proposed based on challenges identified in the proposed FL
life cycle. Compared with other platforms, EasyFL not only requires just three
lines of code (at least 10x lesser) to build a vanilla FL application but also
incurs lower training overhead. Besides, our evaluations demonstrate that
EasyFL expedites distributed training by 1.5x. It also improves the efficiency
of deployment. We believe that EasyFL will increase the productivity of
researchers and democratize FL to wider audiences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ARM-Net: Adaptive Relation Modeling Network for Structured Data. (arXiv:2107.01830v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1">Shaofeng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kaiping Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagadish_H/0/1/0/all/0/1">H. V. Jagadish</a>, <a href="http://arxiv.org/find/cs/1/au:+Ooi_B/0/1/0/all/0/1">Beng Chin Ooi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Meihui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01830">
                                    <div class="article-summary-box-inner">
                                        <span>Relational databases are the de facto standard for storing and querying
structured data, and extracting insights from structured data requires advanced
analytics. Deep neural networks (DNNs) have achieved super-human prediction
performance in particular data types, e.g., images. However, existing DNNs may
not produce meaningful results when applied to structured data. The reason is
that there are correlations and dependencies across combinations of attribute
values in a table, and these do not follow simple additive patterns that can be
easily mimicked by a DNN. The number of possible such cross features is
combinatorial, making them computationally prohibitive to model. Furthermore,
the deployment of learning models in real-world applications has also
highlighted the need for interpretability, especially for high-stakes
applications, which remains another issue of concern to DNNs.

In this paper, we present ARM-Net, an adaptive relation modeling network
tailored for structured data, and a lightweight framework ARMOR based on
ARM-Net for relational data analytics. The key idea is to model feature
interactions with cross features selectively and dynamically, by first
transforming the input features into exponential space, and then determining
the interaction order and interaction weights adaptively for each cross
feature. We propose a novel sparse attention mechanism to dynamically generate
the interaction weights given the input tuple, so that we can explicitly model
cross features of arbitrary orders with noisy features filtered selectively.
Then during model inference, ARM-Net can specify the cross features being used
for each prediction for higher accuracy and better interpretability. Our
extensive experiments on real-world datasets demonstrate that ARM-Net
consistently outperforms existing models and provides more interpretable
predictions for data-driven decision making.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A similarity-based Bayesian mixture-of-experts model. (arXiv:2012.02130v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1">Tianfang Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Bokrantz_R/0/1/0/all/0/1">Rasmus Bokrantz</a>, <a href="http://arxiv.org/find/stat/1/au:+Olsson_J/0/1/0/all/0/1">Jimmy Olsson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02130">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new nonparametric mixture-of-experts model for multivariate
regression problems, inspired by the probabilistic $k$-nearest neighbors
algorithm. Using a conditionally specified model, predictions for out-of-sample
inputs are based on similarities to each observed data point, yielding
predictive distributions represented by Gaussian mixtures. Posterior inference
is performed on the parameters of the mixture components as well as the
distance metric using a mean-field variational Bayes algorithm accompanied with
a stochastic gradient-based optimization procedure. The proposed method is
especially advantageous in settings where inputs are of relatively high
dimension in comparison to the data size, where input--output relationships are
complex, and where predictive distributions may be skewed or multimodal.
Computational studies on two synthetic datasets and one dataset comprising dose
statistics of radiation therapy treatment plans show that our
mixture-of-experts method performs similarly or better than a conditional
Dirichlet process mixture model both in terms of validation metrics and visual
inspection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedSiam: Towards Adaptive Federated Semi-Supervised Learning. (arXiv:2012.03292v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1">Zewei Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_L/0/1/0/all/0/1">Liwei Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Muchao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Junyu Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jinze Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Houping Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fenglong Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03292">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) has emerged as an effective technique to co-training
machine learning models without actually sharing data and leaking privacy.
However, most existing FL methods focus on the supervised setting and ignore
the utilization of unlabeled data. Although there are a few existing studies
trying to incorporate unlabeled data into FL, they all fail to maintain
performance guarantees or generalization ability in various real-world
settings. In this paper, we focus on designing a general framework FedSiam to
tackle different scenarios of federated semi-supervised learning, including
four settings in the labels-at-client scenario and two setting in the
labels-at-server scenario. FedSiam is built upon a siamese network into FL with
a momentum update to handle the non-IID challenges introduced by unlabeled
data. We further propose a new metric to measure the divergence of local model
layers within the siamese network. Based on the divergence, FedSiam can
automatically select layer-level parameters to be uploaded to the server in an
adaptive manner. Experimental results on three datasets under two scenarios
with different data distribution settings demonstrate that the proposed FedSiam
framework outperforms state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causally Invariant Predictor with Shift-Robustness. (arXiv:2107.01876v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zheng_X/0/1/0/all/0/1">Xiangyu Zheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Sun_X/0/1/0/all/0/1">Xinwei Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01876">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an invariant causal predictor that is robust to
distribution shift across domains and maximally reserves the transferable
invariant information. Based on a disentangled causal factorization, we
formulate the distribution shift as soft interventions in the system, which
covers a wide range of cases for distribution shift as we do not make prior
specifications on the causal structure or the intervened variables. Instead of
imposing regularizations to constrain the invariance of the predictor, we
propose to predict by the intervened conditional expectation based on the
do-operator and then prove that it is invariant across domains. More
importantly, we prove that the proposed predictor is the robust predictor that
minimizes the worst-case quadratic loss among the distributions of all domains.
For empirical learning, we propose an intuitive and flexible estimating method
based on data regeneration and present a local causal discovery procedure to
guide the regeneration step. The key idea is to regenerate data such that the
regenerated distribution is compatible with the intervened graph, which allows
us to incorporate standard supervised learning methods with the regenerated
data. Experimental results on both synthetic and real data demonstrate the
efficacy of our predictor in improving the predictive accuracy and robustness
across domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Time Series Forecasting: An Image-driven Approach. (arXiv:2107.01273v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Naftali Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_S/0/1/0/all/0/1">Srijan Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhen Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Balch_T/0/1/0/all/0/1">Tucker Balch</a>, <a href="http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1">Manuela Veloso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01273">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address time-series forecasting as a computer vision task.
We capture input data as an image and train a model to produce the subsequent
image. This approach results in predicting distributions as opposed to
pointwise values. To assess the robustness and quality of our approach, we
examine various datasets and multiple evaluation metrics. Our experiments show
that our forecasting tool is effective for cyclic data but somewhat less for
irregular data such as stock prices. Importantly, when using image-based
evaluation metrics, we find our method to outperform various baselines,
including ARIMA, and a numerical variation of our deep learning approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improper Reinforcement Learning with Gradient-based Policy Optimization. (arXiv:2102.08201v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaki_M/0/1/0/all/0/1">Mohammadi Zaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1">Avinash Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gopalan_A/0/1/0/all/0/1">Aditya Gopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08201">
                                    <div class="article-summary-box-inner">
                                        <span>We consider an improper reinforcement learning setting where a learner is
given $M$ base controllers for an unknown Markov decision process, and wishes
to combine them optimally to produce a potentially new controller that can
outperform each of the base ones. This can be useful in tuning across
controllers, learnt possibly in mismatched or simulated environments, to obtain
a good controller for a given target environment with relatively few trials.

\par We propose a gradient-based approach that operates over a class of
improper mixtures of the controllers. We derive convergence rate guarantees for
the approach assuming access to a gradient oracle. The value function of the
mixture and its gradient may not be available in closed-form; however, we show
that we can employ rollouts and simultaneous perturbation stochastic
approximation (SPSA) for explicit gradient descent optimization. Numerical
results on (i) the standard control theoretic benchmark of stabilizing an
inverted pendulum and (ii) a constrained queueing task show that our improper
policy optimization algorithm can stabilize the system even when the base
policies at its disposal are unstable\footnote{Under review. Please do not
distribute.}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Theoretic Meta Learning with Gaussian Processes. (arXiv:2009.03228v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Titsias_M/0/1/0/all/0/1">Michalis K. Titsias</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiz_F/0/1/0/all/0/1">Francisco J. R. Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikoloutsopoulos_S/0/1/0/all/0/1">Sotirios Nikoloutsopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Galashov_A/0/1/0/all/0/1">Alexandre Galashov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03228">
                                    <div class="article-summary-box-inner">
                                        <span>We formulate meta learning using information theoretic concepts; namely,
mutual information and the information bottleneck. The idea is to learn a
stochastic representation or encoding of the task description, given by a
training set, that is highly informative about predicting the validation set.
By making use of variational approximations to the mutual information, we
derive a general and tractable framework for meta learning. This framework
unifies existing gradient-based algorithms and also allows us to derive new
algorithms. In particular, we develop a memory-based algorithm that uses
Gaussian processes to obtain non-parametric encoding representations. We
demonstrate our method on a few-shot regression problem and on four few-shot
classification problems, obtaining competitive accuracy when compared to
existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MaxVA: Fast Adaptation of Step Sizes by Maximizing Observed Variance of Gradients. (arXiv:2006.11918v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11918">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive gradient methods such as RMSProp and Adam use exponential moving
estimate of the squared gradient to compute adaptive step sizes, achieving
better convergence than SGD in face of noisy objectives. However, Adam can have
undesirable convergence behaviors due to unstable or extreme adaptive learning
rates. Methods such as AMSGrad and AdaBound have been proposed to stabilize the
adaptive learning rates of Adam in the later stage of training, but they do not
outperform Adam in some practical tasks such as training Transformers
\cite{transformer}. In this paper, we propose an adaptive learning rate
principle, in which the running mean of squared gradient in Adam is replaced by
a weighted mean, with weights chosen to maximize the estimated variance of each
coordinate. This results in a faster adaptation to the local gradient variance,
which leads to more desirable empirical convergence behaviors than Adam. We
prove the proposed algorithm converges under mild assumptions for nonconvex
stochastic optimization problems, and demonstrate the improved efficacy of our
adaptive averaging approach on machine translation, natural language
understanding and large-batch pretraining of BERT. The code is available at
https://github.com/zhuchen03/MaxVA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Learning-Based Adaptive Control for Safety Critical Systems. (arXiv:1910.02325v3 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fan_D/0/1/0/all/0/1">David D. Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_J/0/1/0/all/0/1">Jennifer Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Thakker_R/0/1/0/all/0/1">Rohan Thakker</a>, <a href="http://arxiv.org/find/eess/1/au:+Alatur_N/0/1/0/all/0/1">Nikhilesh Alatur</a>, <a href="http://arxiv.org/find/eess/1/au:+Agha_mohammadi_A/0/1/0/all/0/1">Ali-akbar Agha-mohammadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Theodorou_E/0/1/0/all/0/1">Evangelos A. Theodorou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.02325">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has enjoyed much recent success, and applying state-of-the-art
model learning methods to controls is an exciting prospect. However, there is a
strong reluctance to use these methods on safety-critical systems, which have
constraints on safety, stability, and real-time performance. We propose a
framework which satisfies these constraints while allowing the use of deep
neural networks for learning model uncertainties. Central to our method is the
use of Bayesian model learning, which provides an avenue for maintaining
appropriate degrees of caution in the face of the unknown. In the proposed
approach, we develop an adaptive control framework leveraging the theory of
stochastic CLFs (Control Lyapunov Functions) and stochastic CBFs (Control
Barrier Functions) along with tractable Bayesian model learning via Gaussian
Processes or Bayesian neural networks. Under reasonable assumptions, we
guarantee stability and safety while adapting to unknown dynamics with
probability 1. We demonstrate this architecture for high-speed terrestrial
mobility targeting potential applications in safety-critical high-speed Mars
rover missions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks. (arXiv:2102.06462v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yujun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1">Milad Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1">Kevin Swersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaoqing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1">Danai Koutra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06462">
                                    <div class="article-summary-box-inner">
                                        <span>Most graph convolutional neural networks (GCNs) perform poorly in graphs
where neighbors typically have different features/classes (heterophily) and
when stacking multiple layers (oversmoothing). These two seemingly unrelated
problems have been studied independently, but there is recent empirical
evidence that solving one problem may benefit the other. In this work, going
beyond empirical observations, we aim to: (1) propose a new perspective to
analyze the heterophily and oversmoothing problems under a unified theoretical
framework, (2) identify the common causes of the two problems based on the
proposed framework, and (3) propose simple yet effective strategies that
address the common causes. Focusing on the node classification task, we use
linear separability of node representations as an indicator to reflect the
performance of GCNs and we propose to study the linear separability by
analyzing the statistical change of the node representations in the graph
convolution. We find that the relative degree of a node (compared to its
neighbors) and the heterophily level of a node&#x27;s neighborhood are the root
causes that influence the separability of node representations. Our analysis
suggests that: (1) Nodes with high heterophily always produce less separable
representations after graph convolution; (2) Even with low heterophily, degree
disparity between nodes can influence the network dynamics and result in a
pseudo-heterophily situation, which helps to explain oversmoothing. Based on
our insights, we propose simple modifications to the GCN architecture -- i.e.,
degree corrections and signed messages -- which alleviate the root causes of
these issues, and also show this empirically on 9 real networks. Compared to
other approaches, which tend to work well in one regime but fail in others, our
modified GCN model consistently performs well across all settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Latency Real-Time Non-Parallel Voice Conversion based on Cyclic Variational Autoencoder and Multiband WaveRNN with Data-Driven Linear Prediction. (arXiv:2105.09858v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tobing_P/0/1/0/all/0/1">Patrick Lumban Tobing</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1">Tomoki Toda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09858">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a low-latency real-time (LLRT) non-parallel voice
conversion (VC) framework based on cyclic variational autoencoder (CycleVAE)
and multiband WaveRNN with data-driven linear prediction (MWDLP). CycleVAE is a
robust non-parallel multispeaker spectral model, which utilizes a
speaker-independent latent space and a speaker-dependent code to generate
reconstructed/converted spectral features given the spectral features of an
input speaker. On the other hand, MWDLP is an efficient and a high-quality
neural vocoder that can handle multispeaker data and generate speech waveform
for LLRT applications with CPU. To accommodate LLRT constraint with CPU, we
propose a novel CycleVAE framework that utilizes mel-spectrogram as spectral
features and is built with a sparse network architecture. Further, to improve
the modeling performance, we also propose a novel fine-tuning procedure that
refines the frame-rate CycleVAE network by utilizing the waveform loss from the
MWDLP network. The experimental results demonstrate that the proposed framework
achieves high-performance VC, while allowing for LLRT usage with a single-core
of $2.1$--$2.7$ GHz CPU on a real-time factor of $0.87$--$0.95$, including
input/output, feature extraction, on a frame shift of $10$ ms, a window length
of $27.5$ ms, and $2$ lookup frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CInC Flow: Characterizable Invertible 3x3 Convolution. (arXiv:2107.01358v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagar_S/0/1/0/all/0/1">Sandeep Nagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dufraisse_M/0/1/0/all/0/1">Marius Dufraisse</a>, <a href="http://arxiv.org/find/cs/1/au:+Varma_G/0/1/0/all/0/1">Girish Varma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01358">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are an essential alternative to GANs for generative
modelling, which can be optimized directly on the maximum likelihood of the
dataset. They also allow computation of the exact latent vector corresponding
to an image since they are composed of invertible transformations. However, the
requirement of invertibility of the transformation prevents standard and
expressive neural network models such as CNNs from being directly used.
Emergent convolutions were proposed to construct an invertible 3$\times$3 CNN
layer using a pair of masked CNN layers, making them inefficient. We study
conditions such that 3$\times$3 CNNs are invertible, allowing them to construct
expressive normalizing flows. We derive necessary and sufficient conditions on
a padded CNN for it to be invertible. Our conditions for invertibility are
simple, can easily be maintained during the training process. Since we require
only a single CNN layer for every effective invertible CNN layer, our approach
is more efficient than emerging convolutions. We also proposed a coupling
method, Quad-coupling. We benchmark our approach and show similar performance
results to emergent convolutions while improving the model&#x27;s efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On The Distribution of Penultimate Activations of Classification Networks. (arXiv:2107.01900v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minkyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yoonho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1">Suha Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01900">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies probability distributions ofpenultimate activations of
classification networks.We show that, when a classification network istrained
with the cross-entropy loss, its final classi-fication layer forms
aGenerative-Discriminativepairwith a generative classifier based on a
specificdistribution of penultimate activations. More im-portantly, the
distribution is parameterized by theweights of the final fully-connected layer,
and canbe considered as a generative model that synthe-sizes the penultimate
activations without feedinginput data. We empirically demonstrate that
thisgenerative model enables stable knowledge dis-tillation in the presence of
domain shift, and cantransfer knowledge from a classifier to
variationalautoencoders and generative adversarial networksfor
class-conditional image generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Finite Reward Automaton Inference and Reinforcement Learning Using Queries and Counterexamples. (arXiv:2006.15714v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ojha_A/0/1/0/all/0/1">Aditya Ojha</a>, <a href="http://arxiv.org/find/cs/1/au:+Neider_D/0/1/0/all/0/1">Daniel Neider</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15714">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the fact that deep reinforcement learning (RL) has surpassed
human-level performances in various tasks, it still has several fundamental
challenges. First, most RL methods require intensive data from the exploration
of the environment to achieve satisfactory performance. Second, the use of
neural networks in RL renders it hard to interpret the internals of the system
in a way that humans can understand. To address these two challenges, we
propose a framework that enables an RL agent to reason over its exploration
process and distill high-level knowledge for effectively guiding its future
explorations. Specifically, we propose a novel RL algorithm that learns
high-level knowledge in the form of a finite reward automaton by using the L*
learning algorithm. We prove that in episodic RL, a finite reward automaton can
express any non-Markovian bounded reward functions with finitely many reward
values and approximate any non-Markovian bounded reward function (with
infinitely many reward values) with arbitrary precision. We also provide a
lower bound for the episode length such that the proposed RL approach almost
surely converges to an optimal policy in the limit. We test this approach on
two RL environments with non-Markovian reward functions, choosing a variety of
tasks with increasing complexity for each environment. We compare our algorithm
with the state-of-the-art RL algorithms for non-Markovian reward functions,
such as Joint Inference of Reward machines and Policies for RL (JIRP), Learning
Reward Machine (LRM), and Proximal Policy Optimization (PPO2). Our results show
that our algorithm converges to an optimal policy faster than other baseline
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Taxonomy of Saliency Metrics for Channel Pruning. (arXiv:1906.04675v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Persand_K/0/1/0/all/0/1">Kaveena Persand</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_A/0/1/0/all/0/1">Andrew Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gregg_D/0/1/0/all/0/1">David Gregg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.04675">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning unimportant parameters can allow deep neural networks (DNNs) to
reduce their heavy computation and memory requirements. A saliency metric
estimates which parameters can be safely pruned with little impact on the
classification performance of the DNN. Many saliency metrics have been
proposed, each within the context of a wider pruning algorithm. The result is
that it is difficult to separate the effectiveness of the saliency metric from
the wider pruning algorithm that surrounds it. Similar-looking saliency metrics
can yield very different results because of apparently minor design choices. We
propose a taxonomy of saliency metrics based on four mostly-orthogonal
principal components. We show that a broad range of metrics from the pruning
literature can be grouped according to these components. Our taxonomy not only
serves as a guide to prior work, but allows us to construct new saliency
metrics by exploring novel combinations of our taxonomic components. We perform
an in-depth experimental investigation of more than 300 saliency metrics. Our
results provide decisive answers to open research questions, and demonstrate
the importance of reduction and scaling when pruning groups of weights. We find
that some of our constructed metrics can outperform the best existing
state-of-the-art metrics for convolutional neural network channel pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Off-Policy Ranking. (arXiv:2107.01360v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yue Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xudong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1">Jian Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01360">
                                    <div class="article-summary-box-inner">
                                        <span>Off-policy evaluation (OPE) leverages data generated by other policies to
evaluate a target policy. Previous OPE methods mainly focus on precisely
estimating the true performance of a policy. We observe that in many
applications, (1) the end goal of OPE is to compare two or multiple candidate
policies and choose a good one, which is actually a much simpler task than
evaluating their true performance; and (2) there are usually multiple policies
that have been deployed in real-world systems and thus whose true performance
is known through serving real users. Inspired by the two observations, in this
work, we define a new problem, supervised off-policy ranking (SOPR), which aims
to rank a set of new/target policies based on supervised learning by leveraging
off-policy data and policies with known performance. We further propose a
method for supervised off-policy ranking that learns a policy scoring model by
correctly ranking training policies with known performance rather than
estimating their precise performance. Our method leverages logged states and
policies to learn a Transformer based model that maps offline interaction data
including logged states and the actions taken by a target policy on these
states to a score. Experiments on different games, datasets, training policy
sets, and test policy sets show that our method outperforms strong baseline OPE
methods in terms of both rank correlation and performance gap between the truly
best and the best of the ranked top three policies. Furthermore, our method is
more stable than baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extended Few-Shot Learning: Exploiting Existing Resources for Novel Tasks. (arXiv:2012.07176v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Esfandiarpoor_R/0/1/0/all/0/1">Reza Esfandiarpoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_A/0/1/0/all/0/1">Amy Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajabdollahi_M/0/1/0/all/0/1">Mohsen Hajabdollahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1">Stephen H. Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07176">
                                    <div class="article-summary-box-inner">
                                        <span>In many practical few-shot learning problems, even though labeled examples
are scarce, there are abundant auxiliary datasets that potentially contain
useful information. We propose the problem of extended few-shot learning to
study these scenarios. We then introduce a framework to address the challenges
of efficiently selecting and effectively using auxiliary data in few-shot image
classification. Given a large auxiliary dataset and a notion of semantic
similarity among classes, we automatically select pseudo shots, which are
labeled examples from other classes related to the target task. We show that
naive approaches, such as (1) modeling these additional examples the same as
the target task examples or (2) using them to learn features via transfer
learning, only increase accuracy by a modest amount. Instead, we propose a
masking module that adjusts the features of auxiliary data to be more similar
to those of the target classes. We show that this masking module performs
better than naively modeling the support examples and transfer learning by 4.68
and 6.03 percentage points, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attribute-aware Explainable Complementary Clothing Recommendation. (arXiv:2107.01655v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01655">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling mix-and-match relationships among fashion items has become
increasingly demanding yet challenging for modern E-commerce recommender
systems. When performing clothes matching, most existing approaches leverage
the latent visual features extracted from fashion item images for compatibility
modelling, which lacks explainability of generated matching results and can
hardly convince users of the recommendations. Though recent methods start to
incorporate pre-defined attribute information (e.g., colour, style, length,
etc.) for learning item representations and improving the model
interpretability, their utilisation of attribute information is still mainly
reserved for enhancing the learned item representations and generating
explanations via post-processing. As a result, this creates a severe bottleneck
when we are trying to advance the recommendation accuracy and generating
fine-grained explanations since the explicit attributes have only loose
connections to the actual recommendation process. This work aims to tackle the
explainability challenge in fashion recommendation tasks by proposing a novel
Attribute-aware Fashion Recommender (AFRec). Specifically, AFRec recommender
assesses the outfit compatibility by explicitly leveraging the extracted
attribute-level representations from each item&#x27;s visual feature. The attributes
serve as the bridge between two fashion items, where we quantify the affinity
of a pair of items through the learned compatibility between their attributes.
Extensive experiments have demonstrated that, by making full use of the
explicit attributes in the recommendation process, AFRec is able to achieve
state-of-the-art recommendation accuracy and generate intuitive explanations at
the same time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lottery Tickets in Linear Models: An Analysis of Iterative Magnitude Pruning. (arXiv:2007.08243v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elesedy_B/0/1/0/all/0/1">Bryn Elesedy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanade_V/0/1/0/all/0/1">Varun Kanade</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08243">
                                    <div class="article-summary-box-inner">
                                        <span>We analyse the pruning procedure behind the lottery ticket hypothesis
arXiv:1803.03635v5, iterative magnitude pruning (IMP), when applied to linear
models trained by gradient flow. We begin by presenting sufficient conditions
on the statistical structure of the features under which IMP prunes those
features that have smallest projection onto the data. Following this, we
explore IMP as a method for sparse estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Approximation of Functions on Sets. (arXiv:2107.01959v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wagstaff_E/0/1/0/all/0/1">Edward Wagstaff</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuchs_F/0/1/0/all/0/1">Fabian B. Fuchs</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelcke_M/0/1/0/all/0/1">Martin Engelcke</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1">Michael A. Osborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Posner_I/0/1/0/all/0/1">Ingmar Posner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01959">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling functions of sets, or equivalently, permutation-invariant
functions, is a long-standing challenge in machine learning. Deep Sets is a
popular method which is known to be a universal approximator for continuous set
functions. We provide a theoretical analysis of Deep Sets which shows that this
universal approximation property is only guaranteed if the model&#x27;s latent space
is sufficiently high-dimensional. If the latent space is even one dimension
lower than necessary, there exist piecewise-affine functions for which Deep
Sets performs no better than a na\&quot;ive constant baseline, as judged by
worst-case error. Deep Sets may be viewed as the most efficient incarnation of
the Janossy pooling paradigm. We identify this paradigm as encompassing most
currently popular set-learning methods. Based on this connection, we discuss
the implications of our results for set learning more broadly, and identify
some open questions on the universality of Janossy pooling in general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When and How to Fool Explainable Models (and Humans) with Adversarial Examples. (arXiv:2107.01943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vadillo_J/0/1/0/all/0/1">Jon Vadillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Santana_R/0/1/0/all/0/1">Roberto Santana</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozano_J/0/1/0/all/0/1">Jose A. Lozano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01943">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable deployment of machine learning models such as neural networks
continues to be challenging due to several limitations. Some of the main
shortcomings are the lack of interpretability and the lack of robustness
against adversarial examples or out-of-distribution inputs. In this paper, we
explore the possibilities and limits of adversarial attacks for explainable
machine learning models. First, we extend the notion of adversarial examples to
fit in explainable machine learning scenarios, in which the inputs, the output
classifications and the explanations of the model&#x27;s decisions are assessed by
humans. Next, we propose a comprehensive framework to study whether (and how)
adversarial examples can be generated for explainable models under human
assessment, introducing novel attack paradigms. In particular, our framework
considers a wide range of relevant (yet often ignored) factors such as the type
of problem, the user expertise or the objective of the explanations in order to
identify the attack strategies that should be adopted in each scenario to
successfully deceive the model (and the human). These contributions intend to
serve as a basis for a more rigorous and realistic study of adversarial
examples in the field of explainable machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MARINA: Faster Non-Convex Distributed Learning with Compression. (arXiv:2102.07845v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gorbunov_E/0/1/0/all/0/1">Eduard Gorbunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Burlachenko_K/0/1/0/all/0/1">Konstantin Burlachenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhize Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1">Peter Richt&#xe1;rik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07845">
                                    <div class="article-summary-box-inner">
                                        <span>We develop and analyze MARINA: a new communication efficient method for
non-convex distributed learning over heterogeneous datasets. MARINA employs a
novel communication compression strategy based on the compression of gradient
differences that is reminiscent of but different from the strategy employed in
the DIANA method of Mishchenko et al. (2019). Unlike virtually all competing
distributed first-order methods, including DIANA, ours is based on a carefully
designed biased gradient estimator, which is the key to its superior
theoretical and practical performance. The communication complexity bounds we
prove for MARINA are evidently better than those of all previous first-order
methods. Further, we develop and analyze two variants of MARINA: VR-MARINA and
PP-MARINA. The first method is designed for the case when the local loss
functions owned by clients are either of a finite sum or of an expectation
form, and the second method allows for a partial participation of clients -- a
feature important in federated learning. All our methods are superior to
previous state-of-the-art methods in terms of oracle/communication complexity.
Finally, we provide a convergence analysis of all methods for problems
satisfying the Polyak-Lojasiewicz condition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Audiovisual Synthesis via Exemplar Autoencoders. (arXiv:2001.04463v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Aayush Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04463">
                                    <div class="article-summary-box-inner">
                                        <span>We present an unsupervised approach that converts the input speech of any
individual into audiovisual streams of potentially-infinitely many output
speakers. Our approach builds on simple autoencoders that project out-of-sample
data onto the distribution of the training set. We use Exemplar Autoencoders to
learn the voice, stylistic prosody, and visual appearance of a specific target
exemplar speech. In contrast to existing methods, the proposed approach can be
easily extended to an arbitrarily large number of speakers and styles using
only 3 minutes of target audio-video data, without requiring {\em any} training
data for the input speaker. To do so, we learn audiovisual bottleneck
representations that capture the structured linguistic content of speech. We
outperform prior approaches on both audio and video synthesis, and provide
extensive qualitative analysis on our project page --
https://www.cs.cmu.edu/~exemplar-ae/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">All Local Minima are Global for Two-Layer ReLU Neural Networks: The Hidden Convex Optimization Landscape. (arXiv:2006.05900v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacotte_J/0/1/0/all/0/1">Jonathan Lacotte</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1">Mert Pilanci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05900">
                                    <div class="article-summary-box-inner">
                                        <span>We prove that finding all globally optimal two-layer ReLU neural networks can
be performed by solving a convex optimization program with cone constraints.
Our analysis is novel, characterizes all optimal solutions, and does not
leverage duality-based analysis which was recently used to lift neural network
training into convex spaces. Given the set of solutions of our convex
optimization program, we show how to construct exactly the entire set of
optimal neural networks. We provide a detailed characterization of this optimal
set and its invariant transformations. As additional consequences of our convex
perspective, (i) we establish that Clarke stationary points found by stochastic
gradient descent correspond to the global optimum of a subsampled convex
problem (ii) we provide a polynomial-time algorithm for checking if a neural
network is a global minimum of the training loss (iii) we provide an explicit
construction of a continuous path between any neural network and the global
minimum of its sublevel set and (iv) characterize the minimal size of the
hidden layer so that the neural network optimization landscape has no spurious
valleys. Overall, we provide a rich framework for studying the landscape of
neural network training loss through convexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Matching a Desired Causal State via Shift Interventions. (arXiv:2107.01850v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1">Jiaqi Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Squires_C/0/1/0/all/0/1">Chandler Squires</a>, <a href="http://arxiv.org/find/stat/1/au:+Uhler_C/0/1/0/all/0/1">Caroline Uhler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01850">
                                    <div class="article-summary-box-inner">
                                        <span>Transforming a causal system from a given initial state to a desired target
state is an important task permeating multiple fields including control theory,
biology, and materials science. In causal models, such transformations can be
achieved by performing a set of interventions. In this paper, we consider the
problem of identifying a shift intervention that matches the desired mean of a
system through active learning. We define the Markov equivalence class that is
identifiable from shift interventions and propose two active learning
strategies that are guaranteed to exactly match a desired mean. We then derive
a worst-case lower bound for the number of interventions required and show that
these strategies are optimal for certain classes of graphs. In particular, we
show that our strategies may require exponentially fewer interventions than the
previously considered approaches, which optimize for structure learning in the
underlying causal graph. In line with our theoretical results, we also
demonstrate experimentally that our proposed active learning strategies require
fewer interventions compared to several baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial Imitation Learning. (arXiv:2006.16785v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blonde_L/0/1/0/all/0/1">Lionel Blond&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Strasser_P/0/1/0/all/0/1">Pablo Strasser</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1">Alexandros Kalousis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16785">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the recent success of reinforcement learning in various domains,
these approaches remain, for the most part, deterringly sensitive to
hyper-parameters and are often riddled with essential engineering feats
allowing their success. We consider the case of off-policy generative
adversarial imitation learning, and perform an in-depth review, qualitative and
quantitative, of the method. We show that forcing the learned reward function
to be local Lipschitz-continuous is a sine qua non condition for the method to
perform well. We then study the effects of this necessary condition and provide
several theoretical results involving the local Lipschitzness of the
state-value function. We complement these guarantees with empirical evidence
attesting to the strong positive effect that the consistent satisfaction of the
Lipschitzness constraint on the reward has on imitation performance. Finally,
we tackle a generic pessimistic reward preconditioning add-on spawning a large
class of reward shaping methods, which makes the base method it is plugged into
provably more robust, as shown in several additional theoretical guarantees. We
then discuss these through a fine-grained lens and share our insights.
Crucially, the guarantees derived and reported in this work are valid for any
reward satisfying the Lipschitzness condition, nothing is specific to
imitation. As such, these may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Convergence of Nesterov Accelerated Method for Over-Parameterized Neural Networks. (arXiv:2107.01832v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhisong Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01832">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the empirical success of deep learning, it still lacks theoretical
understandings to explain why randomly initialized neural network trained by
first-order optimization methods is able to achieve zero training loss, even
though its landscape is non-convex and non-smooth. Recently, there are some
works to demystifies this phenomenon under over-parameterized regime. In this
work, we make further progress on this area by considering a commonly used
momentum optimization algorithm: Nesterov accelerated method (NAG). We analyze
the convergence of NAG for two-layer fully connected neural network with ReLU
activation. Specifically, we prove that the error of NAG converges to zero at a
linear convergence rate $1-\Theta(1/\sqrt{\kappa})$, where $\kappa &gt; 1$ is
determined by the initialization and the architecture of neural network.
Comparing to the rate $1-\Theta(1/\kappa)$ of gradient descent, NAG achieves an
acceleration. Besides, it also validates NAG and Heavy-ball method can achieve
a similar convergence rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis Tool for Singers. (arXiv:2105.00173v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Szelogowski_D/0/1/0/all/0/1">Daniel Szelogowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00173">
                                    <div class="article-summary-box-inner">
                                        <span>Current computational-emotion research has focused on applying acoustic
properties to analyze how emotions are perceived mathematically or used in
natural language processing machine learning models. While recent interest has
focused on analyzing emotions from the spoken voice, little experimentation has
been performed to discover how emotions are recognized in the singing voice --
both in noiseless and noisy data (i.e., data that is either inaccurate,
difficult to interpret, has corrupted/distorted/nonsense information like
actual noise sounds in this case, or has a low ratio of usable/unusable
information). Not only does this ignore the challenges of training machine
learning models on more subjective data and testing them with much noisier
data, but there is also a clear disconnect in progress between advancing the
development of convolutional neural networks and the goal of emotionally
cognizant artificial intelligence. By training a new model to include this type
of information with a rich comprehension of psycho-acoustic properties, not
only can models be trained to recognize information within extremely noisy
data, but advancement can be made toward more complex biofeedback applications
-- including creating a model which could recognize emotions given any human
information (language, breath, voice, body, posture) and be used in any
performance medium (music, speech, acting) or psychological assistance for
patients with disorders such as BPD, alexithymia, autism, among others. This
paper seeks to reflect and expand upon the findings of related research and
present a stepping-stone toward this end goal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering of Time Series Data with Prior Geographical Information. (arXiv:2107.01310v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asadi_R/0/1/0/all/0/1">Reza Asadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Regan_A/0/1/0/all/0/1">Amelia Regan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01310">
                                    <div class="article-summary-box-inner">
                                        <span>Time Series data are broadly studied in various domains of transportation
systems. Traffic data area challenging example of spatio-temporal data, as it
is multi-variate time series with high correlations in spatial and temporal
neighborhoods. Spatio-temporal clustering of traffic flow data find similar
patterns in both spatial and temporal domain, where it provides better
capability for analyzing a transportation network, and improving related
machine learning models, such as traffic flow prediction and anomaly detection.
In this paper, we propose a spatio-temporal clustering model, where it clusters
time series data based on spatial and temporal contexts. We propose a variation
of a Deep Embedded Clustering(DEC) model for finding spatio-temporal clusters.
The proposed model Spatial-DEC (S-DEC) use prior geographical information in
building latent feature representations. We also define evaluation metrics for
spatio-temporal clusters. Not only do the obtained clusters have better
temporal similarity when evaluated using DTW distance, but also the clusters
better represents spatial connectivity and dis-connectivity. We use traffic
flow data obtained by PeMS in our analysis. The results show that the proposed
Spatial-DEC can find more desired spatio-temporal clusters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SGLB: Stochastic Gradient Langevin Boosting. (arXiv:2001.07248v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ustimenko_A/0/1/0/all/0/1">Aleksei Ustimenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1">Liudmila Prokhorenkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.07248">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces Stochastic Gradient Langevin Boosting (SGLB) - a
powerful and efficient machine learning framework that may deal with a wide
range of loss functions and has provable generalization guarantees. The method
is based on a special form of the Langevin diffusion equation specifically
designed for gradient boosting. This allows us to theoretically guarantee the
global convergence even for multimodal loss functions, while standard gradient
boosting algorithms can guarantee only local optimum. We also empirically show
that SGLB outperforms classic gradient boosting when applied to classification
tasks with 0-1 loss function, which is known to be multimodal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially Private False Discovery Rate Control. (arXiv:1807.04209v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Dwork_C/0/1/0/all/0/1">Cynthia Dwork</a>, <a href="http://arxiv.org/find/math/1/au:+Su_W/0/1/0/all/0/1">Weijie J. Su</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1807.04209">
                                    <div class="article-summary-box-inner">
                                        <span>Differential privacy provides a rigorous framework for privacy-preserving
data analysis. This paper proposes the first differentially private procedure
for controlling the false discovery rate (FDR) in multiple hypothesis testing.
Inspired by the Benjamini-Hochberg procedure (BHq), our approach is to first
repeatedly add noise to the logarithms of the $p$-values to ensure differential
privacy and to select an approximately smallest $p$-value serving as a
promising candidate at each iteration; the selected $p$-values are further
supplied to the BHq and our private procedure releases only the rejected ones.
Moreover, we develop a new technique that is based on a backward submartingale
for proving FDR control of a broad class of multiple testing procedures,
including our private procedure, and both the BHq step-up and step-down
procedures. As a novel aspect, the proof works for arbitrary dependence between
the true null and false null test statistics, while FDR control is maintained
up to a small multiplicative factor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v11 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1">Felix Leibfried</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutordoir_V/0/1/0/all/0/1">Vincent Dutordoir</a>, <a href="http://arxiv.org/find/cs/1/au:+John_S/0/1/0/all/0/1">ST John</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrande_N/0/1/0/all/0/1">Nicolas Durrande</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13962">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
interdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive calibration for binary classification. (arXiv:2107.01726v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vovk_V/0/1/0/all/0/1">Vladimir Vovk</a>, <a href="http://arxiv.org/find/cs/1/au:+Petej_I/0/1/0/all/0/1">Ivan Petej</a>, <a href="http://arxiv.org/find/cs/1/au:+Gammerman_A/0/1/0/all/0/1">Alex Gammerman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01726">
                                    <div class="article-summary-box-inner">
                                        <span>This note proposes a way of making probability forecasting rules less
sensitive to changes in data distribution, concentrating on the simple case of
binary classification. This is important in applications of machine learning,
where the quality of a trained predictor may drop significantly in the process
of its exploitation. Our techniques are based on recent work on conformal test
martingales and older work on prediction with expert advice, namely tracking
the best expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effects of boundary conditions in fully convolutional networks for learning spatio-temporal dynamics. (arXiv:2106.11160v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alguacil_A/0/1/0/all/0/1">Antonio Alguacil</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_W/0/1/0/all/0/1">Wagner Gon&#xe7;alves Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauerheim_M/0/1/0/all/0/1">Michael Bauerheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacob_M/0/1/0/all/0/1">Marc C. Jacob</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreau_S/0/1/0/all/0/1">St&#xe9;phane Moreau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11160">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate modeling of boundary conditions is crucial in computational physics.
The ever increasing use of neural networks as surrogates for physics-related
problems calls for an improved understanding of boundary condition treatment,
and its influence on the network accuracy. In this paper, several strategies to
impose boundary conditions (namely padding, improved spatial context, and
explicit encoding of physical boundaries) are investigated in the context of
fully convolutional networks applied to recurrent tasks. These strategies are
evaluated on two spatio-temporal evolving problems modeled by partial
differential equations: the 2D propagation of acoustic waves (hyperbolic PDE)
and the heat equation (parabolic PDE). Results reveal a high sensitivity of
both accuracy and stability on the boundary implementation in such recurrent
tasks. It is then demonstrated that the choice of the optimal padding strategy
is directly linked to the data semantics. Furthermore, the inclusion of
additional input spatial context or explicit physics-based rules allows a
better handling of boundaries in particular for large number of recurrences,
resulting in more robust and stable neural networks, while facilitating the
design and versatility of such networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Purification: How Adversarial Training Performs Robust Deep Learning. (arXiv:2005.10190v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1">Zeyuan Allen-Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10190">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the empirical success of using Adversarial Training to defend deep
learning models against adversarial perturbations, so far, it still remains
rather unclear what the principles are behind the existence of adversarial
perturbations, and what adversarial training does to the neural network to
remove them.

In this paper, we present a principle that we call Feature Purification,
where we show one of the causes of the existence of adversarial examples is the
accumulation of certain small dense mixtures in the hidden weights during the
training process of a neural network; and more importantly, one of the goals of
adversarial training is to remove such mixtures to purify hidden weights. We
present both experiments on the CIFAR-10 dataset to illustrate this principle,
and a theoretical result proving that for certain natural classification tasks,
training a two-layer neural network with ReLU activation using randomly
initialized gradient descent indeed satisfies this principle.

Technically, we give, to the best of our knowledge, the first result proving
that the following two can hold simultaneously for training a neural network
with ReLU activation. (1) Training over the original data is indeed non-robust
to small adversarial perturbations of some radius. (2) Adversarial training,
even with an empirical perturbation algorithm such as FGM, can in fact be
provably robust against ANY perturbations of the same radius. Finally, we also
prove a complexity lower bound, showing that low complexity models such as
linear classifiers, low-degree polynomials, or even the neural tangent kernel
for this network, CANNOT defend against perturbations of this same radius, no
matter what algorithms are used to train them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Sparse Coding using Hierarchical Riemannian Pursuit. (arXiv:2104.10314v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Ye Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Lau_V/0/1/0/all/0/1">Vincent Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1">Songfu Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10314">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse coding is a class of unsupervised methods for learning a sparse
representation of the input data in the form of a linear combination of a
dictionary and a sparse code. This learning framework has led to
state-of-the-art results in various image and video processing tasks. However,
classical methods learn the dictionary and the sparse code based on alternative
optimizations, usually without theoretical guarantees for either optimality or
convergence due to non-convexity of the problem. Recent works on sparse coding
with a complete dictionary provide strong theoretical guarantees thanks to the
development of the non-convex optimization. However, initial non-convex
approaches learn the dictionary in the sparse coding problem sequentially in an
atom-by-atom manner, which leads to a long execution time. More recent works
seek to directly learn the entire dictionary at once, which substantially
reduces the execution time. However, the associated recovery performance is
degraded with a finite number of data samples. In this paper, we propose an
efficient sparse coding scheme with a two-stage optimization. The proposed
scheme leverages the global and local Riemannian geometry of the two-stage
optimization problem and facilitates fast implementation for superb dictionary
recovery performance by a finite number of samples without atom-by-atom
calculation. We further prove that, with high probability, the proposed scheme
can exactly recover any atom in the target dictionary with a finite number of
samples if it is adopted to recover one atom of the dictionary. An application
on wireless sensor data compression is also proposed. Experiments on both
synthetic and real-world data verify the efficiency and effectiveness of the
proposed scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Scheduling Federated Deep Learning using Meta-Gradients for Inter-Hospital Learning. (arXiv:2107.01707v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+el_Bouri_R/0/1/0/all/0/1">Rasheed el-Bouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1">Tingting Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1">David A. Clifton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01707">
                                    <div class="article-summary-box-inner">
                                        <span>Given the abundance and ease of access of personal data today, individual
privacy has become of paramount importance, particularly in the healthcare
domain. In this work, we aim to utilise patient data extracted from multiple
hospital data centres to train a machine learning model without sacrificing
patient privacy. We develop a scheduling algorithm in conjunction with a
student-teacher algorithm that is deployed in a federated manner. This allows a
central model to learn from batches of data at each federal node. The teacher
acts between data centres to update the main task (student) algorithm using the
data that is stored in the various data centres. We show that the scheduler,
trained using meta-gradients, can effectively organise training and as a result
train a machine learning model on a diverse dataset without needing explicit
access to the patient data. We achieve state-of-the-art performance and show
how our method overcomes some of the problems faced in the federated learning
such as node poisoning. We further show how the scheduler can be used as a
mechanism for transfer learning, allowing different teachers to work together
in training a student for state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random Neural Networks in the Infinite Width Limit as Gaussian Processes. (arXiv:2107.01562v1 [math.PR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Hanin_B/0/1/0/all/0/1">Boris Hanin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01562">
                                    <div class="article-summary-box-inner">
                                        <span>This article gives a new proof that fully connected neural networks with
random weights and biases converge to Gaussian processes in the regime where
the input dimension, output dimension, and depth are kept fixed, while the
hidden layer widths tend to infinity. Unlike prior work, convergence is shown
assuming only moment conditions for the distribution of weights and for quite
general non-linearities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantile Encoder: Tackling High Cardinality Categorical Features in Regression Problems. (arXiv:2105.13783v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mougan_C/0/1/0/all/0/1">Carlos Mougan</a>, <a href="http://arxiv.org/find/cs/1/au:+Masip_D/0/1/0/all/0/1">David Masip</a>, <a href="http://arxiv.org/find/cs/1/au:+Nin_J/0/1/0/all/0/1">Jordi Nin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pujol_O/0/1/0/all/0/1">Oriol Pujol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13783">
                                    <div class="article-summary-box-inner">
                                        <span>Regression problems have been widely studied in machinelearning literature
resulting in a plethora of regression models and performance measures. However,
there are few techniques specially dedicated to solve the problem of how to
incorporate categorical features to regression problems. Usually, categorical
feature encoders are general enough to cover both classification and regression
problems. This lack of specificity results in underperforming regression
models. In this paper,we provide an in-depth analysis of how to tackle high
cardinality categor-ical features with the quantile. Our proposal outperforms
state-of-the-encoders, including the traditional statistical mean target
encoder, when considering the Mean Absolute Error, especially in the presence
of long-tailed or skewed distributions. Besides, to deal with possible
overfitting when there are categories with small support, our encoder benefits
from additive smoothing. Finally, we describe how to expand the encoded values
by creating a set of features with different quantiles. This expanded encoder
provides a more informative output about the categorical feature in question,
further boosting the performance of the regression model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subspace Clustering Based Analysis of Neural Networks. (arXiv:2107.01296v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saini_U/0/1/0/all/0/1">Uday Singh Saini</a>, <a href="http://arxiv.org/find/cs/1/au:+Devineni_P/0/1/0/all/0/1">Pravallika Devineni</a>, <a href="http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1">Evangelos E. Papalexakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01296">
                                    <div class="article-summary-box-inner">
                                        <span>Tools to analyze the latent space of deep neural networks provide a step
towards better understanding them. In this work, we motivate sparse subspace
clustering (SSC) with an aim to learn affinity graphs from the latent structure
of a given neural network layer trained over a set of inputs. We then use tools
from Community Detection to quantify structures present in the input. These
experiments reveal that as we go deeper in a network, inputs tend to have an
increasing affinity to other inputs of the same class. Subsequently, we utilise
matrix similarity measures to perform layer-wise comparisons between affinity
graphs. In doing so we first demonstrate that when comparing a given layer
currently under training to its final state, the shallower the layer of the
network, the quicker it is to converge than the deeper layers. When performing
a pairwise analysis of the entire network architecture, we observe that, as the
network increases in size, it reorganises from a state where each layer is
moderately similar to its neighbours, to a state where layers within a block
have high similarity than to layers in other blocks. Finally, we analyze the
learned affinity graphs of the final convolutional layer of the network and
demonstrate how an input&#x27;s local neighbourhood affects its classification by
the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knodle: Modular Weakly Supervised Learning with PyTorch. (arXiv:2104.11557v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sedova_A/0/1/0/all/0/1">Anastasiia Sedova</a>, <a href="http://arxiv.org/find/cs/1/au:+Stephan_A/0/1/0/all/0/1">Andreas Stephan</a>, <a href="http://arxiv.org/find/cs/1/au:+Speranskaya_M/0/1/0/all/0/1">Marina Speranskaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11557">
                                    <div class="article-summary-box-inner">
                                        <span>Strategies for improving the training and prediction quality of weakly
supervised machine learning models vary in how much they are tailored to a
specific task or integrated with a specific model architecture. In this work,
we introduce Knodle, a software framework that treats weak data annotations,
deep learning models, and methods for improving weakly supervised training as
separate, modular components. This modularization gives the training process
access to fine-grained information such as data set characteristics, matches of
heuristic rules, or elements of the deep learning model ultimately used for
prediction. Hence, our framework can encompass a wide range of training methods
for improving weak supervision, ranging from methods that only look at
correlations of rules and output classes (independently of the machine learning
model trained with the resulting labels), to those that harness the interplay
of neural networks and weakly labeled data. We illustrate the benchmarking
potential of the framework with a performance comparison of several reference
implementations on a selection of datasets that are already available in
Knodle.

The framework is published as an open-source Python package knodle and
available at https://github.com/knodle/knodle.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiple-criteria Based Active Learning with Fixed-size Determinantal Point Processes. (arXiv:2107.01622v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1">Xueying Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Antoni B. Chan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01622">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning aims to achieve greater accuracy with less training data by
selecting the most useful data samples from which it learns. Single-criterion
based methods (i.e., informativeness and representativeness based methods) are
simple and efficient; however, they lack adaptability to different real-world
scenarios. In this paper, we introduce a multiple-criteria based active
learning algorithm, which incorporates three complementary criteria, i.e.,
informativeness, representativeness and diversity, to make appropriate
selections in the active learning rounds under different data types. We
consider the selection process as a Determinantal Point Process, which good
balance among these criteria. We refine the query selection strategy by both
selecting the hardest unlabeled data sample and biasing towards the classifiers
that are more suitable for the current data distribution. In addition, we also
consider the dependencies and relationships between these data points in data
selection by means of centroidbased clustering approaches. Through evaluations
on synthetic and real-world datasets, we show that our method performs
significantly better and is more stable than other multiple-criteria based AL
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Dimensional State and Action Representation Learning with MDP Homomorphism Metrics. (arXiv:2107.01677v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Botteghi_N/0/1/0/all/0/1">Nicol&#xf2; Botteghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Poel_M/0/1/0/all/0/1">Mannes Poel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sirmacek_B/0/1/0/all/0/1">Beril Sirmacek</a>, <a href="http://arxiv.org/find/cs/1/au:+Brune_C/0/1/0/all/0/1">Christoph Brune</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01677">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Reinforcement Learning has shown its ability in solving complicated
problems directly from high-dimensional observations. However, in end-to-end
settings, Reinforcement Learning algorithms are not sample-efficient and
requires long training times and quantities of data. In this work, we proposed
a framework for sample-efficient Reinforcement Learning that take advantage of
state and action representations to transform a high-dimensional problem into a
low-dimensional one. Moreover, we seek to find the optimal policy mapping
latent states to latent actions. Because now the policy is learned on abstract
representations, we enforce, using auxiliary loss functions, the lifting of
such policy to the original problem domain. Results show that the novel
framework can efficiently learn low-dimensional and interpretable state and
action representations and the optimal latent policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Explainable AI System for the Diagnosis of High Dimensional Biomedical Data. (arXiv:2107.01820v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ultsch_A/0/1/0/all/0/1">Alfred Ultsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_J/0/1/0/all/0/1">J&#xf6;rg Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohnert_M/0/1/0/all/0/1">Maximilian R&#xf6;hnert</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonin_M/0/1/0/all/0/1">Malte Von Bonin</a>, <a href="http://arxiv.org/find/cs/1/au:+Oelschlagel_U/0/1/0/all/0/1">Uta Oelschl&#xe4;gel</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_C/0/1/0/all/0/1">Cornelia Brendel</a>, <a href="http://arxiv.org/find/cs/1/au:+Thrun_M/0/1/0/all/0/1">Michael C. Thrun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01820">
                                    <div class="article-summary-box-inner">
                                        <span>Typical state of the art flow cytometry data samples consists of measures of
more than 100.000 cells in 10 or more features. AI systems are able to diagnose
such data with almost the same accuracy as human experts. However, there is one
central challenge in such systems: their decisions have far-reaching
consequences for the health and life of people, and therefore, the decisions of
AI systems need to be understandable and justifiable by humans. In this work,
we present a novel explainable AI method, called ALPODS, which is able to
classify (diagnose) cases based on clusters, i.e., subpopulations, in the
high-dimensional data. ALPODS is able to explain its decisions in a form that
is understandable for human experts. For the identified subpopulations, fuzzy
reasoning rules expressed in the typical language of domain experts are
generated. A visualization method based on these rules allows human experts to
understand the reasoning used by the AI system. A comparison to a selection of
state of the art explainable AI systems shows that ALPODS operates efficiently
on known benchmark data and also on everyday routine case data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Q-SpiNN: A Framework for Quantizing Spiking Neural Networks. (arXiv:2107.01807v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Putra_R/0/1/0/all/0/1">Rachmad Vidya Wicaksana Putra</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01807">
                                    <div class="article-summary-box-inner">
                                        <span>A prominent technique for reducing the memory footprint of Spiking Neural
Networks (SNNs) without decreasing the accuracy significantly is quantization.
However, the state-of-the-art only focus on employing the weight quantization
directly from a specific quantization scheme, i.e., either the post-training
quantization (PTQ) or the in-training quantization (ITQ), and do not consider
(1) quantizing other SNN parameters (e.g., neuron membrane potential), (2)
exploring different combinations of quantization approaches (i.e., quantization
schemes, precision levels, and rounding schemes), and (3) selecting the SNN
model with a good memory-accuracy trade-off at the end. Therefore, the memory
saving offered by these state-of-the-art to meet the targeted accuracy is
limited, thereby hindering processing SNNs on the resource-constrained systems
(e.g., the IoT-Edge devices). Towards this, we propose Q-SpiNN, a novel
quantization framework for memory-efficient SNNs. The key mechanisms of the
Q-SpiNN are: (1) employing quantization for different SNN parameters based on
their significance to the accuracy, (2) exploring different combinations of
quantization schemes, precision levels, and rounding schemes to find efficient
SNN model candidates, and (3) developing an algorithm that quantifies the
benefit of the memory-accuracy trade-off obtained by the candidates, and
selects the Pareto-optimal one. The experimental results show that, for the
unsupervised network, the Q-SpiNN reduces the memory footprint by ca. 4x, while
maintaining the accuracy within 1% from the baseline on the MNIST dataset. For
the supervised network, the Q-SpiNN reduces the memory by ca. 2x, while keeping
the accuracy within 2% from the baseline on the DVS-Gesture dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Theoretical Analysis of Fine-tuning with Linear Teachers. (arXiv:2107.01641v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shachaf_G/0/1/0/all/0/1">Gal Shachaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Brutzkus_A/0/1/0/all/0/1">Alon Brutzkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1">Amir Globerson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01641">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-tuning is a common practice in deep learning, achieving excellent
generalization results on downstream tasks using relatively little training
data. Although widely used in practice, it is lacking strong theoretical
understanding. We analyze the sample complexity of this scheme for regression
with linear teachers in several architectures. Intuitively, the success of
fine-tuning depends on the similarity between the source tasks and the target
task, however measuring it is non trivial. We show that a relevant measure
considers the relation between the source task, the target task and the
covariance structure of the target data. In the setting of linear regression,
we show that under realistic settings a substantial sample complexity reduction
is plausible when the above measure is low. For deep linear regression, we
present a novel result regarding the inductive bias of gradient-based training
when the network is initialized with pretrained weights. Using this result we
show that the similarity measure for this setting is also affected by the depth
of the network. We further present results on shallow ReLU models, and analyze
the dependence of sample complexity there on source and target tasks. We
empirically demonstrate our results for both synthetic and realistic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of the Delta Method and the Bootstrap in Deep Learning Classification. (arXiv:2107.01606v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nilsen_G/0/1/0/all/0/1">Geir K. Nilsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Munthe_Kaas_A/0/1/0/all/0/1">Antonella Z. Munthe-Kaas</a>, <a href="http://arxiv.org/find/cs/1/au:+Skaug_H/0/1/0/all/0/1">Hans J. Skaug</a>, <a href="http://arxiv.org/find/cs/1/au:+Brun_M/0/1/0/all/0/1">Morten Brun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01606">
                                    <div class="article-summary-box-inner">
                                        <span>We validate the recently introduced deep learning classification adapted
Delta method by a comparison with the classical Bootstrap. We show that there
is a strong linear relationship between the quantified predictive epistemic
uncertainty levels obtained from the two methods when applied on two
LeNet-based neural network classifiers using the MNIST and CIFAR-10 datasets.
Furthermore, we demonstrate that the Delta method offers a five times
computation time reduction compared to the Bootstrap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning. (arXiv:2012.09816v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1">Zeyuan Allen-Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09816">
                                    <div class="article-summary-box-inner">
                                        <span>We formally study how ensemble of deep learning models can improve test
accuracy, and how the superior performance of ensemble can be distilled into a
single model using knowledge distillation. We consider the challenging case
where the ensemble is simply an average of the outputs of a few independently
trained neural networks with the SAME architecture, trained using the SAME
algorithm on the SAME data set, and they only differ by the random seeds used
in the initialization.

We empirically show that ensemble/knowledge distillation in deep learning
works very differently from traditional learning theory, especially differently
from ensemble of random feature mappings or the neural-tangent-kernel feature
mappings, and is potentially out of the scope of existing theorems. Thus, to
properly understand ensemble and knowledge distillation in deep learning, we
develop a theory showing that when data has a structure we refer to as
&quot;multi-view&quot;, then ensemble of independently trained neural networks can
provably improve test accuracy, and such superior test accuracy can also be
provably distilled into a single model by training a single model to match the
output of the ensemble instead of the true label. Our result sheds light on how
ensemble works in deep learning in a way that is completely different from
traditional theorems, and how the &quot;dark knowledge&quot; is hidden in the outputs of
the ensemble -- that can be used in knowledge distillation -- comparing to the
true data labels. In the end, we prove that self-distillation can also be
viewed as implicitly combining ensemble and knowledge distillation to improve
test accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially Private Sliced Wasserstein Distance. (arXiv:2107.01848v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1">Alain Rakotomamonjy</a> (DocApp - LITIS), <a href="http://arxiv.org/find/cs/1/au:+Ralaivola_L/0/1/0/all/0/1">Liva Ralaivola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01848">
                                    <div class="article-summary-box-inner">
                                        <span>Developing machine learning methods that are privacy preserving is today a
central topic of research, with huge practical impacts. Among the numerous ways
to address privacy-preserving learning, we here take the perspective of
computing the divergences between distributions under the Differential Privacy
(DP) framework -- being able to compute divergences between distributions is
pivotal for many machine learning problems, such as learning generative models
or domain adaptation problems. Instead of resorting to the popular
gradient-based sanitization method for DP, we tackle the problem at its roots
by focusing on the Sliced Wasserstein Distance and seamlessly making it
differentially private. Our main contribution is as follows: we analyze the
property of adding a Gaussian perturbation to the intrinsic randomized
mechanism of the Sliced Wasserstein Distance, and we establish the
sensitivityof the resulting differentially private mechanism. One of our
important findings is that this DP mechanism transforms the Sliced Wasserstein
distance into another distance, that we call the Smoothed Sliced Wasserstein
Distance. This new differentially private distribution distance can be plugged
into generative models and domain adaptation algorithms in a transparent way,
and we empirically show that it yields highly competitive performance compared
with gradient-based DP approaches from the literature, with almost no loss in
accuracy for the domain adaptation problems that we consider.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Implicit Regularization of ReLU Neural Networks Characterizes the Learned Function -- Part I: the 1-D Case of Two Layers with Random First Layer. (arXiv:1911.02903v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heiss_J/0/1/0/all/0/1">Jakob Heiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Teichmann_J/0/1/0/all/0/1">Josef Teichmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Wutte_H/0/1/0/all/0/1">Hanna Wutte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.02903">
                                    <div class="article-summary-box-inner">
                                        <span>Today, various forms of neural networks are trained to perform approximation
tasks in many fields. However, the estimates obtained are not fully understood
on function space. Empirical results suggest that typical training algorithms
favor regularized solutions. These observations motivate us to analyze
properties of the neural networks found by gradient descent initialized close
to zero, that is frequently employed to perform the training task. As a
starting point, we consider one dimensional (shallow) ReLU neural networks in
which weights are chosen randomly and only the terminal layer is trained.
First, we rigorously show that for such networks ridge regularized regression
corresponds in function space to regularizing the estimate&#x27;s second derivative
for fairly general loss functionals. For least squares regression, we show that
the trained network converges to the smooth spline interpolation of the
training data as the number of hidden nodes tends to infinity. Moreover, we
derive a correspondence between the early stopped gradient descent and the
smoothing spline regression. Our analysis might give valuable insight on the
properties of the solutions obtained using gradient descent methods in general
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Transferability of Targeted Adversarial Examples via Hierarchical Generative Networks. (arXiv:2107.01809v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01809">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer-based adversarial attacks can effectively evaluate model robustness
in the black-box setting. Though several methods have demonstrated impressive
transferability of untargeted adversarial examples, targeted adversarial
transferability is still challenging. The existing methods either have low
targeted transferability or sacrifice computational efficiency. In this paper,
we develop a simple yet practical framework to efficiently craft targeted
transfer-based adversarial examples. Specifically, we propose a conditional
generative attacking model, which can generate the adversarial examples
targeted at different classes by simply altering the class embedding and share
a single backbone. Extensive experiments demonstrate that our method improves
the success rates of targeted black-box attacks by a significant margin over
the existing methods -- it reaches an average success rate of 29.6\% against
six diverse models based only on one substitute white-box model in the standard
testing of NeurIPS 2017 competition, which outperforms the state-of-the-art
gradient-based attack methods (with an average success rate of $&lt;$2\%) by a
large margin. Moreover, the proposed method is also more efficient beyond an
order of magnitude than gradient-based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Decision Rules for Binary Classification. (arXiv:2107.01325v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lawless_C/0/1/0/all/0/1">Connor Lawless</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunluk_O/0/1/0/all/0/1">Oktay Gunluk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01325">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, machine learning has begun automating decision making in
fields as varied as college admissions, credit lending, and criminal
sentencing. The socially sensitive nature of some of these applications
together with increasing regulatory constraints has necessitated the need for
algorithms that are both fair and interpretable. In this paper we consider the
problem of building Boolean rule sets in disjunctive normal form (DNF), an
interpretable model for binary classification, subject to fairness constraints.
We formulate the problem as an integer program that maximizes classification
accuracy with explicit constraints on two different measures of classification
parity: equality of opportunity and equalized odds. Column generation
framework, with a novel formulation, is used to efficiently search over
exponentially many possible rules. When combined with faster heuristics, our
method can deal with large data-sets. Compared to other fair and interpretable
classifiers, our method is able to find rule sets that meet stricter notions of
fairness with a modest trade-off in accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KAISA: An Adaptive Second-order Optimizer Framework for Deep Neural Networks. (arXiv:2107.01739v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pauloski_J/0/1/0/all/0/1">J. Gregory Pauloski</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_S/0/1/0/all/0/1">Shivaram Venkataraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chard_K/0/1/0/all/0/1">Kyle Chard</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1">Ian Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01739">
                                    <div class="article-summary-box-inner">
                                        <span>Kronecker-factored Approximate Curvature (K-FAC) has recently been shown to
converge faster in deep neural network (DNN) training than stochastic gradient
descent (SGD); however, K-FAC&#x27;s larger memory footprint hinders its
applicability to large models. We present KAISA, a K-FAC-enabled, Adaptable,
Improved, and ScAlable second-order optimizer framework that adapts the memory
footprint, communication, and computation given specific models and hardware to
achieve maximized performance and enhanced scalability. We quantify the
tradeoffs between memory and communication cost and evaluate KAISA on large
models, including ResNet-50, Mask R-CNN, U-Net, and BERT, on up to 128 NVIDIA
A100 GPUs. Compared to the original optimizers, KAISA converges 18.1-36.3%
faster across applications with the same global batch size. Under a fixed
memory budget, KAISA converges 32.5% and 41.6% faster in ResNet-50 and
BERT-Large, respectively. KAISA can balance memory and communication to achieve
scaling efficiency equal to or better than the baseline optimizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Split-and-Bridge: Adaptable Class Incremental Learning within a Single Neural Network. (arXiv:2107.01349v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jong-Yeong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dong-Wan Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01349">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning has been a major problem in the deep learning community,
where the main challenge is how to effectively learn a series of newly arriving
tasks without forgetting the knowledge of previous tasks. Initiated by Learning
without Forgetting (LwF), many of the existing works report that knowledge
distillation is effective to preserve the previous knowledge, and hence they
commonly use a soft label for the old task, namely a knowledge distillation
(KD) loss, together with a class label for the new task, namely a cross entropy
(CE) loss, to form a composite loss for a single neural network. However, this
approach suffers from learning the knowledge by a CE loss as a KD loss often
more strongly influences the objective function when they are in a competitive
situation within a single network. This could be a critical problem
particularly in a class incremental scenario, where the knowledge across tasks
as well as within the new task, both of which can only be acquired by a CE
loss, is essentially learned due to the existence of a unified classifier. In
this paper, we propose a novel continual learning method, called
Split-and-Bridge, which can successfully address the above problem by partially
splitting a neural network into two partitions for training the new task
separated from the old task and re-connecting them for learning the knowledge
across tasks. In our thorough experimental analysis, our Split-and-Bridge
method outperforms the state-of-the-art competitors in KD-based continual
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Guided Deep Learning for Dynamical Systems: A survey. (arXiv:2107.01272v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01272">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling complex physical dynamics is a fundamental task in science and
engineering. Traditional physics-based models are interpretable but rely on
rigid assumptions. And the direct numerical approximation is usually
computationally intensive, requiring significant computational resources and
expertise. While deep learning (DL) provides novel alternatives for efficiently
recognizing complex patterns and emulating nonlinear dynamics, it does not
necessarily obey the governing laws of physical systems, nor do they generalize
well across different systems. Thus, the study of physics-guided DL emerged and
has gained great progress. It aims to take the best from both physics-based
modeling and state-of-the-art DL models to better solve scientific problems. In
this paper, we provide a structured overview of existing methodologies of
integrating prior physical knowledge or physics-based modeling into DL and
discuss the emerging opportunities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Comparative Fairness for Human-Auditing and Its Relation to Traditional Fairness Notions. (arXiv:2107.01277v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Telukunta_M/0/1/0/all/0/1">Mukund Telukunta</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadendla_V/0/1/0/all/0/1">Venkata Sriram Siddhardh Nadendla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01277">
                                    <div class="article-summary-box-inner">
                                        <span>Bias evaluation in machine-learning based services (MLS) based on traditional
algorithmic fairness notions that rely on comparative principles is practically
difficult, making it necessary to rely on human auditor feedback. However, in
spite of taking rigorous training on various comparative fairness notions,
human auditors are known to disagree on various aspects of fairness notions in
practice, making it difficult to collect reliable feedback. This paper offers a
paradigm shift to the domain of algorithmic fairness via proposing a new
fairness notion based on the principle of non-comparative justice. In contrary
to traditional fairness notions where the outcomes of two individuals/groups
are compared, our proposed notion compares the MLS&#x27; outcome with a desired
outcome for each input. This desired outcome naturally describes a human
auditor&#x27;s expectation, and can be easily used to evaluate MLS on crowd-auditing
platforms. We show that any MLS can be deemed fair from the perspective of
comparative fairness (be it in terms of individual fairness, statistical
parity, equal opportunity or calibration) if it is non-comparatively fair with
respect to a fair auditor. We also show that the converse holds true in the
context of individual fairness. Given that such an evaluation relies on the
trustworthiness of the auditor, we also present an approach to identify fair
and reliable auditors by estimating their biases with respect to a given set of
sensitive attributes, as well as quantify the uncertainty in the estimation of
biases within a given MLS. Furthermore, all of the above results are also
validated on COMPAS, German credit and Adult Census Income datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cluster Representatives Selection in Non-Metric Spaces for Nearest Prototype Classification. (arXiv:2107.01345v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hlavac_J/0/1/0/all/0/1">Jaroslav Hlav&#xe1;&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kopp_M/0/1/0/all/0/1">Martin Kopp</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohout_J/0/1/0/all/0/1">Jan Kohout</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01345">
                                    <div class="article-summary-box-inner">
                                        <span>The nearest prototype classification is a less computationally intensive
replacement for the $k$-NN method, especially when large datasets are
considered. In metric spaces, centroids are often used as prototypes to
represent whole clusters. The selection of cluster prototypes in non-metric
spaces is more challenging as the idea of computing centroids is not directly
applicable.

In this paper, we present CRS, a novel method for selecting a small yet
representative subset of objects as a cluster prototype. Memory and
computationally efficient selection of representatives is enabled by leveraging
the similarity graph representation of each cluster created by the NN-Descent
algorithm. CRS can be used in an arbitrary metric or non-metric space because
of the graph-based approach, which requires only a pairwise similarity measure.
As we demonstrate in the experimental evaluation, our method outperforms the
state of the art techniques on multiple datasets from different domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Re-Evaluating GermEval17 Using German Pre-Trained Language Models. (arXiv:2102.12330v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Assenmacher_M/0/1/0/all/0/1">M. A&#xdf;enmacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Corvonato_A/0/1/0/all/0/1">A. Corvonato</a>, <a href="http://arxiv.org/find/cs/1/au:+Heumann_C/0/1/0/all/0/1">C. Heumann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12330">
                                    <div class="article-summary-box-inner">
                                        <span>The lack of a commonly used benchmark data set (collection) such as
(Super-)GLUE (Wang et al., 2018, 2019) for the evaluation of non-English
pre-trained language models is a severe shortcoming of current English-centric
NLP-research. It concentrates a large part of the research on English,
neglecting the uncertainty when transferring conclusions found for the English
language to other languages. We evaluate the performance of the German and
multilingual BERT-based models currently available via the huggingface
transformers library on the four tasks of the GermEval17 workshop. We compare
them to pre-BERT architectures (Wojatzki et al., 2017; Schmitt et al., 2018;
Attia et al., 2018) as well as to an ELMo-based architecture (Biesialska et
al., 2020) and a BERT-based approach (Guhr et al., 2020). The observed
improvements are put in relation to those for similar tasks and similar models
(pre-BERT vs. BERT-based) for the English language in order to draw tentative
conclusions about whether the observed improvements are transferable to German
or potentially other related languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Reachability Knowledge into a Multi-Spatial Graph Convolution Based Seq2Seq Model for Traffic Forecasting. (arXiv:2107.01528v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jiexia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Furong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Juanjuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1">Kejiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chengzhong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01528">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate traffic state prediction is the foundation of transportation control
and guidance. It is very challenging due to the complex spatiotemporal
dependencies in traffic data. Existing works cannot perform well for multi-step
traffic prediction that involves long future time period. The spatiotemporal
information dilution becomes serve when the time gap between input step and
predicted step is large, especially when traffic data is not sufficient or
noisy. To address this issue, we propose a multi-spatial graph convolution
based Seq2Seq model. Our main novelties are three aspects: (1) We enrich the
spatiotemporal information of model inputs by fusing multi-view features (time,
location and traffic states) (2) We build multiple kinds of spatial
correlations based on both prior knowledge and data-driven knowledge to improve
model performance especially in insufficient or noisy data cases. (3) A
spatiotemporal attention mechanism based on reachability knowledge is novelly
designed to produce high-level features fed into decoder of Seq2Seq directly to
ease information dilution. Our model is evaluated on two real world traffic
datasets and achieves better performance than other competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Designing Machine Learning Pipeline Toolkit for AutoML Surrogate Modeling Optimization. (arXiv:2107.01253v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palmes_P/0/1/0/all/0/1">Paulito P. Palmes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kishimoto_A/0/1/0/all/0/1">Akihiro Kishimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinescu_R/0/1/0/all/0/1">Radu Marinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1">Parikshit Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Daly_E/0/1/0/all/0/1">Elizabeth Daly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01253">
                                    <div class="article-summary-box-inner">
                                        <span>The pipeline optimization problem in machine learning requires simultaneous
optimization of pipeline structures and parameter adaptation of their elements.
Having an elegant way to express these structures can help lessen the
complexity in the management and analysis of their performances together with
the different choices of optimization strategies. With these issues in mind, we
created the AMLP toolkit which facilitates the creation and evaluation of
complex machine learning pipeline structures using simple expressions. We use
AMLP to find optimal pipeline signatures, datamine them, and use these
datamined features to speed-up learning and prediction. We formulated a
two-stage pipeline optimization with surrogate modeling in AMLP which
outperforms other AutoML approaches with a 4-hour time budget in less than 5
minutes of AMLP computation time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Theory for Imbalanced Binary Classification. (arXiv:2107.01777v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Singh_S/0/1/0/all/0/1">Shashank Singh</a>, <a href="http://arxiv.org/find/math/1/au:+Khim_J/0/1/0/all/0/1">Justin Khim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01777">
                                    <div class="article-summary-box-inner">
                                        <span>Within the vast body of statistical theory developed for binary
classification, few meaningful results exist for imbalanced classification, in
which data are dominated by samples from one of the two classes. Existing
theory faces at least two main challenges. First, meaningful results must
consider more complex performance measures than classification accuracy. To
address this, we characterize a novel generalization of the Bayes-optimal
classifier to any performance metric computed from the confusion matrix, and we
use this to show how relative performance guarantees can be obtained in terms
of the error of estimating the class probability function under uniform
($\mathcal{L}_\infty$) loss. Second, as we show, optimal classification
performance depends on certain properties of class imbalance that have not
previously been formalized. Specifically, we propose a novel sub-type of class
imbalance, which we call Uniform Class Imbalance. We analyze how Uniform Class
Imbalance influences optimal classifier performance and show that it
necessitates different classifier behavior than other types of class imbalance.
We further illustrate these two contributions in the case of $k$-nearest
neighbor classification, for which we develop novel guarantees. Together, these
results provide some of the first meaningful finite-sample statistical theory
for imbalanced binary classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Greedy Rank Learning in Autoencoders via Overparameterized Linear Networks. (arXiv:2107.01301v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Shih-Yu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Thilak_V/0/1/0/all/0/1">Vimal Thilak</a>, <a href="http://arxiv.org/find/cs/1/au:+Littwin_E/0/1/0/all/0/1">Etai Littwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Saremi_O/0/1/0/all/0/1">Omid Saremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1">Joshua M. Susskind</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01301">
                                    <div class="article-summary-box-inner">
                                        <span>Deep linear networks trained with gradient descent yield low rank solutions,
as is typically studied in matrix factorization. In this paper, we take a step
further and analyze implicit rank regularization in autoencoders. We show
greedy learning of low-rank latent codes induced by a linear sub-network at the
autoencoder bottleneck. We further propose orthogonal initialization and
principled learning rate adjustment to mitigate sensitivity of training
dynamics to spectral prior and linear depth. With linear autoencoders on
synthetic data, our method converges stably to ground-truth latent code rank.
With nonlinear autoencoders, our method converges to latent ranks optimal for
downstream classification and image sampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Block-Term Tensor Decomposition Model Selection and Computation: The Bayesian Way. (arXiv:2101.02931v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Giampouras_P/0/1/0/all/0/1">Paris V. Giampouras</a>, <a href="http://arxiv.org/find/stat/1/au:+Rontogiannis_A/0/1/0/all/0/1">Athanasios A. Rontogiannis</a>, <a href="http://arxiv.org/find/stat/1/au:+Kofidis_E/0/1/0/all/0/1">Eleftherios Kofidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02931">
                                    <div class="article-summary-box-inner">
                                        <span>The so-called block-term decomposition (BTD) tensor model, especially in its
rank-$(L_r,L_r,1)$ version, has been recently receiving increasing attention
due to its enhanced ability of representing systems and signals that are
composed of \emph{blocks} of rank higher than one, a scenario encountered in
numerous and diverse applications. Uniqueness conditions and fitting methods
have thus been thoroughly studied. Nevertheless, the challenging problem of
estimating the BTD model structure, namely the number of block terms, $R$, and
their individual ranks, $L_r$, has only recently started to attract significant
attention, mainly through regularization-based approaches which entail the need
to tune the regularization parameter(s). In this work, we build on ideas of
sparse Bayesian learning (SBL) and put forward a fully automated Bayesian
approach. Through a suitably crafted multi-level \emph{hierarchical}
probabilistic model, which gives rise to heavy-tailed prior distributions for
the BTD factors, structured sparsity is \emph{jointly} imposed. Ranks are then
estimated from the numbers of blocks ($R$) and columns ($L_r$) of
non-negligible energy. Approximate posterior inference is implemented, within
the variational inference framework. The resulting iterative algorithm
completely avoids hyperparameter tuning, which is a significant defect of
regularization-based methods. Alternative probabilistic models are also
explored and the connections with their regularization-based counterparts are
brought to light with the aid of the associated maximum a-posteriori (MAP)
estimators. We report simulation results with both synthetic and real-word
data, which demonstrate the merits of the proposed method in terms of both rank
estimation and model fitting as compared to state-of-the-art relevant methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-Driven Learning of Feedforward Neural Networks with Different Activation Functions. (arXiv:2107.01702v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Grzegorz Dudek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01702">
                                    <div class="article-summary-box-inner">
                                        <span>This work contributes to the development of a new data-driven method (D-DM)
of feedforward neural networks (FNNs) learning. This method was proposed
recently as a way of improving randomized learning of FNNs by adjusting the
network parameters to the target function fluctuations. The method employs
logistic sigmoid activation functions for hidden nodes. In this study, we
introduce other activation functions, such as bipolar sigmoid, sine function,
saturating linear functions, reLU, and softplus. We derive formulas for their
parameters, i.e. weights and biases. In the simulation study, we evaluate the
performance of FNN data-driven learning with different activation functions.
The results indicate that the sigmoid activation functions perform much better
than others in the approximation of complex, fluctuated target functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pulmonary Vessel Segmentation based on Orthogonal Fused U-Net++ of Chest CT Images. (arXiv:2107.01502v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xinglong Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_N/0/1/0/all/0/1">Ning Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01502">
                                    <div class="article-summary-box-inner">
                                        <span>Pulmonary vessel segmentation is important for clinical diagnosis of
pulmonary diseases, while is also challenging due to the complicated structure.
In this work, we present an effective framework and refinement process of
pulmonary vessel segmentation from chest computed tomographic (CT) images. The
key to our approach is a 2.5D segmentation network applied from three
orthogonal axes, which presents a robust and fully automated pulmonary vessel
segmentation result with lower network complexity and memory usage compared to
3D networks. The slice radius is introduced to convolve the adjacent
information of the center slice and the multi-planar fusion optimizes the
presentation of intra- and inter- slice features. Besides, the tree-like
structure of the pulmonary vessel is extracted in the post-processing process,
which is used for segmentation refining and pruning. In the evaluation
experiments, three fusion methods are tested and the most promising one is
compared with the state-of-the-art 2D and 3D structures on 300 cases of lung
images randomly selected from LIDC dataset. Our method outperforms other
network structures by a large margin and achieves by far the highest average
DICE score of 0.9272 and precision of 0.9310, as per our knowledge from the
pulmonary vessel segmentation models available in the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning ODEs via Diffeomorphisms for Fast and Robust Integration. (arXiv:2107.01650v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhi_W/0/1/0/all/0/1">Weiming Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_T/0/1/0/all/0/1">Tin Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ott_L/0/1/0/all/0/1">Lionel Ott</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonilla_E/0/1/0/all/0/1">Edwin V. Bonilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1">Fabio Ramos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01650">
                                    <div class="article-summary-box-inner">
                                        <span>Advances in differentiable numerical integrators have enabled the use of
gradient descent techniques to learn ordinary differential equations (ODEs). In
the context of machine learning, differentiable solvers are central for Neural
ODEs (NODEs), a class of deep learning models with continuous depth, rather
than discrete layers. However, these integrators can be unsatisfactorily slow
and inaccurate when learning systems of ODEs from long sequences, or when
solutions of the system vary at widely different timescales in each dimension.
In this paper we propose an alternative approach to learning ODEs from data: we
represent the underlying ODE as a vector field that is related to another base
vector field by a differentiable bijection, modelled by an invertible neural
network. By restricting the base ODE to be amenable to integration, we can
drastically speed up and improve the robustness of integration. We demonstrate
the efficacy of our method in training and evaluating continuous neural
networks models, as well as in learning benchmark ODE systems. We observe
improvements of up to two orders of magnitude when integrating learned ODEs
with GPUs computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Concept Drift With Neural Network Model Uncertainty. (arXiv:2107.01873v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baier_L/0/1/0/all/0/1">Lucas Baier</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlor_T/0/1/0/all/0/1">Tim Schl&#xf6;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoffer_J/0/1/0/all/0/1">Jakob Sch&#xf6;ffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhl_N/0/1/0/all/0/1">Niklas K&#xfc;hl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01873">
                                    <div class="article-summary-box-inner">
                                        <span>Deployed machine learning models are confronted with the problem of changing
data over time, a phenomenon also called concept drift. While existing
approaches of concept drift detection already show convincing results, they
require true labels as a prerequisite for successful drift detection.
Especially in many real-world application scenarios-like the ones covered in
this work-true labels are scarce, and their acquisition is expensive.
Therefore, we introduce a new algorithm for drift detection, Uncertainty Drift
Detection (UDD), which is able to detect drifts without access to true labels.
Our approach is based on the uncertainty estimates provided by a deep neural
network in combination with Monte Carlo Dropout. Structural changes over time
are detected by applying the ADWIN technique on the uncertainty estimates, and
detected drifts trigger a retraining of the prediction model. In contrast to
input data-based drift detection, our approach considers the effects of the
current input data on the properties of the prediction model rather than
detecting change on the input data only (which can lead to unnecessary
retrainings). We show that UDD outperforms other state-of-the-art strategies on
two synthetic as well as ten real-world data sets for both regression and
classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Langevin Monte Carlo: random coordinate descent and variance reduction. (arXiv:2007.14209v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ding_Z/0/1/0/all/0/1">Zhiyan Ding</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_Q/0/1/0/all/0/1">Qin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14209">
                                    <div class="article-summary-box-inner">
                                        <span>Sampling from a log-concave distribution function on $\mathbb{R}^d$ (with
$d\gg 1$) is a popular problem that has wide applications. In this paper we
study the application of random coordinate descent method (RCD) on the Langevin
Monte Carlo (LMC) sampling method, and we find two sides of the theory:

1. The direct application of RCD on LMC does reduce the number of finite
differencing approximations per iteration, but it induces a large variance
error term. More iterations are then needed, and ultimately the method gains no
computational advantage;

2. When variance reduction techniques (such as SAGA and SVRG) are
incorporated in RCD-LMC, the variance error term is reduced. The new methods,
compared to the vanilla LMC, reduce the total computational cost by $d$ folds,
and achieve the optimal cost rate.

We perform our investigations in both overdamped and underdamped settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NOTE: Solution for KDD-CUP 2021 WikiKG90M-LSC. (arXiv:2107.01892v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1">Weiyue Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zeyang Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1">Hui Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1">Siming Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhengjie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yunsheng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shikun Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeyu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01892">
                                    <div class="article-summary-box-inner">
                                        <span>WikiKG90M in KDD Cup 2021 is a large encyclopedic knowledge graph, which
could benefit various downstream applications such as question answering and
recommender systems. Participants are invited to complete the knowledge graph
by predicting missing triplets. Recent representation learning methods have
achieved great success on standard datasets like FB15k-237. Thus, we train the
advanced algorithms in different domains to learn the triplets, including OTE,
QuatE, RotatE and TransE. Significantly, we modified OTE into NOTE (short for
Norm-OTE) for better performance. Besides, we use both the DeepWalk and the
post-smoothing technique to capture the graph structure for supplementation. In
addition to the representations, we also use various statistical probabilities
among the head entities, the relations and the tail entities for the final
prediction. Experimental results show that the ensemble of state-of-the-art
representation learning methods could draw on each others strengths. And we
develop feature engineering from validation candidates for further
improvements. Please note that we apply the same strategy on the test set for
final inference. And these features may not be practical in the real world when
considering ranking against all the entities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Survey: Leakage and Privacy at Inference Time. (arXiv:2107.01614v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jegorova_M/0/1/0/all/0/1">Marija Jegorova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaul_C/0/1/0/all/0/1">Chaitanya Kaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayor_C/0/1/0/all/0/1">Charlie Mayor</a>, <a href="http://arxiv.org/find/cs/1/au:+ONeil_A/0/1/0/all/0/1">Alison Q. O&#x27;Neil</a>, <a href="http://arxiv.org/find/cs/1/au:+Weir_A/0/1/0/all/0/1">Alexander Weir</a>, <a href="http://arxiv.org/find/cs/1/au:+Murray_Smith_R/0/1/0/all/0/1">Roderick Murray-Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsaftaris_S/0/1/0/all/0/1">Sotirios A. Tsaftaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01614">
                                    <div class="article-summary-box-inner">
                                        <span>Leakage of data from publicly available Machine Learning (ML) models is an
area of growing significance as commercial and government applications of ML
can draw on multiple sources of data, potentially including users&#x27; and clients&#x27;
sensitive data. We provide a comprehensive survey of contemporary advances on
several fronts, covering involuntary data leakage which is natural to ML
models, potential malevolent leakage which is caused by privacy attacks, and
currently available defence mechanisms. We focus on inference-time leakage, as
the most likely scenario for publicly available models. We first discuss what
leakage is in the context of different data, tasks, and model architectures. We
then propose a taxonomy across involuntary and malevolent leakage, available
defences, followed by the currently available assessment metrics and
applications. We conclude with outstanding challenges and open questions,
outlining some promising directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimum Wasserstein Distance Estimator under Finite Location-scale Mixtures. (arXiv:2107.01323v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1">Qiong Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Jiahua Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01323">
                                    <div class="article-summary-box-inner">
                                        <span>When a population exhibits heterogeneity, we often model it via a finite
mixture: decompose it into several different but homogeneous subpopulations.
Contemporary practice favors learning the mixtures by maximizing the likelihood
for statistical efficiency and the convenient EM-algorithm for numerical
computation. Yet the maximum likelihood estimate (MLE) is not well defined for
the most widely used finite normal mixture in particular and for finite
location-scale mixture in general. We hence investigate feasible alternatives
to MLE such as minimum distance estimators. Recently, the Wasserstein distance
has drawn increased attention in the machine learning community. It has
intuitive geometric interpretation and is successfully employed in many new
applications. Do we gain anything by learning finite location-scale mixtures
via a minimum Wasserstein distance estimator (MWDE)? This paper investigates
this possibility in several respects. We find that the MWDE is consistent and
derive a numerical solution under finite location-scale mixtures. We study its
robustness against outliers and mild model mis-specifications. Our moderate
scaled simulation study shows the MWDE suffers some efficiency loss against a
penalized version of MLE in general without noticeable gain in robustness. We
reaffirm the general superiority of the likelihood based learning strategies
even for the non-regular finite location-scale mixtures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Where is the Grass Greener? Revisiting Generalized Policy Iteration for Offline Reinforcement Learning. (arXiv:2107.01407v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blonde_L/0/1/0/all/0/1">Lionel Blond&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1">Alexandros Kalousis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01407">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of state-of-the-art baselines in the offline RL regime varies
widely over the spectrum of dataset qualities, ranging from &quot;far-from-optimal&quot;
random data to &quot;close-to-optimal&quot; expert demonstrations. We re-implement these
under a fair, unified, and highly factorized framework, and show that when a
given baseline outperforms its competing counterparts on one end of the
spectrum, it never does on the other end. This consistent trend prevents us
from naming a victor that outperforms the rest across the board. We attribute
the asymmetry in performance between the two ends of the quality spectrum to
the amount of inductive bias injected into the agent to entice it to posit that
the behavior underlying the offline dataset is optimal for the task. The more
bias is injected, the higher the agent performs, provided the dataset is
close-to-optimal. Otherwise, its effect is brutally detrimental. Adopting an
advantage-weighted regression template as base, we conduct an investigation
which corroborates that injections of such optimality inductive bias, when not
done parsimoniously, makes the agent subpar in the datasets it was dominant as
soon as the offline policy is sub-optimal. In an effort to design methods that
perform well across the whole spectrum, we revisit the generalized policy
iteration scheme for the offline regime, and study the impact of nine distinct
newly-introduced proposal distributions over actions, involved in proposed
generalization of the policy evaluation and policy improvement update rules. We
show that certain orchestrations strike the right balance and can improve the
performance on one end of the spectrum without harming it on the other end.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning. (arXiv:2105.15134v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zixin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15134">
                                    <div class="article-summary-box-inner">
                                        <span>How can neural networks trained by contrastive learning extract features from
the unlabeled data? Why does contrastive learning usually need much stronger
data augmentations than supervised learning to ensure good representations?
These questions involve both the optimization and statistical aspects of deep
learning, but can hardly be answered by analyzing supervised learning, where
the target functions are the highest pursuit. Indeed, in self-supervised
learning, it is inevitable to relate to the optimization/generalization of
neural networks to how they can encode the latent structures in the data, which
we refer to as the feature learning process.

In this work, we formally study how contrastive learning learns the feature
representations for neural networks by analyzing its feature learning process.
We consider the case where our data are comprised of two types of features: the
more semantically aligned sparse features which we want to learn from, and the
other dense features we want to avoid. Theoretically, we prove that contrastive
learning using $\mathbf{ReLU}$ networks provably learns the desired sparse
features if proper augmentations are adopted. We present an underlying
principle called $\textbf{feature decoupling}$ to explain the effects of
augmentations, where we theoretically characterize how augmentations can reduce
the correlations of dense features between positive samples while keeping the
correlations of sparse features intact, thereby forcing the neural networks to
learn from the self-supervision of sparse features. Empirically, we verified
that the feature decoupling principle matches the underlying mechanism of
contrastive learning in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Gaussian Process Emulation using Stochastic Imputation. (arXiv:2107.01590v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ming_D/0/1/0/all/0/1">Deyu Ming</a>, <a href="http://arxiv.org/find/stat/1/au:+Williamson_D/0/1/0/all/0/1">Daniel Williamson</a>, <a href="http://arxiv.org/find/stat/1/au:+Guillas_S/0/1/0/all/0/1">Serge Guillas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01590">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel deep Gaussian process (DGP) inference method for computer
model emulation using stochastic imputation. By stochastically imputing the
latent layers, the approach transforms the DGP into the linked GP, a
state-of-the-art surrogate model formed by linking a system of feed-forward
coupled GPs. This transformation renders a simple while efficient DGP training
procedure that only involves optimizations of conventional stationary GPs. In
addition, the analytically tractable mean and variance of the linked GP allows
one to implement predictions from DGP emulators in a fast and accurate manner.
We demonstrate the method in a series of synthetic examples and real-world
applications, and show that it is a competitive candidate for efficient DGP
surrogate modeling in comparison to the variational inference and the
fully-Bayesian approach. A $\texttt{Python}$ package $\texttt{dgpsi}$
implementing the method is also produced and available at
https://github.com/mingdeyu/DGP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SDCOR: Scalable Density-based Clustering for Local Outlier Detection in Massive-Scale Datasets. (arXiv:2006.07616v11 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nozad_S/0/1/0/all/0/1">Sayyed Ahmad Naghavi Nozad</a>, <a href="http://arxiv.org/find/cs/1/au:+Haeri_M/0/1/0/all/0/1">Maryam Amir Haeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Folino_G/0/1/0/all/0/1">Gianluigi Folino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07616">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a batch-wise density-based clustering approach for local
outlier detection in massive-scale datasets. Unlike the well-known traditional
algorithms, which assume that all the data is memory-resident, our proposed
method is scalable and processes the input data chunk-by-chunk within the
confines of a limited memory buffer. A temporary clustering model is built at
the first phase; then, it is gradually updated by analyzing consecutive memory
loads of points. Subsequently, at the end of scalable clustering, the
approximate structure of the original clusters is obtained. Finally, by another
scan of the entire dataset and using a suitable criterion, an outlying score is
assigned to each object called SDCOR (Scalable Density-based Clustering
Outlierness Ratio). Evaluations on real-life and synthetic datasets demonstrate
that the proposed method has a low linear time complexity and is more effective
and efficient compared to best-known conventional density-based methods, which
need to load all data into the memory; and also, to some fast distance-based
methods, which can perform on data resident in the disk.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble and Auxiliary Tasks for Data-Efficient Deep Reinforcement Learning. (arXiv:2107.01904v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maulana_M/0/1/0/all/0/1">Muhammad Rizki Maulana</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wee Sun Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01904">
                                    <div class="article-summary-box-inner">
                                        <span>Ensemble and auxiliary tasks are both well known to improve the performance
of machine learning models when data is limited. However, the interaction
between these two methods is not well studied, particularly in the context of
deep reinforcement learning. In this paper, we study the effects of ensemble
and auxiliary tasks when combined with the deep Q-learning algorithm. We
perform a case study on ATARI games under limited data constraint. Moreover, we
derive a refined bias-variance-covariance decomposition to analyze the
different ways of learning ensembles and using auxiliary tasks, and use the
analysis to help provide some understanding of the case study. Our code is open
source and available at https://github.com/NUS-LID/RENAULT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Randomized Neural Networks for Forecasting Time Series with Multiple Seasonality. (arXiv:2107.01705v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Grzegorz Dudek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01705">
                                    <div class="article-summary-box-inner">
                                        <span>This work contributes to the development of neural forecasting models with
novel randomization-based learning methods. These methods improve the fitting
abilities of the neural model, in comparison to the standard method, by
generating network parameters in accordance with the data and target function
features. A pattern-based representation of time series makes the proposed
approach useful for forecasting time series with multiple seasonality. In the
simulation study, we evaluate the performance of the proposed models and find
that they can compete in terms of forecasting accuracy with fully-trained
networks. Extremely fast and easy training, simple architecture, ease of
implementation, high accuracy as well as dealing with nonstationarity and
multiple seasonality in time series make the proposed model very attractive for
a wide range of complex time series forecasting problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Informed Deep Reversible Regression Model for Temperature Field Reconstruction of Heat-Source Systems. (arXiv:2106.11929v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zhiqiang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Weien Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Wen Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11929">
                                    <div class="article-summary-box-inner">
                                        <span>Temperature monitoring during the life time of heat source components in
engineering systems becomes essential to guarantee the normal work and the
working life of these components. However, prior methods, which mainly use the
interpolate estimation to reconstruct the temperature field from limited
monitoring points, require large amounts of temperature tensors for an accurate
estimation. This may decrease the availability and reliability of the system
and sharply increase the monitoring cost. To solve this problem, this work
develops a novel physics-informed deep reversible regression models for
temperature field reconstruction of heat-source systems (TFR-HSS), which can
better reconstruct the temperature field with limited monitoring points
unsupervisedly. First, we define the TFR-HSS task mathematically, and
numerically model the task, and hence transform the task as an image-to-image
regression problem. Then this work develops the deep reversible regression
model which can better learn the physical information, especially over the
boundary. Finally, considering the physical characteristics of heat conduction
as well as the boundary conditions, this work proposes the physics-informed
reconstruction loss including four training losses and jointly learns the deep
surrogate model with these losses unsupervisedly. Experimental studies have
conducted over typical two-dimensional heat-source systems to demonstrate the
effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Positional and Structural Node Features for Graph Neural Networks on Non-attributed Graphs. (arXiv:2107.01495v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zijie Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01495">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have been widely used in various graph-related
problems such as node classification and graph classification, where the
superior performance is mainly established when natural node features are
available. However, it is not well understood how GNNs work without natural
node features, especially regarding the various ways to construct artificial
ones. In this paper, we point out the two types of artificial node
features,i.e., positional and structural node features, and provide insights on
why each of them is more appropriate for certain tasks,i.e., positional node
classification, structural node classification, and graph classification.
Extensive experimental results on 10 benchmark datasets validate our insights,
thus leading to a practical guideline on the choices between different
artificial node features for GNNs on non-attributed graphs. The code is
available at https://github.com/zjzijielu/gnn-exp/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning and its Connections with Neuroscience and Psychology. (arXiv:2007.01099v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1">Ajay Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitlangia_S/0/1/0/all/0/1">Sharad Chitlangia</a>, <a href="http://arxiv.org/find/cs/1/au:+Baths_V/0/1/0/all/0/1">Veeky Baths</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01099">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning methods have recently been very successful at
performing complex sequential tasks like playing Atari games, Go and Poker.
These algorithms have outperformed humans in several tasks by learning from
scratch, using only scalar rewards obtained through interaction with their
environment. While there certainly has been considerable independent innovation
to produce such results, many core ideas in reinforcement learning are inspired
by phenomena in animal learning, psychology and neuroscience. In this paper, we
comprehensively review a large number of findings in both neuroscience and
psychology that evidence reinforcement learning as a promising candidate for
modeling learning and decision making in the brain. In doing so, we construct a
mapping between various classes of modern RL algorithms and specific findings
in both neurophysiological and behavioral literature. We then discuss the
implications of this observed relationship between RL, neuroscience and
psychology and its role in advancing research in both AI and brain science.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPI-GAN: Towards Single-Pixel Imaging through Generative Adversarial Network. (arXiv:2107.01330v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1">Nazmul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1">Nazanin Rahnavard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01330">
                                    <div class="article-summary-box-inner">
                                        <span>Single-pixel imaging is a novel imaging scheme that has gained popularity due
to its huge computational gain and potential for a low-cost alternative to
imaging beyond the visible spectrum. The traditional reconstruction methods
struggle to produce a clear recovery when one limits the number of illumination
patterns from a spatial light modulator. As a remedy, several
deep-learning-based solutions have been proposed which lack good generalization
ability due to the architectural setup and loss functions. In this paper, we
propose a generative adversarial network-based reconstruction framework for
single-pixel imaging, referred to as SPI-GAN. Our method can reconstruct images
with 17.92 dB PSNR and 0.487 SSIM, even if the sampling ratio drops to 5%. This
facilitates much faster reconstruction making our method suitable for
single-pixel video. Furthermore, our ResNet-like architecture for the generator
leads to useful representation learning that allows us to reconstruct
completely unseen objects. The experimental results demonstrate that SPI-GAN
achieves significant performance gain, e.g. near 3dB PSNR gain, over the
current state-of-the-art method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CT Image Harmonization for Enhancing Radiomics Studies. (arXiv:2107.01337v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Selim_M/0/1/0/all/0/1">Md Selim</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Fei_B/0/1/0/all/0/1">Baowei Fei</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_G/0/1/0/all/0/1">Guo-Qiang Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Jin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01337">
                                    <div class="article-summary-box-inner">
                                        <span>While remarkable advances have been made in Computed Tomography (CT),
capturing CT images with non-standardized protocols causes low reproducibility
regarding radiomic features, forming a barrier on CT image analysis in a large
scale. RadiomicGAN is developed to effectively mitigate the discrepancy caused
by using non-standard reconstruction kernels. RadiomicGAN consists of hybrid
neural blocks including both pre-trained and trainable layers adopted to learn
radiomic feature distributions efficiently. A novel training approach, called
Dynamic Window-based Training, has been developed to smoothly transform the
pre-trained model to the medical imaging domain. Model performance evaluated
using 1401 radiomic features show that RadiomicGAN clearly outperforms the
state-of-art image standardization models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification. (arXiv:2107.01461v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xianjun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuzhong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chin-Hui Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01461">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel neural model compression strategy combining data
augmentation, knowledge transfer, pruning, and quantization for device-robust
acoustic scene classification (ASC). Specifically, we tackle the ASC task in a
low-resource environment leveraging a recently proposed advanced neural network
pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a
sub-network neural model associated with a small amount non-zero model
parameters. The effectiveness of LTH for low-complexity acoustic modeling is
assessed by investigating various data augmentation and compression schemes,
and we report an efficient joint framework for low-complexity multi-device ASC,
called Acoustic Lottery. Acoustic Lottery could compress an ASC model over
$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and
Log loss of 0.76) compared to its not compressed seed model. All results
reported in this work are based on a joint effort of four groups, namely
GT-USTC-UKE-Tencent, aiming to address the &quot;Low-Complexity Acoustic Scene
Classification (ASC) with Multiple Devices&quot; in the DCASE 2021 Challenge Task
1a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two Ridge Solutions for the Incremental Broad Learning System on Added Nodes. (arXiv:1911.04872v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hufei Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.04872">
                                    <div class="article-summary-box-inner">
                                        <span>The original Broad Learning System (BLS) on new added nodes and its existing
efficient implementation both assume the ridge parameter is near 0 in the ridge
inverse to approximate the generalized inverse, and compute the generalized
inverse solution for the output weights. In this paper, we propose two ridge
solutions for the output weights in the BLS on added nodes, where the ridge
parameter can be any positive real number. One of the proposed ridge solutions
computes the output weights from the inverse Cholesky factor, which is updated
by extending the existing inverse Cholesky factorization. The other proposed
ridge solution computes the output weights from the ridge inverse, and updates
the ridge inverse by extending the Greville method that can only computes the
generalized inverse of a partitioned matrix. The proposed BLS algorithm based
on the ridge inverse requires the same complexity as the original BLS
algorithm, while the proposed BLS algorithm based on the inverse Cholesky
factor requires less complexity and training time than the original BLS and the
existing efficient BLS. Both the proposed ridge solutions for BLS achieve the
same testing accuracy as the standard ridge solution in the numerical
experiments. The difference between the testing accuracy of the proposed ridge
solutions and that of the existing generalized inverse solutions is negligible
when the ridge parameter is very small, and becomes too big to be ignored when
the ridge parameter is not very small. When the ridge parameter is not near 0,
usually the proposed two ridge solutions for BLS achieve better testing
accuracy than the existing generalized inverse solutions for BLS, and then the
former are more preferred than the latter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Role of &quot;Live&quot; in Livestreaming Markets: Evidence Using Orthogonal Random Forest. (arXiv:2107.01629v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Cong_Z/0/1/0/all/0/1">Ziwei Cong</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1">Jia Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Manchanda_P/0/1/0/all/0/1">Puneet Manchanda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01629">
                                    <div class="article-summary-box-inner">
                                        <span>The common belief about the growing medium of livestreaming is that its value
lies in its &quot;live&quot; component. In this paper, we leverage data from a large
livestreaming platform to examine this belief. We are able to do this as this
platform also allows viewers to purchase the recorded version of the
livestream. We summarize the value of livestreaming content by estimating how
demand responds to price before, on the day of, and after the livestream. We do
this by proposing a generalized Orthogonal Random Forest framework. This
framework allows us to estimate heterogeneous treatment effects in the presence
of high-dimensional confounders whose relationships with the treatment policy
(i.e., price) are complex but partially known. We find significant dynamics in
the price elasticity of demand over the temporal distance to the scheduled
livestreaming day and after. Specifically, demand gradually becomes less price
sensitive over time to the livestreaming day and is inelastic on the
livestreaming day. Over the post-livestream period, demand is still sensitive
to price, but much less than the pre-livestream period. This indicates that the
vlaue of livestreaming persists beyond the live component. Finally, we provide
suggestive evidence for the likely mechanisms driving our results. These are
quality uncertainty reduction for the patterns pre- and post-livestream and the
potential of real-time interaction with the creator on the day of the
livestream.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Class Introspection: A Novel Technique for Detecting Unlabeled Subclasses by Leveraging Classifier Explainability Methods. (arXiv:2107.01657v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kage_P/0/1/0/all/0/1">Patrick Kage</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreadis_P/0/1/0/all/0/1">Pavlos Andreadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01657">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting latent structure within a dataset is a crucial step in performing
analysis of a dataset. However, existing state-of-the-art techniques for
subclass discovery are limited: either they are limited to detecting very small
numbers of outliers or they lack the statistical power to deal with complex
data such as image or audio. This paper proposes a solution to this subclass
discovery problem: by leveraging instance explanation methods, an existing
classifier can be extended to detect latent classes via differences in the
classifier&#x27;s internal decisions about each instance. This works not only with
simple classification techniques but also with deep neural networks, allowing
for a powerful and flexible approach to detecting latent structure within
datasets. Effectively, this represents a projection of the dataset into the
classifier&#x27;s &quot;explanation space,&quot; and preliminary results show that this
technique outperforms the baseline for the detection of latent classes even
with limited processing. This paper also contains a pipeline for analyzing
classifiers automatically, and a web application for interactively exploring
the results from this technique.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Byzantine-robust Federated Learning through Spatial-temporal Analysis of Local Model Updates. (arXiv:2107.01477v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhuohang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Luyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jian Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01477">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) enables multiple distributed clients (e.g., mobile
devices) to collaboratively train a centralized model while keeping the
training data locally on the client. Compared to traditional centralized
machine learning, FL offers many favorable features such as offloading
operations which would usually be performed by a central server and reducing
risks of serious privacy leakage. However, Byzantine clients that send
incorrect or disruptive updates due to system failures or adversarial attacks
may disturb the joint learning process, consequently degrading the performance
of the resulting model. In this paper, we propose to mitigate these failures
and attacks from a spatial-temporal perspective. Specifically, we use a
clustering-based method to detect and exclude incorrect updates by leveraging
their geometric properties in the parameter space. Moreover, to further handle
malicious clients with time-varying behaviors, we propose to adaptively adjust
the learning rate according to momentum-based update speculation. Extensive
experiments on 4 public datasets demonstrate that our algorithm achieves
enhanced robustness comparing to existing methods under both cross-silo and
cross-device FL settings with faulty/malicious clients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Traffic Signal Control with Communicative Deep Reinforcement Learning Agents: a Case Study. (arXiv:2107.01347v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fazzini_P/0/1/0/all/0/1">Paolo Fazzini</a>, <a href="http://arxiv.org/find/cs/1/au:+Wheeler_I/0/1/0/all/0/1">Isaac Wheeler</a>, <a href="http://arxiv.org/find/cs/1/au:+Petracchini_F/0/1/0/all/0/1">Francesco Petracchini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01347">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we theoretically and experimentally analyze Multi-Agent
Advantage Actor-Critic (MA2C) and Independent Advantage Actor-Critic (IA2C),
two recently proposed multi-agent reinforcement learning methods that can be
applied to control traffic signals in urban areas. The two methods differ in
their use of a reward calculated locally or globally and in the management of
agents&#x27; communication. We analyze the methods theoretically with the framework
provided by non-Markov decision processes, which provides useful insights in
the analysis of the algorithms. Moreover, we analyze the efficacy and the
robustness of the methods experimentally by testing them in two traffic areas
in the Bologna (Italy) area, simulated by SUMO, a software tool. The
experimental results indicate that MA2C achieves the best performance in the
majority of cases, outperforms the alternative method considered, and displays
sufficient stability during the learning process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing the Numbers of Queries and Replies in Federated Learning with Differential Privacy. (arXiv:2107.01895v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yipeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuezheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yao Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shui Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01895">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) empowers distributed clients to collaboratively train
a shared machine learning model through exchanging parameter information.
Despite the fact that FL can protect clients&#x27; raw data, malicious users can
still crack original data with disclosed parameters. To amend this flaw,
differential privacy (DP) is incorporated into FL clients to disturb original
parameters, which however can significantly impair the accuracy of the trained
model. In this work, we study a crucial question which has been vastly
overlooked by existing works: what are the optimal numbers of queries and
replies in FL with DP so that the final model accuracy is maximized. In FL, the
parameter server (PS) needs to query participating clients for multiple global
iterations to complete training. Each client responds a query from the PS by
conducting a local iteration. Our work investigates how many times the PS
should query clients and how many times each client should reply the PS. We
investigate two most extensively used DP mechanisms (i.e., the Laplace
mechanism and Gaussian mechanisms). Through conducting convergence rate
analysis, we can determine the optimal numbers of queries and replies in FL
with DP so that the final model accuracy can be maximized. Finally, extensive
experiments are conducted with publicly available datasets: MNIST and FEMNIST,
to verify our analysis and the results demonstrate that properly setting the
numbers of queries and replies can significantly improve the final model
accuracy in FL with DP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Hierarchical Graph Neural Networks for Image Clustering. (arXiv:2107.01319v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_Y/0/1/0/all/0/1">Yifan Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Tong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tianjun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1">David Wipf Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01319">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a hierarchical graph neural network (GNN) model that learns how to
cluster a set of images into an unknown number of identities using a training
set of images annotated with labels belonging to a disjoint set of identities.
Our hierarchical GNN uses a novel approach to merge connected components
predicted at each level of the hierarchy to form a new graph at the next level.
Unlike fully unsupervised hierarchical clustering, the choice of grouping and
complexity criteria stems naturally from supervision in the training set. The
resulting method, Hi-LANDER, achieves an average of 54% improvement in F-score
and 8% increase in Normalized Mutual Information (NMI) relative to current
GNN-based clustering algorithms. Additionally, state-of-the-art GNN-based
methods rely on separate models to predict linkage probabilities and node
densities as intermediate steps of the clustering process. In contrast, our
unified framework achieves a seven-fold decrease in computational cost. We
release our training and inference code at
https://github.com/dmlc/dgl/tree/master/examples/pytorch/hilander.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Randomized Dimensionality Reduction for Facility Location and Single-Linkage Clustering. (arXiv:2107.01804v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Silwal_S/0/1/0/all/0/1">Sandeep Silwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Indyk_P/0/1/0/all/0/1">Piotr Indyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamir_O/0/1/0/all/0/1">Or Zamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01804">
                                    <div class="article-summary-box-inner">
                                        <span>Random dimensionality reduction is a versatile tool for speeding up
algorithms for high-dimensional problems. We study its application to two
clustering problems: the facility location problem, and the single-linkage
hierarchical clustering problem, which is equivalent to computing the minimum
spanning tree. We show that if we project the input pointset $X$ onto a random
$d &#x3D; O(d_X)$-dimensional subspace (where $d_X$ is the doubling dimension of
$X$), then the optimum facility location cost in the projected space
approximates the original cost up to a constant factor. We show an analogous
statement for minimum spanning tree, but with the dimension $d$ having an extra
$\log \log n$ term and the approximation factor being arbitrarily close to $1$.
Furthermore, we extend these results to approximating solutions instead of just
their costs. Lastly, we provide experimental results to validate the quality of
solutions and the speedup due to the dimensionality reduction. Unlike several
previous papers studying this approach in the context of $k$-means and
$k$-medians, our dimension bound does not depend on the number of clusters but
only on the intrinsic dimensionality of $X$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Complex Users&#x27; Preferences for Recommender Systems. (arXiv:2107.01529v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yakhchi_S/0/1/0/all/0/1">Shahpar Yakhchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01529">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems (RSs) have emerged as very useful tools to help customers
with their decision-making process, find items of their interest, and alleviate
the information overload problem. There are two different lines of approaches
in RSs: (1) general recommenders with the main goal of discovering long-term
users&#x27; preferences, and (2) sequential recommenders with the main focus of
capturing short-term users&#x27; preferences in a session of user-item interaction
(here, a session refers to a record of purchasing multiple items in one
shopping event). While considering short-term users&#x27; preferences may satisfy
their current needs and interests, long-term users&#x27; preferences provide users
with the items that they may interact with, eventually. In this thesis, we
first focus on improving the performance of general RSs. Most of the existing
general RSs tend to exploit the users&#x27; rating patterns on common items to
detect similar users. The data sparsity problem (i.e. the lack of available
information) is one of the major challenges for the current general RSs, and
they may fail to have any recommendations when there are no common items of
interest among users. We call this problem data sparsity with no feedback on
common items (DSW-n-FCI). To overcome this problem, we propose a
personality-based RS in which similar users are identified based on the
similarity of their personality traits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven mapping between functional connectomes using optimal transport. (arXiv:2107.01303v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Dadashkarimi_J/0/1/0/all/0/1">Javid Dadashkarimi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Karbasi_A/0/1/0/all/0/1">Amin Karbasi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Scheinost_D/0/1/0/all/0/1">Dustin Scheinost</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01303">
                                    <div class="article-summary-box-inner">
                                        <span>Functional connectomes derived from functional magnetic resonance imaging
have long been used to understand the functional organization of the brain.
Nevertheless, a connectome is intrinsically linked to the atlas used to create
it. In other words, a connectome generated from one atlas is different in scale
and resolution compared to a connectome generated from another atlas. Being
able to map connectomes and derived results between different atlases without
additional pre-processing is a crucial step in improving interpretation and
generalization between studies that use different atlases. Here, we use optimal
transport, a powerful mathematical technique, to find an optimum mapping
between two atlases. This mapping is then used to transform time series from
one atlas to another in order to reconstruct a connectome. We validate our
approach by comparing transformed connectomes against their &quot;gold-standard&quot;
counterparts (i.e., connectomes generated directly from an atlas) and
demonstrate the utility of transformed connectomes by applying these
connectomes to predictive models based on a different atlas. We show that these
transformed connectomes are significantly similar to their &quot;gold-standard&quot;
counterparts and maintain individual differences in brain-behavior
associations, demonstrating both the validity of our approach and its utility
in downstream analyses. Overall, our approach is a promising avenue to increase
the generalization of connectome-based results across different atlases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sibling Regression for Generalized Linear Models. (arXiv:2107.01338v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Shankar_S/0/1/0/all/0/1">Shiv Shankar</a>, <a href="http://arxiv.org/find/stat/1/au:+Sheldon_D/0/1/0/all/0/1">Daniel Sheldon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01338">
                                    <div class="article-summary-box-inner">
                                        <span>Field observations form the basis of many scientific studies, especially in
ecological and social sciences. Despite efforts to conduct such surveys in a
standardized way, observations can be prone to systematic measurement errors.
The removal of systematic variability introduced by the observation process, if
possible, can greatly increase the value of this data. Existing non-parametric
techniques for correcting such errors assume linear additive noise models. This
leads to biased estimates when applied to generalized linear models (GLM). We
present an approach based on residual functions to address this limitation. We
then demonstrate its effectiveness on synthetic data and show it reduces
systematic detection variability in moth surveys.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Synthetic Data for Opinion-free Blind Image Quality Assessment in the Wild. (arXiv:2106.14076v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiri Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiangguo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuming Fang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14076">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, most existing blind image quality assessment (BIQA) models 1) are
developed for synthetically-distorted images and often generalize poorly to
authentic ones; 2) heavily rely on human ratings, which are prohibitively
labor-expensive to collect. Here, we propose an $opinion$-$free$ BIQA method
that learns from synthetically-distorted images and multiple agents to assess
the perceptual quality of authentically-distorted ones captured in the wild
without relying on human labels. Specifically, we first assemble a large number
of image pairs from synthetically-distorted images and use a set of
full-reference image quality assessment (FR-IQA) models to assign pseudo-binary
labels of each pair indicating which image has higher quality as the
supervisory signal. We then train a convolutional neural network (CNN)-based
BIQA model to rank the perceptual quality, optimized for consistency with the
binary labels. Since there exists domain shift between the synthetically- and
authentically-distorted images, an unsupervised domain adaptation (UDA) module
is introduced to alleviate this issue. Extensive experiments demonstrate the
effectiveness of our proposed $opinion$-$free$ BIQA model, yielding
state-of-the-art performance in terms of correlation with human opinion scores,
as well as gMAD competition. Codes will be made publicly available upon
acceptance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lottery Ticket Hypothesis Framework for Low-Complexity Device-Robust Neural Acoustic Scene Classification. (arXiv:2107.01461v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao-Han Huck Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1">Sabato Marco Siniscalchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xianjun Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuanjun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuzhong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chin-Hui Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01461">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel neural model compression strategy combining data
augmentation, knowledge transfer, pruning, and quantization for device-robust
acoustic scene classification (ASC). Specifically, we tackle the ASC task in a
low-resource environment leveraging a recently proposed advanced neural network
pruning mechanism, namely Lottery Ticket Hypothesis (LTH), to find a
sub-network neural model associated with a small amount non-zero model
parameters. The effectiveness of LTH for low-complexity acoustic modeling is
assessed by investigating various data augmentation and compression schemes,
and we report an efficient joint framework for low-complexity multi-device ASC,
called Acoustic Lottery. Acoustic Lottery could compress an ASC model over
$1/10^{4}$ and attain a superior performance (validation accuracy of 74.01% and
Log loss of 0.76) compared to its not compressed seed model. All results
reported in this work are based on a joint effort of four groups, namely
GT-USTC-UKE-Tencent, aiming to address the &quot;Low-Complexity Acoustic Scene
Classification (ASC) with Multiple Devices&quot; in the DCASE 2021 Challenge Task
1a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Steganography with Kerckhoffs&#x27; Principle. (arXiv:1711.04916v3 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ke_Y/0/1/0/all/0/1">Yan Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_T/0/1/0/all/0/1">Tingting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1711.04916">
                                    <div class="article-summary-box-inner">
                                        <span>The distortion in steganography that usually comes from the modification or
recoding on the cover image during the embedding process leaves the
steganalyzer with possibility of discriminating. Faced with such a risk, we
propose generative steganography with Kerckhoffs&#x27; principle (GSK) in this
letter. In GSK, the secret messages are generated by a cover image using a
generator rather than embedded into the cover, thus resulting in no
modifications in the cover. To ensure the security, the generators are trained
to meet Kerckhoffs&#x27; principle based on generative adversarial networks (GAN).
Everything about the GSK system, except the extraction key, is public knowledge
for the receivers. The secret messages can be outputted by the generator if and
only if the extraction key and the cover image are both inputted. In the
generator training procedures, there are two GANs, Message- GAN and Cover-GAN,
designed to work jointly making the generated results under the control of the
extraction key and the cover image. We provide experimental results on the
training process and give an example of the working process by adopting a
generator trained on MNIST, which demonstrate that GSK can use a cover image
without any modification to generate messages, and without the extraction key
or the cover image, only meaningless results would be obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Audiovisual Synthesis via Exemplar Autoencoders. (arXiv:2001.04463v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Aayush Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04463">
                                    <div class="article-summary-box-inner">
                                        <span>We present an unsupervised approach that converts the input speech of any
individual into audiovisual streams of potentially-infinitely many output
speakers. Our approach builds on simple autoencoders that project out-of-sample
data onto the distribution of the training set. We use Exemplar Autoencoders to
learn the voice, stylistic prosody, and visual appearance of a specific target
exemplar speech. In contrast to existing methods, the proposed approach can be
easily extended to an arbitrarily large number of speakers and styles using
only 3 minutes of target audio-video data, without requiring {\em any} training
data for the input speaker. To do so, we learn audiovisual bottleneck
representations that capture the structured linguistic content of speech. We
outperform prior approaches on both audio and video synthesis, and provide
extensive qualitative analysis on our project page --
https://www.cs.cmu.edu/~exemplar-ae/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-05">2021-07-05</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversational Machine Reading Comprehension for Vietnamese Healthcare Texts. (arXiv:2105.01542v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1">Son T. Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_M/0/1/0/all/0/1">Mao Nguyen Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1">Loi Duc Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1">Khiem Vinh Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01542">
                                    <div class="article-summary-box-inner">
                                        <span>Machine reading comprehension (MRC) is a sub-field in natural language
processing that aims to assist computers understand unstructured texts and then
answer questions related to them. In practice, the conversation is an essential
way to communicate and transfer information. To help machines understand
conversation texts, we present UIT-ViCoQA, a new corpus for conversational
machine reading comprehension in the Vietnamese language. This corpus consists
of 10,000 questions with answers over 2,000 conversations about health news
articles. Then, we evaluate several baseline approaches for conversational
machine comprehension on the UIT-ViCoQA corpus. The best model obtains an F1
score of 45.27%, which is 30.91 points behind human performance (76.18%),
indicating that there is ample room for improvement. Our dataset is available
at our website: this http URL for research purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Lifelong Learning of End-to-end ASR. (arXiv:2104.01616v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Heng-Jui Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1">Lin-shan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01616">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) technologies today are primarily optimized
for given datasets; thus, any changes in the application environment (e.g.,
acoustic conditions or topic domains) may inevitably degrade the performance.
We can collect new data describing the new environment and fine-tune the
system, but this naturally leads to higher error rates for the earlier
datasets, referred to as catastrophic forgetting. The concept of lifelong
learning (LLL) aiming to enable a machine to sequentially learn new tasks from
new datasets describing the changing real world without forgetting the
previously learned knowledge is thus brought to attention. This paper reports,
to our knowledge, the first effort to extensively consider and analyze the use
of various approaches of LLL in end-to-end (E2E) ASR, including proposing novel
methods in saving data for past domains to mitigate the catastrophic forgetting
problem. An overall relative reduction of 28.7% in WER was achieved compared to
the fine-tuning baseline when sequentially learning on three very different
benchmark corpora. This can be the first step toward the highly desired ASR
technologies capable of synchronizing with the continuously changing real
world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask Learning for Grapheme-to-Phoneme Conversion of Anglicisms in German Speech Recognition. (arXiv:2105.12708v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pritzen_J/0/1/0/all/0/1">Julia Pritzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gref_M/0/1/0/all/0/1">Michael Gref</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuhlke_D/0/1/0/all/0/1">Dietlind Z&#xfc;hlke</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_C/0/1/0/all/0/1">Christoph Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12708">
                                    <div class="article-summary-box-inner">
                                        <span>Loanwords, such as Anglicisms, are a challenge in German speech recognition.
Due to their irregular pronunciation compared to native German words,
automatically generated pronunciation dictionaries often include faulty phoneme
sequences for Anglicisms. In this work, we propose a multitask
sequence-to-sequence approach for grapheme-to-phoneme conversion to improve the
phonetization of Anglicisms. We extended a grapheme-to-phoneme model with a
classifier to distinguish Anglicisms from native German words. With this
approach, the model learns to generate pronunciations differently depending on
the classification result. We used our model to create supplementary Anglicism
pronunciation dictionaries that are added to an existing German speech
recognition model. Tested on a dedicated Anglicism evaluation set, we improved
the recognition of Anglicisms compared to a baseline model, reducing the word
error rate by 1 % and the Anglicism error rate by 3 %. We show that multitask
learning can help solving the challenge of loanwords in German speech
recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. (arXiv:2106.12672v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1">Yi Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Vinh Q. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1">Jai Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hyung Won Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1">Dara Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_S/0/1/0/all/0/1">Simon Baumgartner</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1">Donald Metzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12672">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art models in natural language processing rely on separate rigid
subword tokenization algorithms, which limit their generalization ability and
adaptation to new settings. In this paper, we propose a new model inductive
bias that learns a subword tokenization end-to-end as part of the model. To
this end, we introduce a soft gradient-based subword tokenization module (GBST)
that automatically learns latent subword representations from characters in a
data-driven fashion. Concretely, GBST enumerates candidate subword blocks and
learns to score them in a position-wise fashion using a block scoring network.
We additionally introduce Charformer, a deep Transformer model that integrates
GBST and operates on the byte level. Via extensive experiments on English GLUE,
multilingual, and noisy text datasets, we show that Charformer outperforms a
series of competitive byte-level baselines while generally performing on par
and sometimes outperforming subword-based models. Additionally, Charformer is
fast, improving the speed of both vanilla byte-level and subword-level
Transformers by 28%-100% while maintaining competitive quality. We believe this
work paves the way for highly performant token-free models that are trained
completely end-to-end.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Patent Mining and Relevance Classification using Transformers. (arXiv:2105.03979v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1">Th&#xe9;o Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Vermeiren_W/0/1/0/all/0/1">Walter Vermeiren</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranwez_S/0/1/0/all/0/1">Sylvie Ranwez</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Binbin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03979">
                                    <div class="article-summary-box-inner">
                                        <span>Patent analysis and mining are time-consuming and costly processes for
companies, but nevertheless essential if they are willing to remain
competitive. To face the overload induced by numerous patents, the idea is to
automatically filter them, bringing only few to read to experts. This paper
reports a successful application of fine-tuning and retraining on pre-trained
deep Natural Language Processing models on patent classification. The solution
that we propose combines several state-of-the-art treatments to achieve our
goal - decrease the workload while preserving recall and precision metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Gender Bias in Speech Translation. (arXiv:2010.14465v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1">Marta R. Costa-juss&#xe0;</a>, <a href="http://arxiv.org/find/cs/1/au:+Basta_C/0/1/0/all/0/1">Christine Basta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1">Gerard I. G&#xe1;llego</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14465">
                                    <div class="article-summary-box-inner">
                                        <span>The scientific community is increasingly aware of the necessity to embrace
pluralism and consistently represent major and minor social groups. Currently,
there are no standard evaluation techniques for different types of biases.
Accordingly, there is an urgent need to provide evaluation sets and protocols
to measure existing biases in our automatic systems. Evaluating the biases
should be an essential step towards mitigating them in the systems.

This paper introduces WinoST, a new freely available challenge set for
evaluating gender bias in speech translation. WinoST is the speech version of
WinoMT which is a MT challenge set and both follow an evaluation protocol to
measure gender accuracy. Using a state-of-the-art end-to-end speech translation
system, we report the gender bias evaluation on four language pairs and we show
that gender accuracy in speech translation is more than 23% lower than in MT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Augmentation by Concatenation for Low-Resource Translation: A Mystery and a Solution. (arXiv:2105.01691v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Toan Q. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1">Kenton Murray</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1">David Chiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01691">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the driving factors behind concatenation, a
simple but effective data augmentation method for low-resource neural machine
translation. Our experiments suggest that discourse context is unlikely the
cause for the improvement of about +1 BLEU across four language pairs. Instead,
we demonstrate that the improvement comes from three other factors unrelated to
discourse: context diversity, length diversity, and (to a lesser extent)
position shifting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AlloST: Low-resource Speech Translation without Source Transcription. (arXiv:2105.00171v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yao-Fei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-Shin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hsin-Min Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00171">
                                    <div class="article-summary-box-inner">
                                        <span>The end-to-end architecture has made promising progress in speech translation
(ST). However, the ST task is still challenging under low-resource conditions.
Most ST models have shown unsatisfactory results, especially in the absence of
word information from the source speech utterance. In this study, we survey
methods to improve ST performance without using source transcription, and
propose a learning framework that utilizes a language-independent universal
phone recognizer. The framework is based on an attention-based
sequence-to-sequence model, where the encoder generates the phonetic embeddings
and phone-aware acoustic representations, and the decoder controls the fusion
of the two embedding streams to produce the target token sequence. In addition
to investigating different fusion strategies, we explore the specific usage of
byte pair encoding (BPE), which compresses a phone sequence into a
syllable-like segmented sequence. Due to the conversion of symbols, a segmented
sequence represents not only pronunciation but also language-dependent
information lacking in phones. Experiments conducted on the Fisher
Spanish-English and Taigi-Mandarin drama corpora show that our method
outperforms the conformer-based baseline, and the performance is close to that
of the existing best method using source transcription.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ExplainaBoard: An Explainable Leaderboard for NLP. (arXiv:2104.06387v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shuaicheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Junqi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Zihuiwen Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zi-Yi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06387">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of NLP research, leaderboards have emerged as one
tool to track the performance of various systems on various NLP tasks. They are
effective in this goal to some extent, but generally present a rather
simplistic one-dimensional view of the submitted systems, communicated only
through holistic accuracy numbers. In this paper, we present a new
conceptualization and implementation of NLP evaluation: the ExplainaBoard,
which in addition to inheriting the functionality of the standard leaderboard,
also allows researchers to (i) diagnose strengths and weaknesses of a single
system (e.g.~what is the best-performing system bad at?) (ii) interpret
relationships between multiple systems. (e.g.~where does system A outperform
system B? What if we combine systems A, B, and C?) and (iii) examine prediction
results closely (e.g.~what are common errors made by multiple systems, or in
what contexts do particular errors occur?). So far, ExplainaBoard covers more
than 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps
updated and is recently upgraded by supporting (1) multilingual multi-task
benchmark, (2) meta-evaluation, and (3) more complicated task: machine
translation, which reviewers also suggested.} We not only released an online
platform on the website \url{this http URL} but also make
our evaluation tool an API with MIT Licence at Github
\url{https://github.com/neulab/explainaBoard} and PyPi
\url{https://pypi.org/project/interpret-eval/} that allows users to
conveniently assess their models offline. We additionally release all output
files from systems that we have run or collected to motivate &quot;output-driven&quot;
research in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text-guided Legal Knowledge Graph Reasoning. (arXiv:2104.02284v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Luoqiu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1">Zhen Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hongbin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shumin Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tou_H/0/1/0/all/0/1">Huaixiao Tou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02284">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have witnessed the prosperity of legal artificial intelligence
with the development of technologies. In this paper, we propose a novel legal
application of legal provision prediction (LPP), which aims to predict the
related legal provisions of affairs. We formulate this task as a challenging
knowledge graph completion problem, which requires not only text understanding
but also graph reasoning. To this end, we propose a novel text-guided graph
reasoning approach. We collect amounts of real-world legal provision data from
the Guangdong government service website and construct a legal dataset called
LegalLPP. Extensive experimental results on the dataset show that our approach
achieves better performance compared with baselines. The code and dataset are
available in \url{https://github.com/zjunlp/LegalPP} for reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-to-English Machine Translation Tools, Data, and Pretrained Models. (arXiv:2104.00290v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gowda_T/0/1/0/all/0/1">Thamme Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattmann_C/0/1/0/all/0/1">Chris A Mattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00290">
                                    <div class="article-summary-box-inner">
                                        <span>While there are more than 7000 languages in the world, most translation
research efforts have targeted a few high-resource languages. Commercial
translation systems support only one hundred languages or fewer, and do not
make these models available for transfer to low resource languages. In this
work, we present useful tools for machine translation research: MTData,
NLCodec, and RTG. We demonstrate their usefulness by creating a multilingual
neural machine translation model capable of translating from 500 source
languages to English. We make this multilingual model readily downloadable and
usable as a service, or as a parent model for transfer-learning to even
lower-resource languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ethics Sheets for AI Tasks. (arXiv:2107.01183v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1">Saif M. Mohammad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01183">
                                    <div class="article-summary-box-inner">
                                        <span>Several high-profile events, such as the use of biased recidivism systems and
mass testing of emotion recognition systems on vulnerable sub-populations, have
highlighted how technology will often lead to more adverse outcomes for those
that are already marginalized. In this paper, I will make a case for thinking
about ethical considerations not just at the level of individual models and
datasets, but also at the level of AI tasks. I will present a new form of such
an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the
assumptions and ethical considerations hidden in how a task is commonly framed
and in the choices we make regarding the data, method, and evaluation. Finally,
I will provide an example ethics sheet for automatic emotion recognition.
Together with Data Sheets for datasets and Model Cards for AI systems, Ethics
Sheets aid in the development and deployment of responsible AI systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporally Correlated Task Scheduling for Sequence Learning. (arXiv:2007.05290v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xueqing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lewen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yingce Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiqing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lijun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shufang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05290">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence learning has attracted much research attention from the machine
learning community in recent years. In many applications, a sequence learning
task is usually associated with multiple temporally correlated auxiliary tasks,
which are different in terms of how much input information to use or which
future step to predict. For example, (i) in simultaneous machine translation,
one can conduct translation under different latency (i.e., how many input words
to read/wait before translation); (ii) in stock trend forecasting, one can
predict the price of a stock in different future days (e.g., tomorrow, the day
after tomorrow). While it is clear that those temporally correlated tasks can
help each other, there is a very limited exploration on how to better leverage
multiple auxiliary tasks to boost the performance of the main task. In this
work, we introduce a learnable scheduler to sequence learning, which can
adaptively select auxiliary tasks for training depending on the model status
and the current training data. The scheduler and the model for the main task
are jointly trained through bi-level optimization. Experiments show that our
method significantly improves the performance of simultaneous machine
translation and stock trend forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UIT-ISE-NLP at SemEval-2021 Task 5: Toxic Spans Detection with BiLSTM-CRF and ToxicBERT Comment Classification. (arXiv:2104.10100v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1">Son T. Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10100">
                                    <div class="article-summary-box-inner">
                                        <span>We present our works on SemEval-2021 Task 5 about Toxic Spans Detection. This
task aims to build a model for identifying toxic words in whole posts. We use
the BiLSTM-CRF model combining with ToxicBERT Classification to train the
detection model for identifying toxic words in posts. Our model achieves 62.23%
by F1-score on the Toxic Spans Detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Decisions in Language Based Persuasion Games. (arXiv:2012.09966v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Apel_R/0/1/0/all/0/1">Reut Apel</a>, <a href="http://arxiv.org/find/cs/1/au:+Erev_I/0/1/0/all/0/1">Ido Erev</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>, <a href="http://arxiv.org/find/cs/1/au:+Tennenholtz_M/0/1/0/all/0/1">Moshe Tennenholtz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09966">
                                    <div class="article-summary-box-inner">
                                        <span>Sender-receiver interactions, and specifically persuasion games, are widely
researched in economic modeling and artificial intelligence, and serve as a
solid foundation for powerful applications. However, in the classic persuasion
games setting, the messages sent from the expert to the decision-maker are
abstract or well-structured application-specific signals rather than natural
(human) language messages, although natural language is a very common
communication signal in real-world persuasion setups. This paper addresses the
use of natural language in persuasion games, exploring its impact on the
decisions made by the players and aiming to construct effective models for the
prediction of these decisions. For this purpose, we conduct an online repeated
interaction experiment. At each trial of the interaction, an informed expert
aims to sell an uninformed decision-maker a vacation in a hotel, by sending her
a review that describes the hotel. While the expert is exposed to several
scored reviews, the decision-maker observes only the single review sent by the
expert, and her payoff in case she chooses to take the hotel is a random draw
from the review score distribution available to the expert only. The expert&#x27;s
payoff, in turn, depends on the number of times the decision-maker chooses the
hotel. We consider a number of modeling approaches for this setup, differing
from each other in the model type (deep neural network (DNN) vs. linear
classifier), the type of features used by the model (textual, behavioral or
both) and the source of the textual features (DNN-based vs. hand-crafted). Our
results demonstrate that given a prefix of the interaction sequence, our models
can predict the future decisions of the decision-maker, particularly when a
sequential modeling approach and hand-crafted textual features are applied.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concept Identification of Directly and Indirectly Related Mentions Referring to Groups of Persons. (arXiv:2107.00955v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhukova_A/0/1/0/all/0/1">Anastasia Zhukova</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamborg_F/0/1/0/all/0/1">Felix Hamborg</a>, <a href="http://arxiv.org/find/cs/1/au:+Donnay_K/0/1/0/all/0/1">Karsten Donnay</a>, <a href="http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1">Bela Gipp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00955">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised concept identification through clustering, i.e., identification
of semantically related words and phrases, is a common approach to identify
contextual primitives employed in various use cases, e.g., text dimension
reduction, i.e., replace words with the concepts to reduce the vocabulary size,
summarization, and named entity resolution. We demonstrate the first results of
an unsupervised approach for the identification of groups of persons as actors
extracted from a set of related articles. Specifically, the approach clusters
mentions of groups of persons that act as non-named entity actors in the texts,
e.g., &quot;migrant families&quot; &#x3D; &quot;asylum-seekers.&quot; Compared to our baseline, the
approach keeps the mentions of the geopolitical entities separated, e.g., &quot;Iran
leaders&quot; !&#x3D; &quot;European leaders,&quot; and clusters (in)directly related mentions with
diverse wording, e.g., &quot;American officials&quot; &#x3D; &quot;Trump Administration.&quot;</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRIFT: A Toolkit for Diachronic Analysis of Scientific Literature. (arXiv:2107.01198v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Abheesht Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chhablani_G/0/1/0/all/0/1">Gunjan Chhablani</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_H/0/1/0/all/0/1">Harshit Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_R/0/1/0/all/0/1">Rajaswa Patil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01198">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present to the NLP community, and to the wider research
community as a whole, an application for the diachronic analysis of research
corpora. We open source an easy-to-use tool coined: DRIFT, which allows
researchers to track research trends and development over the years. The
analysis methods are collated from well-cited research works, with a few of our
own methods added for good measure. Succinctly put, some of the analysis
methods are: keyword extraction, word clouds, predicting
declining/stagnant/growing trends using Productivity, tracking bi-grams using
Acceleration plots, finding the Semantic Drift of words, tracking trends using
similarity, etc. To demonstrate the utility and efficacy of our tool, we
perform a case study on the cs.CL corpus of the arXiv repository and draw
inferences from the analysis methods. The toolkit and the associated code are
available here: https://github.com/rajaswa/DRIFT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DUKweb: Diachronic word representations from the UK Web Archive corpus. (arXiv:2107.01076v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1">Adam Tsakalidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Basile_P/0/1/0/all/0/1">Pierpaolo Basile</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazzi_M/0/1/0/all/0/1">Marya Bazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>, <a href="http://arxiv.org/find/cs/1/au:+McGillivray_B/0/1/0/all/0/1">Barbara McGillivray</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01076">
                                    <div class="article-summary-box-inner">
                                        <span>Lexical semantic change (detecting shifts in the meaning and usage of words)
is an important task for social and cultural studies as well as for Natural
Language Processing applications. Diachronic word embeddings (time-sensitive
vector representations of words that preserve their meaning) have become the
standard resource for this task. However, given the significant computational
resources needed for their generation, very few resources exist that make
diachronic word embeddings available to the scientific community.

In this paper we present DUKweb, a set of large-scale resources designed for
the diachronic analysis of contemporary English. DUKweb was created from the
JISC UK Web Domain Dataset (1996-2013), a very large archive which collects
resources from the Internet Archive that were hosted on domains ending in
&#x60;.uk&#x27;. DUKweb consists of a series word co-occurrence matrices and two types of
word embeddings for each year in the JISC UK Web Domain dataset. We show the
reuse potential of DUKweb and its quality standards via a case study on word
meaning change detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Identification of Hindi-English tweets using code-mixed BERT. (arXiv:2107.01202v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mohd Zeeshan Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Beg_M/0/1/0/all/0/1">M M Sufyan Beg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Tanvir Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohd Jazib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasim_G/0/1/0/all/0/1">Ghazali Wasim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01202">
                                    <div class="article-summary-box-inner">
                                        <span>Language identification of social media text has been an interesting problem
of study in recent years. Social media messages are predominantly in code mixed
in non-English speaking states. Prior knowledge by pre-training contextual
embeddings have shown state of the art results for a range of downstream tasks.
Recently, models such as BERT have shown that using a large amount of unlabeled
data, the pretrained language models are even more beneficial for learning
common language representations. Extensive experiments exploiting transfer
learning and fine-tuning BERT models to identify language on Twitter are
presented in this paper. The work utilizes a data collection of
Hindi-English-Urdu codemixed text for language pre-training and Hindi-English
codemixed for subsequent word-level language classification. The results show
that the representations pre-trained over codemixed data produce better results
by their monolingual counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling. (arXiv:2107.00967v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1">Haitao Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zujie Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yafang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1">Gerard de Melo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00967">
                                    <div class="article-summary-box-inner">
                                        <span>Human language understanding operates at multiple levels of granularity
(e.g., words, phrases, and sentences) with increasing levels of abstraction
that can be hierarchically combined. However, existing deep models with stacked
layers do not explicitly model any sort of hierarchical process. This paper
proposes a recursive Transformer model based on differentiable CKY style binary
trees to emulate the composition process. We extend the bidirectional language
model pre-training objective to this architecture, attempting to predict each
word given its left and right abstraction nodes. To scale up our approach, we
also introduce an efficient pruned tree induction algorithm to enable encoding
in just a linear number of composition steps. Experimental results on language
modeling and unsupervised parsing show the effectiveness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Spoken Utterance Classification. (arXiv:2107.01068v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalalvand_S/0/1/0/all/0/1">Shahab Jalalvand</a>, <a href="http://arxiv.org/find/cs/1/au:+Bangalore_S/0/1/0/all/0/1">Srinivas Bangalore</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01068">
                                    <div class="article-summary-box-inner">
                                        <span>An intelligent virtual assistant (IVA) enables effortless conversations in
call routing through spoken utterance classification (SUC) which is a special
form of spoken language understanding (SLU). Building a SUC system requires a
large amount of supervised in-domain data that is not always available. In this
paper, we introduce an unsupervised spoken utterance classification approach
(USUC) that does not require any in-domain data except for the intent labels
and a few para-phrases per intent. USUC is consisting of a KNN classifier (K&#x3D;1)
and a complex embedding model trained on a large amount of unsupervised
customer service corpus. Among all embedding models, we demonstrate that Elmo
works best for USUC. However, an Elmo model is too slow to be used at run-time
for call routing. To resolve this issue, first, we compute the uni- and bi-gram
embedding vectors offline and we build a lookup table of n-grams and their
corresponding embedding vector. Then we use this table to compute sentence
embedding vectors at run-time, along with back-off techniques for unseen
n-grams. Experiments show that USUC outperforms the traditional utterance
classification methods by reducing the classification error rate from 32.9% to
27.0% without requiring supervised data. Moreover, our lookup and back-off
technique increases the processing speed from 16 utterances per second to 118
utterances per second.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement Learning Agents. (arXiv:2107.00956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1">Grgur Kova&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1">R&#xe9;my Portelas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00956">
                                    <div class="article-summary-box-inner">
                                        <span>Building embodied autonomous agents capable of participating in social
interactions with humans is one of the main challenges in AI. Within the Deep
Reinforcement Learning (DRL) field, this objective motivated multiple works on
embodied language use. However, current approaches focus on language as a
communication tool in very simplified and non-diverse social situations: the
&quot;naturalness&quot; of language is reduced to the concept of high vocabulary size and
variability. In this paper, we argue that aiming towards human-level AI
requires a broader set of key social skills: 1) language use in complex and
variable social contexts; 2) beyond language, complex embodied communication in
multimodal settings within constantly evolving social worlds. We explain how
concepts from cognitive sciences could help AI to draw a roadmap towards
human-like intelligence, with a focus on its social dimensions. As a first
step, we propose to expand current research to a broader set of core social
skills. To do this, we present SocialAI, a benchmark to assess the acquisition
of social skills of DRL agents using multiple grid-world environments featuring
other (scripted) social agents. We then study the limits of a recent SOTA DRL
approach when tested on SocialAI and discuss important next steps towards
proficient social agents. Videos and code are available at
https://sites.google.com/view/socialai.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Investigation of the (In)effectiveness of Counterfactually Augmented Data. (arXiv:2107.00753v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nitish Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00753">
                                    <div class="article-summary-box-inner">
                                        <span>While pretrained language models achieve excellent performance on natural
language understanding benchmarks, they tend to rely on spurious correlations
and generalize poorly to out-of-distribution (OOD) data. Recent work has
explored using counterfactually-augmented data (CAD) -- data generated by
minimally perturbing examples to flip the ground-truth label -- to identify
robust features that are invariant under distribution shift. However, empirical
results using CAD for OOD generalization have been mixed. To explain this
discrepancy, we draw insights from a linear Gaussian model and demonstrate the
pitfalls of CAD. Specifically, we show that (a) while CAD is effective at
identifying robust features, it may prevent the model from learning unperturbed
robust features, and (b) CAD may exacerbate existing spurious correlations in
the data. Our results show that the lack of perturbation diversity in current
CAD datasets limits its effectiveness on OOD generalization, calling for
innovative crowdsourcing procedures to elicit diverse perturbation of examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Centric Domain Adaptation for Historical Text with OCR Errors. (arXiv:2107.00927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marz_L/0/1/0/all/0/1">Luisa M&#xe4;rz</a>, <a href="http://arxiv.org/find/cs/1/au:+Schweter_S/0/1/0/all/0/1">Stefan Schweter</a>, <a href="http://arxiv.org/find/cs/1/au:+Poerner_N/0/1/0/all/0/1">Nina Poerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00927">
                                    <div class="article-summary-box-inner">
                                        <span>We propose new methods for in-domain and cross-domain Named Entity
Recognition (NER) on historical data for Dutch and French. For the cross-domain
case, we address domain shift by integrating unsupervised in-domain data via
contextualized string embeddings; and OCR errors by injecting synthetic OCR
errors into the source domain and address data centric domain adaptation. We
propose a general approach to imitate OCR errors in arbitrary input data. Our
cross-domain as well as our in-domain results outperform several strong
baselines and establish state-of-the-art results. We publish preprocessed
versions of the French and Dutch Europeana NER corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Token Pruning for Transformers. (arXiv:2107.00910v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sehoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Sheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorsley_D/0/1/0/all/0/1">David Thorsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1">Amir Gholami</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassoun_J/0/1/0/all/0/1">Joseph Hassoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00910">
                                    <div class="article-summary-box-inner">
                                        <span>A major challenge in deploying transformer models is their prohibitive
inference cost, which quadratically scales with the input sequence length. This
makes it especially difficult to use transformers for processing long
sequences. To address this, we present a novel Learned Token Pruning (LTP)
method that reduces redundant tokens as the data passes through the different
layers of the transformer. In particular, LTP prunes tokens with an attention
score below a threshold value, which is learned during training. Importantly,
our threshold based method avoids algorithmically expensive operations such as
top-k token selection which are used in prior token pruning methods, and also
leads to structured pruning. We extensively test the performance of our
approach on multiple GLUE tasks and show that our learned threshold based
method consistently outperforms the prior state-of-the-art top-k token based
method by up to ~2% higher accuracy with the same amount of FLOPs. Furthermore,
our preliminary results show up to 1.4x and 1.9x throughput improvement on
Tesla T4 GPU and Intel Haswell CPU, respectively, with less than 1% of accuracy
drop (and up to 2.1x FLOPs reduction). Our code has been developed in PyTorch
and has been open-sourced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions. (arXiv:2107.00789v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kambara_M/0/1/0/all/0/1">Motonari Kambara</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00789">
                                    <div class="article-summary-box-inner">
                                        <span>There have been many studies in robotics to improve the communication skills
of domestic service robots. Most studies, however, have not fully benefited
from recent advances in deep neural networks because the training datasets are
not large enough. In this paper, our aim is to augment the datasets based on a
crossmodal language generation model. We propose the Case Relation Transformer
(CRT), which generates a fetching instruction sentence from an image, such as
&quot;Move the blue flip-flop to the lower left box.&quot; Unlike existing methods, the
CRT uses the Transformer to integrate the visual features and geometry features
of objects in the image. The CRT can handle the objects because of the Case
Relation Block. We conducted comparison experiments and a human evaluation. The
experimental results show the CRT outperforms baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Target-dependent UNITER: A Transformer-Based Multimodal Language Comprehension Model for Domestic Service Robots. (arXiv:2107.00811v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_S/0/1/0/all/0/1">Shintaro Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00811">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, domestic service robots have an insufficient ability to interact
naturally through language. This is because understanding human instructions is
complicated by various ambiguities and missing information. In existing
methods, the referring expressions that specify the relationships between
objects are insufficiently modeled. In this paper, we propose Target-dependent
UNITER, which learns the relationship between the target object and other
objects directly by focusing on the relevant regions within an image, rather
than the whole image. Our method is an extension of the UNITER-based
Transformer that can be pretrained on general-purpose datasets. We extend the
UNITER approach by introducing a new architecture for handling the target
candidates. Our model is validated on two standard datasets, and the results
show that Target-dependent UNITER outperforms the baseline method in terms of
classification accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heterogeneous Graph Attention Network for Multi-hop Machine Reading Comprehension. (arXiv:2107.00841v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1">Feng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1">Jian-Cheng Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zi-Li Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yan-Yan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujita_H/0/1/0/all/0/1">Hamido Fujita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00841">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-hop machine reading comprehension is a challenging task in natural
language processing, which requires more reasoning ability and explainability.
Spectral models based on graph convolutional networks grant the inferring
abilities and lead to competitive results, however, part of them still face the
challenge of analyzing the reasoning in a human-understandable way. Inspired by
the concept of the Grandmother Cells in cognitive neuroscience, a spatial graph
attention framework named crname, imitating the procedure was proposed. This
model is designed to assemble the semantic features in multi-angle
representations and automatically concentrate or alleviate the information for
reasoning. The name &quot;crname&quot; is a metaphor for the pattern of the model: regard
the subjects of queries as the start points of clues, take the reasoning
entities as bridge points, and consider the latent candidate entities as the
grandmother cells, and the clues end up in candidate entities. The proposed
model allows us to visualize the reasoning graph and analyze the importance of
edges connecting two entities and the selectivity in the mention and candidate
nodes, which can be easier to be comprehended empirically. The official
evaluations in open-domain multi-hop reading dataset WikiHop and Drug-drug
Interactions dataset MedHop prove the validity of our approach and show the
probability of the application of the model in the molecular biology domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Misinformation Detection on YouTube Using Video Captions. (arXiv:2107.00941v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jagtap_R/0/1/0/all/0/1">Raj Jagtap</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhinav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1">Rahul Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Shakshi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rajesh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+George_C/0/1/0/all/0/1">Clint P. George</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00941">
                                    <div class="article-summary-box-inner">
                                        <span>Millions of people use platforms such as YouTube, Facebook, Twitter, and
other mass media. Due to the accessibility of these platforms, they are often
used to establish a narrative, conduct propaganda, and disseminate
misinformation. This work proposes an approach that uses state-of-the-art NLP
techniques to extract features from video captions (subtitles). To evaluate our
approach, we utilize a publicly accessible and labeled dataset for classifying
videos as misinformation or not. The motivation behind exploring video captions
stems from our analysis of videos metadata. Attributes such as the number of
views, likes, dislikes, and comments are ineffective as videos are hard to
differentiate using this information. Using caption dataset, the proposed
models can classify videos among three classes (Misinformation, Debunking
Misinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the
relevance of the misinformation class, we re-formulate our classification
problem as a two-class classification - Misinformation vs. others (Debunking
Misinformation and Neutral). In our experiments, the proposed models can
classify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">He Thinks He Knows Better than the Doctors: BERT for Event Factuality Fails on Pragmatics. (arXiv:2107.00807v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nanjiang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Marneffe_M/0/1/0/all/0/1">Marie-Catherine de Marneffe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00807">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate how well BERT performs on predicting factuality in several
existing English datasets, encompassing various linguistic constructions.
Although BERT obtains a strong performance on most datasets, it does so by
exploiting common surface patterns that correlate with certain factuality
labels, and it fails on instances where pragmatic reasoning is necessary.
Contrary to what the high performance suggests, we are still far from having a
robust system for factuality prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Primer on Pretrained Multilingual Language Models. (arXiv:2107.00676v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1">Sumanth Doddapaneni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_G/0/1/0/all/0/1">Gowtham Ramesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1">Anoop Kunchukuttan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Pratyush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1">Mitesh M. Khapra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00676">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual Language Models (MLLMs) such as mBERT, XLM, XLM-R, \textit{etc.}
have emerged as a viable option for bringing the power of pretraining to a
large number of languages. Given their success in zero shot transfer learning,
there has emerged a large body of work in (i) building bigger MLLMs covering a
large number of languages (ii) creating exhaustive benchmarks covering a wider
variety of tasks and languages for evaluating MLLMs (iii) analysing the
performance of MLLMs on monolingual, zero shot crosslingual and bilingual tasks
(iv) understanding the universal language patterns (if any) learnt by MLLMs and
(v) augmenting the (often) limited capacity of MLLMs to improve their
performance on seen or even unseen languages. In this survey, we review the
existing literature covering the above broad areas of research pertaining to
MLLMs. Based on our survey, we recommend some promising directions of future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive decoding of words from visual speech recognition models. (arXiv:2107.00692v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shillingford_B/0/1/0/all/0/1">Brendan Shillingford</a>, <a href="http://arxiv.org/find/cs/1/au:+Assael_Y/0/1/0/all/0/1">Yannis Assael</a>, <a href="http://arxiv.org/find/cs/1/au:+Denil_M/0/1/0/all/0/1">Misha Denil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00692">
                                    <div class="article-summary-box-inner">
                                        <span>This work describes an interactive decoding method to improve the performance
of visual speech recognition systems using user input to compensate for the
inherent ambiguity of the task. Unlike most phoneme-to-word decoding pipelines,
which produce phonemes and feed these through a finite state transducer, our
method instead expands words in lockstep, facilitating the insertion of
interaction points at each word position. Interaction points enable us to
solicit input during decoding, allowing users to interactively direct the
decoding process. We simulate the behavior of user input using an oracle to
give an automated evaluation, and show promise for the use of this method for
text input.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-F: A Transformer network with effective methods for learning universal sentence representation. (arXiv:2107.00653v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yu Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00653">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer model is widely used in natural language processing for
sentence representation. However, the previous Transformer-based models focus
on function words that have limited meaning in most cases and could merely
extract high-level semantic abstraction features. In this paper, two approaches
are introduced to improve the performance of Transformers. We calculated the
attention score by multiplying the part-of-speech weight vector with the
correlation coefficient, which helps extract the words with more practical
meaning. The weight vector is obtained by the input text sequence based on the
importance of the part-of-speech. Furthermore, we fuse the features of each
layer to make the sentence representation results more comprehensive and
accurate. In experiments, we demonstrate the effectiveness of our model
Transformer-F on three standard text classification datasets. Experimental
results show that our proposed model significantly boosts the performance of
text classification as compared to the baseline model. Specifically, we obtain
a 5.28% relative improvement over the vanilla Transformer on the simple tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalizing Flow based Hidden Markov Models for Classification of Speech Phones with Explainability. (arXiv:2107.00730v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anubhab Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Honore_A/0/1/0/all/0/1">Antoine Honor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1">Saikat Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00730">
                                    <div class="article-summary-box-inner">
                                        <span>In pursuit of explainability, we develop generative models for sequential
data. The proposed models provide state-of-the-art classification results and
robust performance for speech phone classification. We combine modern neural
networks (normalizing flows) and traditional generative models (hidden Markov
models - HMMs). Normalizing flow-based mixture models (NMMs) are used to model
the conditional probability distribution given the hidden state in the HMMs.
Model parameters are learned through judicious combinations of time-tested
Bayesian learning methods and contemporary neural network learning methods. We
mainly combine expectation-maximization (EM) and mini-batch gradient descent.
The proposed generative models can compute likelihood of a data and hence
directly suitable for maximum-likelihood (ML) classification approach. Due to
structural flexibility of HMMs, we can use different normalizing flow models.
This leads to different types of HMMs providing diversity in data modeling
capacity. The diversity provides an opportunity for easy decision fusion from
different models. For a standard speech phone classification setup involving 39
phones (classes) and the TIMIT dataset, we show that the use of standard
features called mel-frequency-cepstral-coeffcients (MFCCs), the proposed
generative models, and the decision fusion together can achieve $86.6\%$
accuracy by generative training only. This result is close to state-of-the-art
results, for examples, $86.2\%$ accuracy of PyTorch-Kaldi toolkit [1], and
$85.1\%$ accuracy using light gated recurrent units [2]. We do not use any
discriminative learning approach and related sophisticated features in this
article.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Max-Mahalanobis Classifiers for Image Classification, Generation and More. (arXiv:2101.00122v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiulong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00122">
                                    <div class="article-summary-box-inner">
                                        <span>Joint Energy-based Model (JEM) of Grathwohl et al. shows that a standard
softmax classifier can be reinterpreted as an energy-based model (EBM) for the
joint distribution p(x,y); the resulting model can be optimized to improve
calibration, robustness, and out-of-distribution detection, while generating
samples rivaling the quality of recent GAN-based approaches. However, the
softmax classifier that JEM exploits is inherently discriminative and its
latent feature space is not well formulated as probabilistic distributions,
which may hinder its potential for image generation and incur training
instability. We hypothesize that generative classifiers, such as Linear
Discriminant Analysis (LDA), might be more suitable for image generation since
generative classifiers model the data generation process explicitly. This paper
therefore investigates an LDA classifier for image classification and
generation. In particular, the Max-Mahalanobis Classifier (MMC), a special case
of LDA, fits our goal very well. We show that our Generative MMC (GMMC) can be
trained discriminatively, generatively, or jointly for image classification and
generation. Extensive experiments on multiple datasets show that GMMC achieves
state-of-the-art discriminative and generative performances, while
outperforming JEM in calibration, adversarial robustness, and
out-of-distribution detection by a significant margin. Our source code is
available at https://github.com/sndnyang/GMMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NTIRE 2021 Multi-modal Aerial View Object Classification Challenge. (arXiv:2107.01189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jerrick Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1">Nathan Inkawhich</a>, <a href="http://arxiv.org/find/cs/1/au:+Nina_O/0/1/0/all/0/1">Oliver Nina</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Bob Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yuru Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songzheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiaqi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Mengru Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gongzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Huanqia Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Chengxue Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_S/0/1/0/all/0/1">Sol Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Miron_C/0/1/0/all/0/1">Casian Miron</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasarica_A/0/1/0/all/0/1">Alexandru Pasarica</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng-Yen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1">Hung-Min Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jiarui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1">Jie Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1">Chia-Ying Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1">Michael Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shangguan_Z/0/1/0/all/0/1">Zhongkai Shangguan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zihe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yifei_X/0/1/0/all/0/1">Xu Yifei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lehan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1">Min Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01189">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce the first Challenge on Multi-modal Aerial View
Object Classification (MAVOC) in conjunction with the NTIRE 2021 workshop at
CVPR. This challenge is composed of two different tracks using EO andSAR
imagery. Both EO and SAR sensors possess different advantages and drawbacks.
The purpose of this competition is to analyze how to use both sets of sensory
information in complementary ways. We discuss the top methods submitted for
this competition and evaluate their results on our blind test set. Our
challenge results show significant improvement of more than 15% accuracy from
our current baselines for each track of the competition</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Deep Learning Technique for Video Segmentation. (arXiv:2107.01153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianfei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1">Fatih Porikli</a>, <a href="http://arxiv.org/find/cs/1/au:+Crandall_D/0/1/0/all/0/1">David Crandall</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01153">
                                    <div class="article-summary-box-inner">
                                        <span>Video segmentation, i.e., partitioning video frames into multiple segments or
objects, plays a critical role in a broad range of practical applications,
e.g., visual effect assistance in movie, scene understanding in autonomous
driving, and virtual background creation in video conferencing, to name a few.
Recently, due to the renaissance of connectionism in computer vision, there has
been an influx of numerous deep learning based approaches that have been
dedicated to video segmentation and delivered compelling performance. In this
survey, we comprehensively review two basic lines of research in this area,
i.e., generic object segmentation (of unknown categories) in videos and video
semantic segmentation, by introducing their respective task settings,
background concepts, perceived need, development history, and main challenges.
We also provide a detailed overview of representative literature on both
methods and datasets. Additionally, we present quantitative performance
comparisons of the reviewed methods on benchmark datasets. At last, we point
out a set of unsolved open issues in this field, and suggest possible
opportunities for further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Fire Detection in Landsat-8 Imagery: a Large-Scale Dataset and a Deep-Learning Study. (arXiv:2101.03409v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Gabriel Henrique de Almeida Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusioka_A/0/1/0/all/0/1">Andr&#xe9; Minoro Fusioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassu_B/0/1/0/all/0/1">Bogdan Tomoyuki Nassu</a>, <a href="http://arxiv.org/find/cs/1/au:+Minetto_R/0/1/0/all/0/1">Rodrigo Minetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03409">
                                    <div class="article-summary-box-inner">
                                        <span>Active fire detection in satellite imagery is of critical importance to the
management of environmental conservation policies, supporting decision-making
and law enforcement. This is a well established field, with many techniques
being proposed over the years, usually based on pixel or region-level
comparisons involving sensor-specific thresholds and neighborhood statistics.
In this paper, we address the problem of active fire detection using deep
learning techniques. In recent years, deep learning techniques have been
enjoying an enormous success in many fields, but their use for active fire
detection is relatively new, with open questions and demand for datasets and
architectures for evaluation. This paper addresses these issues by introducing
a new large-scale dataset for active fire detection, with over 150,000 image
patches (more than 200 GB of data) extracted from Landsat-8 images captured
around the world in August and September 2020, containing wildfires in several
locations. The dataset was split in two parts, and contains 10-band spectral
images with associated outputs, produced by three well known handcrafted
algorithms for active fire detection in the first part, and manually annotated
masks in the second part. We also present a study on how different
convolutional neural network architectures can be used to approximate these
handcrafted algorithms, and how models trained on automatically segmented
patches can be combined to achieve better performance than the original
algorithms - with the best combination having 87.2% precision and 92.4% recall
on our manually annotated dataset. The proposed dataset, source codes and
trained models are available on Github
(https://github.com/pereira-gha/activefire), creating opportunities for further
advances in the field</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness for Image Generation with Uncertain Sensitive Attributes. (arXiv:2106.12182v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalal_A/0/1/0/all/0/1">Ajil Jalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1">Sushrut Karmalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_J/0/1/0/all/0/1">Jessica Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1">Eric Price</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12182">
                                    <div class="article-summary-box-inner">
                                        <span>This work tackles the issue of fairness in the context of generative
procedures, such as image super-resolution, which entail different definitions
from the standard classification setting. Moreover, while traditional group
fairness definitions are typically defined with respect to specified protected
groups -- camouflaging the fact that these groupings are artificial and carry
historical and political motivations -- we emphasize that there are no ground
truth identities. For instance, should South and East Asians be viewed as a
single group or separate groups? Should we consider one race as a whole or
further split by gender? Choosing which groups are valid and who belongs in
them is an impossible dilemma and being &quot;fair&quot; with respect to Asians may
require being &quot;unfair&quot; with respect to South Asians. This motivates the
introduction of definitions that allow algorithms to be \emph{oblivious} to the
relevant groupings.

We define several intuitive notions of group fairness and study their
incompatibilities and trade-offs. We show that the natural extension of
demographic parity is strongly dependent on the grouping, and \emph{impossible}
to achieve obliviously. On the other hand, the conceptually new definition we
introduce, Conditional Proportional Representation, can be achieved obliviously
through Posterior Sampling. Our experiments validate our theoretical results
and achieve fair image reconstruction using state-of-the-art generative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous-Time Deep Glioma Growth Models. (arXiv:2106.12917v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Petersen_J/0/1/0/all/0/1">Jens Petersen</a>, <a href="http://arxiv.org/find/eess/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/eess/1/au:+Kohler_G/0/1/0/all/0/1">Gregor K&#xf6;hler</a>, <a href="http://arxiv.org/find/eess/1/au:+Jager_P/0/1/0/all/0/1">Paul F. J&#xe4;ger</a>, <a href="http://arxiv.org/find/eess/1/au:+Zimmerer_D/0/1/0/all/0/1">David Zimmerer</a>, <a href="http://arxiv.org/find/eess/1/au:+Neuberger_U/0/1/0/all/0/1">Ulf Neuberger</a>, <a href="http://arxiv.org/find/eess/1/au:+Wick_W/0/1/0/all/0/1">Wolfgang Wick</a>, <a href="http://arxiv.org/find/eess/1/au:+Debus_J/0/1/0/all/0/1">J&#xfc;rgen Debus</a>, <a href="http://arxiv.org/find/eess/1/au:+Heiland_S/0/1/0/all/0/1">Sabine Heiland</a>, <a href="http://arxiv.org/find/eess/1/au:+Bendszus_M/0/1/0/all/0/1">Martin Bendszus</a>, <a href="http://arxiv.org/find/eess/1/au:+Vollmuth_P/0/1/0/all/0/1">Philipp Vollmuth</a>, <a href="http://arxiv.org/find/eess/1/au:+Maier_Hein_K/0/1/0/all/0/1">Klaus H. Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12917">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to estimate how a tumor might evolve in the future could have
tremendous clinical benefits, from improved treatment decisions to better dose
distribution in radiation therapy. Recent work has approached the glioma growth
modeling problem via deep learning and variational inference, thus learning
growth dynamics entirely from a real patient data distribution. So far, this
approach was constrained to predefined image acquisition intervals and
sequences of fixed length, which limits its applicability in more realistic
scenarios. We overcome these limitations by extending Neural Processes, a class
of conditional generative models for stochastic time series, with a
hierarchical multi-scale representation encoding including a spatio-temporal
attention mechanism. The result is a learned growth model that can be
conditioned on an arbitrary number of observations, and that can produce a
distribution of temporally consistent growth trajectories on a continuous time
axis. On a dataset of 379 patients, the approach successfully captures both
global and finer-grained variations in the images, exhibiting superior
performance compared to other learned growth models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topo-boundary: A Benchmark Dataset on Topological Road-boundary Detection Using Aerial Images for Autonomous Driving. (arXiv:2103.17119v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhenhua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17119">
                                    <div class="article-summary-box-inner">
                                        <span>Road-boundary detection is important for autonomous driving. It can be used
to constrain autonomous vehicles running on road areas to ensure driving
safety. Compared with online road-boundary detection using on-vehicle
cameras/Lidars, offline detection using aerial images could alleviate the
severe occlusion issue. Moreover, the offline detection results can be directly
employed to annotate high-definition (HD) maps. In recent years, deep-learning
technologies have been used in offline detection. But there still lacks a
publicly available dataset for this task, which hinders the research progress
in this area. So in this paper, we propose a new benchmark dataset, named
\textit{Topo-boundary}, for offline topological road-boundary detection. The
dataset contains 25,295 $1000\times1000$-sized 4-channel aerial images. Each
image is provided with 8 training labels for different sub-tasks. We also
design a new entropy-based metric for connectivity evaluation, which could
better handle noises or outliers. We implement and evaluate 3
segmentation-based baselines and 5 graph-based baselines using the dataset. We
also propose a new imitation-learning-based baseline which is enhanced from our
previous work. The superiority of our enhancement is demonstrated from the
comparison. The dataset and our-implemented code for the baselines are
available at \texttt{\url{https://tonyxuqaq.github.io/Topo-boundary/}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HandVoxNet++: 3D Hand Shape and Pose Estimation using Voxel-Based Neural Networks. (arXiv:2107.01205v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jameel Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimada_S/0/1/0/all/0/1">Soshi Shimada</a>, <a href="http://arxiv.org/find/cs/1/au:+Elhayek_A/0/1/0/all/0/1">Ahmed Elhayek</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sk Aziz Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01205">
                                    <div class="article-summary-box-inner">
                                        <span>3D hand shape and pose estimation from a single depth map is a new and
challenging computer vision problem with many applications. Existing methods
addressing it directly regress hand meshes via 2D convolutional neural
networks, which leads to artifacts due to perspective distortions in the
images. To address the limitations of the existing methods, we develop
HandVoxNet++, i.e., a voxel-based deep network with 3D and graph convolutions
trained in a fully supervised manner. The input to our network is a 3D
voxelized-depth-map-based on the truncated signed distance function (TSDF).
HandVoxNet++ relies on two hand shape representations. The first one is the 3D
voxelized grid of hand shape, which does not preserve the mesh topology and
which is the most accurate representation. The second representation is the
hand surface that preserves the mesh topology. We combine the advantages of
both representations by aligning the hand surface to the voxelized hand shape
either with a new neural Graph-Convolutions-based Mesh Registration
(GCN-MeshReg) or classical segment-wise Non-Rigid Gravitational Approach
(NRGA++) which does not rely on training data. In extensive evaluations on
three public benchmarks, i.e., SynHand5M, depth-based HANDS19 challenge and
HO-3D, the proposed HandVoxNet++ achieves the state-of-the-art performance. In
this journal extension of our previous approach presented at CVPR 2020, we gain
41.09% and 13.7% higher shape alignment accuracy on SynHand5M and HANDS19
datasets, respectively. Our method is ranked first on the HANDS19 challenge
dataset (Task 1: Depth-Based 3D Hand Pose Estimation) at the moment of the
submission of our results to the portal in August 2020.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Marching Cubes. (arXiv:2106.11272v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiqin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11272">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Neural Marching Cubes (NMC), a data-driven approach for
extracting a triangle mesh from a discretized implicit field. Classical MC is
defined by coarse tessellation templates isolated to individual cubes. While
more refined tessellations have been proposed, they all make heuristic
assumptions, such as trilinearity, when determining the vertex positions and
local mesh topologies in each cube. In principle, none of these approaches can
reconstruct geometric features that reveal coherence or dependencies between
nearby cubes (e.g., a sharp edge), as such information is unaccounted for,
resulting in poor estimates of the true underlying implicit field. To tackle
these challenges, we re-cast MC from a deep learning perspective, by designing
tessellation templates more apt at preserving geometric features, and learning
the vertex positions and mesh topologies from training meshes, to account for
contextual information from nearby cubes. We develop a compact per-cube
parameterization to represent the output triangle mesh, while being compatible
with neural processing, so that a simple 3D convolutional network can be
employed for the training. We show that all topological cases in each cube that
are applicable to our design can be easily derived using our representation,
and the resulting tessellations can also be obtained naturally and efficiently
by following a few design guidelines. In addition, our network learns local
features with limited receptive fields, hence it generalizes well to new shapes
and new datasets. We evaluate our neural MC approach by quantitative and
qualitative comparisons to all well-known MC variants. In particular, we
demonstrate the ability of our network to recover sharp features such as edges
and corners, a long-standing issue of MC and its variants. Our network also
reconstructs local mesh topologies more accurately than previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Plant Cover Estimation with Convolutional Neural Networks. (arXiv:2106.11154v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korschens_M/0/1/0/all/0/1">Matthias K&#xf6;rschens</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodesheim_P/0/1/0/all/0/1">Paul Bodesheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Romermann_C/0/1/0/all/0/1">Christine R&#xf6;mermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucher_S/0/1/0/all/0/1">Solveig Franziska Bucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Migliavacca_M/0/1/0/all/0/1">Mirco Migliavacca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulrich_J/0/1/0/all/0/1">Josephine Ulrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Denzler_J/0/1/0/all/0/1">Joachim Denzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11154">
                                    <div class="article-summary-box-inner">
                                        <span>Monitoring the responses of plants to environmental changes is essential for
plant biodiversity research. This, however, is currently still being done
manually by botanists in the field. This work is very laborious, and the data
obtained is, though following a standardized method to estimate plant coverage,
usually subjective and has a coarse temporal resolution. To remedy these
caveats, we investigate approaches using convolutional neural networks (CNNs)
to automatically extract the relevant data from images, focusing on plant
community composition and species coverages of 9 herbaceous plant species. To
this end, we investigate several standard CNN architectures and different
pretraining methods. We find that we outperform our previous approach at higher
image resolutions using a custom CNN with a mean absolute error of 5.16%. In
addition to these investigations, we also conduct an error analysis based on
the temporal aspect of the plant cover images. This analysis gives insight into
where problems for automatic approaches lie, like occlusion and likely
misclassifications caused by temporal changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReGO: Reference-Guided Outpainting for Scenery Image. (arXiv:2106.10601v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaxiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xueming Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Li Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10601">
                                    <div class="article-summary-box-inner">
                                        <span>We aim to tackle the challenging yet practical scenery image outpainting task
in this work. Recently, generative adversarial learning has significantly
advanced the image outpainting by producing semantic consistent content for the
given image. However, the existing methods always suffer from the blurry
texture and the artifacts of the generative part, making the overall
outpainting results lack authenticity. To overcome the weakness, this work
investigates a principle way to synthesize texture-rich results by borrowing
pixels from its neighbors (\ie, reference images), named
\textbf{Re}ference-\textbf{G}uided \textbf{O}utpainting (ReGO). Particularly,
the ReGO designs an Adaptive Content Selection (ACS) module to transfer the
pixel of reference images for texture compensating of the target one. To
prevent the style of the generated part from being affected by the reference
images, a style ranking loss is further proposed to augment the ReGO to
synthesize style-consistent results. Extensive experiments on two popular
benchmarks, NS6K~\cite{yangzx} and NS8K~\cite{wang}, well demonstrate the
effectiveness of our ReGO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fourier Transform Approximation as an Auxiliary Task for Image Classification. (arXiv:2106.11478v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chen Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11478">
                                    <div class="article-summary-box-inner">
                                        <span>Image reconstruction is likely the most predominant auxiliary task for image
classification, but we would like to think twice about this convention. In this
paper, we investigated &quot;approximating the Fourier Transform of the input image&quot;
as a potential alternative, in the hope that it may further boost the
performances on the primary task or introduce novel constraints not well
covered by image reconstruction. We experimented with five popular
classification architectures on the CIFAR-10 dataset, and the empirical results
indicated that our proposed auxiliary task generally improves the
classification accuracy. More notably, the results showed that in certain cases
our proposed auxiliary task may enhance the classifiers&#x27; resistance to
adversarial attacks generated using the fast gradient sign method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Training Enhances Online Continual Learning. (arXiv:2103.14010v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gallardo_J/0/1/0/all/0/1">Jhair Gallardo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayes_T/0/1/0/all/0/1">Tyler L. Hayes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1">Christopher Kanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14010">
                                    <div class="article-summary-box-inner">
                                        <span>In continual learning, a system must incrementally learn from a
non-stationary data stream without catastrophic forgetting. Recently, multiple
methods have been devised for incrementally learning classes on large-scale
image classification tasks, such as ImageNet. State-of-the-art continual
learning methods use an initial supervised pre-training phase, in which the
first 10% - 50% of the classes in a dataset are used to learn representations
in an offline manner before continual learning of new classes begins. We
hypothesize that self-supervised pre-training could yield features that
generalize better than supervised learning, especially when the number of
samples used for pre-training is small. We test this hypothesis using the
self-supervised MoCo-V2, Barlow Twins, and SwAV algorithms. On ImageNet, we
find that these methods outperform supervised pre-training considerably for
online continual learning, and the gains are larger when fewer samples are
available. Our findings are consistent across three online continual learning
algorithms. Our best system achieves a 14.95% relative increase in top-1
accuracy on class incremental ImageNet over the prior state of the art for
online continual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Clinical Outcomes in COVID-19 using Radiomics and Deep Learning on Chest Radiographs: A Multi-Institutional Study. (arXiv:2007.08028v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bae_J/0/1/0/all/0/1">Joseph Bae</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kapse_S/0/1/0/all/0/1">Saarthak Kapse</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gattu_R/0/1/0/all/0/1">Rishabh Gattu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Syed Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shah_N/0/1/0/all/0/1">Neal Shah</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marshall_C/0/1/0/all/0/1">Colin Marshall</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pierce_J/0/1/0/all/0/1">Jonathan Pierce</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Phatak_T/0/1/0/all/0/1">Tej Phatak</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1">Amit Gupta</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Green_J/0/1/0/all/0/1">Jeremy Green</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Madan_N/0/1/0/all/0/1">Nikhil Madan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Prasanna_P/0/1/0/all/0/1">Prateek Prasanna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08028">
                                    <div class="article-summary-box-inner">
                                        <span>We predict mechanical ventilation requirement and mortality using
computational modeling of chest radiographs (CXRs) for coronavirus disease 2019
(COVID-19) patients. This two-center, retrospective study analyzed 530
deidentified CXRs from 515 COVID-19 patients treated at Stony Brook University
Hospital and Newark Beth Israel Medical Center between March and August 2020.
DL and machine learning classifiers to predict mechanical ventilation
requirement and mortality were trained and evaluated using patient CXRs. A
novel radiomic embedding framework was also explored for outcome prediction.
All results are compared against radiologist grading of CXRs (zone-wise expert
severity scores). Radiomic and DL classification models had mAUCs of
0.78+/-0.02 and 0.81+/-0.04, compared with expert scores mAUCs of 0.75+/-0.02
and 0.79+/-0.05 for mechanical ventilation requirement and mortality
prediction, respectively. Combined classifiers using both radiomics and expert
severity scores resulted in mAUCs of 0.79+/-0.04 and 0.83+/-0.04 for each
prediction task, demonstrating improvement over either artificial intelligence
or radiologist interpretation alone. Our results also suggest instances where
inclusion of radiomic features in DL improves model predictions, something that
might be explored in other pathologies. The models proposed in this study and
the prognostic information they provide might aid physician decision making and
resource allocation during the COVID-19 pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Outlier-Robust Estimation: Hardness, Minimally Tuned Algorithms, and Applications. (arXiv:2007.15109v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonante_P/0/1/0/all/0/1">Pasquale Antonante</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzoumas_V/0/1/0/all/0/1">Vasileios Tzoumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Heng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlone_L/0/1/0/all/0/1">Luca Carlone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15109">
                                    <div class="article-summary-box-inner">
                                        <span>Nonlinear estimation in robotics and vision is typically plagued with
outliers due to wrong data association, or to incorrect detections from signal
processing and machine learning methods. This paper introduces two unifying
formulations for outlier-robust estimation, Generalized Maximum Consensus
(G-MC) and Generalized Truncated Least Squares (G-TLS), and investigates
fundamental limits, practical algorithms, and applications. Our first
contribution is a proof that outlier-robust estimation is inapproximable: in
the worst case, it is impossible to (even approximately) find the set of
outliers, even with slower-than-polynomial-time algorithms (particularly,
algorithms running in quasi-polynomial time). As a second contribution, we
review and extend two general-purpose algorithms. The first, Adaptive Trimming
(ADAPT), is combinatorial, and is suitable for G-MC; the second, Graduated
Non-Convexity (GNC), is based on homotopy methods, and is suitable for G-TLS.
We extend ADAPT and GNC to the case where the user does not have prior
knowledge of the inlier-noise statistics (or the statistics may vary over time)
and is unable to guess a reasonable threshold to separate inliers from outliers
(as the one commonly used in RANSAC). We propose the first minimally tuned
algorithms for outlier rejection, that dynamically decide how to separate
inliers from outliers. Our third contribution is an evaluation of the proposed
algorithms on robot perception problems: mesh registration, image-based object
detection (shape alignment), and pose graph optimization. ADAPT and GNC execute
in real-time, are deterministic, outperform RANSAC, and are robust up to 80-90%
outliers. Their minimally tuned versions also compare favorably with the state
of the art, even though they do not rely on a noise bound for the inliers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VMAF And Variants: Towards A Unified VQA. (arXiv:2103.07770v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Topiwala_P/0/1/0/all/0/1">Pankaj Topiwala</a>, <a href="http://arxiv.org/find/eess/1/au:+Dai_W/0/1/0/all/0/1">Wei Dai</a>, <a href="http://arxiv.org/find/eess/1/au:+Pian_J/0/1/0/all/0/1">Jiangfeng Pian</a>, <a href="http://arxiv.org/find/eess/1/au:+Biondi_K/0/1/0/all/0/1">Katalina Biondi</a>, <a href="http://arxiv.org/find/eess/1/au:+Krovvidi_A/0/1/0/all/0/1">Arvind Krovvidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07770">
                                    <div class="article-summary-box-inner">
                                        <span>Video quality assessment (VQA) is now a fastgrowing subject, beginning to
mature in the full reference (FR) case, while the burgeoning no reference (NR)
case remains challenging. We investigate variants of the popular VMAF video
quality assessment algorithm for the FR case, using support vector regression
and feedforward neural networks, and extend it to the NR case, using the same
learning architectures, to develop a partially unified framework for VQA. When
heavily trained, algorithms such as VMAF perform well on test datasets, with
90%+ match; but predicting performance in the wild is better done by
training/testing from scratch, as we do. Even from scratch, we achieve 90%+
performance in FR, with gains over VMAF. And we greatly reduce complexity vs.
leading recent NR algorithms, VIDEVAL, RAPIQUE, yet exceed 80% in SRCC. In our
preliminary testing, we find the improvements in trainability, while also
constraining computational complexity, as quite encouraging, suggesting further
study and analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointGuard: Provably Robust 3D Point Cloud Classification. (arXiv:2103.03046v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongbin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jinyuan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03046">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud classification has many safety-critical applications such as
autonomous driving and robotic grasping. However, several studies showed that
it is vulnerable to adversarial attacks. In particular, an attacker can make a
classifier predict an incorrect label for a 3D point cloud via carefully
modifying, adding, and/or deleting a small number of its points. Randomized
smoothing is state-of-the-art technique to build certifiably robust 2D image
classifiers. However, when applied to 3D point cloud classification, randomized
smoothing can only certify robustness against adversarially modified points.

In this work, we propose PointGuard, the first defense that has provable
robustness guarantees against adversarially modified, added, and/or deleted
points. Specifically, given a 3D point cloud and an arbitrary point cloud
classifier, our PointGuard first creates multiple subsampled point clouds, each
of which contains a random subset of the points in the original point cloud;
then our PointGuard predicts the label of the original point cloud as the
majority vote among the labels of the subsampled point clouds predicted by the
point cloud classifier. Our first major theoretical contribution is that we
show PointGuard provably predicts the same label for a 3D point cloud when the
number of adversarially modified, added, and/or deleted points is bounded. Our
second major theoretical contribution is that we prove the tightness of our
derived bound when no assumptions on the point cloud classifier are made.
Moreover, we design an efficient algorithm to compute our certified robustness
guarantees. We also empirically evaluate PointGuard on ModelNet40 and ScanNet
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The 2021 Image Similarity Dataset and Challenge. (arXiv:2106.09672v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Douze_M/0/1/0/all/0/1">Matthijs Douze</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolias_G/0/1/0/all/0/1">Giorgos Tolias</a>, <a href="http://arxiv.org/find/cs/1/au:+Pizzi_E/0/1/0/all/0/1">Ed Pizzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papakipos_Z/0/1/0/all/0/1">Zo&#xeb; Papakipos</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_L/0/1/0/all/0/1">Lowik Chanussot</a>, <a href="http://arxiv.org/find/cs/1/au:+Radenovic_F/0/1/0/all/0/1">Filip Radenovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenicek_T/0/1/0/all/0/1">Tomas Jenicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Maximov_M/0/1/0/all/0/1">Maxim Maximov</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taix&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1">Ismail Elezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chum_O/0/1/0/all/0/1">Ond&#x159;ej Chum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1">Cristian Canton Ferrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09672">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a new benchmark for large-scale image similarity
detection. This benchmark is used for the Image Similarity Challenge at
NeurIPS&#x27;21 (ISC2021). The goal is to determine whether a query image is a
modified copy of any image in a reference corpus of size 1~million. The
benchmark features a variety of image transformations such as automated
transformations, hand-crafted image edits and machine-learning based
manipulations. This mimics real-life cases appearing in social media, for
example for integrity-related problems dealing with misinformation and
objectionable content. The strength of the image manipulations, and therefore
the difficulty of the benchmark, is calibrated according to the performance of
a set of baseline approaches. Both the query and reference set contain a
majority of &quot;distractor&quot; images that do not match, which corresponds to a
real-life needle-in-haystack setting, and the evaluation metric reflects that.
We expect the DISC21 benchmark to promote image copy detection as an important
and challenging computer vision task and refresh the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-visual Attentive Fusion for Continuous Emotion Recognition. (arXiv:2107.01175v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the development set,
the achieved CCC is 0.410 for valence and 0.661 for arousal, which
significantly outperforms the baseline method with the corresponding CCC of
0.210 and 0.230 for valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in the Creative Industries: A Review. (arXiv:2007.12391v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1">David Bull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the &#x60;creator&#x27;, remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Relationship Forecasting in Videos. (arXiv:2107.01181v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mi_L/0/1/0/all/0/1">Li Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1">Yangjun Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenzhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01181">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world scenarios often require the anticipation of object interactions in
unknown future, which would assist the decision-making process of both humans
and agents. To meet this challenge, we present a new task named Visual
Relationship Forecasting (VRF) in videos to explore the prediction of visual
relationships in a reasoning manner. Specifically, given a subject-object pair
with H existing frames, VRF aims to predict their future interactions for the
next T frames without visual evidence. To evaluate the VRF task, we introduce
two video datasets named VRF-AG and VRF-VidOR, with a series of
spatio-temporally localized visual relation annotations in a video. These two
datasets densely annotate 13 and 35 visual relationships in 1923 and 13447
video clips, respectively. In addition, we present a novel Graph Convolutional
Transformer (GCT) framework, which captures both object-level and frame-level
dependencies by spatio-temporal Graph Convolution Network and Transformer.
Experimental results on both VRF-AG and VRF-VidOR datasets demonstrate that GCT
outperforms the state-of-the-art sequence modelling methods on visual
relationship forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Representation Learning for Hand Shape Estimation. (arXiv:2106.04324v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmermann_C/0/1/0/all/0/1">Christian Zimmermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Argus_M/0/1/0/all/0/1">Max Argus</a>, <a href="http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04324">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents improvements in monocular hand shape estimation by
building on top of recent advances in unsupervised learning. We extend momentum
contrastive learning and contribute a structured collection of hand images,
well suited for visual representation learning, which we call HanCo. We find
that the representation learned by established contrastive learning methods can
be improved significantly by exploiting advanced background removal techniques
and multi-view information. These allow us to generate more diverse instance
pairs than those obtained by augmentations commonly used in exemplar based
approaches. Our method leads to a more suitable representation for the hand
shape estimation task and shows a 4.7% reduction in mesh error and a 3.6%
improvement in F-score compared to an ImageNet pretrained baseline. We make our
benchmark dataset publicly available, to encourage further research into this
direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of Loss Functions to Improve Generalizability of Deep Metric Learning methods. (arXiv:2107.01130v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01130">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Metric Learning (DML) learns a non-linear semantic embedding from input
data that brings similar pairs together while keeps dissimilar data away from
each other. To this end, many different methods are proposed in the last decade
with promising results in various applications. The success of a DML algorithm
greatly depends on its loss function. However, no loss function is perfect, and
it deals only with some aspects of an optimal similarity embedding. Besides,
the generalizability of the DML on unseen categories during the test stage is
an important matter that is not considered by existing loss functions. To
address these challenges, we propose novel approaches to combine different
losses built on top of a shared deep feature extractor. The proposed ensemble
of losses enforces the deep model to extract features that are consistent with
all losses. Since the selected losses are diverse and each emphasizes different
aspects of an optimal semantic embedding, our effective combining methods yield
a considerable improvement over any individual loss and generalize well on
unseen categories. Here, there is no limitation in choosing loss functions, and
our methods can work with any set of existing ones. Besides, they can optimize
each loss function as well as its weight in an end-to-end paradigm with no need
to adjust any hyper-parameter. We evaluate our methods on some popular datasets
from the machine vision domain in conventional Zero-Shot-Learning (ZSL)
settings. The results are very encouraging and show that our methods outperform
all baseline losses by a large margin in all datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Incomplete is Contrastive Learning? AnInter-intra Variant Dual Representation Method forSelf-supervised Video Recognition. (arXiv:2107.01194v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhengyang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01194">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning applied to self-supervised representation learning has
seen a resurgence in deep models. In this paper, we find that existing
contrastive learning based solutions for self-supervised video recognition
focus on inter-variance encoding but ignore the intra-variance existing in
clips within the same video. We thus propose to learn dual representations for
each clip which (\romannumeral 1) encode intra-variance through a shuffle-rank
pretext task; (\romannumeral 2) encode inter-variance through a temporal
coherent contrastive loss. Experiment results show that our method plays an
essential role in balancing inter and intra variances and brings consistent
performance gains on multiple backbones and contrastive learning frameworks.
Integrated with SimCLR and pretrained on Kinetics-400, our method achieves
$\textbf{82.0\%}$ and $\textbf{51.2\%}$ downstream classification accuracy on
UCF101 and HMDB51 test sets respectively and $\textbf{46.1\%}$ video retrieval
accuracy on UCF101, outperforming both pretext-task based and contrastive
learning based counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSN: Multi-Style Network for Trajectory Prediction. (arXiv:2107.00932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1">Conghao Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_B/0/1/0/all/0/1">Beihao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1">Qinmu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+You_X/0/1/0/all/0/1">Xinge You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00932">
                                    <div class="article-summary-box-inner">
                                        <span>It is essential but challenging to predict future trajectories of various
agents in complex scenes. Whether it is internal personality factors of agents,
interactive behavior of the neighborhood, or the influence of surroundings, it
will have an impact on their future behavior styles. It means that even for the
same physical type of agents, there are huge differences in their behavior
preferences. Although recent works have made significant progress in studying
agents&#x27; multi-modal plannings, most of them still apply the same prediction
strategy to all agents, which makes them difficult to fully show the multiple
styles of vast agents. In this paper, we propose the Multi-Style Network (MSN)
to focus on this problem by divide agents&#x27; preference styles into several
hidden behavior categories adaptively and train each category&#x27;s prediction
network separately, therefore giving agents all styles of predictions
simultaneously. Experiments demonstrate that our deterministic MSN-D and
generative MSN-G outperform many recent state-of-the-art methods and show
better multi-style characteristics in the visualized results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shi_Z/0/1/0/all/0/1">Zenglin Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mettes_P/0/1/0/all/0/1">Pascal Mettes</a>, <a href="http://arxiv.org/find/eess/1/au:+Maji_S/0/1/0/all/0/1">Subhransu Maji</a>, <a href="http://arxiv.org/find/eess/1/au:+Snoek_C/0/1/0/all/0/1">Cees G. M. Snoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01125">
                                    <div class="article-summary-box-inner">
                                        <span>The deep image prior has demonstrated the remarkable ability that untrained
networks can address inverse imaging problems, such as denoising, inpainting
and super-resolution, by optimizing on just a single degraded image. Despite
its promise, it suffers from two limitations. First, it remains unclear how one
can control the prior beyond the choice of the network architecture. Second, it
requires an oracle to determine when to stop the optimization as the
performance degrades after reaching a peak. In this paper, we study the deep
image prior from a spectral bias perspective to address these problems. By
introducing a frequency-band correspondence measure, we observe that deep image
priors for inverse imaging exhibit a spectral bias during optimization, where
low-frequency image signals are learned faster and better than high-frequency
noise signals. This pinpoints why degraded images can be denoised or inpainted
when the optimization is stopped at the right time. Based on our observations,
we propose to control the spectral bias in the deep image prior to prevent
performance degradation and to speed up optimization convergence. We do so in
the two core layer types of inverse imaging networks: the convolution layer and
the upsampling layer. We present a Lipschitz-controlled approach for the
convolution and a Gaussian-controlled approach for the upsampling layer. We
further introduce a stopping criterion to avoid superfluous computation. The
experiments on denoising, inpainting and super-resolution show that our method
no longer suffers from performance degradation during optimization, relieving
us from the need for an oracle criterion to stop early. We further outline a
stopping criterion to avoid superfluous computation. Finally, we show that our
approach obtains favorable restoration results compared to current approaches,
across all tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive Learners With FlatNCE. (arXiv:2107.01152v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xuan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1">Liqun Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1">Shuyang Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Chung_T/0/1/0/all/0/1">Tagyoung Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeng_B/0/1/0/all/0/1">Belinda Zeng</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_W/0/1/0/all/0/1">Wenlian Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Fan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01152">
                                    <div class="article-summary-box-inner">
                                        <span>InfoNCE-based contrastive representation learners, such as SimCLR, have been
tremendously successful in recent years. However, these contrastive schemes are
notoriously resource demanding, as their effectiveness breaks down with
small-batch training (i.e., the log-K curse, whereas K is the batch-size). In
this work, we reveal mathematically why contrastive learners fail in the
small-batch-size regime, and present a novel simple, non-trivial contrastive
objective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no
longer explicitly appeals to a discriminative classification goal for
contrastive learning. Theoretically, we show FlatNCE is the mathematical dual
formulation of InfoNCE, thus bridging the classical literature on energy
modeling; and empirically, we demonstrate that, with minimal modification of
code, FlatNCE enables immediate performance boost independent of the
subject-matter engineering efforts. The significance of this work is furthered
by the powerful generalization of contrastive learning techniques, and the
introduction of new tools to monitor and diagnose contrastive training. We
substantiate our claims with empirical evidence on CIFAR10, ImageNet, and other
datasets, where FlatNCE consistently outperforms InfoNCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sub-millisecond Video Synchronization of Multiple Android Smartphones. (arXiv:2107.00987v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhmetyanov_A/0/1/0/all/0/1">Azat Akhmetyanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kornilova_A/0/1/0/all/0/1">Anastasiia Kornilova</a>, <a href="http://arxiv.org/find/cs/1/au:+Faizullin_M/0/1/0/all/0/1">Marsel Faizullin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pozo_D/0/1/0/all/0/1">David Pozo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_G/0/1/0/all/0/1">Gonzalo Ferrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00987">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of building an affordable easy-to-setup
synchronized multi-view camera system, which is in demand for many Computer
Vision and Robotics applications in high-dynamic environments. In our work, we
propose a solution for this problem - a publicly-available Android application
for synchronized video recording on multiple smartphones with sub-millisecond
accuracy. We present a generalized mathematical model of timestamping for
Android smartphones and prove its applicability on 47 different physical
devices. Also, we estimate the time drift parameter for those smartphones,
which is less than 1.2 millisecond per minute for most of the considered
devices, that makes smartphones&#x27; camera system a worthy analog for professional
multi-view systems. Finally, we demonstrate Android-app performance on the
camera system built from Android smartphones quantitatively, showing less than
300 microseconds synchronization error, and qualitatively - on panorama
stitching task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of end-to-end neural network architectures and data augmentation methods for automatic infant motility assessment using wearable sensors. (arXiv:2107.01086v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Airaksinen_M/0/1/0/all/0/1">Manu Airaksinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanhatalo_S/0/1/0/all/0/1">Sampsa Vanhatalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasanen_O/0/1/0/all/0/1">Okko R&#xe4;s&#xe4;nen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01086">
                                    <div class="article-summary-box-inner">
                                        <span>Infant motility assessment using intelligent wearables is a promising new
approach for assessment of infant neurophysiological development, and where
efficient signal analysis plays a central role. This study investigates the use
of different end-to-end neural network architectures for processing infant
motility data from wearable sensors. We focus on the performance and
computational burden of alternative sensor encoder and time-series modelling
modules and their combinations. In addition, we explore the benefits of data
augmentation methods in ideal and non-ideal recording conditions. The
experiments are conducted using a data-set of multi-sensor movement recordings
from 7-month-old infants, as captured by a recently proposed smart jumpsuit for
infant motility assessment. Our results indicate that the choice of the encoder
module has a major impact on classifier performance. For sensor encoders, the
best performance was obtained with parallel 2-dimensional convolutions for
intra-sensor channel fusion with shared weights for all sensors. The results
also indicate that a relatively compact feature representation is obtainable
for within-sensor feature extraction without a drastic loss to classifier
performance. Comparison of time-series models revealed that feed-forward
dilated convolutions with residual and skip connections outperformed all
RNN-based models in performance, training time, and training stability. The
experiments also indicate that data augmentation improves model robustness in
simulated packet loss or sensor dropout scenarios. In particular, signal- and
sensor-dropout-based augmentation strategies provided considerable boosts to
performance without negatively affecting the baseline performance. Overall the
results provide tangible suggestions on how to optimize end-to-end neural
network training for multi-channel movement sensor data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-view Geo-localization with Evolving Transformer. (arXiv:2107.00842v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongji Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiufan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yingying Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00842">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of cross-view geo-localization, which
estimates the geospatial location of a street view image by matching it with a
database of geo-tagged aerial images. The cross-view matching task is extremely
challenging due to drastic appearance and geometry differences across views.
Unlike existing methods that predominantly fall back on CNN, here we devise a
novel evolving geo-localization Transformer (EgoTR) that utilizes the
properties of self-attention in Transformer to model global dependencies, thus
significantly decreasing visual ambiguities in cross-view geo-localization. We
also exploit the positional encoding of Transformer to help the EgoTR
understand and correspond geometric configurations between ground and aerial
images. Compared to state-of-the-art methods that impose strong assumption on
geometry knowledge, the EgoTR flexibly learns the positional embeddings through
the training objective and hence becomes more practical in many real-world
scenarios. Although Transformer is well suited to our task, its vanilla
self-attention mechanism independently interacts within image patches in each
layer, which overlooks correlations between layers. Instead, this paper propose
a simple yet effective self-cross attention mechanism to improve the quality of
learned representations. The self-cross attention models global dependencies
between adjacent layers, which relates between image patches while modeling how
features evolve in the previous layer. As a result, the proposed self-cross
attention leads to more stable training, improves the generalization ability
and encourages representations to keep evolving as the network goes deeper.
Extensive experiments demonstrate that our EgoTR performs favorably against
state-of-the-art methods on standard, fine-grained and cross-dataset cross-view
geo-localization tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parasitic Egg Detection and Classification in Low-cost Microscopic Images using Transfer Learning. (arXiv:2107.00968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suwannaphong_T/0/1/0/all/0/1">Thanaphon Suwannaphong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavana_S/0/1/0/all/0/1">Sawaphob Chavana</a>, <a href="http://arxiv.org/find/cs/1/au:+Tongsom_S/0/1/0/all/0/1">Sahapol Tongsom</a>, <a href="http://arxiv.org/find/cs/1/au:+Palasuwan_D/0/1/0/all/0/1">Duangdao Palasuwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chalidabhongse_T/0/1/0/all/0/1">Thanarat H. Chalidabhongse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00968">
                                    <div class="article-summary-box-inner">
                                        <span>Intestinal parasitic infection leads to several morbidities to humans
worldwide, especially in tropical countries. The traditional diagnosis usually
relies on manual analysis from microscopic images which is prone to human error
due to morphological similarity of different parasitic eggs and abundance of
impurities in a sample. Many studies have developed automatic systems for
parasite egg detection to reduce human workload. However, they work with high
quality microscopes, which unfortunately remain unaffordable in some rural
areas. Our work thus exploits a benefit of a low-cost USB microscope. This
instrument however provides poor quality of images due to limitation of
magnification (10x), causing difficulty in parasite detection and species
classification. In this paper, we propose a CNN-based technique using transfer
learning strategy to enhance the efficiency of automatic parasite
classification in poor-quality microscopic images. The patch-based technique
with sliding window is employed to search for location of the eggs. Two
networks, AlexNet and ResNet50, are examined with a trade-off between
architecture size and classification performance. The results show that our
proposed framework outperforms the state-of-the-art object recognition methods.
Our system combined with final decision from an expert may improve the real
faecal examination with low-cost microscopes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Visual Navigation. (arXiv:2107.01151v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haiyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xizhou Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01151">
                                    <div class="article-summary-box-inner">
                                        <span>As a fundamental problem for Artificial Intelligence, multi-agent system
(MAS) is making rapid progress, mainly driven by multi-agent reinforcement
learning (MARL) techniques. However, previous MARL methods largely focused on
grid-world like or game environments; MAS in visually rich environments has
remained less explored. To narrow this gap and emphasize the crucial role of
perception in MAS, we propose a large-scale 3D dataset, CollaVN, for
multi-agent visual navigation (MAVN). In CollaVN, multiple agents are entailed
to cooperatively navigate across photo-realistic environments to reach target
locations. Diverse MAVN variants are explored to make our problem more general.
Moreover, a memory-augmented communication framework is proposed. Each agent is
equipped with a private, external memory to persistently store communication
information. This allows agents to make better use of their past communication
information, enabling more efficient collaboration and robust long-term
planning. In our experiments, several baselines and evaluation metrics are
designed. We also empirically verify the efficacy of our proposed MARL approach
across different MAVN task settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optical Braille Recognition using Circular Hough Transform. (arXiv:2107.00993v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khanam_Z/0/1/0/all/0/1">Zeba Khanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Usmani_A/0/1/0/all/0/1">Atiya Usmani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00993">
                                    <div class="article-summary-box-inner">
                                        <span>Braille has empowered visually challenged community to read and write. But at
the same time, it has created a gap due to widespread inability of non-Braille
users to understand Braille scripts. This gap has fuelled researchers to
propose Optical Braille Recognition techniques to convert Braille documents to
natural language. The main motivation of this work is to cement the
communication gap at academic institutions by translating personal documents of
blind students. This has been accomplished by proposing an economical and
effective technique which digitizes Braille documents using a smartphone
camera. For any given Braille image, a dot detection mechanism based on Hough
transform is proposed which is invariant to skewness, noise and other
deterrents. The detected dots are then clustered into Braille cells using
distance-based clustering algorithm. In succession, the standard physical
parameters of each Braille cells are estimated for feature extraction and
classification as natural language characters. The comprehensive evaluation of
this technique on the proposed dataset of 54 Braille scripts has yielded into
accuracy of 98.71%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation. (arXiv:2107.01079v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammernik_K/0/1/0/all/0/1">Kerstin Hammernik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Cheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01079">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based segmentation methods are vulnerable to unforeseen data
distribution shifts during deployment, e.g. change of image appearances or
contrasts caused by different scanners, unexpected imaging artifacts etc. In
this paper, we present a cooperative framework for training image segmentation
models and a latent space augmentation method for generating hard examples.
Both contributions improve model generalization and robustness with limited
data. The cooperative training framework consists of a fast-thinking network
(FTN) and a slow-thinking network (STN). The FTN learns decoupled image
features and shape features for image reconstruction and segmentation tasks.
The STN learns shape priors for segmentation correction and refinement. The two
networks are trained in a cooperative manner. The latent space augmentation
generates challenging examples for training by masking the decoupled latent
space in both channel-wise and spatial-wise manners. We performed extensive
experiments on public cardiac imaging datasets. Using only 10 subjects from a
single site for training, we demonstrated improved cross-site segmentation
performance and increased robustness against various unforeseen imaging
artifacts compared to strong baseline methods. Particularly, cooperative
training with latent space data augmentation yields 15% improvement in terms of
average Dice score when compared to a standard training method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WiCluster: Passive Indoor 2D/3D Positioning using WiFi without Precise Labels. (arXiv:2107.01002v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karmanov_I/0/1/0/all/0/1">Ilia Karmanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanjani_F/0/1/0/all/0/1">Farhad G. Zanjani</a>, <a href="http://arxiv.org/find/cs/1/au:+Merlin_S/0/1/0/all/0/1">Simone Merlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadampot_I/0/1/0/all/0/1">Ishaque Kadampot</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijkman_D/0/1/0/all/0/1">Daniel Dijkman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01002">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce WiCluster, a new machine learning (ML) approach for passive
indoor positioning using radio frequency (RF) channel state information (CSI).
WiCluster can predict both a zone-level position and a precise 2D or 3D
position, without using any precise position labels during training. Prior
CSI-based indoor positioning work has relied on non-parametric approaches using
digital signal-processing (DSP) and, more recently, parametric approaches
(e.g., fully supervised ML methods). However these do not handle the complexity
of real-world environments well and do not meet requirements for large-scale
commercial deployments: the accuracy of DSP-based method deteriorates
significantly in non-line-of-sight conditions, while supervised ML methods need
large amounts of hard-to-acquire centimeter accuracy position labels. In
contrast, WiCluster is both precise and requires weaker label-information that
can be easily collected. Our first contribution is a novel dimensionality
reduction method for charting. It combines a triplet-loss with a multi-scale
clustering-loss to map the high-dimensional CSI representation to a 2D/3D
latent space. Our second contribution is two weakly supervised losses that map
this latent space into a Cartesian map, resulting in meter-accuracy position
results. These losses only require simple to acquire priors: a sketch of the
floorplan, approximate location of access-point locations and a few CSI packets
that are labeled with the corresponding zone in the floorplan. Thirdly, we
report results and a robustness study for 2D positioning in a single-floor
office building and 3D positioning in a two-floor home to show the robustness
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Usefulness of Unsupervised monitoring in Cultural Heritage Monuments. (arXiv:2107.00964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zafeiropoulos_C/0/1/0/all/0/1">Charalampos Zafeiropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzortzis_I/0/1/0/all/0/1">Ioannis N. Tzortzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rallis_I/0/1/0/all/0/1">Ioannis Rallis</a>, <a href="http://arxiv.org/find/cs/1/au:+Protopapadakis_E/0/1/0/all/0/1">Eftychios Protopapadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1">Nikolaos Doulamis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1">Anastasios Doulamis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00964">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we scrutinize the effectiveness of various clustering
techniques, investigating their applicability in Cultural Heritage monitoring
applications. In the context of this paper, we detect the level of
decomposition and corrosion on the walls of Saint Nicholas fort in Rhodes
utilizing hyperspectral images. A total of 6 different clustering approaches
have been evaluated over a set of 14 different orthorectified hyperspectral
images. Experimental setup in this study involves K-means, Spectral, Meanshift,
DBSCAN, Birch and Optics algorithms. For each of these techniques we evaluate
its performance by the use of performance metrics such as Calinski-Harabasz,
Davies-Bouldin indexes and Silhouette value. In this approach, we evaluate the
outcomes of the clustering methods by comparing them with a set of annotated
images which denotes the ground truth regarding the decomposition and/or
corrosion area of the original images. The results depict that a few clustering
techniques applied on the given dataset succeeded decent accuracy, precision,
recall and f1 scores. Eventually, it was observed that the deterioration was
detected quite accurately.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LensID: A CNN-RNN-Based Framework Towards Lens Irregularity Detection in Cataract Surgery Videos. (arXiv:2107.00875v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ghamsarian_N/0/1/0/all/0/1">Negin Ghamsarian</a>, <a href="http://arxiv.org/find/eess/1/au:+Taschwer_M/0/1/0/all/0/1">Mario Taschwer</a>, <a href="http://arxiv.org/find/eess/1/au:+Putzgruber_Adamitsch_D/0/1/0/all/0/1">Doris Putzgruber-Adamitsch</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarny_S/0/1/0/all/0/1">Stephanie Sarny</a>, <a href="http://arxiv.org/find/eess/1/au:+El_Shabrawi_Y/0/1/0/all/0/1">Yosuf El-Shabrawi</a>, <a href="http://arxiv.org/find/eess/1/au:+Schoeffmann_K/0/1/0/all/0/1">Klaus Schoeffmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00875">
                                    <div class="article-summary-box-inner">
                                        <span>A critical complication after cataract surgery is the dislocation of the lens
implant leading to vision deterioration and eye trauma. In order to reduce the
risk of this complication, it is vital to discover the risk factors during the
surgery. However, studying the relationship between lens dislocation and its
suspicious risk factors using numerous videos is a time-extensive procedure.
Hence, the surgeons demand an automatic approach to enable a larger-scale and,
accordingly, more reliable study. In this paper, we propose a novel framework
as the major step towards lens irregularity detection. In particular, we
propose (I) an end-to-end recurrent neural network to recognize the
lens-implantation phase and (II) a novel semantic segmentation network to
segment the lens and pupil after the implantation phase. The phase recognition
results reveal the effectiveness of the proposed surgical phase recognition
approach. Moreover, the segmentation results confirm the proposed segmentation
network&#x27;s effectiveness compared to state-of-the-art rival approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResIST: Layer-Wise Decomposition of ResNets for Distributed Training. (arXiv:2107.00961v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1">Christopher M. Jermaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00961">
                                    <div class="article-summary-box-inner">
                                        <span>We propose {\rm \texttt{ResIST}}, a novel distributed training protocol for
Residual Networks (ResNets). {\rm \texttt{ResIST}} randomly decomposes a global
ResNet into several shallow sub-ResNets that are trained independently in a
distributed manner for several local iterations, before having their updates
synchronized and aggregated into the global model. In the next round, new
sub-ResNets are randomly generated and the process repeats. By construction,
per iteration, {\rm \texttt{ResIST}} communicates only a small portion of
network parameters to each machine and never uses the full model during
training. Thus, {\rm \texttt{ResIST}} reduces the communication, memory, and
time requirements of ResNet training to only a fraction of the requirements of
previous methods. In comparison to common protocols like data-parallel training
and data-parallel training with local SGD, {\rm \texttt{ResIST}} yields a
decrease in wall-clock training time, while being competitive with respect to
model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Single Image Super-resolution Under Complex Noise. (arXiv:2107.00986v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1">Zongsheng Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jianwen Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00986">
                                    <div class="article-summary-box-inner">
                                        <span>While the researches on single image super-resolution (SISR), especially
equipped with deep neural networks (DNNs), have achieved tremendous successes
recently, they still suffer from two major limitations. Firstly, the real image
degradation is usually unknown and highly variant from one to another, making
it extremely hard to train a single model to handle the general SISR task.
Secondly, most of current methods mainly focus on the downsampling process of
the degradation, but ignore or underestimate the inevitable noise
contamination. For example, the commonly-used independent and identically
distributed (i.i.d.) Gaussian noise distribution always largely deviates from
the real image noise (e.g., camera sensor noise), which limits their
performance in real scenarios. To address these issues, this paper proposes a
model-based unsupervised SISR method to deal with the general SISR task with
unknown degradations. Instead of the traditional i.i.d. Gaussian noise
assumption, a novel patch-based non-i.i.d. noise modeling method is proposed to
fit the complex real noise. Besides, a deep generator parameterized by a DNN is
used to map the latent variable to the high-resolution image, and the
conventional hyper-Laplacian prior is also elaborately embedded into such
generator to further constrain the image gradients. Finally, a Monte Carlo EM
algorithm is designed to solve our model, which provides a general inference
framework to update the image generator both w.r.t. the latent variable and the
network parameters. Comprehensive experiments demonstrate that the proposed
method can evidently surpass the current state of the art (SotA) method (about
1dB PSNR) not only with a slighter model (0.34M vs. 2.40M) but also faster
speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ultrasound Video Transformers for Cardiac Ejection Fraction Estimation. (arXiv:2107.00977v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reynaud_H/0/1/0/all/0/1">Hadrien Reynaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1">Benjamin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Beqiri_A/0/1/0/all/0/1">Arian Beqiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Leeson_P/0/1/0/all/0/1">Paul Leeson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00977">
                                    <div class="article-summary-box-inner">
                                        <span>Cardiac ultrasound imaging is used to diagnose various heart diseases. Common
analysis pipelines involve manual processing of the video frames by expert
clinicians. This suffers from intra- and inter-observer variability. We propose
a novel approach to ultrasound video analysis using a transformer architecture
based on a Residual Auto-Encoder Network and a BERT model adapted for token
classification. This enables videos of any length to be processed. We apply our
model to the task of End-Systolic (ES) and End-Diastolic (ED) frame detection
and the automated computation of the left ventricular ejection fraction. We
achieve an average frame distance of 3.36 frames for the ES and 7.17 frames for
the ED on videos of arbitrary length. Our end-to-end learnable approach can
estimate the ejection fraction with a MAE of 5.95 and $R^2$ of 0.52 in 0.15s
per video, showing that segmentation is not the only way to predict ejection
fraction. Code and models are available at https://github.com/HReynaud/UVT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets. (arXiv:2107.00860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyung_E/0/1/0/all/0/1">Eunyoung Hyung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00860">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of recent Neural Architecture Search (NAS) methods on
various tasks which have shown to output networks that largely outperform
human-designed networks, conventional NAS methods have mostly tackled the
optimization of searching for the network architecture for a single task
(dataset), which does not generalize well across multiple tasks (datasets).
Moreover, since such task-specific methods search for a neural architecture
from scratch for every given task, they incur a large computational cost, which
is problematic when the time and monetary budget are limited. In this paper, we
propose an efficient NAS framework that is trained once on a database
consisting of datasets and pretrained networks and can rapidly search for a
neural architecture for a novel dataset. The proposed MetaD2A (Meta
Dataset-to-Architecture) model can stochastically generate graphs
(architectures) from a given set (dataset) via a cross-modal latent space
learned with amortized meta-learning. Moreover, we also propose a
meta-performance predictor to estimate and select the best architecture without
direct training on target datasets. The experimental results demonstrate that
our model meta-learned on subsets of ImageNet-1K and architectures from
NAS-Bench 201 search space successfully generalizes to multiple unseen datasets
including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU
seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than
NSGANetV2, a transferable NAS method, with comparable performance. We believe
that the MetaD2A proposes a new research direction for rapid NAS as well as
ways to utilize the knowledge from rich databases of datasets and architectures
accumulated over the past years. Code is available at
https://github.com/HayeonLee/MetaD2A.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixed Supervision Learning for Whole Slide Image Classification. (arXiv:2107.00934v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiahui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaodi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiqiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Q/0/1/0/all/0/1">Qi Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris N. Metaxas</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaoting Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00934">
                                    <div class="article-summary-box-inner">
                                        <span>Weak supervision learning on classification labels has demonstrated high
performance in various tasks. When a few pixel-level fine annotations are also
affordable, it is natural to leverage both of the pixel-level (e.g.,
segmentation) and image level (e.g., classification) annotation to further
improve the performance. In computational pathology, however, such weak or
mixed supervision learning is still a challenging task, since the high
resolution of whole slide images makes it unattainable to perform end-to-end
training of classification models. An alternative approach is to analyze such
data by patch-base model training, i.e., using self-supervised learning to
generate pixel-level pseudo labels for patches. However, such methods usually
have model drifting issues, i.e., hard to converge, because the noise
accumulates during the self-training process. To handle those problems, we
propose a mixed supervision learning framework for super high-resolution images
to effectively utilize their various labels (e.g., sufficient image-level
coarse annotations and a few pixel-level fine labels). During the patch
training stage, this framework can make use of coarse image-level labels to
refine self-supervised learning and generate high-quality pixel-level pseudo
labels. A comprehensive strategy is proposed to suppress pixel-level false
positives and false negatives. Three real-world datasets with very large number
of images (i.e., more than 10,000 whole slide images) and various types of
labels are used to evaluate the effectiveness of mixed supervision learning. We
reduced the false positive rate by around one third compared to state of the
art while retaining 100\% sensitivity, in the task of image-level
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Magnification-independent Histopathological Image Classification with Similarity-based Multi-scale Embeddings. (arXiv:2107.01063v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yibao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xingru Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qianni Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01063">
                                    <div class="article-summary-box-inner">
                                        <span>The classification of histopathological images is of great value in both
cancer diagnosis and pathological studies. However, multiple reasons, such as
variations caused by magnification factors and class imbalance, make it a
challenging task where conventional methods that learn from image-label
datasets perform unsatisfactorily in many cases. We observe that tumours of the
same class often share common morphological patterns. To exploit this fact, we
propose an approach that learns similarity-based multi-scale embeddings (SMSE)
for magnification-independent histopathological image classification. In
particular, a pair loss and a triplet loss are leveraged to learn
similarity-based embeddings from image pairs or image triplets. The learned
embeddings provide accurate measurements of similarities between images, which
are regarded as a more effective form of representation for histopathological
morphology than normal image features. Furthermore, in order to ensure the
generated models are magnification-independent, images acquired at different
magnification factors are simultaneously fed to networks during training for
learning multi-scale embeddings. In addition to the SMSE, to eliminate the
impact of class imbalance, instead of using the hard sample mining strategy
that intuitively discards some easy samples, we introduce a new reinforced
focal loss to simultaneously punish hard misclassified samples while
suppressing easy well-classified samples. Experimental results show that the
SMSE improves the performance for histopathological image classification tasks
for both breast and liver cancers by a large margin compared to previous
methods. In particular, the SMSE achieves the best performance on the BreakHis
benchmark with an improvement ranging from 5% to 18% compared to previous
methods using traditional features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition Based on Wrist-worn Sensors. (arXiv:2107.00710v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cote_Allard_U/0/1/0/all/0/1">Ulysse C&#xf4;t&#xe9;-Allard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakobsen_P/0/1/0/all/0/1">Petter Jakobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stautland_A/0/1/0/all/0/1">Andrea Stautland</a>, <a href="http://arxiv.org/find/cs/1/au:+Nordgreen_T/0/1/0/all/0/1">Tine Nordgreen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fasmer_O/0/1/0/all/0/1">Ole Bernt Fasmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oedegaard_K/0/1/0/all/0/1">Ketil Joachim Oedegaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresen_J/0/1/0/all/0/1">Jim Torresen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00710">
                                    <div class="article-summary-box-inner">
                                        <span>Manic episodes of bipolar disorder can lead to uncritical behaviour and
delusional psychosis, often with destructive consequences for those affected
and their surroundings. Early detection and intervention of a manic episode are
crucial to prevent escalation, hospital admission and premature death. However,
people with bipolar disorder may not recognize that they are experiencing a
manic episode and symptoms such as euphoria and increased productivity can also
deter affected individuals from seeking help. This work proposes to perform
user-independent, automatic mood-state detection based on actigraphy and
electrodermal activity acquired from a wrist-worn device during mania and after
recovery (euthymia). This paper proposes a new deep learning-based ensemble
method leveraging long (20h) and short (5 minutes) time-intervals to
discriminate between the mood-states. When tested on 47 bipolar patients, the
proposed classification scheme achieves an average accuracy of 91.59% in
euthymic/manic mood-state recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HO-3D_v3: Improving the Accuracy of Hand-Object Annotations of the HO-3D Dataset. (arXiv:2107.00887v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hampali_S/0/1/0/all/0/1">Shreyas Hampali</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1">Sayan Deb Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1">Vincent Lepetit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00887">
                                    <div class="article-summary-box-inner">
                                        <span>HO-3D is a dataset providing image sequences of various hand-object
interaction scenarios annotated with the 3D pose of the hand and the object and
was originally introduced as HO-3D_v2. The annotations were obtained
automatically using an optimization method, &#x27;HOnnotate&#x27;, introduced in the
original paper. HO-3D_v3 provides more accurate annotations for both the hand
and object poses thus resulting in better estimates of contact regions between
the hand and the object. In this report, we elaborate on the improvements to
the HOnnotate method and provide evaluations to compare the accuracy of
HO-3D_v2 and HO-3D_v3. HO-3D_v3 results in 4mm higher accuracy compared to
HO-3D_v2 for hand poses while exhibiting higher contact regions with the object
surface.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Target-dependent UNITER: A Transformer-Based Multimodal Language Comprehension Model for Domestic Service Robots. (arXiv:2107.00811v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_S/0/1/0/all/0/1">Shintaro Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00811">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, domestic service robots have an insufficient ability to interact
naturally through language. This is because understanding human instructions is
complicated by various ambiguities and missing information. In existing
methods, the referring expressions that specify the relationships between
objects are insufficiently modeled. In this paper, we propose Target-dependent
UNITER, which learns the relationship between the target object and other
objects directly by focusing on the relevant regions within an image, rather
than the whole image. Our method is an extension of the UNITER-based
Transformer that can be pretrained on general-purpose datasets. We extend the
UNITER approach by introducing a new architecture for handling the target
candidates. Our model is validated on two standard datasets, and the results
show that Target-dependent UNITER outperforms the baseline method in terms of
classification accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Case Relation Transformer: A Crossmodal Language Generation Model for Fetching Instructions. (arXiv:2107.00789v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kambara_M/0/1/0/all/0/1">Motonari Kambara</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Komei Sugiura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00789">
                                    <div class="article-summary-box-inner">
                                        <span>There have been many studies in robotics to improve the communication skills
of domestic service robots. Most studies, however, have not fully benefited
from recent advances in deep neural networks because the training datasets are
not large enough. In this paper, our aim is to augment the datasets based on a
crossmodal language generation model. We propose the Case Relation Transformer
(CRT), which generates a fetching instruction sentence from an image, such as
&quot;Move the blue flip-flop to the lower left box.&quot; Unlike existing methods, the
CRT uses the Transformer to integrate the visual features and geometry features
of objects in the image. The CRT can handle the objects because of the Case
Relation Block. We conducted comparison experiments and a human evaluation. The
experimental results show the CRT outperforms baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic Image Transfer for Illumination Manipulation. (arXiv:2107.00704v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junqing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzhansky_M/0/1/0/all/0/1">Michael Ruzhansky</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qianying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haihui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00704">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel intrinsic image transfer (IIT) algorithm for
illumination manipulation, which creates a local image translation between two
illumination surfaces. This model is built on an optimization-based framework
consisting of three photo-realistic losses defined on the sub-layers factorized
by an intrinsic image decomposition. We illustrate that all losses can be
reduced without the necessity of taking an intrinsic image decomposition under
the well-known spatial-varying illumination illumination-invariant reflectance
prior knowledge. Moreover, with a series of relaxations, all of them can be
directly defined on images, giving a closed-form solution for image
illumination manipulation. This new paradigm differs from the prevailing
Retinex-based algorithms, as it provides an implicit way to deal with the
per-pixel image illumination. We finally demonstrate its versatility and
benefits to the illumination-related tasks such as illumination compensation,
image enhancement, and high dynamic range (HDR) image compression, and show the
high-quality results on natural image datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MMF: Multi-Task Multi-Structure Fusion for Hierarchical Image Classification. (arXiv:2107.00808v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoni Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yucan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00808">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical classification is significant for complex tasks by providing
multi-granular predictions and encouraging better mistakes. As the label
structure decides its performance, many existing approaches attempt to
construct an excellent label structure for promoting the classification
results. In this paper, we consider that different label structures provide a
variety of prior knowledge for category recognition, thus fusing them is
helpful to achieve better hierarchical classification results. Furthermore, we
propose a multi-task multi-structure fusion model to integrate different label
structures. It contains two kinds of branches: one is the traditional
classification branch to classify the common subclasses, the other is
responsible for identifying the heterogeneous superclasses defined by different
label structures. Besides the effect of multiple label structures, we also
explore the architecture of the deep model for better hierachical
classification and adjust the hierarchical evaluation metrics for multiple
label structures. Experimental results on CIFAR100 and Car196 show that our
method obtains significantly better results than using a flat classifier or a
hierarchical classifier with any single label structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Uncertainty of Classifier for Unsupervised Domain Adaptation. (arXiv:2107.00727v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Shanu Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod Kumar Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Praphul Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00727">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding unsupervised domain adaptation has been an important task that
has been well explored. However, the wide variety of methods have not analyzed
the role of a classifier&#x27;s performance in detail. In this paper, we thoroughly
examine the role of a classifier in terms of matching source and target
distributions. We specifically investigate the classifier ability by matching
a) the distribution of features, b) probabilistic uncertainty for samples and
c) certainty activation mappings. Our analysis suggests that using these three
distributions does result in a consistently improved performance on all the
datasets. Our work thus extends present knowledge on the role of the various
distributions obtained from the classifier towards solving unsupervised domain
adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Passing a Non-verbal Turing Test: Evaluating Gesture Animations Generated from Speech. (arXiv:2107.00712v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rebol_M/0/1/0/all/0/1">Manuel Rebol</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutl_C/0/1/0/all/0/1">Christian G&#xfc;tl</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietroszek_K/0/1/0/all/0/1">Krzysztof Pietroszek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00712">
                                    <div class="article-summary-box-inner">
                                        <span>In real life, people communicate using both speech and non-verbal signals
such as gestures, face expression or body pose. Non-verbal signals impact the
meaning of the spoken utterance in an abundance of ways. An absence of
non-verbal signals impoverishes the process of communication. Yet, when users
are represented as avatars, it is difficult to translate non-verbal signals
along with the speech into the virtual world without specialized motion-capture
hardware. In this paper, we propose a novel, data-driven technique for
generating gestures directly from speech. Our approach is based on the
application of Generative Adversarial Neural Networks (GANs) to model the
correlation rather than causation between speech and gestures. This approach
approximates neuroscience findings on how non-verbal communication and speech
are correlated. We create a large dataset which consists of speech and
corresponding gestures in a 3D human pose format from which our model learns
the speaker-specific correlation. We evaluate the proposed technique in a user
study that is inspired by the Turing test. For the study, we animate the
generated gestures on a virtual character. We find that users are not able to
distinguish between the generated and the recorded gestures. Moreover, users
are able to identify our synthesized gestures as related or not related to a
given utterance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">1st Place Solutions for UG2+ Challenge 2021 -- (Semi-)supervised Face detection in the low light condition. (arXiv:2107.00818v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Pengcheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Lingqiao Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zhilong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yuan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00818">
                                    <div class="article-summary-box-inner">
                                        <span>In this technical report, we briefly introduce the solution of our team
&quot;TAL-ai&quot; for (Semi-) supervised Face detection in the low light condition in
UG2+ Challenge in CVPR 2021. By conducting several experiments with popular
image enhancement methods and image transfer methods, we pulled the low light
image and the normal image to a more closer domain. And it is observed that
using these data to training can achieve better performance. We also adapt
several popular object detection frameworks, e.g., DetectoRS, Cascade-RCNN, and
large backbone like Swin-transformer. Finally, we ensemble several models which
achieved mAP 74.89 on the testing set, ranking 1st on the final leaderboard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Multi-Robot Perception via Learned Data Association. (arXiv:2107.00769v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Glaser_N/0/1/0/all/0/1">Nathaniel Glaser</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yen-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Junjiao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00769">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address the multi-robot collaborative perception problem,
specifically in the context of multi-view infilling for distributed semantic
segmentation. This setting entails several real-world challenges, especially
those relating to unregistered multi-agent image data. Solutions must
effectively leverage multiple, non-static, and intermittently-overlapping RGB
perspectives. To this end, we propose the Multi-Agent Infilling Network: an
extensible neural architecture that can be deployed (in a distributed manner)
to each agent in a robotic swarm. Specifically, each robot is in charge of
locally encoding and decoding visual information, and an extensible neural
mechanism allows for an uncertainty-aware and context-based exchange of
intermediate features. We demonstrate improved performance on a realistic
multi-robot AirSim dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios. (arXiv:2107.00717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1">Suraj Kothawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_N/0/1/0/all/0/1">Nathan Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1">Krishnateja Killamsetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00717">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning has proven to be useful for minimizing labeling costs by
selecting the most informative samples. However, existing active learning
methods do not work well in realistic scenarios such as imbalance or rare
classes, out-of-distribution data in the unlabeled set, and redundancy. In this
work, we propose SIMILAR (Submodular Information Measures based actIve
LeARning), a unified active learning framework using recently proposed
submodular information measures (SIM) as acquisition functions. We argue that
SIMILAR not only works in standard active learning, but also easily extends to
the realistic settings considered above and acts as a one-stop solution for
active learning that is scalable to large real-world datasets. Empirically, we
show that SIMILAR significantly outperforms existing active learning algorithms
by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case
of out-of-distribution data on several image classification tasks like
CIFAR-10, MNIST, and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Image Segmentation by Mutual Information Maximization and Adversarial Regularization. (arXiv:2107.00691v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mirsadeghi_S/0/1/0/all/0/1">S. Ehsan Mirsadeghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Royat_A/0/1/0/all/0/1">Ali Royat</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezatofighi_H/0/1/0/all/0/1">Hamid Rezatofighi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00691">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation is one of the basic, yet essential scene understanding
tasks for an autonomous agent. The recent developments in supervised machine
learning and neural networks have enjoyed great success in enhancing the
performance of the state-of-the-art techniques for this task. However, their
superior performance is highly reliant on the availability of a large-scale
annotated dataset. In this paper, we propose a novel fully unsupervised
semantic segmentation method, the so-called Information Maximization and
Adversarial Regularization Segmentation (InMARS). Inspired by human perception
which parses a scene into perceptual groups, rather than analyzing each pixel
individually, our proposed approach first partitions an input image into
meaningful regions (also known as superpixels). Next, it utilizes
Mutual-Information-Maximization followed by an adversarial training strategy to
cluster these regions into semantically meaningful classes. To customize an
adversarial training scheme for the problem, we incorporate adversarial pixel
noise along with spatial perturbations to impose photometrical and geometrical
invariance on the deep neural network. Our experiments demonstrate that our
method achieves the state-of-the-art performance on two commonly used
unsupervised semantic segmentation datasets, COCO-Stuff, and Potsdam.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UTNet: A Hybrid Transformer Architecture for Medical Image Segmentation. (arXiv:2107.00781v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yunhe Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Metaxas_D/0/1/0/all/0/1">Dimitris Metaxas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00781">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer architecture has emerged to be successful in a number of natural
language processing tasks. However, its applications to medical vision remain
largely unexplored. In this study, we present UTNet, a simple yet powerful
hybrid Transformer architecture that integrates self-attention into a
convolutional neural network for enhancing medical image segmentation. UTNet
applies self-attention modules in both encoder and decoder for capturing
long-range dependency at different scales with minimal overhead. To this end,
we propose an efficient self-attention mechanism along with relative position
encoding that reduces the complexity of self-attention operation significantly
from $O(n^2)$ to approximate $O(n)$. A new self-attention decoder is also
proposed to recover fine-grained details from the skipped connections in the
encoder. Our approach addresses the dilemma that Transformer requires huge
amounts of data to learn vision inductive bias. Our hybrid layer design allows
the initialization of Transformer into convolutional networks without a need of
pre-training. We have evaluated UTNet on the multi-label, multi-vendor cardiac
magnetic resonance imaging cohort. UTNet demonstrates superior segmentation
performance and robustness against the state-of-the-art approaches, holding the
promise to generalize well on other medical image segmentations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polarized Self-Attention: Towards High-quality Pixel-wise Regression. (arXiv:2107.00782v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huajun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fuqiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xinyi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00782">
                                    <div class="article-summary-box-inner">
                                        <span>Pixel-wise regression is probably the most common problem in fine-grained
computer vision tasks, such as estimating keypoint heatmaps and segmentation
masks. These regression problems are very challenging particularly because they
require, at low computation overheads, modeling long-range dependencies on
high-resolution inputs/outputs to estimate the highly nonlinear pixel-wise
semantics. While attention mechanisms in Deep Convolutional Neural
Networks(DCNNs) has become popular for boosting long-range dependencies,
element-specific attention, such as Nonlocal blocks, is highly complex and
noise-sensitive to learn, and most of simplified attention hybrids try to reach
the best compromise among multiple types of tasks. In this paper, we present
the Polarized Self-Attention(PSA) block that incorporates two critical designs
towards high-quality pixel-wise regression: (1) Polarized filtering: keeping
high internal resolution in both channel and spatial attention computation
while completely collapsing input tensors along their counterpart dimensions.
(2) Enhancement: composing non-linearity that directly fits the output
distribution of typical fine-grained regression, such as the 2D Gaussian
distribution (keypoint heatmaps), or the 2D Binormial distribution (binary
segmentation masks). PSA appears to have exhausted the representation capacity
within its channel-only and spatial-only branches, such that there is only
marginal metric differences between its sequential and parallel layouts.
Experimental results show that PSA boosts standard baselines by $2-4$ points,
and boosts state-of-the-arts by $1-2$ points on 2D pose estimation and semantic
segmentation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blind Image Super-Resolution via Contrastive Representation Learning. (arXiv:2107.00708v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiahui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yingchen Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00708">
                                    <div class="article-summary-box-inner">
                                        <span>Image super-resolution (SR) research has witnessed impressive progress thanks
to the advance of convolutional neural networks (CNNs) in recent years.
However, most existing SR methods are non-blind and assume that degradation has
a single fixed and known distribution (e.g., bicubic) which struggle while
handling degradation in real-world data that usually follows a multi-modal,
spatially variant, and unknown distribution. The recent blind SR studies
address this issue via degradation estimation, but they do not generalize well
to multi-source degradation and cannot handle spatially variant degradation. We
design CRL-SR, a contrastive representation learning network that focuses on
blind SR of images with multi-modal and spatially variant distributions. CRL-SR
addresses the blind SR challenges from two perspectives. The first is
contrastive decoupling encoding which introduces contrastive learning to
extract resolution-invariant embedding and discard resolution-variant embedding
under the guidance of a bidirectional contrastive loss. The second is
contrastive feature refinement which generates lost or corrupted high-frequency
details under the guidance of a conditional contrastive loss. Extensive
experiments on synthetic datasets and real images show that the proposed CRL-SR
can handle multi-modal and spatially variant degradation effectively under
blind settings and it also outperforms state-of-the-art SR methods
qualitatively and quantitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming Obstructions via Bandwidth-Limited Multi-Agent Spatial Handshaking. (arXiv:2107.00771v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Glaser_N/0/1/0/all/0/1">Nathaniel Glaser</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yen-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1">Junjiao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1">Zsolt Kira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00771">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we address bandwidth-limited and obstruction-prone
collaborative perception, specifically in the context of multi-agent semantic
segmentation. This setting presents several key challenges, including
processing and exchanging unregistered robotic swarm imagery. To be successful,
solutions must effectively leverage multiple non-static and
intermittently-overlapping RGB perspectives, while heeding bandwidth
constraints and overcoming unwanted foreground obstructions. As such, we
propose an end-to-end learn-able Multi-Agent Spatial Handshaking network (MASH)
to process, compress, and propagate visual information across a robotic swarm.
Our distributed communication module operates directly (and exclusively) on raw
image data, without additional input requirements such as pose, depth, or
warping data. We demonstrate superior performance of our model compared against
several baselines in a photo-realistic multi-robot AirSim environment,
especially in the presence of image occlusions. Our method achieves an absolute
11% IoU improvement over strong baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aerial Map-Based Navigation Using Semantic Segmentation and Pattern Matching. (arXiv:2107.00689v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Youngjoo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00689">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel approach to map-based navigation system for
unmanned aircraft. The proposed system attempts label-to-label matching, not
image-to-image matching between aerial images and a map database. By using
semantic segmentation, the ground objects are labelled and the configuration of
the objects is used to find the corresponding location in the map database. The
use of the deep learning technique as a tool for extracting high-level features
reduces the image-based localization problem to a pattern matching problem.
This paper proposes a pattern matching algorithm which does not require
altitude information or a camera model to estimate the absolute horizontal
position. The feasibility analysis with simulated images shows the proposed
map-based navigation can be realized with the proposed pattern matching
algorithm and it is able to provide positions given the labelled objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Cross-Session Information for Session-based Recommendation with Graph Neural Networks. (arXiv:2107.00852v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruihong_Q/0/1/0/all/0/1">Qiu Ruihong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_H/0/1/0/all/0/1">Huang Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jingjing_L/0/1/0/all/0/1">Li Jingjing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongzhi_Y/0/1/0/all/0/1">Yin Hongzhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00852">
                                    <div class="article-summary-box-inner">
                                        <span>Different from the traditional recommender system, the session-based
recommender system introduces the concept of the session, i.e., a sequence of
interactions between a user and multiple items within a period, to preserve the
user&#x27;s recent interest. The existing work on the session-based recommender
system mainly relies on mining sequential patterns within individual sessions,
which are not expressive enough to capture more complicated dependency
relationships among items. In addition, it does not consider the cross-session
information due to the anonymity of the session data, where the linkage between
different sessions is prevented. In this paper, we solve these problems with
the graph neural networks technique. First, each session is represented as a
graph rather than a linear sequence structure, based on which a novel Full
Graph Neural Network (FGNN) is proposed to learn complicated item dependency.
To exploit and incorporate cross-session information in the individual
session&#x27;s representation learning, we further construct a Broadly Connected
Session (BCS) graph to link different sessions and a novel Mask-Readout
function to improve session embedding based on the BCS graph. Extensive
experiments have been conducted on two e-commerce benchmark datasets, i.e.,
Yoochoose and Diginetica, and the experimental results demonstrate the
superiority of our proposal through comparisons with state-of-the-art
session-based recommender models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-Demand and Lightweight Knowledge Graph Generation -- a Demonstration with DBpedia. (arXiv:2107.00873v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brockmeier_M/0/1/0/all/0/1">Malte Brockmeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yawen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pateer_S/0/1/0/all/0/1">Sunita Pateer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hertling_S/0/1/0/all/0/1">Sven Hertling</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00873">
                                    <div class="article-summary-box-inner">
                                        <span>Modern large-scale knowledge graphs, such as DBpedia, are datasets which
require large computational resources to serve and process. Moreover, they
often have longer release cycles, which leads to outdated information in those
graphs. In this paper, we present DBpedia on Demand -- a system which serves
DBpedia resources on demand without the need to materialize and store the
entire graph, and which even provides limited querying functionality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Positional Information for Session-based Recommendation. (arXiv:2107.00846v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruihong_Q/0/1/0/all/0/1">Qiu Ruihong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_H/0/1/0/all/0/1">Huang Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_C/0/1/0/all/0/1">Chen Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongzhi_Y/0/1/0/all/0/1">Yin Hongzhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00846">
                                    <div class="article-summary-box-inner">
                                        <span>For present e-commerce platforms, session-based recommender systems are
developed to predict users&#x27; preference for next-item recommendation. Although a
session can usually reflect a user&#x27;s current preference, a local shift of the
user&#x27;s intention within the session may still exist. Specifically, the
interactions that take place in the early positions within a session generally
indicate the user&#x27;s initial intention, while later interactions are more likely
to represent the latest intention. Such positional information has been rarely
considered in existing methods, which restricts their ability to capture the
significance of interactions at different positions. To thoroughly exploit the
positional information within a session, a theoretical framework is developed
in this paper to provide an in-depth analysis of the positional information. We
formally define the properties of forward-awareness and backward-awareness to
evaluate the ability of positional encoding schemes in capturing the initial
and the latest intention. According to our analysis, existing positional
encoding schemes are generally forward-aware only, which can hardly represent
the dynamics of the intention in a session. To enhance the positional encoding
scheme for the session-based recommendation, a dual positional encoding (DPE)
is proposed to account for both forward-awareness and backward-awareness. Based
on DPE, we propose a novel Positional Recommender (PosRec) model with a
well-designed Position-aware Gated Graph Neural Network module to fully exploit
the positional information for session-based recommendation tasks. Extensive
experiments are conducted on two e-commerce benchmark datasets, Yoochoose and
Diginetica and the experimental results show the superiority of the PosRec by
comparing it with the state-of-the-art session-based recommender models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability. (arXiv:2107.00833v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1">Mihaela Curmei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1">Sarah Dean</a>, <a href="http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1">Benjamin Recht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00833">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider how preference models in interactive recommendation
systems determine the availability of content and users&#x27; opportunities for
discovery. We propose an evaluation procedure based on stochastic reachability
to quantify the maximum probability of recommending a target piece of content
to an user for a set of allowable strategic modifications. This framework
allows us to compute an upper bound on the likelihood of recommendation with
minimal assumptions about user behavior. Stochastic reachability can be used to
detect biases in the availability of content and diagnose limitations in the
opportunities for discovery granted to users. We show that this metric can be
computed efficiently as a convex program for a variety of practical settings,
and further argue that reachability is not inherently at odds with accuracy. We
demonstrate evaluations of recommendation algorithms trained on large datasets
of explicit and implicit ratings. Our results illustrate how preference models,
selection rules, and user interventions impact reachability and how these
effects can be distributed unevenly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Low-Pass Filters: Adaptive Feature Propagation on Graphs. (arXiv:2103.14187v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sean Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14187">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have been extensively studied for prediction
tasks on graphs. As pointed out by recent studies, most GNNs assume local
homophily, i.e., strong similarities in local neighborhoods. This assumption
however limits the generalizability power of GNNs. To address this limitation,
we propose a flexible GNN model, which is capable of handling any graphs
without being restricted by their underlying homophily. At its core, this model
adopts a node attention mechanism based on multiple learnable spectral filters;
therefore, the aggregation scheme is learned adaptively for each graph in the
spectral domain. We evaluated the proposed model on node classification tasks
over eight benchmark datasets. The proposed model is shown to generalize well
to both homophilic and heterophilic graphs. Further, it outperforms all
state-of-the-art baselines on heterophilic graphs and performs comparably with
them on homophilic graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Fire Detection in Landsat-8 Imagery: a Large-Scale Dataset and a Deep-Learning Study. (arXiv:2101.03409v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Gabriel Henrique de Almeida Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Fusioka_A/0/1/0/all/0/1">Andr&#xe9; Minoro Fusioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassu_B/0/1/0/all/0/1">Bogdan Tomoyuki Nassu</a>, <a href="http://arxiv.org/find/cs/1/au:+Minetto_R/0/1/0/all/0/1">Rodrigo Minetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03409">
                                    <div class="article-summary-box-inner">
                                        <span>Active fire detection in satellite imagery is of critical importance to the
management of environmental conservation policies, supporting decision-making
and law enforcement. This is a well established field, with many techniques
being proposed over the years, usually based on pixel or region-level
comparisons involving sensor-specific thresholds and neighborhood statistics.
In this paper, we address the problem of active fire detection using deep
learning techniques. In recent years, deep learning techniques have been
enjoying an enormous success in many fields, but their use for active fire
detection is relatively new, with open questions and demand for datasets and
architectures for evaluation. This paper addresses these issues by introducing
a new large-scale dataset for active fire detection, with over 150,000 image
patches (more than 200 GB of data) extracted from Landsat-8 images captured
around the world in August and September 2020, containing wildfires in several
locations. The dataset was split in two parts, and contains 10-band spectral
images with associated outputs, produced by three well known handcrafted
algorithms for active fire detection in the first part, and manually annotated
masks in the second part. We also present a study on how different
convolutional neural network architectures can be used to approximate these
handcrafted algorithms, and how models trained on automatically segmented
patches can be combined to achieve better performance than the original
algorithms - with the best combination having 87.2% precision and 92.4% recall
on our manually annotated dataset. The proposed dataset, source codes and
trained models are available on Github
(https://github.com/pereira-gha/activefire), creating opportunities for further
advances in the field</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable and Instance-Robust Predictions for Online Matching, Flows and Load Balancing. (arXiv:2011.11743v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lavastida_T/0/1/0/all/0/1">Thomas Lavastida</a>, <a href="http://arxiv.org/find/cs/1/au:+Moseley_B/0/1/0/all/0/1">Benjamin Moseley</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_R/0/1/0/all/0/1">R. Ravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenyang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11743">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new model for augmenting algorithms with predictions by
requiring that they are formally learnable and instance robust. Learnability
ensures that predictions can be efficiently constructed from a reasonable
amount of past data. Instance robustness ensures that the prediction is robust
to modest changes in the problem input, where the measure of the change may be
problem specific. Instance robustness insists on a smooth degradation in
performance as a function of the change. Ideally, the performance is never
worse than worst-case bounds. This also allows predictions to be objectively
compared.

We design online algorithms with predictions for a network flow allocation
problem and restricted assignment makespan minimization. For both problems, two
key properties are established: high quality predictions can be learned from a
small sample of prior instances and these predictions are robust to errors that
smoothly degrade as the underlying problem instance changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum machine learning with adaptive linear optics. (arXiv:2102.04579v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Chabaud_U/0/1/0/all/0/1">Ulysse Chabaud</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Markham_D/0/1/0/all/0/1">Damian Markham</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Sohbi_A/0/1/0/all/0/1">Adel Sohbi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04579">
                                    <div class="article-summary-box-inner">
                                        <span>We study supervised learning algorithms in which a quantum device is used to
perform a computational subroutine - either for prediction via probability
estimation, or to compute a kernel via estimation of quantum states overlap. We
design implementations of these quantum subroutines using Boson Sampling
architectures in linear optics, supplemented by adaptive measurements. We then
challenge these quantum algorithms by deriving classical simulation algorithms
for the tasks of output probability estimation and overlap estimation. We
obtain different classical simulability regimes for these two computational
tasks in terms of the number of adaptive measurements and input photons. In
both cases, our results set explicit limits to the range of parameters for
which a quantum advantage can be envisaged with adaptive linear optics compared
to classical machine learning algorithms: we show that the number of input
photons and the number of adaptive measurements cannot be simultaneously small
compared to the number of modes. Interestingly, our analysis leaves open the
possibility of a near-term quantum advantage with a single adaptive
measurement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Complexity of Symbolic Finite-State Automata. (arXiv:2011.05389v3 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fisman_D/0/1/0/all/0/1">Dana Fisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Frenkel_H/0/1/0/all/0/1">Hadar Frenkel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zilles_S/0/1/0/all/0/1">Sandra Zilles</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05389">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit the complexity of procedures on SFAs (such as intersection,
emptiness, etc.) and analyze them according to the measures we find suitable
for symbolic automata: the number of states, the maximal number of transitions
exiting a state, and the size of the most complex transition predicate. We pay
attention to the special forms of SFAs: {normalized SFAs} and {neat SFAs}, as
well as to SFAs over a {monotonic} effective Boolean algebra.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointGuard: Provably Robust 3D Point Cloud Classification. (arXiv:2103.03046v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongbin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jinyuan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03046">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud classification has many safety-critical applications such as
autonomous driving and robotic grasping. However, several studies showed that
it is vulnerable to adversarial attacks. In particular, an attacker can make a
classifier predict an incorrect label for a 3D point cloud via carefully
modifying, adding, and/or deleting a small number of its points. Randomized
smoothing is state-of-the-art technique to build certifiably robust 2D image
classifiers. However, when applied to 3D point cloud classification, randomized
smoothing can only certify robustness against adversarially modified points.

In this work, we propose PointGuard, the first defense that has provable
robustness guarantees against adversarially modified, added, and/or deleted
points. Specifically, given a 3D point cloud and an arbitrary point cloud
classifier, our PointGuard first creates multiple subsampled point clouds, each
of which contains a random subset of the points in the original point cloud;
then our PointGuard predicts the label of the original point cloud as the
majority vote among the labels of the subsampled point clouds predicted by the
point cloud classifier. Our first major theoretical contribution is that we
show PointGuard provably predicts the same label for a 3D point cloud when the
number of adversarially modified, added, and/or deleted points is bounded. Our
second major theoretical contribution is that we prove the tightness of our
derived bound when no assumptions on the point cloud classifier are made.
Moreover, we design an efficient algorithm to compute our certified robustness
guarantees. We also empirically evaluate PointGuard on ModelNet40 and ScanNet
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure Learning from Related Data Sets with a Hierarchical Bayesian Score. (arXiv:2008.01683v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Azzimonti_L/0/1/0/all/0/1">Laura Azzimonti</a>, <a href="http://arxiv.org/find/stat/1/au:+Corani_G/0/1/0/all/0/1">Giorgio Corani</a>, <a href="http://arxiv.org/find/stat/1/au:+Scutari_M/0/1/0/all/0/1">Marco Scutari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01683">
                                    <div class="article-summary-box-inner">
                                        <span>Score functions for learning the structure of Bayesian networks in the
literature assume that data are a homogeneous set of observations; whereas it
is often the case that they comprise different related, but not homogeneous,
data sets collected in different ways. In this paper we propose a new Bayesian
Dirichlet score, which we call Bayesian Hierarchical Dirichlet (BHD). The
proposed score is based on a hierarchical model that pools information across
data sets to learn a single encompassing network structure, while taking into
account the differences in their probabilistic structures. We derive a
closed-form expression for BHD using a variational approximation of the
marginal likelihood and we study its performance using simulated data. We find
that, when data comprise multiple related data sets, BHD outperforms the
Bayesian Dirichlet equivalent uniform (BDeu) score in terms of reconstruction
accuracy as measured by the Structural Hamming distance, and that it is as
accurate as BDeu when data are homogeneous. Moreover, the estimated networks
are sparser and therefore more interpretable than those obtained with BDeu,
thanks to a lower number of false positive arcs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Oracle Complexity of Higher-Order Smooth Non-Convex Finite-Sum Optimization. (arXiv:2103.05138v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Emmenegger_N/0/1/0/all/0/1">Nicolas Emmenegger</a>, <a href="http://arxiv.org/find/math/1/au:+Kyng_R/0/1/0/all/0/1">Rasmus Kyng</a>, <a href="http://arxiv.org/find/math/1/au:+Zehmakan_A/0/1/0/all/0/1">Ahad N. Zehmakan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05138">
                                    <div class="article-summary-box-inner">
                                        <span>We prove lower bounds for higher-order methods in smooth non-convex
finite-sum optimization. Our contribution is threefold: We first show that a
deterministic algorithm cannot profit from the finite-sum structure of the
objective, and that simulating a pth-order regularized method on the whole
function by constructing exact gradient information is optimal up to constant
factors. We further show lower bounds for randomized algorithms and compare
them with the best known upper bounds. To address some gaps between the bounds,
we propose a new second-order smoothness assumption that can be seen as an
analogue of the first-order mean-squared smoothness assumption. We prove that
it is sufficient to ensure state-of-the-art convergence guarantees, while
allowing for a sharper lower bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Real-World BCI: CCSPNet, A Compact Subject-Independent Motor Imagery Framework. (arXiv:2012.13567v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nouri_M/0/1/0/all/0/1">Mahbod Nouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Moradi_F/0/1/0/all/0/1">Faraz Moradi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaemi_H/0/1/0/all/0/1">Hafez Ghaemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_A/0/1/0/all/0/1">Ali Motie Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13567">
                                    <div class="article-summary-box-inner">
                                        <span>A conventional subject-dependent (SD) brain-computer interface (BCI) requires
a complete data-gathering, training, and calibration phase for each user before
it can be used. In recent years, a number of subject-independent (SI) BCIs have
been developed. However, there are many problems preventing them from being
used in real-world BCI applications. A weaker performance compared to the
subject-dependent (SD) approach, and a relatively large model requiring high
computational power are the most important ones. Therefore, a potential
real-world BCI would greatly benefit from a compact low-power
subject-independent BCI framework, ready to be used immediately after the user
puts it on. To move towards this goal, we propose a novel subject-independent
BCI framework named CCSPNet (Convolutional Common Spatial Pattern Network)
trained on the motor imagery (MI) paradigm of a large-scale
electroencephalography (EEG) signals database consisting of 21600 trials for 54
subjects performing two-class hand-movement MI tasks. The proposed framework
applies a wavelet kernel convolutional neural network (WKCNN) and a temporal
convolutional neural network (TCNN) in order to represent and extract the
diverse spectral features of EEG signals. The outputs of the convolutional
layers go through a common spatial pattern (CSP) algorithm for spatial feature
extraction. The number of CSP features is reduced by a dense neural network,
and the final class label is determined by a linear discriminative analysis
(LDA) classifier. The CCSPNet framework evaluation results show that it is
possible to have a low-power compact BCI that achieves both SD and SI
performance comparable to complex and computationally expensive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in the Creative Industries: A Review. (arXiv:2007.12391v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bull_D/0/1/0/all/0/1">David Bull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.12391">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the &#x60;creator&#x27;, remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROOTS: Object-Centric Representation and Rendering of 3D Scenes. (arXiv:2006.06130v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1">Fei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Sungjin Ahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06130">
                                    <div class="article-summary-box-inner">
                                        <span>A crucial ability of human intelligence is to build up models of individual
3D objects from partial scene observations. Recent works achieve object-centric
generation but without the ability to infer the representation, or achieve 3D
scene representation learning but without object-centric compositionality.
Therefore, learning to represent and render 3D scenes with object-centric
compositionality remains elusive. In this paper, we propose a probabilistic
generative model for learning to build modular and compositional 3D object
models from partial observations of a multi-object scene. The proposed model
can (i) infer the 3D object representations by learning to search and group
object areas and also (ii) render from an arbitrary viewpoint not only
individual objects but also the full scene by compositing the objects. The
entire learning process is unsupervised and end-to-end. In experiments, in
addition to generation quality, we also demonstrate that the learned
representation permits object-wise manipulation and novel scene generation, and
generalizes to various settings. Results can be found on our project website:
https://sites.google.com/view/roots3d</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How good is your explanation? Algorithmic stability measures to assess the qualityof explanations for deep neural networks. (arXiv:2009.04521v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fel_T/0/1/0/all/0/1">Thomas Fel</a> (ANITI), <a href="http://arxiv.org/find/cs/1/au:+Vigouroux_D/0/1/0/all/0/1">David Vigouroux</a>, <a href="http://arxiv.org/find/cs/1/au:+Cadene_R/0/1/0/all/0/1">R&#xe9;mi Cad&#xe8;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1">Thomas Serre</a> (ANITI)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04521">
                                    <div class="article-summary-box-inner">
                                        <span>A plethora of methods have been proposed to explain howdeep neural networks
reach a decision but comparativelylittle effort has been made to ensure that
the explanationsproduced by these methods are objectively relevant.
Whiledesirable properties for a good explanation are easy to come,objective
measures have been harder to derive. Here, we pro-pose two new measures to
evaluate explanations borrowedfrom the field of algorithmic stability: relative
consistencyReCo and mean generalizability MeGe. We conduct severalexperiments
on multiple image datasets and network archi-tectures to demonstrate the
benefits of the proposed measuresover representative methods. We show that
popular fidelitymeasures are not sufficient to guarantee good
explanations.Finally, we show empirically that 1-Lipschitz networks pro-vide
general and consistent explanations, regardless of theexplanation method used,
making them a relevant directionfor explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Clinical Outcomes in COVID-19 using Radiomics and Deep Learning on Chest Radiographs: A Multi-Institutional Study. (arXiv:2007.08028v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bae_J/0/1/0/all/0/1">Joseph Bae</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kapse_S/0/1/0/all/0/1">Saarthak Kapse</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gattu_R/0/1/0/all/0/1">Rishabh Gattu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ali_S/0/1/0/all/0/1">Syed Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Shah_N/0/1/0/all/0/1">Neal Shah</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marshall_C/0/1/0/all/0/1">Colin Marshall</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Pierce_J/0/1/0/all/0/1">Jonathan Pierce</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Phatak_T/0/1/0/all/0/1">Tej Phatak</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1">Amit Gupta</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Green_J/0/1/0/all/0/1">Jeremy Green</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Madan_N/0/1/0/all/0/1">Nikhil Madan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Prasanna_P/0/1/0/all/0/1">Prateek Prasanna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08028">
                                    <div class="article-summary-box-inner">
                                        <span>We predict mechanical ventilation requirement and mortality using
computational modeling of chest radiographs (CXRs) for coronavirus disease 2019
(COVID-19) patients. This two-center, retrospective study analyzed 530
deidentified CXRs from 515 COVID-19 patients treated at Stony Brook University
Hospital and Newark Beth Israel Medical Center between March and August 2020.
DL and machine learning classifiers to predict mechanical ventilation
requirement and mortality were trained and evaluated using patient CXRs. A
novel radiomic embedding framework was also explored for outcome prediction.
All results are compared against radiologist grading of CXRs (zone-wise expert
severity scores). Radiomic and DL classification models had mAUCs of
0.78+/-0.02 and 0.81+/-0.04, compared with expert scores mAUCs of 0.75+/-0.02
and 0.79+/-0.05 for mechanical ventilation requirement and mortality
prediction, respectively. Combined classifiers using both radiomics and expert
severity scores resulted in mAUCs of 0.79+/-0.04 and 0.83+/-0.04 for each
prediction task, demonstrating improvement over either artificial intelligence
or radiologist interpretation alone. Our results also suggest instances where
inclusion of radiomic features in DL improves model predictions, something that
might be explored in other pathologies. The models proposed in this study and
the prognostic information they provide might aid physician decision making and
resource allocation during the COVID-19 pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Survey of Data Augmentation for Time Series Classification with Neural Networks. (arXiv:2007.15951v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1">Brian Kenji Iwana</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1">Seiichi Uchida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15951">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, deep artificial neural networks have achieved many successes
in pattern recognition. Part of this success can be attributed to the reliance
on big data to increase generalization. However, in the field of time series
recognition, many datasets are often very small. One method of addressing this
problem is through the use of data augmentation. In this paper, we survey data
augmentation techniques for time series and their application to time series
classification with neural networks. We propose a taxonomy and outline the four
families in time series data augmentation, including transformation-based
methods, pattern mixing, generative models, and decomposition methods.
Furthermore, we empirically evaluate 12 time series data augmentation methods
on 128 time series classification datasets with six different types of neural
networks. Through the results, we are able to analyze the characteristics,
advantages and disadvantages, and recommendations of each data augmentation
method. This survey aims to help in the selection of time series data
augmentation for neural network applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Tucker Rank Reduction for Non-Negative Tensors Using Mean-Field Approximation. (arXiv:2103.02898v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghalamkari_K/0/1/0/all/0/1">Kazu Ghalamkari</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Mahito Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02898">
                                    <div class="article-summary-box-inner">
                                        <span>We present an efficient low-rank approximation algorithm for non-negative
tensors. The algorithm is derived from our two findings: First, we show that
rank-1 approximation for tensors can be viewed as a mean-field approximation by
treating each tensor as a probability distribution. Second, we theoretically
provide a sufficient condition for distribution parameters to reduce Tucker
ranks of tensors and, interestingly, this sufficient condition can be achieved
by iterative application of the mean-field approximation. Since the mean-field
approximation is always given as a closed formula, our findings lead to a fast
low-rank approximation algorithm without using a gradient method. We
empirically demonstrate that our algorithm is faster than the existing
non-negative Tucker rank reduction methods with achieving competitive or better
approximation of given tensors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards closing the gap between the theory and practice of SVRG. (arXiv:1908.02725v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sebbouh_O/0/1/0/all/0/1">Othmane Sebbouh</a>, <a href="http://arxiv.org/find/math/1/au:+Gazagnadou_N/0/1/0/all/0/1">Nidham Gazagnadou</a>, <a href="http://arxiv.org/find/math/1/au:+Jelassi_S/0/1/0/all/0/1">Samy Jelassi</a>, <a href="http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>, <a href="http://arxiv.org/find/math/1/au:+Gower_R/0/1/0/all/0/1">Robert M. Gower</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.02725">
                                    <div class="article-summary-box-inner">
                                        <span>Among the very first variance reduced stochastic methods for solving the
empirical risk minimization problem was the SVRG method (Johnson &amp; Zhang 2013).
SVRG is an inner-outer loop based method, where in the outer loop a reference
full gradient is evaluated, after which $m \in \mathbb{N}$ steps of an inner
loop are executed where the reference gradient is used to build a variance
reduced estimate of the current gradient. The simplicity of the SVRG method and
its analysis have led to multiple extensions and variants for even non-convex
optimization. We provide a more general analysis of SVRG than had been
previously done by using arbitrary sampling, which allows us to analyse
virtually all forms of mini-batching through a single theorem. Furthermore, our
analysis is focused on more practical variants of SVRG including a new variant
of the loopless SVRG (Hofman et al 2015, Kovalev et al 2019, Kulunchakov and
Mairal 2019) and a variant of k-SVRG (Raj and Stich 2018) where $m&#x3D;n$ and where
$n$ is the number of data points. Since our setup and analysis reflect what is
done in practice, we are able to set the parameters such as the mini-batch size
and step size using our theory in such a way that produces a more efficient
algorithm in practice, as we show in extensive numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Dependent Randomized Smoothing. (arXiv:2012.04351v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1">Adel Bibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04351">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized smoothing is a recent technique that achieves state-of-art
performance in training certifiably robust deep neural networks. While the
smoothing family of distributions is often connected to the choice of the norm
used for certification, the parameters of these distributions are always set as
global hyper parameters independent of the input data on which a network is
certified. In this work, we revisit Gaussian randomized smoothing and show that
the variance of the Gaussian distribution can be optimized at each input so as
to maximize the certification radius for the construction of the smoothed
classifier. This new approach is generic, parameter-free, and easy to
implement. In fact, we show that our data dependent framework can be seamlessly
incorporated into 3 randomized smoothing approaches, leading to consistent
improved certified accuracy. When this framework is used in the training
routine of these approaches followed by a data dependent certification, we
achieve 9\% and 6\% improvement over the certified accuracy of the strongest
baseline for a radius of 0.5 on CIFAR10 and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory Efficient Meta-Learning with Large Images. (arXiv:2107.01105v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bronskill_J/0/1/0/all/0/1">John Bronskill</a>, <a href="http://arxiv.org/find/stat/1/au:+Massiceti_D/0/1/0/all/0/1">Daniela Massiceti</a>, <a href="http://arxiv.org/find/stat/1/au:+Patacchiola_M/0/1/0/all/0/1">Massimiliano Patacchiola</a>, <a href="http://arxiv.org/find/stat/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/stat/1/au:+Nowozin_S/0/1/0/all/0/1">Sebastian Nowozin</a>, <a href="http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1">Richard E. Turner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01105">
                                    <div class="article-summary-box-inner">
                                        <span>Meta learning approaches to few-shot classification are computationally
efficient at test time requiring just a few optimization steps or single
forward pass to learn a new task, but they remain highly memory-intensive to
train. This limitation arises because a task&#x27;s entire support set, which can
contain up to 1000 images, must be processed before an optimization step can be
taken. Harnessing the performance gains offered by large images thus requires
either parallelizing the meta-learner across multiple GPUs, which may not be
available, or trade-offs between task and image size when memory constraints
apply. We improve on both options by proposing LITE, a general and memory
efficient episodic training scheme that enables meta-training on large tasks
composed of large images on a single GPU. We achieve this by observing that the
gradients for a task can be decomposed into a sum of gradients over the task&#x27;s
training images. This enables us to perform a forward pass on a task&#x27;s entire
training set but realize significant memory savings by back-propagating only a
random subset of these images which we show is an unbiased approximation of the
full gradient. We use LITE to train meta-learners and demonstrate new
state-of-the-art accuracy on the real-world ORBIT benchmark and 3 of the 4
parts of the challenging VTAB+MD benchmark relative to leading meta-learners.
LITE also enables meta-learners to be competitive with transfer learning
approaches but at a fraction of the test-time computational cost, thus serving
as a counterpoint to the recent narrative that transfer learning is all you
need for few-shot classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHADOWCAST: Controllable Graph Generation. (arXiv:2006.03774v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tann_W/0/1/0/all/0/1">Wesley Joon-Wie Tann</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ee-Chien Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1">Bryan Hooi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03774">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the controllable graph generation problem, formulated as
controlling graph attributes during the generative process to produce desired
graphs with understandable structures. Using a transparent and straightforward
Markov model to guide this generative process, practitioners can shape and
understand the generated graphs. We propose ${\rm S{\small HADOW}C{\small
AST}}$, a generative model capable of controlling graph generation while
retaining the original graph&#x27;s intrinsic properties. The proposed model is
based on a conditional generative adversarial network. Given an observed graph
and some user-specified Markov model parameters, ${\rm S{\small HADOW}C{\small
AST}}$ controls the conditions to generate desired graphs. Comprehensive
experiments on three real-world network datasets demonstrate our model&#x27;s
competitive performance in the graph generation task. Furthermore, we show its
effective controllability by directing ${\rm S{\small HADOW}C{\small AST}}$ to
generate hypothetical scenarios with different graph structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mirrorless Mirror Descent: A Natural Derivation of Mirror Descent. (arXiv:2004.01025v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunasekar_S/0/1/0/all/0/1">Suriya Gunasekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodworth_B/0/1/0/all/0/1">Blake Woodworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01025">
                                    <div class="article-summary-box-inner">
                                        <span>We present a primal only derivation of Mirror Descent as a &quot;partial&quot;
discretization of gradient flow on a Riemannian manifold where the metric
tensor is the Hessian of the Mirror Descent potential. We contrast this
discretization to Natural Gradient Descent, which is obtained by a &quot;full&quot;
forward Euler discretization. This view helps shed light on the relationship
between the methods and allows generalizing Mirror Descent to general
Riemannian geometries, even when the metric tensor is {\em not} a Hessian, and
thus there is no &quot;dual.&quot;</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Functional Perspective on Learning Symmetric Functions with Neural Networks. (arXiv:2008.06952v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zweig_A/0/1/0/all/0/1">Aaron Zweig</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1">Joan Bruna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06952">
                                    <div class="article-summary-box-inner">
                                        <span>Symmetric functions, which take as input an unordered, fixed-size set, are
known to be universally representable by neural networks that enforce
permutation invariance. These architectures only give guarantees for fixed
input sizes, yet in many practical applications, including point clouds and
particle physics, a relevant notion of generalization should include varying
the input size. In this work we treat symmetric functions (of any size) as
functions over probability measures, and study the learning and representation
of neural networks defined on measures. By focusing on shallow architectures,
we establish approximation and generalization bounds under different choices of
regularization (such as RKHS and variation norms), that capture a hierarchy of
functional spaces with increasing degree of non-linear learning. The resulting
models can be learned efficiently and enjoy generalization guarantees that
extend across input sizes, as we verify empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Machine Learning-Ready HPC Ensembles with Merlin. (arXiv:1912.02892v2 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peterson_J/0/1/0/all/0/1">J. Luc Peterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bay_B/0/1/0/all/0/1">Ben Bay</a>, <a href="http://arxiv.org/find/cs/1/au:+Koning_J/0/1/0/all/0/1">Joe Koning</a>, <a href="http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1">Peter Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Semler_J/0/1/0/all/0/1">Jessica Semler</a>, <a href="http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1">Jeremy White</a>, <a href="http://arxiv.org/find/cs/1/au:+Anirudh_R/0/1/0/all/0/1">Rushil Anirudh</a>, <a href="http://arxiv.org/find/cs/1/au:+Athey_K/0/1/0/all/0/1">Kevin Athey</a>, <a href="http://arxiv.org/find/cs/1/au:+Bremer_P/0/1/0/all/0/1">Peer-Timo Bremer</a>, <a href="http://arxiv.org/find/cs/1/au:+Natale_F/0/1/0/all/0/1">Francesco Di Natale</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">David Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_J/0/1/0/all/0/1">Jim A. Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobs_S/0/1/0/all/0/1">Sam A. Jacobs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kustowski_B/0/1/0/all/0/1">Bogdan Kustowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Langer_S/0/1/0/all/0/1">Steven Langer</a>, <a href="http://arxiv.org/find/cs/1/au:+Spears_B/0/1/0/all/0/1">Brian Spears</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiagarajan_J/0/1/0/all/0/1">Jayaraman Thiagarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Essen_B/0/1/0/all/0/1">Brian Van Essen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1">Jae-Seung Yeom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02892">
                                    <div class="article-summary-box-inner">
                                        <span>With the growing complexity of computational and experimental facilities,
many scientific researchers are turning to machine learning (ML) techniques to
analyze large scale ensemble data. With complexities such as multi-component
workflows, heterogeneous machine architectures, parallel file systems, and
batch scheduling, care must be taken to facilitate this analysis in a high
performance computing (HPC) environment. In this paper, we present Merlin, a
workflow framework to enable large ML-friendly ensembles of scientific HPC
simulations. By augmenting traditional HPC with distributed compute
technologies, Merlin aims to lower the barrier for scientific subject matter
experts to incorporate ML into their analysis. In addition to its design, we
describe some example applications that Merlin has enabled on leadership-class
HPC resources, such as the ML-augmented optimization of nuclear fusion
experiments and the calibration of infectious disease models to study the
progression of and possible mitigation strategies for COVID-19.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Road Roughness Estimation Using Machine Learning. (arXiv:2107.01199v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bajic_M/0/1/0/all/0/1">Milena Bajic</a>, <a href="http://arxiv.org/find/cs/1/au:+Pour_S/0/1/0/all/0/1">Shahrzad M. Pour</a>, <a href="http://arxiv.org/find/cs/1/au:+Skar_A/0/1/0/all/0/1">Asmus Skar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pettinari_M/0/1/0/all/0/1">Matteo Pettinari</a>, <a href="http://arxiv.org/find/cs/1/au:+Levenberg_E/0/1/0/all/0/1">Eyal Levenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Alstrom_T/0/1/0/all/0/1">Tommy Sonne Alstr&#xf8;m</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01199">
                                    <div class="article-summary-box-inner">
                                        <span>Road roughness is a very important road condition for the infrastructure, as
the roughness affects both the safety and ride comfort of passengers. The roads
deteriorate over time which means the road roughness must be continuously
monitored in order to have an accurate understand of the condition of the road
infrastructure. In this paper, we propose a machine learning pipeline for road
roughness prediction using the vertical acceleration of the car and the car
speed. We compared well-known supervised machine learning models such as linear
regression, naive Bayes, k-nearest neighbor, random forest, support vector
machine, and the multi-layer perceptron neural network. The models are trained
on an optimally selected set of features computed in the temporal and
statistical domain. The results demonstrate that machine learning methods can
accurately predict road roughness, using the recordings of the cost
approachable in-vehicle sensors installed in conventional passenger cars. Our
findings demonstrate that the technology is well suited to meet future pavement
condition monitoring, by enabling continuous monitoring of a wide road network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Identification of Hindi-English tweets using code-mixed BERT. (arXiv:2107.01202v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_M/0/1/0/all/0/1">Mohd Zeeshan Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Beg_M/0/1/0/all/0/1">M M Sufyan Beg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Tanvir Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohd Jazib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasim_G/0/1/0/all/0/1">Ghazali Wasim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01202">
                                    <div class="article-summary-box-inner">
                                        <span>Language identification of social media text has been an interesting problem
of study in recent years. Social media messages are predominantly in code mixed
in non-English speaking states. Prior knowledge by pre-training contextual
embeddings have shown state of the art results for a range of downstream tasks.
Recently, models such as BERT have shown that using a large amount of unlabeled
data, the pretrained language models are even more beneficial for learning
common language representations. Extensive experiments exploiting transfer
learning and fine-tuning BERT models to identify language on Twitter are
presented in this paper. The work utilizes a data collection of
Hindi-English-Urdu codemixed text for language pre-training and Hindi-English
codemixed for subsequent word-level language classification. The results show
that the representations pre-trained over codemixed data produce better results
by their monolingual counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Model Compression Via Two-Stage Deep Reinforcement Learning. (arXiv:1912.02254v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1">Huixin Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei-Ming Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yongcan Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02254">
                                    <div class="article-summary-box-inner">
                                        <span>Besides accuracy, the model size of convolutional neural networks (CNN)
models is another important factor considering limited hardware resources in
practical applications. For example, employing deep neural networks on mobile
systems requires the design of accurate yet fast CNN for low latency in
classification and object detection. To fulfill the need, we aim at obtaining
CNN models with both high testing accuracy and small size to address resource
constraints in many embedded devices. In particular, this paper focuses on
proposing a generic reinforcement learning-based model compression approach in
a two-stage compression pipeline: pruning and quantization. The first stage of
compression, i.e., pruning, is achieved via exploiting deep reinforcement
learning (DRL) to co-learn the accuracy and the FLOPs updated after layer-wise
channel pruning and element-wise variational pruning via information dropout.
The second stage, i.e., quantization, is achieved via a similar DRL approach
but focuses on obtaining the optimal bits representation for individual layers.
We further conduct experimental results on CIFAR-10 and ImageNet datasets. For
the CIFAR-10 dataset, the proposed method can reduce the size of VGGNet by 9x
from 20.04MB to 2.2MB with a slight accuracy increase. For the ImageNet
dataset, the proposed method can reduce the size of VGG-16 by 33x from 138MB to
4.14MB with no accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Causal Structure Discovery in Earth System Sciences. (arXiv:2107.01126v1 [physics.data-an])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Melkas_L/0/1/0/all/0/1">Laila Melkas</a>, <a href="http://arxiv.org/find/physics/1/au:+Savvides_R/0/1/0/all/0/1">Rafael Savvides</a>, <a href="http://arxiv.org/find/physics/1/au:+Chandramouli_S/0/1/0/all/0/1">Suyog Chandramouli</a>, <a href="http://arxiv.org/find/physics/1/au:+Makela_J/0/1/0/all/0/1">Jarmo M&#xe4;kel&#xe4;</a>, <a href="http://arxiv.org/find/physics/1/au:+Nieminen_T/0/1/0/all/0/1">Tuomo Nieminen</a>, <a href="http://arxiv.org/find/physics/1/au:+Mammarella_I/0/1/0/all/0/1">Ivan Mammarella</a>, <a href="http://arxiv.org/find/physics/1/au:+Puolamaki_K/0/1/0/all/0/1">Kai Puolam&#xe4;ki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01126">
                                    <div class="article-summary-box-inner">
                                        <span>Causal structure discovery (CSD) models are making inroads into several
domains, including Earth system sciences. Their widespread adaptation is
however hampered by the fact that the resulting models often do not take into
account the domain knowledge of the experts and that it is often necessary to
modify the resulting models iteratively. We present a workflow that is required
to take this knowledge into account and to apply CSD algorithms in Earth system
sciences. At the same time, we describe open research questions that still need
to be addressed. We present a way to interactively modify the outputs of the
CSD algorithms and argue that the user interaction can be modelled as a greedy
finding of the local maximum-a-posteriori solution of the likelihood function,
which is composed of the likelihood of the causal model and the prior
distribution representing the knowledge of the expert user. We use a real-world
data set for examples constructed in collaboration with our co-authors, who are
the domain area experts. We show that finding maximally usable causal models in
the Earth system sciences or other similar domains is a difficult task which
contains many interesting open research questions. We argue that taking the
domain knowledge into account has a substantial effect on the final causal
models discovered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization. (arXiv:2107.01131v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1">Yuewei Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Deng_X/0/1/0/all/0/1">Xinwei Deng</a>, <a href="http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Fan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01131">
                                    <div class="article-summary-box-inner">
                                        <span>Successful applications of InfoNCE and its variants have popularized the use
of contrastive variational mutual information (MI) estimators in machine
learning. While featuring superior stability, these estimators crucially depend
on costly large-batch training, and they sacrifice bound tightness for variance
reduction. To overcome these limitations, we revisit the mathematics of popular
variational MI bounds from the lens of unnormalized statistical modeling and
convex optimization. Our investigation not only yields a new unified
theoretical framework encompassing popular variational MI bounds but also leads
to a novel, simple, and powerful contrastive MI estimator named as FLO.
Theoretically, we show that the FLO estimator is tight, and it provably
converges under stochastic gradient descent. Empirically, our FLO estimator
overcomes the limitations of its predecessors and learns more efficiently. The
utility of FLO is verified using an extensive set of benchmarks, which also
reveals the trade-offs in practical MI estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Neural Network for Cybersecurity: A Comprehensive Review. (arXiv:2107.01185v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Podder_P/0/1/0/all/0/1">Prajoy Podder</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharati_S/0/1/0/all/0/1">Subrato Bharati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_M/0/1/0/all/0/1">M. Rubaiyat Hossain Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_P/0/1/0/all/0/1">Pinto Kumar Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Kose_U/0/1/0/all/0/1">Utku Kose</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01185">
                                    <div class="article-summary-box-inner">
                                        <span>Cybersecurity is a very emerging field that protects systems, networks, and
data from digital attacks. With the increase in the scale of the Internet and
the evolution of cyber attacks, developing novel cybersecurity tools has become
important, particularly for Internet of things (IoT) networks. This paper
provides a systematic review of the application of deep learning (DL)
approaches for cybersecurity. This paper provides a short description of DL
methods which is used in cybersecurity, including deep belief networks,
generative adversarial networks, recurrent neural networks, and others. Next,
we illustrate the differences between shallow learning and DL. Moreover, a
discussion is provided on the currently prevailing cyber-attacks in IoT and
other networks, and the effectiveness of DL methods to manage these attacks.
Besides, this paper describes studies that highlight the DL technique,
cybersecurity applications, and the source of datasets. Next, a discussion is
provided on the feasibility of DL systems for malware detection and
classification, intrusion detection, and other frequent cyber-attacks,
including identifying file type, spam, and network traffic. Our review
indicates that high classification accuracy of 99.72% is obtained by restricted
Boltzmann machine (RBM) when applied to a custom dataset, while long short-term
memory (LSTM) achieves an accuracy of 99.80% for KDD Cup 99 dataset. Finally,
this article discusses the importance of cybersecurity for reliable and
practicable IoT-driven healthcare systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CHISEL: Compression-Aware High-Accuracy Embedded Indoor Localization with Deep Learning. (arXiv:2107.01192v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiku_S/0/1/0/all/0/1">Saideep Tiku</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasricha_S/0/1/0/all/0/1">Sudeep Pasricha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01192">
                                    <div class="article-summary-box-inner">
                                        <span>GPS technology has revolutionized the way we localize and navigate outdoors.
However, the poor reception of GPS signals in buildings makes it unsuitable for
indoor localization. WiFi fingerprinting-based indoor localization is one of
the most promising ways to meet this demand. Unfortunately, most work in the
domain fails to resolve challenges associated with deployability on
resource-limited embedded devices. In this work, we propose a compression-aware
and high-accuracy deep learning framework called CHISEL that outperforms the
best-known works in the area while maintaining localization robustness on
embedded devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-user VoiceFilter-Lite via Attentive Speaker Embedding. (arXiv:2107.01201v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rikhye_R/0/1/0/all/0/1">Rajeev Rikhye</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liang_Q/0/1/0/all/0/1">Qiao Liang</a>, <a href="http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1">Yanzhang He</a>, <a href="http://arxiv.org/find/eess/1/au:+McGraw_I/0/1/0/all/0/1">Ian McGraw</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01201">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a solution to allow speaker conditioned speech
models, such as VoiceFilter-Lite, to support an arbitrary number of enrolled
users in a single pass. This is achieved by using an attention mechanism on
multiple speaker embeddings to compute a single attentive embedding, which is
then used as a side input to the model. We implemented multi-user
VoiceFilter-Lite and evaluated it for three tasks: (1) a streaming automatic
speech recognition (ASR) task; (2) a text-independent speaker verification
task; and (3) a personalized keyphrase detection task, where ASR has to detect
keyphrases from multiple enrolled users in a noisy environment. Our experiments
show that, with up to four enrolled users, multi-user VoiceFilter-Lite is able
to significantly reduce speech recognition and speaker verification errors when
there is overlapping speech, without affecting performance under other acoustic
conditions. This attentive speaker embedding approach can also be easily
applied to other speaker-conditioned models such as personal VAD and
personalized ASR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Uncertainty of Classifier for Unsupervised Domain Adaptation. (arXiv:2107.00727v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Shanu Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod Kumar Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Praphul Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00727">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding unsupervised domain adaptation has been an important task that
has been well explored. However, the wide variety of methods have not analyzed
the role of a classifier&#x27;s performance in detail. In this paper, we thoroughly
examine the role of a classifier in terms of matching source and target
distributions. We specifically investigate the classifier ability by matching
a) the distribution of features, b) probabilistic uncertainty for samples and
c) certainty activation mappings. Our analysis suggests that using these three
distributions does result in a consistently improved performance on all the
datasets. Our work thus extends present knowledge on the role of the various
distributions obtained from the classifier towards solving unsupervised domain
adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Algorithms for Structured Prediction. (arXiv:1809.04091v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sepehry_B/0/1/0/all/0/1">Behrooz Sepehry</a>, <a href="http://arxiv.org/find/cs/1/au:+Iranmanesh_E/0/1/0/all/0/1">Ehsan Iranmanesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedlander_M/0/1/0/all/0/1">Michael P. Friedlander</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronagh_P/0/1/0/all/0/1">Pooya Ronagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1809.04091">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce two quantum algorithms for solving structured prediction
problems. We first show that a stochastic gradient descent that uses the
quantum minimum finding algorithm and takes its probabilistic failure into
account solves the structured prediction problem with a runtime that scales
with the square root of the size of the label space, and in $\widetilde
O\left(1/\epsilon\right)$ with respect to the precision, $\epsilon$, of the
solution. Motivated by robust inference techniques in machine learning, we then
introduce another quantum algorithm that solves a smooth approximation of the
structured prediction problem with a similar quantum speedup in the size of the
label space and a similar scaling in the precision parameter. In doing so, we
analyze a variant of stochastic gradient descent for convex optimization in the
presence of an additive error in the calculation of the gradients, and show
that its convergence rate does not deteriorate if the additive errors are of
the order $O(\sqrt\epsilon)$. This algorithm uses quantum Gibbs sampling at
temperature $\Omega (\epsilon)$ as a subroutine. Based on these theoretical
observations, we propose a method for using quantum Gibbs samplers to combine
feedforward neural networks with probabilistic graphical models for quantum
machine learning. Our numerical results using Monte Carlo simulations on an
image tagging task demonstrate the benefit of the approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeformRS: Certifying Input Deformations with Randomized Smoothing. (arXiv:2107.00996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1">Adel Bibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naeemullah Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00996">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are vulnerable to input deformations in the form of
vector fields of pixel displacements and to other parameterized geometric
deformations e.g. translations, rotations, etc. Current input deformation
certification methods either (i) do not scale to deep networks on large input
datasets, or (ii) can only certify a specific class of deformations, e.g. only
rotations. We reformulate certification in randomized smoothing setting for
both general vector field and parameterized deformations and propose
DeformRS-VF and DeformRS-Par, respectively. Our new formulation scales to large
networks on large input datasets. For instance, DeformRS-Par certifies rich
deformations, covering translations, rotations, scaling, affine deformations,
and other visually aligned deformations such as ones parameterized by
Discrete-Cosine-Transform basis. Extensive experiments on MNIST, CIFAR10 and
ImageNet show that DeformRS-Par outperforms existing state-of-the-art in
certified accuracy, e.g. improved certified accuracy of 6% against perturbed
rotations in the set [-10,10] degrees on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResIST: Layer-Wise Decomposition of ResNets for Distributed Training. (arXiv:2107.00961v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Jermaine_C/0/1/0/all/0/1">Christopher M. Jermaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00961">
                                    <div class="article-summary-box-inner">
                                        <span>We propose {\rm \texttt{ResIST}}, a novel distributed training protocol for
Residual Networks (ResNets). {\rm \texttt{ResIST}} randomly decomposes a global
ResNet into several shallow sub-ResNets that are trained independently in a
distributed manner for several local iterations, before having their updates
synchronized and aggregated into the global model. In the next round, new
sub-ResNets are randomly generated and the process repeats. By construction,
per iteration, {\rm \texttt{ResIST}} communicates only a small portion of
network parameters to each machine and never uses the full model during
training. Thus, {\rm \texttt{ResIST}} reduces the communication, memory, and
time requirements of ResNet training to only a fraction of the requirements of
previous methods. In comparison to common protocols like data-parallel training
and data-parallel training with local SGD, {\rm \texttt{ResIST}} yields a
decrease in wall-clock training time, while being competitive with respect to
model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Metro Origin-Destination Prediction via Heterogeneous Information Aggregation. (arXiv:2107.00946v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingbo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuying Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_M/0/1/0/all/0/1">Mingzhi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00946">
                                    <div class="article-summary-box-inner">
                                        <span>Metro origin-destination prediction is a crucial yet challenging task for
intelligent transportation management, which aims to accurately forecast two
specific types of cross-station ridership, i.e., Origin-Destination (OD) one
and Destination-Origin (DO) one. However, complete OD matrices of previous time
intervals can not be obtained immediately in online metro systems, and
conventional methods only used limited information to forecast the future OD
and DO ridership separately.In this work, we proposed a novel neural network
module termed Heterogeneous Information Aggregation Machine (HIAM), which fully
exploits heterogeneous information of historical data (e.g., incomplete OD
matrices, unfinished order vectors, and DO matrices) to jointly learn the
evolutionary patterns of OD and DO ridership. Specifically, an OD modeling
branch estimates the potential destinations of unfinished orders explicitly to
complement the information of incomplete OD matrices, while a DO modeling
branch takes DO matrices as input to capture the spatial-temporal distribution
of DO ridership. Moreover, a Dual Information Transformer is introduced to
propagate the mutual information among OD features and DO features for modeling
the OD-DO causality and correlation. Based on the proposed HIAM, we develop a
unified Seq2Seq network to forecast the future OD and DO ridership
simultaneously. Extensive experiments conducted on two large-scale benchmarks
demonstrate the effectiveness of our method for online metro origin-destination
prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Training and Latent Space Data Augmentation for Robust Medical Image Segmentation. (arXiv:2107.01079v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammernik_K/0/1/0/all/0/1">Kerstin Hammernik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Cheng Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01079">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based segmentation methods are vulnerable to unforeseen data
distribution shifts during deployment, e.g. change of image appearances or
contrasts caused by different scanners, unexpected imaging artifacts etc. In
this paper, we present a cooperative framework for training image segmentation
models and a latent space augmentation method for generating hard examples.
Both contributions improve model generalization and robustness with limited
data. The cooperative training framework consists of a fast-thinking network
(FTN) and a slow-thinking network (STN). The FTN learns decoupled image
features and shape features for image reconstruction and segmentation tasks.
The STN learns shape priors for segmentation correction and refinement. The two
networks are trained in a cooperative manner. The latent space augmentation
generates challenging examples for training by masking the decoupled latent
space in both channel-wise and spatial-wise manners. We performed extensive
experiments on public cardiac imaging datasets. Using only 10 subjects from a
single site for training, we demonstrated improved cross-site segmentation
performance and increased robustness against various unforeseen imaging
artifacts compared to strong baseline methods. Particularly, cooperative
training with latent space data augmentation yields 15% improvement in terms of
average Dice score when compared to a standard training method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Backward-Compatible Prediction Updates: A Probabilistic Approach. (arXiv:2107.01057v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trauble_F/0/1/0/all/0/1">Frederik Tr&#xe4;uble</a>, <a href="http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleindessner_M/0/1/0/all/0/1">Matth&#xe4;us Kleindessner</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehler_P/0/1/0/all/0/1">Peter Gehler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01057">
                                    <div class="article-summary-box-inner">
                                        <span>When machine learning systems meet real world applications, accuracy is only
one of several requirements. In this paper, we assay a complementary
perspective originating from the increasing availability of pre-trained and
regularly improving state-of-the-art models. While new improved models develop
at a fast pace, downstream tasks vary more slowly or stay constant. Assume that
we have a large unlabelled data set for which we want to maintain accurate
predictions. Whenever a new and presumably better ML models becomes available,
we encounter two problems: (i) given a limited budget, which data points should
be re-evaluated using the new model?; and (ii) if the new predictions differ
from the current ones, should we update? Problem (i) is about compute cost,
which matters for very large data sets and models. Problem (ii) is about
maintaining consistency of the predictions, which can be highly relevant for
downstream applications; our demand is to avoid negative flips, i.e., changing
correct to incorrect predictions. In this paper, we formalize the Prediction
Update Problem and present an efficient probabilistic approach as answer to the
above questions. In extensive experiments on standard classification benchmark
data sets, we show that our method outperforms alternative strategies along key
metrics for backward-compatible prediction updates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Momentum Accelerates the Convergence of Stochastic AUPRC Maximization. (arXiv:2107.01173v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lijun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01173">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study stochastic optimization of areas under
precision-recall curves (AUPRC), which is widely used for combating imbalanced
classification tasks. Although a few methods have been proposed for maximizing
AUPRC, stochastic optimization of AUPRC with convergence guarantee remains an
undeveloped territory. A recent work [42] has proposed a promising approach
towards AUPRC based on maximizing a surrogate loss for the average precision,
and proved an $O(1/\epsilon^5)$ complexity for finding an $\epsilon$-stationary
solution of the non-convex objective. In this paper, we further improve the
stochastic optimization of AURPC by (i) developing novel stochastic momentum
methods with a better iteration complexity of $O(1/\epsilon^4)$ for finding an
$\epsilon$-stationary solution; and (ii) designing a novel family of stochastic
adaptive methods with the same iteration complexity of $O(1/\epsilon^4)$, which
enjoy faster convergence in practice. To this end, we propose two innovative
techniques that are critical for improving the convergence: (i) the biased
estimators for tracking individual ranking scores are updated in a randomized
coordinate-wise manner; and (ii) a momentum update is used on top of the
stochastic gradient estimator for tracking the gradient of the objective.
Extensive experiments on various data sets demonstrate the effectiveness of the
proposed algorithms. Of independent interest, the proposed stochastic momentum
and adaptive algorithms are also applicable to a class of two-level stochastic
dependent compositional optimization problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vox Populi, Vox DIY: Benchmark Dataset for Crowdsourced Audio Transcription. (arXiv:2107.01091v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pavlichenko_N/0/1/0/all/0/1">Nikita Pavlichenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Stelmakh_I/0/1/0/all/0/1">Ivan Stelmakh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ustalov_D/0/1/0/all/0/1">Dmitry Ustalov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01091">
                                    <div class="article-summary-box-inner">
                                        <span>Domain-specific data is the crux of the successful transfer of machine
learning systems from benchmarks to real life. Crowdsourcing has become one of
the standard tools for cheap and time-efficient data collection for simple
problems such as image classification: thanks in large part to advances in
research on aggregation methods. However, the applicability of crowdsourcing to
more complex tasks (e.g., speech recognition) remains limited due to the lack
of principled aggregation methods for these modalities. The main obstacle
towards designing advanced aggregation methods is the absence of training data,
and in this work, we focus on bridging this gap in speech recognition. For
this, we collect and release CrowdSpeech -- the first publicly available
large-scale dataset of crowdsourced audio transcriptions. Evaluation of
existing aggregation methods on our data shows room for improvement, suggesting
that our work may entail the design of better algorithms. At a higher level, we
also contribute to the more general challenge of collecting high-quality
datasets using crowdsourcing: we develop a principled pipeline for constructing
datasets of crowdsourced audio transcriptions in any novel domain. We show its
applicability on an under-resourced language by constructing VoxDIY -- a
counterpart of CrowdSpeech for the Russian language. We also release the code
that allows a full replication of our data collection pipeline and share
various insights on best practices of data collection via crowdsourcing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Layer Algebra: A Framework to Measure Capacity and Compression in Deep Learning. (arXiv:2107.01081v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Badias_A/0/1/0/all/0/1">Alberto Badias</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Ashis Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01081">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new framework to measure the intrinsic properties of (deep)
neural networks. While we focus on convolutional networks, our framework can be
extrapolated to any network architecture. In particular, we evaluate two
network properties, namely, capacity (related to expressivity) and compression,
both of which depend only on the network structure and are independent of the
training and test data. To this end, we propose two metrics: the first one,
called layer complexity, captures the architectural complexity of any network
layer; and, the second one, called layer intrinsic power, encodes how data is
compressed along the network. The metrics are based on the concept of layer
algebra, which is also introduced in this paper. This concept is based on the
idea that the global properties depend on the network topology, and the leaf
nodes of any neural network can be approximated using local transfer functions,
thereby, allowing a simple computation of the global metrics. We also compare
the properties of the state-of-the art architectures using our metrics and use
the properties to analyze the classification accuracy on benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NTIRE 2021 Multi-modal Aerial View Object Classification Challenge. (arXiv:2107.01189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jerrick Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1">Nathan Inkawhich</a>, <a href="http://arxiv.org/find/cs/1/au:+Nina_O/0/1/0/all/0/1">Oliver Nina</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sahil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Bob Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1">Yuru Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Songzheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiaqi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Mengru Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gongzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xueli Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Huanqia Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Chengxue Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_S/0/1/0/all/0/1">Sol Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Miron_C/0/1/0/all/0/1">Casian Miron</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasarica_A/0/1/0/all/0/1">Alexandru Pasarica</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng-Yen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1">Hung-Min Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jiarui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1">Jie Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1">Chia-Ying Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_M/0/1/0/all/0/1">Michael Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shangguan_Z/0/1/0/all/0/1">Zhongkai Shangguan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zihe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yifei_X/0/1/0/all/0/1">Xu Yifei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lehan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kele Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1">Min Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01189">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce the first Challenge on Multi-modal Aerial View
Object Classification (MAVOC) in conjunction with the NTIRE 2021 workshop at
CVPR. This challenge is composed of two different tracks using EO andSAR
imagery. Both EO and SAR sensors possess different advantages and drawbacks.
The purpose of this competition is to analyze how to use both sets of sensory
information in complementary ways. We discuss the top methods submitted for
this competition and evaluate their results on our blind test set. Our
challenge results show significant improvement of more than 15% accuracy from
our current baselines for each track of the competition</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding. (arXiv:2104.13020v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1">Jose M. Pe&#xf1;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13020">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for assessing the sensitivity of the true causal effect
to unmeasured confounding. The method requires the analyst to specify two
intuitive parameters. Otherwise, the method is assumption-free. The method
returns an interval that contains the true causal effect. Moreover, the bounds
of the interval are sharp, i.e. attainable. We show experimentally that our
bounds can be sharper than those obtained by the method of Ding and VanderWeele
(2016). Finally, we extend our method to bound the natural direct and indirect
effects when there are measured mediators and unmeasured exposure-outcome
confounding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness for Image Generation with Uncertain Sensitive Attributes. (arXiv:2106.12182v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jalal_A/0/1/0/all/0/1">Ajil Jalal</a>, <a href="http://arxiv.org/find/cs/1/au:+Karmalkar_S/0/1/0/all/0/1">Sushrut Karmalkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffmann_J/0/1/0/all/0/1">Jessica Hoffmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Price_E/0/1/0/all/0/1">Eric Price</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12182">
                                    <div class="article-summary-box-inner">
                                        <span>This work tackles the issue of fairness in the context of generative
procedures, such as image super-resolution, which entail different definitions
from the standard classification setting. Moreover, while traditional group
fairness definitions are typically defined with respect to specified protected
groups -- camouflaging the fact that these groupings are artificial and carry
historical and political motivations -- we emphasize that there are no ground
truth identities. For instance, should South and East Asians be viewed as a
single group or separate groups? Should we consider one race as a whole or
further split by gender? Choosing which groups are valid and who belongs in
them is an impossible dilemma and being &quot;fair&quot; with respect to Asians may
require being &quot;unfair&quot; with respect to South Asians. This motivates the
introduction of definitions that allow algorithms to be \emph{oblivious} to the
relevant groupings.

We define several intuitive notions of group fairness and study their
incompatibilities and trade-offs. We show that the natural extension of
demographic parity is strongly dependent on the grouping, and \emph{impossible}
to achieve obliviously. On the other hand, the conceptually new definition we
introduce, Conditional Proportional Representation, can be achieved obliviously
through Posterior Sampling. Our experiments validate our theoretical results
and achieve fair image reconstruction using state-of-the-art generative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simpler, Faster, Stronger: Breaking The log-K Curse On Contrastive Learners With FlatNCE. (arXiv:2107.01152v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xuan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1">Liqun Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1">Shuyang Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Chung_T/0/1/0/all/0/1">Tagyoung Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zeng_B/0/1/0/all/0/1">Belinda Zeng</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_W/0/1/0/all/0/1">Wenlian Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_F/0/1/0/all/0/1">Fan Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01152">
                                    <div class="article-summary-box-inner">
                                        <span>InfoNCE-based contrastive representation learners, such as SimCLR, have been
tremendously successful in recent years. However, these contrastive schemes are
notoriously resource demanding, as their effectiveness breaks down with
small-batch training (i.e., the log-K curse, whereas K is the batch-size). In
this work, we reveal mathematically why contrastive learners fail in the
small-batch-size regime, and present a novel simple, non-trivial contrastive
objective named FlatNCE, which fixes this issue. Unlike InfoNCE, our FlatNCE no
longer explicitly appeals to a discriminative classification goal for
contrastive learning. Theoretically, we show FlatNCE is the mathematical dual
formulation of InfoNCE, thus bridging the classical literature on energy
modeling; and empirically, we demonstrate that, with minimal modification of
code, FlatNCE enables immediate performance boost independent of the
subject-matter engineering efforts. The significance of this work is furthered
by the powerful generalization of contrastive learning techniques, and the
introduction of new tools to monitor and diagnose contrastive training. We
substantiate our claims with empirical evidence on CIFAR10, ImageNet, and other
datasets, where FlatNCE consistently outperforms InfoNCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combinatorial Optimization with Physics-Inspired Graph Neural Networks. (arXiv:2107.01188v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuetz_M/0/1/0/all/0/1">Martin J. A. Schuetz</a>, <a href="http://arxiv.org/find/cs/1/au:+Brubaker_J/0/1/0/all/0/1">J. Kyle Brubaker</a>, <a href="http://arxiv.org/find/cs/1/au:+Katzgraber_H/0/1/0/all/0/1">Helmut G. Katzgraber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01188">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate how graph neural networks can be used to solve combinatorial
optimization problems. Our approach is broadly applicable to canonical NP-hard
problems in the form of quadratic unconstrained binary optimization problems,
such as maximum cut, minimum vertex cover, maximum independent set, as well as
Ising spin glasses and higher-order generalizations thereof in the form of
polynomial unconstrained binary optimization problems. We apply a relaxation
strategy to the problem Hamiltonian to generate a differentiable loss function
with which we train the graph neural network and apply a simple projection to
integer variables once the unsupervised training process has completed. We
showcase our approach with numerical results for the canonical maximum cut and
maximum independent set problems. We find that the graph neural network
optimizer performs on par or outperforms existing solvers, with the ability to
scale beyond the state of the art to problems with millions of variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empirically Measuring Transfer Distance for System Design and Operation. (arXiv:2107.01184v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cody_T/0/1/0/all/0/1">Tyler Cody</a>, <a href="http://arxiv.org/find/cs/1/au:+Adams_S/0/1/0/all/0/1">Stephen Adams</a>, <a href="http://arxiv.org/find/cs/1/au:+Beling_P/0/1/0/all/0/1">Peter A. Beling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01184">
                                    <div class="article-summary-box-inner">
                                        <span>Classical machine learning approaches are sensitive to non-stationarity.
Transfer learning can address non-stationarity by sharing knowledge from one
system to another, however, in areas like machine prognostics and defense, data
is fundamentally limited. Therefore, transfer learning algorithms have little,
if any, examples from which to learn. Herein, we suggest that these constraints
on algorithmic learning can be addressed by systems engineering. We formally
define transfer distance in general terms and demonstrate its use in
empirically quantifying the transferability of models. We consider the use of
transfer distance in the design of machine rebuild procedures to allow for
transferable prognostic models. We also consider the use of transfer distance
in predicting operational performance in computer vision. Practitioners can use
the presented methodology to design and operate systems with consideration for
the learning theoretic challenges faced by component learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tengyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Ching-An Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1">Paul Mineiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Alekh Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06926">
                                    <div class="article-summary-box-inner">
                                        <span>The use of pessimism, when reasoning about datasets lacking exhaustive
exploration has recently gained prominence in offline reinforcement learning.
Despite the robustness it adds to the algorithm, overly pessimistic reasoning
can be equally damaging in precluding the discovery of good policies, which is
an issue for the popular bonus-based pessimism. In this paper, we introduce the
notion of Bellman-consistent pessimism for general function approximation:
instead of calculating a point-wise lower bound for the value function, we
implement pessimism at the initial state over the set of functions consistent
with the Bellman equations. Our theoretical guarantees only require Bellman
closedness as standard in the exploratory setting, in which case bonus-based
pessimism fails to provide guarantees. Even in the special case of linear MDPs
where stronger function-approximation assumptions hold, our result improves
upon a recent bonus-based approach by $\mathcal{O}(d)$ in its sample complexity
when the action space is finite. Remarkably, our algorithms automatically adapt
to the best bias-variance tradeoff in the hindsight, whereas most prior
approaches require tuning extra hyperparameters a priori.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-Grained Gap-Dependent Bounds for Tabular MDPs via Adaptive Multi-Step Bootstrap. (arXiv:2102.04692v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haike Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04692">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new model-free algorithm for episodic finite-horizon
Markov Decision Processes (MDP), Adaptive Multi-step Bootstrap (AMB), which
enjoys a stronger gap-dependent regret bound. The first innovation is to
estimate the optimal $Q$-function by combining an optimistic bootstrap with an
adaptive multi-step Monte Carlo rollout. The second innovation is to select the
action with the largest confidence interval length among admissible actions
that are not dominated by any other actions. We show when each state has a
unique optimal action, AMB achieves a gap-dependent regret bound that only
scales with the sum of the inverse of the sub-optimality gaps. In contrast,
Simchowitz and Jamieson (2019) showed all upper-confidence-bound (UCB)
algorithms suffer an additional $\Omega\left(\frac{S}{\Delta_{min}}\right)$
regret due to over-exploration where $\Delta_{min}$ is the minimum
sub-optimality gap and $S$ is the number of states. We further show that for
general MDPs, AMB suffers an additional $\frac{|Z_{mul}|}{\Delta_{min}}$
regret, where $Z_{mul}$ is the set of state-action pairs $(s,a)$&#x27;s satisfying
$a$ is a non-unique optimal action for $s$. We complement our upper bound with
a lower bound showing the dependency on $\frac{|Z_{mul}|}{\Delta_{min}}$ is
unavoidable for any consistent algorithm. This lower bound also implies a
separation between reinforcement learning and contextual bandits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unintended Effects on Adaptive Learning Rate for Training Neural Network with Output Scale Change. (arXiv:2103.03466v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kanoh_R/0/1/0/all/0/1">Ryuichi Kanoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Mahito Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03466">
                                    <div class="article-summary-box-inner">
                                        <span>A multiplicative constant scaling factor is often applied to the model output
to adjust the dynamics of neural network parameters. This has been used as one
of the key interventions in an empirical study of lazy and active behavior.
However, we show that the combination of such scaling and a commonly used
adaptive learning rate optimizer strongly affects the training behavior of the
neural network. This is problematic as it can cause \emph{unintended behavior}
of neural networks, resulting in the misinterpretation of experimental results.
Specifically, for some scaling settings, the effect of the adaptive learning
rate disappears or is strongly influenced by the scaling factor. To avoid the
unintended effect, we present a modification of an optimization algorithm and
demonstrate remarkable differences between adaptive learning rate optimization
and simple gradient descent, especially with a small ($&lt;1.0$) scaling factor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FF-NSL: Feed-Forward Neural-Symbolic Learner. (arXiv:2106.13103v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cunnington_D/0/1/0/all/0/1">Daniel Cunnington</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1">Mark Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1">Alessandra Russo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lobo_J/0/1/0/all/0/1">Jorge Lobo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13103">
                                    <div class="article-summary-box-inner">
                                        <span>Inductive Logic Programming (ILP) aims to learn generalised, interpretable
hypotheses in a data-efficient manner. However, current ILP systems require
training examples to be specified in a structured logical form. To address this
problem, this paper proposes a neural-symbolic learning framework, called
Feed-Forward Neural-Symbolic Learner (FF-NSL), that integrates state-of-the-art
ILP systems, based on the Answer Set semantics, with Neural Networks (NNs), in
order to learn interpretable hypotheses from labelled unstructured data. To
demonstrate the generality and robustness of FF-NSL, we use two datasets
subject to distributional shifts, for which pre-trained NNs may give incorrect
predictions with high confidence. Experimental results show that FF-NSL
outperforms tree-based and neural-based approaches by learning more accurate
and interpretable hypotheses with fewer examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm. (arXiv:2106.04763v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1">Mohammad Javad Azizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1">Branislav Kveton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04763">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of best-arm identification (BAI) in contextual bandits
in the fixed-budget setting. We propose a general successive elimination
algorithm that proceeds in stages and eliminates a fixed fraction of suboptimal
arms in each stage. This design takes advantage of the strengths of static and
adaptive allocations. We analyze the algorithm in linear models and obtain a
better error bound than prior work. We also apply it to generalized linear
models (GLMs) and bound its error. This is the first BAI algorithm for GLMs in
the fixed-budget setting. Our extensive numerical experiments show that our
algorithm outperforms the state of art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Application of neural networks to classification of data of the TUS orbital telescope. (arXiv:2106.03361v2 [astro-ph.IM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Zotov_M/0/1/0/all/0/1">Mikhail Zotov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03361">
                                    <div class="article-summary-box-inner">
                                        <span>We employ neural networks for classification of data of the TUS fluorescence
telescope, the world&#x27;s first orbital detector of ultra-high energy cosmic rays.
We focus on two particular types of signals in the TUS data: track-like flashes
produced by cosmic ray hits of the photodetector and flashes that originated
from distant lightnings. We demonstrate that even simple neural networks
combined with certain conventional methods of data analysis can be highly
effective in tasks of classification of data of fluorescence telescopes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weather-based forecasting of energy generation, consumption and price for electrical microgrids management. (arXiv:2107.01034v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Dumas_J/0/1/0/all/0/1">Jonathan Dumas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01034">
                                    <div class="article-summary-box-inner">
                                        <span>The Intergovernmental Panel on Climate Change proposes different mitigation
strategies to achieve the net emissions reductions that would be required to
follow a pathway that limits global warming to 1.5{\deg}C with no or limited
overshoot. The transition towards a carbon-free society goes through an
inevitable increase of the share of renewable generation in the energy mix and
a drastic decrease in terms of the total consumption of fossil fuels.
Therefore, this thesis studies the integration of renewables in power systems
by investigating forecasting and decision-making tools. Indeed, in contrast to
conventional power plants, renewable energy is subject to uncertainty. Most of
the generation technologies based on renewable sources are non-dispatchable,
and their production is stochastic and hard to predict in advance. A high share
of renewables is a great challenge for power systems that have been designed
and sized for dispatchable units. In this context, probabilistic forecasts,
which aim at modeling the distribution of all possible future realizations,
have become an important tool to equip decision-makers, hopefully leading to
better decisions in energy applications. This thesis focus on two main research
questions: (1) How to produce reliable probabilistic forecasts of renewable
generation, consumption, and electricity prices? (2) How to make decisions with
uncertainty using probabilistic forecasts? The thesis perimeter is the energy
management of &quot;small&quot; systems such as microgrids at a residential scale on a
day-ahead basis. It is divided into two main parts to propose directions to
address both research questions (1) a forecasting part; (2) a planning and
control part.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Optimize: A Primer and A Benchmark. (arXiv:2103.12828v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_W/0/1/0/all/0/1">Wuyang Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Heaton_H/0/1/0/all/0/1">Howard Heaton</a>, <a href="http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1">Jialin Liu</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12828">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to optimize (L2O) is an emerging approach that leverages machine
learning to develop optimization methods, aiming at reducing the laborious
iterations of hand engineering. It automates the design of an optimization
method based on its performance on a set of training problems. This data-driven
procedure generates methods that can efficiently solve problems similar to
those in the training. In sharp contrast, the typical and traditional designs
of optimization methods are theory-driven, so they obtain performance
guarantees over the classes of problems specified by the theory. The difference
makes L2O suitable for repeatedly solving a certain type of optimization
problems over a specific distribution of data, while it typically fails on
out-of-distribution problems. The practicality of L2O depends on the type of
target optimization, the chosen architecture of the method to learn, and the
training procedure. This new paradigm has motivated a community of researchers
to explore L2O and report their findings.

This article is poised to be the first comprehensive survey and benchmark of
L2O for continuous optimization. We set up taxonomies, categorize existing
works and research directions, present insights, and identify open challenges.
We also benchmarked many existing L2O approaches on a few but representative
optimization problems. For reproducible research and fair benchmarking
purposes, we released our software implementation and data in the package
Open-L2O at https://github.com/VITA-Group/Open-L2O.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kernel Thinning. (arXiv:2105.05842v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dwivedi_R/0/1/0/all/0/1">Raaz Dwivedi</a>, <a href="http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05842">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce kernel thinning, a new procedure for compressing a distribution
$\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given
a suitable reproducing kernel $\mathbf{k}$ and $\mathcal{O}(n^2)$ time, kernel
thinning compresses an $n$-point approximation to $\mathbb{P}$ into a
$\sqrt{n}$-point approximation with comparable worst-case integration error in
the associated reproducing kernel Hilbert space. With high probability, the
maximum discrepancy in integration error is
$\mathcal{O}_d(n^{-\frac{1}{2}}\sqrt{\log n})$ for compactly supported
$\mathbb{P}$ and $\mathcal{O}_d(n^{-\frac{1}{2}} \sqrt{(\log n)^{d+1}\log\log
n})$ for sub-exponential $\mathbb{P}$ on $\mathbb{R}^d$. In contrast, an
equal-sized i.i.d. sample from $\mathbb{P}$ suffers $\Omega(n^{-\frac14})$
integration error. Our sub-exponential guarantees resemble the classical
quasi-Monte Carlo error rates for uniform $\mathbb{P}$ on $[0,1]^d$ but apply
to general distributions on $\mathbb{R}^d$ and a wide range of common kernels.
We use our results to derive explicit non-asymptotic maximum mean discrepancy
bounds for Gaussian, Mat\&#x27;ern, and B-spline kernels and present two vignettes
illustrating the practical benefits of kernel thinning over i.i.d. sampling and
standard Markov chain Monte Carlo thinning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmented Federated Learning for Adaptive Intrusion Detection System. (arXiv:2107.00881v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shingi_G/0/1/0/all/0/1">Geet Shingi</a>, <a href="http://arxiv.org/find/cs/1/au:+Saglani_H/0/1/0/all/0/1">Harsh Saglani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Preeti Jain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00881">
                                    <div class="article-summary-box-inner">
                                        <span>Cyberattacks are a major issues and it causes organizations great financial,
and reputation harm. However, due to various factors, the current network
intrusion detection systems (NIDS) seem to be insufficent. Predominant NIDS
identifies Cyberattacks through a handcrafted dataset of rules. Although the
recent applications of machine learning and deep learning have alleviated the
enormous effort in NIDS, the security of network data has always been a prime
concern. However, to encounter the security problem and enable sharing among
organizations, Federated Learning (FL) scheme is employed. Although the current
FL systems have been successful, a network&#x27;s data distribution does not always
fit into a single global model as in FL. Thus, in such cases, having a single
global model in FL is no feasible. In this paper, we propose a
Segmented-Federated Learning (Segmented-FL) learning scheme for a more
efficient NIDS. The Segmented-FL approach employs periodic local model
evaluation based on which the segmentation occurs. We aim to bring similar
network environments to the same group. Further, the Segmented-FL system is
coupled with a weighted aggregation of local model parameters based on the
number of data samples a worker possesses to further augment the performance.
The improved performance by our system as compared to the FL and centralized
systems on standard dataset further validates our system and makes a strong
case for extending our technique across various tasks. The solution finds its
application in organizations that want to collaboratively learn on diverse
network environments and protect the privacy of individual datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-to-English Machine Translation Tools, Data, and Pretrained Models. (arXiv:2104.00290v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gowda_T/0/1/0/all/0/1">Thamme Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattmann_C/0/1/0/all/0/1">Chris A Mattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00290">
                                    <div class="article-summary-box-inner">
                                        <span>While there are more than 7000 languages in the world, most translation
research efforts have targeted a few high-resource languages. Commercial
translation systems support only one hundred languages or fewer, and do not
make these models available for transfer to low resource languages. In this
work, we present useful tools for machine translation research: MTData,
NLCodec, and RTG. We demonstrate their usefulness by creating a multilingual
neural machine translation model capable of translating from 500 source
languages to English. We make this multilingual model readily downloadable and
usable as a service, or as a parent model for transfer-learning to even
lower-resource languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-Speakers Single Channel Speech Separation with Optimal Permutation Training. (arXiv:2104.08955v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dovrat_S/0/1/0/all/0/1">Shaked Dovrat</a>, <a href="http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1">Eliya Nachmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08955">
                                    <div class="article-summary-box-inner">
                                        <span>Single channel speech separation has experienced great progress in the last
few years. However, training neural speech separation for a large number of
speakers (e.g., more than 10 speakers) is out of reach for the current methods,
which rely on the Permutation Invariant Loss (PIT). In this work, we present a
permutation invariant training that employs the Hungarian algorithm in order to
train with an $O(C^3)$ time complexity, where $C$ is the number of speakers, in
comparison to $O(C!)$ of PIT based methods. Furthermore, we present a modified
architecture that can handle the increased number of speakers. Our approach
separates up to $20$ speakers and improves the previous results for large $C$
by a wide margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Encoding with AutoEncoders for Weakly-supervised Anomaly Detection. (arXiv:2105.10500v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yingjie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xucheng Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fanxing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Ce Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingqiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10500">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised anomaly detection aims at learning an anomaly detector from
a limited amount of labeled data and abundant unlabeled data. Recent works
build deep neural networks for anomaly detection by discriminatively mapping
the normal samples and abnormal samples to different regions in the feature
space or fitting different distributions. However, due to the limited number of
annotated anomaly samples, directly training networks with the discriminative
loss may not be sufficient. To overcome this issue, this paper proposes a novel
strategy to transform the input data into a more meaningful representation that
could be used for anomaly detection. Specifically, we leverage an autoencoder
to encode the input data and utilize three factors, hidden representation,
reconstruction residual vector, and reconstruction error, as the new
representation for the input data. This representation amounts to encode a test
sample with its projection on the training data manifold, its direction to its
projection and its distance to its projection. In addition to this encoding, we
also propose a novel network architecture to seamlessly incorporate those three
factors. From our extensive experiments, the benefits of the proposed strategy
are clearly demonstrated by its superior performance over the competitive
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Neural Relational Inference for Interacting Systems. (arXiv:2106.11083v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramos_J/0/1/0/all/0/1">Joao A. Candido Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Blonde_L/0/1/0/all/0/1">Lionel Blond&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Armand_S/0/1/0/all/0/1">St&#xe9;phane Armand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1">Alexandros Kalousis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11083">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we want to learn to model the dynamics of similar yet distinct
groups of interacting objects. These groups follow some common physical laws
that exhibit specificities that are captured through some vectorial
description. We develop a model that allows us to do conditional generation
from any such group given its vectorial description. Unlike previous work on
learning dynamical systems that can only do trajectory completion and require a
part of the trajectory dynamics to be provided as input in generation time, we
do generation using only the conditioning vector with no access to generation
time&#x27;s trajectories. We evaluate our model in the setting of modeling human
gait and, in particular pathological human gait.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural networks for Anatomical Therapeutic Chemical (ATC). (arXiv:2101.11713v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Nanni_L/0/1/0/all/0/1">Loris Nanni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lumini_A/0/1/0/all/0/1">Alessandra Lumini</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Brahnam_S/0/1/0/all/0/1">Sheryl Brahnam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11713">
                                    <div class="article-summary-box-inner">
                                        <span>Motivation: Automatic Anatomical Therapeutic Chemical (ATC) classification is
a critical and highly competitive area of research in bioinformatics because of
its potential for expediting drug develop-ment and research. Predicting an
unknown compound&#x27;s therapeutic and chemical characteristics ac-cording to how
these characteristics affect multiple organs/systems makes automatic ATC
classifica-tion a challenging multi-label problem. Results: In this work, we
propose combining multiple multi-label classifiers trained on distinct sets of
features, including sets extracted from a Bidirectional Long Short-Term Memory
Network (BiLSTM). Experiments demonstrate the power of this approach, which is
shown to outperform the best methods reported in the literature, including the
state-of-the-art developed by the fast.ai research group. Availability: All
source code developed for this study is available at
https://github.com/LorisNanni. Contact: loris.nanni@unipd.it</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating the electrical power output of industrial devices with end-to-end time-series classification in the presence of label noise. (arXiv:2105.00349v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castellani_A/0/1/0/all/0/1">Andrea Castellani</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1">Sebastian Schmitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1">Barbara Hammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00349">
                                    <div class="article-summary-box-inner">
                                        <span>In complex industrial settings, it is common practice to monitor the
operation of machines in order to detect undesired states, adjust maintenance
schedules, optimize system performance or collect usage statistics of
individual machines. In this work, we focus on estimating the power output of a
Combined Heat and Power (CHP) machine of a medium-sized company facility by
analyzing the total facility power consumption. We formulate the problem as a
time-series classification problem where the class label represents the CHP
power output. As the facility is fully instrumented and sensor measurements
from the CHP are available, we generate the training labels in an automated
fashion from the CHP sensor readings. However, sensor failures result in
mislabeled training data samples which are hard to detect and remove from the
dataset. Therefore, we propose a novel multi-task deep learning approach that
jointly trains a classifier and an autoencoder with a shared embedding
representation. The proposed approach targets to gradually correct the
mislabelled data samples during training in a self-supervised fashion, without
any prior assumption on the amount of label noise. We benchmark our approach on
several time-series classification datasets and find it to be comparable and
sometimes better than state-of-the-art methods. On the real-world use-case of
predicting the CHP power output, we thoroughly evaluate the architectural
design choices and show that the final architecture considerably increases the
robustness of the learning process and consistently beats other recent
state-of-the-art algorithms in the presence of unstructured as well as
structured label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Textual Echo Cancellation. (arXiv:2008.06006v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ding_S/0/1/0/all/0/1">Shaojin Ding</a>, <a href="http://arxiv.org/find/eess/1/au:+Jia_Y/0/1/0/all/0/1">Ye Jia</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_K/0/1/0/all/0/1">Ke Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Q/0/1/0/all/0/1">Quan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.06006">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Textual Echo Cancellation (TEC) - a framework for
cancelling the text-to-speech (TTS) playback echo from overlapping speech
recordings. Such a system can largely improve speech recognition performance
and user experience for intelligent devices such as smart speakers, as the user
can talk to the device while the device is still playing the TTS signal
responding to the previous query. We implement this system by using a novel
sequence-to-sequence model with multi-source attention that takes both the
microphone mixture signal and source text of the TTS playback as inputs, and
predicts the enhanced audio. Experiments show that the textual information of
the TTS playback is critical to enhancement performance. Besides, the text
sequence is much smaller in size compared with the raw acoustic signal of the
TTS playback, and can be immediately transmitted to the device or ASR server
even before the playback is synthesized. Therefore, our proposed approach
effectively reduces Internet communication and latency compared with
alternative approaches such as acoustic echo cancellation (AEC).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Screening for a Reweighted Penalized Conditional Gradient Method. (arXiv:2107.01106v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yifan Sun</a>, <a href="http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01106">
                                    <div class="article-summary-box-inner">
                                        <span>The conditional gradient method (CGM) is widely used in large-scale sparse
convex optimization, having a low per iteration computational cost for
structured sparse regularizers and a greedy approach to collecting nonzeros. We
explore the sparsity acquiring properties of a general penalized CGM (P-CGM)
for convex regularizers and a reweighted penalized CGM (RP-CGM) for nonconvex
regularizers, replacing the usual convex constraints with gauge-inspired
penalties. This generalization does not increase the per-iteration complexity
noticeably. Without assuming bounded iterates or using line search, we show
$O(1/t)$ convergence of the gap of each subproblem, which measures distance to
a stationary point. We couple this with a screening rule which is safe in the
convex case, converging to the true support at a rate $O(1/(\delta^2))$ where
$\delta \geq 0$ measures how close the problem is to degeneracy. In the
nonconvex case the screening rule converges to the true support in a finite
number of iterations, but is not necessarily safe in the intermediate iterates.
In our experiments, we verify the consistency of the method and adjust the
aggressiveness of the screening rule by tuning the concavity of the
regularizer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">R2D2: Recursive Transformer based on Differentiable Tree for Interpretable Hierarchical Language Modeling. (arXiv:2107.00967v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1">Haitao Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zujie Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yafang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1">Gerard de Melo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00967">
                                    <div class="article-summary-box-inner">
                                        <span>Human language understanding operates at multiple levels of granularity
(e.g., words, phrases, and sentences) with increasing levels of abstraction
that can be hierarchically combined. However, existing deep models with stacked
layers do not explicitly model any sort of hierarchical process. This paper
proposes a recursive Transformer model based on differentiable CKY style binary
trees to emulate the composition process. We extend the bidirectional language
model pre-training objective to this architecture, attempting to predict each
word given its left and right abstraction nodes. To scale up our approach, we
also introduce an efficient pruned tree induction algorithm to enable encoding
in just a linear number of composition steps. Experimental results on language
modeling and unsupervised parsing show the effectiveness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Multivariate Signs for Nonparametric Hypothesis Testing in High Dimensions. (arXiv:2107.01103v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Majumdar_S/0/1/0/all/0/1">Subhabrata Majumdar</a>, <a href="http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1">Snigdhansu Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01103">
                                    <div class="article-summary-box-inner">
                                        <span>High-dimensional data, where the dimension of the feature space is much
larger than sample size, arise in a number of statistical applications. In this
context, we construct the generalized multivariate sign transformation, defined
as a vector divided by its norm. For different choices of the norm function,
the resulting transformed vector adapts to certain geometrical features of the
data distribution. Building up on this idea, we obtain one-sample and
two-sample testing procedures for mean vectors of high-dimensional data using
these generalized sign vectors. These tests are based on U-statistics using
kernel inner products, do not require prohibitive assumptions, and are amenable
to a fast randomization-based implementation. Through experiments in a number
of data settings, we show that tests using generalized signs display higher
power than existing tests, while maintaining nominal type-I error rates.
Finally, we provide example applications on the MNIST and Minnesota Twin
Studies genomic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unveiling the structure of wide flat minima in neural networks. (arXiv:2107.01163v1 [cond-mat.dis-nn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Baldassi_C/0/1/0/all/0/1">Carlo Baldassi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lauditi_C/0/1/0/all/0/1">Clarissa Lauditi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Malatesta_E/0/1/0/all/0/1">Enrico M. Malatesta</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Perugini_G/0/1/0/all/0/1">Gabriele Perugini</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zecchina_R/0/1/0/all/0/1">Riccardo Zecchina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01163">
                                    <div class="article-summary-box-inner">
                                        <span>The success of deep learning has revealed the application potential of neural
networks across the sciences and opened up fundamental theoretical problems. In
particular, the fact that learning algorithms based on simple variants of
gradient methods are able to find near-optimal minima of highly nonconvex loss
functions is an unexpected feature of neural networks which needs to be
understood in depth. Such algorithms are able to fit the data almost perfectly,
even in the presence of noise, and yet they have excellent predictive
capabilities. Several empirical results have shown a reproducible correlation
between the so-called flatness of the minima achieved by the algorithms and the
generalization performance. At the same time, statistical physics results have
shown that in nonconvex networks a multitude of narrow minima may coexist with
a much smaller number of wide flat minima, which generalize well. Here we show
that wide flat minima arise from the coalescence of minima that correspond to
high-margin classifications. Despite being exponentially rare compared to
zero-margin solutions, high-margin minima tend to concentrate in particular
regions. These minima are in turn surrounded by other solutions of smaller and
smaller margin, leading to dense regions of solutions over long distances. Our
analysis also provides an alternative analytical method for estimating when
flat minima appear and when algorithms begin to find solutions, as the number
of model parameters varies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Centric Domain Adaptation for Historical Text with OCR Errors. (arXiv:2107.00927v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marz_L/0/1/0/all/0/1">Luisa M&#xe4;rz</a>, <a href="http://arxiv.org/find/cs/1/au:+Schweter_S/0/1/0/all/0/1">Stefan Schweter</a>, <a href="http://arxiv.org/find/cs/1/au:+Poerner_N/0/1/0/all/0/1">Nina Poerner</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00927">
                                    <div class="article-summary-box-inner">
                                        <span>We propose new methods for in-domain and cross-domain Named Entity
Recognition (NER) on historical data for Dutch and French. For the cross-domain
case, we address domain shift by integrating unsupervised in-domain data via
contextualized string embeddings; and OCR errors by injecting synthetic OCR
errors into the source domain and address data centric domain adaptation. We
propose a general approach to imitate OCR errors in arbitrary input data. Our
cross-domain as well as our in-domain results outperform several strong
baselines and establish state-of-the-art results. We publish preprocessed
versions of the French and Dutch Europeana NER corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discretization Drift in Two-Player Games. (arXiv:2105.13922v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1">Mihaela Rosca</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Dherin_B/0/1/0/all/0/1">Benoit Dherin</a>, <a href="http://arxiv.org/find/stat/1/au:+Barrett_D/0/1/0/all/0/1">David G. T. Barrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13922">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient-based methods for two-player games produce rich dynamics that can
solve challenging problems, yet can be difficult to stabilize and understand.
Part of this complexity originates from the discrete update steps given by
simultaneous or alternating gradient descent, which causes each player to drift
away from the continuous gradient flow -- a phenomenon we call discretization
drift. Using backward error analysis, we derive modified continuous dynamical
systems that closely follow the discrete dynamics. These modified dynamics
provide an insight into the notorious challenges associated with zero-sum
games, including Generative Adversarial Networks. In particular, we identify
distinct components of the discretization drift that can alter performance and
in some cases destabilize the game. Finally, quantifying discretization drift
allows us to identify regularizers that explicitly cancel harmful forms of
drift or strengthen beneficial forms of drift, and thus improve performance of
GAN training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MegazordNet: combining statistical and machine learning standpoints for time series forecasting. (arXiv:2107.01017v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Menezes_A/0/1/0/all/0/1">Angelo Garangau Menezes</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mastelini_S/0/1/0/all/0/1">Saulo Martiello Mastelini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01017">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting financial time series is considered to be a difficult task due to
the chaotic feature of the series. Statistical approaches have shown solid
results in some specific problems such as predicting market direction and
single-price of stocks; however, with the recent advances in deep learning and
big data techniques, new promising options have arises to tackle financial time
series forecasting. Moreover, recent literature has shown that employing a
combination of statistics and machine learning may improve accuracy in the
forecasts in comparison to single solutions. Taking into consideration the
mentioned aspects, in this work, we proposed the MegazordNet, a framework that
explores statistical features within a financial series combined with a
structured deep learning model for time series forecasting. We evaluated our
approach predicting the closing price of stocks in the S&amp;P 500 using different
metrics, and we were able to beat single statistical and machine learning
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parasitic Egg Detection and Classification in Low-cost Microscopic Images using Transfer Learning. (arXiv:2107.00968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suwannaphong_T/0/1/0/all/0/1">Thanaphon Suwannaphong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chavana_S/0/1/0/all/0/1">Sawaphob Chavana</a>, <a href="http://arxiv.org/find/cs/1/au:+Tongsom_S/0/1/0/all/0/1">Sahapol Tongsom</a>, <a href="http://arxiv.org/find/cs/1/au:+Palasuwan_D/0/1/0/all/0/1">Duangdao Palasuwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chalidabhongse_T/0/1/0/all/0/1">Thanarat H. Chalidabhongse</a>, <a href="http://arxiv.org/find/cs/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00968">
                                    <div class="article-summary-box-inner">
                                        <span>Intestinal parasitic infection leads to several morbidities to humans
worldwide, especially in tropical countries. The traditional diagnosis usually
relies on manual analysis from microscopic images which is prone to human error
due to morphological similarity of different parasitic eggs and abundance of
impurities in a sample. Many studies have developed automatic systems for
parasite egg detection to reduce human workload. However, they work with high
quality microscopes, which unfortunately remain unaffordable in some rural
areas. Our work thus exploits a benefit of a low-cost USB microscope. This
instrument however provides poor quality of images due to limitation of
magnification (10x), causing difficulty in parasite detection and species
classification. In this paper, we propose a CNN-based technique using transfer
learning strategy to enhance the efficiency of automatic parasite
classification in poor-quality microscopic images. The patch-based technique
with sliding window is employed to search for location of the eggs. Two
networks, AlexNet and ResNet50, are examined with a trade-off between
architecture size and classification performance. The results show that our
proposed framework outperforms the state-of-the-art object recognition methods.
Our system combined with final decision from an expert may improve the real
faecal examination with low-cost microscopes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Personalized Medicine to Population Health: A Survey of mHealth Sensing Techniques. (arXiv:2107.00948v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sijia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukhechba_M/0/1/0/all/0/1">Mehdi Boukhechba</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1">Laura E. Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daqing Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00948">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile Sensing Apps have been widely used as a practical approach to collect
behavioral and health-related information from individuals and provide timely
intervention to promote health and well-beings, such as mental health and
chronic cares. As the objectives of mobile sensing could be either \emph{(a)
personalized medicine for individuals} or \emph{(b) public health for
populations}, in this work we review the design of these mobile sensing apps,
and propose to categorize the design of these apps/systems in two paradigms --
\emph{(i) Personal Sensing} and \emph{(ii) Crowd Sensing} paradigms. While both
sensing paradigms might incorporate with common ubiquitous sensing
technologies, such as wearable sensors, mobility monitoring, mobile data
offloading, and/or cloud-based data analytics to collect and process sensing
data from individuals, we present a novel taxonomy system with two major
components that can specify and classify apps/systems from aspects of the
life-cycle of mHealth Sensing: \emph{(1) Sensing Task Creation \&amp;
Participation}, \emph{(2) Health Surveillance \&amp; Data Collection}, and
\emph{(3) Data Analysis \&amp; Knowledge Discovery}. With respect to different
goals of the two paradigms, this work systematically reviews this field, and
summarizes the design of typical apps/systems in the view of the configurations
and interactions between these two components. In addition to summarization,
the proposed taxonomy system also helps figure out the potential directions of
mobile sensing for health from both personalized medicines and population
health perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design and implementation of an islanded hybrid microgrid system for a large resort center for Penang Island with the proper application of excess energy. (arXiv:2107.01032v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shezan_S/0/1/0/all/0/1">SK. A. Shezan</a>, <a href="http://arxiv.org/find/eess/1/au:+Rawdah_S/0/1/0/all/0/1">S. Rawdah</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1">Shafin Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Rahman_Z/0/1/0/all/0/1">Ziaur Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01032">
                                    <div class="article-summary-box-inner">
                                        <span>The energy demand is growing daily at an accelerated pace due to the
internationalization and development of civilization. Yet proper economic
utilization of additional energy generated by the Islanded Hybrid Microgrid
System (IHMS) that was not consumed by the load is a major global challenge. To
resolve the above-stated summons, this research focuses on a multi-optimal
combination of IHMS for the Penang Hill Resort located on Penang Island,
Malaysia, with effective use of redundant energy. To avail this excess energy
efficiently, an electrical heater along with a storage tank has been designed
concerning diversion load having proper energy management. Furthermore, the
system design has adopted the HOMER Pro software for profitable and practical
analysis. Alongside, MATLAB Simulink had stabilized the whole system by
representing the values of 2068 and 19,072 kW that have been determined as the
approximated peak and average load per day for the resort. Moreover, the
optimized IHMS is comprehended of Photovoltaic (PV) cells, Diesel Generator,
Wind Turbine, Battery, and Converter. Adjacent to this, the optimized system
ensued in having a Net Present Cost (NPC) of $21.66 million, Renewable Fraction
(RF) of 27.8%, Cost of Energy (COE) of $0.165/kWh, CO2 of 1,735,836 kg/year,
and excess energy of 517.29MWh per annum. Since the diesel generator lead
system was included in the scheme, a COE of $0.217/kWh, CO2 of 5,124,879
kg/year, and NPC of $23.25 million were attained. The amount of excess energy
is effectively utilized with an electrical heater as a diversion load.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Usefulness of Unsupervised monitoring in Cultural Heritage Monuments. (arXiv:2107.00964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zafeiropoulos_C/0/1/0/all/0/1">Charalampos Zafeiropoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzortzis_I/0/1/0/all/0/1">Ioannis N. Tzortzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rallis_I/0/1/0/all/0/1">Ioannis Rallis</a>, <a href="http://arxiv.org/find/cs/1/au:+Protopapadakis_E/0/1/0/all/0/1">Eftychios Protopapadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1">Nikolaos Doulamis</a>, <a href="http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1">Anastasios Doulamis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00964">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we scrutinize the effectiveness of various clustering
techniques, investigating their applicability in Cultural Heritage monitoring
applications. In the context of this paper, we detect the level of
decomposition and corrosion on the walls of Saint Nicholas fort in Rhodes
utilizing hyperspectral images. A total of 6 different clustering approaches
have been evaluated over a set of 14 different orthorectified hyperspectral
images. Experimental setup in this study involves K-means, Spectral, Meanshift,
DBSCAN, Birch and Optics algorithms. For each of these techniques we evaluate
its performance by the use of performance metrics such as Calinski-Harabasz,
Davies-Bouldin indexes and Silhouette value. In this approach, we evaluate the
outcomes of the clustering methods by comparing them with a set of annotated
images which denotes the ground truth regarding the decomposition and/or
corrosion area of the original images. The results depict that a few clustering
techniques applied on the given dataset succeeded decent accuracy, precision,
recall and f1 scores. Eventually, it was observed that the deterioration was
detected quite accurately.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DUKweb: Diachronic word representations from the UK Web Archive corpus. (arXiv:2107.01076v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsakalidis_A/0/1/0/all/0/1">Adam Tsakalidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Basile_P/0/1/0/all/0/1">Pierpaolo Basile</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazzi_M/0/1/0/all/0/1">Marya Bazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>, <a href="http://arxiv.org/find/cs/1/au:+McGillivray_B/0/1/0/all/0/1">Barbara McGillivray</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01076">
                                    <div class="article-summary-box-inner">
                                        <span>Lexical semantic change (detecting shifts in the meaning and usage of words)
is an important task for social and cultural studies as well as for Natural
Language Processing applications. Diachronic word embeddings (time-sensitive
vector representations of words that preserve their meaning) have become the
standard resource for this task. However, given the significant computational
resources needed for their generation, very few resources exist that make
diachronic word embeddings available to the scientific community.

In this paper we present DUKweb, a set of large-scale resources designed for
the diachronic analysis of contemporary English. DUKweb was created from the
JISC UK Web Domain Dataset (1996-2013), a very large archive which collects
resources from the Internet Archive that were hosted on domains ending in
&#x60;.uk&#x27;. DUKweb consists of a series word co-occurrence matrices and two types of
word embeddings for each year in the JISC UK Web Domain dataset. We show the
reuse potential of DUKweb and its quality standards via a case study on word
meaning change detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WiCluster: Passive Indoor 2D/3D Positioning using WiFi without Precise Labels. (arXiv:2107.01002v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karmanov_I/0/1/0/all/0/1">Ilia Karmanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanjani_F/0/1/0/all/0/1">Farhad G. Zanjani</a>, <a href="http://arxiv.org/find/cs/1/au:+Merlin_S/0/1/0/all/0/1">Simone Merlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadampot_I/0/1/0/all/0/1">Ishaque Kadampot</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijkman_D/0/1/0/all/0/1">Daniel Dijkman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01002">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce WiCluster, a new machine learning (ML) approach for passive
indoor positioning using radio frequency (RF) channel state information (CSI).
WiCluster can predict both a zone-level position and a precise 2D or 3D
position, without using any precise position labels during training. Prior
CSI-based indoor positioning work has relied on non-parametric approaches using
digital signal-processing (DSP) and, more recently, parametric approaches
(e.g., fully supervised ML methods). However these do not handle the complexity
of real-world environments well and do not meet requirements for large-scale
commercial deployments: the accuracy of DSP-based method deteriorates
significantly in non-line-of-sight conditions, while supervised ML methods need
large amounts of hard-to-acquire centimeter accuracy position labels. In
contrast, WiCluster is both precise and requires weaker label-information that
can be easily collected. Our first contribution is a novel dimensionality
reduction method for charting. It combines a triplet-loss with a multi-scale
clustering-loss to map the high-dimensional CSI representation to a 2D/3D
latent space. Our second contribution is two weakly supervised losses that map
this latent space into a Cartesian map, resulting in meter-accuracy position
results. These losses only require simple to acquire priors: a sketch of the
floorplan, approximate location of access-point locations and a few CSI packets
that are labeled with the corresponding zone in the floorplan. Thirdly, we
report results and a robustness study for 2D positioning in a single-floor
office building and 3D positioning in a two-floor home to show the robustness
of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure-aware reinforcement learning for node-overload protection in mobile edge computing. (arXiv:2107.01025v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jitani_A/0/1/0/all/0/1">Anirudha Jitani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1">Aditya Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhongwen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abou_zeid_H/0/1/0/all/0/1">Hatem Abou-zeid</a>, <a href="http://arxiv.org/find/cs/1/au:+Fapi_E/0/1/0/all/0/1">Emmanuel T. Fapi</a>, <a href="http://arxiv.org/find/cs/1/au:+Purmehdi_H/0/1/0/all/0/1">Hakimeh Purmehdi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01025">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile Edge Computing (MEC) refers to the concept of placing computational
capability and applications at the edge of the network, providing benefits such
as reduced latency in handling client requests, reduced network congestion, and
improved performance of applications. The performance and reliability of MEC
are degraded significantly when one or several edge servers in the cluster are
overloaded. Especially when a server crashes due to the overload, it causes
service failures in MEC. In this work, an adaptive admission control policy to
prevent edge node from getting overloaded is presented. This approach is based
on a recently-proposed low complexity RL (Reinforcement Learning) algorithm
called SALMUT (Structure-Aware Learning for Multiple Thresholds), which
exploits the structure of the optimal admission control policy in multi-class
queues for an average-cost setting. We extend the framework to work for node
overload-protection problem in a discounted-cost setting. The proposed solution
is validated using several scenarios mimicking real-world deployments in two
different settings - computer simulations and a docker testbed. Our empirical
evaluations show that the total discounted cost incurred by SALMUT is similar
to state-of-the-art deep RL algorithms such as PPO (Proximal Policy
Optimization) and A2C (Advantage Actor Critic) but requires an order of
magnitude less time to train, outputs easily interpretable policy, and can be
deployed in an online manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feeling of Presence Maximization: mmWave-Enabled Virtual Reality Meets Deep Reinforcement Learning. (arXiv:2107.01001v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Peng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quek_T/0/1/0/all/0/1">Tony Q. S. Quek</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingxuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chaoqun You</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xianbin Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01001">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the problem of providing ultra-reliable and
energy-efficient virtual reality (VR) experiences for wireless mobile users. To
ensure reliable ultra-high-definition (UHD) video frame delivery to mobile
users and enhance their immersive visual experiences, a coordinated multipoint
(CoMP) transmission technique and millimeter wave (mmWave) communications are
exploited. Owing to user movement and time-varying wireless channels, the
wireless VR experience enhancement problem is formulated as a
sequence-dependent and mixed-integer problem with a goal of maximizing users&#x27;
feeling of presence (FoP) in the virtual world, subject to power consumption
constraints on access points (APs) and users&#x27; head-mounted displays (HMDs). The
problem, however, is hard to be directly solved due to the lack of users&#x27;
accurate tracking information and the sequence-dependent and mixed-integer
characteristics. To overcome this challenge, we develop a parallel echo state
network (ESN) learning method to predict users&#x27; tracking information by
training fresh and historical tracking samples separately collected by APs.
With the learnt results, we propose a deep reinforcement learning (DRL) based
optimization algorithm to solve the formulated problem. In this algorithm, we
implement deep neural networks (DNNs) as a scalable solution to produce integer
decision variables and solving a continuous power control problem to criticize
the integer decision variables. Finally, the performance of the proposed
algorithm is compared with various benchmark algorithms, and the impact of
different design parameters is also discussed. Simulation results demonstrate
that the proposed algorithm is more 4.14% energy-efficient than the benchmark
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gamers Private Network Performance Forecasting. From Raw Data to the Data Warehouse with Machine Learning and Neural Nets. (arXiv:2107.00998v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Albert Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1">Chun Yin Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hains_G/0/1/0/all/0/1">Ga&#xe9;tan Hains</a>, <a href="http://arxiv.org/find/cs/1/au:+Humphrey_J/0/1/0/all/0/1">Jack Humphrey</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuhrmann_H/0/1/0/all/0/1">Hans Fuhrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Khmelevsky_Y/0/1/0/all/0/1">Youry Khmelevsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazur_C/0/1/0/all/0/1">Chris Mazur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00998">
                                    <div class="article-summary-box-inner">
                                        <span>Gamers Private Network (GPN) is a client/server technology that guarantees a
connection for online video games that is more reliable and lower latency than
a standard internet connection. Users of the GPN technology benefit from a
stable and high-quality gaming experience for online games, which are hosted
and played across the world. After transforming a massive volume of raw
networking data collected by WTFast, we have structured the cleaned data into a
special-purpose data warehouse and completed the extensive analysis using
machine learning and neural nets technologies, and business intelligence tools.
These analyses demonstrate the ability to predict and quantify changes in the
network and demonstrate the benefits gained from the use of a GPN for users
when connected to an online game session.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Representation for Neural Code Search. (arXiv:2107.00992v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zimin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1">Martin Monperrus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00992">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic code search is about finding semantically relevant code snippets for
a given natural language query. In the state-of-the-art approaches, the
semantic similarity between code and query is quantified as the distance of
their representation in the shared vector space. In this paper, to improve the
vector space, we introduce tree-serialization methods on a simplified form of
AST and build the multimodal representation for the code data. We conduct
extensive experiments using a single corpus that is large-scale and
multi-language: CodeSearchNet. Our results show that both our tree-serialized
representations and multimodal learning model improve the performance of neural
code search. Last, we define two intuitive quantification metrics oriented to
the completeness of semantic and syntactic information of the code data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ExplainaBoard: An Explainable Leaderboard for NLP. (arXiv:2104.06387v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yang Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shuaicheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Junqi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Zihuiwen Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zi-Yi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06387">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of NLP research, leaderboards have emerged as one
tool to track the performance of various systems on various NLP tasks. They are
effective in this goal to some extent, but generally present a rather
simplistic one-dimensional view of the submitted systems, communicated only
through holistic accuracy numbers. In this paper, we present a new
conceptualization and implementation of NLP evaluation: the ExplainaBoard,
which in addition to inheriting the functionality of the standard leaderboard,
also allows researchers to (i) diagnose strengths and weaknesses of a single
system (e.g.~what is the best-performing system bad at?) (ii) interpret
relationships between multiple systems. (e.g.~where does system A outperform
system B? What if we combine systems A, B, and C?) and (iii) examine prediction
results closely (e.g.~what are common errors made by multiple systems, or in
what contexts do particular errors occur?). So far, ExplainaBoard covers more
than 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps
updated and is recently upgraded by supporting (1) multilingual multi-task
benchmark, (2) meta-evaluation, and (3) more complicated task: machine
translation, which reviewers also suggested.} We not only released an online
platform on the website \url{this http URL} but also make
our evaluation tool an API with MIT Licence at Github
\url{https://github.com/neulab/explainaBoard} and PyPi
\url{https://pypi.org/project/interpret-eval/} that allows users to
conveniently assess their models offline. We additionally release all output
files from systems that we have run or collected to motivate &quot;output-driven&quot;
research in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-based training of Gaussian Mixture Models for High-Dimensional Streaming Data. (arXiv:1912.09379v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gepperth_A/0/1/0/all/0/1">Alexander Gepperth</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfulb_B/0/1/0/all/0/1">Benedikt Pf&#xfc;lb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.09379">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for efficiently training Gaussian Mixture Model (GMM)
by Stochastic Gradient Descent (SGD) with non-stationary, high-dimensional
streaming data. Our training scheme does not require data-driven parameter
initialization (e.g., k-means) and can thus be trained based on a random
initialization. Furthermore, the approach allows mini-batch sizes as low as 1,
which are typical for streaming-data settings. Major problems in such settings
are undesirable local optima during early training phases and numerical
instabilities due to high data dimensionalities. We introduce an adaptive
annealing procedure to address the first problem, whereas numerical
instabilities are eliminated by using an exponential-free approximation to the
standard GMM log-likelihood. Experiments on a variety of visual and non-visual
benchmarks show that our SGD approach can be trained completely without, for
instance, k-means based centroid initialization. It also compares favorably to
an online variant of Expectation-Maximization (EM) - stochastic EM (sEM), which
it outperforms by a large margin for very high-dimensional data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Spotlight: A General Method for Discovering Systematic Errors in Deep Learning Models. (arXiv:2107.00758v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+dEon_G/0/1/0/all/0/1">Greg d&#x27;Eon</a>, <a href="http://arxiv.org/find/cs/1/au:+dEon_J/0/1/0/all/0/1">Jason d&#x27;Eon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1">James R. Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Leyton_Brown_K/0/1/0/all/0/1">Kevin Leyton-Brown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00758">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised learning models often make systematic errors on rare subsets of
the data. However, such systematic errors can be difficult to identify, as
model performance can only be broken down across sensitive groups when these
groups are known and explicitly labelled. This paper introduces a method for
discovering systematic errors, which we call the spotlight. The key idea is
that similar inputs tend to have similar representations in the final hidden
layer of a neural network. We leverage this structure by &quot;shining a spotlight&quot;
on this representation space to find contiguous regions where the model
performs poorly. We show that the spotlight surfaces semantically meaningful
areas of weakness in a wide variety of model architectures, including image
classifiers, language models, and recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based statistical noise reduction for multidimensional spectral data. (arXiv:2107.00844v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Younsik Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_D/0/1/0/all/0/1">Dongjin Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Huh_S/0/1/0/all/0/1">Soonsang Huh</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dongjoon Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1">Sunbeom Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_J/0/1/0/all/0/1">Junyoung Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minsoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1">Hanyoung Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1">Jongkeun Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyung_W/0/1/0/all/0/1">Wonshik Kyung</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_B/0/1/0/all/0/1">Byungmin Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Suyoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyun_J/0/1/0/all/0/1">Jounghoon Hyun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yeonghoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yeongkwan Kimand Changyoung Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00844">
                                    <div class="article-summary-box-inner">
                                        <span>In spectroscopic experiments, data acquisition in multi-dimensional phase
space may require long acquisition time, owing to the large phase space volume
to be covered. In such case, the limited time available for data acquisition
can be a serious constraint for experiments in which multidimensional spectral
data are acquired. Here, taking angle-resolved photoemission spectroscopy
(ARPES) as an example, we demonstrate a denoising method that utilizes deep
learning as an intelligent way to overcome the constraint. With readily
available ARPES data and random generation of training data set, we
successfully trained the denoising neural network without overfitting. The
denoising neural network can remove the noise in the data while preserving its
intrinsic information. We show that the denoising neural network allows us to
perform similar level of second-derivative and line shape analysis on data
taken with two orders of magnitude less acquisition time. The importance of our
method lies in its applicability to any multidimensional spectral data that are
susceptible to statistical noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of Loss Functions to Improve Generalizability of Deep Metric Learning methods. (arXiv:2107.01130v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01130">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Metric Learning (DML) learns a non-linear semantic embedding from input
data that brings similar pairs together while keeps dissimilar data away from
each other. To this end, many different methods are proposed in the last decade
with promising results in various applications. The success of a DML algorithm
greatly depends on its loss function. However, no loss function is perfect, and
it deals only with some aspects of an optimal similarity embedding. Besides,
the generalizability of the DML on unseen categories during the test stage is
an important matter that is not considered by existing loss functions. To
address these challenges, we propose novel approaches to combine different
losses built on top of a shared deep feature extractor. The proposed ensemble
of losses enforces the deep model to extract features that are consistent with
all losses. Since the selected losses are diverse and each emphasizes different
aspects of an optimal semantic embedding, our effective combining methods yield
a considerable improvement over any individual loss and generalize well on
unseen categories. Here, there is no limitation in choosing loss functions, and
our methods can work with any set of existing ones. Besides, they can optimize
each loss function as well as its weight in an end-to-end paradigm with no need
to adjust any hyper-parameter. We evaluate our methods on some popular datasets
from the machine vision domain in conventional Zero-Shot-Learning (ZSL)
settings. The results are very encouraging and show that our methods outperform
all baseline losses by a large margin in all datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Marching Cubes. (arXiv:2106.11272v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiqin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11272">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Neural Marching Cubes (NMC), a data-driven approach for
extracting a triangle mesh from a discretized implicit field. Classical MC is
defined by coarse tessellation templates isolated to individual cubes. While
more refined tessellations have been proposed, they all make heuristic
assumptions, such as trilinearity, when determining the vertex positions and
local mesh topologies in each cube. In principle, none of these approaches can
reconstruct geometric features that reveal coherence or dependencies between
nearby cubes (e.g., a sharp edge), as such information is unaccounted for,
resulting in poor estimates of the true underlying implicit field. To tackle
these challenges, we re-cast MC from a deep learning perspective, by designing
tessellation templates more apt at preserving geometric features, and learning
the vertex positions and mesh topologies from training meshes, to account for
contextual information from nearby cubes. We develop a compact per-cube
parameterization to represent the output triangle mesh, while being compatible
with neural processing, so that a simple 3D convolutional network can be
employed for the training. We show that all topological cases in each cube that
are applicable to our design can be easily derived using our representation,
and the resulting tessellations can also be obtained naturally and efficiently
by following a few design guidelines. In addition, our network learns local
features with limited receptive fields, hence it generalizes well to new shapes
and new datasets. We evaluate our neural MC approach by quantitative and
qualitative comparisons to all well-known MC variants. In particular, we
demonstrate the ability of our network to recover sharp features such as edges
and corners, a long-standing issue of MC and its variants. Our network also
reconstructs local mesh topologies more accurately than previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Max-Mahalanobis Classifiers for Image Classification, Generation and More. (arXiv:2101.00122v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiulong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00122">
                                    <div class="article-summary-box-inner">
                                        <span>Joint Energy-based Model (JEM) of Grathwohl et al. shows that a standard
softmax classifier can be reinterpreted as an energy-based model (EBM) for the
joint distribution p(x,y); the resulting model can be optimized to improve
calibration, robustness, and out-of-distribution detection, while generating
samples rivaling the quality of recent GAN-based approaches. However, the
softmax classifier that JEM exploits is inherently discriminative and its
latent feature space is not well formulated as probabilistic distributions,
which may hinder its potential for image generation and incur training
instability. We hypothesize that generative classifiers, such as Linear
Discriminant Analysis (LDA), might be more suitable for image generation since
generative classifiers model the data generation process explicitly. This paper
therefore investigates an LDA classifier for image classification and
generation. In particular, the Max-Mahalanobis Classifier (MMC), a special case
of LDA, fits our goal very well. We show that our Generative MMC (GMMC) can be
trained discriminatively, generatively, or jointly for image classification and
generation. Extensive experiments on multiple datasets show that GMMC achieves
state-of-the-art discriminative and generative performances, while
outperforming JEM in calibration, adversarial robustness, and
out-of-distribution detection by a significant margin. Our source code is
available at https://github.com/sndnyang/GMMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Charformer: Fast Character Transformers via Gradient-based Subword Tokenization. (arXiv:2106.12672v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1">Yi Tay</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Vinh Q. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1">Jai Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hyung Won Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1">Dara Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhen Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_S/0/1/0/all/0/1">Simon Baumgartner</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1">Donald Metzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12672">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art models in natural language processing rely on separate rigid
subword tokenization algorithms, which limit their generalization ability and
adaptation to new settings. In this paper, we propose a new model inductive
bias that learns a subword tokenization end-to-end as part of the model. To
this end, we introduce a soft gradient-based subword tokenization module (GBST)
that automatically learns latent subword representations from characters in a
data-driven fashion. Concretely, GBST enumerates candidate subword blocks and
learns to score them in a position-wise fashion using a block scoring network.
We additionally introduce Charformer, a deep Transformer model that integrates
GBST and operates on the byte level. Via extensive experiments on English GLUE,
multilingual, and noisy text datasets, we show that Charformer outperforms a
series of competitive byte-level baselines while generally performing on par
and sometimes outperforming subword-based models. Additionally, Charformer is
fast, improving the speed of both vanilla byte-level and subword-level
Transformers by 28%-100% while maintaining competitive quality. We believe this
work paves the way for highly performant token-free models that are trained
completely end-to-end.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SocialAI: Benchmarking Socio-Cognitive Abilities in Deep Reinforcement Learning Agents. (arXiv:2107.00956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1">Grgur Kova&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1">R&#xe9;my Portelas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00956">
                                    <div class="article-summary-box-inner">
                                        <span>Building embodied autonomous agents capable of participating in social
interactions with humans is one of the main challenges in AI. Within the Deep
Reinforcement Learning (DRL) field, this objective motivated multiple works on
embodied language use. However, current approaches focus on language as a
communication tool in very simplified and non-diverse social situations: the
&quot;naturalness&quot; of language is reduced to the concept of high vocabulary size and
variability. In this paper, we argue that aiming towards human-level AI
requires a broader set of key social skills: 1) language use in complex and
variable social contexts; 2) beyond language, complex embodied communication in
multimodal settings within constantly evolving social worlds. We explain how
concepts from cognitive sciences could help AI to draw a roadmap towards
human-like intelligence, with a focus on its social dimensions. As a first
step, we propose to expand current research to a broader set of core social
skills. To do this, we present SocialAI, a benchmark to assess the acquisition
of social skills of DRL agents using multiple grid-world environments featuring
other (scripted) social agents. We then study the limits of a recent SOTA DRL
approach when tested on SocialAI and discuss important next steps towards
proficient social agents. Videos and code are available at
https://sites.google.com/view/socialai.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Feedback-Enabled Cyber Resilience. (arXiv:2107.00783v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yunhan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Linan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Quanyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00783">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid growth in the number of devices and their connectivity has enlarged
the attack surface and weakened cyber systems. As attackers become increasingly
sophisticated and resourceful, mere reliance on traditional cyber protection,
such as intrusion detection, firewalls, and encryption, is insufficient to
secure cyber systems. Cyber resilience provides a new security paradigm that
complements inadequate protection with resilience mechanisms. A Cyber-Resilient
Mechanism (CRM) adapts to the known or zero-day threats and uncertainties in
real-time and strategically responds to them to maintain the critical functions
of the cyber systems. Feedback architectures play a pivotal role in enabling
the online sensing, reasoning, and actuation of the CRM. Reinforcement Learning
(RL) is an important class of algorithms that epitomize the feedback
architectures for cyber resiliency, allowing the CRM to provide dynamic and
sequential responses to attacks with limited prior knowledge of the attacker.
In this work, we review the literature on RL for cyber resiliency and discuss
the cyber-resilient defenses against three major types of vulnerabilities,
i.e., posture-related, information-related, and human-related vulnerabilities.
We introduce moving target defense, defensive cyber deception, and assistive
human security technologies as three application domains of CRMs to elaborate
on their designs. The RL technique also has vulnerabilities itself. We explain
the major vulnerabilities of RL and present several attack models in which the
attacks target the rewards, the measurements, and the actuators. We show that
the attacker can trick the RL agent into learning a nefarious policy with
minimum attacking effort, which shows serious security concerns for RL-enabled
systems. Finally, we discuss the future challenges of RL for cyber security and
resiliency and emerging applications of RL-based CRMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A\c{C}AI: Ascent Similarity Caching with Approximate Indexes. (arXiv:2107.00957v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salem_T/0/1/0/all/0/1">Tareq Si Salem</a>, <a href="http://arxiv.org/find/cs/1/au:+Neglia_G/0/1/0/all/0/1">Giovanni Neglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Carra_D/0/1/0/all/0/1">Damiano Carra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00957">
                                    <div class="article-summary-box-inner">
                                        <span>Similarity search is a key operation in multimedia retrieval systems and
recommender systems, and it will play an important role also for future machine
learning and augmented reality applications. When these systems need to serve
large objects with tight delay constraints, edge servers close to the end-user
can operate as similarity caches to speed up the retrieval. In this paper we
present A\c{C}AI, a new similarity caching policy which improves on the state
of the art by using (i) an (approximate) index for the whole catalog to decide
which objects to serve locally and which to retrieve from the remote server,
and (ii) a mirror ascent algorithm to update the set of local objects with
strong guarantees even when the request process does not exhibit any
statistical regularity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consequence-aware Sequential Counterfactual Generation. (arXiv:2104.05592v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naumann_P/0/1/0/all/0/1">Philip Naumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntoutsi_E/0/1/0/all/0/1">Eirini Ntoutsi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05592">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactuals have become a popular technique nowadays for interacting with
black-box machine learning models and understanding how to change a particular
instance to obtain a desired outcome from the model. However, most existing
approaches assume instant materialization of these changes, ignoring that they
may require effort and a specific order of application. Recently, methods have
been proposed that also consider the order in which actions are applied,
leading to the so-called sequential counterfactual generation problem.

In this work, we propose a model-agnostic method for sequential
counterfactual generation. We formulate the task as a multi-objective
optimization problem and present a genetic algorithm approach to find optimal
sequences of actions leading to the counterfactuals. Our cost model considers
not only the direct effect of an action, but also its consequences.
Experimental results show that compared to state-of-the-art, our approach
generates less costly solutions, is more efficient and provides the user with a
diverse set of solutions to choose from.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Hyperparameter Optimization with BoTorch, GPyTorch and Ax. (arXiv:1912.05686v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Daniel T. Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.05686">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models are full of hyperparameters, which are set manually
before the learning process can start. To find the best configuration for these
hyperparameters in such a high dimensional space, with time-consuming and
expensive model training / validation, is not a trivial challenge. Bayesian
optimization is a powerful tool for the joint optimization of hyperparameters,
efficiently trading off exploration and exploitation of the hyperparameter
space. In this paper, we discuss Bayesian hyperparameter optimization,
including hyperparameter optimization, Bayesian optimization, and Gaussian
processes. We also review BoTorch, GPyTorch and Ax, the new open-source
frameworks that we use for Bayesian optimization, Gaussian process inference
and adaptive experimentation, respectively. For experimentation, we apply
Bayesian hyperparameter optimization, for optimizing group weights, to weighted
group pooling, which couples unsupervised tiered graph autoencoders learning
and supervised graph prediction learning for molecular graphs. We find that Ax,
BoTorch and GPyTorch together provide a simple-to-use but powerful framework
for Bayesian hyperparameter optimization, using Ax&#x27;s high-level API that
constructs and runs a full optimization loop and returns the best
hyperparameter configuration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SparseDNN: Fast Sparse Deep Learning Inference on CPUs. (arXiv:2101.07948v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07948">
                                    <div class="article-summary-box-inner">
                                        <span>The last few years have seen gigantic leaps in algorithms and systems to
support efficient deep learning inference. Pruning and quantization algorithms
can now consistently compress neural networks by an order of magnitude. For a
compressed neural network, a multitude of inference frameworks have been
designed to maximize the performance of the target hardware. While we find
mature support for quantized neural networks in production frameworks such as
OpenVINO and MNN, support for pruned sparse neural networks is still lacking.
To tackle this challenge, we present SparseDNN, a sparse deep learning
inference engine targeting CPUs. We present both kernel-level optimizations
with a sparse code generator to accelerate sparse operators and novel
network-level optimizations catering to sparse networks. We show that our
sparse code generator can achieve significant speedups over state-of-the-art
sparse and dense libraries. On end-to-end benchmarks such as Huggingface
pruneBERT, SparseDNN achieves up to 5x throughput improvement over dense
inference with state-of-the-art OpenVINO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Systematic Evaluation of Causal Discovery in Visual Model Based Reinforcement Learning. (arXiv:2107.00848v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ke_N/0/1/0/all/0/1">Nan Rosemary Ke</a>, <a href="http://arxiv.org/find/stat/1/au:+Didolkar_A/0/1/0/all/0/1">Aniket Didolkar</a>, <a href="http://arxiv.org/find/stat/1/au:+Mittal_S/0/1/0/all/0/1">Sarthak Mittal</a>, <a href="http://arxiv.org/find/stat/1/au:+Goyal_A/0/1/0/all/0/1">Anirudh Goyal</a>, <a href="http://arxiv.org/find/stat/1/au:+Lajoie_G/0/1/0/all/0/1">Guillaume Lajoie</a>, <a href="http://arxiv.org/find/stat/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/stat/1/au:+Rezende_D/0/1/0/all/0/1">Danilo Rezende</a>, <a href="http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/stat/1/au:+Mozer_M/0/1/0/all/0/1">Michael Mozer</a>, <a href="http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00848">
                                    <div class="article-summary-box-inner">
                                        <span>Inducing causal relationships from observations is a classic problem in
machine learning. Most work in causality starts from the premise that the
causal variables themselves are observed. However, for AI agents such as robots
trying to make sense of their environment, the only observables are low-level
variables like pixels in images. To generalize well, an agent must induce
high-level variables, particularly those which are causal or are affected by
causal variables. A central goal for AI and causality is thus the joint
discovery of abstract representations and causal structure. However, we note
that existing environments for studying causal induction are poorly suited for
this objective because they have complicated task-specific causal graphs which
are impossible to manipulate parametrically (e.g., number of nodes, sparsity,
causal chain length, etc.). In this work, our goal is to facilitate research in
learning representations of high-level variables as well as causal structures
among them. In order to systematically probe the ability of methods to identify
these variables and structures, we design a suite of benchmarking RL
environments. We evaluate various representation learning algorithms from the
literature and find that explicitly incorporating structure and modularity in
models can help causal induction in model-based reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SE(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials. (arXiv:2101.03164v2 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Batzner_S/0/1/0/all/0/1">Simon Batzner</a>, <a href="http://arxiv.org/find/physics/1/au:+Musaelian_A/0/1/0/all/0/1">Albert Musaelian</a>, <a href="http://arxiv.org/find/physics/1/au:+Sun_L/0/1/0/all/0/1">Lixin Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Geiger_M/0/1/0/all/0/1">Mario Geiger</a>, <a href="http://arxiv.org/find/physics/1/au:+Mailoa_J/0/1/0/all/0/1">Jonathan P. Mailoa</a>, <a href="http://arxiv.org/find/physics/1/au:+Kornbluth_M/0/1/0/all/0/1">Mordechai Kornbluth</a>, <a href="http://arxiv.org/find/physics/1/au:+Molinari_N/0/1/0/all/0/1">Nicola Molinari</a>, <a href="http://arxiv.org/find/physics/1/au:+Smidt_T/0/1/0/all/0/1">Tess E. Smidt</a>, <a href="http://arxiv.org/find/physics/1/au:+Kozinsky_B/0/1/0/all/0/1">Boris Kozinsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03164">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents Neural Equivariant Interatomic Potentials (NequIP), a
SE(3)-equivariant neural network approach for learning interatomic potentials
from ab-initio calculations for molecular dynamics simulations. While most
contemporary symmetry-aware models use invariant convolutions and only act on
scalars, NequIP employs SE(3)-equivariant convolutions for interactions of
geometric tensors, resulting in a more information-rich and faithful
representation of atomic environments. The method achieves state-of-the-art
accuracy on a challenging set of diverse molecules and materials while
exhibiting remarkable data efficiency. NequIP outperforms existing models with
up to three orders of magnitude fewer training data, challenging the widely
held belief that deep neural networks require massive training sets. The high
data efficiency of the method allows for the construction of accurate
potentials using high-order quantum chemical level of theory as reference and
enables high-fidelity molecular dynamics simulations over long time scales.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systems Theory of Transfer Learning. (arXiv:2107.01196v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cody_T/0/1/0/all/0/1">Tyler Cody</a>, <a href="http://arxiv.org/find/cs/1/au:+Beling_P/0/1/0/all/0/1">Peter A. Beling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01196">
                                    <div class="article-summary-box-inner">
                                        <span>Existing frameworks for transfer learning are incomplete from a systems
theoretic perspective. They place emphasis on notions of domain and task, and
neglect notions of structure and behavior. In doing so, they limit the extent
to which formalism can be carried through into the elaboration of their
frameworks. Herein, we use Mesarovician systems theory to define transfer
learning as a relation on sets and subsequently characterize the general nature
of transfer learning as a mathematical construct. We interpret existing
frameworks in terms of ours and go beyond existing frameworks to define notions
of transferability, transfer roughness, and transfer distance. Importantly,
despite its formalism, our framework avoids the detailed mathematics of
learning theory or machine learning solution methods without excluding their
consideration. As such, we provide a formal, general systems framework for
modeling transfer learning that offers a rigorous foundation for system design
and analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conflict-free collective stochastic decision making by orbital angular momentum entangled photons. (arXiv:2107.00877v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Amakasu_T/0/1/0/all/0/1">Takashi Amakasu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chauvet_N/0/1/0/all/0/1">Nicolas Chauvet</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bachelier_G/0/1/0/all/0/1">Guillaume Bachelier</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Huant_S/0/1/0/all/0/1">Serge Huant</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Horisaki_R/0/1/0/all/0/1">Ryoichi Horisaki</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Naruse_M/0/1/0/all/0/1">Makoto Naruse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00877">
                                    <div class="article-summary-box-inner">
                                        <span>In recent cross-disciplinary studies involving both optics and computing,
single-photon-based decision-making has been demonstrated by utilizing the
wave-particle duality of light to solve multi-armed bandit problems.
Furthermore, entangled-photon-based decision-making has managed to solve a
competitive multi-armed bandit problem in such a way that conflicts of
decisions among players are avoided while ensuring equality. However, as these
studies are based on the polarization of light, the number of available choices
is limited to two, corresponding to two orthogonal polarization states. Here we
propose a scalable principle to solve competitive decision-making situations by
using the orbital angular momentum as the tunable degree of freedom of photons,
which theoretically allows an unlimited number of arms. Moreover, by extending
the Hong-Ou-Mandel effect to more than two states, we theoretically establish
an experimental configuration able to generate entangled photon states with
orbital angular momentum and conditions that provide conflict-free selections
at every turn. We numerically examine total rewards regarding three-armed
bandit problems, for which the proposed strategy accomplishes almost the
theoretical maximum, which is greater than a conventional mixed strategy
intending to realize Nash equilibrium. This is thanks to the entanglement
property that achieves no-conflict selections, even in the exploring phase to
find the best arms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reconsidering Dependency Networks from an Information Geometry Perspective. (arXiv:2107.00871v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takabatake_K/0/1/0/all/0/1">Kazuya Takabatake</a>, <a href="http://arxiv.org/find/cs/1/au:+Akaho_S/0/1/0/all/0/1">Shotaro Akaho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00871">
                                    <div class="article-summary-box-inner">
                                        <span>Dependency networks (Heckerman et al., 2000) are potential probabilistic
graphical models for systems comprising a large number of variables. Like
Bayesian networks, the structure of a dependency network is represented by a
directed graph, and each node has a conditional probability table. Learning and
inference are realized locally on individual nodes; therefore, computation
remains tractable even with a large number of variables. However, the
dependency network&#x27;s learned distribution is the stationary distribution of a
Markov chain called pseudo-Gibbs sampling and has no closed-form expressions.
This technical disadvantage has impeded the development of dependency networks.
In this paper, we consider a certain manifold for each node. Then, we can
interpret pseudo-Gibbs sampling as iterative m-projections onto these
manifolds. This interpretation provides a theoretical bound for the location
where the stationary distribution of pseudo-Gibbs sampling exists in
distribution space. Furthermore, this interpretation involves structure and
parameter learning algorithms as optimization problems. In addition, we compare
dependency and Bayesian networks experimentally. The results demonstrate that
the dependency network and the Bayesian network have roughly the same
performance in terms of the accuracy of their learned distributions. The
results also show that the dependency network can learn much faster than the
Bayesian network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-Leakage Resilient Federated Learning. (arXiv:2107.01154v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wenqi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yanzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_G/0/1/0/all/0/1">Gong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyengar_A/0/1/0/all/0/1">Arun Iyengar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01154">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning(FL) is an emerging distributed learning paradigm with
default client privacy because clients can keep sensitive data on their devices
and only share local training parameter updates with the federated server.
However, recent studies reveal that gradient leakages in FL may compromise the
privacy of client training data. This paper presents a gradient leakage
resilient approach to privacy-preserving federated learning with per training
example-based client differential privacy, coined as Fed-CDP. It makes three
original contributions. First, we identify three types of client gradient
leakage threats in federated learning even with encrypted client-server
communications. We articulate when and why the conventional server coordinated
differential privacy approach, coined as Fed-SDP, is insufficient to protect
the privacy of the training data. Second, we introduce Fed-CDP, the per
example-based client differential privacy algorithm, and provide a formal
analysis of Fed-CDP with the $(\epsilon, \delta)$ differential privacy
guarantee, and a formal comparison between Fed-CDP and Fed-SDP in terms of
privacy accounting. Third, we formally analyze the privacy-utility trade-off
for providing differential privacy guarantee by Fed-CDP and present a dynamic
decay noise-injection policy to further improve the accuracy and resiliency of
Fed-CDP. We evaluate and compare Fed-CDP and Fed-CDP(decay) with Fed-SDP in
terms of differential privacy guarantee and gradient leakage resilience over
five benchmark datasets. The results show that the Fed-CDP approach outperforms
conventional Fed-SDP in terms of resilience to client gradient leakages while
offering competitive accuracy performance in federated learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Theory of Deep Convolutional Neural Networks III: Approximating Radial Functions. (arXiv:2107.00896v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_T/0/1/0/all/0/1">Tong Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zhongjie Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Ding-Xuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00896">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a family of deep neural networks consisting of two groups of
convolutional layers, a downsampling operator, and a fully connected layer. The
network structure depends on two structural parameters which determine the
numbers of convolutional layers and the width of the fully connected layer. We
establish an approximation theory with explicit approximation rates when the
approximated function takes a composite form $f\circ Q$ with a feature
polynomial $Q$ and a univariate function $f$. In particular, we prove that such
a network can outperform fully connected shallow networks in approximating
radial functions with $Q(x) &#x3D;|x|^2$, when the dimension $d$ of data from
$\mathbb{R}^d$ is large. This gives the first rigorous proof for the
superiority of deep convolutional neural networks in approximating functions
with special structures. Then we carry out generalization analysis for
empirical risk minimization with such a deep network in a regression framework
with the regression function of the form $f\circ Q$. Our network structure
which does not use any composite information or the functions $Q$ and $f$ can
automatically extract features and make use of the composite nature of the
regression function via tuning the structural parameters. Our analysis provides
an error bound which decreases with the network depth to a minimum and then
increases, verifying theoretically a trade-off phenomenon observed for network
depths in many practical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating deep double descent by concatenating inputs. (arXiv:2107.00797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">John Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qihan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00797">
                                    <div class="article-summary-box-inner">
                                        <span>The double descent curve is one of the most intriguing properties of deep
neural networks. It contrasts the classical bias-variance curve with the
behavior of modern neural networks, occurring where the number of samples nears
the number of parameters. In this work, we explore the connection between the
double descent phenomena and the number of samples in the deep neural network
setting. In particular, we propose a construction which augments the existing
dataset by artificially increasing the number of samples. This construction
empirically mitigates the double descent curve in this setting. We reproduce
existing work on deep double descent, and observe a smooth descent into the
overparameterized region for our construction. This occurs both with respect to
the model size, and with respect to the number epochs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-optimal Algorithms for Explainable k-Medians and k-Means. (arXiv:2107.00798v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makarychev_K/0/1/0/all/0/1">Konstantin Makarychev</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_L/0/1/0/all/0/1">Liren Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00798">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of explainable $k$-medians and $k$-means introduced
by Dasgupta, Frost, Moshkovitz, and Rashtchian~(ICML 2020). In this problem,
our goal is to find a \emph{threshold decision tree} that partitions data into
$k$ clusters and minimizes the $k$-medians or $k$-means objective. The obtained
clustering is easy to interpret because every decision node of a threshold tree
splits data based on a single feature into two groups. We propose a new
algorithm for this problem which is $\tilde O(\log k)$ competitive with
$k$-medians with $\ell_1$ norm and $\tilde O(k)$ competitive with $k$-means.
This is an improvement over the previous guarantees of $O(k)$ and $O(k^2)$ by
Dasgupta et al (2020). We also provide a new algorithm which is $O(\log^{3/2}
k)$ competitive for $k$-medians with $\ell_2$ norm. Our first algorithm is
near-optimal: Dasgupta et al (2020) showed a lower bound of $\Omega(\log k)$
for $k$-medians; in this work, we prove a lower bound of $\tilde\Omega(k)$ for
$k$-means. We also provide a lower bound of $\Omega(\log k)$ for $k$-medians
with $\ell_2$ norm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shared Data and Algorithms for Deep Learning in Fundamental Physics. (arXiv:2107.00656v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benato_L/0/1/0/all/0/1">Lisa Benato</a>, <a href="http://arxiv.org/find/cs/1/au:+Buhmann_E/0/1/0/all/0/1">Erik Buhmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdmann_M/0/1/0/all/0/1">Martin Erdmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fackeldey_P/0/1/0/all/0/1">Peter Fackeldey</a>, <a href="http://arxiv.org/find/cs/1/au:+Glombitza_J/0/1/0/all/0/1">Jonas Glombitza</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartmann_N/0/1/0/all/0/1">Nikolai Hartmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasieczka_G/0/1/0/all/0/1">Gregor Kasieczka</a>, <a href="http://arxiv.org/find/cs/1/au:+Korcari_W/0/1/0/all/0/1">William Korcari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhr_T/0/1/0/all/0/1">Thomas Kuhr</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinheimer_J/0/1/0/all/0/1">Jan Steinheimer</a>, <a href="http://arxiv.org/find/cs/1/au:+Stocker_H/0/1/0/all/0/1">Horst St&#xf6;cker</a>, <a href="http://arxiv.org/find/cs/1/au:+Plehn_T/0/1/0/all/0/1">Tilman Plehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kai Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00656">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a collection of datasets from fundamental physics research --
including particle physics, astroparticle physics, and hadron- and nuclear
physics -- for supervised machine learning studies. These datasets, containing
hadronic top quarks, cosmic-ray induced air showers, phase transitions in
hadronic matter, and generator-level histories, are made public to simplify
future work on cross-disciplinary machine learning and transfer learning in
fundamental physics. Based on these data, we present a simple yet flexible
graph-based neural network architecture that can easily be applied to a wide
range of supervised learning tasks in these domains. We show that our approach
reaches performance close to state-of-the-art dedicated methods on all
datasets. To simplify adaptation for various problems, we provide
easy-to-follow instructions on how graph-based representations of data
structures, relevant for fundamental physics, can be constructed and provide
code implementations for several of them. Implementations are also provided for
our proposed method and all reference algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cell-average based neural network method for hyperbolic and parabolic partial differential equations. (arXiv:2107.00813v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Qiu_C/0/1/0/all/0/1">Changxin Qiu</a>, <a href="http://arxiv.org/find/math/1/au:+Yan_J/0/1/0/all/0/1">Jue Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00813">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by finite volume scheme, a cell-average based neural network method
is proposed. The method is based on the integral or weak formulation of partial
differential equations. A simple feed forward network is forced to learn the
solution average evolution between two neighboring time steps. Offline
supervised training is carried out to obtain the optimal network parameter set,
which uniquely identifies one finite volume like neural network method. Once
well trained, the network method is implemented as a finite volume scheme, thus
is mesh dependent. Different to traditional numerical methods, our method can
be relieved from the explicit scheme CFL restriction and can adapt to any time
step size for solution evolution. For Heat equation, first order of convergence
is observed and the errors are related to the spatial mesh size but are
observed independent of the mesh size in time. The cell-average based neural
network method can sharply evolve contact discontinuity with almost zero
numerical diffusion introduced. Shock and rarefaction waves are well captured
for nonlinear hyperbolic conservation laws.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIMILAR: Submodular Information Measures Based Active Learning In Realistic Scenarios. (arXiv:2107.00717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kothawade_S/0/1/0/all/0/1">Suraj Kothawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Beck_N/0/1/0/all/0/1">Nathan Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1">Krishnateja Killamsetty</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00717">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning has proven to be useful for minimizing labeling costs by
selecting the most informative samples. However, existing active learning
methods do not work well in realistic scenarios such as imbalance or rare
classes, out-of-distribution data in the unlabeled set, and redundancy. In this
work, we propose SIMILAR (Submodular Information Measures based actIve
LeARning), a unified active learning framework using recently proposed
submodular information measures (SIM) as acquisition functions. We argue that
SIMILAR not only works in standard active learning, but also easily extends to
the realistic settings considered above and acts as a one-stop solution for
active learning that is scalable to large real-world datasets. Empirically, we
show that SIMILAR significantly outperforms existing active learning algorithms
by as much as ~5% - 18% in the case of rare classes and ~5% - 10% in the case
of out-of-distribution data on several image classification tasks like
CIFAR-10, MNIST, and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Experience Report on Machine Learning Reproducibility: Guidance for Practitioners and TensorFlow Model Garden Contributors. (arXiv:2107.00821v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banna_V/0/1/0/all/0/1">Vishnu Banna</a>, <a href="http://arxiv.org/find/cs/1/au:+Chinnakotla_A/0/1/0/all/0/1">Akhil Chinnakotla</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhengxin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegesana_A/0/1/0/all/0/1">Ani Vegesana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vivek_N/0/1/0/all/0/1">Naveen Vivek</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnappa_K/0/1/0/all/0/1">Kruthi Krishnappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yung-Hsiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiruvathukal_G/0/1/0/all/0/1">George K. Thiruvathukal</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James C. Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00821">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning techniques are becoming a fundamental tool for scientific
and engineering progress. These techniques are applied in contexts as diverse
as astronomy and spam filtering. However, correctly applying these techniques
requires careful engineering. Much attention has been paid to the technical
potential; relatively little attention has been paid to the software
engineering process required to bring research-based machine learning
techniques into practical utility. Technology companies have supported the
engineering community through machine learning frameworks such as TensorFLow
and PyTorch, but the details of how to engineer complex machine learning models
in these frameworks have remained hidden.

To promote best practices within the engineering community, academic
institutions and Google have partnered to launch a Special Interest Group on
Machine Learning Models (SIGMODELS) whose goal is to develop exemplary
implementations of prominent machine learning models in community locations
such as the TensorFlow Model Garden (TFMG). The purpose of this report is to
define a process for reproducing a state-of-the-art machine learning model at a
level of quality suitable for inclusion in the TFMG. We define the engineering
process and elaborate on each step, from paper analysis to model release. We
report on our experiences implementing the YOLO model family with a team of 26
student researchers, share the tools we developed, and describe the lessons we
learned along the way.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gap-Dependent Bounds for Two-Player Markov Games. (arXiv:2107.00685v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zehao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S.Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00685">
                                    <div class="article-summary-box-inner">
                                        <span>As one of the most popular methods in the field of reinforcement learning,
Q-learning has received increasing attention. Recently, there have been more
theoretical works on the regret bound of algorithms that belong to the
Q-learning class in different settings. In this paper, we analyze the
cumulative regret when conducting Nash Q-learning algorithm on 2-player
turn-based stochastic Markov games (2-TBSG), and propose the very first gap
dependent logarithmic upper bounds in the episodic tabular setting. This bound
matches the theoretical lower bound only up to a logarithmic term. Furthermore,
we extend the conclusion to the discounted game setting with infinite horizon
and propose a similar gap dependent logarithmic regret bound. Also, under the
linear MDP assumption, we obtain another logarithmic regret for 2-TBSG, in both
centralized and independent settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Map of Bandits for E-commerce. (arXiv:2107.00680v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lihong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00680">
                                    <div class="article-summary-box-inner">
                                        <span>The rich body of Bandit literature not only offers a diverse toolbox of
algorithms, but also makes it hard for a practitioner to find the right
solution to solve the problem at hand. Typical textbooks on Bandits focus on
designing and analyzing algorithms, and surveys on applications often present a
list of individual applications. While these are valuable resources, there
exists a gap in mapping applications to appropriate Bandit algorithms. In this
paper, we aim to reduce this gap with a structured map of Bandits to help
practitioners navigate to find relevant and practical Bandit algorithms.
Instead of providing a comprehensive overview, we focus on a small number of
key decision points related to reward, action, and features, which often affect
how Bandit algorithms are chosen in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets. (arXiv:2107.00860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyung_E/0/1/0/all/0/1">Eunyoung Hyung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00860">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of recent Neural Architecture Search (NAS) methods on
various tasks which have shown to output networks that largely outperform
human-designed networks, conventional NAS methods have mostly tackled the
optimization of searching for the network architecture for a single task
(dataset), which does not generalize well across multiple tasks (datasets).
Moreover, since such task-specific methods search for a neural architecture
from scratch for every given task, they incur a large computational cost, which
is problematic when the time and monetary budget are limited. In this paper, we
propose an efficient NAS framework that is trained once on a database
consisting of datasets and pretrained networks and can rapidly search for a
neural architecture for a novel dataset. The proposed MetaD2A (Meta
Dataset-to-Architecture) model can stochastically generate graphs
(architectures) from a given set (dataset) via a cross-modal latent space
learned with amortized meta-learning. Moreover, we also propose a
meta-performance predictor to estimate and select the best architecture without
direct training on target datasets. The experimental results demonstrate that
our model meta-learned on subsets of ImageNet-1K and architectures from
NAS-Bench 201 search space successfully generalizes to multiple unseen datasets
including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU
seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than
NSGANetV2, a transferable NAS method, with comparable performance. We believe
that the MetaD2A proposes a new research direction for rapid NAS as well as
ways to utilize the knowledge from rich databases of datasets and architectures
accumulated over the past years. Code is available at
https://github.com/HayeonLee/MetaD2A.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploration noise for learning linear-quadratic mean field games. (arXiv:2107.00839v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Delarue_F/0/1/0/all/0/1">Fran&#xe7;ois Delarue</a>, <a href="http://arxiv.org/find/math/1/au:+Vasileiadis_A/0/1/0/all/0/1">Athanasios Vasileiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00839">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of this paper is to demonstrate that common noise may serve as an
exploration noise for learning the solution of a mean field game. This concept
is here exemplified through a toy linear-quadratic model, for which a suitable
form of common noise has already been proven to restore existence and
uniqueness. We here go one step further and prove that the same form of common
noise may force the convergence of the learning algorithm called &#x60;fictitious
play&#x27;, and this without any further potential or monotone structure. Several
numerical examples are provided in order to support our theoretical analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Robust Drug-Target Interaction Prediction via Ensemble Modeling and Transfer Learning. (arXiv:2107.00719v1 [q-bio.BM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Kao_P/0/1/0/all/0/1">Po-Yu Kao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kao_S/0/1/0/all/0/1">Shu-Min Kao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_N/0/1/0/all/0/1">Nan-Lan Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1">Yen-Chu Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00719">
                                    <div class="article-summary-box-inner">
                                        <span>Drug-target interaction (DTI) prediction plays a crucial role in drug
discovery, and deep learning approaches have achieved state-of-the-art
performance in this field. We introduce an ensemble of deep learning models
(EnsembleDLM) for robust DTI prediction. EnsembleDLM only uses the sequence
information of chemical compounds and proteins, and it aggregates the
predictions from multiple deep neural networks. This approach reduces the
chance of overfitting, yields an unbiased prediction, and achieves
state-of-the-art performance in Davis and KIBA datasets. EnsembleDLM also
reaches state-of-the-art performance in cross-domain applications and decent
cross-domain performance (Pearson correlation coefficient and concordance index
&gt; 0.8) with transfer learning using approximately twice the amount of test data
in the new domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inverse-Dirichlet Weighting Enables Reliable Training of Physics Informed Neural Networks. (arXiv:2107.00940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maddu_S/0/1/0/all/0/1">Suryanarayana Maddu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sturm_D/0/1/0/all/0/1">Dominik Sturm</a>, <a href="http://arxiv.org/find/cs/1/au:+M%7Fuller_C/0/1/0/all/0/1">Christian L. M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sbalzarini_I/0/1/0/all/0/1">Ivo F. Sbalzarini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00940">
                                    <div class="article-summary-box-inner">
                                        <span>We characterize and remedy a failure mode that may arise from multi-scale
dynamics with scale imbalances during training of deep neural networks, such as
Physics Informed Neural Networks (PINNs). PINNs are popular machine-learning
templates that allow for seamless integration of physical equation models with
data. Their training amounts to solving an optimization problem over a weighted
sum of data-fidelity and equation-fidelity objectives. Conflicts between
objectives can arise from scale imbalances, heteroscedasticity in the data,
stiffness of the physical equation, or from catastrophic interference during
sequential training. We explain the training pathology arising from this and
propose a simple yet effective inverse-Dirichlet weighting strategy to
alleviate the issue. We compare with Sobolev training of neural networks,
providing the baseline of analytically $\boldsymbol{\epsilon}$-optimal
training. We demonstrate the effectiveness of inverse-Dirichlet weighting in
various applications, including a multi-scale model of active turbulence, where
we show orders of magnitude improvement in accuracy and convergence over
conventional PINN training. For inverse modeling using sequential training, we
find that inverse-Dirichlet weighting protects a PINN against catastrophic
forgetting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Misinformation Detection on YouTube Using Video Captions. (arXiv:2107.00941v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jagtap_R/0/1/0/all/0/1">Raj Jagtap</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhinav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_R/0/1/0/all/0/1">Rahul Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Shakshi Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rajesh Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+George_C/0/1/0/all/0/1">Clint P. George</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00941">
                                    <div class="article-summary-box-inner">
                                        <span>Millions of people use platforms such as YouTube, Facebook, Twitter, and
other mass media. Due to the accessibility of these platforms, they are often
used to establish a narrative, conduct propaganda, and disseminate
misinformation. This work proposes an approach that uses state-of-the-art NLP
techniques to extract features from video captions (subtitles). To evaluate our
approach, we utilize a publicly accessible and labeled dataset for classifying
videos as misinformation or not. The motivation behind exploring video captions
stems from our analysis of videos metadata. Attributes such as the number of
views, likes, dislikes, and comments are ineffective as videos are hard to
differentiate using this information. Using caption dataset, the proposed
models can classify videos among three classes (Misinformation, Debunking
Misinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the
relevance of the misinformation class, we re-formulate our classification
problem as a two-class classification - Misinformation vs. others (Debunking
Misinformation and Neutral). In our experiments, the proposed models can
classify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-F: A Transformer network with effective methods for learning universal sentence representation. (arXiv:2107.00653v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yu Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00653">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer model is widely used in natural language processing for
sentence representation. However, the previous Transformer-based models focus
on function words that have limited meaning in most cases and could merely
extract high-level semantic abstraction features. In this paper, two approaches
are introduced to improve the performance of Transformers. We calculated the
attention score by multiplying the part-of-speech weight vector with the
correlation coefficient, which helps extract the words with more practical
meaning. The weight vector is obtained by the input text sequence based on the
importance of the part-of-speech. Furthermore, we fuse the features of each
layer to make the sentence representation results more comprehensive and
accurate. In experiments, we demonstrate the effectiveness of our model
Transformer-F on three standard text classification datasets. Experimental
results show that our proposed model significantly boosts the performance of
text classification as compared to the baseline model. Specifically, we obtain
a 5.28% relative improvement over the vanilla Transformer on the simple tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decision tree heuristics can fail, even in the smoothed setting. (arXiv:2107.00819v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blanc_G/0/1/0/all/0/1">Guy Blanc</a>, <a href="http://arxiv.org/find/cs/1/au:+Lange_J/0/1/0/all/0/1">Jane Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_M/0/1/0/all/0/1">Mingda Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1">Li-Yang Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00819">
                                    <div class="article-summary-box-inner">
                                        <span>Greedy decision tree learning heuristics are mainstays of machine learning
practice, but theoretical justification for their empirical success remains
elusive. In fact, it has long been known that there are simple target functions
for which they fail badly (Kearns and Mansour, STOC 1996).

Recent work of Brutzkus, Daniely, and Malach (COLT 2020) considered the
smoothed analysis model as a possible avenue towards resolving this disconnect.
Within the smoothed setting and for targets $f$ that are $k$-juntas, they
showed that these heuristics successfully learn $f$ with depth-$k$ decision
tree hypotheses. They conjectured that the same guarantee holds more generally
for targets that are depth-$k$ decision trees.

We provide a counterexample to this conjecture: we construct targets that are
depth-$k$ decision trees and show that even in the smoothed setting, these
heuristics build trees of depth $2^{\Omega(k)}$ before achieving high accuracy.
We also show that the guarantees of Brutzkus et al. cannot extend to the
agnostic setting: there are targets that are very close to $k$-juntas, for
which these heuristics build trees of depth $2^{\Omega(k)}$ before achieving
high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Causal Neural Connection: Expressiveness, Learnability, and Inference. (arXiv:2107.00793v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_K/0/1/0/all/0/1">Kevin Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kai-Zhan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bareinboim_E/0/1/0/all/0/1">Elias Bareinboim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00793">
                                    <div class="article-summary-box-inner">
                                        <span>One of the central elements of any causal inference is an object called
structural causal model (SCM), which represents a collection of mechanisms and
exogenous sources of random variation of the system under investigation (Pearl,
2000). An important property of many kinds of neural networks is universal
approximability: the ability to approximate any function to arbitrary
precision. Given this property, one may be tempted to surmise that a collection
of neural nets is capable of learning any SCM by training on data generated by
that SCM. In this paper, we show this is not the case by disentangling the
notions of expressivity and learnability. Specifically, we show that the causal
hierarchy theorem (Thm. 1, Bareinboim et al., 2020), which describes the limits
of what can be learned from data, still holds for neural models. For instance,
an arbitrarily complex and expressive neural net is unable to predict the
effects of interventions given observational data alone. Given this result, we
introduce a special type of SCM called a neural causal model (NCM), and
formalize a new type of inductive bias to encode structural constraints
necessary for performing causal inferences. Building on this new class of
models, we focus on solving two canonical tasks found in the literature known
as causal identification and estimation. Leveraging the neural toolbox, we
develop an algorithm that is both sufficient and necessary to determine whether
a causal effect can be learned from data (i.e., causal identifiability); it
then estimates the effect whenever identifiability holds (causal estimation).
Simulations corroborate the proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Bridging Generic and Personalized Federated Learning. (arXiv:2107.00778v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hong-You Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00778">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is promising for its ability to collaboratively train
models with multiple clients without accessing their data, but vulnerable when
clients&#x27; data distributions diverge from each other. This divergence further
leads to a dilemma: &quot;Should we prioritize the learned model&#x27;s generic
performance (for future use at the server) or its personalized performance (for
each client)?&quot; These two, seemingly competing goals have divided the community
to focus on one or the other, yet in this paper we show that it is possible to
approach both at the same time. Concretely, we propose a novel federated
learning framework that explicitly decouples a model&#x27;s dual duties with two
prediction tasks. On the one hand, we introduce a family of losses that are
robust to non-identical class distributions, enabling clients to train a
generic predictor with a consistent objective across them. On the other hand,
we formulate the personalized predictor as a lightweight adaptive module that
is learned to minimize each client&#x27;s empirical risk on top of the generic
predictor. With this two-loss, two-predictor framework which we name Federated
Robust Decoupling Fed-RoD, the learned model can simultaneously achieve
state-of-the-art generic and personalized performance, essentially bridging the
two tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Investigation of the (In)effectiveness of Counterfactually Augmented Data. (arXiv:2107.00753v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Nitish Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">He He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00753">
                                    <div class="article-summary-box-inner">
                                        <span>While pretrained language models achieve excellent performance on natural
language understanding benchmarks, they tend to rely on spurious correlations
and generalize poorly to out-of-distribution (OOD) data. Recent work has
explored using counterfactually-augmented data (CAD) -- data generated by
minimally perturbing examples to flip the ground-truth label -- to identify
robust features that are invariant under distribution shift. However, empirical
results using CAD for OOD generalization have been mixed. To explain this
discrepancy, we draw insights from a linear Gaussian model and demonstrate the
pitfalls of CAD. Specifically, we show that (a) while CAD is effective at
identifying robust features, it may prevent the model from learning unperturbed
robust features, and (b) CAD may exacerbate existing spurious correlations in
the data. Our results show that the lack of perturbation diversity in current
CAD datasets limits its effectiveness on OOD generalization, calling for
innovative crowdsourcing procedures to elicit diverse perturbation of examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Primal Heuristics for Mixed Integer Programs. (arXiv:2107.00866v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yunzhuang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Eberhard_A/0/1/0/all/0/1">Andrew Eberhard</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaodong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00866">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel primal heuristic for Mixed Integer Programs, by
employing machine learning techniques. Mixed Integer Programming is a general
technique for formulating combinatorial optimization problems. Inside a solver,
primal heuristics play a critical role in finding good feasible solutions that
enable one to tighten the duality gap from the outset of the Branch-and-Bound
algorithm (B&amp;B), greatly improving its performance by pruning the B&amp;B tree
aggressively. In this paper, we investigate whether effective primal heuristics
can be automatically learned via machine learning. We propose a new method to
represent an optimization problem as a graph, and train a Graph Convolutional
Network on solved problem instances with known optimal solutions. This in turn
can predict the values of decision variables in the optimal solution for an
unseen problem instance of a similar type. The prediction of variable solutions
is then leveraged by a novel configuration of the B&amp;B method, Probabilistic
Branching with guided Depth-first Search (PB-DFS) approach, aiming to find
(near-)optimal solutions quickly. The experimental results show that this new
heuristic can find better primal solutions at a much earlier stage of the
solving process, compared to other state-of-the-art primal heuristics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Contrastive Learning for Accented Speech Recognition. (arXiv:2107.00921v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Tao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hantao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wei Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00921">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network based speech recognition systems suffer from performance
degradation due to accented speech, especially unfamiliar accents. In this
paper, we study the supervised contrastive learning framework for accented
speech recognition. To build different views (similar &quot;positive&quot; data samples)
for contrastive learning, three data augmentation techniques including noise
injection, spectrogram augmentation and TTS-same-sentence generation are
further investigated. From the experiments on the Common Voice dataset, we have
shown that contrastive learning helps to build data-augmentation invariant and
pronunciation invariant representations, which significantly outperforms
traditional joint training methods in both zero-shot and full-shot settings.
Experiments show that contrastive learning can improve accuracy by 3.66%
(zero-shot) and 3.78% (full-shot) on average, comparing to the joint training
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RL-NCS: Reinforcement learning based data-driven approach for nonuniform compressed sensing. (arXiv:2107.00838v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_N/0/1/0/all/0/1">Nazmul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaeemzadeh_A/0/1/0/all/0/1">Alireza Zaeemzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnavard_N/0/1/0/all/0/1">Nazanin Rahnavard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00838">
                                    <div class="article-summary-box-inner">
                                        <span>A reinforcement-learning-based non-uniform compressed sensing (NCS) framework
for time-varying signals is introduced. The proposed scheme, referred to as
RL-NCS, aims to boost the performance of signal recovery through an optimal and
adaptive distribution of sensing energy among two groups of coefficients of the
signal, referred to as the region of interest (ROI) coefficients and non-ROI
coefficients. The coefficients in ROI usually have greater importance and need
to be reconstructed with higher accuracy compared to non-ROI coefficients. In
order to accomplish this task, the ROI is predicted at each time step using two
specific approaches. One of these approaches incorporates a long short-term
memory (LSTM) network for the prediction. The other approach employs the
previous ROI information for predicting the next step ROI. Using the
exploration-exploitation technique, a Q-network learns to choose the best
approach for designing the measurement matrix. Furthermore, a joint loss
function is introduced for the efficient training of the Q-network as well as
the LSTM network. The result indicates a significant performance gain for our
proposed method, even for rapidly varying signals and a reduced number of
measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition Based on Wrist-worn Sensors. (arXiv:2107.00710v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cote_Allard_U/0/1/0/all/0/1">Ulysse C&#xf4;t&#xe9;-Allard</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakobsen_P/0/1/0/all/0/1">Petter Jakobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stautland_A/0/1/0/all/0/1">Andrea Stautland</a>, <a href="http://arxiv.org/find/cs/1/au:+Nordgreen_T/0/1/0/all/0/1">Tine Nordgreen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fasmer_O/0/1/0/all/0/1">Ole Bernt Fasmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Oedegaard_K/0/1/0/all/0/1">Ketil Joachim Oedegaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresen_J/0/1/0/all/0/1">Jim Torresen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00710">
                                    <div class="article-summary-box-inner">
                                        <span>Manic episodes of bipolar disorder can lead to uncritical behaviour and
delusional psychosis, often with destructive consequences for those affected
and their surroundings. Early detection and intervention of a manic episode are
crucial to prevent escalation, hospital admission and premature death. However,
people with bipolar disorder may not recognize that they are experiencing a
manic episode and symptoms such as euphoria and increased productivity can also
deter affected individuals from seeking help. This work proposes to perform
user-independent, automatic mood-state detection based on actigraphy and
electrodermal activity acquired from a wrist-worn device during mania and after
recovery (euthymia). This paper proposes a new deep learning-based ensemble
method leveraging long (20h) and short (5 minutes) time-intervals to
discriminate between the mood-states. When tested on 47 bipolar patients, the
proposed classification scheme achieves an average accuracy of 91.59% in
euthymic/manic mood-state recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning for Relative Density-Ratio Estimation. (arXiv:2107.00801v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kumagai_A/0/1/0/all/0/1">Atsutoshi Kumagai</a>, <a href="http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/stat/1/au:+Fujiwara_Y/0/1/0/all/0/1">Yasuhiro Fujiwara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00801">
                                    <div class="article-summary-box-inner">
                                        <span>The ratio of two probability densities, called a density-ratio, is a vital
quantity in machine learning. In particular, a relative density-ratio, which is
a bounded extension of the density-ratio, has received much attention due to
its stability and has been used in various applications such as outlier
detection and dataset comparison. Existing methods for (relative) density-ratio
estimation (DRE) require many instances from both densities. However,
sufficient instances are often unavailable in practice. In this paper, we
propose a meta-learning method for relative DRE, which estimates the relative
density-ratio from a few instances by using knowledge in related datasets.
Specifically, given two datasets that consist of a few instances, our model
extracts the datasets&#x27; information by using neural networks and uses it to
obtain instance embeddings appropriate for the relative DRE. We model the
relative density-ratio by a linear model on the embedded space, whose global
optimum solution can be obtained as a closed-form solution. The closed-form
solution enables fast and effective adaptation to a few instances, and its
differentiability enables us to train our model such that the expected test
error for relative DRE can be explicitly minimized after adapting to a few
instances. We empirically demonstrate the effectiveness of the proposed method
by using three problems: relative DRE, dataset comparison, and outlier
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">q-Paths: Generalizing the Geometric Annealing Path using Power Means. (arXiv:2107.00745v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Masrani_V/0/1/0/all/0/1">Vaden Masrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Brekelmans_R/0/1/0/all/0/1">Rob Brekelmans</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Thang Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1">Greg Ver Steeg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1">Frank Wood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00745">
                                    <div class="article-summary-box-inner">
                                        <span>Many common machine learning methods involve the geometric annealing path, a
sequence of intermediate densities between two distributions of interest
constructed using the geometric average. While alternatives such as the
moment-averaging path have demonstrated performance gains in some settings,
their practical applicability remains limited by exponential family endpoint
assumptions and a lack of closed form energy function. In this work, we
introduce $q$-paths, a family of paths which is derived from a generalized
notion of the mean, includes the geometric and arithmetic mixtures as special
cases, and admits a simple closed form involving the deformed logarithm
function from nonextensive thermodynamics. Following previous analysis of the
geometric path, we interpret our $q$-paths as corresponding to a
$q$-exponential family of distributions, and provide a variational
representation of intermediate densities as minimizing a mixture of
$\alpha$-divergences to the endpoints. We show that small deviations away from
the geometric path yield empirical gains for Bayesian inference using
Sequential Monte Carlo and generative model evaluation using Annealed
Importance Sampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-shot Learning for Unsupervised Feature Selection. (arXiv:2107.00816v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumagai_A/0/1/0/all/0/1">Atsutoshi Kumagai</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujiwara_Y/0/1/0/all/0/1">Yasuhiro Fujiwara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00816">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a few-shot learning method for unsupervised feature selection,
which is a task to select a subset of relevant features in unlabeled data.
Existing methods usually require many instances for feature selection. However,
sufficient instances are often unavailable in practice. The proposed method can
select a subset of relevant features in a target task given a few unlabeled
target instances by training with unlabeled instances in multiple source tasks.
Our model consists of a feature selector and decoder. The feature selector
outputs a subset of relevant features taking a few unlabeled instances as input
such that the decoder can reconstruct the original features of unseen instances
from the selected ones. The feature selector uses the Concrete random variables
to select features via gradient descent. To encode task-specific properties
from a few unlabeled instances to the model, the Concrete random variables and
decoder are modeled using permutation-invariant neural networks that take a few
unlabeled instances as input. Our model is trained by minimizing the expected
test reconstruction error given a few unlabeled instances that is calculated
with datasets in source tasks. We experimentally demonstrate that the proposed
method outperforms existing feature selection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-Beat Interval Estimation with Tiramisu Model: A Novel Approach with Reduced Error. (arXiv:2107.00693v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Arefeen_A/0/1/0/all/0/1">Asiful Arefeen</a>, <a href="http://arxiv.org/find/eess/1/au:+Akbari_A/0/1/0/all/0/1">Ali Akbari</a>, <a href="http://arxiv.org/find/eess/1/au:+Mirzadeh_S/0/1/0/all/0/1">Seyed Iman Mirzadeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Jafari_R/0/1/0/all/0/1">Roozbeh Jafari</a>, <a href="http://arxiv.org/find/eess/1/au:+Shirazi_B/0/1/0/all/0/1">Behrooz A. Shirazi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghasemzadeh_H/0/1/0/all/0/1">Hassan Ghasemzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00693">
                                    <div class="article-summary-box-inner">
                                        <span>Inter-beat interval (IBI) measurement enables estimation of heart-rate
variability (HRV) which, in turns, can provide early indication of potential
cardiovascular diseases. However, extracting IBIs from noisy signals is
challenging since the morphology of the signal is distorted in the presence of
the noise. Electrocardiogram (ECG) of a person in heavy motion is highly
corrupted with noise, known as motion-artifact, and IBI extracted from it is
inaccurate. As a part of remote health monitoring and wearable system
development, denoising ECG signals and estimating IBIs correctly from them have
become an emerging topic among signal-processing researchers. Apart from
conventional methods, deep-learning techniques have been successfully used in
signal denoising recently, and diagnosis process has become easier, leading to
accuracy levels that were previously unachievable. We propose a deep-learning
approach leveraging tiramisu autoencoder model to suppress motion-artifact
noise and make the R-peaks of the ECG signal prominent even in the presence of
high-intensity motion. After denoising, IBIs are estimated more accurately
expediting diagnosis tasks. Results illustrate that our method enables IBI
estimation from noisy ECG signals with SNR up to -30dB with average root mean
square error (RMSE) of 13 milliseconds for estimated IBIs. At this noise level,
our error percentage remains below 8% and outperforms other state of the art
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying Availability and Discovery in Recommender Systems via Stochastic Reachability. (arXiv:2107.00833v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Curmei_M/0/1/0/all/0/1">Mihaela Curmei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dean_S/0/1/0/all/0/1">Sarah Dean</a>, <a href="http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1">Benjamin Recht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00833">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider how preference models in interactive recommendation
systems determine the availability of content and users&#x27; opportunities for
discovery. We propose an evaluation procedure based on stochastic reachability
to quantify the maximum probability of recommending a target piece of content
to an user for a set of allowable strategic modifications. This framework
allows us to compute an upper bound on the likelihood of recommendation with
minimal assumptions about user behavior. Stochastic reachability can be used to
detect biases in the availability of content and diagnose limitations in the
opportunities for discovery granted to users. We show that this metric can be
computed efficiently as a convex program for a variety of practical settings,
and further argue that reachability is not inherently at odds with accuracy. We
demonstrate evaluations of recommendation algorithms trained on large datasets
of explicit and implicit ratings. Our results illustrate how preference models,
selection rules, and user interventions impact reachability and how these
effects can be distributed unevenly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Task Success Classifiers for Robotic Manipulation from Few Real Demonstrations. (arXiv:2107.00722v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohtasib_A/0/1/0/all/0/1">Abdalkarim Mohtasib</a>, <a href="http://arxiv.org/find/cs/1/au:+E%2E_A/0/1/0/all/0/1">Amir Ghalamzan E.</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellotto_N/0/1/0/all/0/1">Nicola Bellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuayahuitl_H/0/1/0/all/0/1">Heriberto Cuay&#xe1;huitl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00722">
                                    <div class="article-summary-box-inner">
                                        <span>Robots learning a new manipulation task from a small amount of demonstrations
are increasingly demanded in different workspaces. A classifier model assessing
the quality of actions can predict the successful completion of a task, which
can be used by intelligent agents for action-selection. This paper presents a
novel classifier that learns to classify task completion only from a few
demonstrations. We carry out a comprehensive comparison of different neural
classifiers, e.g. fully connected-based, fully convolutional-based,
sequence2sequence-based, and domain adaptation-based classification. We also
present a new dataset including five robot manipulation tasks, which is
publicly available. We compared the performances of our novel classifier and
the existing models using our dataset and the MIME dataset. The results suggest
domain adaptation and timing-based features improve success prediction. Our
novel model, i.e. fully convolutional neural network with domain adaptation and
timing features, achieves an average classification accuracy of 97.3\% and
95.5\% across tasks in both datasets whereas state-of-the-art classifiers
without domain adaptation and timing-features only achieve 82.4\% and 90.3\%,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Reinforcement Learning Tricks for Video Games. (arXiv:2107.00703v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kanervisto_A/0/1/0/all/0/1">Anssi Kanervisto</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1">Christian Scheller</a>, <a href="http://arxiv.org/find/cs/1/au:+Schraner_Y/0/1/0/all/0/1">Yanick Schraner</a>, <a href="http://arxiv.org/find/cs/1/au:+Hautamaki_V/0/1/0/all/0/1">Ville Hautam&#xe4;ki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00703">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) research focuses on general solutions that can be
applied across different domains. This results in methods that RL practitioners
can use in almost any domain. However, recent studies often lack the
engineering steps (&quot;tricks&quot;) which may be needed to effectively use RL, such as
reward shaping, curriculum learning, and splitting a large task into smaller
chunks. Such tricks are common, if not necessary, to achieve state-of-the-art
results and win RL competitions. To ease the engineering efforts, we distill
descriptions of tricks from state-of-the-art results and study how well these
tricks can improve a standard deep Q-learning agent. The long-term goal of this
work is to enable combining proven RL methods with domain-specific tricks by
providing a unified software framework and accompanying insights in multiple
domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Bike Spreading Problem. (arXiv:2107.00761v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costa_E/0/1/0/all/0/1">Elia Costa</a>, <a href="http://arxiv.org/find/cs/1/au:+Silvestri_F/0/1/0/all/0/1">Francesco Silvestri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00761">
                                    <div class="article-summary-box-inner">
                                        <span>A free-floating bike-sharing system (FFBSS) is a dockless rental system where
an individual can borrow a bike and returns it everywhere, within the service
area. To improve the rental service, available bikes should be distributed over
the entire service area: a customer leaving from any position is then more
likely to find a near bike and then to use the service. Moreover, spreading
bikes among the entire service area increases urban spatial equity since the
benefits of FFBSS are not a prerogative of just a few zones. For guaranteeing
such distribution, the FFBSS operator can use vans to manually relocate bikes,
but it incurs high economic and environmental costs. We propose a novel
approach that exploits the existing bike flows generated by customers to
distribute bikes. More specifically, by envisioning the problem as an Influence
Maximization problem, we show that it is possible to position batches of bikes
on a small number of zones, and then the daily use of FFBSS will efficiently
spread these bikes on a large area. We show that detecting these areas is
NP-complete, but there exists a simple and efficient $1-1/e$ approximation
algorithm; our approach is then evaluated on a dataset of rides from the
free-floating bike-sharing system of the city of Padova.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Almost Tight Approximation Algorithms for Explainable Clustering. (arXiv:2107.00774v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Esfandiari_H/0/1/0/all/0/1">Hossein Esfandiari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1">Shyam Narayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00774">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, due to an increasing interest for transparency in artificial
intelligence, several methods of explainable machine learning have been
developed with the simultaneous goal of accuracy and interpretability by
humans. In this paper, we study a recent framework of explainable clustering
first suggested by Dasgupta et al.~\cite{dasgupta2020explainable}.
Specifically, we focus on the $k$-means and $k$-medians problems and provide
nearly tight upper and lower bounds.

First, we provide an $O(\log k \log \log k)$-approximation algorithm for
explainable $k$-medians, improving on the best known algorithm of
$O(k)$~\cite{dasgupta2020explainable} and nearly matching the known
$\Omega(\log k)$ lower bound~\cite{dasgupta2020explainable}. In addition, in
low-dimensional spaces $d \ll \log k$, we show that our algorithm also provides
an $O(d \log^2 d)$-approximate solution for explainable $k$-medians. This
improves over the best known bound of $O(d \log k)$ for low
dimensions~\cite{laber2021explainable}, and is a constant for constant
dimensional spaces. To complement this, we show a nearly matching $\Omega(d)$
lower bound. Next, we study the $k$-means problem in this context and provide
an $O(k \log k)$-approximation algorithm for explainable $k$-means, improving
over the $O(k^2)$ bound of Dasgupta et al. and the $O(d k \log k)$ bound of
\cite{laber2021explainable}. To complement this we provide an almost tight
$\Omega(k)$ lower bound, improving over the $\Omega(\log k)$ lower bound of
Dasgupta et al. All our algorithms run in near linear time in the number of
points and the dimension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Deep Reinforcement Learning Based Stock Direction Prediction using Knowledge Graph and Community Aware Sentiments. (arXiv:2107.00931v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altuner_A/0/1/0/all/0/1">Anil Berk Altuner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilimci_Z/0/1/0/all/0/1">Zeynep Hilal Kilimci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00931">
                                    <div class="article-summary-box-inner">
                                        <span>Stock market prediction has been an important topic for investors,
researchers, and analysts. Because it is affected by too many factors, stock
market prediction is a difficult task to handle. In this study, we propose a
novel method that is based on deep reinforcement learning methodologies for the
direction prediction of stocks using sentiments of community and knowledge
graph. For this purpose, we firstly construct a social knowledge graph of users
by analyzing relations between connections. After that, time series analysis of
related stock and sentiment analysis is blended with deep reinforcement
methodology. Turkish version of Bidirectional Encoder Representations from
Transformers (BerTurk) is employed to analyze the sentiments of the users while
deep Q-learning methodology is used for the deep reinforcement learning side of
the proposed model to construct the deep Q network. In order to demonstrate the
effectiveness of the proposed model, Garanti Bank (GARAN), Akbank (AKBNK),
T\&quot;urkiye \.I\c{s} Bankas{\i} (ISCTR) stocks in Istanbul Stock Exchange are
used as a case study. Experiment results show that the proposed novel model
achieves remarkable results for stock market prediction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalizing Flow based Hidden Markov Models for Classification of Speech Phones with Explainability. (arXiv:2107.00730v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anubhab Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Honore_A/0/1/0/all/0/1">Antoine Honor&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1">Saikat Chatterjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00730">
                                    <div class="article-summary-box-inner">
                                        <span>In pursuit of explainability, we develop generative models for sequential
data. The proposed models provide state-of-the-art classification results and
robust performance for speech phone classification. We combine modern neural
networks (normalizing flows) and traditional generative models (hidden Markov
models - HMMs). Normalizing flow-based mixture models (NMMs) are used to model
the conditional probability distribution given the hidden state in the HMMs.
Model parameters are learned through judicious combinations of time-tested
Bayesian learning methods and contemporary neural network learning methods. We
mainly combine expectation-maximization (EM) and mini-batch gradient descent.
The proposed generative models can compute likelihood of a data and hence
directly suitable for maximum-likelihood (ML) classification approach. Due to
structural flexibility of HMMs, we can use different normalizing flow models.
This leads to different types of HMMs providing diversity in data modeling
capacity. The diversity provides an opportunity for easy decision fusion from
different models. For a standard speech phone classification setup involving 39
phones (classes) and the TIMIT dataset, we show that the use of standard
features called mel-frequency-cepstral-coeffcients (MFCCs), the proposed
generative models, and the decision fusion together can achieve $86.6\%$
accuracy by generative training only. This result is close to state-of-the-art
results, for examples, $86.2\%$ accuracy of PyTorch-Kaldi toolkit [1], and
$85.1\%$ accuracy using light gated recurrent units [2]. We do not use any
discriminative learning approach and related sophisticated features in this
article.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flow-based sampling for multimodal distributions in lattice field theory. (arXiv:2107.00734v1 [hep-lat])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1">Daniel C. Hackett</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Hsieh_C/0/1/0/all/0/1">Chung-Chun Hsieh</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Albergo_M/0/1/0/all/0/1">Michael S. Albergo</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1">Denis Boyda</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Chen_J/0/1/0/all/0/1">Jiunn-Wei Chen</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Chen_K/0/1/0/all/0/1">Kai-Feng Chen</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Cranmer_K/0/1/0/all/0/1">Kyle Cranmer</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1">Gurtej Kanwar</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1">Phiala E. Shanahan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00734">
                                    <div class="article-summary-box-inner">
                                        <span>Recent results have demonstrated that samplers constructed with flow-based
generative models are a promising new approach for configuration generation in
lattice field theory. In this paper, we present a set of methods to construct
flow models for targets with multiple separated modes (i.e. theories with
multiple vacua). We demonstrate the application of these methods to modeling
two-dimensional real scalar field theory in its symmetry-broken phase. In this
context we investigate the performance of different flow-based sampling
algorithms, including a composite sampling algorithm where flow-based proposals
are occasionally augmented by applying updates using traditional algorithms
like HMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-visual Attentive Fusion for Continuous Emotion Recognition. (arXiv:2107.01175v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the development set,
the achieved CCC is 0.410 for valence and 0.661 for arousal, which
significantly outperforms the baseline method with the corresponding CCC of
0.210 and 0.230 for valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instagrammable Data: Using Visuals to Showcase More Than Numbers on AJ Labs Instagram Page. (arXiv:2107.00938v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+de_Lima_Santos_M/0/1/0/all/0/1">Mathias-Felipe de-Lima-Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kooli_A/0/1/0/all/0/1">Arwa Kooli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00938">
                                    <div class="article-summary-box-inner">
                                        <span>News outlets are developing formats dedicated to social platforms that
capture audience attention, such as Instagram stories, Facebook Instant
articles, and YouTube videos. In some cases, these formats are created in
collaboration with the tech companies themselves. At the same time, the use of
data-driven storytelling is becoming increasingly integrated into the
ever-complex business models of news outlets, generating more impact and
visibility. Previous studies have focused on studying these two effects
separately. To address this gap in the literature, this paper identifies and
analyzes the use of data journalism on the Instagram content of AJ Labs, the
team dedicated to producing data-driven and interactive stories for the Al
Jazeera news network. Drawing upon a mixed-method approach, this study examines
the use and characteristics of data stories on social media platforms. Results
suggest that there is reliance on producing visual content that covers topics
such as politics and violence. In general, AJ Labs relies on the use of
infographics and produces its own unique data. To conclude, this paper suggests
potential ways to improve the use of Instagram to tell data stories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-02">2021-07-02</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards the evaluation of automatic simultaneous speech translation from a communicative perspective. (arXiv:2103.08364v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fantinuoli_C/0/1/0/all/0/1">Claudio Fantinuoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Prandi_B/0/1/0/all/0/1">Bianca Prandi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08364">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, automatic speech-to-speech and speech-to-text translation
has gained momentum thanks to advances in artificial intelligence, especially
in the domains of speech recognition and machine translation. The quality of
such applications is commonly tested with automatic metrics, such as BLEU,
primarily with the goal of assessing improvements of releases or in the context
of evaluation campaigns. However, little is known about how the output of such
systems is perceived by end users or how they compare to human performances in
similar communicative tasks.

In this paper, we present the results of an experiment aimed at evaluating
the quality of a real-time speech translation engine by comparing it to the
performance of professional simultaneous interpreters. To do so, we adopt a
framework developed for the assessment of human interpreters and use it to
perform a manual evaluation on both human and machine performances. In our
sample, we found better performance for the human interpreters in terms of
intelligibility, while the machine performs slightly better in terms of
informativeness. The limitations of the study and the possible enhancements of
the chosen framework are discussed. Despite its intrinsic limitations, the use
of this framework represents a first step towards a user-centric and
communication-oriented methodology for evaluating real-time automatic speech
translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPBERT: An Efficient Pre-training BERT on SPARQL Queries for Question Answering over Knowledge Graphs. (arXiv:2106.09997v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1">Hieu Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1">Long Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Anibal_J/0/1/0/all/0/1">James Anibal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Truong-Son Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09997">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose SPBERT, a transformer-based language model
pre-trained on massive SPARQL query logs. By incorporating masked language
modeling objectives and the word structural objective, SPBERT can learn
general-purpose representations in both natural language and SPARQL query
language. We investigate how SPBERT and encoder-decoder architecture can be
adapted for Knowledge-based QA corpora. We conduct exhaustive experiments on
two additional tasks, including SPARQL Query Construction and Answer
Verbalization Generation. The experimental results show that SPBERT can obtain
promising results, achieving state-of-the-art BLEU scores on several of these
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tweet Sentiment Quantification: An Experimental Re-Evaluation. (arXiv:2011.08091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1">Fabrizio Sebastiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08091">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment quantification is the task of estimating the relative frequency (or
&quot;prevalence&quot;) of sentiment-related classes (such as Positive, Neutral,
Negative) in a sample of unlabelled texts; this is especially important when
these texts are tweets, since most sentiment classification endeavours carried
out on Twitter data actually have quantification (and not the classification of
individual tweets) as their ultimate goal. It is well-known that solving
quantification via &quot;classify and count&quot; (i.e., by classifying all unlabelled
items via a standard classifier and counting the items that have been assigned
to a given class) is suboptimal in terms of accuracy, and that more accurate
quantification methods exist. In 2016, Gao and Sebastiani carried out a
systematic comparison of quantification methods on the task of tweet sentiment
quantification. In hindsight, we observe that the experimental protocol
followed in that work is flawed, and that its results are thus unreliable. We
now re-evaluate those quantification methods on the very same datasets, this
time following a now consolidated and much more robust experimental protocol,
that involves 5775 as many experiments as run in the original study. Our
experimentation yields results dramatically different from those obtained by
Gao and Sebastiani, and thus provide a different, much more solid understanding
of the relative strengths and weaknesses of different sentiment quantification
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Graph-based Transformer Framework for Biomedical Relation Extraction. (arXiv:2107.00596v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pingali_S/0/1/0/all/0/1">Sriram Pingali</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_S/0/1/0/all/0/1">Shweta Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutta_P/0/1/0/all/0/1">Pratik Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sriparna Saha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00596">
                                    <div class="article-summary-box-inner">
                                        <span>The recent advancement of pre-trained Transformer models has propelled the
development of effective text mining models across various biomedical tasks.
However, these models are primarily learned on the textual data and often lack
the domain knowledge of the entities to capture the context beyond the
sentence. In this study, we introduced a novel framework that enables the model
to learn multi-omnics biological information about entities (proteins) with the
help of additional multi-modal cues like molecular structure. Towards this,
rather developing modality-specific architectures, we devise a generalized and
optimized graph based multi-modal learning mechanism that utilizes the
GraphBERT model to encode the textual and molecular structure information and
exploit the underlying features of various modalities to enable end-to-end
learning. We evaluated our proposed method on ProteinProtein Interaction task
from the biomedical corpus, where our proposed generalized approach is observed
to be benefited by the additional domain-specific modality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What do End-to-End Speech Models Learn about Speaker, Language and Channel Information? A Layer-wise and Neuron-level Analysis. (arXiv:2107.00439v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1">Nadir Durrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00439">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end DNN architectures have pushed the state-of-the-art in speech
technologies, as well as in other spheres of AI, leading researchers to train
more complex and deeper models. These improvements came at the cost of
transparency. DNNs are innately opaque and difficult to interpret. We no longer
understand what features are learned, where they are preserved, and how they
inter-operate. Such an analysis is important for better model understanding,
debugging and to ensure fairness in ethical decision making. In this work, we
analyze the representations trained within deep speech models, towards the task
of speaker recognition, dialect identification and reconstruction of masked
signals. We carry a layer- and neuron-level analysis on the utterance-level
representations captured within pretrained speech models for speaker, language
and channel properties. We study: is this information captured in the learned
representations? where is it preserved? how is it distributed? and can we
identify a minimal subset of network that posses this information. Using
diagnostic classifiers, we answered these questions. Our results reveal: (i)
channel and gender information is omnipresent and is redundantly distributed
(ii) complex properties such as dialectal information is encoded only in the
task-oriented pretrained network and is localised in the upper layers (iii) a
minimal subset of neurons can be extracted to encode the predefined property
(iv) salient neurons are sometimes shared between properties and can highlights
presence of biases in the network. Our cross-architectural comparison indicates
that (v) the pretrained models captures speaker-invariant information and (vi)
the pretrained CNNs models are competitive to the Transformers for encoding
information for the studied properties. To the best of our knowledge, this is
the first study to investigate neuron analysis on the speech models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Meets Perturbations: Robust and Interpretable Attention with Adversarial Training. (arXiv:2009.12064v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kitada_S/0/1/0/all/0/1">Shunsuke Kitada</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyatomi_H/0/1/0/all/0/1">Hitoshi Iyatomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12064">
                                    <div class="article-summary-box-inner">
                                        <span>Although attention mechanisms have been applied to a variety of deep learning
models and have been shown to improve the prediction performance, it has been
reported to be vulnerable to perturbations to the mechanism. To overcome the
vulnerability to perturbations in the mechanism, we are inspired by adversarial
training (AT), which is a powerful regularization technique for enhancing the
robustness of the models. In this paper, we propose a general training
technique for natural language processing tasks, including AT for attention
(Attention AT) and more interpretable AT for attention (Attention iAT). The
proposed techniques improved the prediction performance and the model
interpretability by exploiting the mechanisms with AT. In particular, Attention
iAT boosts those advantages by introducing adversarial perturbation, which
enhances the difference in the attention of the sentences. Evaluation
experiments with ten open datasets revealed that AT for attention mechanisms,
especially Attention iAT, demonstrated (1) the best performance in nine out of
ten tasks and (2) more interpretable attention (i.e., the resulting attention
correlated more strongly with gradient-based word importance) for all tasks.
Additionally, the proposed techniques are (3) much less dependent on
perturbation size in AT. Our code is available at
https://github.com/shunk031/attention-meets-perturbation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR. (arXiv:2107.00635v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Inaguma_H/0/1/0/all/0/1">Hirofumi Inaguma</a>, <a href="http://arxiv.org/find/eess/1/au:+Kawahara_T/0/1/0/all/0/1">Tatsuya Kawahara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00635">
                                    <div class="article-summary-box-inner">
                                        <span>While attention-based encoder-decoder (AED) models have been successfully
extended to the online variants for streaming automatic speech recognition
(ASR), such as monotonic chunkwise attention (MoChA), the models still have a
large label emission latency because of the unconstrained end-to-end training
objective. Previous works tackled this problem by leveraging alignment
information to control the timing to emit tokens during training. In this work,
we propose a simple alignment-free regularization method, StableEmit, to
encourage MoChA to emit tokens earlier. StableEmit discounts the selection
probabilities in hard monotonic attention for token boundary detection by a
constant factor and regularizes them to recover the total attention mass during
training. As a result, the scale of the selection probabilities is increased,
and the values can reach a threshold for token emission earlier, leading to a
reduction of emission latency and deletion errors. Moreover, StableEmit can be
combined with methods that constraint alignments to further improve the
accuracy and latency. Experimental evaluations with LSTM and Conformer encoders
demonstrate that StableEmit significantly reduces the recognition errors and
the emission latency simultaneously. We also show that the use of alignment
information is complementary in both metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention. (arXiv:2103.15722v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chengdong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Menglong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15722">
                                    <div class="article-summary-box-inner">
                                        <span>Self-attention (SA), which encodes vector sequences according to their
pairwise similarity, is widely used in speech recognition due to its strong
context modeling ability. However, when applied to long sequence data, its
accuracy is reduced. This is caused by the fact that its weighted average
operator may lead to the dispersion of the attention distribution, which
results in the relationship between adjacent signals ignored. To address this
issue, in this paper, we introduce relative-position-awareness self-attention
(RPSA). It not only maintains the global-range dependency modeling ability of
self-attention, but also improves the localness modeling ability. Because the
local window length of the original RPSA is fixed and sensitive to different
test data, here we propose Gaussian-based self-attention (GSA) whose window
length is learnable and adaptive to the test data automatically. We further
generalize GSA to a new residual Gaussian self-attention (resGSA) for the
performance improvement. We apply RPSA, GSA, and resGSA to Transformer-based
speech recognition respectively. Experimental results on the AISHELL-1 Mandarin
speech recognition corpus demonstrate the effectiveness of the proposed
methods. For example, the resGSA-Transformer achieves a character error rate
(CER) of 5.86% on the test set, which is relative 7.8% lower than that of the
SA-Transformer. Although the performance of the proposed resGSA-Transformer is
only slightly better than that of the RPSA-Transformer, it does not have to
tune the window length manually.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dialectal Speech Recognition and Translation of Swiss German Speech to Standard German Text: Microsoft&#x27;s Submission to SwissText 2021. (arXiv:2106.08126v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Arabskyy_Y/0/1/0/all/0/1">Yuriy Arabskyy</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_A/0/1/0/all/0/1">Aashish Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1">Subhadeep Dey</a>, <a href="http://arxiv.org/find/eess/1/au:+Koller_O/0/1/0/all/0/1">Oscar Koller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08126">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the winning approach in the Shared Task 3 at SwissText
2021 on Swiss German Speech to Standard German Text, a public competition on
dialect recognition and translation. Swiss German refers to the multitude of
Alemannic dialects spoken in the German-speaking parts of Switzerland. Swiss
German differs significantly from standard German in pronunciation, word
inventory and grammar. It is mostly incomprehensible to native German speakers.
Moreover, it lacks a standardized written script. To solve the challenging
task, we propose a hybrid automatic speech recognition system with a lexicon
that incorporates translations, a 1st pass language model that deals with Swiss
German particularities, a transfer-learned acoustic model and a strong neural
language model for 2nd pass rescoring. Our submission reaches 46.04% BLEU on a
blind conversational test set and outperforms the second best competitor by a
12% relative margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keyboards as a new model of computation. (arXiv:2102.10182v3 [cs.FL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geran_Y/0/1/0/all/0/1">Yoan G&#xe9;ran</a>, <a href="http://arxiv.org/find/cs/1/au:+Laboureix_B/0/1/0/all/0/1">Bastien Laboureix</a>, <a href="http://arxiv.org/find/cs/1/au:+Mascle_C/0/1/0/all/0/1">Corto Mascle</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_V/0/1/0/all/0/1">Valentin D. Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10182">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new formalisation of languages, called keyboards. We consider
a set of elementary operations (writing/erasing a letter, going to the right or
to the left,...) and we define a keyboard as a set of finite sequences of such
operations, called keys. The corresponding language is the set of words
obtained by applying some sequence of those keys. Unlike classical models of
computation, every key can be applied anytime. We define various classes of
languages based on different sets of elementary operations, and compare their
expressive powers. We also compare them to well-known classes of languages
(Chomsky hierarchy). We obtain a strict hierarchy of languages, whose
expressivity is orthogonal to the one of the aforementionned classical models.

--

Nous introduisons une nouvelle repr\&#x27;esentation de langages, les claviers. On
se munit d&#x27;un ensemble d&#x27;op\&#x27;erations \&#x27;el\&#x27;ementaires (ajout, effacement d&#x27;une
lettre, d\&#x27;eplacement \&#x60;a droite, \&#x60;a gauche, ...), et on d\&#x27;efinit un clavier
comme un ensemble de suites finies d&#x27;op\&#x27;erations \&#x27;el\&#x27;ementaires, appel\&#x27;ees
touches. Son langage sera l&#x27;ensemble des mots obtenus en appliquant une suite
quelconque de touches. Contrairement \&#x60;a des mod\&#x60;eles de calcul classiques,
toutes les touches peuvent \^etre appliqu\&#x27;ees \&#x60;a tout moment. En premier lieu
nous d\&#x27;efinissons diff\&#x27;erentes classes de claviers en faisant varier
l&#x27;ensemble des op\&#x27;erations \&#x27;el\&#x27;ementaires autoris\&#x27;ees, et nous comparons
l&#x27;expressivit\&#x27;e des classes de langages obtenues. Nous comparons \&#x27;egalement
ces classes \&#x60;a la hi\&#x27;erarchie de Chomsky. Nous obtenons que toutes les
classes \&#x27;etudi\&#x27;ees sont diff\&#x27;erentes, et nous caract\&#x27;erisons les classes
inclues dans les rationnels et les alg\&#x27;ebriques. L&#x27;expressivit\&#x27;e des claviers
semble orthogonale \&#x60;a celle des mod\&#x60;eles \&#x27;evoqu\&#x27;es pr\&#x27;ec\&#x27;edemment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Generation of Temporally-ordered Event Sequences. (arXiv:2012.15786v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shih-Ting Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1">Nathanael Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1">Greg Durrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15786">
                                    <div class="article-summary-box-inner">
                                        <span>Models of narrative schema knowledge have proven useful for a range of
event-related tasks, but they typically do not capture the temporal
relationships between events. We propose a single model that addresses both
temporal ordering, sorting given events into the order they occurred, and event
infilling, predicting new events which fit into an existing temporally-ordered
sequence. We use a BART-based conditional generation model that can capture
both temporality and common event co-occurrence, meaning it can be flexibly
applied to different tasks in this space. Our model is trained as a denoising
autoencoder: we take temporally-ordered event sequences, shuffle them, delete
some events, and then attempt to recover the original event sequence. This task
teaches the model to make inferences given incomplete knowledge about the
events in an underlying scenario. On the temporal ordering task, we show that
our model is able to unscramble event sequences from existing datasets without
access to explicitly labeled temporal training data, outperforming both a
BERT-based pairwise model and a BERT-based pointer network. On event infilling,
human evaluation shows that our model is able to generate events that fit
better temporally into the input events when compared to GPT-2 story completion
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POSNoise: An Effective Countermeasure Against Topic Biases in Authorship Analysis. (arXiv:2005.06605v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halvani_O/0/1/0/all/0/1">Oren Halvani</a>, <a href="http://arxiv.org/find/cs/1/au:+Graner_L/0/1/0/all/0/1">Lukas Graner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06605">
                                    <div class="article-summary-box-inner">
                                        <span>Authorship verification (AV) is a fundamental research task in digital text
forensics, which addresses the problem of whether two texts were written by the
same person. In recent years, a variety of AV methods have been proposed that
focus on this problem and can be divided into two categories: The first
category refers to such methods that are based on explicitly defined features,
where one has full control over which features are considered and what they
actually represent. The second category, on the other hand, relates to such AV
methods that are based on implicitly defined features, where no control
mechanism is involved, so that any character sequence in a text can serve as a
potential feature. However, AV methods belonging to the second category bear
the risk that the topic of the texts may bias their classification predictions,
which in turn may lead to misleading conclusions regarding their results. To
tackle this problem, we propose a preprocessing technique called POSNoise,
which effectively masks topic-related content in a given text. In this way, AV
methods are forced to focus on such text units that are more related to the
writing style. Our empirical evaluation based on six AV methods (falling into
the second category) and seven corpora shows that POSNoise leads to better
results compared to a well-known topic masking approach in 34 out of 42 cases,
with an increase in accuracy of up to 10%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Feature and Instance Attribution to Detect Artifacts. (arXiv:2107.00323v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1">Pouya Pezeshkpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sarthak Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1">Byron C. Wallace</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00323">
                                    <div class="article-summary-box-inner">
                                        <span>Training the large deep neural networks that dominate NLP requires large
datasets. Many of these are collected automatically or via crowdsourcing, and
may exhibit systematic biases or annotation artifacts. By the latter, we mean
correlations between inputs and outputs that are spurious, insofar as they do
not represent a generally held causal relationship between features and
classes; models that exploit such correlations may appear to perform a given
task well, but fail on out of sample data. In this paper we propose methods to
facilitate identification of training data artifacts, using new hybrid
approaches that combine saliency maps (which highlight important input
features) with instance attribution methods (which retrieve training samples
influential to a given prediction). We show that this proposed training-feature
attribution approach can be used to uncover artifacts in training data, and use
it to identify previously unreported artifacts in a few standard NLP datasets.
We execute a small user study to evaluate whether these methods are useful to
NLP researchers in practice, with promising results. We make code for all
methods and experiments in this paper available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Dependency Parsing for Semi-Structured Document Information Extraction. (arXiv:2005.00642v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonseok Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yim_J/0/1/0/all/0/1">Jinyeong Yim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sohee Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minjoon Seo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00642">
                                    <div class="article-summary-box-inner">
                                        <span>Information Extraction (IE) for semi-structured document images is often
approached as a sequence tagging problem by classifying each recognized input
token into one of the IOB (Inside, Outside, and Beginning) categories. However,
such problem setup has two inherent limitations that (1) it cannot easily
handle complex spatial relationships and (2) it is not suitable for highly
structured information, which are nevertheless frequently observed in
real-world document images. To tackle these issues, we first formulate the IE
task as spatial dependency parsing problem that focuses on the relationship
among text tokens in the documents. Under this setup, we then propose SPADE
(SPAtial DEpendency parser) that models highly complex spatial relationships
and an arbitrary number of information layers in the documents in an end-to-end
manner. We evaluate it on various kinds of documents such as receipts, name
cards, forms, and invoices, and show that it achieves a similar or better
performance compared to strong baselines including BERT-based IOB taggger.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Transformers. (arXiv:2103.01209v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01209">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the GANformer, a novel and efficient type of transformer, and
explore it for the task of visual generative modeling. The network employs a
bipartite structure that enables long-range interactions across the image,
while maintaining computation of linear efficiency, that can readily scale to
high-resolution synthesis. It iteratively propagates information from a set of
latent variables to the evolving visual features and vice versa, to support the
refinement of each in light of the other and encourage the emergence of
compositional representations of objects and scenes. In contrast to the classic
transformer architecture, it utilizes multiplicative integration that allows
flexible region-based modulation, and can thus be seen as a generalization of
the successful StyleGAN network. We demonstrate the model&#x27;s strength and
robustness through a careful evaluation over a range of datasets, from
simulated multi-object environments to rich real-world indoor and outdoor
scenes, showing it achieves state-of-the-art results in terms of image quality
and diversity, while enjoying fast learning and better data-efficiency. Further
qualitative and quantitative experiments offer us an insight into the model&#x27;s
inner workings, revealing improved interpretability and stronger
disentanglement, and illustrating the benefits and efficacy of our approach. An
implementation of the model is available at
https://github.com/dorarad/gansformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLINE: Contrastive Learning with Semantic Negative Examples for Natural Language Understanding. (arXiv:2107.00440v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Piji Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hai-Tao Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00440">
                                    <div class="article-summary-box-inner">
                                        <span>Despite pre-trained language models have proven useful for learning
high-quality semantic representations, these models are still vulnerable to
simple perturbations. Recent works aimed to improve the robustness of
pre-trained models mainly focus on adversarial training from perturbed examples
with similar semantics, neglecting the utilization of different or even
opposite semantics. Different from the image processing field, the text is
discrete and few word substitutions can cause significant semantic changes. To
study the impact of semantics caused by small perturbations, we conduct a
series of pilot experiments and surprisingly find that adversarial training is
useless or even harmful for the model to detect these semantic changes. To
address this problem, we propose Contrastive Learning with semantIc Negative
Examples (CLINE), which constructs semantic negative examples unsupervised to
improve the robustness under semantically adversarial attacking. By comparing
with similar and opposite semantic examples, the model can effectively perceive
the semantic changes caused by small perturbations. Empirical results show that
our approach yields substantial improvements on a range of sentiment analysis,
reasoning, and reading comprehension tasks. And CLINE also ensures the
compactness within the same semantics and separability across different
semantics in sentence-level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification of COVID-19 related Fake News via Neural Stacking. (arXiv:2101.03988v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1">Boshko Koloski</a>, <a href="http://arxiv.org/find/cs/1/au:+Perdih_T/0/1/0/all/0/1">Timen Stepi&#x161;nik Perdih</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1">Senja Pollak</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1">Bla&#x17e; &#x160;krlj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03988">
                                    <div class="article-summary-box-inner">
                                        <span>Identification of Fake News plays a prominent role in the ongoing pandemic,
impacting multiple aspects of day-to-day life. In this work we present a
solution to the shared task titled COVID19 Fake News Detection in English,
scoring the 50th place amongst 168 submissions. The solution was within 1.5% of
the best performing solution. The proposed solution employs a heterogeneous
representation ensemble, adapted for the classification task via an additional
neural classification head comprised of multiple hidden layers. The paper
consists of detailed ablation studies further displaying the proposed method&#x27;s
behavior and possible implications. The solution is freely available.
\url{https://gitlab.com/boshko.koloski/covid19-fake-news}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Zero-Shot Translation by Disentangling Positional Information. (arXiv:2012.15127v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Danni Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1">Jan Niehues</a>, <a href="http://arxiv.org/find/cs/1/au:+Cross_J/0/1/0/all/0/1">James Cross</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzman_F/0/1/0/all/0/1">Francisco Guzm&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xian Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15127">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual neural machine translation has shown the capability of directly
translating between language pairs unseen in training, i.e. zero-shot
translation. Despite being conceptually attractive, it often suffers from low
output quality. The difficulty of generalizing to new translation directions
suggests the model representations are highly specific to those language pairs
seen in training. We demonstrate that a main factor causing the
language-specific representations is the positional correspondence to input
tokens. We show that this can be easily alleviated by removing residual
connections in an encoder layer. With this modification, we gain up to 18.5
BLEU points on zero-shot translation while retaining quality on supervised
directions. The improvements are particularly prominent between related
languages, where our proposed model outperforms pivot-based translation.
Moreover, our approach allows easy integration of new languages, which
substantially expands translation coverage. By thorough inspections of the
hidden layer outputs, we show that our approach indeed leads to more
language-independent representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ESPnet-ST IWSLT 2021 Offline Speech Translation System. (arXiv:2107.00636v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Inaguma_H/0/1/0/all/0/1">Hirofumi Inaguma</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_B/0/1/0/all/0/1">Brian Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Dalmia_S/0/1/0/all/0/1">Siddharth Dalmia</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_P/0/1/0/all/0/1">Pengcheng Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_J/0/1/0/all/0/1">Jiatong Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Duh_K/0/1/0/all/0/1">Kevin Duh</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00636">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the ESPnet-ST group&#x27;s IWSLT 2021 submission in the
offline speech translation track. This year we made various efforts on training
data, architecture, and audio segmentation. On the data side, we investigated
sequence-level knowledge distillation (SeqKD) for end-to-end (E2E) speech
translation. Specifically, we used multi-referenced SeqKD from multiple
teachers trained on different amounts of bitext. On the architecture side, we
adopted the Conformer encoder and the Multi-Decoder architecture, which equips
dedicated decoders for speech recognition and translation tasks in a unified
encoder-decoder model and enables search in both source and target language
spaces during inference. We also significantly improved audio segmentation by
using the pyannote.audio toolkit and merging multiple short segments for long
context modeling. Experimental evaluations showed that each of them contributed
to large improvements in translation performance. Our best E2E system combined
all the above techniques with model ensembling and achieved 31.4 BLEU on the
2-ref of tst2021 and 21.2 BLEU and 19.3 BLEU on the two single references of
tst2021.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Learning-Based Approach for Improving Generalization Capability of Machine Reading Comprehension Systems. (arXiv:2107.00368v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baradaran_R/0/1/0/all/0/1">Razieh Baradaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirkhani_H/0/1/0/all/0/1">Hossein Amirkhani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00368">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Reading Comprehension (MRC) is an active field in natural language
processing with many successful developed models in recent years. Despite their
high in-distribution accuracy, these models suffer from two issues: high
training cost and low out-of-distribution accuracy. Even though some approaches
have been presented to tackle the generalization problem, they have high,
intolerable training costs. In this paper, we investigate the effect of
ensemble learning approach to improve generalization of MRC systems without
retraining a big model. After separately training the base models with
different structures on different datasets, they are ensembled using weighting
and stacking approaches in probabilistic and non-probabilistic settings. Three
configurations are investigated including heterogeneous, homogeneous, and
hybrid on eight datasets and six state-of-the-art models. We identify the
important factors in the effectiveness of ensemble methods. Also, we compare
the robustness of ensemble and fine-tuned models against data distribution
shifts. The experimental results show the effectiveness and robustness of the
ensemble approach in improving the out-of-distribution accuracy of MRC systems,
especially when the base models are similar in accuracies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GlyphCRM: Bidirectional Encoder Representation for Chinese Character with its Glyph. (arXiv:2107.00395v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Baotian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingcai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yang Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yuxin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lin Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00395">
                                    <div class="article-summary-box-inner">
                                        <span>Previous works indicate that the glyph of Chinese characters contains rich
semantic information and has the potential to enhance the representation of
Chinese characters. The typical method to utilize the glyph features is by
incorporating them into the character embedding space. Inspired by previous
methods, we innovatively propose a Chinese pre-trained representation model
named as GlyphCRM, which abandons the ID-based character embedding method yet
solely based on sequential character images. We render each character into a
binary grayscale image and design two-channel position feature maps for it.
Formally, we first design a two-layer residual convolutional neural network,
namely HanGlyph to generate the initial glyph representation of Chinese
characters, and subsequently adopt multiple bidirectional encoder Transformer
blocks as the superstructure to capture the context-sensitive information.
Meanwhile, we feed the glyph features extracted from each layer of the HanGlyph
module into the underlying Transformer blocks by skip-connection method to
fully exploit the glyph features of Chinese characters. As the HanGlyph module
can obtain a sufficient glyph representation of any Chinese character, the
long-standing out-of-vocabulary problem could be effectively solved. Extensive
experimental results indicate that GlyphCRM substantially outperforms the
previous BERT-based state-of-the-art model on 9 fine-tuning tasks, and it has
strong transferability and generalization on specialized fields and
low-resource tasks. We hope this work could spark further research beyond the
realms of well-established representation of Chinese texts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Target-side Inflection in Placeholder Translation. (arXiv:2107.00334v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ri_R/0/1/0/all/0/1">Ryokan Ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakazawa_T/0/1/0/all/0/1">Toshiaki Nakazawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1">Yoshimasa Tsuruoka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00334">
                                    <div class="article-summary-box-inner">
                                        <span>Placeholder translation systems enable the users to specify how a specific
phrase is translated in the output sentence. The system is trained to output
special placeholder tokens, and the user-specified term is injected into the
output through the context-free replacement of the placeholder token. However,
this approach could result in ungrammatical sentences because it is often the
case that the specified term needs to be inflected according to the context of
the output, which is unknown before the translation. To address this problem,
we propose a novel method of placeholder translation that can inflect specified
terms according to the grammatical construction of the output sentence. We
extend the sequence-to-sequence architecture with a character-level decoder
that takes the lemma of a user-specified term and the words generated from the
word-level decoder to output the correct inflected form of the lemma. We
evaluate our approach with a Japanese-to-English translation task in the
scientific writing domain, and show that our model can incorporate specified
terms in the correct form more successfully than other comparable models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiCite: Modeling realistic citations requires moving beyond the single-sentence single-label setting. (arXiv:2107.00414v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_B/0/1/0/all/0/1">Brandon Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhl_B/0/1/0/all/0/1">Bailey Kuhl</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_S/0/1/0/all/0/1">Sophie Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1">David Jurgens</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1">Arman Cohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1">Kyle Lo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00414">
                                    <div class="article-summary-box-inner">
                                        <span>Citation context analysis (CCA) is an important task in natural language
processing that studies how and why scholars discuss each others&#x27; work. Despite
being studied for decades, traditional frameworks for CCA have largely relied
on overly-simplistic assumptions of how authors cite, which ignore several
important phenomena. For instance, scholarly papers often contain rich
discussions of cited work that span multiple sentences and express multiple
intents concurrently. Yet, CCA is typically approached as a single-sentence,
single-label classification task, and thus existing datasets fail to capture
this interesting discourse. In our work, we address this research gap by
proposing a novel framework for CCA as a document-level context extraction and
labeling task. We release MultiCite, a new dataset of 12,653 citation contexts
from over 1,200 computational linguistics papers. Not only is it the largest
collection of expert-annotated citation contexts to-date, MultiCite contains
multi-sentence, multi-label citation contexts within full paper texts. Finally,
we demonstrate how our dataset, while still usable for training classic CCA
models, also supports the development of new types of models for CCA beyond
fixed-width text classification. We release our code and dataset at
https://github.com/allenai/multicite.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scientia Potentia Est -- On the Role of Knowledge in Computational Argumentation. (arXiv:2107.00281v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1">Anne Lauscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1">Henning Wachsmuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00281">
                                    <div class="article-summary-box-inner">
                                        <span>Despite extensive research in the past years, the computational modeling of
argumentation remains challenging. The primary reason lies in the inherent
complexity of the human processes behind, which commonly requires the
integration of extensive knowledge far beyond what is needed for many other
natural language understanding tasks. Existing work on the mining, assessment,
reasoning, and generation of arguments acknowledges this issue, calling for
more research on the integration of common sense and world knowledge into
computational models. However, a systematic effort to collect and organize the
types of knowledge needed is still missing, hindering targeted progress in the
field. In this opinionated survey paper, we address the issue by (1) proposing
a pyramid of types of knowledge required in computational argumentation, (2)
briefly discussing the state of the art on the role and integration of these
types in the field, and (3) outlining the main challenges for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Distillation for Quality Estimation. (arXiv:2107.00411v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gajbhiye_A/0/1/0/all/0/1">Amit Gajbhiye</a>, <a href="http://arxiv.org/find/cs/1/au:+Fomicheva_M/0/1/0/all/0/1">Marina Fomicheva</a>, <a href="http://arxiv.org/find/cs/1/au:+Alva_Manchego_F/0/1/0/all/0/1">Fernando Alva-Manchego</a>, <a href="http://arxiv.org/find/cs/1/au:+Blain_F/0/1/0/all/0/1">Fr&#xe9;d&#xe9;ric Blain</a>, <a href="http://arxiv.org/find/cs/1/au:+Obamuyide_A/0/1/0/all/0/1">Abiola Obamuyide</a>, <a href="http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1">Nikolaos Aletras</a>, <a href="http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1">Lucia Specia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00411">
                                    <div class="article-summary-box-inner">
                                        <span>Quality Estimation (QE) is the task of automatically predicting Machine
Translation quality in the absence of reference translations, making it
applicable in real-time settings, such as translating online social media
conversations. Recent success in QE stems from the use of multilingual
pre-trained representations, where very large models lead to impressive
results. However, the inference time, disk and memory requirements of such
models do not allow for wide usage in the real world. Models trained on
distilled pre-trained representations remain prohibitively large for many usage
scenarios. We instead propose to directly transfer knowledge from a strong QE
teacher model to a much smaller model with a different, shallower architecture.
We show that this approach, in combination with data augmentation, leads to
light-weight QE models that perform competitively with distilled pre-trained
representations with 8x fewer parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Central Repository: a Cross-lingual Framework for Developing Wordnets. (arXiv:2107.00333v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guinovart_X/0/1/0/all/0/1">Xavier G&#xf3;mez Guinovart</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Dios_I/0/1/0/all/0/1">Itziar Gonzalez-Dios</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliver_A/0/1/0/all/0/1">Antoni Oliver</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1">German Rigau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00333">
                                    <div class="article-summary-box-inner">
                                        <span>Language resources are necessary for language processing,but building them is
costly, involves many researches from different areas and needs constant
updating. In this paper, we describe the crosslingual framework used for
developing the Multilingual Central Repository (MCR), a multilingual knowledge
base that includes wordnets of Basque, Catalan, English, Galician, Portuguese,
Spanish and the following ontologies: Base Concepts, Top Ontology, WordNet
Domains and Suggested Upper Merged Ontology. We present the story of MCR, its
state in 2017 and the developed tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Objective Evaluation Framework for Pathological Speech Synthesis. (arXiv:2107.00308v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halpern_B/0/1/0/all/0/1">Bence Mark Halpern</a>, <a href="http://arxiv.org/find/cs/1/au:+Fritsch_J/0/1/0/all/0/1">Julian Fritsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermann_E/0/1/0/all/0/1">Enno Hermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_R/0/1/0/all/0/1">Rob van Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Scharenborg_O/0/1/0/all/0/1">Odette Scharenborg</a>, <a href="http://arxiv.org/find/cs/1/au:+_Doss_M/0/1/0/all/0/1">Mathew Magimai.-Doss</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00308">
                                    <div class="article-summary-box-inner">
                                        <span>The development of pathological speech systems is currently hindered by the
lack of a standardised objective evaluation framework. In this work, (1) we
utilise existing detection and analysis techniques to propose a general
framework for the consistent evaluation of synthetic pathological speech. This
framework evaluates the voice quality and the intelligibility aspects of speech
and is shown to be complementary using our experiments. (2) Using our proposed
evaluation framework, we develop and test a dysarthric voice conversion system
(VC) using CycleGAN-VC and a PSOLA-based speech rate modification technique. We
show that the developed system is able to synthesise dysarthric speech with
different levels of speech intelligibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Capturing Event Argument Interaction via A Bi-Directional Entity-Level Recurrent Decoder. (arXiv:2107.00189v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_X/0/1/0/all/0/1">Xiangyu Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1">Wei Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shikun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Quanxiu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Huixing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wei Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00189">
                                    <div class="article-summary-box-inner">
                                        <span>Capturing interactions among event arguments is an essential step towards
robust event argument extraction (EAE). However, existing efforts in this
direction suffer from two limitations: 1) The argument role type information of
contextual entities is mainly utilized as training signals, ignoring the
potential merits of directly adopting it as semantically rich input features;
2) The argument-level sequential semantics, which implies the overall
distribution pattern of argument roles over an event mention, is not well
characterized. To tackle the above two bottlenecks, we formalize EAE as a
Seq2Seq-like learning problem for the first time, where a sentence with a
specific event trigger is mapped to a sequence of event argument roles. A
neural architecture with a novel Bi-directional Entity-level Recurrent Decoder
(BERD) is proposed to generate argument roles by incorporating contextual
entities&#x27; argument role predictions, like a word-by-word text generation
process, thereby distinguishing implicit argument distribution patterns within
an event more accurately.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-pronoun Data Augmentation for Japanese-to-English Translation. (arXiv:2107.00318v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ri_R/0/1/0/all/0/1">Ryokan Ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakazawa_T/0/1/0/all/0/1">Toshiaki Nakazawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1">Yoshimasa Tsuruoka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00318">
                                    <div class="article-summary-box-inner">
                                        <span>For Japanese-to-English translation, zero pronouns in Japanese pose a
challenge, since the model needs to infer and produce the corresponding pronoun
in the target side of the English sentence. However, although fully resolving
zero pronouns often needs discourse context, in some cases, the local context
within a sentence gives clues to the inference of the zero pronoun. In this
study, we propose a data augmentation method that provides additional training
signals for the translation model to learn correlations between local context
and zero pronouns. We show that the proposed method significantly improves the
accuracy of zero pronoun translation with machine translation experiments in
the conversational domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word-Free Spoken Language Understanding for Mandarin-Chinese. (arXiv:2107.00186v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhiyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuexin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Akshat Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00186">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken dialogue systems such as Siri and Alexa provide great convenience to
people&#x27;s everyday life. However, current spoken language understanding (SLU)
pipelines largely depend on automatic speech recognition (ASR) modules, which
require a large amount of language-specific training data. In this paper, we
propose a Transformer-based SLU system that works directly on phones. This
acoustic-based SLU system consists of only two blocks and does not require the
presence of ASR module. The first block is a universal phone recognition
system, and the second block is a Transformer-based language model for phones.
We verify the effectiveness of the system on an intent classification dataset
in Mandarin Chinese.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021. (arXiv:2107.00279v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Mengge Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuchen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_L/0/1/0/all/0/1">Lirong Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00279">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes USTC-NELSLIP&#x27;s submissions to the IWSLT2021 Simultaneous
Speech Translation task. We proposed a novel simultaneous translation model,
Cross Attention Augmented Transducer (CAAT), which extends conventional RNN-T
to sequence-to-sequence tasks without monotonic constraints, e.g., simultaneous
translation. Experiments on speech-to-text (S2T) and text-to-text (T2T)
simultaneous translation tasks shows CAAT achieves better quality-latency
trade-offs compared to \textit{wait-k}, one of the previous state-of-the-art
approaches. Based on CAAT architecture and data augmentation, we build S2T and
T2T simultaneous translation systems in this evaluation campaign. Compared to
last year&#x27;s optimal systems, our S2T simultaneous translation system improves
by an average of 11.3 BLEU for all latency regimes, and our T2T simultaneous
translation system improves by an average of 4.6 BLEU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems. (arXiv:2107.00315v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1">Chitta Baral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00315">
                                    <div class="article-summary-box-inner">
                                        <span>Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">All That&#x27;s &#x27;Human&#x27; Is Not Gold: Evaluating Human Evaluation of Generated Text. (arXiv:2107.00061v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Clark_E/0/1/0/all/0/1">Elizabeth Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+August_T/0/1/0/all/0/1">Tal August</a>, <a href="http://arxiv.org/find/cs/1/au:+Serrano_S/0/1/0/all/0/1">Sofia Serrano</a>, <a href="http://arxiv.org/find/cs/1/au:+Haduong_N/0/1/0/all/0/1">Nikita Haduong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1">Suchin Gururangan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00061">
                                    <div class="article-summary-box-inner">
                                        <span>Human evaluations are typically considered the gold standard in natural
language generation, but as models&#x27; fluency improves, how well can evaluators
detect and judge machine-generated text? We run a study assessing non-experts&#x27;
ability to distinguish between human- and machine-authored text (GPT2 and GPT3)
in three domains (stories, news articles, and recipes). We find that, without
training, evaluators distinguished between GPT3- and human-authored text at
random chance level. We explore three approaches for quickly training
evaluators to better identify GPT3-authored text (detailed instructions,
annotated examples, and paired examples) and find that while evaluators&#x27;
accuracy improved up to 55%, it did not significantly improve across the three
domains. Given the inconsistent results across text domains and the often
contradictory reasons evaluators gave for their judgments, we examine the role
untrained human evaluations play in NLG evaluation and provide recommendations
to NLG researchers for improving human evaluations of text generated from
state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Abstractive Question Summarization with Question-aware Semantic Rewards. (arXiv:2107.00176v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yadav_S/0/1/0/all/0/1">Shweta Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1">Deepak Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Abacha_A/0/1/0/all/0/1">Asma Ben Abacha</a>, <a href="http://arxiv.org/find/cs/1/au:+Demner_Fushman_D/0/1/0/all/0/1">Dina Demner-Fushman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00176">
                                    <div class="article-summary-box-inner">
                                        <span>The growth of online consumer health questions has led to the necessity for
reliable and accurate question answering systems. A recent study showed that
manual summarization of consumer health questions brings significant
improvement in retrieving relevant answers. However, the automatic
summarization of long questions is a challenging task due to the lack of
training data and the complexity of the related subtasks, such as the question
focus and type recognition. In this paper, we introduce a reinforcement
learning-based framework for abstractive question summarization. We propose two
novel rewards obtained from the downstream tasks of (i) question-type
identification and (ii) question-focus recognition to regularize the question
generation model. These rewards ensure the generation of semantically valid
questions and encourage the inclusion of key medical entities/foci in the
question summary. We evaluated our proposed method on two benchmark datasets
and achieved higher performance over state-of-the-art models. The manual
evaluation of the summaries reveals that the generated questions are more
diverse and have fewer factual inconsistencies than the baseline summaries</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regressing Location on Text for Probabilistic Geocoding. (arXiv:2107.00080v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Radford_B/0/1/0/all/0/1">Benjamin J. Radford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00080">
                                    <div class="article-summary-box-inner">
                                        <span>Text data are an important source of detailed information about social and
political events. Automated systems parse large volumes of text data to infer
or extract structured information that describes actors, actions, dates, times,
and locations. One of these sub-tasks is geocoding: predicting the geographic
coordinates associated with events or locations described by a given text. We
present an end-to-end probabilistic model for geocoding text data.
Additionally, we collect a novel data set for evaluating the performance of
geocoding systems. We compare the model-based solution, called ELECTRo-map, to
the current state-of-the-art open source system for geocoding texts for event
data. Finally, we discuss the benefits of end-to-end model-based geocoding,
including principled uncertainty estimation and the ability of these models to
leverage contextual information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to communicate about shared procedural abstractions. (arXiv:2107.00077v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McCarthy_W/0/1/0/all/0/1">William P. McCarthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hawkins_R/0/1/0/all/0/1">Robert D. Hawkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Holdaway_C/0/1/0/all/0/1">Cameron Holdaway</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Judith E. Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00077">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world tasks require agents to coordinate their behavior to achieve
shared goals. Successful collaboration requires not only adopting the same
communicative conventions, but also grounding these conventions in the same
task-appropriate conceptual abstractions. We investigate how humans use natural
language to collaboratively solve physical assembly problems more effectively
over time. Human participants were paired up in an online environment to
reconstruct scenes containing two block towers. One participant could see the
target towers, and sent assembly instructions for the other participant to
reconstruct. Participants provided increasingly concise instructions across
repeated attempts on each pair of towers, using higher-level referring
expressions that captured each scene&#x27;s hierarchical structure. To explain these
findings, we extend recent probabilistic models of ad-hoc convention formation
with an explicit perceptual learning mechanism. These results shed light on the
inductive biases that enable intelligent agents to coordinate upon shared
procedural abstractions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zipf&#x27;s laws of meaning in Catalan. (arXiv:2107.00042v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Catala_N/0/1/0/all/0/1">Neus Catal&#xe0;</a>, <a href="http://arxiv.org/find/cs/1/au:+Baixeries_J/0/1/0/all/0/1">Jaume Baixeries</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_Cancho_R/0/1/0/all/0/1">Ramon Ferrer-Cancho</a>, <a href="http://arxiv.org/find/cs/1/au:+Padro_L/0/1/0/all/0/1">Llu&#xed;s Padr&#xf3;</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_Fernandez_A/0/1/0/all/0/1">Antoni Hern&#xe1;ndez-Fern&#xe1;ndez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00042">
                                    <div class="article-summary-box-inner">
                                        <span>In his pioneering research, G. K. Zipf formulated a couple of statistical
laws on the relationship between the frequency of a word with its number of
meanings: the law of meaning distribution, relating the frequency of a word and
its frequency rank, and the meaning-frequency law, relating the frequency of a
word with its number of meanings. Although these laws were formulated more than
half a century ago, they have been only investigated in a few languages. Here
we present the first study of these laws in Catalan.

We verify these laws in Catalan via the relationship among their exponents
and that of the rank-frequency law. We present a new protocol for the analysis
of these Zipfian laws that can be extended to other languages. We report the
first evidence of two marked regimes for these laws in written language and
speech, paralleling the two regimes in Zipf&#x27;s rank-frequency law in large
multi-author corpora discovered in early 2000s. Finally, the implications of
these two regimes will be discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Reversible Embedding Mapping using Bi-Directional Manifold Alignment. (arXiv:2107.00124v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesan_A/0/1/0/all/0/1">Ashwinkumar Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraro_F/0/1/0/all/0/1">Francis Ferraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oates_T/0/1/0/all/0/1">Tim Oates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00124">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a Bi-Directional Manifold Alignment (BDMA) that learns a
non-linear mapping between two manifolds by explicitly training it to be
bijective. We demonstrate BDMA by training a model for a pair of languages
rather than individual, directed source and target combinations, reducing the
number of models by 50%. We show that models trained with BDMA in the &quot;forward&quot;
(source to target) direction can successfully map words in the &quot;reverse&quot;
(target to source) direction, yielding equivalent (or better) performance to
standard unidirectional translation models where the source and target language
is flipped. We also show how BDMA reduces the overall size of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable Open-ended Question Generation with A New Question Type Ontology. (arXiv:2107.00152v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Shuyang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00152">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the less-explored task of generating open-ended questions that
are typically answered by multiple sentences. We first define a new question
type ontology which differentiates the nuanced nature of questions better than
widely used question words. A new dataset with 4,959 questions is labeled based
on the new ontology. We then propose a novel question type-aware question
generation framework, augmented by a semantic graph representation, to jointly
predict question focuses and produce the question. Based on this framework, we
further use both exemplars and automatically generated templates to improve
controllability and diversity. Experiments on two newly collected large-scale
datasets show that our model improves question quality over competitive
comparisons based on automatic metrics. Human judges also rate our model
outputs highly in answerability, coverage of scope, and overall quality.
Finally, our model variants with templates can produce questions with enhanced
controllability and diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elbert: Fast Albert with Confidence-Window Based Early Exit. (arXiv:2107.00175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1">Keli Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Siyuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00175">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great success in Natural Language Processing (NLP) area, large
pre-trained language models like BERT are not well-suited for
resource-constrained or real-time applications owing to the large number of
parameters and slow inference speed. Recently, compressing and accelerating
BERT have become important topics. By incorporating a parameter-sharing
strategy, ALBERT greatly reduces the number of parameters while achieving
competitive performance. Nevertheless, ALBERT still suffers from a long
inference time. In this work, we propose the ELBERT, which significantly
improves the average inference speed compared to ALBERT due to the proposed
confidence-window based early exit mechanism, without introducing additional
parameters or extra training overhead. Experimental results show that ELBERT
achieves an adaptive inference speedup varying from 2$\times$ to 10$\times$
with negligible accuracy degradation compared to ALBERT on various datasets.
Besides, ELBERT achieves higher accuracy than existing early exit methods used
for accelerating BERT under the same computation cost. Furthermore, to
understand the principle of the early exit mechanism, we also visualize the
decision-making process of it in ELBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Feature Space: A Geometrical Perspective. (arXiv:2007.00062v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kansizoglou_I/0/1/0/all/0/1">Ioannis Kansizoglou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bampis_L/0/1/0/all/0/1">Loukas Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasteratos_A/0/1/0/all/0/1">Antonios Gasteratos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00062">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most prominent attributes of Neural Networks (NNs) constitutes
their capability of learning to extract robust and descriptive features from
high dimensional data, like images. Hence, such an ability renders their
exploitation as feature extractors particularly frequent in an abundant of
modern reasoning systems. Their application scope mainly includes complex
cascade tasks, like multi-modal recognition and deep Reinforcement Learning
(RL). However, NNs induce implicit biases that are difficult to avoid or to
deal with and are not met in traditional image descriptors. Moreover, the lack
of knowledge for describing the intra-layer properties -- and thus their
general behavior -- restricts the further applicability of the extracted
features. With the paper at hand, a novel way of visualizing and understanding
the vector space before the NNs&#x27; output layer is presented, aiming to enlighten
the deep feature vectors&#x27; properties under classification tasks. Main attention
is paid to the nature of overfitting in the feature space and its adverse
effect on further exploitation. We present the findings that can be derived
from our model&#x27;s formulation, and we evaluate them on realistic recognition
scenarios, proving its prominence by improving the obtained results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Transformers. (arXiv:2103.01209v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01209">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the GANformer, a novel and efficient type of transformer, and
explore it for the task of visual generative modeling. The network employs a
bipartite structure that enables long-range interactions across the image,
while maintaining computation of linear efficiency, that can readily scale to
high-resolution synthesis. It iteratively propagates information from a set of
latent variables to the evolving visual features and vice versa, to support the
refinement of each in light of the other and encourage the emergence of
compositional representations of objects and scenes. In contrast to the classic
transformer architecture, it utilizes multiplicative integration that allows
flexible region-based modulation, and can thus be seen as a generalization of
the successful StyleGAN network. We demonstrate the model&#x27;s strength and
robustness through a careful evaluation over a range of datasets, from
simulated multi-object environments to rich real-world indoor and outdoor
scenes, showing it achieves state-of-the-art results in terms of image quality
and diversity, while enjoying fast learning and better data-efficiency. Further
qualitative and quantitative experiments offer us an insight into the model&#x27;s
inner workings, revealing improved interpretability and stronger
disentanglement, and illustrating the benefits and efficacy of our approach. An
implementation of the model is available at
https://github.com/dorarad/gansformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-term Cross Adversarial Training: A Robust Meta-learning Method for Few-shot Classification Tasks. (arXiv:2106.12900v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xuelong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12900">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning model can quickly adapt to new tasks using few-shot labeled
data. However, despite achieving good generalization on few-shot classification
tasks, it is still challenging to improve the adversarial robustness of the
meta-learning model in few-shot learning. Although adversarial training (AT)
methods such as Adversarial Query (AQ) can improve the adversarially robust
performance of meta-learning models, AT is still computationally expensive
training. On the other hand, meta-learning models trained with AT will drop
significant accuracy on the original clean images. This paper proposed a
meta-learning method on the adversarially robust neural network called
Long-term Cross Adversarial Training (LCAT). LCAT will update meta-learning
model parameters cross along the natural and adversarial sample distribution
direction with long-term to improve both adversarial and clean few-shot
classification accuracy. Due to cross-adversarial training, LCAT only needs
half of the adversarial training epoch than AQ, resulting in a low adversarial
training computation. Experiment results show that LCAT achieves superior
performance both on the clean and adversarial few-shot classification accuracy
than SOTA adversarial training methods for meta-learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmenting two-dimensional structures with strided tensor networks. (arXiv:2102.06900v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Selvan_R/0/1/0/all/0/1">Raghavendra Selvan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dam_E/0/1/0/all/0/1">Erik B Dam</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_J/0/1/0/all/0/1">Jens Petersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06900">
                                    <div class="article-summary-box-inner">
                                        <span>Tensor networks provide an efficient approximation of operations involving
high dimensional tensors and have been extensively used in modelling quantum
many-body systems. More recently, supervised learning has been attempted with
tensor networks, primarily focused on tasks such as image classification. In
this work, we propose a novel formulation of tensor networks for supervised
image segmentation which allows them to operate on high resolution medical
images. We use the matrix product state (MPS) tensor network on non-overlapping
patches of a given input image to predict the segmentation mask by learning a
pixel-wise linear classification rule in a high dimensional space. The proposed
model is end-to-end trainable using backpropagation. It is implemented as a
Strided Tensor Network to reduce the parameter complexity. The performance of
the proposed method is evaluated on two public medical imaging datasets and
compared to relevant baselines. The evaluation shows that the strided tensor
network yields competitive performance compared to CNN-based models while using
fewer resources. Additionally, based on the experiments we discuss the
feasibility of using fully linear models for segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lattice Fusion Networks for Image Denoising. (arXiv:2011.14196v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hosseini_S/0/1/0/all/0/1">Seyed Mohsen Hosseini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14196">
                                    <div class="article-summary-box-inner">
                                        <span>A novel method for feature fusion in convolutional neural networks is
proposed in this paper. Different feature fusion techniques are suggested to
facilitate the flow of information and improve the training of deep neural
networks. Some of these techniques as well as the proposed network can be
considered a type of Directed Acyclic Graph (DAG) Network, where a layer can
receive inputs from other layers and have outputs to other layers. In the
proposed general framework of Lattice Fusion Network (LFNet), feature maps of
each convolutional layer are passed to other layers based on a lattice graph
structure, where nodes are convolutional layers. To evaluate the performance of
the proposed architecture, different designs based on the general framework of
LFNet are implemented for the task of image denoising. This task is used as an
example where training deep convolutional networks is needed. Results are
compared with state of the art methods. The proposed network is able to achieve
better results with far fewer learnable parameters, which shows the
effectiveness of LFNets for training of deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data. (arXiv:2107.00648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braman_N/0/1/0/all/0/1">Nathaniel Braman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_J/0/1/0/all/0/1">Jacob W. H. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Goossens_E/0/1/0/all/0/1">Emery T. Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1">Caleb Willis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpe_M/0/1/0/all/0/1">Martin C. Stumpe</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_J/0/1/0/all/0/1">Jagadish Venkataraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00648">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical decision-making in oncology involves multimodal data such as
radiology scans, molecular profiling, histopathology slides, and clinical
factors. Despite the importance of these modalities individually, no deep
learning framework to date has combined them all to predict patient prognosis.
Here, we predict the overall survival (OS) of glioma patients from diverse
multimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to
combine information from multiparametric MRI exams, biopsy-based modalities
(such as H&amp;E slide images and/or DNA sequencing), and clinical variables into a
comprehensive multimodal risk score. Prognostic embeddings from each modality
are learned and combined via attention-gated tensor fusion. To maximize the
information gleaned from each modality, we introduce a multimodal
orthogonalization (MMO) loss term that increases model performance by
incentivizing constituent embeddings to be more complementary. DOF predicts OS
in glioma patients with a median C-index of 0.788 +/- 0.067, significantly
outperforming (p&#x3D;0.023) the best performing unimodal model with a median
C-index of 0.718 +/- 0.064. The prognostic model significantly stratifies
glioma patients by OS within clinical subsets, adding further granularity to
prognostic clinical grading and molecular subtyping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interval-valued aggregation functions based on moderate deviations applied to Motor-Imagery-Based Brain Computer Interface. (arXiv:2011.09831v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fumanal_Idocin_J/0/1/0/all/0/1">Javier Fumanal-Idocin</a>, <a href="http://arxiv.org/find/cs/1/au:+Takac_Z/0/1/0/all/0/1">Zdenko Tak&#xe1;&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanz_J/0/1/0/all/0/1">Javier Fern&#xe1;ndez Jose Antonio Sanz</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyena_H/0/1/0/all/0/1">Harkaitz Goyena</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Ching-Teng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1">Humberto Bustince</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09831">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we study the use of moderate deviation functions to measure
similarity and dissimilarity among a set of given interval-valued data. To do
so, we introduce the notion of interval-valued moderate deviation function and
we study in particular those interval-valued moderate deviation functions which
preserve the width of the input intervals. Then, we study how to apply these
functions to construct interval-valued aggregation functions. We have applied
them in the decision making phase of two Motor-Imagery Brain Computer Interface
frameworks, obtaining better results than those obtained using other numerical
and intervalar aggregations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Human Action Recognition. (arXiv:2107.00606v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1">Simone Angarano</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1">Francesco Salvetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelini_F/0/1/0/all/0/1">Federico Angelini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent, and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time
short-time human action recognition. Extensive experimentation on MPOSE2021
with our proposed methodology and several previous architectural solutions
proves the effectiveness of the AcT model and poses the base for future work on
HAR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Color Variants Identification in Fashion e-commerce via Contrastive Self-Supervised Representation Learning. (arXiv:2104.08581v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_U/0/1/0/all/0/1">Ujjal Kr Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Repakula_S/0/1/0/all/0/1">Sandeep Repakula</a>, <a href="http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1">Maulik Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_A/0/1/0/all/0/1">Abhinav Ravi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08581">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we utilize deep visual Representation Learning to address an
important problem in fashion e-commerce: color variants identification, i.e.,
identifying fashion products that match exactly in their design (or style), but
only to differ in their color. At first we attempt to tackle the problem by
obtaining manual annotations (depicting whether two products are color
variants), and train a supervised triplet loss based neural network model to
learn representations of fashion products. However, for large scale real-world
industrial datasets such as addressed in our paper, it is infeasible to obtain
annotations for the entire dataset, while capturing all the difficult corner
cases. Interestingly, we observed that color variants are essentially
manifestations of color jitter based augmentations. Thus, we instead explore
Self-Supervised Learning (SSL) to solve this problem. We observed that existing
state-of-the-art SSL methods perform poor, for our problem. To address this, we
propose a novel SSL based color variants model that simultaneously focuses on
different parts of an apparel. Quantitative and qualitative evaluation shows
that our method outperforms existing SSL methods, and at times, the supervised
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High Resolution Face Editing with Masked GAN Latent Code Optimization. (arXiv:2103.11135v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pernus_M/0/1/0/all/0/1">Martin Pernu&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Struc_V/0/1/0/all/0/1">Vitomir &#x160;truc</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobrisek_S/0/1/0/all/0/1">Simon Dobri&#x161;ek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11135">
                                    <div class="article-summary-box-inner">
                                        <span>Face editing represents a popular research topic within the computer vision
and image processing communities. While significant progress has been made
recently in this area, existing solutions: (i) are still largely focused on
low-resolution images, (ii) often generate editing results with visual
artefacts, or (iii) lack fine-grained control and alter multiple (entangled)
attributes at once, when trying to generate the desired facial semantics. In
this paper, we aim to address these issues though a novel attribute editing
approach called MaskFaceGAN. The proposed approach is based on an optimization
procedure that directly optimizes the latent code of a pre-trained
(state-of-the-art) Generative Adversarial Network (i.e., StyleGAN2) with
respect to several constraints that ensure: (i) preservation of relevant image
content, (ii) generation of the targeted facial attributes, and (iii)
spatially--selective treatment of local image areas. The constraints are
enforced with the help of an (differentiable) attribute classifier and face
parser that provide the necessary reference information for the optimization
procedure. MaskFaceGAN is evaluated in extensive experiments on the CelebA-HQ,
Helen and SiblingsDB-HQf datasets and in comparison with several
state-of-the-art techniques from the literature, i.e., StarGAN, AttGAN, STGAN,
and two versions of InterFaceGAN. Our experimental results show that the
proposed approach is able to edit face images with respect to several facial
attributes with unprecedented image quality and at high-resolutions
(1024x1024), while exhibiting considerably less problems with attribute
entanglement than competing solutions. The source code is made freely available
from: https://github.com/MartinPernus/MaskFaceGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Knowledge Distillation with A Single Stream Structure for RGB-D Salient Object Detection. (arXiv:2106.09517v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1">Guangyu Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1">Tania Stathaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09517">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-D salient object detection(SOD) demonstrates its superiority on detecting
in complex environments due to the additional depth information introduced in
the data. Inevitably, an independent stream is introduced to extract features
from depth images, leading to extra computation and parameters. This
methodology which sacrifices the model size to improve the detection accuracy
may impede the practical application of SOD problems. To tackle this dilemma,
we propose a dynamic distillation method along with a lightweight framework,
which significantly reduces the parameters. This method considers the factors
of both teacher and student performance within the training stage and
dynamically assigns the distillation weight instead of applying a fixed weight
on the student model. Extensive experiments are conducted on five public
datasets to demonstrate that our method can achieve competitive performance
compared to 10 prior methods through a 78.2MB lightweight structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Recognition to Prediction: Analysis of Human Action and Trajectory Prediction in Video. (arXiv:2011.10670v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Junwei Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10670">
                                    <div class="article-summary-box-inner">
                                        <span>With the advancement in computer vision deep learning, systems now are able
to analyze an unprecedented amount of rich visual information from videos to
enable applications such as autonomous driving, socially-aware robot assistant
and public safety monitoring. Deciphering human behaviors to predict their
future paths/trajectories and what they would do from videos is important in
these applications. However, human trajectory prediction still remains a
challenging task, as scene semantics and human intent are difficult to model.
Many systems do not provide high-level semantic attributes to reason about
pedestrian future. This design hinders prediction performance in video data
from diverse domains and unseen scenarios. To enable optimal future human
behavioral forecasting, it is crucial for the system to be able to detect and
analyze human activities as well as scene semantics, passing informative
features to the subsequent prediction module for context understanding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effects of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction. (arXiv:2101.03244v10 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Saha_A/0/1/0/all/0/1">Anindo Saha</a>, <a href="http://arxiv.org/find/eess/1/au:+Hosseinzadeh_M/0/1/0/all/0/1">Matin Hosseinzadeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03244">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multi-stage 3D computer-aided detection and diagnosis (CAD)
model for automated localization of clinically significant prostate cancer
(csPCa) in bi-parametric MR imaging (bpMRI). Deep attention mechanisms drive
its detection network, targeting salient structures and highly discriminative
feature dimensions across multiple resolutions. Its goal is to accurately
identify csPCa lesions from indolent cancer and the wide range of benign
pathology that can afflict the prostate gland. Simultaneously, a decoupled
residual classifier is used to achieve consistent false positive reduction,
without sacrificing high sensitivity or computational efficiency. In order to
guide model generalization with domain-specific clinical knowledge, a
probabilistic anatomical prior is used to encode the spatial prevalence and
zonal distinction of csPCa. Using a large dataset of 1950 prostate bpMRI paired
with radiologically-estimated annotations, we hypothesize that such CNN-based
models can be trained to detect biopsy-confirmed malignancies in an independent
cohort.

For 486 institutional testing scans, the 3D CAD system achieves
83.69$\pm$5.22% and 93.19$\pm$2.96% detection sensitivity at 0.50 and 1.46
false positive(s) per patient, respectively, with 0.882$\pm$0.030 AUROC in
patient-based diagnosis $-$significantly outperforming four state-of-the-art
baseline architectures (U-SEResNet, UNet++, nnU-Net, Attention U-Net) from
recent literature. For 296 external biopsy-confirmed testing scans, the
ensembled CAD system shares moderate agreement with a consensus of expert
radiologists (76.69%; $kappa$ $&#x3D;$ 0.51$\pm$0.04) and independent pathologists
(81.08%; $kappa$ $&#x3D;$ 0.56$\pm$0.06); demonstrating strong generalization to
histologically-confirmed csPCa diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Self Supervised Learning: the BT, the HSIC, and the VICReg. (arXiv:2105.12247v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sayan Nag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12247">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning and pre-training strategies have developed over the
last few years especially for Convolutional Neural Networks (CNNs). Recently
application of such methods can also be noticed for Graph Neural Networks
(GNNs) . In this paper, we have used a graph based self-supervised learning
strategy with different loss functions (Barlow Twins[Zbontar et al., 2021],
HSIC[Tsai et al., 2021], VICReg[Bardes et al., 2021]) which have shown
promising results when applied with CNNs previously. We have also proposed a
hybrid loss function combining the advantages of VICReg and HSIC and called it
as VICRegHSIC. The performance of these aforementioned methods have been
compared when applied to different datasets such as MUTAG, PROTEINS and
IMDB-Binary. Moreover, the impact of different batch sizes, projector
dimensions and data augmentation strategies have also been explored</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1">Ivan Evtimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1">Ian Covert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1">Tadayoshi Kohno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06654">
                                    <div class="article-summary-box-inner">
                                        <span>When data is publicly released for human consumption, it is unclear how to
prevent its unauthorized usage for machine learning purposes. Successful model
training may be preventable with carefully designed dataset modifications, and
we present a proof-of-concept approach for the image classification setting. We
propose methods based on the notion of adversarial shortcuts, which encourage
models to rely on non-robust signals rather than semantic features, and our
experiments demonstrate that these measures successfully prevent deep learning
models from achieving high accuracy on real, unmodified data examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to See before Learning to Act: Visual Pre-training for Manipulation. (arXiv:2107.00646v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yen_Chen_L/0/1/0/all/0/1">Lin Yen-Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Andy Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shuran Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsung-Yi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00646">
                                    <div class="article-summary-box-inner">
                                        <span>Does having visual priors (e.g. the ability to detect objects) facilitate
learning to perform vision-based manipulation (e.g. picking up objects)? We
study this problem under the framework of transfer learning, where the model is
first trained on a passive vision task, and adapted to perform an active
manipulation task. We find that pre-training on vision tasks significantly
improves generalization and sample efficiency for learning to manipulate
objects. However, realizing these gains requires careful selection of which
parts of the model to transfer. Our key insight is that outputs of standard
vision models highly correlate with affordance maps commonly used in
manipulation. Therefore, we explore directly transferring model parameters from
vision networks to affordance prediction networks, and show that this can
result in successful zero-shot adaptation, where a robot can pick up certain
objects with zero robotic experience. With just a small amount of robotic
experience, we can further fine-tune the affordance model to achieve better
results. With just 10 minutes of suction experience or 1 hour of grasping
experience, our method achieves ~80% success rate at picking up novel objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows. (arXiv:2107.00652v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Baining Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00652">
                                    <div class="article-summary-box-inner">
                                        <span>We present CSWin Transformer, an efficient and effective Transformer-based
backbone for general-purpose vision tasks. A challenging issue in Transformer
design is that global self-attention is very expensive to compute whereas local
self-attention often limits the field of interactions of each token. To address
this issue, we develop the Cross-Shaped Window self-attention mechanism for
computing self-attention in the horizontal and vertical stripes in parallel
that form a cross-shaped window, with each stripe obtained by splitting the
input feature into stripes of equal width. We provide a detailed mathematical
analysis of the effect of the stripe width and vary the stripe width for
different layers of the Transformer network which achieves strong modeling
capability while limiting the computation cost. We also introduce
Locally-enhanced Positional Encoding (LePE), which handles the local positional
information better than existing encoding schemes. LePE naturally supports
arbitrary input resolutions, and is thus especially effective and friendly for
downstream tasks. Incorporated with these designs and a hierarchical structure,
CSWin Transformer demonstrates competitive performance on common vision tasks.
Specifically, it achieves 85.4% Top-1 accuracy on ImageNet-1K without any extra
training data or label, 53.9 box AP and 46.4 mask AP on the COCO detection
task, and 51.7 mIOU on the ADE20K semantic segmentation task, surpassing
previous state-of-the-art Swin Transformer backbone by +1.2, +2.0, +1.4, and
+2.0 respectively under the similar FLOPs setting. By further pretraining on
the larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy on ImageNet-1K
and state-of-the-art segmentation performance on ADE20K with 55.2 mIoU. The
code and models will be available at
https://github.com/microsoft/CSWin-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Auxiliary Actor-Critic for 6D Robotic Grasping with Point Clouds. (arXiv:2010.00824v4 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lirui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yu Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1">Arsalan Mousavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00824">
                                    <div class="article-summary-box-inner">
                                        <span>6D robotic grasping beyond top-down bin-picking scenarios is a challenging
task. Previous solutions based on 6D grasp synthesis with robot motion planning
usually operate in an open-loop setting, which are sensitive to grasp synthesis
errors. In this work, we propose a new method for learning closed-loop control
policies for 6D grasping. Our policy takes a segmented point cloud of an object
from an egocentric camera as input, and outputs continuous 6D control actions
of the robot gripper for grasping the object. We combine imitation learning and
reinforcement learning and introduce a goal-auxiliary actor-critic algorithm
for policy learning. We demonstrate that our learned policy can be integrated
into a tabletop 6D grasping system and a human-robot handover system to improve
the grasping performance of unseen objects. Our videos and code can be found at
https://sites.google.com/view/gaddpg .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Individual Tree Detection and Crown Delineation with 3D Information from Multi-view Satellite Images. (arXiv:2107.00592v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Changlin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00592">
                                    <div class="article-summary-box-inner">
                                        <span>Individual tree detection and crown delineation (ITDD) are critical in forest
inventory management and remote sensing based forest surveys are largely
carried out through satellite images. However, most of these surveys only use
2D spectral information which normally has not enough clues for ITDD. To fully
explore the satellite images, we propose a ITDD method using the orthophoto and
digital surface model (DSM) derived from the multi-view satellite data. Our
algorithm utilizes the top-hat morphological operation to efficiently extract
the local maxima from DSM as treetops, and then feed them to a modi-fied
superpixel segmentation that combines both 2D and 3D information for tree crown
delineation. In subsequent steps, our method incorporates the biological
characteristics of the crowns through plant allometric equation to falsify
potential outliers. Experiments against manually marked tree plots on three
representative regions have demonstrated promising results - the best overall
detection accuracy can be 89%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointINS: Point-based Instance Segmentation. (arXiv:2003.06148v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yukang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingcong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06148">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the mask representation in instance segmentation
with Point-of-Interest (PoI) features. Differentiating multiple potential
instances within a single PoI feature is challenging because learning a
high-dimensional mask feature for each instance using vanilla convolution
demands a heavy computing burden. To address this challenge, we propose an
instance-aware convolution. It decomposes this mask representation learning
task into two tractable modules as instance-aware weights and instance-agnostic
features. The former is to parametrize convolution for producing mask features
corresponding to different instances, improving mask learning efficiency by
avoiding employing several independent convolutions. Meanwhile, the latter
serves as mask templates in a single point. Together, instance-aware mask
features are computed by convolving the template with dynamic weights, used for
the mask prediction. Along with instance-aware convolution, we propose
PointINS, a simple and practical instance segmentation approach, building upon
dense one-stage detectors. Through extensive experiments, we evaluated the
effectiveness of our framework built upon RetinaNet and FCOS. PointINS in
ResNet101 backbone achieves a 38.3 mask mean average precision (mAP) on COCO
dataset, outperforming existing point-based methods by a large margin. It gives
a comparable performance to the region-based Mask R-CNN with faster inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1">Andrea Dittadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papa_S/0/1/0/all/0/1">Samuele Papa</a>, <a href="http://arxiv.org/find/cs/1/au:+Vita_M/0/1/0/all/0/1">Michele De Vita</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1">Ole Winther</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00637">
                                    <div class="article-summary-box-inner">
                                        <span>The idea behind object-centric representation learning is that natural scenes
can better be modeled as compositions of objects and their relations as opposed
to distributed representations. This inductive bias can be injected into neural
networks to potentially improve systematic generalization and learning
efficiency of downstream tasks in scenes with multiple objects. In this paper,
we train state-of-the-art unsupervised models on five common multi-object
datasets and evaluate segmentation accuracy and downstream object property
prediction. In addition, we study systematic generalization and robustness by
investigating the settings where either single objects are out-of-distribution
-- e.g., having unseen colors, textures, and shapes -- or global properties of
the scene are altered -- e.g., by occlusions, cropping, or increasing the
number of objects. From our experimental study, we find object-centric
representations to be generally useful for downstream tasks and robust to
shifts in the data distribution, especially if shifts affect single objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Interpretable Convolutional Neural Networks by Differentiating Class-specific Filters. (arXiv:2007.08194v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Haoyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_Z/0/1/0/all/0/1">Zhihao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yuyuan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zihao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08194">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been successfully used in a range
of tasks. However, CNNs are often viewed as &quot;black-box&quot; and lack of
interpretability. One main reason is due to the filter-class entanglement -- an
intricate many-to-many correspondence between filters and classes. Most
existing works attempt post-hoc interpretation on a pre-trained model, while
neglecting to reduce the entanglement underlying the model. In contrast, we
focus on alleviating filter-class entanglement during training. Inspired by
cellular differentiation, we propose a novel strategy to train interpretable
CNNs by encouraging class-specific filters, among which each filter responds to
only one (or few) class. Concretely, we design a learnable sparse
Class-Specific Gate (CSG) structure to assign each filter with one (or few)
class in a flexible way. The gate allows a filter&#x27;s activation to pass only
when the input samples come from the specific class. Extensive experiments
demonstrate the fabulous performance of our method in generating a sparse and
highly class-related representation of the input, which leads to stronger
interpretability. Moreover, comparing with the standard training strategy, our
model displays benefits in applications like object localization and
adversarial sample detection. Code link: https://github.com/hyliang96/CSGCNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Gravitational Approach for Rigid Point Set Registration with Ordinary Differential Equations. (arXiv:2009.14005v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Sk Aziz Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Kahraman_K/0/1/0/all/0/1">Kerem Kahraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14005">
                                    <div class="article-summary-box-inner">
                                        <span>This article introduces a new physics-based method for rigid point set
alignment called Fast Gravitational Approach (FGA). In FGA, the source and
target point sets are interpreted as rigid particle swarms with masses
interacting in a globally multiply-linked manner while moving in a simulated
gravitational force field. The optimal alignment is obtained by explicit
modeling of forces acting on the particles as well as their velocities and
displacements with second-order ordinary differential equations of motion.
Additional alignment cues (point-based or geometric features, and other
boundary conditions) can be integrated into FGA through particle masses. We
propose a smooth-particle mass function for point mass initialization, which
improves robustness to noise and structural discontinuities. To avoid
prohibitive quadratic complexity of all-to-all point interactions, we adapt a
Barnes-Hut tree for accelerated force computation and achieve quasilinear
computational complexity. We show that the new method class has characteristics
not found in previous alignment methods such as efficient handling of partial
overlaps, inhomogeneous point sampling densities, and coping with large point
clouds with reduced runtime compared to the state of the art. Experiments show
that our method performs on par with or outperforms all compared competing
non-deep-learning-based and general-purpose techniques (which do not assume the
availability of training data and a scene prior) in resolving transformations
for LiDAR data and gains state-of-the-art accuracy and speed when coping with
different types of data disturbances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-task Two-stream Spatiotemporal Convolutional Neural Network for Convective Storm Nowcasting. (arXiv:2010.14100v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">W. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">H. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">P. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">L. Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14100">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of convective storm nowcasting is local prediction of severe and
imminent convective storms. Here, we consider the convective storm nowcasting
problem from the perspective of machine learning. First, we use a pixel-wise
sampling method to construct spatiotemporal features for nowcasting, and
flexibly adjust the proportions of positive and negative samples in the
training set to mitigate class-imbalance issues. Second, we employ a concise
two-stream convolutional neural network to extract spatial and temporal cues
for nowcasting. This simplifies the network structure, reduces the training
time requirement, and improves classification accuracy. The two-stream network
used both radar and satellite data. In the resulting two-stream, fused
convolutional neural network, some of the parameters are entered into a
single-stream convolutional neural network, but it can learn the features of
many data. Further, considering the relevance of classification and regression
tasks, we develop a multi-task learning strategy that predicts the labels used
in such tasks. We integrate two-stream multi-task learning into a single
convolutional neural network. Given the compact architecture, this network is
more efficient and easier to optimize than existing recurrent neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness in Cardiac MR Image Analysis: An Investigation of Bias Due to Data Imbalance in Deep Learning Based Segmentation. (arXiv:2106.12387v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puyol_Anton_E/0/1/0/all/0/1">Esther Puyol-Anton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruijsink_B/0/1/0/all/0/1">Bram Ruijsink</a>, <a href="http://arxiv.org/find/cs/1/au:+Piechnik_S/0/1/0/all/0/1">Stefan K. Piechnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubauer_S/0/1/0/all/0/1">Stefan Neubauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_S/0/1/0/all/0/1">Steffen E. Petersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a>, <a href="http://arxiv.org/find/cs/1/au:+King_A/0/1/0/all/0/1">Andrew P. King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12387">
                                    <div class="article-summary-box-inner">
                                        <span>The subject of &quot;fairness&quot; in artificial intelligence (AI) refers to assessing
AI algorithms for potential bias based on demographic characteristics such as
race and gender, and the development of algorithms to address this bias. Most
applications to date have been in computer vision, although some work in
healthcare has started to emerge. The use of deep learning (DL) in cardiac MR
segmentation has led to impressive results in recent years, and such techniques
are starting to be translated into clinical practice. However, no work has yet
investigated the fairness of such models. In this work, we perform such an
analysis for racial/gender groups, focusing on the problem of training data
imbalance, using a nnU-Net model trained and evaluated on cine short axis
cardiac MR data from the UK Biobank dataset, consisting of 5,903 subjects from
6 different racial groups. We find statistically significant differences in
Dice performance between different racial groups. To reduce the racial bias, we
investigated three strategies: (1) stratified batch sampling, in which batch
sampling is stratified to ensure balance between racial groups; (2) fair
meta-learning for segmentation, in which a DL classifier is trained to classify
race and jointly optimized with the segmentation model; and (3) protected group
models, in which a different segmentation model is trained for each racial
group. We also compared the results to the scenario where we have a perfectly
balanced database. To assess fairness we used the standard deviation (SD) and
skewed error ratio (SER) of the average Dice values. Our results demonstrate
that the racial bias results from the use of imbalanced training data, and that
all proposed bias mitigation strategies improved fairness, with the best SD and
SER resulting from the use of protected group models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA-LOAM: Semantic-aided LiDAR SLAM with Loop Closure. (arXiv:2106.11516v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xin Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangrui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wanlong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_F/0/1/0/all/0/1">Feng Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11516">
                                    <div class="article-summary-box-inner">
                                        <span>LiDAR-based SLAM system is admittedly more accurate and stable than others,
while its loop closure detection is still an open issue. With the development
of 3D semantic segmentation for point cloud, semantic information can be
obtained conveniently and steadily, essential for high-level intelligence and
conductive to SLAM. In this paper, we present a novel semantic-aided LiDAR SLAM
with loop closure based on LOAM, named SA-LOAM, which leverages semantics in
odometry as well as loop closure detection. Specifically, we propose a
semantic-assisted ICP, including semantically matching, downsampling and plane
constraint, and integrates a semantic graph-based place recognition method in
our loop closure detection module. Benefitting from semantics, we can improve
the localization accuracy, detect loop closures effectively, and construct a
global consistent semantic map even in large-scale scenes. Extensive
experiments on KITTI and Ford Campus dataset show that our system significantly
improves baseline performance, has generalization ability to unseen data and
achieves competitive results compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary Layers in Deep Neural Networks. (arXiv:2104.07085v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Hongyi Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabawi_D/0/1/0/all/0/1">Diaa Dabawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cetin_A/0/1/0/all/0/1">Ahmet Enis Cetin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07085">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel layer based on fast Walsh-Hadamard
transform (WHT) and smooth-thresholding to replace $1\times 1$ convolution
layers in deep neural networks. In the WHT domain, we denoise the transform
domain coefficients using the new smooth-thresholding non-linearity, a smoothed
version of the well-known soft-thresholding operator. We also introduce a
family of multiplication-free operators from the basic 2$\times$2 Hadamard
transform to implement $3\times 3$ depthwise separable convolution layers.
Using these two types of layers, we replace the bottleneck layers in
MobileNet-V2 to reduce the network&#x27;s number of parameters with a slight loss in
accuracy. For example, by replacing the final third bottleneck layers, we
reduce the number of parameters from 2.270M to 540K. This reduces the accuracy
from 95.21\% to 92.98\% on the CIFAR-10 dataset. Our approach significantly
improves the speed of data processing. The fast Walsh-Hadamard transform has a
computational complexity of $O(m\log_2 m)$. As a result, it is computationally
more efficient than the $1\times1$ convolution layer. The fast Walsh-Hadamard
layer processes a tensor in $\mathbb{R}^{10\times32\times32\times1024}$ about 2
times faster than $1\times1$ convolution layer on NVIDIA Jetson Nano computer
board.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusing Higher-Order Features in Graph Neural Networks for Skeleton-Based Action Recognition. (arXiv:2105.01563v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhenyue Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_P/0/1/0/all/0/1">Pan Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+McKay_B/0/1/0/all/0/1">Bob McKay</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1">Saeed Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01563">
                                    <div class="article-summary-box-inner">
                                        <span>Skeleton sequences are lightweight and compact, thus are ideal candidates for
action recognition on edge devices. Recent skeleton-based action recognition
methods extract features from 3D joint coordinates as spatial-temporal cues,
using these representations in a graph neural network for feature fusion to
boost recognition performance. The use of first- and second-order features,
\ie{} joint and bone representations, has led to high accuracy. Nonetheless,
many models are still confused by actions that have similar motion
trajectories. To address these issues, we propose fusing third-order features
in the form of angular encoding into modern architectures to robustly capture
the relationships between joints and body parts. This simple fusion with
popular spatial-temporal graph neural networks achieves new state-of-the-art
accuracy in two large benchmarks, including NTU60 and NTU120, while employing
fewer parameters and reduced run time. Our source code is publicly available
at: https://github.com/ZhenyueQin/Angular-Skeleton-Encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multimodal VAEs through Mutual Supervision. (arXiv:2106.12570v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joy_T/0/1/0/all/0/1">Tom Joy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuge Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmon_S/0/1/0/all/0/1">Sebastian M. Schmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1">N. Siddharth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12570">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal VAEs seek to model the joint distribution over heterogeneous data
(e.g.\ vision, language), whilst also capturing a shared representation across
such modalities. Prior work has typically combined information from the
modalities by reconciling idiosyncratic representations directly in the
recognition model through explicit products, mixtures, or other such
factorisations. Here we introduce a novel alternative, the MEME, that avoids
such explicit combinations by repurposing semi-supervised VAEs to combine
information between modalities implicitly through mutual supervision. This
formulation naturally allows learning from partially-observed data where some
modalities can be entirely missing -- something that most existing approaches
either cannot handle, or do so to a limited extent. We demonstrate that MEME
outperforms baselines on standard metrics across both partial and complete
observation schemes on the MNIST-SVHN (image-image) and CUB (image-text)
datasets. We also contrast the quality of the representations learnt by mutual
supervision against standard approaches and observe interesting trends in its
ability to capture relatedness between data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning. (arXiv:2106.11562v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sungmin Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Beomyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">Youngjoon Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11562">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a class-incremental semantic segmentation (CISS) problem. While
some recently proposed algorithms utilized variants of knowledge distillation
(KD) technique to tackle the problem, they only partially addressed the key
additional challenges in CISS that causes the catastrophic forgetting; i.e.,
the semantic drift of the background class and multi-label prediction issue. To
better address these challenges, we propose a new method, dubbed as SSUL-M
(Semantic Segmentation with Unknown Label with Memory), by carefully combining
several techniques tailored for semantic segmentation. More specifically, we
make three main contributions; (1) modeling unknown class within the background
class to help learning future classes (help plasticity), (2) freezing backbone
network and past classifiers with binary cross-entropy loss and pseudo-labeling
to overcome catastrophic forgetting (help stability), and (3) utilizing tiny
exemplar memory for the first time in CISS to improve both plasticity and
stability. As a result, we show our method achieves significantly better
performance than the recent state-of-the-art baselines on the standard
benchmark datasets. Furthermore, we justify our contributions with thorough and
extensive ablation analyses and discuss different natures of the CISS problem
compared to the standard class-incremental learning for classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation. (arXiv:2107.00644v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1">Nicklas Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00644">
                                    <div class="article-summary-box-inner">
                                        <span>While agents trained by Reinforcement Learning (RL) can solve increasingly
challenging tasks directly from visual observations, generalizing learned
skills to novel environments remains very challenging. Extensive use of data
augmentation is a promising technique for improving generalization in RL, but
it is often found to decrease sample efficiency and can even lead to
divergence. In this paper, we investigate causes of instability when using data
augmentation in common off-policy RL algorithms. We identify two problems, both
rooted in high-variance Q-targets. Based on our findings, we propose a simple
yet effective technique for stabilizing this class of algorithms under
augmentation. We perform extensive empirical evaluation of image-based RL using
both ConvNets and Vision Transformers (ViT) on a family of benchmarks based on
DeepMind Control Suite, as well as in robotic manipulation tasks. Our method
greatly improves stability and sample efficiency of ConvNets under
augmentation, and achieves generalization results competitive with
state-of-the-art methods for image-based RL. We further show that our method
scales to RL with ViT-based architectures, and that data augmentation may be
especially important in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoFormer: Searching Transformers for Visual Recognition. (arXiv:2107.00651v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Houwen Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibin Ling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00651">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pure transformer-based models have shown great potentials for
vision tasks such as image classification and detection. However, the design of
transformer networks is challenging. It has been observed that the depth,
embedding dimension, and number of heads can largely affect the performance of
vision transformers. Previous models configure these dimensions based upon
manual crafting. In this work, we propose a new one-shot architecture search
framework, namely AutoFormer, dedicated to vision transformer search.
AutoFormer entangles the weights of different blocks in the same layers during
supernet training. Benefiting from the strategy, the trained supernet allows
thousands of subnets to be very well-trained. Specifically, the performance of
these subnets with weights inherited from the supernet is comparable to those
retrained from scratch. Besides, the searched models, which we refer to
AutoFormers, surpass the recent state-of-the-arts such as ViT and DeiT. In
particular, AutoFormer-tiny/small/base achieve 74.7%/81.7%/82.4% top-1 accuracy
on ImageNet with 5.7M/22.9M/53.7M parameters, respectively. Lastly, we verify
the transferability of AutoFormer by providing the performance on downstream
benchmarks and distillation experiments. Code and models are available at
https://github.com/microsoft/AutoML.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLIP-It! Language-Guided Video Summarization. (arXiv:2107.00650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_M/0/1/0/all/0/1">Medhini Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00650">
                                    <div class="article-summary-box-inner">
                                        <span>A generic video summary is an abridged version of a video that conveys the
whole story and features the most important scenes. Yet the importance of
scenes in a video is often subjective, and users should have the option of
customizing the summary by using natural language to specify what is important
to them. Further, existing models for fully automatic generic summarization
have not exploited available language models, which can serve as an effective
prior for saliency. This work introduces CLIP-It, a single framework for
addressing both generic and query-focused video summarization, typically
approached separately in the literature. We propose a language-guided
multimodal transformer that learns to score frames in a video based on their
importance relative to one another and their correlation with a user-defined
query (for query-focused summarization) or an automatically generated dense
video caption (for generic video summarization). Our model can be extended to
the unsupervised setting by training without ground-truth supervision. We
outperform baselines and prior work by a significant margin on both standard
video summarization datasets (TVSum and SumMe) and a query-focused video
summarization dataset (QFVS). Particularly, we achieve large improvements in
the transfer setting, attesting to our method&#x27;s strong generalization
capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Neural Domain Adaptation for Document Image Binarization. (arXiv:2012.01204v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castellanos_F/0/1/0/all/0/1">Francisco J. Castellanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_A/0/1/0/all/0/1">Antonio-Javier Gallego</a>, <a href="http://arxiv.org/find/cs/1/au:+Calvo_Zaragoza_J/0/1/0/all/0/1">Jorge Calvo-Zaragoza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01204">
                                    <div class="article-summary-box-inner">
                                        <span>Binarization is a well-known image processing task, whose objective is to
separate the foreground of an image from the background. One of the many tasks
for which it is useful is that of preprocessing document images in order to
identify relevant information, such as text or symbols. The wide variety of
document types, alphabets, and formats makes binarization challenging. There
are multiple proposals with which to solve this problem, from classical
manually-adjusted methods, to more recent approaches based on machine learning.
The latter techniques require a large amount of training data in order to
obtain good results; however, labeling a portion of each existing collection of
documents is not feasible in practice. This is a common problem in supervised
learning, which can be addressed by using the so-called Domain Adaptation (DA)
techniques. These techniques take advantage of the knowledge learned in one
domain, for which labeled data are available, to apply it to other domains for
which there are no labeled data. This paper proposes a method that combines
neural networks and DA in order to carry out unsupervised document
binarization. However, when both the source and target domains are very
similar, this adaptation could be detrimental. Our methodology, therefore,
first measures the similarity between domains in an innovative manner in order
to determine whether or not it is appropriate to apply the adaptation process.
The results reported in the experimentation, when evaluating up to 20 possible
combinations among five different domains, show that our proposal successfully
deals with the binarization of new document domains without the need for
labeled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Framework of Bundle Adjustment and Feature Matching for High-Resolution Satellite Images. (arXiv:2107.00598v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ling_X/0/1/0/all/0/1">Xiao Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00598">
                                    <div class="article-summary-box-inner">
                                        <span>Bundle adjustment (BA) is a technique for refining sensor orientations of
satellite images, while adjustment accuracy is correlated with feature matching
results. Feature match-ing often contains high uncertainties in weak/repeat
textures, while BA results are helpful in reducing these uncertainties. To
compute more accurate orientations, this article incorpo-rates BA and feature
matching in a unified framework and formulates the union as the optimization of
a global energy function so that the solutions of the BA and feature matching
are constrained with each other. To avoid a degeneracy in the optimization, we
propose a comprised solution by breaking the optimization of the global energy
function into two-step suboptimizations and compute the local minimums of each
suboptimization in an incremental manner. Experiments on multi-view
high-resolution satellite images show that our proposed method outperforms
state-of-the-art orientation techniques with or without accurate least-squares
matching.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are Convolutional Neural Networks or Transformers more like human vision?. (arXiv:2105.07197v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tuli_S/0/1/0/all/0/1">Shikhar Tuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1">Ishita Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Grant_E/0/1/0/all/0/1">Erin Grant</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07197">
                                    <div class="article-summary-box-inner">
                                        <span>Modern machine learning models for computer vision exceed humans in accuracy
on specific visual recognition tasks, notably on datasets like ImageNet.
However, high accuracy can be achieved in many ways. The particular decision
function found by a machine learning system is determined not only by the data
to which the system is exposed, but also the inductive biases of the model,
which are typically harder to characterize. In this work, we follow a recent
trend of in-depth behavioral analyses of neural network models that go beyond
accuracy as an evaluation metric by looking at patterns of errors. Our focus is
on comparing a suite of standard Convolutional Neural Networks (CNNs) and a
recently-proposed attention-based network, the Vision Transformer (ViT), which
relaxes the translation-invariance constraint of CNNs and therefore represents
a model with a weaker set of inductive biases. Attention-based networks have
previously been shown to achieve higher accuracy than CNNs on vision tasks, and
we demonstrate, using new metrics for examining error consistency with more
granularity, that their errors are also more consistent with those of humans.
These results have implications both for building more human-like vision
models, as well as for understanding visual object recognition in humans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Sparsity for Smoothing Filters. (arXiv:2107.00627v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junqing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haihui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuechao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzhansky_M/0/1/0/all/0/1">Michael Ruzhansky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00627">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an interesting semi-sparsity smoothing algorithm
based on a novel sparsity-inducing optimization framework. This method is
derived from the multiple observations, that is, semi-sparsity prior knowledge
is more universally applicable, especially in areas where sparsity is not fully
admitted, such as polynomial-smoothing surfaces. We illustrate that this
semi-sparsity can be identified into a generalized $L_0$-norm minimization in
higher-order gradient domains, thereby giving rise to a new &#x60;&#x60;feature-aware&#x27;&#x27;
filtering method with a powerful simultaneous-fitting ability in both sparse
features (singularities and sharpening edges) and non-sparse regions
(polynomial-smoothing surfaces). Notice that a direct solver is always
unavailable due to the non-convexity and combinatorial nature of $L_0$-norm
minimization. Instead, we solve the model based on an efficient half-quadratic
splitting minimization with fast Fourier transforms (FFTs) for acceleration. We
finally demonstrate its versatility and many benefits to a series of
signal/image processing and computer vision applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explicit Clothing Modeling for an Animatable Full-Body Avatar. (arXiv:2106.14879v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_D/0/1/0/all/0/1">Donglai Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Prada_F/0/1/0/all/0/1">Fabian Andres Prada</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagautdinov_T/0/1/0/all/0/1">Timur Bagautdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weipeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yuan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">He Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodgins_J/0/1/0/all/0/1">Jessica Hodgins</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chenglei Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14879">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown great progress in building photorealistic animatable
full-body codec avatars, but these avatars still face difficulties in
generating high-fidelity animation of clothing. To address the difficulties, we
propose a method to build an animatable clothed body avatar with an explicit
representation of the clothing on the upper body from multi-view captured
videos. We use a two-layer mesh representation to separately register the 3D
scans with templates. In order to improve the photometric correspondence across
different frames, texture alignment is then performed through inverse rendering
of the clothing geometry and texture predicted by a variational autoencoder. We
then train a new two-layer codec avatar with separate modeling of the upper
clothing and the inner body layer. To learn the interaction between the body
dynamics and clothing states, we use a temporal convolution network to predict
the clothing latent code based on a sequence of input skeletal poses. We show
photorealistic animation output for three different actors, and demonstrate the
advantage of our clothed-body avatars over single-layer avatars in the previous
work. We also show the benefit of an explicit clothing model which allows the
clothing texture to be edited in the animation output.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Practicality of Deterministic Epistemic Uncertainty. (arXiv:2107.00649v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Postels_J/0/1/0/all/0/1">Janis Postels</a>, <a href="http://arxiv.org/find/cs/1/au:+Segu_M/0/1/0/all/0/1">Mattia Segu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1">Tao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fisher Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00649">
                                    <div class="article-summary-box-inner">
                                        <span>A set of novel approaches for estimating epistemic uncertainty in deep neural
networks with a single forward pass has recently emerged as a valid alternative
to Bayesian Neural Networks. On the premise of informative representations,
these deterministic uncertainty methods (DUMs) achieve strong performance on
detecting out-of-distribution (OOD) data while adding negligible computational
costs at inference time. However, it remains unclear whether DUMs are well
calibrated and can seamlessly scale to real-world applications - both
prerequisites for their practical deployment. To this end, we first provide a
taxonomy of DUMs, evaluate their calibration under continuous distributional
shifts and their performance on OOD detection for image classification tasks.
Then, we extend the most promising approaches to semantic segmentation. We find
that, while DUMs scale to realistic vision tasks and perform well on OOD
detection, the practicality of current methods is undermined by poor
calibration under realistic distributional shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focal Self-attention for Local-Global Interactions in Vision Transformers. (arXiv:2107.00641v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00641">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformer and its variants have shown great promise on
various computer vision tasks. The ability of capturing short- and long-range
visual dependencies through self-attention is arguably the main source for the
success. But it also brings challenges due to quadratic computational overhead,
especially for the high-resolution vision tasks (e.g., object detection). In
this paper, we present focal self-attention, a new mechanism that incorporates
both fine-grained local and coarse-grained global interactions. Using this new
mechanism, each token attends the closest surrounding tokens at fine
granularity but the tokens far away at coarse granularity, and thus can capture
both short- and long-range visual dependencies efficiently and effectively.
With focal self-attention, we propose a new variant of Vision Transformer
models, called Focal Transformer, which achieves superior performance over the
state-of-the-art vision Transformers on a range of public image classification
and object detection benchmarks. In particular, our Focal Transformer models
with a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8
Top-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.
Using Focal Transformers as the backbones, we obtain consistent and substantial
improvements over the current state-of-the-art Swin Transformers for 6
different object detection methods trained with standard 1x and 3x schedules.
Our largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs
on COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,
creating new SoTA on three of the most challenging computer vision tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Visual Recognition in Limited Data Regime using Self-Supervision and Self-Distillation. (arXiv:2107.00067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazumder_P/0/1/0/all/0/1">Pratik Mazumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Pravendra Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P. Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00067">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models generally learn the biases present in the training data.
Researchers have proposed several approaches to mitigate such biases and make
the model fair. Bias mitigation techniques assume that a sufficiently large
number of training examples are present. However, we observe that if the
training data is limited, then the effectiveness of bias mitigation methods is
severely degraded. In this paper, we propose a novel approach to address this
problem. Specifically, we adapt self-supervision and self-distillation to
reduce the impact of biases on the model in this setting. Self-supervision and
self-distillation are not used for bias mitigation. However, through this work,
we demonstrate for the first time that these techniques are very effective in
bias mitigation. We empirically show that our approach can significantly reduce
the biases learned by the model. Further, we experimentally demonstrate that
our approach is complementary to other bias mitigation strategies. Our approach
significantly improves their performance and further reduces the model biases
in the limited data regime. Specifically, on the L-CIFAR-10S skewed dataset,
our approach significantly reduces the bias score of the baseline model by
78.22% and outperforms it in terms of accuracy by a significant absolute margin
of 8.89%. It also significantly reduces the bias score for the state-of-the-art
domain independent bias mitigation method by 59.26% and improves its
performance by a significant absolute margin of 7.08%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Filter Networks for Image Classification. (arXiv:2107.00645v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00645">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-attention and pure multi-layer perceptrons (MLP)
models for vision have shown great potential in achieving promising performance
with fewer inductive biases. These models are generally based on learning
interaction among spatial locations from raw data. The complexity of
self-attention and MLP grows quadratically as the image size increases, which
makes these models hard to scale up when high-resolution features are required.
In this paper, we present the Global Filter Network (GFNet), a conceptually
simple yet computationally efficient architecture, that learns long-term
spatial dependencies in the frequency domain with log-linear complexity. Our
architecture replaces the self-attention layer in vision transformers with
three key operations: a 2D discrete Fourier transform, an element-wise
multiplication between frequency-domain features and learnable global filters,
and a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity
trade-offs of our models on both ImageNet and downstream tasks. Our results
demonstrate that GFNet can be a very competitive alternative to
transformer-style models and CNNs in efficiency, generalization ability and
robustness. Code is available at https://github.com/raoyongming/GFNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Segmentation with Domain Adaptation for Small Sampled Orbital CT Images. (arXiv:2107.00418v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Suh_S/0/1/0/all/0/1">Sungho Suh</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheon_S/0/1/0/all/0/1">Sojeong Cheon</a>, <a href="http://arxiv.org/find/eess/1/au:+Choi_W/0/1/0/all/0/1">Wonseo Choi</a>, <a href="http://arxiv.org/find/eess/1/au:+Chung_Y/0/1/0/all/0/1">Yeon Woong Chung</a>, <a href="http://arxiv.org/find/eess/1/au:+Cho_W/0/1/0/all/0/1">Won-Kyung Cho</a>, <a href="http://arxiv.org/find/eess/1/au:+Paik_J/0/1/0/all/0/1">Ji-Sun Paik</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1">Sung Eun Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_D/0/1/0/all/0/1">Dong-Jin Chang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_Y/0/1/0/all/0/1">Yong Oh Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00418">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have been widely used for medical image analysis.
However, the lack of access a to large-scale annotated dataset poses a great
challenge, especially in the case of rare diseases, or new domains for the
research society. Transfer of pre-trained features, from the relatively large
dataset is a considerable solution. In this paper, we have explored supervised
segmentation using domain adaptation for optic nerve and orbital tumor, when
only small sampled CT images are given. Even the lung image database consortium
image collection (LIDC-IDRI) is a cross-domain to orbital CT, but the proposed
domain adaptation method improved the performance of attention U-Net for the
segmentation in public optic nerve dataset and our clinical orbital tumor
dataset. The code and dataset are available at https://github.com/cmcbigdata.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Iterative Spatiotemporal Filtering for Classification of Multitemporal Satellite Data Sets. (arXiv:2107.00590v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Albanwan_H/0/1/0/all/0/1">Hessah Albanwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaohu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Desheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guldmann_J/0/1/0/all/0/1">Jean-Michel Guldmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00590">
                                    <div class="article-summary-box-inner">
                                        <span>The current practice in land cover/land use change analysis relies heavily on
the individually classified maps of the multitemporal data set. Due to varying
acquisition conditions (e.g., illumination, sensors, seasonal differences), the
classification maps yielded are often inconsistent through time for robust
statistical analysis. 3D geometric features have been shown to be stable for
assessing differences across the temporal data set. Therefore, in this article
we investigate he use of a multitemporal orthophoto and digital surface model
derived from satellite data for spatiotemporal classification. Our approach
consists of two major steps: generating per-class probability distribution maps
using the random-forest classifier with limited training samples, and making
spatiotemporal inferences using an iterative 3D spatiotemporal filter operating
on per-class probability maps. Our experimental results demonstrate that the
proposed methods can consistently improve the individual classification results
by 2%-6% and thus can be an important postclassification refinement approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generic Event Boundary Detection Challenge at CVPR 2021 Technical Report: Cascaded Temporal Attention Network (CASTANET). (arXiv:2107.00239v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Dexiang Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Congcong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1">Longyin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Libo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00239">
                                    <div class="article-summary-box-inner">
                                        <span>This report presents the approach used in the submission of Generic Event
Boundary Detection (GEBD) Challenge at CVPR21. In this work, we design a
Cascaded Temporal Attention Network (CASTANET) for GEBD, which is formed by
three parts, the backbone network, the temporal attention module, and the
classification module. Specifically, the Channel-Separated Convolutional
Network (CSN) is used as the backbone network to extract features, and the
temporal attention module is designed to enforce the network to focus on the
discriminative features. After that, the cascaded architecture is used in the
classification module to generate more accurate boundaries. In addition, the
ensemble strategy is used to further improve the performance of the proposed
method. The proposed method achieves 83.30% F1 score on Kinetics-GEBD test set,
which improves 20.5% F1 score compared to the baseline method. Code is
available at https://github.com/DexiangHong/Cascade-PC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SALYPATH: A Deep-Based Architecture for visual attention prediction. (arXiv:2107.00559v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kerkouri_M/0/1/0/all/0/1">Mohamed Amine Kerkouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tliba_M/0/1/0/all/0/1">Marouane Tliba</a>, <a href="http://arxiv.org/find/cs/1/au:+Chetouani_A/0/1/0/all/0/1">Aladine Chetouani</a>, <a href="http://arxiv.org/find/cs/1/au:+Harba_R/0/1/0/all/0/1">Rachid Harba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00559">
                                    <div class="article-summary-box-inner">
                                        <span>Human vision is naturally more attracted by some regions within their field
of view than others. This intrinsic selectivity mechanism, so-called visual
attention, is influenced by both high- and low-level factors; such as the
global environment (illumination, background texture, etc.), stimulus
characteristics (color, intensity, orientation, etc.), and some prior visual
information. Visual attention is useful for many computer vision applications
such as image compression, recognition, and captioning. In this paper, we
propose an end-to-end deep-based method, so-called SALYPATH (SALiencY and
scanPATH), that efficiently predicts the scanpath of an image through features
of a saliency model. The idea is predict the scanpath by exploiting the
capacity of a deep-based model to predict the saliency. The proposed method was
evaluated through 2 well-known datasets. The results obtained showed the
relevance of the proposed framework comparing to state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dep-$L_0$: Improving $L_0$-based Network Sparsification via Dependency Modeling. (arXiv:2107.00070v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00070">
                                    <div class="article-summary-box-inner">
                                        <span>Training deep neural networks with an $L_0$ regularization is one of the
prominent approaches for network pruning or sparsification. The method prunes
the network during training by encouraging weights to become exactly zero.
However, recent work of Gale et al. reveals that although this method yields
high compression rates on smaller datasets, it performs inconsistently on
large-scale learning tasks, such as ResNet50 on ImageNet. We analyze this
phenomenon through the lens of variational inference and find that it is likely
due to the independent modeling of binary gates, the mean-field approximation,
which is known in Bayesian statistics for its poor performance due to the crude
approximation. To mitigate this deficiency, we propose a dependency modeling of
binary gates, which can be modeled effectively as a multi-layer perceptron
(MLP). We term our algorithm Dep-$L_0$ as it prunes networks via a
dependency-enabled $L_0$ regularization. Extensive experiments on CIFAR10,
CIFAR100 and ImageNet with VGG16, ResNet50, ResNet56 show that our Dep-$L_0$
outperforms the original $L_0$-HC algorithm of Louizos et al. by a significant
margin, especially on ImageNet. Compared with the state-of-the-arts network
sparsification algorithms, our dependency modeling makes the $L_0$-based
sparsification once again very competitive on large-scale learning tasks. Our
source code is available at https://github.com/leo-yangli/dep-l0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Certified Segmentation via Randomized Smoothing. (arXiv:2107.00228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1">Marc Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1">Maximilian Baader</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00228">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new certification method for image and point cloud segmentation
based on randomized smoothing. The method leverages a novel scalable algorithm
for prediction and certification that correctly accounts for multiple testing,
necessary for ensuring statistical guarantees. The key to our approach is
reliance on established multiple-testing correction mechanisms as well as the
ability to abstain from classifying single pixels or points while still
robustly segmenting the overall input. Our experimental evaluation on synthetic
data and challenging datasets, such as Pascal Context, Cityscapes, and
ShapeNet, shows that our algorithm can achieve, for the first time, competitive
accuracy and certification guarantees on real-world segmentation tasks. We
provide an implementation at https://github.com/eth-sri/segmentation-smoothing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossless Coding of Point Cloud Geometry using a Deep Generative Model. (arXiv:2107.00400v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_D/0/1/0/all/0/1">Dat Thanh Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Quach_M/0/1/0/all/0/1">Maurice Quach</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenzise_G/0/1/0/all/0/1">Giuseppe Valenzise</a>, <a href="http://arxiv.org/find/eess/1/au:+Duhamel_P/0/1/0/all/0/1">Pierre Duhamel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00400">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a lossless point cloud (PC) geometry compression method
that uses neural networks to estimate the probability distribution of voxel
occupancy. First, to take into account the PC sparsity, our method adaptively
partitions a point cloud into multiple voxel block sizes. This partitioning is
signalled via an octree. Second, we employ a deep auto-regressive generative
model to estimate the occupancy probability of each voxel given the previously
encoded ones. We then employ the estimated probabilities to code efficiently a
block using a context-based arithmetic coder. Our context has variable size and
can expand beyond the current block to learn more accurate probabilities. We
also consider using data augmentation techniques to increase the generalization
capability of the learned probability models, in particular in the presence of
noise and lower-density point clouds. Experimental evaluation, performed on a
variety of point clouds from four different datasets and with diverse
characteristics, demonstrates that our method reduces significantly (by up to
30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overhead-MNIST: Machine Learning Baselines for Image Classification. (arXiv:2107.00436v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Larsen_E/0/1/0/all/0/1">Erik Larsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1">David Noever</a>, <a href="http://arxiv.org/find/cs/1/au:+MacVittie_K/0/1/0/all/0/1">Korey MacVittie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lilly_J/0/1/0/all/0/1">John Lilly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00436">
                                    <div class="article-summary-box-inner">
                                        <span>Twenty-three machine learning algorithms were trained then scored to
establish baseline comparison metrics and to select an image classification
algorithm worthy of embedding into mission-critical satellite imaging systems.
The Overhead-MNIST dataset is a collection of satellite images similar in style
to the ubiquitous MNIST hand-written digits found in the machine learning
literature. The CatBoost classifier, Light Gradient Boosting Machine, and
Extreme Gradient Boosting models produced the highest accuracies, Areas Under
the Curve (AUC), and F1 scores in a PyCaret general comparison. Separate
evaluations showed that a deep convolutional architecture was the most
promising. We present results for the overall best performing algorithm as a
baseline for edge deployability and future performance improvement: a
convolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen
test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DivergentNets: Medical Image Segmentation by Network Ensemble. (arXiv:2107.00283v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00283">
                                    <div class="article-summary-box-inner">
                                        <span>Detection of colon polyps has become a trending topic in the intersecting
fields of machine learning and gastrointestinal endoscopy. The focus has mainly
been on per-frame classification. More recently, polyp segmentation has gained
attention in the medical community. Segmentation has the advantage of being
more accurate than per-frame classification or object detection as it can show
the affected area in greater detail. For our contribution to the EndoCV 2021
segmentation challenge, we propose two separate approaches. First, a
segmentation model named TriUNet composed of three separate UNet models.
Second, we combine TriUNet with an ensemble of well-known segmentation models,
namely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called
DivergentNets to produce more generalizable medical image segmentation masks.
In addition, we propose a modified Dice loss that calculates loss only for a
single class when performing multiclass segmentation, forcing the model to
focus on what is most important. Overall, the proposed methods achieved the
best average scores for each respective round in the challenge, with TriUNet
being the winning model in Round I and DivergentNets being the winning model in
Round II of the segmentation generalization challenge at EndoCV 2021. The
implementation of our approach is made publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the detection-to-track association for online multi-object tracking. (arXiv:2107.00500v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xufeng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chang-Tsun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_V/0/1/0/all/0/1">Victor Sanchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Maple_C/0/1/0/all/0/1">Carsten Maple</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00500">
                                    <div class="article-summary-box-inner">
                                        <span>Driven by recent advances in object detection with deep neural networks, the
tracking-by-detection paradigm has gained increasing prevalence in the research
community of multi-object tracking (MOT). It has long been known that
appearance information plays an essential role in the detection-to-track
association, which lies at the core of the tracking-by-detection paradigm.
While most existing works consider the appearance distances between the
detections and the tracks, they ignore the statistical information implied by
the historical appearance distance records in the tracks, which can be
particularly useful when a detection has similar distances with two or more
tracks. In this work, we propose a hybrid track association (HTA) algorithm
that models the historical appearance distances of a track with an incremental
Gaussian mixture model (IGMM) and incorporates the derived statistical
information into the calculation of the detection-to-track association cost.
Experimental results on three MOT benchmarks confirm that HTA effectively
improves the target identification performance with a small compromise to the
tracking speed. Additionally, compared to many state-of-the-art trackers, the
DeepSORT tracker equipped with HTA achieves better or comparable performance in
terms of the balance of tracking quality and speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Measuring Bias in Image Classification. (arXiv:2107.00360v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schaaf_N/0/1/0/all/0/1">Nina Schaaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitri_O/0/1/0/all/0/1">Omar de Mitri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hang Beom Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Windberger_A/0/1/0/all/0/1">Alexander Windberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1">Marco F. Huber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00360">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNN) have become de fact state-of-the-art for
the main computer vision tasks. However, due to the complex underlying
structure their decisions are hard to understand which limits their use in some
context of the industrial world. A common and hard to detect challenge in
machine learning (ML) tasks is data bias. In this work, we present a systematic
approach to uncover data bias by means of attribution maps. For this purpose,
first an artificial dataset with a known bias is created and used to train
intentionally biased CNNs. The networks&#x27; decisions are then inspected using
attribution maps. Finally, meaningful metrics are used to measure the
attribution maps&#x27; representativeness with respect to the known bias. The
proposed study shows that some attribution map techniques highlight the
presence of bias in the data better than others and metrics can support the
identification of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GlyphCRM: Bidirectional Encoder Representation for Chinese Character with its Glyph. (arXiv:2107.00395v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Baotian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingcai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yang Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yuxin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lin Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00395">
                                    <div class="article-summary-box-inner">
                                        <span>Previous works indicate that the glyph of Chinese characters contains rich
semantic information and has the potential to enhance the representation of
Chinese characters. The typical method to utilize the glyph features is by
incorporating them into the character embedding space. Inspired by previous
methods, we innovatively propose a Chinese pre-trained representation model
named as GlyphCRM, which abandons the ID-based character embedding method yet
solely based on sequential character images. We render each character into a
binary grayscale image and design two-channel position feature maps for it.
Formally, we first design a two-layer residual convolutional neural network,
namely HanGlyph to generate the initial glyph representation of Chinese
characters, and subsequently adopt multiple bidirectional encoder Transformer
blocks as the superstructure to capture the context-sensitive information.
Meanwhile, we feed the glyph features extracted from each layer of the HanGlyph
module into the underlying Transformer blocks by skip-connection method to
fully exploit the glyph features of Chinese characters. As the HanGlyph module
can obtain a sufficient glyph representation of any Chinese character, the
long-standing out-of-vocabulary problem could be effectively solved. Extensive
experimental results indicate that GlyphCRM substantially outperforms the
previous BERT-based state-of-the-art model on 9 fine-tuning tasks, and it has
strong transferability and generalization on specialized fields and
low-resource tasks. We hope this work could spark further research beyond the
realms of well-established representation of Chinese texts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crowdsourcing Evaluation of Saliency-based XAI Methods. (arXiv:2107.00456v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaotian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1">Arseny Tolmachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_T/0/1/0/all/0/1">Tatsuya Yamamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1">Koh Takeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1">Seiji Okajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1">Tomoyoshi Takebayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1">Koji Maruhashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00456">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the reasons behind the predictions made by deep neural networks
is critical for gaining human trust in many important applications, which is
reflected in the increasing demand for explainability in AI (XAI) in recent
years. Saliency-based feature attribution methods, which highlight important
parts of images that contribute to decisions by classifiers, are often used as
XAI methods, especially in the field of computer vision. In order to compare
various saliency-based XAI methods quantitatively, several approaches for
automated evaluation schemes have been proposed; however, there is no guarantee
that such automated evaluation metrics correctly evaluate explainability, and a
high rating by an automated evaluation scheme does not necessarily mean a high
explainability for humans. In this study, instead of the automated evaluation,
we propose a new human-based evaluation scheme using crowdsourcing to evaluate
XAI methods. Our method is inspired by a human computation game, &quot;Peek-a-boom&quot;,
and can efficiently compare different XAI methods by exploiting the power of
crowds. We evaluate the saliency maps of various XAI methods on two datasets
with automated and crowd-based evaluation schemes. Our experiments show that
the result of our crowd-based evaluation scheme is different from those of
automated evaluation schemes. In addition, we regard the crowd-based evaluation
results as ground truths and provide a quantitative performance measure to
compare different automated evaluation schemes. We also discuss the impact of
crowd workers on the results and show that the varying ability of crowd workers
does not significantly impact the results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Disambiguate Strongly Interacting Hands via Probabilistic Per-pixel Part Segmentation. (arXiv:2107.00434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zicong Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1">Adrian Spurr</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocabas_M/0/1/0/all/0/1">Muhammed Kocabas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siyu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael J. Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00434">
                                    <div class="article-summary-box-inner">
                                        <span>In natural conversation and interaction, our hands often overlap or are in
contact with each other. Due to the homogeneous appearance of hands, this makes
estimating the 3D pose of interacting hands from images difficult. In this
paper we demonstrate that self-similarity, and the resulting ambiguities in
assigning pixel observations to the respective hands and their parts, is a
major cause of the final 3D pose error. Motivated by this insight, we propose
DIGIT, a novel method for estimating the 3D poses of two interacting hands from
a single monocular image. The method consists of two interwoven branches that
process the input imagery into a per-pixel semantic part segmentation mask and
a visual feature volume. In contrast to prior work, we do not decouple the
segmentation from the pose estimation stage, but rather leverage the per-pixel
probabilities directly in the downstream pose estimation task. To do so, the
part probabilities are merged with the visual features and processed via
fully-convolutional layers. We experimentally show that the proposed approach
achieves new state-of-the-art performance on the InterHand2.6M dataset for both
single and interacting hands across all metrics. We provide detailed ablation
studies to demonstrate the efficacy of our method and to provide insights into
how the modelling of pixel ownership affects single and interacting hand pose
estimation. Our code will be released for research purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OPT: Omni-Perception Pre-Trainer for Cross-Modal Understanding and Generation. (arXiv:2107.00249v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinxin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Longteng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zijia Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mingzhen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weining Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinqiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hanqing Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00249">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an Omni-perception Pre-Trainer (OPT) for
cross-modal understanding and generation, by jointly modeling visual, text and
audio resources. OPT is constructed in an encoder-decoder framework, including
three single-modal encoders to generate token-based embeddings for each
modality, a cross-modal encoder to encode the correlations among the three
modalities, and two cross-modal decoders to generate text and image
respectively. For the OPT&#x27;s pre-training, we design a multi-task pretext
learning scheme to model multi-modal resources from three different data
granularities, \ie, token-, modality-, and sample-level modeling, through which
OPT learns to align and translate among different modalities. The pre-training
task is carried out on a large amount of image-text-audio triplets from Open
Images. Experimental results show that OPT can learn strong image-text-audio
multi-modal representations and achieve promising results on a variety of
cross-modal understanding and generation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Human Motion Prediction Through Continual Learning. (arXiv:2107.00544v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yasar_M/0/1/0/all/0/1">Mohammad Samin Yasar</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_T/0/1/0/all/0/1">Tariq Iqbal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00544">
                                    <div class="article-summary-box-inner">
                                        <span>Human motion prediction is an essential component for enabling closer
human-robot collaboration. The task of accurately predicting human motion is
non-trivial. It is compounded by the variability of human motion, both at a
skeletal level due to the varying size of humans and at a motion level due to
individual movement&#x27;s idiosyncrasies. These variables make it challenging for
learning algorithms to obtain a general representation that is robust to the
diverse spatio-temporal patterns of human motion. In this work, we propose a
modular sequence learning approach that allows end-to-end training while also
having the flexibility of being fine-tuned. Our approach relies on the
diversity of training samples to first learn a robust representation, which can
then be fine-tuned in a continual learning setup to predict the motion of new
subjects. We evaluated the proposed approach by comparing its performance
against state-of-the-art baselines. The results suggest that our approach
outperforms other methods over all the evaluated temporal horizons, using a
small amount of data for fine-tuning. The improved performance of our approach
opens up the possibility of using continual learning for personalized and
reliable motion prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter Extreme Points Geodesics for Weakly Supervised Segmentation. (arXiv:2107.00583v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dorent_R/0/1/0/all/0/1">Reuben Dorent</a>, <a href="http://arxiv.org/find/cs/1/au:+Joutard_S/0/1/0/all/0/1">Samuel Joutard</a>, <a href="http://arxiv.org/find/cs/1/au:+Shapey_J/0/1/0/all/0/1">Jonathan Shapey</a>, <a href="http://arxiv.org/find/cs/1/au:+Kujawa_A/0/1/0/all/0/1">Aaron Kujawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Modat_M/0/1/0/all/0/1">Marc Modat</a>, <a href="http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vercauteren_T/0/1/0/all/0/1">Tom Vercauteren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00583">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce $\textit{InExtremIS}$, a weakly supervised 3D approach to train
a deep image segmentation network using particularly weak train-time
annotations: only 6 extreme clicks at the boundary of the objects of interest.
Our fully-automatic method is trained end-to-end and does not require any
test-time annotations. From the extreme points, 3D bounding boxes are extracted
around objects of interest. Then, deep geodesics connecting extreme points are
generated to increase the amount of &quot;annotated&quot; voxels within the bounding
boxes. Finally, a weakly supervised regularised loss derived from a Conditional
Random Field formulation is used to encourage prediction consistency over
homogeneous regions. Extensive experiments are performed on a large open
dataset for Vestibular Schwannoma segmentation. $\textit{InExtremIS}$ obtained
competitive performance, approaching full supervision and outperforming
significantly other weakly supervised techniques based on bounding boxes.
Moreover, given a fixed annotation time budget, $\textit{InExtremIS}$
outperforms full supervision. Our code and data are available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedMix: Approximation of Mixup under Mean Augmented Federated Learning. (arXiv:2107.00233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1">Tehrim Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Sumin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00233">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) allows edge devices to collectively learn a model
without directly sharing data within each device, thus preserving privacy and
eliminating the need to store data globally. While there are promising results
under the assumption of independent and identically distributed (iid) local
data, current state-of-the-art algorithms suffer from performance degradation
as the heterogeneity of local data across clients increases. To resolve this
issue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),
where clients send and receive averaged local data, subject to the privacy
requirements of target applications. Under our framework, we propose a new
augmentation algorithm, named FedMix, which is inspired by a phenomenal yet
simple data augmentation method, Mixup, but does not require local raw data to
be directly shared among devices. Our method shows greatly improved performance
in the standard benchmark datasets of FL, under highly non-iid federated
settings, compared to conventional algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Compression Towards Machine Vision: Network Architecture Design and Optimization. (arXiv:2107.00328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shurun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yan Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00328">
                                    <div class="article-summary-box-inner">
                                        <span>The research of visual signal compression has a long history. Fueled by deep
learning, exciting progress has been made recently. Despite achieving better
compression performance, existing end-to-end compression algorithms are still
designed towards better signal quality in terms of rate-distortion
optimization. In this paper, we show that the design and optimization of
network architecture could be further improved for compression towards machine
vision. We propose an inverted bottleneck structure for end-to-end compression
towards machine vision, which specifically accounts for efficient
representation of the semantic information. Moreover, we quest the capability
of optimization by incorporating the analytics accuracy into the optimization
process, and the optimality is further explored with generalized rate-accuracy
optimization in an iterative manner. We use object detection as a showcase for
end-to-end compression towards machine vision, and extensive experiments show
that the proposed scheme achieves significant BD-rate savings in terms of
analysis performance. Moreover, the promise of the scheme is also demonstrated
with strong generalization capability towards other machine vision tasks, due
to the enabling of signal-level reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Diabetic Retinopathy Detection and Retinal Image Generation. (arXiv:2107.00296v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Niu_Y/0/1/0/all/0/1">Yuhao Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_L/0/1/0/all/0/1">Lin Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yitian Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_F/0/1/0/all/0/1">Feng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00296">
                                    <div class="article-summary-box-inner">
                                        <span>Though deep learning has shown successful performance in classifying the
label and severity stage of certain diseases, most of them give few
explanations on how to make predictions. Inspired by Koch&#x27;s Postulates, the
foundation in evidence-based medicine (EBM) to identify the pathogen, we
propose to exploit the interpretability of deep learning application in medical
diagnosis. By determining and isolating the neuron activation patterns on which
diabetic retinopathy (DR) detector relies to make decisions, we demonstrate the
direct relation between the isolated neuron activation and lesions for a
pathological explanation. To be specific, we first define novel pathological
descriptors using activated neurons of the DR detector to encode both spatial
and appearance information of lesions. Then, to visualize the symptom encoded
in the descriptor, we propose Patho-GAN, a new network to synthesize medically
plausible retinal images. By manipulating these descriptors, we could even
arbitrarily control the position, quantity, and categories of generated
lesions. We also show that our synthesized images carry the symptoms directly
related to diabetic retinopathy diagnosis. Our generated images are both
qualitatively and quantitatively superior to the ones by previous methods.
Besides, compared to existing methods that take hours to generate an image, our
second level speed endows the potential to be an effective solution for data
augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VideoLightFormer: Lightweight Action Recognition using Transformers. (arXiv:2107.00451v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient video action recognition remains a challenging problem. One large
model after another takes the place of the state-of-the-art on the Kinetics
dataset, but real-world efficiency evaluations are often lacking. In this work,
we fill this gap and investigate the use of transformers for efficient action
recognition. We propose a novel, lightweight action recognition architecture,
VideoLightFormer. In a factorized fashion, we carefully extend the 2D
convolutional Temporal Segment Network with transformers, while maintaining
spatial and temporal video structure throughout the entire model. Existing
methods often resort to one of the two extremes, where they either apply huge
transformers to video features, or minimal transformers on highly pooled video
features. Our method differs from them by keeping the transformer models small,
but leveraging full spatiotemporal feature structure. We evaluate
VideoLightFormer in a high-efficiency setting on the temporally-demanding
EPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it
achieves a better mix of efficiency and accuracy than existing state-of-the-art
models, apart from the Temporal Shift Module on SSV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSC: Semantic Scan Context for Large-Scale Place Recognition. (arXiv:2107.00382v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xin Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangrui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tianxin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00382">
                                    <div class="article-summary-box-inner">
                                        <span>Place recognition gives a SLAM system the ability to correct cumulative
errors. Unlike images that contain rich texture features, point clouds are
almost pure geometric information which makes place recognition based on point
clouds challenging. Existing works usually encode low-level features such as
coordinate, normal, reflection intensity, etc., as local or global descriptors
to represent scenes. Besides, they often ignore the translation between point
clouds when matching descriptors. Different from most existing methods, we
explore the use of high-level features, namely semantics, to improve the
descriptor&#x27;s representation ability. Also, when matching descriptors, we try to
correct the translation between point clouds to improve accuracy. Concretely,
we propose a novel global descriptor, Semantic Scan Context, which explores
semantic information to represent scenes more effectively. We also present a
two-step global semantic ICP to obtain the 3D pose (x, y, yaw) used to align
the point cloud to improve matching performance. Our experiments on the KITTI
dataset show that our approach outperforms the state-of-the-art methods with a
large margin. Our code is available at: https://github.com/lilin-hitcrt/SSC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIDV-2020: A Comprehensive Benchmark Dataset for Identity Document Analysis. (arXiv:2107.00396v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bulatov_K/0/1/0/all/0/1">Konstantin Bulatov</a>, <a href="http://arxiv.org/find/cs/1/au:+Emelianova_E/0/1/0/all/0/1">Ekaterina Emelianova</a>, <a href="http://arxiv.org/find/cs/1/au:+Tropin_D/0/1/0/all/0/1">Daniil Tropin</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoryukina_N/0/1/0/all/0/1">Natalya Skoryukina</a>, <a href="http://arxiv.org/find/cs/1/au:+Chernyshova_Y/0/1/0/all/0/1">Yulia Chernyshova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheshkus_A/0/1/0/all/0/1">Alexander Sheshkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Usilin_S/0/1/0/all/0/1">Sergey Usilin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_Z/0/1/0/all/0/1">Zuheng Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Burie_J/0/1/0/all/0/1">Jean-Christophe Burie</a>, <a href="http://arxiv.org/find/cs/1/au:+Luqman_M/0/1/0/all/0/1">Muhammad Muzzamil Luqman</a>, <a href="http://arxiv.org/find/cs/1/au:+Arlazarov_V/0/1/0/all/0/1">Vladimir V. Arlazarov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00396">
                                    <div class="article-summary-box-inner">
                                        <span>Identity documents recognition is an important sub-field of document
analysis, which deals with tasks of robust document detection, type
identification, text fields recognition, as well as identity fraud prevention
and document authenticity validation given photos, scans, or video frames of an
identity document capture. Significant amount of research has been published on
this topic in recent years, however a chief difficulty for such research is
scarcity of datasets, due to the subject matter being protected by security
requirements. A few datasets of identity documents which are available lack
diversity of document types, capturing conditions, or variability of document
field values. In addition, the published datasets were typically designed only
for a subset of document recognition problems, not for a complex identity
document analysis. In this paper, we present a dataset MIDV-2020 which consists
of 1000 video clips, 2000 scanned images, and 1000 photos of 1000 unique mock
identity documents, each with unique text field values and unique artificially
generated faces, with rich annotation. For the presented benchmark dataset
baselines are provided for such tasks as document location and identification,
text fields recognition, and face detection. With 72409 annotated images in
total, to the date of publication the proposed dataset is the largest publicly
available identity documents dataset with variable artificially generated data,
and we believe that it will prove invaluable for advancement of the field of
document analysis and recognition. The dataset is available for download at
this ftp URL and this http URL .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iMiGUE: An Identity-free Video Dataset for Micro-Gesture Understanding and Emotion Analysis. (arXiv:2107.00285v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Henglin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zitong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaobai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhaoz%3F_G/0/1/0/all/0/1">Guoying Zhaoz?</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00285">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new dataset for the emotional artificial intelligence
research: identity-free video dataset for Micro-Gesture Understanding and
Emotion analysis (iMiGUE). Different from existing public datasets, iMiGUE
focuses on nonverbal body gestures without using any identity information,
while the predominant researches of emotion analysis concern sensitive
biometric data, like face and speech. Most importantly, iMiGUE focuses on
micro-gestures, i.e., unintentional behaviors driven by inner feelings, which
are different from ordinary scope of gestures from other gesture datasets which
are mostly intentionally performed for illustrative purposes. Furthermore,
iMiGUE is designed to evaluate the ability of models to analyze the emotional
states by integrating information of recognized micro-gesture, rather than just
recognizing prototypes in the sequences separately (or isolatedly). This is
because the real need for emotion AI is to understand the emotional states
behind gestures in a holistic way. Moreover, to counter for the challenge of
imbalanced sample distribution of this dataset, an unsupervised learning method
is proposed to capture latent representations from the micro-gesture sequences
themselves. We systematically investigate representative methods on this
dataset, and comprehensive experimental results reveal several interesting
insights from the iMiGUE, e.g., micro-gesture-based analysis can promote
emotion understanding. We confirm that the new iMiGUE dataset could advance
studies of micro-gesture and emotion AI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Graph Learning for Disease Prediction. (arXiv:2107.00206v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenfeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00206">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from the powerful expressive capability of graphs, graph-based
approaches have achieved impressive performance in various biomedical
applications. Most existing methods tend to define the adjacency matrix among
samples manually based on meta-features, and then obtain the node embeddings
for downstream tasks by Graph Representation Learning (GRL). However, it is not
easy for these approaches to generalize to unseen samples. Meanwhile, the
complex correlation between modalities is also ignored. As a result, these
factors inevitably yield the inadequacy of providing valid information about
the patient&#x27;s condition for a reliable diagnosis. In this paper, we propose an
end-to-end Multimodal Graph Learning framework (MMGL) for disease prediction.
To effectively exploit the rich information across multi-modality associated
with diseases, amodal-attentional multi-modal fusion is proposed to integrate
the features of each modality by leveraging the correlation and complementarity
between the modalities. Furthermore, instead of defining the adjacency matrix
manually as existing methods, the latent graph structure can be captured
through a novel way of adaptive graph learning. It could be jointly optimized
with the prediction model, thus revealing the intrinsic connections among
samples. Unlike the previous transductive methods, our model is also applicable
to the scenario of inductive learning for those unseen data. An extensive group
of experiments on two disease prediction problems is then carefully designed
and presented, demonstrating that MMGL obtains more favorable performances. In
addition, we also visualize and analyze the learned graph structure to provide
more reliable decision support for doctors in real medical applications and
inspiration for disease research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SinGAN-Seg: Synthetic Training Data Generation for Medical Image Segmentation. (arXiv:2107.00471v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Salehi_P/0/1/0/all/0/1">Pegah Salehi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sheshkal_S/0/1/0/all/0/1">Sajad Amouei Sheshkal</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Hammer_H/0/1/0/all/0/1">Hugo L.Hammer</a>, <a href="http://arxiv.org/find/eess/1/au:+Parasa_S/0/1/0/all/0/1">Sravanthi Parasa</a>, <a href="http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00471">
                                    <div class="article-summary-box-inner">
                                        <span>Processing medical data to find abnormalities is a time-consuming and costly
task, requiring tremendous efforts from medical experts. Therefore, Ai has
become a popular tool for the automatic processing of medical data, acting as a
supportive tool for doctors. AI tools highly depend on data for training the
models. However, there are several constraints to access to large amounts of
medical data to train machine learning algorithms in the medical domain, e.g.,
due to privacy concerns and the costly, time-consuming medical data annotation
process. To address this, in this paper we present a novel synthetic data
generation pipeline called SinGAN-Seg to produce synthetic medical data with
the corresponding annotated ground truth masks. We show that these synthetic
data generation pipelines can be used as an alternative to bypass privacy
concerns and as an alternative way to produce artificial segmentation datasets
with corresponding ground truth masks to avoid the tedious medical data
annotation process. As a proof of concept, we used an open polyp segmentation
dataset. By training UNet++ using both the real polyp segmentation dataset and
the corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we
show that the synthetic data can achieve a very close performance to the real
data when the real segmentation datasets are large enough. In addition, we show
that synthetic data generated from the SinGAN-Seg pipeline improving the
performance of segmentation algorithms when the training dataset is very small.
Since our SinGAN-Seg pipeline is applicable for any medical dataset, this
pipeline can be used with any other segmentation datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Bottlenecks for Multimodal Fusion. (arXiv:2107.00135v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagrani_A/0/1/0/all/0/1">Arsha Nagrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnab_A/0/1/0/all/0/1">Anurag Arnab</a>, <a href="http://arxiv.org/find/cs/1/au:+Jansen_A/0/1/0/all/0/1">Aren Jansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chen Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00135">
                                    <div class="article-summary-box-inner">
                                        <span>Humans perceive the world by concurrently processing and fusing
high-dimensional inputs from multiple modalities such as vision and audio.
Machine perception models, in stark contrast, are typically modality-specific
and optimised for unimodal benchmarks, and hence late-stage fusion of final
representations or predictions from each modality (&#x60;late-fusion&#x27;) is still a
dominant paradigm for multimodal video classification. Instead, we introduce a
novel transformer based architecture that uses &#x60;fusion bottlenecks&#x27; for
modality fusion at multiple layers. Compared to traditional pairwise
self-attention, our model forces information between different modalities to
pass through a small number of bottleneck latents, requiring the model to
collate and condense the most relevant information in each modality and only
share what is necessary. We find that such a strategy improves fusion
performance, at the same time reducing computational cost. We conduct thorough
ablation studies, and achieve state-of-the-art results on multiple audio-visual
classification benchmarks including Audioset, Epic-Kitchens and VGGSound. All
code and models will be released.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems. (arXiv:2107.00315v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1">Chitta Baral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00315">
                                    <div class="article-summary-box-inner">
                                        <span>Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks. (arXiv:2107.00415v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchisio_A/0/1/0/all/0/1">Alberto Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Pira_G/0/1/0/all/0/1">Giacomo Pira</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_M/0/1/0/all/0/1">Maurizio Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Masera_G/0/1/0/all/0/1">Guido Masera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00415">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs), despite being energy-efficient when
implemented on neuromorphic hardware and coupled with event-based Dynamic
Vision Sensors (DVS), are vulnerable to security threats, such as adversarial
attacks, i.e., small perturbations added to the input for inducing a
misclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet
efficient adversarial attack methodologies targeted to perturb the event
sequences that compose the input of the SNNs. First, we show that noise filters
for DVS can be used as defense mechanisms against adversarial attacks.
Afterwards, we implement several attacks and test them in the presence of two
types of noise filters for DVS cameras. The experimental results show that the
filters can only partially defend the SNNs against our proposed DVS-Attacks.
Using the best settings for the noise filters, our proposed Mask Filter-Aware
Dash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset
and by more than 65% on the MNIST dataset, compared to the original clean
frames. The source code of all the proposed DVS-Attacks and noise filters is
released at https://github.com/albertomarchisio/DVS-Attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Knowledge Distillation: An Inheritance and Exploration Framework. (arXiv:2107.00181v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1">Jun Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xinmei Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Bing Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00181">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Distillation (KD) is a popular technique to transfer knowledge from
a teacher model or ensemble to a student model. Its success is generally
attributed to the privileged information on similarities/consistency between
the class distributions or intermediate feature representations of the teacher
model and the student model. However, directly pushing the student model to
mimic the probabilities/features of the teacher model to a large extent limits
the student model in learning undiscovered knowledge/features. In this paper,
we propose a novel inheritance and exploration knowledge distillation framework
(IE-KD), in which a student model is split into two parts - inheritance and
exploration. The inheritance part is learned with a similarity loss to transfer
the existing learned knowledge from the teacher model to the student model,
while the exploration part is encouraged to learn representations different
from the inherited ones with a dis-similarity loss. Our IE-KD framework is
generic and can be easily combined with existing distillation or mutual
learning methods for training deep neural networks. Extensive experiments
demonstrate that these two parts can jointly push the student model to learn
more diversified and effective representations, and our IE-KD can be a general
technique to improve the student network to achieve SOTA performance.
Furthermore, by applying our IE-KD to the training of two networks, the
performance of both can be improved w.r.t. deep mutual learning. The code and
models of IE-KD will be make publicly available at
https://github.com/yellowtownhz/IE-KD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feasibility of Haralick&#x27;s Texture Features for the Classification of Chromogenic In-situ Hybridization Images. (arXiv:2107.00235v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pavlov_S/0/1/0/all/0/1">Stoyan Pavlov</a>, <a href="http://arxiv.org/find/eess/1/au:+Momcheva_G/0/1/0/all/0/1">Galina Momcheva</a>, <a href="http://arxiv.org/find/eess/1/au:+Burlakova_P/0/1/0/all/0/1">Pavlina Burlakova</a>, <a href="http://arxiv.org/find/eess/1/au:+Atanasov_S/0/1/0/all/0/1">Simeon Atanasov</a>, <a href="http://arxiv.org/find/eess/1/au:+Stoyanov_D/0/1/0/all/0/1">Dimo Stoyanov</a>, <a href="http://arxiv.org/find/eess/1/au:+Ivanov_M/0/1/0/all/0/1">Martin Ivanov</a>, <a href="http://arxiv.org/find/eess/1/au:+Tonchev_A/0/1/0/all/0/1">Anton Tonchev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00235">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a proof of concept for the usefulness of second-order
texture features for the qualitative analysis and classification of chromogenic
in-situ hybridization whole slide images in high-throughput imaging
experiments. The challenge is that currently, the gold standard for gene
expression grading in such images is expert assessment. The idea of the
research team is to use different approaches in the analysis of these images
that will be used for structural segmentation and functional analysis in gene
expression. The article presents such perspective idea to select a number of
textural features that are going to be used for classification. In our
experiment, natural grouping of image samples (tiles) depending on their local
texture properties was explored in an unsupervised classification procedure.
The features are reduced to two dimensions with fuzzy c-means clustering. The
overall conclusion of this experiment is that Haralick features are a viable
choice for classification and analysis of chromogenic in-situ hybridization
image data. The principal component analysis approach produced slightly more
&quot;understandable&quot; from an annotator&#x27;s point of view classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drone swarm patrolling with uneven coverage requirements. (arXiv:2107.00362v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Piciarelli_C/0/1/0/all/0/1">Claudio Piciarelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Foresti_G/0/1/0/all/0/1">Gian Luca Foresti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00362">
                                    <div class="article-summary-box-inner">
                                        <span>Swarms of drones are being more and more used in many practical scenarios,
such as surveillance, environmental monitoring, search and rescue in
hardly-accessible areas, etc.. While a single drone can be guided by a human
operator, the deployment of a swarm of multiple drones requires proper
algorithms for automatic task-oriented control. In this paper, we focus on
visual coverage optimization with drone-mounted camera sensors. In particular,
we consider the specific case in which the coverage requirements are uneven,
meaning that different parts of the environment have different coverage
priorities. We model these coverage requirements with relevance maps and
propose a deep reinforcement learning algorithm to guide the swarm. The paper
first defines a proper learning model for a single drone, and then extends it
to the case of multiple drones both with greedy and cooperative strategies.
Experimental results show the performance of the proposed method, also compared
with a standard patrolling algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?. (arXiv:2107.00166v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1">Minghai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00166">
                                    <div class="article-summary-box-inner">
                                        <span>There have been long-standing controversies and inconsistencies over the
experiment setup and criteria for identifying the &quot;winning ticket&quot; in
literature. To reconcile such, we revisit the definition of lottery ticket
hypothesis, with comprehensive and more rigorous conditions. Under our new
definition, we show concrete evidence to clarify whether the winning ticket
exists across the major DNN architectures and/or applications. Through
extensive experiments, we perform quantitative analysis on the correlations
between winning tickets and various experimental factors, and empirically study
the patterns of our observations. We find that the key training
hyperparameters, such as learning rate and training epochs, as well as the
architecture characteristics such as capacities and residual connections, are
all highly correlated with whether and when the winning tickets can be
identified. Based on our analysis, we summarize a guideline for parameter
settings in regards of specific architecture characteristics, which we hope to
catalyze the research progress on the topic of lottery ticket hypothesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Model Drift Estimation with Batch Normalization Statistics for Dataset Shift Detection and Model Selection. (arXiv:2107.00191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wonju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_S/0/1/0/all/0/1">Seok-Yong Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jooeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Minje Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechil_K/0/1/0/all/0/1">Kirill Chechil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00191">
                                    <div class="article-summary-box-inner">
                                        <span>While many real-world data streams imply that they change frequently in a
nonstationary way, most of deep learning methods optimize neural networks on
training data, and this leads to severe performance degradation when dataset
shift happens. However, it is less possible to annotate or inspect newly
streamed data by humans, and thus it is desired to measure model drift at
inference time in an unsupervised manner. In this paper, we propose a novel
method of model drift estimation by exploiting statistics of batch
normalization layer on unlabeled test data. To remedy possible sampling error
of streamed input data, we adopt low-rank approximation to each
representational layer. We show the effectiveness of our method not only on
dataset shift detection but also on model selection when there are multiple
candidate models among model zoo or training trajectories in an unsupervised
way. We further demonstrate the consistency of our method by comparing model
drift scores between different network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaXpert: Adapting Neural Architecture for Growing Data. (arXiv:2107.00254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1">Shuaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiaxiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guanghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00254">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world applications, data often come in a growing manner, where the
data volume and the number of classes may increase dynamically. This will bring
a critical challenge for learning: given the increasing data volume or the
number of classes, one has to instantaneously adjust the neural model capacity
to obtain promising performance. Existing methods either ignore the growing
nature of data or seek to independently search an optimal architecture for a
given dataset, and thus are incapable of promptly adjusting the architectures
for the changed data. To address this, we present a neural architecture
adaptation method, namely Adaptation eXpert (AdaXpert), to efficiently adjust
previous architectures on the growing data. Specifically, we introduce an
architecture adjuster to generate a suitable architecture for each data
snapshot, based on the previous architecture and the different extent between
current and previous data distributions. Furthermore, we propose an adaptation
condition to determine the necessity of adjustment, thereby avoiding
unnecessary and time-consuming adjustments. Extensive experiments on two growth
scenarios (increasing data volume and number of classes) demonstrate the
effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Hierarchical Super-Resolution for Scientific Data Reduction and Visualization. (arXiv:2107.00462v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wurster_S/0/1/0/all/0/1">Skylar W. Wurster</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_H/0/1/0/all/0/1">Han-Wei Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_H/0/1/0/all/0/1">Hanqi Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Peterka_T/0/1/0/all/0/1">Thomas Peterka</a>, <a href="http://arxiv.org/find/eess/1/au:+Raj_M/0/1/0/all/0/1">Mukund Raj</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jiayi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00462">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for hierarchical super resolution (SR) using neural
networks on an octree data representation. We train a hierarchy of neural
networks, each capable of 2x upscaling in each spatial dimension between two
levels of detail, and use these networks in tandem to facilitate large scale
factor super resolution, scaling with the number of trained networks. We
utilize these networks in a hierarchical super resolution algorithm that
upscales multiresolution data to a uniform high resolution without introducing
seam artifacts on octree node boundaries. We evaluate application of this
algorithm in a data reduction framework by dynamically downscaling input data
to an octree-based data structure to represent the multiresolution data before
compressing for additional storage reduction. We demonstrate that our approach
avoids seam artifacts common to multiresolution data formats, and show how
neural network super resolution assisted data reduction can preserve global
features better than compressors alone at the same compression ratios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PoliTO-IIT Submission to the EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition. (arXiv:2107.00337v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Plizzari_C/0/1/0/all/0/1">Chiara Plizzari</a>, <a href="http://arxiv.org/find/cs/1/au:+Planamente_M/0/1/0/all/0/1">Mirco Planamente</a>, <a href="http://arxiv.org/find/cs/1/au:+Alberti_E/0/1/0/all/0/1">Emanuele Alberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1">Barbara Caputo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00337">
                                    <div class="article-summary-box-inner">
                                        <span>In this report, we describe the technical details of our submission to the
EPIC-Kitchens-100 Unsupervised Domain Adaptation (UDA) Challenge in Action
Recognition. To tackle the domain-shift which exists under the UDA setting, we
first exploited a recent Domain Generalization (DG) technique, called Relative
Norm Alignment (RNA). It consists in designing a model able to generalize well
to any unseen domain, regardless of the possibility to access target data at
training time. Then, in a second phase, we extended the approach to work on
unlabelled target data, allowing the model to adapt to the target distribution
in an unsupervised fashion. For this purpose, we included in our framework
existing UDA algorithms, such as Temporal Attentive Adversarial Adaptation
Network (TA3N), jointly with new multi-stream consistency losses, namely
Temporal Hard Norm Alignment (T-HNA) and Min-Entropy Consistency (MEC). Our
submission (entry &#x27;plnet&#x27;) is visible on the leaderboard and it achieved the
1st position for &#x27;verb&#x27;, and the 3rd position for both &#x27;noun&#x27; and &#x27;action&#x27;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Task Adaptation for Cross-domain Few-shot Learning. (arXiv:2107.00358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei-Hong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xialei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1">Hakan Bilen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00358">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we look at the problem of cross-domain few-shot classification
that aims to learn a classifier from previously unseen classes and domains with
few labeled samples. We study several strategies including various adapter
topologies and operations in terms of their performance and efficiency that can
be easily attached to existing methods with different meta-training strategies
and adapt them for a given task during meta-test phase. We show that parametric
adapters attached to convolutional layers with residual connections performs
the best, and significantly improves the performance of the state-of-the-art
models in the Meta-Dataset benchmark with minor additional cost. Our code will
be available at https://github.com/VICO-UoE/URL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CBNetV2: A Composite Backbone Network Architecture for Object Detection. (arXiv:2107.00420v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1">Tingting Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiaojie Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yudong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongtao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1">Wei Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibing Ling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00420">
                                    <div class="article-summary-box-inner">
                                        <span>Modern top-performing object detectors depend heavily on backbone networks,
whose advances bring consistent performance gains through exploring more
effective network structures. However, designing or searching for a new
backbone and pre-training it on ImageNet may require a large number of
computational resources, making it costly to obtain better detection
performance. In this paper, we propose a novel backbone network, namely
CBNetV2, by constructing compositions of existing open-sourced pre-trained
backbones. In particular, CBNetV2 architecture groups multiple identical
backbones, which are connected through composite connections. We also propose a
better training strategy with the Assistant Supervision for CBNet-based
detectors. Without additional pre-training, CBNetV2 can be integrated into
mainstream detectors, including one-stage and two-stage detectors, as well as
anchor-based and anchor-free-based ones, and significantly improve their
performance by more than 3.0% AP over the baseline on COCO. Also, experiments
provide strong evidence showing that composite backbones are more efficient and
resource-friendly than pre-trained wider and deeper networks, including
manual-based and NAS-based, as well as CNN-based and Transformer-based ones.
Particularly, with single-model and single-scale testing, our HTC Dual-Swin-B
achieves 58.6% box AP and 51.1% mask AP on COCO test-dev, which is
significantly better than the state-of-the-art result (i.e., 57.7% box AP and
50.2% mask AP) achieved by a stronger baseline HTC++ with a larger backbone
Swin-L. Code will be released at https://github.com/VDIGPKU/CBNetV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E-DSSR: Efficient Dynamic Surgical Scene Reconstruction with Transformer-based Stereoscopic Depth Perception. (arXiv:2107.00229v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yonghao Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhaoshuo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yee_C/0/1/0/all/0/1">Chi Hang Yee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_C/0/1/0/all/0/1">Chi Fai Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_R/0/1/0/all/0/1">Russell H. Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Unberath_M/0/1/0/all/0/1">Mathias Unberath</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1">Qi Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00229">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstructing the scene of robotic surgery from the stereo endoscopic video
is an important and promising topic in surgical data science, which potentially
supports many applications such as surgical visual perception, robotic surgery
education and intra-operative context awareness. However, current methods are
mostly restricted to reconstructing static anatomy assuming no tissue
deformation, tool occlusion and de-occlusion, and camera movement. However,
these assumptions are not always satisfied in minimal invasive robotic
surgeries. In this work, we present an efficient reconstruction pipeline for
highly dynamic surgical scenes that runs at 28 fps. Specifically, we design a
transformer-based stereoscopic depth perception for efficient depth estimation
and a light-weight tool segmentor to handle tool occlusion. After that, a
dynamic reconstruction algorithm which can estimate the tissue deformation and
camera movement, and aggregate the information over time is proposed for
surgical scene reconstruction. We evaluate the proposed pipeline on two
datasets, the public Hamlyn Centre Endoscopic Video Dataset and our in-house
DaVinci robotic surgery dataset. The results demonstrate that our method can
recover the scene obstructed by the surgical tool and handle the movement of
camera in realistic surgical scenarios effectively at real-time speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthonormal Product Quantization Network for Scalable Face Image Retrieval. (arXiv:2107.00327v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhe_X/0/1/0/all/0/1">Xuefei Zhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hong Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00327">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep hashing with Hamming distance metric has drawn increasing
attention for face image retrieval tasks. However, its counterpart deep
quantization methods, which learn binary code representations with
dictionary-related distance metrics, have seldom been explored for the task.
This paper makes the first attempt to integrate product quantization into an
end-to-end deep learning framework for face image retrieval. Unlike prior deep
quantization methods where the codewords for quantization are learned from
data, we propose a novel scheme using predefined orthonormal vectors as
codewords, which aims to enhance the quantization informativeness and reduce
the codewords&#x27; redundancy. To make the most of the discriminative information,
we design a tailored loss function that maximizes the identity discriminability
in each quantization subspace for both the quantized and the original features.
Furthermore, an entropy-based regularization term is imposed to reduce the
quantization error. We conduct experiments on three commonly-used datasets
under the settings of both single-domain and cross-domain retrieval. It shows
that the proposed method outperforms all the compared deep hashing/quantization
methods under both settings with significant superiority. The proposed
codewords scheme consistently improves both regular model performance and model
generalization ability, verifying the importance of codewords&#x27; distribution for
the quantization quality. Besides, our model&#x27;s better generalization ability
than deep hashing models indicates that it is more suitable for scalable face
image retrieval tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmenting 3D Hybrid Scenes via Zero-Shot Learning. (arXiv:2107.00430v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhanyi Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00430">
                                    <div class="article-summary-box-inner">
                                        <span>This work is to tackle the problem of point cloud semantic segmentation for
3D hybrid scenes under the framework of zero-shot learning. Here by hybrid, we
mean the scene consists of both seen-class and unseen-class 3D objects, a more
general and realistic setting in application. To our knowledge, this problem
has not been explored in the literature. To this end, we propose a network to
synthesize point features for various classes of objects by leveraging the
semantic features of both seen and unseen object classes, called PFNet. The
proposed PFNet employs a GAN architecture to synthesize point features, where
the semantic relationship between seen-class and unseen-class features is
consolidated by adapting a new semantic regularizer, and the synthesized
features are used to train a classifier for predicting the labels of the
testing 3D scene points. Besides we also introduce two benchmarks for
algorithmic evaluation by re-organizing the public S3DIS and ScanNet datasets
under six different data splits. Experimental results on the two benchmarks
validate our proposed method, and we hope our introduced two benchmarks and
methodology could be of help for more research on this new direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple Training Strategies and Model Scaling for Object Detection. (arXiv:2107.00057v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xianzhi Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1">Barret Zoph</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_W/0/1/0/all/0/1">Wei-Chih Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tsung-Yi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00057">
                                    <div class="article-summary-box-inner">
                                        <span>The speed-accuracy Pareto curve of object detection systems have advanced
through a combination of better model architectures, training and inference
methods. In this paper, we methodically evaluate a variety of these techniques
to understand where most of the improvements in modern detection systems come
from. We benchmark these improvements on the vanilla ResNet-FPN backbone with
RetinaNet and RCNN detectors. The vanilla detectors are improved by 7.7% in
accuracy while being 30% faster in speed. We further provide simple scaling
strategies to generate family of models that form two Pareto curves, named
RetinaNet-RS and Cascade RCNN-RS. These simple rescaled detectors explore the
speed-accuracy trade-off between the one-stage RetinaNet detectors and
two-stage RCNN detectors. Our largest Cascade RCNN-RS models achieve 52.9% AP
with a ResNet152-FPN backbone and 53.6% with a SpineNet143L backbone. Finally,
we show the ResNet architecture, with three minor architectural changes,
outperforms EfficientNet as the backbone for object detection and instance
segmentation systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_L/0/1/0/all/0/1">Lu Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00197">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to train a strong classifier using limited
labeled examples. Many existing works take the meta-learning approach, sampling
few-shot tasks in turn and optimizing the few-shot learner&#x27;s performance on
classifying the query examples. In this paper, we point out two potential
weaknesses of this approach. First, the sampled query examples may not provide
sufficient supervision for the few-shot learner. Second, the effectiveness of
meta-learning diminishes sharply with increasing shots (i.e., the number of
training examples per class). To resolve these issues, we propose a novel
objective to directly train the few-shot learner to perform like a strong
classifier. Concretely, we associate each sampled few-shot task with a strong
classifier, which is learned with ample labeled examples. The strong classifier
has a better generalization ability and we use it to supervise the few-shot
learner. We present an efficient way to construct the strong classifier, making
our proposed objective an easily plug-and-play term to existing meta-learning
based FSL methods. We validate our approach in combinations with many
representative meta-learning methods. On several benchmark datasets including
miniImageNet and tiredImageNet, our approach leads to a notable improvement
across a variety of tasks. More importantly, with our approach, meta-learning
based FSL methods can consistently outperform non-meta-learning based ones,
even in a many-shot setting, greatly strengthening their applicability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circuit Complexity of Visual Search. (arXiv:2107.00223v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uchizawa_K/0/1/0/all/0/1">Kei Uchizawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_H/0/1/0/all/0/1">Haruki Abe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00223">
                                    <div class="article-summary-box-inner">
                                        <span>We study computational hardness of feature and conjunction search through the
lens of circuit complexity. Let $x &#x3D; (x_1, ... , x_n)$ (resp., $y &#x3D; (y_1, ... ,
y_n)$) be Boolean variables each of which takes the value one if and only if a
neuron at place $i$ detects a feature (resp., another feature). We then simply
formulate the feature and conjunction search as Boolean functions ${\rm
FTR}_n(x) &#x3D; \bigvee_{i&#x3D;1}^n x_i$ and ${\rm CONJ}_n(x, y) &#x3D; \bigvee_{i&#x3D;1}^n x_i
\wedge y_i$, respectively. We employ a threshold circuit or a discretized
circuit (such as a sigmoid circuit or a ReLU circuit with discretization) as
our models of neural networks, and consider the following four computational
resources: [i] the number of neurons (size), [ii] the number of levels (depth),
[iii] the number of active neurons outputting non-zero values (energy), and
[iv] synaptic weight resolution (weight).

We first prove that any threshold circuit $C$ of size $s$, depth $d$, energy
$e$ and weight $w$ satisfies $\log rk(M_C) \le ed (\log s + \log w + \log n)$,
where $rk(M_C)$ is the rank of the communication matrix $M_C$ of a
$2n$-variable Boolean function that $C$ computes. Since ${\rm CONJ}_n$ has rank
$2^n$, we have $n \le ed (\log s + \log w + \log n)$. Thus, an exponential
lower bound on the size of even sublinear-depth threshold circuits exists if
the energy and weight are sufficiently small. Since ${\rm FTR}_n$ is computable
independently of $n$, our result suggests that computational capacity for the
feature and conjunction search are different. We also show that the inequality
is tight up to a constant factor if $ed &#x3D; o(n/ \log n)$. We next show that a
similar inequality holds for any discretized circuit. Thus, if we regard the
number of gates outputting non-zero values as a measure for sparse activity,
our results suggest that larger depth helps neural networks to acquire sparse
activity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Egocentric Image Captioning for Privacy-Preserved Passive Dietary Intake Monitoring. (arXiv:2107.00372v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_F/0/1/0/all/0/1">Frank P.-W. Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1">Xiao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jobarteh_M/0/1/0/all/0/1">Modou L. Jobarteh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1">Wenyan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Baranowski_T/0/1/0/all/0/1">Tom Baranowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_Asiedu_M/0/1/0/all/0/1">Matilda Steiner-Asiedu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_A/0/1/0/all/0/1">Alex K. Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+McCrory_M/0/1/0/all/0/1">Megan A McCrory</a>, <a href="http://arxiv.org/find/cs/1/au:+Sazonov_E/0/1/0/all/0/1">Edward Sazonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mingui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Frost_G/0/1/0/all/0/1">Gary Frost</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_B/0/1/0/all/0/1">Benny Lo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00372">
                                    <div class="article-summary-box-inner">
                                        <span>Camera-based passive dietary intake monitoring is able to continuously
capture the eating episodes of a subject, recording rich visual information,
such as the type and volume of food being consumed, as well as the eating
behaviours of the subject. However, there currently is no method that is able
to incorporate these visual clues and provide a comprehensive context of
dietary intake from passive recording (e.g., is the subject sharing food with
others, what food the subject is eating, and how much food is left in the
bowl). On the other hand, privacy is a major concern while egocentric wearable
cameras are used for capturing. In this paper, we propose a privacy-preserved
secure solution (i.e., egocentric image captioning) for dietary assessment with
passive monitoring, which unifies food recognition, volume estimation, and
scene understanding. By converting images into rich text descriptions,
nutritionists can assess individual dietary intake based on the captions
instead of the original images, reducing the risk of privacy leakage from
images. To this end, an egocentric dietary image captioning dataset has been
built, which consists of in-the-wild images captured by head-worn and
chest-worn cameras in field studies in Ghana. A novel transformer-based
architecture is designed to caption egocentric dietary images. Comprehensive
experiments have been conducted to evaluate the effectiveness and to justify
the design of the proposed architecture for egocentric dietary image
captioning. To the best of our knowledge, this is the first work that applies
image captioning to dietary intake assessment in real life settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Graph-Based Deep Learning for Computational Histopathology. (arXiv:2107.00272v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmedt_Aristizabal_D/0/1/0/all/0/1">David Ahmedt-Aristizabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Armin_M/0/1/0/all/0/1">Mohammad Ali Armin</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersson_L/0/1/0/all/0/1">Lars Petersson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00272">
                                    <div class="article-summary-box-inner">
                                        <span>With the remarkable success of representation learning for prediction
problems, we have witnessed a rapid expansion of the use of machine learning
and deep learning for the analysis of digital pathology and biopsy image
patches. However, traditional learning over patch-wise features using
convolutional neural networks limits the model when attempting to capture
global contextual information. The phenotypical and topological distribution of
constituent histological entities play a critical role in tissue diagnosis. As
such, graph data representations and deep learning have attracted significant
attention for encoding tissue representations, and capturing intra- and inter-
entity level interactions. In this review, we provide a conceptual grounding of
graph-based deep learning and discuss its current success for tumor
localization and classification, tumor invasion and staging, image retrieval,
and survival prediction. We provide an overview of these methods in a
systematic manner organized by the graph representation of the input image
including whole slide images and tissue microarrays. We also outline the
limitations of existing techniques, and suggest potential future advances in
this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLDA: Contrastive Learning for Semi-Supervised Domain Adaptation. (arXiv:2107.00085v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Ankit Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00085">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) aims to align the labeled source
distribution with the unlabeled target distribution to obtain domain invariant
predictive models. However, the application of well-known UDA approaches does
not generalize well in Semi-Supervised Domain Adaptation (SSDA) scenarios where
few labeled samples from the target domain are available. In this paper, we
propose a simple Contrastive Learning framework for semi-supervised Domain
Adaptation (CLDA) that attempts to bridge the intra-domain gap between the
labeled and unlabeled target distributions and inter-domain gap between source
and unlabeled target distribution in SSDA. We suggest employing class-wise
contrastive learning to reduce the inter-domain gap and instance-level
contrastive alignment between the original (input image) and strongly augmented
unlabeled target images to minimize the intra-domain discrepancy. We have shown
empirically that both of these modules complement each other to achieve
superior performance. Experiments on three well-known domain adaptation
benchmark datasets namely DomainNet, Office-Home, and Office31 demonstrate the
effectiveness of our approach. CLDA achieves state-of-the-art results on all
the above datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extraction of Key-frames of Endoscopic Videos by using Depth Information. (arXiv:2107.00005v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sasmal_P/0/1/0/all/0/1">Pradipta Sasmal</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Avinash Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhuyan_M/0/1/0/all/0/1">M.K. Bhuyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwahori_Y/0/1/0/all/0/1">Yuji Iwahori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00005">
                                    <div class="article-summary-box-inner">
                                        <span>A deep learning-based monocular depth estimation (MDE) technique is proposed
for selection of most informative frames (key frames) of an endoscopic video.
In most of the cases, ground truth depth maps of polyps are not readily
available and that is why the transfer learning approach is adopted in our
method. An endoscopic modalities generally capture thousands of frames. In this
scenario, it is quite important to discard low-quality and clinically
irrelevant frames of an endoscopic video while the most informative frames
should be retained for clinical diagnosis. In this view, a key-frame selection
strategy is proposed by utilizing the depth information of polyps. In our
method, image moment, edge magnitude, and key-points are considered for
adaptively selecting the key frames. One important application of our proposed
method could be the 3D reconstruction of polyps with the help of extracted key
frames. Also, polyps are localized with the help of extracted depth maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Detection and Diagnosis of Diabetic Retinopathy: A Comprehensive Survey. (arXiv:2107.00115v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lakshminarayanan_V/0/1/0/all/0/1">Vasudevan Lakshminarayanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kherdfallah_H/0/1/0/all/0/1">Hoda Kherdfallah</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarkar_A/0/1/0/all/0/1">Arya Sarkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Balaji_J/0/1/0/all/0/1">J. Jothi Balaji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00115">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetic Retinopathy (DR) is a leading cause of vision loss in the world,. In
the past few Diabetic Retinopathy (DR) is a leading cause of vision loss in the
world. In the past few years, Artificial Intelligence (AI) based approaches
have been used to detect and grade DR. Early detection enables appropriate
treatment and thus prevents vision loss, Both fundus and optical coherence
tomography (OCT) images are used to image the retina. With deep
learning/machine learning apprroaches it is possible to extract features from
the images and detect the presence of DR. Multiple strategies are implemented
to detect and grade the presence of DR using classification, segmentation, and
hybrid techniques. This review covers the literature dealing with AI approaches
to DR that have been published in the open literature over a five year span
(2016-2021). In addition a comprehensive list of available DR datasets is
reported. Both the PICO (P-patient, I-intervention, C-control O-outcome) and
Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA)2009
search strategies were employed. We summarize a total of 114 published articles
which conformed to the scope of the review. In addition a list of 43 major
datasets is presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep auxiliary learning for visual localization using colorization task. (arXiv:2107.00222v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_M/0/1/0/all/0/1">Mi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Q/0/1/0/all/0/1">Qiong Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Hao Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xiahua Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00222">
                                    <div class="article-summary-box-inner">
                                        <span>Visual localization is one of the most important components for robotics and
autonomous driving. Recently, inspiring results have been shown with CNN-based
methods which provide a direct formulation to end-to-end regress 6-DoF absolute
pose. Additional information like geometric or semantic constraints is
generally introduced to improve performance. Especially, the latter can
aggregate high-level semantic information into localization task, but it
usually requires enormous manual annotations. To this end, we propose a novel
auxiliary learning strategy for camera localization by introducing
scene-specific high-level semantics from self-supervised representation
learning task. Viewed as a powerful proxy task, image colorization task is
chosen as complementary task that outputs pixel-wise color version of grayscale
photograph without extra annotations. In our work, feature representations from
colorization network are embedded into localization network by design to
produce discriminative features for pose regression. Meanwhile an attention
mechanism is introduced for the benefit of localization performance. Extensive
experiments show that our model significantly improve localization accuracy
over state-of-the-arts on both indoor and outdoor datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-class Steel Detector Using Patch GAN Discriminator for Visualising Anomalous Feature Map. (arXiv:2107.00143v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yasuno_T/0/1/0/all/0/1">Takato Yasuno</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujii_J/0/1/0/all/0/1">Junichiro Fujii</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukami_S/0/1/0/all/0/1">Sakura Fukami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00143">
                                    <div class="article-summary-box-inner">
                                        <span>For steel product manufacturing in indoor factories, steel defect detection
is important for quality control. For example, a steel sheet is extremely
delicate, and must be accurately inspected. However, to maintain the painted
steel parts of the infrastructure around a severe outdoor environment,
corrosion detection is critical for predictive maintenance. In this paper, we
propose a general-purpose application for steel anomaly detection that consists
of the following four components. The first, a learner, is a unit image
classification network to determine whether the region of interest or
background has been recognised, after dividing the original large sized image
into 256 square unit images. The second, an extractor, is a discriminator
feature encoder based on a pre-trained steel generator with a patch generative
adversarial network discriminator(GAN). The third, an anomaly detector, is a
one-class support vector machine(SVM) to predict the anomaly score using the
discriminator feature. The fourth, an indicator, is an anomalous probability
map used to visually explain the anomalous features. Furthermore, we
demonstrated our method through the inspection of steel sheet defects with
13,774 unit images using high-speed cameras, and painted steel corrosion with
19,766 unit images based on an eye inspection of the photographs. Finally, we
visualise anomalous feature maps of steel using a strip and painted steel
inspection dataset</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MASS: Multi-Attentional Semantic Segmentation of LiDAR Data for Dense Top-View Understanding. (arXiv:2107.00346v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_J/0/1/0/all/0/1">Juncong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roitberg_A/0/1/0/all/0/1">Alina Roitberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bieder_F/0/1/0/all/0/1">Frank Bieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidenreich_P/0/1/0/all/0/1">Philipp Heidenreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiller_C/0/1/0/all/0/1">Christoph Stiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00346">
                                    <div class="article-summary-box-inner">
                                        <span>At the heart of all automated driving systems is the ability to sense the
surroundings, e.g., through semantic segmentation of LiDAR sequences, which
experienced a remarkable progress due to the release of large datasets such as
SemanticKITTI and nuScenes-LidarSeg. While most previous works focus on sparse
segmentation of the LiDAR input, dense output masks provide self-driving cars
with almost complete environment information. In this paper, we introduce MASS
- a Multi-Attentional Semantic Segmentation model specifically built for dense
top-view understanding of the driving scenes. Our framework operates on pillar-
and occupancy features and comprises three attention-based building blocks: (1)
a keypoint-driven graph attention, (2) an LSTM-based attention computed from a
vector embedding of the spatial input, and (3) a pillar-based attention,
resulting in a dense 360-degree segmentation mask. With extensive experiments
on both, SemanticKITTI and nuScenes-LidarSeg, we quantitatively demonstrate the
effectiveness of our model, outperforming the state of the art by 19.0% on
SemanticKITTI and reaching 32.7% in mIoU on nuScenes-LidarSeg, where MASS is
the first work addressing the dense segmentation task. Furthermore, our
multi-attention model is shown to be very effective for 3D object detection
validated on the KITTI-3D dataset, showcasing its high generalizability to
other tasks related to 3D vision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Synthetic Training Data for Deep Learning-Based UAV Trajectory Prediction. (arXiv:2107.00422v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1">Stefan Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Hug_R/0/1/0/all/0/1">Ronny Hug</a>, <a href="http://arxiv.org/find/cs/1/au:+Hubner_W/0/1/0/all/0/1">Wolfgang H&#xfc;bner</a>, <a href="http://arxiv.org/find/cs/1/au:+Arens_M/0/1/0/all/0/1">Michael Arens</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_B/0/1/0/all/0/1">Brendan T. Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00422">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based models, such as recurrent neural networks (RNNs), have
been applied to various sequence learning tasks with great success. Following
this, these models are increasingly replacing classic approaches in object
tracking applications for motion prediction. On the one hand, these models can
capture complex object dynamics with less modeling required, but on the other
hand, they depend on a large amount of training data for parameter tuning.
Towards this end, we present an approach for generating synthetic trajectory
data of unmanned-aerial-vehicles (UAVs) in image space. Since UAVs, or rather
quadrotors are dynamical systems, they can not follow arbitrary trajectories.
With the prerequisite that UAV trajectories fulfill a smoothness criterion
corresponding to a minimal change of higher-order motion, methods for planning
aggressive quadrotors flights can be utilized to generate optimal trajectories
through a sequence of 3D waypoints. By projecting these maneuver trajectories,
which are suitable for controlling quadrotors, to image space, a versatile
trajectory data set is realized. To demonstrate the applicability of the
synthetic trajectory data, we show that an RNN-based prediction model solely
trained on the generated data can outperform classic reference models on a
real-world UAV tracking dataset. The evaluation is done on the publicly
available ANTI-UAV dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedding-based Recommender System for Job to Candidate Matching on Scale. (arXiv:2107.00221v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jing Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingya Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigdel_M/0/1/0/all/0/1">Madhav Sigdel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bopeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_P/0/1/0/all/0/1">Phuong Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mengshu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Korayem_M/0/1/0/all/0/1">Mohammed Korayem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00221">
                                    <div class="article-summary-box-inner">
                                        <span>The online recruitment matching system has been the core technology and
service platform in CareerBuilder. One of the major challenges in an online
recruitment scenario is to provide good matches between job posts and
candidates using a recommender system on the scale. In this paper, we discussed
the techniques for applying an embedding-based recommender system for the large
scale of job to candidates matching. To learn the comprehensive and effective
embedding for job posts and candidates, we have constructed a fused-embedding
via different levels of representation learning from raw text, semantic
entities and location information. The clusters of fused-embedding of job and
candidates are then used to build and train the Faiss index that supports
runtime approximate nearest neighbor search for candidate retrieval. After the
first stage of candidate retrieval, a second stage reranking model that
utilizes other contextual information was used to generate the final matching
result. Both offline and online evaluation results indicate a significant
improvement of our proposed two-staged embedding-based system in terms of
click-through rate (CTR), quality and normalized discounted accumulated gain
(nDCG), compared to those obtained from our baseline system. We further
described the deployment of the system that supports the million-scale job and
candidate matching process at CareerBuilder. The overall improvement of our job
to candidate matching system has demonstrated its feasibility and scalability
at a major online recruitment site.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proof of Reference(PoR): A unified informetrics based consensus mechanism. (arXiv:2107.00214v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khurana_P/0/1/0/all/0/1">Parul Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesan_G/0/1/0/all/0/1">Geetha Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gulshan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1">Kiran Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00214">
                                    <div class="article-summary-box-inner">
                                        <span>Bibliometrics is useful to analyze the research impact for measuring the
research quality. Different bibliographic databases like Scopus, Web of
Science, Google Scholar etc. are accessed for evaluating the trend of
publications and citations from time to time. Some of these databases are free
and some are subscription based. Its always debatable that which bibliographic
database is better and in what terms. To provide an optimal solution to
availability of multiple bibliographic databases, we have implemented a single
authentic database named as &#x60;&#x60;conflate&#x27;&#x27; which can be used for fetching
publication and citation trend of an author. To further strengthen the
generated database and to provide the transparent system to the stakeholders, a
consensus mechanism &#x60;&#x60;proof of reference (PoR)&#x27;&#x27; is proposed. Due to three
consent based checks implemented in PoR, we feel that it could be considered as
a authentic and honest citation data source for the calculation of unified
informetrics for an author.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SearchGCN: Powering Embedding Retrieval by Graph Convolution Networks for E-Commerce Search. (arXiv:2107.00525v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xinlin Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Songlin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Sulong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1">Bo Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wen-Yun Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00525">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolution networks (GCN), which recently becomes new state-of-the-art
method for graph node classification, recommendation and other applications,
has not been successfully applied to industrial-scale search engine yet. In
this proposal, we introduce our approach, namely SearchGCN, for embedding-based
candidate retrieval in one of the largest e-commerce search engine in the
world. Empirical studies demonstrate that SearchGCN learns better embedding
representations than existing methods, especially for long tail queries and
items. Thus, SearchGCN has been deployed into JD.com&#x27;s search production since
July 2020.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphHINGE: Learning Interaction Models of Structured Neighborhood on Heterogeneous Information Network. (arXiv:2011.12683v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiarui Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_K/0/1/0/all/0/1">Kounianhua Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jiarui Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuchen Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12683">
                                    <div class="article-summary-box-inner">
                                        <span>Heterogeneous information network (HIN) has been widely used to characterize
entities of various types and their complex relations. Recent attempts either
rely on explicit path reachability to leverage path-based semantic relatedness
or graph neighborhood to learn heterogeneous network representations before
predictions. These weakly coupled manners overlook the rich interactions among
neighbor nodes, which introduces an early summarization issue. In this paper,
we propose GraphHINGE (Heterogeneous INteract and aggreGatE), which captures
and aggregates the interactive patterns between each pair of nodes through
their structured neighborhoods. Specifically, we first introduce
Neighborhood-based Interaction (NI) module to model the interactive patterns
under the same metapaths, and then extend it to Cross Neighborhood-based
Interaction (CNI) module to deal with different metapaths. Next, in order to
address the complexity issue on large-scale networks, we formulate the
interaction modules via a convolutional framework and learn the parameters
efficiently with fast Fourier transform. Furthermore, we design a novel
neighborhood-based selection (NS) mechanism, a sampling strategy, to filter
high-order neighborhood information based on their low-order performance. The
extensive experiments on six different types of heterogeneous graphs
demonstrate the performance gains by comparing with state-of-the-arts in both
click-through rate prediction and top-N recommendation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pseudo-Relevance Feedback for Multiple Representation Dense Retrieval. (arXiv:2106.11251v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonellotto_N/0/1/0/all/0/1">Nicola Tonellotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11251">
                                    <div class="article-summary-box-inner">
                                        <span>Pseudo-relevance feedback mechanisms, from Rocchio to the relevance models,
have shown the usefulness of expanding and reweighting the users&#x27; initial
queries using information occurring in an initial set of retrieved documents,
known as the pseudo-relevant set. Recently, dense retrieval -- through the use
of neural contextual language models such as BERT for analysing the documents&#x27;
and queries&#x27; contents and computing their relevance scores -- has shown a
promising performance on several information retrieval tasks still relying on
the traditional inverted index for identifying documents relevant to a query.
Two different dense retrieval families have emerged: the use of single embedded
representations for each passage and query (e.g. using BERT&#x27;s [CLS] token), or
via multiple representations (e.g. using an embedding for each token of the
query and document). In this work, we conduct the first study into the
potential for multiple representation dense retrieval to be enhanced using
pseudo-relevance feedback. In particular, based on the pseudo-relevant set of
documents identified using a first-pass dense retrieval, we extract
representative feedback embeddings (using KMeans clustering) -- while ensuring
that these embeddings discriminate among passages (based on IDF) -- which are
then added to the query representation. These additional feedback embeddings
are shown to both enhance the effectiveness of a reranking as well as an
additional dense retrieval operation. Indeed, experiments on the MSMARCO
passage ranking dataset show that MAP can be improved by upto 26% on the TREC
2019 query set and 10% on the TREC 2020 query set by the application of our
proposed ColBERT-PRF method on a ColBERT dense retrieval approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tweet Sentiment Quantification: An Experimental Re-Evaluation. (arXiv:2011.08091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1">Fabrizio Sebastiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08091">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment quantification is the task of estimating the relative frequency (or
&quot;prevalence&quot;) of sentiment-related classes (such as Positive, Neutral,
Negative) in a sample of unlabelled texts; this is especially important when
these texts are tweets, since most sentiment classification endeavours carried
out on Twitter data actually have quantification (and not the classification of
individual tweets) as their ultimate goal. It is well-known that solving
quantification via &quot;classify and count&quot; (i.e., by classifying all unlabelled
items via a standard classifier and counting the items that have been assigned
to a given class) is suboptimal in terms of accuracy, and that more accurate
quantification methods exist. In 2016, Gao and Sebastiani carried out a
systematic comparison of quantification methods on the task of tweet sentiment
quantification. In hindsight, we observe that the experimental protocol
followed in that work is flawed, and that its results are thus unreliable. We
now re-evaluate those quantification methods on the very same datasets, this
time following a now consolidated and much more robust experimental protocol,
that involves 5775 as many experiments as run in the original study. Our
experimentation yields results dramatically different from those obtained by
Gao and Sebastiani, and thus provide a different, much more solid understanding
of the relative strengths and weaknesses of different sentiment quantification
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Search Engine for Scientific Publications: a Cybersecurity Case Study. (arXiv:2107.00082v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oliveira_N/0/1/0/all/0/1">Nuno Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Sousa_N/0/1/0/all/0/1">Norberto Sousa</a>, <a href="http://arxiv.org/find/cs/1/au:+Praca_I/0/1/0/all/0/1">Isabel Pra&#xe7;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00082">
                                    <div class="article-summary-box-inner">
                                        <span>Cybersecurity is a very challenging topic of research nowadays, as
digitalization increases the interaction of people, software and services on
the Internet by means of technology devices and networks connected to it. The
field is broad and has a lot of unexplored ground under numerous disciplines
such as management, psychology, and data science. Its large disciplinary
spectrum and many significant research topics generate a considerable amount of
information, making it hard for us to find what we are looking for when
researching a particular subject. This work proposes a new search engine for
scientific publications which combines both information retrieval and reading
comprehension algorithms to extract answers from a collection of
domain-specific documents. The proposed solution although being applied to the
context of cybersecurity exhibited great generalization capabilities and can be
easily adapted to perform under other distinct knowledge domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Use of Bandit Algorithms in Intelligent Interactive Recommender Systems. (arXiv:2107.00161v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00161">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s business marketplace, many high-tech Internet enterprises
constantly explore innovative ways to provide optimal online user experiences
for gaining competitive advantages. The great needs of developing intelligent
interactive recommendation systems are indicated, which could sequentially
suggest users the most proper items by accurately predicting their preferences,
while receiving the up-to-date feedback to refine the recommendation results,
continuously. Multi-armed bandit algorithms, which have been widely applied
into various online systems, are quite capable of delivering such efficient
recommendation services. However, few existing bandit models are able to adapt
to new changes introduced by the modern recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disrupting Model Training with Adversarial Shortcuts. (arXiv:2106.06654v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1">Ivan Evtimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Covert_I/0/1/0/all/0/1">Ian Covert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1">Tadayoshi Kohno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06654">
                                    <div class="article-summary-box-inner">
                                        <span>When data is publicly released for human consumption, it is unclear how to
prevent its unauthorized usage for machine learning purposes. Successful model
training may be preventable with carefully designed dataset modifications, and
we present a proof-of-concept approach for the image classification setting. We
propose methods based on the notion of adversarial shortcuts, which encourage
models to rely on non-robust signals rather than semantic features, and our
experiments demonstrate that these measures successfully prevent deep learning
models from achieving high accuracy on real, unmodified data examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-term Cross Adversarial Training: A Robust Meta-learning Method for Few-shot Classification Tasks. (arXiv:2106.12900v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xuelong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12900">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning model can quickly adapt to new tasks using few-shot labeled
data. However, despite achieving good generalization on few-shot classification
tasks, it is still challenging to improve the adversarial robustness of the
meta-learning model in few-shot learning. Although adversarial training (AT)
methods such as Adversarial Query (AQ) can improve the adversarially robust
performance of meta-learning models, AT is still computationally expensive
training. On the other hand, meta-learning models trained with AT will drop
significant accuracy on the original clean images. This paper proposed a
meta-learning method on the adversarially robust neural network called
Long-term Cross Adversarial Training (LCAT). LCAT will update meta-learning
model parameters cross along the natural and adversarial sample distribution
direction with long-term to improve both adversarial and clean few-shot
classification accuracy. Due to cross-adversarial training, LCAT only needs
half of the adversarial training epoch than AQ, resulting in a low adversarial
training computation. Experiment results show that LCAT achieves superior
performance both on the clean and adversarial few-shot classification accuracy
than SOTA adversarial training methods for meta-learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Lingual Adaptation for Type Inference. (arXiv:2107.00157v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiaofei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhengzi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00157">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based techniques have been widely applied to the program
analysis tasks, in fields such as type inference, fault localization, and code
summarization. Hitherto deep learning-based software engineering systems rely
thoroughly on supervised learning approaches, which require laborious manual
effort to collect and label a prohibitively large amount of data. However, most
Turing-complete imperative languages share similar control- and data-flow
structures, which make it possible to transfer knowledge learned from one
language to another. In this paper, we propose cross-lingual adaptation of
program analysis, which allows us to leverage prior knowledge learned from the
labeled dataset of one language and transfer it to the others. Specifically, we
implemented a cross-lingual adaptation framework, PLATO, to transfer a deep
learning-based type inference procedure across weakly typed languages, e.g.,
Python to JavaScript and vice versa. PLATO incorporates a novel joint graph
kernelized attention based on abstract syntax tree and control flow graph, and
applies anchor word augmentation across different languages. Besides, by
leveraging data from strongly typed languages, PLATO improves the perplexity of
the backbone cross-programming-language model and the performance of downstream
cross-lingual transfer for type inference. Experimental results illustrate that
our framework significantly improves the transferability over the baseline
method by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multimodal VAEs through Mutual Supervision. (arXiv:2106.12570v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joy_T/0/1/0/all/0/1">Tom Joy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuge Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmon_S/0/1/0/all/0/1">Sebastian M. Schmon</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddharth_N/0/1/0/all/0/1">N. Siddharth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12570">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal VAEs seek to model the joint distribution over heterogeneous data
(e.g.\ vision, language), whilst also capturing a shared representation across
such modalities. Prior work has typically combined information from the
modalities by reconciling idiosyncratic representations directly in the
recognition model through explicit products, mixtures, or other such
factorisations. Here we introduce a novel alternative, the MEME, that avoids
such explicit combinations by repurposing semi-supervised VAEs to combine
information between modalities implicitly through mutual supervision. This
formulation naturally allows learning from partially-observed data where some
modalities can be entirely missing -- something that most existing approaches
either cannot handle, or do so to a limited extent. We demonstrate that MEME
outperforms baselines on standard metrics across both partial and complete
observation schemes on the MNIST-SVHN (image-image) and CUB (image-text)
datasets. We also contrast the quality of the representations learnt by mutual
supervision against standard approaches and observe interesting trends in its
ability to capture relatedness between data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fea2Fea: Exploring Structural Feature Correlations via Graph Neural Networks. (arXiv:2106.13061v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jiaqing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1">Rex Ying</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13061">
                                    <div class="article-summary-box-inner">
                                        <span>Structural features are important features in graph datasets. However,
although there are some correlation analysis of features based on covariance,
there is no relevant research on exploring structural feature correlation on
graphs with graph neural network based models. In this paper, we introduce
graph feature to feature (Fea2Fea) prediction pipelines in a low dimensional
space to explore some preliminary results on structural feature correlation,
which is based on graph neural network. The results show that there exists high
correlation between some of the structural features. A redundant feature
combination with initial node features, which is filtered by graph neural
network has improved its classification accuracy in some graph datasets. We
compare the difference between concatenation methods on connecting embeddings
between features and show that the simplest is the best. We generalize on the
synthetic geometric graphs and certify the results on prediction difficulty
between two structural features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSUL: Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning. (arXiv:2106.11562v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Sungmin Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Beomyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">Youngjoon Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11562">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a class-incremental semantic segmentation (CISS) problem. While
some recently proposed algorithms utilized variants of knowledge distillation
(KD) technique to tackle the problem, they only partially addressed the key
additional challenges in CISS that causes the catastrophic forgetting; i.e.,
the semantic drift of the background class and multi-label prediction issue. To
better address these challenges, we propose a new method, dubbed as SSUL-M
(Semantic Segmentation with Unknown Label with Memory), by carefully combining
several techniques tailored for semantic segmentation. More specifically, we
make three main contributions; (1) modeling unknown class within the background
class to help learning future classes (help plasticity), (2) freezing backbone
network and past classifiers with binary cross-entropy loss and pseudo-labeling
to overcome catastrophic forgetting (help stability), and (3) utilizing tiny
exemplar memory for the first time in CISS to improve both plasticity and
stability. As a result, we show our method achieves significantly better
performance than the recent state-of-the-art baselines on the standard
benchmark datasets. Furthermore, we justify our contributions with thorough and
extensive ablation analyses and discuss different natures of the CISS problem
compared to the standard class-incremental learning for classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POSNoise: An Effective Countermeasure Against Topic Biases in Authorship Analysis. (arXiv:2005.06605v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halvani_O/0/1/0/all/0/1">Oren Halvani</a>, <a href="http://arxiv.org/find/cs/1/au:+Graner_L/0/1/0/all/0/1">Lukas Graner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06605">
                                    <div class="article-summary-box-inner">
                                        <span>Authorship verification (AV) is a fundamental research task in digital text
forensics, which addresses the problem of whether two texts were written by the
same person. In recent years, a variety of AV methods have been proposed that
focus on this problem and can be divided into two categories: The first
category refers to such methods that are based on explicitly defined features,
where one has full control over which features are considered and what they
actually represent. The second category, on the other hand, relates to such AV
methods that are based on implicitly defined features, where no control
mechanism is involved, so that any character sequence in a text can serve as a
potential feature. However, AV methods belonging to the second category bear
the risk that the topic of the texts may bias their classification predictions,
which in turn may lead to misleading conclusions regarding their results. To
tackle this problem, we propose a preprocessing technique called POSNoise,
which effectively masks topic-related content in a given text. In this way, AV
methods are forced to focus on such text units that are more related to the
writing style. Our empirical evaluation based on six AV methods (falling into
the second category) and seven corpora shows that POSNoise leads to better
results compared to a well-known topic masking approach in 34 out of 42 cases,
with an increase in accuracy of up to 10%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial Transformers. (arXiv:2103.01209v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1">Drew A. Hudson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnick_C/0/1/0/all/0/1">C. Lawrence Zitnick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01209">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the GANformer, a novel and efficient type of transformer, and
explore it for the task of visual generative modeling. The network employs a
bipartite structure that enables long-range interactions across the image,
while maintaining computation of linear efficiency, that can readily scale to
high-resolution synthesis. It iteratively propagates information from a set of
latent variables to the evolving visual features and vice versa, to support the
refinement of each in light of the other and encourage the emergence of
compositional representations of objects and scenes. In contrast to the classic
transformer architecture, it utilizes multiplicative integration that allows
flexible region-based modulation, and can thus be seen as a generalization of
the successful StyleGAN network. We demonstrate the model&#x27;s strength and
robustness through a careful evaluation over a range of datasets, from
simulated multi-object environments to rich real-world indoor and outdoor
scenes, showing it achieves state-of-the-art results in terms of image quality
and diversity, while enjoying fast learning and better data-efficiency. Further
qualitative and quantitative experiments offer us an insight into the model&#x27;s
inner workings, revealing improved interpretability and stronger
disentanglement, and illustrating the benefits and efficacy of our approach. An
implementation of the model is available at
https://github.com/dorarad/gansformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional independence for pretext task selection in Self-supervised speech representation learning. (arXiv:2104.07388v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1">Salah Zaiem</a>, <a href="http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1">Slim Essid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07388">
                                    <div class="article-summary-box-inner">
                                        <span>Through solving pretext tasks, self-supervised learning (SSL) leverages
unlabeled data to extract useful latent representations replacing traditional
input features in the downstream task. A common pretext task consists in
pretraining a SSL model on pseudo-labels derived from the original signal. This
technique is particularly relevant for speech data where various meaningful
signal processing features may serve as pseudo-labels. However, the process of
selecting pseudo-labels, for speech or other types of data, remains mostly
unexplored and currently relies on observing the results on the final
downstream task. Nevertheless, this methodology is not sustainable at scale due
to substantial computational (hence carbon) costs. Thus, this paper introduces
a practical and theoretical framework to select relevant pseudo-labels with
respect to a given downstream task. More precisely, we propose a functional
estimator of the pseudo-label utility grounded in the conditional independence
theory, which does not require any training. The experiments conducted on
speaker recognition and automatic speech recognition validate our estimator,
showing a significant correlation between the performance observed on the
downstream task and the utility estimates obtained with our approach,
facilitating the prospection of relevant pseudo-labels for self-supervised
speech representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Feature Space: A Geometrical Perspective. (arXiv:2007.00062v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kansizoglou_I/0/1/0/all/0/1">Ioannis Kansizoglou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bampis_L/0/1/0/all/0/1">Loukas Bampis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasteratos_A/0/1/0/all/0/1">Antonios Gasteratos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00062">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most prominent attributes of Neural Networks (NNs) constitutes
their capability of learning to extract robust and descriptive features from
high dimensional data, like images. Hence, such an ability renders their
exploitation as feature extractors particularly frequent in an abundant of
modern reasoning systems. Their application scope mainly includes complex
cascade tasks, like multi-modal recognition and deep Reinforcement Learning
(RL). However, NNs induce implicit biases that are difficult to avoid or to
deal with and are not met in traditional image descriptors. Moreover, the lack
of knowledge for describing the intra-layer properties -- and thus their
general behavior -- restricts the further applicability of the extracted
features. With the paper at hand, a novel way of visualizing and understanding
the vector space before the NNs&#x27; output layer is presented, aiming to enlighten
the deep feature vectors&#x27; properties under classification tasks. Main attention
is paid to the nature of overfitting in the feature space and its adverse
effect on further exploitation. We present the findings that can be derived
from our model&#x27;s formulation, and we evaluate them on realistic recognition
scenarios, proving its prominence by improving the obtained results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Self Supervised Learning: the BT, the HSIC, and the VICReg. (arXiv:2105.12247v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1">Sayan Nag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12247">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning and pre-training strategies have developed over the
last few years especially for Convolutional Neural Networks (CNNs). Recently
application of such methods can also be noticed for Graph Neural Networks
(GNNs) . In this paper, we have used a graph based self-supervised learning
strategy with different loss functions (Barlow Twins[Zbontar et al., 2021],
HSIC[Tsai et al., 2021], VICReg[Bardes et al., 2021]) which have shown
promising results when applied with CNNs previously. We have also proposed a
hybrid loss function combining the advantages of VICReg and HSIC and called it
as VICRegHSIC. The performance of these aforementioned methods have been
compared when applied to different datasets such as MUTAG, PROTEINS and
IMDB-Binary. Moreover, the impact of different batch sizes, projector
dimensions and data augmentation strategies have also been explored</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random Hyperboxes. (arXiv:2006.00695v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khuat_T/0/1/0/all/0/1">Thanh Tung Khuat</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabrys_B/0/1/0/all/0/1">Bogdan Gabrys</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.00695">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a simple yet powerful ensemble classifier, called Random
Hyperboxes, constructed from individual hyperbox-based classifiers trained on
the random subsets of sample and feature spaces of the training set. We also
show a generalization error bound of the proposed classifier based on the
strength of the individual hyperbox-based classifiers as well as the
correlation among them. The effectiveness of the proposed classifier is
analyzed using a carefully selected illustrative example and compared
empirically with other popular single and ensemble classifiers via 20 datasets
using statistical testing methods. The experimental results confirmed that our
proposed method outperformed other fuzzy min-max neural networks, popular
learning algorithms, and is competitive with other ensemble methods. Finally,
we identify the existing issues related to the generalization error bounds of
the real datasets and inform the potential research directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning How to Search: Generating Effective Test Cases Through Adaptive Fitness Function Selection. (arXiv:2102.04822v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Almulla_H/0/1/0/all/0/1">Hussein Almulla</a>, <a href="http://arxiv.org/find/cs/1/au:+Gay_G/0/1/0/all/0/1">Gregory Gay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04822">
                                    <div class="article-summary-box-inner">
                                        <span>Search-based test generation is guided by feedback from one or more fitness
functions -- scoring functions that judge solution optimality. Choosing
informative fitness functions is crucial to meeting the goals of a tester.
Unfortunately, many goals - such as forcing the class-under-test to throw
exceptions, increasing test suite diversity, and attaining Strong Mutation
Coverage - do not have effective fitness function formulations. We propose that
meeting such goals requires treating fitness function identification as a
secondary optimization step. An adaptive algorithm that can vary the selection
of fitness functions could adjust its selection throughout the generation
process to maximize goal attainment, based on the current population of test
suites. To test this hypothesis, we have implemented two reinforcement learning
algorithms in the EvoSuite unit test generation framework, and used these
algorithms to dynamically set the fitness functions used during generation for
the three goals identified above.

We have evaluated our framework, EvoSuiteFIT, on a set of Java case examples.
EvoSuiteFIT techniques attain significant improvements for two of the three
goals, and show limited improvements on the third when the number of
generations of evolution is fixed. Additionally, for two of the three goals,
EvoSuiteFIT detects faults missed by the other techniques. The ability to
adjust fitness functions allows strategic choices that efficiently produce more
effective test suites, and examining these choices offers insight into how to
attain our testing goals. We find that adaptive fitness function selection is a
powerful technique to apply when an effective fitness function does not already
exist for achieving a testing goal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Color Variants Identification in Fashion e-commerce via Contrastive Self-Supervised Representation Learning. (arXiv:2104.08581v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_U/0/1/0/all/0/1">Ujjal Kr Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Repakula_S/0/1/0/all/0/1">Sandeep Repakula</a>, <a href="http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1">Maulik Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravi_A/0/1/0/all/0/1">Abhinav Ravi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08581">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we utilize deep visual Representation Learning to address an
important problem in fashion e-commerce: color variants identification, i.e.,
identifying fashion products that match exactly in their design (or style), but
only to differ in their color. At first we attempt to tackle the problem by
obtaining manual annotations (depicting whether two products are color
variants), and train a supervised triplet loss based neural network model to
learn representations of fashion products. However, for large scale real-world
industrial datasets such as addressed in our paper, it is infeasible to obtain
annotations for the entire dataset, while capturing all the difficult corner
cases. Interestingly, we observed that color variants are essentially
manifestations of color jitter based augmentations. Thus, we instead explore
Self-Supervised Learning (SSL) to solve this problem. We observed that existing
state-of-the-art SSL methods perform poor, for our problem. To address this, we
propose a novel SSL based color variants model that simultaneously focuses on
different parts of an apparel. Quantitative and qualitative evaluation shows
that our method outperforms existing SSL methods, and at times, the supervised
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Interpretable Convolutional Neural Networks by Differentiating Class-specific Filters. (arXiv:2007.08194v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Haoyu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_Z/0/1/0/all/0/1">Zhihao Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yuyuan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zihao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08194">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been successfully used in a range
of tasks. However, CNNs are often viewed as &quot;black-box&quot; and lack of
interpretability. One main reason is due to the filter-class entanglement -- an
intricate many-to-many correspondence between filters and classes. Most
existing works attempt post-hoc interpretation on a pre-trained model, while
neglecting to reduce the entanglement underlying the model. In contrast, we
focus on alleviating filter-class entanglement during training. Inspired by
cellular differentiation, we propose a novel strategy to train interpretable
CNNs by encouraging class-specific filters, among which each filter responds to
only one (or few) class. Concretely, we design a learnable sparse
Class-Specific Gate (CSG) structure to assign each filter with one (or few)
class in a flexible way. The gate allows a filter&#x27;s activation to pass only
when the input samples come from the specific class. Extensive experiments
demonstrate the fabulous performance of our method in generating a sparse and
highly class-related representation of the input, which leads to stronger
interpretability. Moreover, comparing with the standard training strategy, our
model displays benefits in applications like object localization and
adversarial sample detection. Code link: https://github.com/hyliang96/CSGCNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Physical Layer Communications. (arXiv:2106.11595v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mary_P/0/1/0/all/0/1">Philippe Mary</a>, <a href="http://arxiv.org/find/cs/1/au:+Koivunen_V/0/1/0/all/0/1">Visa Koivunen</a>, <a href="http://arxiv.org/find/cs/1/au:+Moy_C/0/1/0/all/0/1">Christophe Moy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11595">
                                    <div class="article-summary-box-inner">
                                        <span>In this chapter, we will give comprehensive examples of applying RL in
optimizing the physical layer of wireless communications by defining different
class of problems and the possible solutions to handle them. In Section 9.2, we
present all the basic theory needed to address a RL problem, i.e. Markov
decision process (MDP), Partially observable Markov decision process (POMDP),
but also two very important and widely used algorithms for RL, i.e. the
Q-learning and SARSA algorithms. We also introduce the deep reinforcement
learning (DRL) paradigm and the section ends with an introduction to the
multi-armed bandits (MAB) framework. Section 9.3 focuses on some toy examples
to illustrate how the basic concepts of RL are employed in communication
systems. We present applications extracted from literature with simplified
system models using similar notation as in Section 9.2 of this Chapter. In
Section 9.3, we also focus on modeling RL problems, i.e. how action and state
spaces and rewards are chosen. The Chapter is concluded in Section 9.4 with a
prospective thought on RL trends and it ends with a review of a broader state
of the art in Section 9.5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic persistent homology via density-based metric learning. (arXiv:2012.07621v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Borghini_E/0/1/0/all/0/1">Eugenio Borghini</a>, <a href="http://arxiv.org/find/stat/1/au:+Fernandez_X/0/1/0/all/0/1">Ximena Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/stat/1/au:+Groisman_P/0/1/0/all/0/1">Pablo Groisman</a>, <a href="http://arxiv.org/find/stat/1/au:+Mindlin_G/0/1/0/all/0/1">Gabriel Mindlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07621">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of estimating intrinsic distances in a manifold from a
finite sample. We prove that the metric space defined by the sample endowed
with a computable metric known as sample Fermat distance converges a.s. in the
sense of Gromov-Hausdorff. The limiting object is the manifold itself endowed
with the population Fermat distance, an intrinsic metric that accounts for both
the geometry of the manifold and the density that produces the sample. This
result is applied to obtain intrinsic persistence diagrams, which are less
sensitive to the particular embedding of the manifold in the Euclidean space.
We show that this approach is robust to outliers and deduce a method for
pattern recognition in signals, with applications in real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupled Exploration and Exploitation Policies for Sample-Efficient Reinforcement Learning. (arXiv:2101.09458v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1">William F. Whitney</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloesch_M/0/1/0/all/0/1">Michael Bloesch</a>, <a href="http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1">Jost Tobias Springenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1">Abbas Abdolmaleki</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1">Martin Riedmiller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09458">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the close connection between exploration and sample efficiency, most
state of the art reinforcement learning algorithms include no considerations
for exploration beyond maximizing the entropy of the policy. In this work we
address this seeming missed opportunity. We observe that the most common
formulation of directed exploration in deep RL, known as bonus-based
exploration (BBE), suffers from bias and slow coverage in the few-sample
regime. This causes BBE to be actively detrimental to policy learning in many
control tasks. We show that by decoupling the task policy from the exploration
policy, directed exploration can be highly effective for sample-efficient
continuous control. Our method, Decoupled Exploration and Exploitation Policies
(DEEP), can be combined with any off-policy RL algorithm without modification.
When used in conjunction with soft actor-critic, DEEP incurs no performance
penalty in densely-rewarding environments. On sparse environments, DEEP gives a
several-fold improvement in data efficiency due to better exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A general approach for Explanations in terms of Middle Level Features. (arXiv:2106.05037v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Apicella_A/0/1/0/all/0/1">Andrea Apicella</a>, <a href="http://arxiv.org/find/cs/1/au:+Isgro_F/0/1/0/all/0/1">Francesco Isgr&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Prevete_R/0/1/0/all/0/1">Roberto Prevete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05037">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, it is growing interest to make Machine Learning (ML) systems more
understandable and trusting to general users. Thus, generating explanations for
ML system behaviours that are understandable to human beings is a central
scientific and technological issue addressed by the rapidly growing research
area of eXplainable Artificial Intelligence (XAI). Recently, it is becoming
more and more evident that new directions to create better explanations should
take into account what a good explanation is to a human user, and consequently,
develop XAI solutions able to provide user-centred explanations. This paper
suggests taking advantage of developing an XAI general approach that allows
producing explanations for an ML system behaviour in terms of different and
user-selected input features, i.e., explanations composed of input properties
that the human user can select according to his background knowledge and goals.
To this end, we propose an XAI general approach which is able: 1) to construct
explanations in terms of input features that represent more salient and
understandable input properties for a user, which we call here Middle-Level
input Features (MLFs), 2) to be applied to different types of MLFs. We
experimentally tested our approach on two different datasets and using three
different types of MLFs. The results seem encouraging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning deep autoregressive models for hierarchical data. (arXiv:2104.13853v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andersson_C/0/1/0/all/0/1">Carl R. Andersson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wahlstrom_N/0/1/0/all/0/1">Niklas Wahlstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Thomas B. Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13853">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a model for hierarchical structured data as an extension to the
stochastic temporal convolutional network. The proposed model combines an
autoregressive model with a hierarchical variational autoencoder and
downsampling to achieve superior computational complexity. We evaluate the
proposed model on two different types of sequential data: speech and
handwritten text. The results are promising with the proposed model achieving
state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Transformer: A Self-Attention Model for Short-Time Human Action Recognition. (arXiv:2107.00606v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Angarano_S/0/1/0/all/0/1">Simone Angarano</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1">Francesco Salvetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Angelini_F/0/1/0/all/0/1">Federico Angelini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00606">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks based purely on attention have been successful across
several domains, relying on minimal architectural priors from the designer. In
Human Action Recognition (HAR), attention mechanisms have been primarily
adopted on top of standard convolutional or recurrent layers, improving the
overall generalization capability. In this work, we introduce Action
Transformer (AcT), a simple, fully self-attentional architecture that
consistently outperforms more elaborated networks that mix convolutional,
recurrent, and attentive layers. In order to limit computational and energy
requests, building on previous human action recognition research, the proposed
approach exploits 2D pose representations over small temporal windows,
providing a low latency solution for accurate and effective real-time
performance. Moreover, we open-source MPOSE2021, a new large-scale dataset, as
an attempt to build a formal training and evaluation benchmark for real-time
short-time human action recognition. Extensive experimentation on MPOSE2021
with our proposed methodology and several previous architectural solutions
proves the effectiveness of the AcT model and poses the base for future work on
HAR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attribute Selection using Contranominal Scales. (arXiv:2106.10978v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Durrschnabel_D/0/1/0/all/0/1">Dominik D&#xfc;rrschnabel</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyda_M/0/1/0/all/0/1">Maren Koyda</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumme_G/0/1/0/all/0/1">Gerd Stumme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10978">
                                    <div class="article-summary-box-inner">
                                        <span>Formal Concept Analysis (FCA) allows to analyze binary data by deriving
concepts and ordering them in lattices. One of the main goals of FCA is to
enable humans to comprehend the information that is encapsulated in the data;
however, the large size of concept lattices is a limiting factor for the
feasibility of understanding the underlying structural properties. The size of
such a lattice depends on the number of subcontexts in the corresponding formal
context that are isomorphic to a contranominal scale of high dimension. In this
work, we propose the algorithm ContraFinder that enables the computation of all
contranominal scales of a given formal context. Leveraging this algorithm, we
introduce delta-adjusting, a novel approach in order to decrease the number of
contranominal scales in a formal context by the selection of an appropriate
attribute subset. We demonstrate that delta-adjusting a context reduces the
size of the hereby emerging sub-semilattice and that the implication set is
restricted to meaningful implications. This is evaluated with respect to its
associated knowledge by means of a classification task. Hence, our proposed
technique strongly improves understandability while preserving important
conceptual structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification of COVID-19 related Fake News via Neural Stacking. (arXiv:2101.03988v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koloski_B/0/1/0/all/0/1">Boshko Koloski</a>, <a href="http://arxiv.org/find/cs/1/au:+Perdih_T/0/1/0/all/0/1">Timen Stepi&#x161;nik Perdih</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollak_S/0/1/0/all/0/1">Senja Pollak</a>, <a href="http://arxiv.org/find/cs/1/au:+Skrlj_B/0/1/0/all/0/1">Bla&#x17e; &#x160;krlj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03988">
                                    <div class="article-summary-box-inner">
                                        <span>Identification of Fake News plays a prominent role in the ongoing pandemic,
impacting multiple aspects of day-to-day life. In this work we present a
solution to the shared task titled COVID19 Fake News Detection in English,
scoring the 50th place amongst 168 submissions. The solution was within 1.5% of
the best performing solution. The proposed solution employs a heterogeneous
representation ensemble, adapted for the classification task via an additional
neural classification head comprised of multiple hidden layers. The paper
consists of detailed ablation studies further displaying the proposed method&#x27;s
behavior and possible implications. The solution is freely available.
\url{https://gitlab.com/boshko.koloski/covid19-fake-news}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v12 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Siyang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Harding_S/0/1/0/all/0/1">Seth Austin Harding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haibin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shih-wei Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03479">
                                    <div class="article-summary-box-inner">
                                        <span>Many complex multi-robot systems such as robot swarms control and autonomous
vehicle coordination can be modeled as Multi-Agent Reinforcement Learning
(MARL) tasks. QMIX, a widely popular MARL algorithm, has been used as a
baseline for the benchmark environments, e.g., Starcraft Multi-Agent Challenge
(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX
target relaxing the monotonicity constraint of QMIX, allowing for performance
improvement in SMAC. In this paper, we investigate the code-level optimizations
of these variants and the monotonicity constraint. (1) We find that such
improvements of the variants are significantly affected by various code-level
optimizations. (2) The experiment results show that QMIX with normalized
optimizations outperforms other works in SMAC; (3) beyond the common wisdom
from these works, the monotonicity constraint can improve sample efficiency in
SMAC and DEPP. We also discuss why monotonicity constraints work well in purely
cooperative tasks with a theoretical analysis. We open-source the code at
\url{https://github.com/hijkzzz/pymarl2}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Geometry and Classical Cram\&#x27;{e}r-Rao Type Inequalities. (arXiv:2104.01061v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_K/0/1/0/all/0/1">Kumar Vijay Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">M. Ashok Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01061">
                                    <div class="article-summary-box-inner">
                                        <span>We examine the role of information geometry in the context of classical
Cram\&#x27;er-Rao (CR) type inequalities. In particular, we focus on Eguchi&#x27;s theory
of obtaining dualistic geometric structures from a divergence function and then
applying Amari-Nagoaka&#x27;s theory to obtain a CR type inequality. The classical
deterministic CR inequality is derived from Kullback-Leibler (KL)-divergence.
We show that this framework could be generalized to other CR type inequalities
through four examples: $\alpha$-version of CR inequality, generalized CR
inequality, Bayesian CR inequality, and Bayesian $\alpha$-CR inequality. These
are obtained from, respectively, $I_\alpha$-divergence (or relative
$\alpha$-entropy), generalized Csisz\&#x27;ar divergence, Bayesian KL divergence,
and Bayesian $I_\alpha$-divergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Batch Learning in High-Dimensional Sparse Linear Contextual Bandits. (arXiv:2008.11918v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ren_Z/0/1/0/all/0/1">Zhimei Ren</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11918">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of dynamic batch learning in high-dimensional sparse
linear contextual bandits, where a decision maker can only adapt decisions at a
batch level. In particular, the decision maker, only observing rewards at the
end of each batch, dynamically decides how many individuals to include in the
next batch (at the current batch&#x27;s end) and what personalized action-selection
scheme to adopt within the batch. Such batch constraints are ubiquitous in a
variety of practical contexts, including personalized product offerings in
marketing and medical treatment selection in clinical trials. We characterize
the fundamental learning limit in this problem via a novel lower bound analysis
and provide a simple, exploration-free algorithm that uses the LASSO estimator,
which achieves the minimax optimal performance characterized by the lower bound
(up to log factors). To our best knowledge, our work provides the first inroad
into a rigorous understanding of dynamic batch learning with high-dimensional
covariates. We also demonstrate the efficacy of our algorithm on both synthetic
data and the Warfarin medical dosing data. The empirical results show that with
three batches (hence only two opportunities to adapt), our algorithm already
performs comparably (in terms of statistical performance) to the
state-of-the-art fully online high-dimensional linear contextual bandits
algorithm. As an added bonus, since our algorithm operates in batches, it is
orders of magnitudes faster than fully online learning algorithms. As such, our
algorithm provides a desirable candidate for practical data-driven personalized
decision making problems, where limited adaptivity is often a hard constraint.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Tight Communication Lower Bounds for Distributed Optimisation. (arXiv:2010.08222v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_J/0/1/0/all/0/1">Janne H. Korhonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08222">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a standard distributed optimisation setting where $N$ machines,
each holding a $d$-dimensional function $f_i$, aim to jointly minimise the sum
of the functions $\sum_{i &#x3D; 1}^N f_i (x)$. This problem arises naturally in
large-scale distributed optimisation, where a standard solution is to apply
variants of (stochastic) gradient descent. We focus on the communication
complexity of this problem: our main result provides the first fully
unconditional bounds on total number of bits which need to be sent and received
by the $N$ machines to solve this problem under point-to-point communication,
within a given error-tolerance. Specifically, we show that $\Omega( Nd \log d /
N\varepsilon)$ total bits need to be communicated between the machines to find
an additive $\epsilon$-approximation to the minimum of $\sum_{i &#x3D; 1}^N f_i
(x)$. The result holds for both deterministic and randomised algorithms, and,
importantly, requires no assumptions on the algorithm structure. The lower
bound is tight under certain restrictions on parameter values, and is matched
within constant factors for quadratic objectives by a new variant of quantised
gradient descent, which we describe and analyse. Our results bring over tools
from communication complexity to distributed optimisation, which has potential
for further applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A first look into the carbon footprint of federated learning. (arXiv:2102.07627v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xinchi Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Marques_J/0/1/0/all/0/1">Javier Fernandez-Marques</a>, <a href="http://arxiv.org/find/cs/1/au:+Gusmao_P/0/1/0/all/0/1">Pedro Porto Buarque de Gusmao</a>, <a href="http://arxiv.org/find/cs/1/au:+Beutel_D/0/1/0/all/0/1">Daniel J. Beutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Topal_T/0/1/0/all/0/1">Taner Topal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathur_A/0/1/0/all/0/1">Akhil Mathur</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas D. Lane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07627">
                                    <div class="article-summary-box-inner">
                                        <span>Despite impressive results, deep learning-based technologies also raise
severe privacy and environmental concerns induced by the training procedure
often conducted in datacenters. In response, alternatives to centralized
training such as Federated Learning (FL) have emerged. Perhaps unexpectedly,
FL, in particular, is starting to be deployed at a global scale by companies
that must adhere to new legal demands and policies originating from governments
and civil society for privacy protection. However, the potential environmental
impact related to FL remains unclear and unexplored. This paper offers the
first-ever systematic study of the carbon footprint of FL. First, we propose a
rigorous model to quantify the carbon footprint, hence facilitating the
investigation of the relationship between FL design and carbon emissions. Then,
we compare the carbon footprint of FL to traditional centralized learning. Our
findings show that FL, despite being slower to converge in some cases, may
result in a comparatively greener impact than a centralized equivalent setup.
We performed extensive experiments across different types of datasets,
settings, and various deep learning models with FL. Finally, we highlight and
connect the reported results to the future challenges and trends in FL to
reduce its environmental impact, including algorithms efficiency, hardware
capabilities, and stronger industry transparency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Distributed Learning for Crisis Management. (arXiv:2104.12876v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Priyanshu_A/0/1/0/all/0/1">Aman Priyanshu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_M/0/1/0/all/0/1">Mudit Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1">Shreyans Mehta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12876">
                                    <div class="article-summary-box-inner">
                                        <span>Social media platforms such as Twitter, Facebook etc can be utilised as an
important source of information during disaster events. This information can be
used for disaster response and crisis management if processed accurately and
quickly. However, the data present in such situations is ever-changing, and
using considerable resources during such a crisis is not feasible. Therefore,
we have to develop a low resource and continually learning system that
incorporates text classification models which are robust against noisy and
unordered data. We utilised Distributed learning which enabled us to learn on
resource-constrained devices, then to alleviate catastrophic forgetting in our
target neural networks we utilized regularization. We then applied federated
averaging for distributed learning and to aggregate the central model for
continual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable and Adaptive Graph Neural Networks with Self-Label-Enhanced training. (arXiv:2104.09376v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chuxiong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_H/0/1/0/all/0/1">Hongming Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jie Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09376">
                                    <div class="article-summary-box-inner">
                                        <span>It is hard to directly implement Graph Neural Networks (GNNs) on large scaled
graphs. Besides of existed neighbor sampling techniques, scalable methods
decoupling graph convolutions and other learnable transformations into
preprocessing and post classifier allow normal minibatch training. By replacing
redundant concatenation operation with attention mechanism in SIGN, we propose
Scalable and Adaptive Graph Neural Networks (SAGN). SAGN can adaptively gather
neighborhood information among different hops. To further improve scalable
models on semi-supervised learning tasks, we propose Self-Label-Enhance (SLE)
framework combining self-training approach and label propagation in depth. We
add base model with a scalable node label module. Then we iteratively train
models and enhance train set in several stages. To generate input of node label
module, we directly apply label propagation based on one-hot encoded label
vectors without inner random masking. We find out that empirically the label
leakage has been effectively alleviated after graph convolutions. The hard
pseudo labels in enhanced train set participate in label propagation with true
labels. Experiments on both inductive and transductive datasets demonstrate
that, compared with other sampling-based and sampling-free methods, SAGN
achieves better or comparable results and SLE can further improve performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Informed Neural Networks for Minimising Worst-Case Violations in DC Optimal Power Flow. (arXiv:2107.00465v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nellikkath_R/0/1/0/all/0/1">Rahul Nellikkath</a>, <a href="http://arxiv.org/find/eess/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1">Spyros Chatzivasileiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00465">
                                    <div class="article-summary-box-inner">
                                        <span>Physics-informed neural networks exploit the existing models of the
underlying physical systems to generate higher accuracy results with fewer
data. Such approaches can help drastically reduce the computation time and
generate a good estimate of computationally intensive processes in power
systems, such as dynamic security assessment or optimal power flow. Combined
with the extraction of worst-case guarantees for the neural network
performance, such neural networks can be applied in safety-critical
applications in power systems and build a high level of trust among power
system operators. This paper takes the first step and applies, for the first
time to our knowledge, Physics-Informed Neural Networks with Worst-Case
Guarantees for the DC Optimal Power Flow problem. We look for guarantees
related to (i) maximum constraint violations, (ii) maximum distance between
predicted and optimal decision variables, and (iii) maximum sub-optimality in
the entire input domain. In a range of PGLib-OPF networks, we demonstrate how
physics-informed neural networks can be supplied with worst-case guarantees and
how they can lead to reduced worst-case violations compared with conventional
neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lattice Fusion Networks for Image Denoising. (arXiv:2011.14196v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hosseini_S/0/1/0/all/0/1">Seyed Mohsen Hosseini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14196">
                                    <div class="article-summary-box-inner">
                                        <span>A novel method for feature fusion in convolutional neural networks is
proposed in this paper. Different feature fusion techniques are suggested to
facilitate the flow of information and improve the training of deep neural
networks. Some of these techniques as well as the proposed network can be
considered a type of Directed Acyclic Graph (DAG) Network, where a layer can
receive inputs from other layers and have outputs to other layers. In the
proposed general framework of Lattice Fusion Network (LFNet), feature maps of
each convolutional layer are passed to other layers based on a lattice graph
structure, where nodes are convolutional layers. To evaluate the performance of
the proposed architecture, different designs based on the general framework of
LFNet are implemented for the task of image denoising. This task is used as an
example where training deep convolutional networks is needed. Results are
compared with state of the art methods. The proposed network is able to achieve
better results with far fewer learnable parameters, which shows the
effectiveness of LFNets for training of deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Arindam Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayer_A/0/1/0/all/0/1">Artun Bayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1">Santiago Segarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10424">
                                    <div class="article-summary-box-inner">
                                        <span>The graph convolutional network (GCN) is a go-to solution for machine
learning on graphs, but its training is notoriously difficult to scale both in
terms of graph size and the number of model parameters. Although some work has
explored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we
pioneer efficient training of large-scale GCN models (i.e., ultra-wide,
overparameterized models) with the proposal of a novel, distributed training
framework. Our proposed training methodology, called GIST, disjointly
partitions the parameters of a GCN model into several, smaller sub-GCNs that
are trained independently and in parallel. In addition to being compatible with
any GCN architecture, GIST improves model performance, scales to training on
arbitrarily large graphs, significantly decreases wall-clock training time, and
enables the training of markedly overparameterized GCN models. Remarkably, with
GIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which
exceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on
the Amazon2M dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSWin Transformer: A General Vision Transformer Backbone with Cross-Shaped Windows. (arXiv:2107.00652v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaoyi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jianmin Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1">Baining Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00652">
                                    <div class="article-summary-box-inner">
                                        <span>We present CSWin Transformer, an efficient and effective Transformer-based
backbone for general-purpose vision tasks. A challenging issue in Transformer
design is that global self-attention is very expensive to compute whereas local
self-attention often limits the field of interactions of each token. To address
this issue, we develop the Cross-Shaped Window self-attention mechanism for
computing self-attention in the horizontal and vertical stripes in parallel
that form a cross-shaped window, with each stripe obtained by splitting the
input feature into stripes of equal width. We provide a detailed mathematical
analysis of the effect of the stripe width and vary the stripe width for
different layers of the Transformer network which achieves strong modeling
capability while limiting the computation cost. We also introduce
Locally-enhanced Positional Encoding (LePE), which handles the local positional
information better than existing encoding schemes. LePE naturally supports
arbitrary input resolutions, and is thus especially effective and friendly for
downstream tasks. Incorporated with these designs and a hierarchical structure,
CSWin Transformer demonstrates competitive performance on common vision tasks.
Specifically, it achieves 85.4% Top-1 accuracy on ImageNet-1K without any extra
training data or label, 53.9 box AP and 46.4 mask AP on the COCO detection
task, and 51.7 mIOU on the ADE20K semantic segmentation task, surpassing
previous state-of-the-art Swin Transformer backbone by +1.2, +2.0, +1.4, and
+2.0 respectively under the similar FLOPs setting. By further pretraining on
the larger dataset ImageNet-21K, we achieve 87.5% Top-1 accuracy on ImageNet-1K
and state-of-the-art segmentation performance on ADE20K with 55.2 mIoU. The
code and models will be available at
https://github.com/microsoft/CSWin-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data. (arXiv:2107.00648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braman_N/0/1/0/all/0/1">Nathaniel Braman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_J/0/1/0/all/0/1">Jacob W. H. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Goossens_E/0/1/0/all/0/1">Emery T. Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1">Caleb Willis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpe_M/0/1/0/all/0/1">Martin C. Stumpe</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_J/0/1/0/all/0/1">Jagadish Venkataraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00648">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical decision-making in oncology involves multimodal data such as
radiology scans, molecular profiling, histopathology slides, and clinical
factors. Despite the importance of these modalities individually, no deep
learning framework to date has combined them all to predict patient prognosis.
Here, we predict the overall survival (OS) of glioma patients from diverse
multimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to
combine information from multiparametric MRI exams, biopsy-based modalities
(such as H&amp;E slide images and/or DNA sequencing), and clinical variables into a
comprehensive multimodal risk score. Prognostic embeddings from each modality
are learned and combined via attention-gated tensor fusion. To maximize the
information gleaned from each modality, we introduce a multimodal
orthogonalization (MMO) loss term that increases model performance by
incentivizing constituent embeddings to be more complementary. DOF predicts OS
in glioma patients with a median C-index of 0.788 +/- 0.067, significantly
outperforming (p&#x3D;0.023) the best performing unimodal model with a median
C-index of 0.718 +/- 0.064. The prognostic model significantly stratifies
glioma patients by OS within clinical subsets, adding further granularity to
prognostic clinical grading and molecular subtyping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact Remediation: Optimal Interventions to Reduce Inequality. (arXiv:2107.00593v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bynum_L/0/1/0/all/0/1">Lucius E.J. Bynum</a>, <a href="http://arxiv.org/find/cs/1/au:+Loftus_J/0/1/0/all/0/1">Joshua R. Loftus</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanovich_J/0/1/0/all/0/1">Julia Stoyanovich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00593">
                                    <div class="article-summary-box-inner">
                                        <span>A significant body of research in the data sciences considers unfair
discrimination against social categories such as race or gender that could
occur or be amplified as a result of algorithmic decisions. Simultaneously,
real-world disparities continue to exist, even before algorithmic decisions are
made. In this work, we draw on insights from the social sciences and humanistic
studies brought into the realm of causal modeling and constrained optimization,
and develop a novel algorithmic framework for tackling pre-existing real-world
disparities. The purpose of our framework, which we call the &quot;impact
remediation framework,&quot; is to measure real-world disparities and discover the
optimal intervention policies that could help improve equity or access to
opportunity for those who are underserved with respect to an outcome of
interest. We develop a disaggregated approach to tackling pre-existing
disparities that relaxes the typical set of assumptions required for the use of
social categories in structural causal models. Our approach flexibly
incorporates counterfactuals and is compatible with various ontological
assumptions about the nature of social categories. We demonstrate impact
remediation with a real-world case study and compare our disaggregated approach
to an existing state-of-the-art approach, comparing its structure and resulting
policy recommendations. In contrast to most work on optimal policy learning, we
explore disparity reduction itself as an objective, explicitly focusing the
power of algorithms on reducing inequality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Fully Bayesian Gradient-Free Supervised Dimension Reduction Method using Gaussian Processes. (arXiv:2008.03534v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gautier_R/0/1/0/all/0/1">Raphael Gautier</a>, <a href="http://arxiv.org/find/stat/1/au:+Pandita_P/0/1/0/all/0/1">Piyush Pandita</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1">Sayan Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Mavris_D/0/1/0/all/0/1">Dimitri Mavris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03534">
                                    <div class="article-summary-box-inner">
                                        <span>Modern day engineering problems are ubiquitously characterized by
sophisticated computer codes that map parameters or inputs to an underlying
physical process. In other situations, experimental setups are used to model
the physical process in a laboratory, ensuring high precision while being
costly in materials and logistics. In both scenarios, only limited amount of
data can be generated by querying the expensive information source at a finite
number of inputs or designs. This problem is compounded further in the presence
of a high-dimensional input space. State-of-the-art parameter space dimension
reduction methods, such as active subspace, aim to identify a subspace of the
original input space that is sufficient to explain the output response. These
methods are restricted by their reliance on gradient evaluations or copious
data, making them inadequate to expensive problems without direct access to
gradients. The proposed methodology is gradient-free and fully Bayesian, as it
quantifies uncertainty in both the low-dimensional subspace and the surrogate
model parameters. This enables a full quantification of epistemic uncertainty
and robustness to limited data availability. It is validated on multiple
datasets from engineering and science and compared to two other
state-of-the-art methods based on four aspects: a) recovery of the active
subspace, b) deterministic prediction accuracy, c) probabilistic prediction
accuracy, and d) training time. The comparison shows that the proposed method
improves the active subspace recovery and predictive accuracy, in both the
deterministic and probabilistic sense, when only few model observations are
available for training, at the cost of increased training time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Particle Filters through Conditional Normalizing Flow. (arXiv:2107.00488v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Hao Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00488">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable particle filters provide a flexible mechanism to adaptively
train dynamic and measurement models by learning from observed data. However,
most existing differentiable particle filters are within the bootstrap particle
filtering framework and fail to incorporate the information from latest
observations to construct better proposals. In this paper, we utilize
conditional normalizing flows to construct proposal distributions for
differentiable particle filters, enriching the distribution families that the
proposal distributions can represent. In addition, normalizing flows are
incorporated in the construction of the dynamic model, resulting in a more
expressive dynamic model. We demonstrate the performance of the proposed
conditional normalizing flow-based differentiable particle filters in a visual
tracking task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets. (arXiv:2107.00472v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhou_B/0/1/0/all/0/1">Baojian Zhou</a>, <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yifan Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00472">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose approximate Frank-Wolfe (FW) algorithms to solve
convex optimization problems over graph-structured support sets where the
\textit{linear minimization oracle} (LMO) cannot be efficiently obtained in
general. We first demonstrate that two popular approximation assumptions
(\textit{additive} and \textit{multiplicative gap errors)}, are not valid for
our problem, in that no cheap gap-approximate LMO oracle exists in general.
Instead, a new \textit{approximate dual maximization oracle} (DMO) is proposed,
which approximates the inner product rather than the gap. When the objective is
$L$-smooth, we prove that the standard FW method using a $\delta$-approximate
DMO converges as $\mathcal{O}(L / \delta t + (1-\delta)(\delta^{-1} +
\delta^{-2}))$ in general, and as $\mathcal{O}(L/(\delta^2(t+2)))$ over a
$\delta$-relaxation of the constraint set. Additionally, when the objective is
$\mu$-strongly convex and the solution is unique, a variant of FW converges to
$\mathcal{O}(L^2\log(t)/(\mu \delta^6 t^2))$ with the same per-iteration
complexity. Our empirical results suggest that even these improved bounds are
pessimistic, with significant improvement in recovering real-world images with
graph-structured sparsity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Training with Highly Incomplete Datasets. (arXiv:2107.00429v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yu-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Natali_L/0/1/0/all/0/1">Laura Natali</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamialahmadi_O/0/1/0/all/0/1">Oveis Jamialahmadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Romeo_S/0/1/0/all/0/1">Stefano Romeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_J/0/1/0/all/0/1">Joana B. Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Volpe_G/0/1/0/all/0/1">Giovanni Volpe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00429">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network training and validation rely on the availability of large
high-quality datasets. However, in many cases only incomplete datasets are
available, particularly in health care applications, where each patient
typically undergoes different clinical procedures or can drop out of a study.
Since the data to train the neural networks need to be complete, most studies
discard the incomplete datapoints, which reduces the size of the training data,
or impute the missing features, which can lead to artefacts. Alas, both
approaches are inadequate when a large portion of the data is missing. Here, we
introduce GapNet, an alternative deep-learning training approach that can use
highly incomplete datasets. First, the dataset is split into subsets of samples
containing all values for a certain cluster of features. Then, these subsets
are used to train individual neural networks. Finally, this ensemble of neural
networks is combined into a single neural network whose training is fine-tuned
using all complete datapoints. Using two highly incomplete real-world medical
datasets, we show that GapNet improves the identification of patients with
underlying Alzheimer&#x27;s disease pathology and of patients at risk of
hospitalization due to Covid-19. By distilling the information available in
incomplete datasets without having to reduce their size or to impute missing
values, GapNet will permit to extract valuable information from a wide range of
datasets, benefiting diverse fields from medicine to engineering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dittadi_A/0/1/0/all/0/1">Andrea Dittadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Papa_S/0/1/0/all/0/1">Samuele Papa</a>, <a href="http://arxiv.org/find/cs/1/au:+Vita_M/0/1/0/all/0/1">Michele De Vita</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1">Ole Winther</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00637">
                                    <div class="article-summary-box-inner">
                                        <span>The idea behind object-centric representation learning is that natural scenes
can better be modeled as compositions of objects and their relations as opposed
to distributed representations. This inductive bias can be injected into neural
networks to potentially improve systematic generalization and learning
efficiency of downstream tasks in scenes with multiple objects. In this paper,
we train state-of-the-art unsupervised models on five common multi-object
datasets and evaluate segmentation accuracy and downstream object property
prediction. In addition, we study systematic generalization and robustness by
investigating the settings where either single objects are out-of-distribution
-- e.g., having unseen colors, textures, and shapes -- or global properties of
the scene are altered -- e.g., by occlusions, cropping, or increasing the
number of objects. From our experimental study, we find object-centric
representations to be generally useful for downstream tasks and robust to
shifts in the data distribution, especially if shifts affect single objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reparameterized Sampling for Generative Adversarial Networks. (arXiv:2107.00352v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yifei Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1">Jiansheng Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00352">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, sampling methods have been successfully applied to enhance the
sample quality of Generative Adversarial Networks (GANs). However, in practice,
they typically have poor sample efficiency because of the independent proposal
sampling from the generator. In this work, we propose REP-GAN, a novel sampling
method that allows general dependent proposals by REParameterizing the Markov
chains into the latent space of the generator. Theoretically, we show that our
reparameterized proposal admits a closed-form Metropolis-Hastings acceptance
ratio. Empirically, extensive experiments on synthetic and real datasets
demonstrate that our REP-GAN largely improves the sample efficiency and obtains
better sample quality simultaneously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning based iterative learning control for non-repetitive time-varying systems. (arXiv:2107.00421v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yiyang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiang_W/0/1/0/all/0/1">Wei Jiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Charalambous_T/0/1/0/all/0/1">Themistoklis Charalambous</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00421">
                                    <div class="article-summary-box-inner">
                                        <span>The repetitive tracking task for time-varying systems (TVSs) with
non-repetitive time-varying parameters, which is also called non-repetitive
TVSs, is realized in this paper using iterative learning control (ILC). A
machine learning (ML) based nominal model update mechanism, which utilizes the
linear regression technique to update the nominal model at each ILC trial only
using the current trial information, is proposed for non-repetitive TVSs in
order to enhance the ILC performance. Given that the ML mechanism forces the
model uncertainties to remain within the ILC robust tolerance, an ILC update
law is proposed to deal with non-repetitive TVSs. How to tune parameters inside
ML and ILC algorithms to achieve the desired aggregate performance is also
provided. The robustness and reliability of the proposed method are verified by
simulations. Comparison with current state-of-the-art demonstrates its superior
control performance in terms of controlling precision. This paper broadens ILC
applications from time-invariant systems to non-repetitive TVSs, adopts ML
regression technique to estimate non-repetitive time-varying parameters between
two ILC trials and proposes a detailed parameter tuning mechanism to achieve
desired performance, which are the main contributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Stochastic ADMM for Decentralized Reinforcement Learning in Edge Industrial IoT. (arXiv:2107.00481v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1">Wanlu Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yu Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1">Ming Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoglund_M/0/1/0/all/0/1">Mikael Skoglund</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00481">
                                    <div class="article-summary-box-inner">
                                        <span>Edge computing provides a promising paradigm to support the implementation of
Industrial Internet of Things (IIoT) by offloading tasks to nearby edge nodes.
Meanwhile, the increasing network size makes it impractical for centralized
data processing due to limited bandwidth, and consequently a decentralized
learning scheme is preferable. Reinforcement learning (RL) has been widely
investigated and shown to be a promising solution for decision-making and
optimal control processes. For RL in a decentralized setup, edge nodes (agents)
connected through a communication network aim to work collaboratively to find a
policy to optimize the global reward as the sum of local rewards. However,
communication costs, scalability and adaptation in complex environments with
heterogeneous agents may significantly limit the performance of decentralized
RL. Alternating direction method of multipliers (ADMM) has a structure that
allows for decentralized implementation, and has shown faster convergence than
gradient descent based methods. Therefore, we propose an adaptive stochastic
incremental ADMM (asI-ADMM) algorithm and apply the asI-ADMM to decentralized
RL with edge-computing-empowered IIoT networks. We provide convergence
properties for proposed algorithms by designing a Lyapunov function and prove
that the asI-ADMM has $O(\frac{1}{k}) +O(\frac{1}{M})$ convergence rate where
$k$ and $ M$ are the number of iterations and batch samples, respectively.
Then, we test our algorithm with two supervised learning problems. For
performance evaluation, we simulate two applications in decentralized RL
settings with homogeneous and heterogeneous agents. The experiment results show
that our proposed algorithms outperform the state of the art in terms of
communication costs and scalability, and can well adapt to complex IoT
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Diffusion Models. (arXiv:2107.00630v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kingma_D/0/1/0/all/0/1">Diederik P. Kingma</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>, <a href="http://arxiv.org/find/cs/1/au:+Poole_B/0/1/0/all/0/1">Ben Poole</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00630">
                                    <div class="article-summary-box-inner">
                                        <span>Diffusion-based generative models have demonstrated a capacity for
perceptually impressive synthesis, but can they also be great likelihood-based
models? We answer this in the affirmative, and introduce a family of
diffusion-based generative models that obtain state-of-the-art likelihoods on
standard image density estimation benchmarks. Unlike other diffusion-based
models, our method allows for efficient optimization of the noise schedule
jointly with the rest of the model. We show that the variational lower bound
(VLB) simplifies to a remarkably short expression in terms of the
signal-to-noise ratio of the diffused data, thereby improving our theoretical
understanding of this model class. Using this insight, we prove an equivalence
between several models proposed in the literature. In addition, we show that
the continuous-time VLB is invariant to the noise schedule, except for the
signal-to-noise ratio at its endpoints. This enables us to learn a noise
schedule that minimizes the variance of the resulting VLB estimator, leading to
faster optimization. Combining these advances with architectural improvements,
we obtain state-of-the-art likelihoods on image density estimation benchmarks,
outperforming autoregressive models that have dominated these benchmarks for
many years, with often significantly faster optimization. In addition, we show
how to turn the model into a bits-back compression scheme, and demonstrate
lossless compression rates close to the theoretical optimum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Margin Maximization via Dual Acceleration. (arXiv:2107.00595v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Ziwei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a>, <a href="http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1">Matus Telgarsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00595">
                                    <div class="article-summary-box-inner">
                                        <span>We present and analyze a momentum-based gradient method for training linear
classifiers with an exponentially-tailed loss (e.g., the exponential or
logistic loss), which maximizes the classification margin on separable data at
a rate of $\widetilde{\mathcal{O}}(1/t^2)$. This contrasts with a rate of
$\mathcal{O}(1/\log(t))$ for standard gradient descent, and $\mathcal{O}(1/t)$
for normalized gradient descent. This momentum-based method is derived via the
convex dual of the maximum-margin problem, and specifically by applying
Nesterov acceleration to this dual, which manages to result in a simple and
intuitive method in the primal. This dual view can also be used to derive a
stochastic variant, which performs adaptive non-uniform sampling via the dual
variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SinGAN-Seg: Synthetic Training Data Generation for Medical Image Segmentation. (arXiv:2107.00471v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Salehi_P/0/1/0/all/0/1">Pegah Salehi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sheshkal_S/0/1/0/all/0/1">Sajad Amouei Sheshkal</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Hammer_H/0/1/0/all/0/1">Hugo L.Hammer</a>, <a href="http://arxiv.org/find/eess/1/au:+Parasa_S/0/1/0/all/0/1">Sravanthi Parasa</a>, <a href="http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00471">
                                    <div class="article-summary-box-inner">
                                        <span>Processing medical data to find abnormalities is a time-consuming and costly
task, requiring tremendous efforts from medical experts. Therefore, Ai has
become a popular tool for the automatic processing of medical data, acting as a
supportive tool for doctors. AI tools highly depend on data for training the
models. However, there are several constraints to access to large amounts of
medical data to train machine learning algorithms in the medical domain, e.g.,
due to privacy concerns and the costly, time-consuming medical data annotation
process. To address this, in this paper we present a novel synthetic data
generation pipeline called SinGAN-Seg to produce synthetic medical data with
the corresponding annotated ground truth masks. We show that these synthetic
data generation pipelines can be used as an alternative to bypass privacy
concerns and as an alternative way to produce artificial segmentation datasets
with corresponding ground truth masks to avoid the tedious medical data
annotation process. As a proof of concept, we used an open polyp segmentation
dataset. By training UNet++ using both the real polyp segmentation dataset and
the corresponding synthetic dataset generated from the SinGAN-Seg pipeline, we
show that the synthetic data can achieve a very close performance to the real
data when the real segmentation datasets are large enough. In addition, we show
that synthetic data generated from the SinGAN-Seg pipeline improving the
performance of segmentation algorithms when the training dataset is very small.
Since our SinGAN-Seg pipeline is applicable for any medical dataset, this
pipeline can be used with any other segmentation datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence of Stochastic Extragradient for Bilinear Games with Restarted Iteration Averaging. (arXiv:2107.00464v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1">Chris Junchi Li</a>, <a href="http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1">Yaodong Yu</a>, <a href="http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1">Nicolas Loizou</a>, <a href="http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>, <a href="http://arxiv.org/find/math/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>, <a href="http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>, <a href="http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00464">
                                    <div class="article-summary-box-inner">
                                        <span>We study the stochastic bilinear minimax optimization problem, presenting an
analysis of the Stochastic ExtraGradient (SEG) method with constant step size,
and presenting variations of the method that yield favorable convergence. We
first note that the last iterate of the basic SEG method only contracts to a
fixed neighborhood of the Nash equilibrium, independent of the step size. This
contrasts sharply with the standard setting of minimization where standard
stochastic algorithms converge to a neighborhood that vanishes in proportion to
the square-root (constant) step size. Under the same setting, however, we prove
that when augmented with iteration averaging, SEG provably converges to the
Nash equilibrium, and such a rate is provably accelerated by incorporating a
scheduled restarting procedure. In the interpolation setting, we achieve an
optimal convergence rate up to tight constants. We present numerical
experiments that validate our theoretical findings and demonstrate the
effectiveness of the SEG method when equipped with iteration averaging and
restarting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA-MATD3:Self-attention-based multi-agent continuous control method in cooperative environments. (arXiv:2107.00284v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuyang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Bei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00284">
                                    <div class="article-summary-box-inner">
                                        <span>Cooperative problems under continuous control have always been the focus of
multi-agent reinforcement learning. Existing algorithms suffer from the problem
of uneven learning degree with the increase of the number of agents. In this
paper, a new structure for a multi-agent actor critic is proposed, and the
self-attention mechanism is applied in the critic network and the value
decomposition method used to solve the uneven problem. The proposed algorithm
makes full use of the samples in the replay memory buffer to learn the behavior
of a class of agents. First, a new update method is proposed for policy
networks that promotes learning efficiency. Second, the utilization of samples
is improved, at the same time reflecting the ability of perspective-taking
among groups. Finally, the &quot;deceptive signal&quot; in training is eliminated and the
learning degree among agents is more uniform than in the existing methods.
Multiple experiments were conducted in two typical scenarios of a multi-agent
particle environment. Experimental results show that the proposed algorithm can
perform better than the state-of-the-art ones, and that it exhibits higher
learning efficiency with an increasing number of agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dialectal Speech Recognition and Translation of Swiss German Speech to Standard German Text: Microsoft&#x27;s Submission to SwissText 2021. (arXiv:2106.08126v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Arabskyy_Y/0/1/0/all/0/1">Yuriy Arabskyy</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_A/0/1/0/all/0/1">Aashish Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Dey_S/0/1/0/all/0/1">Subhadeep Dey</a>, <a href="http://arxiv.org/find/eess/1/au:+Koller_O/0/1/0/all/0/1">Oscar Koller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08126">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the winning approach in the Shared Task 3 at SwissText
2021 on Swiss German Speech to Standard German Text, a public competition on
dialect recognition and translation. Swiss German refers to the multitude of
Alemannic dialects spoken in the German-speaking parts of Switzerland. Swiss
German differs significantly from standard German in pronunciation, word
inventory and grammar. It is mostly incomprehensible to native German speakers.
Moreover, it lacks a standardized written script. To solve the challenging
task, we propose a hybrid automatic speech recognition system with a lexicon
that incorporates translations, a 1st pass language model that deals with Swiss
German particularities, a transfer-learned acoustic model and a strong neural
language model for 2nd pass rescoring. Our submission reaches 46.04% BLEU on a
blind conversational test set and outperforms the second best competitor by a
12% relative margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Algebraic Neural Networks: Stability to Deformations. (arXiv:2009.01433v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parada_Mayorga_A/0/1/0/all/0/1">Alejandro Parada-Mayorga</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.01433">
                                    <div class="article-summary-box-inner">
                                        <span>We study algebraic neural networks (AlgNNs) with commutative algebras which
unify diverse architectures such as Euclidean convolutional neural networks,
graph neural networks, and group neural networks under the umbrella of
algebraic signal processing. An AlgNN is a stacked layered information
processing structure where each layer is conformed by an algebra, a vector
space and a homomorphism between the algebra and the space of endomorphisms of
the vector space. Signals are modeled as elements of the vector space and are
processed by convolutional filters that are defined as the images of the
elements of the algebra under the action of the homomorphism. We analyze
stability of algebraic filters and AlgNNs to deformations of the homomorphism
and derive conditions on filters that lead to Lipschitz stable operators. We
conclude that stable algebraic filters have frequency responses -- defined as
eigenvalue domain representations -- whose derivative is inversely proportional
to the frequency -- defined as eigenvalue magnitudes. It follows that for a
given level of discriminability, AlgNNs are more stable than algebraic filters,
thereby explaining their better empirical performance. This same phenomenon has
been proven for Euclidean convolutional neural networks and graph neural
networks. Our analysis shows that this is a deep algebraic property shared by a
number of architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous Cars on the Loihi Neuromorphic Research Processor. (arXiv:2107.00401v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Viale_A/0/1/0/all/0/1">Alberto Viale</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchisio_A/0/1/0/all/0/1">Alberto Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_M/0/1/0/all/0/1">Maurizio Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Masera_G/0/1/0/all/0/1">Guido Masera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00401">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous Driving (AD) related features provide new forms of mobility that
are also beneficial for other kind of intelligent and autonomous systems like
robots, smart transportation, and smart industries. For these applications, the
decisions need to be made fast and in real-time. Moreover, in the quest for
electric mobility, this task must follow low power policy, without affecting
much the autonomy of the mean of transport or the robot. These two challenges
can be tackled using the emerging Spiking Neural Networks (SNNs). When deployed
on a specialized neuromorphic hardware, SNNs can achieve high performance with
low latency and low power consumption. In this paper, we use an SNN connected
to an event-based camera for facing one of the key problems for AD, i.e., the
classification between cars and other objects. To consume less power than
traditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The
experiments are made following an offline supervised learning rule, followed by
mapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our
best experiment achieves an accuracy on offline implementation of 86%, that
drops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware
implementation has maximum 0.72 ms of latency for every sample, and consumes
only 310 mW. To the best of our knowledge, this work is the first
implementation of an event-based car classifier on a Neuromorphic Chip.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mandoline: Model Evaluation under Distribution Shift. (arXiv:2107.00643v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mayee Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_K/0/1/0/all/0/1">Karan Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohoni_N/0/1/0/all/0/1">Nimit Sohoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Poms_F/0/1/0/all/0/1">Fait Poms</a>, <a href="http://arxiv.org/find/cs/1/au:+Fatahalian_K/0/1/0/all/0/1">Kayvon Fatahalian</a>, <a href="http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1">Christopher R&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00643">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models are often deployed in different settings than they
were trained and validated on, posing a challenge to practitioners who wish to
predict how well the deployed model will perform on a target distribution. If
an unlabeled sample from the target distribution is available, along with a
labeled sample from a possibly different source distribution, standard
approaches such as importance weighting can be applied to estimate performance
on the target. However, importance weighting struggles when the source and
target distributions have non-overlapping support or are high-dimensional.
Taking inspiration from fields such as epidemiology and polling, we develop
Mandoline, a new evaluation framework that mitigates these issues. Our key
insight is that practitioners may have prior knowledge about the ways in which
the distribution shifts, which we can use to better guide the importance
weighting procedure. Specifically, users write simple &quot;slicing functions&quot; -
noisy, potentially correlated binary functions intended to capture possible
axes of distribution shift - to compute reweighted performance estimates. We
further describe a density ratio estimation framework for the slices and show
how its estimation error scales with slice quality and dataset size. Empirical
validation on NLP and vision tasks shows that \name can estimate performance on
the target distribution up to $3\times$ more accurately compared to standard
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Expected Complexity of Maxout Networks. (arXiv:2107.00379v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tseran_H/0/1/0/all/0/1">Hanna Tseran</a>, <a href="http://arxiv.org/find/stat/1/au:+Montufar_G/0/1/0/all/0/1">Guido Mont&#xfa;far</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00379">
                                    <div class="article-summary-box-inner">
                                        <span>Learning with neural networks relies on the complexity of the representable
functions, but more importantly, the particular assignment of typical
parameters to functions of different complexity. Taking the number of
activation regions as a complexity measure, recent works have shown that the
practical complexity of deep ReLU networks is often far from the theoretical
maximum. In this work we show that this phenomenon also occurs in networks with
maxout (multi-argument) activation functions and when considering the decision
boundaries in classification tasks. We also show that the parameter space has a
multitude of full-dimensional regions with widely different complexity, and
obtain nontrivial lower bounds on the expected complexity. Finally, we
investigate different parameter initialization procedures and show that they
can increase the speed of convergence in training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Large DAGs by Combining Continuous Optimization and Feedback Arc Set Heuristics. (arXiv:2107.00571v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gillot_P/0/1/0/all/0/1">Pierre Gillot</a>, <a href="http://arxiv.org/find/cs/1/au:+Parviainen_P/0/1/0/all/0/1">Pekka Parviainen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00571">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian networks represent relations between variables using a directed
acyclic graph (DAG). Learning the DAG is an NP-hard problem and exact learning
algorithms are feasible only for small sets of variables. We propose two
scalable heuristics for learning DAGs in the linear structural equation case.
Our methods learn the DAG by alternating between unconstrained gradient
descent-based step to optimize an objective function and solving a maximum
acyclic subgraph problem to enforce acyclicity. Thanks to this decoupling, our
methods scale up beyond thousands of variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Acceleration and Feature Learning inInfinitely Wide Neural Networks with Bottlenecks. (arXiv:2107.00364v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Littwin_E/0/1/0/all/0/1">Etai Littwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Saremi_O/0/1/0/all/0/1">Omid Saremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_S/0/1/0/all/0/1">Shuangfei Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Thilak_V/0/1/0/all/0/1">Vimal Thilak</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_H/0/1/0/all/0/1">Hanlin Goh</a>, <a href="http://arxiv.org/find/cs/1/au:+Susskind_J/0/1/0/all/0/1">Joshua M. Susskind</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Greg Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00364">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze the learning dynamics of infinitely wide neural networks with a
finite sized bottle-neck. Unlike the neural tangent kernel limit, a bottleneck
in an otherwise infinite width network al-lows data dependent feature learning
in its bottle-neck representation. We empirically show that a single bottleneck
in infinite networks dramatically accelerates training when compared to purely
in-finite networks, with an improved overall performance. We discuss the
acceleration phenomena by drawing similarities to infinitely wide deep linear
models, where the acceleration effect of a bottleneck can be understood
theoretically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Sound Event Classification by Increasing Shift Invariance in Convolutional Neural Networks. (arXiv:2107.00623v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fonseca_E/0/1/0/all/0/1">Eduardo Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraro_A/0/1/0/all/0/1">Andres Ferraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1">Xavier Serra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00623">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have put into question the commonly assumed shift invariance
property of convolutional networks, showing that small shifts in the input can
affect the output predictions substantially. In this paper, we ask whether lack
of shift invariance is a problem in sound event classification, and whether
there are benefits in addressing it. Specifically, we evaluate two pooling
methods to improve shift invariance in CNNs, based on low-pass filtering and
adaptive sampling of incoming feature maps. These methods are implemented via
small architectural modifications inserted into the pooling layers of CNNs. We
evaluate the effect of these architectural changes on the FSD50K dataset using
models of different capacity and in presence of strong regularization. We show
that these modifications consistently improve sound event classification in all
cases considered, without adding any (or adding very few) trainable parameters,
which makes them an appealing alternative to conventional pooling layers. The
outcome is a new state-of-the-art mAP of 0.541 on the FSD50K classification
benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Feature and Instance Attribution to Detect Artifacts. (arXiv:2107.00323v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1">Pouya Pezeshkpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Sarthak Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1">Byron C. Wallace</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00323">
                                    <div class="article-summary-box-inner">
                                        <span>Training the large deep neural networks that dominate NLP requires large
datasets. Many of these are collected automatically or via crowdsourcing, and
may exhibit systematic biases or annotation artifacts. By the latter, we mean
correlations between inputs and outputs that are spurious, insofar as they do
not represent a generally held causal relationship between features and
classes; models that exploit such correlations may appear to perform a given
task well, but fail on out of sample data. In this paper we propose methods to
facilitate identification of training data artifacts, using new hybrid
approaches that combine saliency maps (which highlight important input
features) with instance attribution methods (which retrieve training samples
influential to a given prediction). We show that this proposed training-feature
attribution approach can be used to uncover artifacts in training data, and use
it to identify previously unreported artifacts in a few standard NLP datasets.
We execute a small user study to evaluate whether these methods are useful to
NLP researchers in practice, with promising results. We make code for all
methods and experiments in this paper available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Inverse Problems with a Flow-based Noise Model. (arXiv:2003.08089v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1">Jay Whang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08089">
                                    <div class="article-summary-box-inner">
                                        <span>We study image inverse problems with a normalizing flow prior. Our
formulation views the solution as the maximum a posteriori estimate of the
image conditioned on the measurements. This formulation allows us to use noise
models with arbitrary dependencies as well as non-linear forward operators. We
empirically validate the efficacy of our method on various inverse problems,
including compressed sensing with quantized measurements and denoising with
highly structured noise patterns. We also present initial theoretical recovery
guarantees for solving inverse problems with a flow prior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Filter Networks for Image Classification. (arXiv:2107.00645v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00645">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-attention and pure multi-layer perceptrons (MLP)
models for vision have shown great potential in achieving promising performance
with fewer inductive biases. These models are generally based on learning
interaction among spatial locations from raw data. The complexity of
self-attention and MLP grows quadratically as the image size increases, which
makes these models hard to scale up when high-resolution features are required.
In this paper, we present the Global Filter Network (GFNet), a conceptually
simple yet computationally efficient architecture, that learns long-term
spatial dependencies in the frequency domain with log-linear complexity. Our
architecture replaces the self-attention layer in vision transformers with
three key operations: a 2D discrete Fourier transform, an element-wise
multiplication between frequency-domain features and learnable global filters,
and a 2D inverse Fourier transform. We exhibit favorable accuracy/complexity
trade-offs of our models on both ImageNet and downstream tasks. Our results
demonstrate that GFNet can be a very competitive alternative to
transformer-style models and CNNs in efficiency, generalization ability and
robustness. Code is available at https://github.com/raoyongming/GFNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based end-to-end speech recognition with residual Gaussian-based self-attention. (arXiv:2103.15722v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chengdong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Menglong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15722">
                                    <div class="article-summary-box-inner">
                                        <span>Self-attention (SA), which encodes vector sequences according to their
pairwise similarity, is widely used in speech recognition due to its strong
context modeling ability. However, when applied to long sequence data, its
accuracy is reduced. This is caused by the fact that its weighted average
operator may lead to the dispersion of the attention distribution, which
results in the relationship between adjacent signals ignored. To address this
issue, in this paper, we introduce relative-position-awareness self-attention
(RPSA). It not only maintains the global-range dependency modeling ability of
self-attention, but also improves the localness modeling ability. Because the
local window length of the original RPSA is fixed and sensitive to different
test data, here we propose Gaussian-based self-attention (GSA) whose window
length is learnable and adaptive to the test data automatically. We further
generalize GSA to a new residual Gaussian self-attention (resGSA) for the
performance improvement. We apply RPSA, GSA, and resGSA to Transformer-based
speech recognition respectively. Experimental results on the AISHELL-1 Mandarin
speech recognition corpus demonstrate the effectiveness of the proposed
methods. For example, the resGSA-Transformer achieves a character error rate
(CER) of 5.86% on the test set, which is relative 7.8% lower than that of the
SA-Transformer. Although the performance of the proposed resGSA-Transformer is
only slightly better than that of the RPSA-Transformer, it does not have to
tune the window length manually.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classical Planning in Deep Latent Space. (arXiv:2107.00110v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asai_M/0/1/0/all/0/1">Masataro Asai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1">Hiroshi Kajino</a>, <a href="http://arxiv.org/find/cs/1/au:+Fukunaga_A/0/1/0/all/0/1">Alex Fukunaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Muise_C/0/1/0/all/0/1">Christian Muise</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00110">
                                    <div class="article-summary-box-inner">
                                        <span>Current domain-independent, classical planners require symbolic models of the
problem domain and instance as input, resulting in a knowledge acquisition
bottleneck. Meanwhile, although deep learning has achieved significant success
in many fields, the knowledge is encoded in a subsymbolic representation which
is incompatible with symbolic systems such as planners. We propose Latplan, an
unsupervised architecture combining deep learning and classical planning. Given
only an unlabeled set of image pairs showing a subset of transitions allowed in
the environment (training inputs), Latplan learns a complete propositional PDDL
action model of the environment. Later, when a pair of images representing the
initial and the goal states (planning inputs) is given, Latplan finds a plan to
the goal state in a symbolic latent space and returns a visualized plan
execution. We evaluate Latplan using image-based versions of 6 planning
domains: 8-puzzle, 15-Puzzle, Blocksworld, Sokoban and Two variations of
LightsOut.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossless Coding of Point Cloud Geometry using a Deep Generative Model. (arXiv:2107.00400v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_D/0/1/0/all/0/1">Dat Thanh Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Quach_M/0/1/0/all/0/1">Maurice Quach</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenzise_G/0/1/0/all/0/1">Giuseppe Valenzise</a>, <a href="http://arxiv.org/find/eess/1/au:+Duhamel_P/0/1/0/all/0/1">Pierre Duhamel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00400">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a lossless point cloud (PC) geometry compression method
that uses neural networks to estimate the probability distribution of voxel
occupancy. First, to take into account the PC sparsity, our method adaptively
partitions a point cloud into multiple voxel block sizes. This partitioning is
signalled via an octree. Second, we employ a deep auto-regressive generative
model to estimate the occupancy probability of each voxel given the previously
encoded ones. We then employ the estimated probabilities to code efficiently a
block using a context-based arithmetic coder. Our context has variable size and
can expand beyond the current block to learn more accurate probabilities. We
also consider using data augmentation techniques to increase the generalization
capability of the learned probability models, in particular in the presence of
noise and lower-density point clouds. Experimental evaluation, performed on a
variety of point clouds from four different datasets and with diverse
characteristics, demonstrates that our method reduces significantly (by up to
30%) the rate for lossless coding compared to the state-of-the-art MPEG codec.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VideoLightFormer: Lightweight Action Recognition using Transformers. (arXiv:2107.00451v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koot_R/0/1/0/all/0/1">Raivo Koot</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haiping Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00451">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient video action recognition remains a challenging problem. One large
model after another takes the place of the state-of-the-art on the Kinetics
dataset, but real-world efficiency evaluations are often lacking. In this work,
we fill this gap and investigate the use of transformers for efficient action
recognition. We propose a novel, lightweight action recognition architecture,
VideoLightFormer. In a factorized fashion, we carefully extend the 2D
convolutional Temporal Segment Network with transformers, while maintaining
spatial and temporal video structure throughout the entire model. Existing
methods often resort to one of the two extremes, where they either apply huge
transformers to video features, or minimal transformers on highly pooled video
features. Our method differs from them by keeping the transformer models small,
but leveraging full spatiotemporal feature structure. We evaluate
VideoLightFormer in a high-efficiency setting on the temporally-demanding
EPIC-KITCHENS-100 and Something-Something-V2 (SSV2) datasets and find that it
achieves a better mix of efficiency and accuracy than existing state-of-the-art
models, apart from the Temporal Shift Module on SSV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MHER: Model-based Hindsight Experience Replay. (arXiv:2107.00306v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Rui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Meng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Lei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yali Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Feng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00306">
                                    <div class="article-summary-box-inner">
                                        <span>Solving multi-goal reinforcement learning (RL) problems with sparse rewards
is generally challenging. Existing approaches have utilized goal relabeling on
collected experiences to alleviate issues raised from sparse rewards. However,
these methods are still limited in efficiency and cannot make full use of
experiences. In this paper, we propose Model-based Hindsight Experience Replay
(MHER), which exploits experiences more efficiently by leveraging environmental
dynamics to generate virtual achieved goals. Replacing original goals with
virtual goals generated from interaction with a trained dynamics model leads to
a novel relabeling method, \emph{model-based relabeling} (MBR). Based on MBR,
MHER performs both reinforcement learning and supervised learning for efficient
policy improvement. Theoretically, we also prove the supervised part in MHER,
i.e., goal-conditioned supervised learning with MBR data, optimizes a lower
bound on the multi-goal RL objective. Experimental results in several
point-based tasks and simulated robotics environments show that MHER achieves
significantly higher sample efficiency than previous state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Hierarchical Super-Resolution for Scientific Data Reduction and Visualization. (arXiv:2107.00462v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wurster_S/0/1/0/all/0/1">Skylar W. Wurster</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_H/0/1/0/all/0/1">Han-Wei Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_H/0/1/0/all/0/1">Hanqi Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Peterka_T/0/1/0/all/0/1">Thomas Peterka</a>, <a href="http://arxiv.org/find/eess/1/au:+Raj_M/0/1/0/all/0/1">Mukund Raj</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1">Jiayi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00462">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach for hierarchical super resolution (SR) using neural
networks on an octree data representation. We train a hierarchy of neural
networks, each capable of 2x upscaling in each spatial dimension between two
levels of detail, and use these networks in tandem to facilitate large scale
factor super resolution, scaling with the number of trained networks. We
utilize these networks in a hierarchical super resolution algorithm that
upscales multiresolution data to a uniform high resolution without introducing
seam artifacts on octree node boundaries. We evaluate application of this
algorithm in a data reduction framework by dynamically downscaling input data
to an octree-based data structure to represent the multiresolution data before
compressing for additional storage reduction. We demonstrate that our approach
avoids seam artifacts common to multiresolution data formats, and show how
neural network super resolution assisted data reduction can preserve global
features better than compressors alone at the same compression ratios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Meets Perturbations: Robust and Interpretable Attention with Adversarial Training. (arXiv:2009.12064v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kitada_S/0/1/0/all/0/1">Shunsuke Kitada</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyatomi_H/0/1/0/all/0/1">Hitoshi Iyatomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12064">
                                    <div class="article-summary-box-inner">
                                        <span>Although attention mechanisms have been applied to a variety of deep learning
models and have been shown to improve the prediction performance, it has been
reported to be vulnerable to perturbations to the mechanism. To overcome the
vulnerability to perturbations in the mechanism, we are inspired by adversarial
training (AT), which is a powerful regularization technique for enhancing the
robustness of the models. In this paper, we propose a general training
technique for natural language processing tasks, including AT for attention
(Attention AT) and more interpretable AT for attention (Attention iAT). The
proposed techniques improved the prediction performance and the model
interpretability by exploiting the mechanisms with AT. In particular, Attention
iAT boosts those advantages by introducing adversarial perturbation, which
enhances the difference in the attention of the sentences. Evaluation
experiments with ten open datasets revealed that AT for attention mechanisms,
especially Attention iAT, demonstrated (1) the best performance in nine out of
ten tasks and (2) more interpretable attention (i.e., the resulting attention
correlated more strongly with gradient-based word importance) for all tasks.
Additionally, the proposed techniques are (3) much less dependent on
perturbation size in AT. Our code is available at
https://github.com/shunk031/attention-meets-perturbation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interviewer-Candidate Role Play: Towards Developing Real-World NLP Systems. (arXiv:2107.00315v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1">Neeraj Varshney</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1">Chitta Baral</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00315">
                                    <div class="article-summary-box-inner">
                                        <span>Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spotting adversarial samples for speaker verification by neural vocoders. (arXiv:2107.00309v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haibin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_P/0/1/0/all/0/1">Po-chun Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Ji Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanshan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jian Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00309">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speaker verification (ASV), one of the most important technology
for biometric identification, has been widely adopted in security-critic
applications, including transaction authentication and access control. However,
previous works have shown ASV is seriously vulnerable to recently emerged
adversarial attacks, yet effective countermeasures against them are limited. In
this paper, we adopt neural vocoders to spot adversarial samples for ASV. We
use neural vocoder to re-synthesize audio and find that the difference between
the ASV scores for the original and re-synthesized audio is a good indicator to
distinguish genuine and adversarial samples. As the very beginning work in this
direction of detecting adversarial samples for ASV, there is no reliable
baseline for comparison. So we first implement Griffin-Lim for detection and
set it as our baseline. The proposed method accomplishes effective detection
performance and outperforms all the baselines in all the settings. We also show
the neural vocoder adopted in the detection framework is dataset independent.
Our codes will be made open-source for future works to do comparison.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BASGD: Buffered Asynchronous SGD for Byzantine Learning. (arXiv:2003.00937v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Rui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wu-Jun Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00937">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed learning has become a hot research topic, due to its wide
application in cluster-based large-scale learning, federated learning, edge
computing and so on. Most distributed learning methods assume no error and
attack on the workers. However, many unexpected cases, such as communication
error and even malicious attack, may happen in real applications. Hence,
Byzantine learning (BL), which refers to distributed learning with attack or
error, has recently attracted much attention. Most existing BL methods are
synchronous, which will result in slow convergence when there exist
heterogeneous workers. Furthermore, in some applications like federated
learning and edge computing, synchronization cannot even be performed most of
the time due to the online workers (clients or edge servers). Hence,
asynchronous BL (ABL) is more general and practical than synchronous BL (SBL).
To the best of our knowledge, there exist only two ABL methods. One of them
cannot resist malicious attack. The other needs to store some training
instances on the server, which has the privacy leak problem. In this paper, we
propose a novel method, called buffered asynchronous stochastic gradient
descent (BASGD), for BL. BASGD is an asynchronous method. Furthermore, BASGD
has no need to store any training instances on the server, and hence can
preserve privacy in ABL. BASGD is theoretically proved to have the ability of
resisting against error and malicious attack. Moreover, BASGD has a similar
theoretical convergence rate to that of vanilla asynchronous SGD (ASGD), with
an extra constant variance. Empirical results show that BASGD can significantly
outperform vanilla ASGD and other ABL baselines, when there exists error or
attack on workers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphological classification of compact and extended radio galaxies using convolutional neural networks and data augmentation techniques. (arXiv:2107.00385v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Maslej_Kresnakova_V/0/1/0/all/0/1">Viera Maslej-Kre&#x161;&#x148;&#xe1;kov&#xe1;</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bouchefry_K/0/1/0/all/0/1">Khadija El Bouchefry</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Butka_P/0/1/0/all/0/1">Peter Butka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00385">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning techniques have been increasingly used in astronomical
applications and have proven to successfully classify objects in image data
with high accuracy. The current work uses archival data from the Faint Images
of the Radio Sky at Twenty Centimeters (FIRST) to classify radio galaxies into
four classes: Fanaroff-Riley Class I (FRI), Fanaroff-Riley Class II (FRII),
Bent-Tailed (BENT), and Compact (COMPT). The model presented in this work is
based on Convolutional Neural Networks (CNNs). The proposed architecture
comprises three parallel blocks of convolutional layers combined and processed
for final classification by two feed-forward layers. Our model classified
selected classes of radio galaxy sources on an independent testing subset with
an average of 96\% for precision, recall, and F1 score. The best selected
augmentation techniques were rotations, horizontal or vertical flips, and
increase of brightness. Shifts, zoom and decrease of brightness worsened the
performance of the model. The current results show that model developed in this
work is able to identify different morphological classes of radio galaxies with
a high efficiency and performance</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Learning with Missing Values Imputation. (arXiv:2106.01708v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Buliao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yunhui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1">Muhammad Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huanhuan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01708">
                                    <div class="article-summary-box-inner">
                                        <span>Incomplete instances with various missing attributes in many real-world
applications have brought challenges to the classification tasks. Missing
values imputation methods are often employed to replace the missing values with
substitute values. However, this process often separates the imputation and
classification, which may lead to inferior performance since label information
are often ignored during imputation. Moreover, traditional methods may rely on
improper assumptions to initialize the missing values, whereas the
unreliability of such initialization might lead to inferior performance. To
address these problems, a novel semi-supervised conditional normalizing flow
(SSCFlow) is proposed in this paper. SSCFlow explicitly utilizes the label
information to facilitate the imputation and classification simultaneously by
estimating the conditional distribution of incomplete instances with a novel
semi-supervised normalizing flow. Moreover, SSCFlow treats the initialized
missing values as corrupted initial imputation and iteratively reconstructs
their latent representations with an overcomplete denoising autoencoder to
approximate their true conditional distribution. Experiments on real-world
datasets demonstrate the robustness and effectiveness of the proposed
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse GCA and Thresholded Gradient Descent. (arXiv:2107.00371v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1">Sheng Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_Z/0/1/0/all/0/1">Zongming Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00371">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized correlation analysis (GCA) is concerned with uncovering linear
relationships across multiple datasets. It generalizes canonical correlation
analysis that is designed for two datasets. We study sparse GCA when there are
potentially multiple generalized correlation tuples in data and the loading
matrix has a small number of nonzero rows. It includes sparse CCA and sparse
PCA of correlation matrices as special cases. We first formulate sparse GCA as
generalized eigenvalue problems at both population and sample levels via a
careful choice of normalization constraints. Based on a Lagrangian form of the
sample optimization problem, we propose a thresholded gradient descent
algorithm for estimating GCA loading vectors and matrices in high dimensions.
We derive tight estimation error bounds for estimators generated by the
algorithm with proper initialization. We also demonstrate the prowess of the
algorithm on a number of synthetic datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Visual Exploration of Relations in Data Sets. (arXiv:1905.02515v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Puolamaki_K/0/1/0/all/0/1">Kai Puolam&#xe4;ki</a>, <a href="http://arxiv.org/find/stat/1/au:+Oikarinen_E/0/1/0/all/0/1">Emilia Oikarinen</a>, <a href="http://arxiv.org/find/stat/1/au:+Henelius_A/0/1/0/all/0/1">Andreas Henelius</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.02515">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient explorative data analysis systems must take into account both what
a user knows and wants to know. This paper proposes a principled framework for
interactive visual exploration of relations in data, through views most
informative given the user&#x27;s current knowledge and objectives. The user can
input pre-existing knowledge of relations in the data and also formulate
specific exploration interests, which are then taken into account in the
exploration. The idea is to steer the exploration process towards the interests
of the user, instead of showing uninteresting or already known relations. The
user&#x27;s knowledge is modelled by a distribution over data sets parametrised by
subsets of rows and columns of data, called tile constraints. We provide a
computationally efficient implementation of this concept based on constrained
randomisation. Furthermore, we describe a novel dimensionality reduction method
for finding the views most informative to the user, which at the limit of no
background knowledge and with generic objectives reduces to PCA. We show that
the method is suitable for interactive use and is robust to noise, outperforms
standard projection pursuit visualisation methods, and gives understandable and
useful results in analysis of real-world data. We provide an open-source
implementation of the framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Never Go Full Batch (in Stochastic Convex Optimization). (arXiv:2107.00469v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Amir_I/0/1/0/all/0/1">Idan Amir</a>, <a href="http://arxiv.org/find/math/1/au:+Carmon_Y/0/1/0/all/0/1">Yair Carmon</a>, <a href="http://arxiv.org/find/math/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>, <a href="http://arxiv.org/find/math/1/au:+Livni_R/0/1/0/all/0/1">Roi Livni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00469">
                                    <div class="article-summary-box-inner">
                                        <span>We study the generalization performance of $\text{full-batch}$ optimization
algorithms for stochastic convex optimization: these are first-order methods
that only access the exact gradient of the empirical risk (rather than
gradients with respect to individual data points), that include a wide range of
algorithms such as gradient descent, mirror descent, and their regularized
and/or accelerated variants. We provide a new separation result showing that,
while algorithms such as stochastic gradient descent can generalize and
optimize the population risk to within $\epsilon$ after $O(1/\epsilon^2)$
iterations, full-batch methods either need at least $\Omega(1/\epsilon^4)$
iterations or exhibit a dimension-dependent sample complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auto-encoding brain networks with applications to analyzing large-scale brain imaging datasets. (arXiv:1911.02728v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_M/0/1/0/all/0/1">Meimei Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengwu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1">David B. Dunson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.02728">
                                    <div class="article-summary-box-inner">
                                        <span>There has been huge interest in studying human brain connectomes inferred
from different imaging modalities and exploring their relationship with human
traits, such as cognition. Brain connectomes are usually represented as
networks, with nodes corresponding to different regions of interest (ROIs) and
edges to connection strengths between ROIs. Due to the high-dimensionality and
non-Euclidean nature of networks, it is challenging to depict their population
distribution and relate them to human traits. Current approaches focus on
summarizing the network using either pre-specified topological features or
principal components analysis (PCA). In this paper, building on recent advances
in deep learning, we develop a nonlinear latent factor model to characterize
the population distribution of brain graphs and infer the relationships between
brain structural connectomes and human traits. We refer to our method as Graph
AuTo-Encoding (GATE). We applied GATE to two large-scale brain imaging
datasets, the Adolescent Brain Cognitive Development (ABCD) study and the Human
Connectome Project (HCP) for adults, to understand the structural brain
connectome and its relationship with cognition. Numerical results demonstrate
huge advantages of GATE over competitors in terms of prediction accuracy,
statistical inference and computing efficiency. We found that structural
connectomes have a stronger association with a wide range of human cognitive
traits than was apparent using previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential prediction under log-loss and misspecification. (arXiv:2102.00050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feder_M/0/1/0/all/0/1">Meir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Polyanskiy_Y/0/1/0/all/0/1">Yury Polyanskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00050">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the question of sequential prediction under the log-loss in terms
of cumulative regret. Namely, given a hypothesis class of distributions,
learner sequentially predicts the (distribution of the) next letter in sequence
and its performance is compared to the baseline of the best constant predictor
from the hypothesis class. The well-specified case corresponds to an additional
assumption that the data-generating distribution belongs to the hypothesis
class as well. Here we present results in the more general misspecified case.
Due to special properties of the log-loss, the same problem arises in the
context of competitive-optimality in density estimation, and model selection.
For the $d$-dimensional Gaussian location hypothesis class, we show that
cumulative regrets in the well-specified and misspecified cases asymptotically
coincide. In other words, we provide an $o(1)$ characterization of the
distribution-free (or PAC) regret in this case -- the first such result as far
as we know. We recall that the worst-case (or individual-sequence) regret in
this case is larger by an additive constant ${d\over 2} + o(1)$. Surprisingly,
neither the traditional Bayesian estimators, nor the Shtarkov&#x27;s normalized
maximum likelihood achieve the PAC regret and our estimator requires special
&quot;robustification&quot; against heavy-tailed data. In addition, we show two general
results for misspecified regret: the existence and uniqueness of the optimal
estimator, and the bound sandwiching the misspecified regret between
well-specified regrets with (asymptotically) close hypotheses classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Consistency-Based Loss for Deep Odometry Through Uncertainty Propagation. (arXiv:2107.00366v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damirchi_H/0/1/0/all/0/1">Hamed Damirchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khorrambakht_R/0/1/0/all/0/1">Rooholla Khorrambakht</a>, <a href="http://arxiv.org/find/cs/1/au:+Taghirad_H/0/1/0/all/0/1">Hamid D. Taghirad</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshiri_B/0/1/0/all/0/1">Behzad Moshiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00366">
                                    <div class="article-summary-box-inner">
                                        <span>The incremental poses computed through odometry can be integrated over time
to calculate the pose of a device with respect to an initial location. The
resulting global pose may be used to formulate a second, consistency based,
loss term in a deep odometry setting. In such cases where multiple losses are
imposed on a network, the uncertainty over each output can be derived to weigh
the different loss terms in a maximum likelihood setting. However, when
imposing a constraint on the integrated transformation, due to how only
odometry is estimated at each iteration of the algorithm, there is no
information about the uncertainty associated with the global pose to weigh the
global loss term. In this paper, we associate uncertainties with the output
poses of a deep odometry network and propagate the uncertainties through each
iteration. Our goal is to use the estimated covariance matrix at each
incremental step to weigh the loss at the corresponding step while weighting
the global loss term using the compounded uncertainty. This formulation
provides an adaptive method to weigh the incremental and integrated loss terms
against each other, noting the increase in uncertainty as new estimates arrive.
We provide quantitative and qualitative analysis of pose estimates and show
that our method surpasses the accuracy of the state-of-the-art Visual Odometry
approaches. Then, uncertainty estimates are evaluated and comparisons against
fixed baselines are provided. Finally, the uncertainty values are used in a
realistic example to show the effectiveness of uncertainty quantification for
localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Well-calibrated prediction intervals for regression problems. (arXiv:2107.00363v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dewolf_N/0/1/0/all/0/1">Nicolas Dewolf</a>, <a href="http://arxiv.org/find/stat/1/au:+Baets_B/0/1/0/all/0/1">Bernard De Baets</a>, <a href="http://arxiv.org/find/stat/1/au:+Waegeman_W/0/1/0/all/0/1">Willem Waegeman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00363">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, various methods have been proposed for estimating
prediction intervals in regression settings, including Bayesian methods,
ensemble methods, direct interval estimation methods and conformal prediction
methods. An important issue is the calibration of these methods: the generated
prediction intervals should have a predefined coverage level, without being
overly conservative. In this work, we review the above four classes of methods
from a conceptual and experimental point of view. Results on benchmark data
sets from various domains highlight large fluctuations in performance from one
data set to another. These observations can be attributed to the violation of
certain assumptions that are inherent to some classes of methods. We illustrate
how conformal prediction can be used as a general calibration procedure for
methods that deliver poor results without a calibration step.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mesh-based graph convolutional neural network models of processes with complex initial states. (arXiv:2107.00090v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frankel_A/0/1/0/all/0/1">Ari Frankel</a>, <a href="http://arxiv.org/find/cs/1/au:+Safta_C/0/1/0/all/0/1">Cosmin Safta</a>, <a href="http://arxiv.org/find/cs/1/au:+Alleman_C/0/1/0/all/0/1">Coleman Alleman</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_R/0/1/0/all/0/1">Reese Jones</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00090">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the evolution of a representative sample of a material with
microstructure is a fundamental problem in homogenization. In this work we
propose a graph convolutional neural network that utilizes the discretized
representation of the initial microstructure directly, without segmentation or
clustering. Compared to feature-based and pixel-based convolutional neural
network models, the proposed method has a number of advantages: (a) it is deep
in that it does not require featurization but can benefit from it, (b) it has a
simple implementation with standard convolutional filters and layers, (c) it
works natively on unstructured and structured grid data without interpolation
(unlike pixel-based convolutional neural networks), and (d) it preserves
rotational invariance like other graph-based convolutional neural networks. We
demonstrate the performance of the proposed network and compare it to
traditional pixel-based convolution neural network models and feature-based
graph convolutional neural networks on three large datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Metadata Extraction Incorporating Visual Features from Scanned Electronic Theses and Dissertations. (arXiv:2107.00516v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1">Muntabir Hasan Choudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayanetti_H/0/1/0/all/0/1">Himarsha R. Jayanetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ingram_W/0/1/0/all/0/1">William A. Ingram</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1">Edward A. Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00516">
                                    <div class="article-summary-box-inner">
                                        <span>Electronic Theses and Dissertations (ETDs) contain domain knowledge that can
be used for many digital library tasks, such as analyzing citation networks and
predicting research trends. Automatic metadata extraction is important to build
scalable digital library search engines. Most existing methods are designed for
born-digital documents, so they often fail to extract metadata from scanned
documents such as for ETDs. Traditional sequence tagging methods mainly rely on
text-based features. In this paper, we propose a conditional random field (CRF)
model that combines text-based and visual features. To verify the robustness of
our model, we extended an existing corpus and created a new ground truth corpus
consisting of 500 ETD cover pages with human validated metadata. Our
experiments show that CRF with visual features outperformed both a heuristic
and a CRF model with only text-based features. The proposed model achieved
81.3%-96% F1 measure on seven metadata fields. The data and source code are
publicly available on Google Drive (https://tinyurl.com/y8kxzwrp) and a GitHub
repository (https://github.com/lamps-lab/ETDMiner/tree/master/etd_crf),
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compression Implies Generalization. (arXiv:2106.07989v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gronlund_A/0/1/0/all/0/1">Allan Gr&#xf8;nlund</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogsgaard_M/0/1/0/all/0/1">Mikael H&#xf8;gsgaard</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamma_L/0/1/0/all/0/1">Lior Kamma</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1">Kasper Green Larsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07989">
                                    <div class="article-summary-box-inner">
                                        <span>Explaining the surprising generalization performance of deep neural networks
is an active and important line of research in theoretical machine learning.
Influential work by Arora et al. (ICML&#x27;18) showed that, noise stability
properties of deep nets occurring in practice can be used to provably compress
model representations. They then argued that the small representations of
compressed networks imply good generalization performance albeit only of the
compressed nets. Extending their compression framework to yield generalization
bounds for the original uncompressed networks remains elusive.

Our main contribution is the establishment of a compression-based framework
for proving generalization bounds. The framework is simple and powerful enough
to extend the generalization bounds by Arora et al. to also hold for the
original network. To demonstrate the flexibility of the framework, we also show
that it allows us to give simple proofs of the strongest known generalization
bounds for other popular machine learning models, namely Support Vector
Machines and Boosting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circuit Complexity of Visual Search. (arXiv:2107.00223v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uchizawa_K/0/1/0/all/0/1">Kei Uchizawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Abe_H/0/1/0/all/0/1">Haruki Abe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00223">
                                    <div class="article-summary-box-inner">
                                        <span>We study computational hardness of feature and conjunction search through the
lens of circuit complexity. Let $x &#x3D; (x_1, ... , x_n)$ (resp., $y &#x3D; (y_1, ... ,
y_n)$) be Boolean variables each of which takes the value one if and only if a
neuron at place $i$ detects a feature (resp., another feature). We then simply
formulate the feature and conjunction search as Boolean functions ${\rm
FTR}_n(x) &#x3D; \bigvee_{i&#x3D;1}^n x_i$ and ${\rm CONJ}_n(x, y) &#x3D; \bigvee_{i&#x3D;1}^n x_i
\wedge y_i$, respectively. We employ a threshold circuit or a discretized
circuit (such as a sigmoid circuit or a ReLU circuit with discretization) as
our models of neural networks, and consider the following four computational
resources: [i] the number of neurons (size), [ii] the number of levels (depth),
[iii] the number of active neurons outputting non-zero values (energy), and
[iv] synaptic weight resolution (weight).

We first prove that any threshold circuit $C$ of size $s$, depth $d$, energy
$e$ and weight $w$ satisfies $\log rk(M_C) \le ed (\log s + \log w + \log n)$,
where $rk(M_C)$ is the rank of the communication matrix $M_C$ of a
$2n$-variable Boolean function that $C$ computes. Since ${\rm CONJ}_n$ has rank
$2^n$, we have $n \le ed (\log s + \log w + \log n)$. Thus, an exponential
lower bound on the size of even sublinear-depth threshold circuits exists if
the energy and weight are sufficiently small. Since ${\rm FTR}_n$ is computable
independently of $n$, our result suggests that computational capacity for the
feature and conjunction search are different. We also show that the inequality
is tight up to a constant factor if $ed &#x3D; o(n/ \log n)$. We next show that a
similar inequality holds for any discretized circuit. Thus, if we regard the
number of gates outputting non-zero values as a measure for sparse activity,
our results suggest that larger depth helps neural networks to acquire sparse
activity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotically Exact and Fast Gaussian Copula Models for Imputation of Mixed Data Types. (arXiv:2102.02642v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Christoffersen_B/0/1/0/all/0/1">Benjamin Christoffersen</a>, <a href="http://arxiv.org/find/stat/1/au:+Clements_M/0/1/0/all/0/1">Mark Clements</a>, <a href="http://arxiv.org/find/stat/1/au:+Humphreys_K/0/1/0/all/0/1">Keith Humphreys</a>, <a href="http://arxiv.org/find/stat/1/au:+Kjellstrom_H/0/1/0/all/0/1">Hedvig Kjellstr&#xf6;m</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02642">
                                    <div class="article-summary-box-inner">
                                        <span>Missing values with mixed data types is a common problem in a large number of
machine learning applications such as processing of surveys and in different
medical applications. Recently, Gaussian copula models have been suggested as a
means of performing imputation of missing values using a probabilistic
framework. While the present Gaussian copula models have shown to yield state
of the art performance, they have two limitations: they are based on an
approximation that is fast but may be imprecise and they do not support
unordered multinomial variables. We address the first limitation using direct
and arbitrarily precise approximations both for model estimation and imputation
by using randomized quasi-Monte Carlo procedures. The method we provide has
lower errors for the estimated model parameters and the imputed values,
compared to previously proposed methods. We also extend the previous Gaussian
copula models to include unordered multinomial variables in addition to the
present support of ordinal, binary, and continuous variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_H/0/1/0/all/0/1">Hsiang Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1">Mario Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Calmon_F/0/1/0/all/0/1">Flavio P. Calmon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04788">
                                    <div class="article-summary-box-inner">
                                        <span>Disparate treatment occurs when a machine learning model yields different
decisions for individuals based on a sensitive attribute (e.g., age, sex). In
domains where prediction accuracy is paramount, it could potentially be
acceptable to fit a model which exhibits disparate treatment. To evaluate the
effect of disparate treatment, we compare the performance of split classifiers
(i.e., classifiers trained and deployed separately on each group) with
group-blind classifiers (i.e., classifiers which do not use a sensitive
attribute). We introduce the benefit-of-splitting for quantifying the
performance improvement by splitting classifiers. Computing the
benefit-of-splitting directly from its definition could be intractable since it
involves solving optimization problems over an infinite-dimensional functional
space. Under different performance measures, we (i) prove an equivalent
expression for the benefit-of-splitting which can be efficiently computed by
solving small-scale convex programs; (ii) provide sharp upper and lower bounds
for the benefit-of-splitting which reveal precise conditions where a
group-blind classifier will always suffer from a non-trivial performance gap
from the split classifiers. In the finite sample regime, splitting is not
necessarily beneficial and we provide data-dependent bounds to understand this
effect. Finally, we validate our theoretical results through numerical
experiments on both synthetic and real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overhead-MNIST: Machine Learning Baselines for Image Classification. (arXiv:2107.00436v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Larsen_E/0/1/0/all/0/1">Erik Larsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1">David Noever</a>, <a href="http://arxiv.org/find/cs/1/au:+MacVittie_K/0/1/0/all/0/1">Korey MacVittie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lilly_J/0/1/0/all/0/1">John Lilly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00436">
                                    <div class="article-summary-box-inner">
                                        <span>Twenty-three machine learning algorithms were trained then scored to
establish baseline comparison metrics and to select an image classification
algorithm worthy of embedding into mission-critical satellite imaging systems.
The Overhead-MNIST dataset is a collection of satellite images similar in style
to the ubiquitous MNIST hand-written digits found in the machine learning
literature. The CatBoost classifier, Light Gradient Boosting Machine, and
Extreme Gradient Boosting models produced the highest accuracies, Areas Under
the Curve (AUC), and F1 scores in a PyCaret general comparison. Separate
evaluations showed that a deep convolutional architecture was the most
promising. We present results for the overall best performing algorithm as a
baseline for edge deployability and future performance improvement: a
convolutional neural network (CNN) scoring 0.965 categorical accuracy on unseen
test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Focal Self-attention for Local-Global Interactions in Vision Transformers. (arXiv:2107.00641v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xiyang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_B/0/1/0/all/0/1">Bin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00641">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformer and its variants have shown great promise on
various computer vision tasks. The ability of capturing short- and long-range
visual dependencies through self-attention is arguably the main source for the
success. But it also brings challenges due to quadratic computational overhead,
especially for the high-resolution vision tasks (e.g., object detection). In
this paper, we present focal self-attention, a new mechanism that incorporates
both fine-grained local and coarse-grained global interactions. Using this new
mechanism, each token attends the closest surrounding tokens at fine
granularity but the tokens far away at coarse granularity, and thus can capture
both short- and long-range visual dependencies efficiently and effectively.
With focal self-attention, we propose a new variant of Vision Transformer
models, called Focal Transformer, which achieves superior performance over the
state-of-the-art vision Transformers on a range of public image classification
and object detection benchmarks. In particular, our Focal Transformer models
with a moderate size of 51.1M and a larger size of 89.8M achieve 83.5 and 83.8
Top-1 accuracy, respectively, on ImageNet classification at 224x224 resolution.
Using Focal Transformers as the backbones, we obtain consistent and substantial
improvements over the current state-of-the-art Swin Transformers for 6
different object detection methods trained with standard 1x and 3x schedules.
Our largest Focal Transformer yields 58.7/58.9 box mAPs and 50.9/51.3 mask mAPs
on COCO mini-val/test-dev, and 55.4 mIoU on ADE20K for semantic segmentation,
creating new SoTA on three of the most challenging computer vision tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Diabetic Retinopathy Detection and Retinal Image Generation. (arXiv:2107.00296v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Niu_Y/0/1/0/all/0/1">Yuhao Niu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_L/0/1/0/all/0/1">Lin Gu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yitian Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_F/0/1/0/all/0/1">Feng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00296">
                                    <div class="article-summary-box-inner">
                                        <span>Though deep learning has shown successful performance in classifying the
label and severity stage of certain diseases, most of them give few
explanations on how to make predictions. Inspired by Koch&#x27;s Postulates, the
foundation in evidence-based medicine (EBM) to identify the pathogen, we
propose to exploit the interpretability of deep learning application in medical
diagnosis. By determining and isolating the neuron activation patterns on which
diabetic retinopathy (DR) detector relies to make decisions, we demonstrate the
direct relation between the isolated neuron activation and lesions for a
pathological explanation. To be specific, we first define novel pathological
descriptors using activated neurons of the DR detector to encode both spatial
and appearance information of lesions. Then, to visualize the symptom encoded
in the descriptor, we propose Patho-GAN, a new network to synthesize medically
plausible retinal images. By manipulating these descriptors, we could even
arbitrarily control the position, quantity, and categories of generated
lesions. We also show that our synthesized images carry the symptoms directly
related to diabetic retinopathy diagnosis. Our generated images are both
qualitatively and quantitatively superior to the ones by previous methods.
Besides, compared to existing methods that take hours to generate an image, our
second level speed endows the potential to be an effective solution for data
augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-facet Contextual Bandits: A Neural Network Perspective. (arXiv:2106.03039v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ban_Y/0/1/0/all/0/1">Yikun Ban</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jingrui He</a>, <a href="http://arxiv.org/find/cs/1/au:+Cook_C/0/1/0/all/0/1">Curtiss B. Cook</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03039">
                                    <div class="article-summary-box-inner">
                                        <span>Contextual multi-armed bandit has shown to be an effective tool in
recommender systems. In this paper, we study a novel problem of multi-facet
bandits involving a group of bandits, each characterizing the users&#x27; needs from
one unique aspect. In each round, for the given user, we need to select one arm
from each bandit, such that the combination of all arms maximizes the final
reward. This problem can find immediate applications in E-commerce, healthcare,
etc. To address this problem, we propose a novel algorithm, named MuFasa, which
utilizes an assembled neural network to jointly learn the underlying reward
functions of multiple bandits. It estimates an Upper Confidence Bound (UCB)
linked with the expected reward to balance between exploitation and
exploration. Under mild assumptions, we provide the regret analysis of MuFasa.
It can achieve the near-optimal $\widetilde{ \mathcal{O}}((K+1)\sqrt{T})$
regret bound where $K$ is the number of bandits and $T$ is the number of played
rounds. Furthermore, we conduct extensive experiments to show that MuFasa
outperforms strong baselines on real-world data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_L/0/1/0/all/0/1">Lu Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_W/0/1/0/all/0/1">Wei-Lun Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00197">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to train a strong classifier using limited
labeled examples. Many existing works take the meta-learning approach, sampling
few-shot tasks in turn and optimizing the few-shot learner&#x27;s performance on
classifying the query examples. In this paper, we point out two potential
weaknesses of this approach. First, the sampled query examples may not provide
sufficient supervision for the few-shot learner. Second, the effectiveness of
meta-learning diminishes sharply with increasing shots (i.e., the number of
training examples per class). To resolve these issues, we propose a novel
objective to directly train the few-shot learner to perform like a strong
classifier. Concretely, we associate each sampled few-shot task with a strong
classifier, which is learned with ample labeled examples. The strong classifier
has a better generalization ability and we use it to supervise the few-shot
learner. We present an efficient way to construct the strong classifier, making
our proposed objective an easily plug-and-play term to existing meta-learning
based FSL methods. We validate our approach in combinations with many
representative meta-learning methods. On several benchmark datasets including
miniImageNet and tiredImageNet, our approach leads to a notable improvement
across a variety of tasks. More importantly, with our approach, meta-learning
based FSL methods can consistently outperform non-meta-learning based ones,
even in a many-shot setting, greatly strengthening their applicability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tweet Sentiment Quantification: An Experimental Re-Evaluation. (arXiv:2011.08091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreo_A/0/1/0/all/0/1">Alejandro Moreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1">Fabrizio Sebastiani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08091">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment quantification is the task of estimating the relative frequency (or
&quot;prevalence&quot;) of sentiment-related classes (such as Positive, Neutral,
Negative) in a sample of unlabelled texts; this is especially important when
these texts are tweets, since most sentiment classification endeavours carried
out on Twitter data actually have quantification (and not the classification of
individual tweets) as their ultimate goal. It is well-known that solving
quantification via &quot;classify and count&quot; (i.e., by classifying all unlabelled
items via a standard classifier and counting the items that have been assigned
to a given class) is suboptimal in terms of accuracy, and that more accurate
quantification methods exist. In 2016, Gao and Sebastiani carried out a
systematic comparison of quantification methods on the task of tweet sentiment
quantification. In hindsight, we observe that the experimental protocol
followed in that work is flawed, and that its results are thus unreliable. We
now re-evaluate those quantification methods on the very same datasets, this
time following a now consolidated and much more robust experimental protocol,
that involves 5775 as many experiments as run in the original study. Our
experimentation yields results dramatically different from those obtained by
Gao and Sebastiani, and thus provide a different, much more solid understanding
of the relative strengths and weaknesses of different sentiment quantification
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imitation Learning from Pixel-Level Demonstrations by HashReward. (arXiv:1909.03773v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1">Xin-Qiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yao-Xiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhi-Hua Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03773">
                                    <div class="article-summary-box-inner">
                                        <span>One of the key issues for imitation learning lies in making policy learned
from limited samples to generalize well in the whole state-action space. This
problem is much more severe in high-dimensional state environments, such as
game playing with raw pixel inputs. Under this situation, even state-of-the-art
adversary-based imitation learning algorithms fail. Through empirical studies,
we find that the main cause lies in the failure of training a powerful
discriminator to generate meaningful rewards in high-dimensional environments.
Although it seems that dimensionality reduction can help, a straightforward
application of off-the-shelf methods cannot achieve good performance. In this
work, we show in theory that the balance between dimensionality reduction and
discriminative training is essential for effective learning. To achieve this
target, we propose HashReward, which utilizes the idea of supervised hashing to
realize such an ideal balance. Experimental results show that HashReward could
outperform state-of-the-art methods for a large gap under the challenging
high-dimensional environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Biased Graph Neural Network Sampler with Near-Optimal Regret. (arXiv:2103.01089v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingru Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1">David Wipf</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Q/0/1/0/all/0/1">Quan Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Le Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01089">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNN) have recently emerged as a vehicle for applying
deep network architectures to graph and relational data. However, given the
increasing size of industrial datasets, in many practical situations the
message passing computations required for sharing information across GNN layers
are no longer scalable. Although various sampling methods have been introduced
to approximate full-graph training within a tractable budget, there remain
unresolved complications such as high variances and limited theoretical
guarantees. To address these issues, we build upon existing work and treat GNN
neighbor sampling as a multi-armed bandit problem but with a newly-designed
reward function that introduces some degree of bias designed to reduce variance
and avoid unstable, possibly-unbounded pay outs. And unlike prior bandit-GNN
use cases, the resulting policy leads to near-optimal regret while accounting
for the GNN training dynamics introduced by SGD. From a practical standpoint,
this translates into lower variance estimates and competitive or superior test
accuracy across several benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Transfer across Visual and Dynamics Domain Gaps via Iterative Grounding. (arXiv:2107.00339v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Grace Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Linghan Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Youngwoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1">Joseph J. Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00339">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to transfer a policy from one environment to another is a
promising avenue for efficient robot learning in realistic settings where task
supervision is not available. This can allow us to take advantage of
environments well suited for training, such as simulators or laboratories, to
learn a policy for a real robot in a home or office. To succeed, such policy
transfer must overcome both the visual domain gap (e.g. different illumination
or background) and the dynamics domain gap (e.g. different robot calibration or
modelling error) between source and target environments. However, prior policy
transfer approaches either cannot handle a large domain gap or can only address
one type of domain gap at a time. In this paper, we propose a novel policy
transfer method with iterative &quot;environment grounding&quot;, IDAPT, that alternates
between (1) directly minimizing both visual and dynamics domain gaps by
grounding the source environment in the target environment domains, and (2)
training a policy on the grounded source environment. This iterative training
progressively aligns the domains between the two environments and adapts the
policy to the target environment. Once trained, the policy can be directly
executed on the target environment. The empirical results on locomotion and
robotic manipulation tasks demonstrate that our approach can effectively
transfer a policy across visual and dynamics domain gaps with minimal
supervision and interaction with the target environment. Videos and code are
available at https://clvrai.com/idapt .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When does gradient descent with logistic loss find interpolating two-layer networks?. (arXiv:2012.02409v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1">Philip M. Long</a>, <a href="http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1">Peter L. Bartlett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02409">
                                    <div class="article-summary-box-inner">
                                        <span>We study the training of finite-width two-layer smoothed ReLU networks for
binary classification using the logistic loss. We show that gradient descent
drives the training loss to zero if the initial loss is small enough. When the
data satisfies certain cluster and separation conditions and the network is
wide enough, we show that one step of gradient descent reduces the loss
sufficiently that the first result applies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Difference Uncertainties as a Signal for Exploration. (arXiv:2010.02255v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1">Sebastian Flennerhag</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jane X. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1">Pablo Sprechmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Visin_F/0/1/0/all/0/1">Francesco Visin</a>, <a href="http://arxiv.org/find/cs/1/au:+Galashov_A/0/1/0/all/0/1">Alexandre Galashov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapturowski_S/0/1/0/all/0/1">Steven Kapturowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Borsa_D/0/1/0/all/0/1">Diana L. Borsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1">Nicolas Heess</a>, <a href="http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1">Andre Barreto</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02255">
                                    <div class="article-summary-box-inner">
                                        <span>An effective approach to exploration in reinforcement learning is to rely on
an agent&#x27;s uncertainty over the optimal policy, which can yield near-optimal
exploration strategies in tabular settings. However, in non-tabular settings
that involve function approximators, obtaining accurate uncertainty estimates
is almost as challenging a problem. In this paper, we highlight that value
estimates are easily biased and temporally inconsistent. In light of this, we
propose a novel method for estimating uncertainty over the value function that
relies on inducing a distribution over temporal difference errors. This
exploration signal controls for state-action transitions so as to isolate
uncertainty in value that is due to uncertainty over the agent&#x27;s parameters.
Because our measure of uncertainty conditions on state-action transitions, we
cannot act on this measure directly. Instead, we incorporate it as an intrinsic
reward and treat exploration as a separate learning problem, induced by the
agent&#x27;s temporal difference uncertainties. We introduce a distinct exploration
policy that learns to collect data with high estimated uncertainty, which gives
rise to a curriculum that smoothly changes throughout learning and vanishes in
the limit of perfect value estimates. We evaluate our method on hard
exploration tasks, including Deep Sea and Atari 2600 environments and find that
our proposed form of exploration facilitates both diverse and deep exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Learning for Channel Allocation in IoT Networks over Unlicensed Bandwidth as a Contextual Multi-player Multi-armed Bandit Game. (arXiv:2003.13314v3 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Leshem_A/0/1/0/all/0/1">Amir Leshem</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1">Dusit Niyato</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13314">
                                    <div class="article-summary-box-inner">
                                        <span>We study a decentralized channel allocation problem in an ad-hoc Internet of
Things network underlaying on the spectrum licensed to a primary cellular
network. In the considered network, the impoverished channel sensing/probing
capability and computational resource on the IoT devices make them difficult to
acquire the detailed Channel State Information (CSI) for the shared multiple
channels. In practice, the unknown patterns of the primary users&#x27; transmission
activities and the time-varying CSI (e.g., due to small-scale fading or device
mobility) also cause stochastic changes in the channel quality. Decentralized
IoT links are thus expected to learn channel conditions online based on partial
observations, while acquiring no information about the channels that they are
not operating on. They also have to reach an efficient, collision-free solution
of channel allocation with limited coordination. Our study maps this problem
into a contextual multi-player, multi-armed bandit game, and proposes a purely
decentralized, three-stage policy learning algorithm through trial-and-error.
Theoretical analyses shows that the proposed scheme guarantees the IoT links to
jointly converge to the social optimal channel allocation with a sub-linear
(i.e., polylogarithmic) regret with respect to the operational time.
Simulations demonstrate that it strikes a good balance between efficiency and
network scalability when compared with the other state-of-the-art decentralized
bandit algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When does gradient descent with logistic loss interpolate using deep networks with smoothed ReLU activations?. (arXiv:2102.04998v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1">Philip M. Long</a>, <a href="http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1">Peter L. Bartlett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04998">
                                    <div class="article-summary-box-inner">
                                        <span>We establish conditions under which gradient descent applied to fixed-width
deep networks drives the logistic loss to zero, and prove bounds on the rate of
convergence. Our analysis applies for smoothed approximations to the ReLU, such
as Swish and the Huberized ReLU, proposed in previous applied work. We provide
two sufficient conditions for convergence. The first is simply a bound on the
loss at initialization. The second is a data separation condition used in prior
analyses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information-theoretic Task Selection for Meta-Reinforcement Learning. (arXiv:2011.01054v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1">Ricardo Luna Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonetti_M/0/1/0/all/0/1">Matteo Leonetti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01054">
                                    <div class="article-summary-box-inner">
                                        <span>In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of
tasks to prepare for and learn faster in new, unseen, but related tasks. The
training tasks are usually hand-crafted to be representative of the expected
distribution of test tasks and hence all used in training. We show that given a
set of training tasks, learning can be both faster and more effective (leading
to better performance in the test tasks), if the training tasks are
appropriately selected. We propose a task selection algorithm,
Information-Theoretic Task Selection (ITTS), based on information theory, which
optimizes the set of tasks used for training in meta-RL, irrespectively of how
they are generated. The algorithm establishes which training tasks are both
sufficiently relevant for the test tasks, and different enough from one
another. We reproduce different meta-RL experiments from the literature and
show that ITTS improves the final performance in all of them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiongjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunpeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08812">
                                    <div class="article-summary-box-inner">
                                        <span>While theoretically appealing, the application of the Wasserstein distance to
large-scale machine learning problems has been hampered by its prohibitive
computational cost. The sliced Wasserstein distance and its variants improve
the computational efficiency through the random projection, yet they suffer
from low accuracy if the number of projections is not sufficiently large,
because the majority of projections result in trivially small values. In this
work, we propose a new family of distance metrics, called augmented sliced
Wasserstein distances (ASWDs), constructed by first mapping samples to
higher-dimensional hypersurfaces parameterized by neural networks. It is
derived from a key observation that (random) linear projections of samples
residing on these hypersurfaces would translate to much more flexible nonlinear
projections in the original sample space, so they can capture complex
structures of the data distribution. We show that the hypersurfaces can be
optimized by gradient ascent efficiently. We provide the condition under which
the ASWD is a valid metric and show that this can be obtained by an injective
neural network architecture. Numerical results demonstrate that the ASWD
significantly outperforms other Wasserstein variants for both synthetic and
real-world problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An error analysis of generative adversarial networks for learning distributions. (arXiv:2105.13010v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yuling Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yunfei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13010">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies how well generative adversarial networks (GANs) learn
probability distributions from finite samples. Our main results establish the
convergence rates of GANs under a collection of integral probability metrics
defined through H\&quot;older classes, including the Wasserstein distance as a
special case. We also show that GANs are able to adaptively learn data
distributions with low-dimensional structures or have H\&quot;older densities, when
the network architectures are chosen properly. In particular, for distributions
concentrated around a low-dimensional set, we show that the learning rates of
GANs do not depend on the high ambient dimension, but on the lower intrinsic
dimension. Our analysis is based on a new oracle inequality decomposing the
estimation error into the generator and discriminator approximation error and
the statistical error, which may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predictive Modeling in the Presence of Nuisance-Induced Spurious Correlations. (arXiv:2107.00520v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puli_A/0/1/0/all/0/1">Aahlad Puli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lily H. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Oermann_E/0/1/0/all/0/1">Eric K. Oermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1">Rajesh Ranganath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00520">
                                    <div class="article-summary-box-inner">
                                        <span>Deep predictive models often make use of spurious correlations between the
label and the covariates that differ between training and test distributions.
In many classification tasks, spurious correlations are induced by a changing
relationship between the label and some nuisance variables correlated with the
covariates. For example, in classifying animals in natural images, the
background, which is the nuisance, can predict the type of animal, but this
nuisance label relationship does not always hold. This nuisance-label
relationship does not always hold. We formalize a family of distributions that
only differ in the nuisance-label relationship and and introduce a distribution
where this relationship is broken called the nuisance-randomized distribution.
We introduce a set of predictive models built from the nuisance-randomized
distribution with representations, that when conditioned on, do not correlate
the label and the nuisance. For models in this set, we lower bound the
performance for any member of the family with the mutual information between
the representation and the label under the nuisance-randomized distribution. To
build predictive models that maximize the performance lower bound, we develop
Nuisance-Randomized Distillation (NURD). We evaluate NURD on a synthetic
example, colored-MNIST, and classifying chest X-rays. When using non-lung
patches as the nuisance in classifying chest X-rays, NURD produces models that
predict pneumonia under strong spurious correlations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Anomaly Feature Vectors for Detecting, Classifying and Warning of Outlier Adversarial Examples. (arXiv:2107.00561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Manohar_Alers_N/0/1/0/all/0/1">Nelson Manohar-Alers</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Ryan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sahib Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jiguo Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_A/0/1/0/all/0/1">Atul Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00561">
                                    <div class="article-summary-box-inner">
                                        <span>We present DeClaW, a system for detecting, classifying, and warning of
adversarial inputs presented to a classification neural network. In contrast to
current state-of-the-art methods that, given an input, detect whether an input
is clean or adversarial, we aim to also identify the types of adversarial
attack (e.g., PGD, Carlini-Wagner or clean). To achieve this, we extract
statistical profiles, which we term as anomaly feature vectors, from a set of
latent features. Preliminary findings suggest that AFVs can help distinguish
among several types of adversarial attacks (e.g., PGD versus Carlini-Wagner)
with close to 93% accuracy on the CIFAR-10 dataset. The results open the door
to using AFV-based methods for exploring not only adversarial attack detection
but also classification of the attack type and then design of attack-specific
mitigation strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable nonlinear modelling of multiple time series with invertible neural networks. (arXiv:2107.00391v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lopez_Ramos_L/0/1/0/all/0/1">Luis Miguel Lopez-Ramos</a>, <a href="http://arxiv.org/find/eess/1/au:+Roy_K/0/1/0/all/0/1">Kevin Roy</a>, <a href="http://arxiv.org/find/eess/1/au:+Beferull_Lozano_B/0/1/0/all/0/1">Baltasar Beferull-Lozano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00391">
                                    <div class="article-summary-box-inner">
                                        <span>A method for nonlinear topology identification is proposed, based on the
assumption that a collection of time series are generated in two steps: i) a
vector autoregressive process in a latent space, and ii) a nonlinear,
component-wise, monotonically increasing observation mapping. The latter
mappings are assumed invertible, and are modelled as shallow neural networks,
so that their inverse can be numerically evaluated, and their parameters can be
learned using a technique inspired in deep learning. Due to the function
inversion, the back-propagation step is not straightforward, and this paper
explains the steps needed to calculate the gradients applying implicit
differentiation. Whereas the model explainability is the same as that for
linear VAR processes, preliminary numerical tests show that the prediction
error becomes smaller.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Theoretical Framework for Fast and Accurate Online Decision-Making. (arXiv:1905.11797v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1">Nicol&#xf2; Cesa-Bianchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1">Tommaso R. Cesari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11797">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel theoretical framework for Return On Investment (ROI)
maximization in repeated decision-making. Our setting is motivated by the use
case of companies that regularly receive proposals for technological
innovations and want to quickly decide whether they are worth implementing. We
design an algorithm for learning ROI-maximizing decision-making policies over a
sequence of innovation proposals. Our algorithm provably converges to an
optimal policy in class $\Pi$ at a rate of order
$\min\big\{1/(N\Delta^2),N^{-1/3}\}$, where $N$ is the number of innovations
and $\Delta$ is the suboptimality gap in $\Pi$. A significant hurdle of our
formulation, which sets it aside from other online learning problems such as
bandits, is that running a policy does not provide an unbiased estimate of its
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Sequential Design for a Single Time-Series. (arXiv:2102.00102v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Malenica_I/0/1/0/all/0/1">Ivana Malenica</a>, <a href="http://arxiv.org/find/math/1/au:+Bibaut_A/0/1/0/all/0/1">Aurelien Bibaut</a>, <a href="http://arxiv.org/find/math/1/au:+Laan_M/0/1/0/all/0/1">Mark J. van der Laan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00102">
                                    <div class="article-summary-box-inner">
                                        <span>The current work is motivated by the need for robust statistical methods for
precision medicine; as such, we address the need for statistical methods that
provide actionable inference for a single unit at any point in time. We aim to
learn an optimal, unknown choice of the controlled components of the design in
order to optimize the expected outcome; with that, we adapt the randomization
mechanism for future time-point experiments based on the data collected on the
individual over time. Our results demonstrate that one can learn the optimal
rule based on a single sample, and thereby adjust the design at any point t
with valid inference for the mean target parameter. This work provides several
contributions to the field of statistical precision medicine. First, we define
a general class of averages of conditional causal parameters defined by the
current context for the single unit time-series data. We define a nonparametric
model for the probability distribution of the time-series under few
assumptions, and aim to fully utilize the sequential randomization in the
estimation procedure via the double robust structure of the efficient influence
curve of the proposed target parameter. We present multiple
exploration-exploitation strategies for assigning treatment, and methods for
estimating the optimal rule. Lastly, we present the study of the data-adaptive
inference on the mean under the optimal treatment rule, where the target
parameter adapts over time in response to the observed context of the
individual. Our target parameter is pathwise differentiable with an efficient
influence function that is doubly robust - which makes it easier to estimate
than previously proposed variations. We characterize the limit distribution of
our estimator under a Donsker condition expressed in terms of a notion of
bracketing entropy adapted to martingale settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Limit Order Book Recreation Model (LOBRM): An Extended Analysis. (arXiv:2107.00534v1 [q-fin.TR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Shi_Z/0/1/0/all/0/1">Zijian Shi</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Cartlidge_J/0/1/0/all/0/1">John Cartlidge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00534">
                                    <div class="article-summary-box-inner">
                                        <span>The limit order book (LOB) depicts the fine-grained demand and supply
relationship for financial assets and is widely used in market microstructure
studies. Nevertheless, the availability and high cost of LOB data restrict its
wider application. The LOB recreation model (LOBRM) was recently proposed to
bridge this gap by synthesizing the LOB from trades and quotes (TAQ) data.
However, in the original LOBRM study, there were two limitations: (1)
experiments were conducted on a relatively small dataset containing only one
day of LOB data; and (2) the training and testing were performed in a
non-chronological fashion, which essentially re-frames the task as
interpolation and potentially introduces lookahead bias. In this study, we
extend the research on LOBRM and further validate its use in real-world
application scenarios. We first advance the workflow of LOBRM by (1) adding a
time-weighted z-score standardization for the LOB and (2) substituting the
ordinary differential equation kernel with an exponential decay kernel to lower
computation complexity. Experiments are conducted on the extended LOBSTER
dataset in a chronological fashion, as it would be used in a real-world
application. We find that (1) LOBRM with decay kernel is superior to
traditional non-linear models, and module ensembling is effective; (2)
prediction accuracy is negatively related to the volatility of order volumes
resting in the LOB; (3) the proposed sparse encoding method for TAQ exhibits
good generalization ability and can facilitate manifold tasks; and (4) the
influence of stochastic drift on prediction accuracy can be alleviated by
increasing historical samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving black-box optimization in VAE latent space using decoder uncertainty. (arXiv:2107.00096v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Notin_P/0/1/0/all/0/1">Pascal Notin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1">Jos&#xe9; Miguel Hern&#xe1;ndez-Lobato</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00096">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization in the latent space of variational autoencoders is a promising
approach to generate high-dimensional discrete objects that maximize an
expensive black-box property (e.g., drug-likeness in molecular generation,
function approximation with arithmetic expressions). However, existing methods
lack robustness as they may decide to explore areas of the latent space for
which no data was available during training and where the decoder can be
unreliable, leading to the generation of unrealistic or invalid objects. We
propose to leverage the epistemic uncertainty of the decoder to guide the
optimization process. This is not trivial though, as a naive estimation of
uncertainty in the high-dimensional and structured settings we consider would
result in high estimator variance. To solve this problem, we introduce an
importance sampling-based estimator that provides more robust estimates of
epistemic uncertainty. Our uncertainty-guided optimization approach does not
require modifications of the model architecture nor the training process. It
produces samples with a better trade-off between black-box objective and
validity of the generated samples, sometimes improving both simultaneously. We
illustrate these advantages across several experimental settings in digit
generation, arithmetic expression approximation and molecule generation for
drug design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Byzantine-Robust Learning on Heterogeneous Datasets via Resampling. (arXiv:2006.09365v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1">Sai Praneeth Karimireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lie He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09365">
                                    <div class="article-summary-box-inner">
                                        <span>In Byzantine robust distributed or federated learning, a central server wants
to train a machine learning model over data distributed across multiple
workers. However, a fraction of these workers may deviate from the prescribed
algorithm and send arbitrary messages. While this problem has received
significant attention recently, most current defenses assume that the workers
have identical data. For realistic cases when the data across workers are
heterogeneous (non-iid), we design new attacks which circumvent current
defenses, leading to significant loss of performance. We then propose a simple
resampling scheme that adapts existing robust algorithms to heterogeneous
datasets at a negligible computational cost. We also theoretically and
experimentally validate our approach, showing that combining resampling with
existing robust algorithms is effective against challenging attacks. Our work
is the first to establish guaranteed convergence for the non-iid Byzantine
robust problem under realistic assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Dependency Parsing for Semi-Structured Document Information Extraction. (arXiv:2005.00642v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonseok Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yim_J/0/1/0/all/0/1">Jinyeong Yim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sohee Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1">Minjoon Seo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00642">
                                    <div class="article-summary-box-inner">
                                        <span>Information Extraction (IE) for semi-structured document images is often
approached as a sequence tagging problem by classifying each recognized input
token into one of the IOB (Inside, Outside, and Beginning) categories. However,
such problem setup has two inherent limitations that (1) it cannot easily
handle complex spatial relationships and (2) it is not suitable for highly
structured information, which are nevertheless frequently observed in
real-world document images. To tackle these issues, we first formulate the IE
task as spatial dependency parsing problem that focuses on the relationship
among text tokens in the documents. Under this setup, we then propose SPADE
(SPAtial DEpendency parser) that models highly complex spatial relationships
and an arbitrary number of information layers in the documents in an end-to-end
manner. We evaluate it on various kinds of documents such as receipts, name
cards, forms, and invoices, and show that it achieves a similar or better
performance compared to strong baselines including BERT-based IOB taggger.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Which Echo Chamber? Regions of Attraction in Learning with Decision-Dependent Distributions. (arXiv:2107.00055v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1">Roy Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1">Lillian J. Ratliff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00055">
                                    <div class="article-summary-box-inner">
                                        <span>As data-driven methods are deployed in real-world settings, the processes
that generate the observed data will often react to the decisions of the
learner. For example, a data source may have some incentive for the algorithm
to provide a particular label (e.g. approve a bank loan), and manipulate their
features accordingly. Work in strategic classification and decision-dependent
distributions seeks to characterize the closed-loop behavior of deploying
learning algorithms by explicitly considering the effect of the classifier on
the underlying data distribution. More recently, works in performative
prediction seek to classify the closed-loop behavior by considering general
properties of the mapping from classifier to data distribution, rather than an
explicit form. Building on this notion, we analyze repeated risk minimization
as the perturbed trajectories of the gradient flows of performative risk
minimization. We consider the case where there may be multiple local minimizers
of performative risk, motivated by real world situations where the initial
conditions may have significant impact on the long-term behavior of the system.
As a motivating example, we consider a company whose current employee
demographics affect the applicant pool they interview: the initial demographics
of the company can affect the long-term hiring policies of the company. We
provide sufficient conditions to characterize the region of attraction for the
various equilibria in this settings. Additionally, we introduce the notion of
performative alignment, which provides a geometric condition on the convergence
of repeated risk minimization to performative risk minimizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Asymmetric Learning in POMDPs. (arXiv:2012.15566v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Warrington_A/0/1/0/all/0/1">Andrew Warrington</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavington_J/0/1/0/all/0/1">J. Wilder Lavington</a>, <a href="http://arxiv.org/find/cs/1/au:+Scibior_A/0/1/0/all/0/1">Adam &#x15a;cibior</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1">Mark Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1">Frank Wood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15566">
                                    <div class="article-summary-box-inner">
                                        <span>Policies for partially observed Markov decision processes can be efficiently
learned by imitating policies for the corresponding fully observed Markov
decision processes. Unfortunately, existing approaches for this kind of
imitation learning have a serious flaw: the expert does not know what the
trainee cannot see, and so may encourage actions that are sub-optimal, even
unsafe, under partial information. We derive an objective to instead train the
expert to maximize the expected reward of the imitating agent policy, and use
it to construct an efficient algorithm, adaptive asymmetric DAgger (A2D), that
jointly trains the expert and the agent. We show that A2D produces an expert
policy that the agent can safely imitate, in turn outperforming policies
learned by imitating a fixed expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Markov Decision Process modeled with Bandits for Sequential Decision Making in Linear-flow. (arXiv:2107.00204v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00204">
                                    <div class="article-summary-box-inner">
                                        <span>In membership/subscriber acquisition and retention, we sometimes need to
recommend marketing content for multiple pages in sequence. Different from
general sequential decision making process, the use cases have a simpler flow
where customers per seeing recommended content on each page can only return
feedback as moving forward in the process or dropping from it until a
termination state. We refer to this type of problems as sequential decision
making in linear--flow. We propose to formulate the problem as an MDP with
Bandits where Bandits are employed to model the transition probability matrix.
At recommendation time, we use Thompson sampling (TS) to sample the transition
probabilities and allocate the best series of actions with analytical solution
through exact dynamic programming. The way that we formulate the problem allows
us to leverage TS&#x27;s efficiency in balancing exploration and exploitation and
Bandit&#x27;s convenience in modeling actions&#x27; incompatibility. In the simulation
study, we observe the proposed MDP with Bandits algorithm outperforms
Q-learning with $\epsilon$-greedy and decreasing $\epsilon$, independent
Bandits, and interaction Bandits. We also find the proposed algorithm&#x27;s
performance is the most robust to changes in the across-page interdependence
strength.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Riemannian Manifolds for Geodesic Motion Skills. (arXiv:2106.04315v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beik_Mohammadi_H/0/1/0/all/0/1">Hadi Beik-Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1">Georgios Arvanitidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1">Leonel Rozo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04315">
                                    <div class="article-summary-box-inner">
                                        <span>For robots to work alongside humans and perform in unstructured environments,
they must learn new motion skills and adapt them to unseen situations on the
fly. This demands learning models that capture relevant motion patterns, while
offering enough flexibility to adapt the encoded skills to new requirements,
such as dynamic obstacle avoidance. We introduce a Riemannian manifold
perspective on this problem, and propose to learn a Riemannian manifold from
human demonstrations on which geodesics are natural motion skills. We realize
this with a variational autoencoder (VAE) over the space of position and
orientations of the robot end-effector. Geodesic motion skills let a robot plan
movements from and to arbitrary points on the data manifold. They also provide
a straightforward method to avoid obstacles by redefining the ambient metric in
an online fashion. Moreover, geodesics naturally exploit the manifold resulting
from multiple--mode tasks to design motions that were not explicitly
demonstrated previously. We test our learning framework using a 7-DoF robotic
manipulator, where the robot satisfactorily learns and reproduces realistic
skills featuring elaborated motion patterns, avoids previously unseen
obstacles, and generates novel movements in multiple-mode settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth Games: Convergence Analysis under Expected Co-coercivity. (arXiv:2107.00052v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loizou_N/0/1/0/all/0/1">Nicolas Loizou</a>, <a href="http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1">Hugo Berard</a>, <a href="http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1">Ioannis Mitliagkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00052">
                                    <div class="article-summary-box-inner">
                                        <span>Two of the most prominent algorithms for solving unconstrained smooth games
are the classical stochastic gradient descent-ascent (SGDA) and the recently
introduced stochastic consensus optimization (SCO) (Mescheder et al., 2017).
SGDA is known to converge to a stationary point for specific classes of games,
but current convergence analyses require a bounded variance assumption. SCO is
used successfully for solving large-scale adversarial problems, but its
convergence guarantees are limited to its deterministic variant. In this work,
we introduce the expected co-coercivity condition, explain its benefits, and
provide the first last-iterate convergence guarantees of SGDA and SCO under
this condition for solving a class of stochastic variational inequality
problems that are potentially non-monotone. We prove linear convergence of both
methods to a neighborhood of the solution when they use constant step-size, and
we propose insightful stepsize-switching rules to guarantee convergence to the
exact solution. In addition, our convergence guarantees hold under the
arbitrary sampling paradigm, and as such, we give insights into the complexity
of minibatching.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Measuring Bias in Image Classification. (arXiv:2107.00360v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schaaf_N/0/1/0/all/0/1">Nina Schaaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitri_O/0/1/0/all/0/1">Omar de Mitri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hang Beom Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Windberger_A/0/1/0/all/0/1">Alexander Windberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Huber_M/0/1/0/all/0/1">Marco F. Huber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00360">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNN) have become de fact state-of-the-art for
the main computer vision tasks. However, due to the complex underlying
structure their decisions are hard to understand which limits their use in some
context of the industrial world. A common and hard to detect challenge in
machine learning (ML) tasks is data bias. In this work, we present a systematic
approach to uncover data bias by means of attribution maps. For this purpose,
first an artificial dataset with a known bias is created and used to train
intentionally biased CNNs. The networks&#x27; decisions are then inspected using
attribution maps. Finally, meaningful metrics are used to measure the
attribution maps&#x27; representativeness with respect to the known bias. The
proposed study shows that some attribution map techniques highlight the
presence of bias in the data better than others and metrics can support the
identification of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simple Generative Network. (arXiv:2106.09330v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nissani_D/0/1/0/all/0/1">Daniel N. Nissani</a> (Nissensohn)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09330">
                                    <div class="article-summary-box-inner">
                                        <span>Generative neural networks are able to mimic intricate probability
distributions such as those of handwritten text, natural images, etc. Since
their inception several models were proposed. The most successful of these were
based on adversarial (GAN), auto-encoding (VAE) and maximum mean discrepancy
(MMD) relatively complex architectures and schemes. Surprisingly, a very simple
architecture (a single feed-forward neural network) in conjunction with an
obvious optimization goal (Kullback_Leibler divergence) was apparently
overlooked. This paper demonstrates that such a model (denoted SGN for its
simplicity) is able to generate samples visually and quantitatively competitive
as compared with the fore-mentioned state of the art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gym-$\mu$RTS: Toward Affordable Full Game Real-time Strategy Games Research with Deep Reinforcement Learning. (arXiv:2105.13807v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Onta&#xf1;&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamford_C/0/1/0/all/0/1">Chris Bamford</a>, <a href="http://arxiv.org/find/cs/1/au:+Grela_L/0/1/0/all/0/1">Lukasz Grela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13807">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, researchers have achieved great success in applying Deep
Reinforcement Learning (DRL) algorithms to Real-time Strategy (RTS) games,
creating strong autonomous agents that could defeat professional players in
StarCraft~II. However, existing approaches to tackle full games have high
computational costs, usually requiring the use of thousands of GPUs and CPUs
for weeks. This paper has two main contributions to address this issue: 1) We
introduce Gym-$\mu$RTS (pronounced &quot;gym-micro-RTS&quot;) as a fast-to-run RL
environment for full-game RTS research and 2) we present a collection of
techniques to scale DRL to play full-game $\mu$RTS as well as ablation studies
to demonstrate their empirical importance. Our best-trained bot can defeat
every $\mu$RTS bot we tested from the past $\mu$RTS competitions when working
in a single-map setting, resulting in a state-of-the-art DRL agent while only
taking about 60 hours of training using a single machine (one GPU, three vCPU,
16GB RAM).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Reversible Embedding Mapping using Bi-Directional Manifold Alignment. (arXiv:2107.00124v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesan_A/0/1/0/all/0/1">Ashwinkumar Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferraro_F/0/1/0/all/0/1">Francis Ferraro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oates_T/0/1/0/all/0/1">Tim Oates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00124">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a Bi-Directional Manifold Alignment (BDMA) that learns a
non-linear mapping between two manifolds by explicitly training it to be
bijective. We demonstrate BDMA by training a model for a pair of languages
rather than individual, directed source and target combinations, reducing the
number of models by 50%. We show that models trained with BDMA in the &quot;forward&quot;
(source to target) direction can successfully map words in the &quot;reverse&quot;
(target to source) direction, yielding equivalent (or better) performance to
standard unidirectional translation models where the source and target language
is flipped. We also show how BDMA reduces the overall size of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel Predictive Entropy Search for Multi-objective Bayesian Optimization with Constraints. (arXiv:2004.00601v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Garrido_Merchan_E/0/1/0/all/0/1">Eduardo C. Garrido-Merch&#xe1;n</a>, <a href="http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1">Daniel Hern&#xe1;ndez-Lobato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.00601">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world problems often involve the optimization of several objectives
under multiple constraints. An example is the hyper-parameter tuning problem of
machine learning algorithms. In particular, the minimization of the estimation
of the generalization error of a deep neural network and at the same time the
minimization of its prediction time. We may also consider as a constraint that
the deep neural network must be implemented in a chip with an area below some
size. Here, both the objectives and the constraint are black boxes, i.e.,
functions whose analytical expressions are unknown and are expensive to
evaluate. Bayesian optimization (BO) methodologies have given state-of-the-art
results for the optimization of black-boxes. Nevertheless, most BO methods are
sequential and evaluate the objectives and the constraints at just one input
location, iteratively. Sometimes, however, we may have resources to evaluate
several configurations in parallel. Notwithstanding, no parallel BO method has
been proposed to deal with the optimization of multiple objectives under
several constraints. If the expensive evaluations can be carried out in
parallel (as when a cluster of computers is available), sequential evaluations
result in a waste of resources. This article introduces PPESMOC, Parallel
Predictive Entropy Search for Multi-objective Bayesian Optimization with
Constraints, an information-based batch method for the simultaneous
optimization of multiple expensive-to-evaluate black-box functions under the
presence of several constraints. Iteratively, PPESMOC selects a batch of input
locations at which to evaluate the black-boxes so as to maximally reduce the
entropy of the Pareto set of the optimization problem. We present empirical
evidence in the form of synthetic, benchmark and real-world experiments that
illustrate the effectiveness of PPESMOC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Certified $\ell_\infty$ Robustness with EMA Method and Ensemble Model. (arXiv:2107.00230v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Binghui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_S/0/1/0/all/0/1">Shiji Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qizhe Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00230">
                                    <div class="article-summary-box-inner">
                                        <span>The neural network with $1$-Lipschitz property based on $\ell_\infty$-dist
neuron has a theoretical guarantee in certified $\ell_\infty$ robustness.
However, due to the inherent difficulties in the training of the network, the
certified accuracy of previous work is limited. In this paper, we propose two
approaches to deal with these difficuties. Aiming at the characteristics of the
training process based on $\ell_\infty$-norm neural network, we introduce the
EMA method to improve the training process. Considering the randomness of the
training algorithm, we propose an ensemble method based on trained base models
that have the $1$-Lipschitz property and gain significant improvement in the
small parameter network. Moreover, we give the theoretical analysis of the
ensemble method based on the $1$-Lipschitz property on the certified
robustness, which ensures the effectiveness and stability of the algorithm. Our
code is available at
https://github.com/Theia-4869/EMA-and-Ensemble-Lip-Networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From DNNs to GANs: Review of efficient hardware architectures for deep learning. (arXiv:2107.00092v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_G/0/1/0/all/0/1">Gaurab Bhattacharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00092">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, the trend in very large scale integration (VLSI) industry is
multi-dimensional, for example, reduction of energy consumption, occupancy of
less space, precise result, less power dissipation, faster response. To meet
these needs, the hardware architecture should be reliable and robust to these
problems. Recently, neural network and deep learning has been started to impact
the present research paradigm significantly which consists of parameters in the
order of millions, nonlinear function for activation, convolutional operation
for feature extraction, regression for classification, generative adversarial
networks. These operations involve huge calculation and memory overhead.
Presently available DSP processors are incapable of performing these operations
and they mostly face the problems, for example, memory overhead, performance
drop and compromised accuracy. Moreover, if a huge silicon area is powered to
accelerate the operation using parallel computation, the ICs will be having
significant chance of burning out due to the considerable generation of heat.
Hence, novel dark silicon constraint is developed to reduce the heat
dissipation without sacrificing the accuracy. Similarly, different algorithms
have been adapted to design a DSP processor compatible for fast performance in
neural network, activation function, convolutional neural network and
generative adversarial network. In this review, we illustrate the recent
developments in hardware for accelerating the efficient implementation of deep
learning networks with enhanced performance. The techniques investigated in
this review are expected to direct future research challenges of hardware
optimization for high-performance computations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Graph-Based Deep Learning for Computational Histopathology. (arXiv:2107.00272v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmedt_Aristizabal_D/0/1/0/all/0/1">David Ahmedt-Aristizabal</a>, <a href="http://arxiv.org/find/cs/1/au:+Armin_M/0/1/0/all/0/1">Mohammad Ali Armin</a>, <a href="http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1">Simon Denman</a>, <a href="http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1">Clinton Fookes</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersson_L/0/1/0/all/0/1">Lars Petersson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00272">
                                    <div class="article-summary-box-inner">
                                        <span>With the remarkable success of representation learning for prediction
problems, we have witnessed a rapid expansion of the use of machine learning
and deep learning for the analysis of digital pathology and biopsy image
patches. However, traditional learning over patch-wise features using
convolutional neural networks limits the model when attempting to capture
global contextual information. The phenotypical and topological distribution of
constituent histological entities play a critical role in tissue diagnosis. As
such, graph data representations and deep learning have attracted significant
attention for encoding tissue representations, and capturing intra- and inter-
entity level interactions. In this review, we provide a conceptual grounding of
graph-based deep learning and discuss its current success for tumor
localization and classification, tumor invasion and staging, image retrieval,
and survival prediction. We provide an overview of these methods in a
systematic manner organized by the graph representation of the input image
including whole slide images and tissue microarrays. We also outline the
limitations of existing techniques, and suggest potential future advances in
this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Execution for Neural Program Synthesis Beyond Domain-Specific Languages. (arXiv:2107.00101v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuandong Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00101">
                                    <div class="article-summary-box-inner">
                                        <span>Program synthesis from input-output examples has been a long-standing
challenge, and recent works have demonstrated some success in designing deep
neural networks for program synthesis. However, existing efforts in
input-output neural program synthesis have been focusing on domain-specific
languages, thus the applicability of previous approaches to synthesize code in
full-fledged popular programming languages, such as C, remains a question. The
main challenges lie in two folds. On the one hand, the program search space
grows exponentially when the syntax and semantics of the programming language
become more complex, which poses higher requirements on the synthesis
algorithm. On the other hand, increasing the complexity of the programming
language also imposes more difficulties on data collection, since building a
large-scale training set for input-output program synthesis require random
program generators to sample programs and input-output examples. In this work,
we take the first step to synthesize C programs from input-output examples. In
particular, we propose LaSynth, which learns the latent representation to
approximate the execution of partially generated programs, even if their
semantics are not well-defined. We demonstrate the possibility of synthesizing
elementary C code from input-output examples, and leveraging learned execution
significantly improves the prediction performance over existing approaches.
Meanwhile, compared to the randomly generated ground-truth programs, LaSynth
synthesizes more concise programs that resemble human-written code. We show
that training on these synthesized programs further improves the prediction
performance for both Karel and C program synthesis, indicating the promise of
leveraging the learned program synthesizer to improve the dataset quality for
input-output program synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Certified Segmentation via Randomized Smoothing. (arXiv:2107.00228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1">Marc Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1">Maximilian Baader</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00228">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new certification method for image and point cloud segmentation
based on randomized smoothing. The method leverages a novel scalable algorithm
for prediction and certification that correctly accounts for multiple testing,
necessary for ensuring statistical guarantees. The key to our approach is
reliance on established multiple-testing correction mechanisms as well as the
ability to abstain from classifying single pixels or points while still
robustly segmenting the overall input. Our experimental evaluation on synthetic
data and challenging datasets, such as Pascal Context, Cityscapes, and
ShapeNet, shows that our algorithm can achieve, for the first time, competitive
accuracy and certification guarantees on real-world segmentation tasks. We
provide an implementation at https://github.com/eth-sri/segmentation-smoothing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dep-$L_0$: Improving $L_0$-based Network Sparsification via Dependency Modeling. (arXiv:2107.00070v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00070">
                                    <div class="article-summary-box-inner">
                                        <span>Training deep neural networks with an $L_0$ regularization is one of the
prominent approaches for network pruning or sparsification. The method prunes
the network during training by encouraging weights to become exactly zero.
However, recent work of Gale et al. reveals that although this method yields
high compression rates on smaller datasets, it performs inconsistently on
large-scale learning tasks, such as ResNet50 on ImageNet. We analyze this
phenomenon through the lens of variational inference and find that it is likely
due to the independent modeling of binary gates, the mean-field approximation,
which is known in Bayesian statistics for its poor performance due to the crude
approximation. To mitigate this deficiency, we propose a dependency modeling of
binary gates, which can be modeled effectively as a multi-layer perceptron
(MLP). We term our algorithm Dep-$L_0$ as it prunes networks via a
dependency-enabled $L_0$ regularization. Extensive experiments on CIFAR10,
CIFAR100 and ImageNet with VGG16, ResNet50, ResNet56 show that our Dep-$L_0$
outperforms the original $L_0$-HC algorithm of Louizos et al. by a significant
margin, especially on ImageNet. Compared with the state-of-the-arts network
sparsification algorithms, our dependency modeling makes the $L_0$-based
sparsification once again very competitive on large-scale learning tasks. Our
source code is available at https://github.com/leo-yangli/dep-l0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-parametric Active Learning and Rate Reduction in Many-body Hilbert Space with Rescaled Logarithmic Fidelity. (arXiv:2107.00195v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Li_W/0/1/0/all/0/1">Wei-Ming Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00195">
                                    <div class="article-summary-box-inner">
                                        <span>In quantum and quantum-inspired machine learning, the very first step is to
embed the data in quantum space known as Hilbert space. Developing quantum
kernel function (QKF), which defines the distances among the samples in the
Hilbert space, belongs to the fundamental topics for machine learning. In this
work, we propose the rescaled logarithmic fidelity (RLF) and a non-parametric
active learning in the quantum space, which we name as RLF-NAL. The rescaling
takes advantage of the non-linearity of the kernel to tune the mutual distances
of samples in the Hilbert space, and meanwhile avoids the exponentially-small
fidelities between quantum many-qubit states. We compare RLF-NAL with several
well-known non-parametric algorithms including naive Bayes classifiers,
$k$-nearest neighbors, and spectral clustering. Our method exhibits excellent
accuracy particularly for the unsupervised case with no labeled samples and the
few-shot cases with small numbers of labeled samples. With the visualizations
by t-SNE, our results imply that the machine learning in the Hilbert space
complies with the principles of maximal coding rate reduction, where the
low-dimensional data exhibit within-class compressibility, between-class
discrimination, and overall diversity. Our proposals can be applied to other
quantum and quantum-inspired machine learning, including the methods using the
parametric models such as tensor networks, quantum circuits, and quantum neural
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reducing the Variance of Gaussian Process Hyperparameter Optimization with Preconditioning. (arXiv:2107.00243v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wenger_J/0/1/0/all/0/1">Jonathan Wenger</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1">Jacob R. Gardner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00243">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes remain popular as a flexible and expressive model class,
but the computational cost of kernel hyperparameter optimization stands as a
major limiting factor to their scaling and broader adoption. Recent work has
made great strides combining stochastic estimation with iterative numerical
techniques, essentially boiling down GP inference to the cost of (many)
matrix-vector multiplies. Preconditioning -- a highly effective step for any
iterative method involving matrix-vector multiplication -- can be used to
accelerate convergence and thus reduce bias in hyperparameter optimization.
Here, we prove that preconditioning has an additional benefit that has been
previously unexplored. It not only reduces the bias of the $\log$-marginal
likelihood estimator and its derivatives, but it also simultaneously can reduce
variance at essentially negligible cost. We leverage this result to derive
sample-efficient algorithms for GP hyperparameter optimization requiring as few
as $\mathcal{O}(\log(\varepsilon^{-1}))$ instead of
$\mathcal{O}(\varepsilon^{-2})$ samples to achieve error $\varepsilon$. Our
theoretical results enable provably efficient and scalable optimization of
kernel hyperparameters, which we validate empirically on a set of large-scale
benchmark problems. There, variance reduction via preconditioning results in an
order of magnitude speedup in hyperparameter optimization of exact GPs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Momentum-inspired Low-Rank Coordinate Descent for Diagonally Constrained SDPs. (arXiv:2106.08775v1 [math.OC] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kim_J/0/1/0/all/0/1">Junhyung Lyle Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Benitez_J/0/1/0/all/0/1">Jose Antonio Lara Benitez</a>, <a href="http://arxiv.org/find/math/1/au:+Toghani_M/0/1/0/all/0/1">Mohammad Taha Toghani</a>, <a href="http://arxiv.org/find/math/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron Wolfe</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08775">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel, practical, and provable approach for solving diagonally
constrained semi-definite programming (SDP) problems at scale using accelerated
non-convex programming. Our algorithm non-trivially combines acceleration
motions from convex optimization with coordinate power iteration and matrix
factorization techniques. The algorithm is extremely simple to implement, and
adds only a single extra hyperparameter -- momentum. We prove that our method
admits local linear convergence in the neighborhood of the optimum and always
converges to a first-order critical point. Experimentally, we showcase the
merits of our method on three major application domains: MaxCut, MaxSAT, and
MIMO signal detection. In all cases, our methodology provides significant
speedups over non-convex and convex SDP solvers -- 5X faster than
state-of-the-art non-convex solvers, and 9 to 10^3 X faster than convex SDP
solvers -- with comparable or improved solution quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ControlBurn: Feature Selection by Sparse Forests. (arXiv:2107.00219v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Brian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1">Miaolan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Udell_M/0/1/0/all/0/1">Madeleine Udell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00219">
                                    <div class="article-summary-box-inner">
                                        <span>Tree ensembles distribute feature importance evenly amongst groups of
correlated features. The average feature ranking of the correlated group is
suppressed, which reduces interpretability and complicates feature selection.
In this paper we present ControlBurn, a feature selection algorithm that uses a
weighted LASSO-based feature selection method to prune unnecessary features
from tree ensembles, just as low-intensity fire reduces overgrown vegetation.
Like the linear LASSO, ControlBurn assigns all the feature importance of a
correlated group of features to a single feature. Moreover, the algorithm is
efficient and only requires a single training iteration to run, unlike
iterative wrapper-based feature selection methods. We show that ControlBurn
performs substantially better than feature selection methods with comparable
computational costs on datasets with correlated features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Knowledge Distillation: An Inheritance and Exploration Framework. (arXiv:2107.00181v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_J/0/1/0/all/0/1">Jun Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xinmei Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Houqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Bing Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00181">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Distillation (KD) is a popular technique to transfer knowledge from
a teacher model or ensemble to a student model. Its success is generally
attributed to the privileged information on similarities/consistency between
the class distributions or intermediate feature representations of the teacher
model and the student model. However, directly pushing the student model to
mimic the probabilities/features of the teacher model to a large extent limits
the student model in learning undiscovered knowledge/features. In this paper,
we propose a novel inheritance and exploration knowledge distillation framework
(IE-KD), in which a student model is split into two parts - inheritance and
exploration. The inheritance part is learned with a similarity loss to transfer
the existing learned knowledge from the teacher model to the student model,
while the exploration part is encouraged to learn representations different
from the inherited ones with a dis-similarity loss. Our IE-KD framework is
generic and can be easily combined with existing distillation or mutual
learning methods for training deep neural networks. Extensive experiments
demonstrate that these two parts can jointly push the student model to learn
more diversified and effective representations, and our IE-KD can be a general
technique to improve the student network to achieve SOTA performance.
Furthermore, by applying our IE-KD to the training of two networks, the
performance of both can be improved w.r.t. deep mutual learning. The code and
models of IE-KD will be make publicly available at
https://github.com/yellowtownhz/IE-KD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Coreset for Continuous-and-Bounded Learning (with Outliers). (arXiv:2107.00068v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zixiu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yiwen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Hu Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00068">
                                    <div class="article-summary-box-inner">
                                        <span>In this big data era, we often confront large-scale data in many machine
learning tasks. A common approach for dealing with large-scale data is to build
a small summary, {\em e.g.,} coreset, that can efficiently represent the
original input. However, real-world datasets usually contain outliers and most
existing coreset construction methods are not resilient against outliers (in
particular, the outliers can be located arbitrarily in the space by an
adversarial attacker). In this paper, we propose a novel robust coreset method
for the {\em continuous-and-bounded learning} problem (with outliers) which
includes a broad range of popular optimization objectives in machine learning,
like logistic regression and $ k $-means clustering. Moreover, our robust
coreset can be efficiently maintained in fully-dynamic environment. To the best
of our knowledge, this is the first robust and fully-dynamic coreset
construction method for these optimization problems. We also conduct the
experiments to evaluate the effectiveness of our robust coreset in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Mediated Teleoperation with a Hand-Arm Exoskeleton in Long Time Delays Using Reinforcement Learning. (arXiv:2107.00359v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beik_Mohammadi_H/0/1/0/all/0/1">Hadi Beik-Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerzel_M/0/1/0/all/0/1">Matthias Kerzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pleintinger_B/0/1/0/all/0/1">Benedikt Pleintinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hulin_T/0/1/0/all/0/1">Thomas Hulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Reisich_P/0/1/0/all/0/1">Philipp Reisich</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_A/0/1/0/all/0/1">Annika Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_A/0/1/0/all/0/1">Aaron Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1">Stefan Wermter</a>, <a href="http://arxiv.org/find/cs/1/au:+Lii_N/0/1/0/all/0/1">Neal Y. Lii</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00359">
                                    <div class="article-summary-box-inner">
                                        <span>Telerobotic systems must adapt to new environmental conditions and deal with
high uncertainty caused by long-time delays. As one of the best alternatives to
human-level intelligence, Reinforcement Learning (RL) may offer a solution to
cope with these issues. This paper proposes to integrate RL with the Model
Mediated Teleoperation (MMT) concept. The teleoperator interacts with a
simulated virtual environment, which provides instant feedback. Whereas
feedback from the real environment is delayed, feedback from the model is
instantaneous, leading to high transparency. The MMT is realized in combination
with an intelligent system with two layers. The first layer utilizes Dynamic
Movement Primitives (DMP) which accounts for certain changes in the avatar
environment. And, the second layer addresses the problems caused by uncertainty
in the model using RL methods. Augmented reality was also provided to fuse the
avatar device and virtual environment models for the teleoperator. Implemented
on DLR&#x27;s Exodex Adam hand-arm haptic exoskeleton, the results show RL methods
are able to find different solutions when changes are applied to the object
position after the demonstration. The results also show DMPs to be effective at
adapting to new conditions where there is no uncertainty involved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DivergentNets: Medical Image Segmentation by Network Ensemble. (arXiv:2107.00283v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thambawita_V/0/1/0/all/0/1">Vajira Thambawita</a>, <a href="http://arxiv.org/find/eess/1/au:+Hicks_S/0/1/0/all/0/1">Steven A. Hicks</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00283">
                                    <div class="article-summary-box-inner">
                                        <span>Detection of colon polyps has become a trending topic in the intersecting
fields of machine learning and gastrointestinal endoscopy. The focus has mainly
been on per-frame classification. More recently, polyp segmentation has gained
attention in the medical community. Segmentation has the advantage of being
more accurate than per-frame classification or object detection as it can show
the affected area in greater detail. For our contribution to the EndoCV 2021
segmentation challenge, we propose two separate approaches. First, a
segmentation model named TriUNet composed of three separate UNet models.
Second, we combine TriUNet with an ensemble of well-known segmentation models,
namely UNet++, FPN, DeepLabv3, and DeepLabv3+, into a model called
DivergentNets to produce more generalizable medical image segmentation masks.
In addition, we propose a modified Dice loss that calculates loss only for a
single class when performing multiclass segmentation, forcing the model to
focus on what is most important. Overall, the proposed methods achieved the
best average scores for each respective round in the challenge, with TriUNet
being the winning model in Round I and DivergentNets being the winning model in
Round II of the segmentation generalization challenge at EndoCV 2021. The
implementation of our approach is made publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning and Deep Learning for Fixed-Text Keystroke Dynamics. (arXiv:2107.00507v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Han-Chih Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Ching-Seh Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1">Mark Stamp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00507">
                                    <div class="article-summary-box-inner">
                                        <span>Keystroke dynamics can be used to analyze the way that users type by
measuring various aspects of keyboard input. Previous work has demonstrated the
feasibility of user authentication and identification utilizing keystroke
dynamics. In this research, we consider a wide variety of machine learning and
deep learning techniques based on fixed-text keystroke-derived features, we
optimize the resulting models, and we compare our results to those obtained in
related research. We find that models based on extreme gradient boosting
(XGBoost) and multi-layer perceptrons (MLP)perform well in our experiments. Our
best models outperform previous comparable research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Conditioned Reinforcement Learning with Imagined Subgoals. (arXiv:2107.00541v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chane_Sane_E/0/1/0/all/0/1">Elliot Chane-Sane</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1">Cordelia Schmid</a>, <a href="http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1">Ivan Laptev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00541">
                                    <div class="article-summary-box-inner">
                                        <span>Goal-conditioned reinforcement learning endows an agent with a large variety
of skills, but it often struggles to solve tasks that require more temporally
extended reasoning. In this work, we propose to incorporate imagined subgoals
into policy learning to facilitate learning of complex tasks. Imagined subgoals
are predicted by a separate high-level policy, which is trained simultaneously
with the policy and its critic. This high-level policy predicts intermediate
states halfway to the goal using the value function as a reachability metric.
We don&#x27;t require the policy to reach these subgoals explicitly. Instead, we use
them to define a prior policy, and incorporate this prior into a KL-constrained
policy iteration scheme to speed up and regularize learning. Imagined subgoals
are used during policy learning, but not during test time, where we only apply
the learned policy. We evaluate our approach on complex robotic navigation and
manipulation tasks and show that it outperforms existing methods by a large
margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Interplay between Distribution Parameters and the Accuracy-Robustness Tradeoff in Classification. (arXiv:2107.00247v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hosseini_A/0/1/0/all/0/1">Alireza Mousavi Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Abouei_A/0/1/0/all/0/1">Amir Mohammad Abouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohban_M/0/1/0/all/0/1">Mohammad Hossein Rohban</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00247">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training tends to result in models that are less accurate on
natural (unperturbed) examples compared to standard models. This can be
attributed to either an algorithmic shortcoming or a fundamental property of
the training data distribution, which admits different solutions for optimal
standard and adversarial classifiers. In this work, we focus on the latter case
under a binary Gaussian mixture classification problem. Unlike earlier work, we
aim to derive the natural accuracy gap between the optimal Bayes and
adversarial classifiers, and study the effect of different distributional
parameters, namely separation between class centroids, class proportions, and
the covariance matrix, on the derived gap. We show that under certain
conditions, the natural error of the optimal adversarial classifier, as well as
the gap, are locally minimized when classes are balanced, contradicting the
performance of the Bayes classifier where perfect balance induces the worst
accuracy. Moreover, we show that with an $\ell_\infty$ bounded perturbation and
an adversarial budget of $\epsilon$, this gap is $\Theta(\epsilon^2)$ for the
worst-case parameters, which for suitably small $\epsilon$ indicates the
theoretical possibility of achieving robust classifiers with near-perfect
accuracy, which is rarely reflected in practical algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Graph Learning for Disease Prediction. (arXiv:2107.00206v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenfeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00206">
                                    <div class="article-summary-box-inner">
                                        <span>Benefiting from the powerful expressive capability of graphs, graph-based
approaches have achieved impressive performance in various biomedical
applications. Most existing methods tend to define the adjacency matrix among
samples manually based on meta-features, and then obtain the node embeddings
for downstream tasks by Graph Representation Learning (GRL). However, it is not
easy for these approaches to generalize to unseen samples. Meanwhile, the
complex correlation between modalities is also ignored. As a result, these
factors inevitably yield the inadequacy of providing valid information about
the patient&#x27;s condition for a reliable diagnosis. In this paper, we propose an
end-to-end Multimodal Graph Learning framework (MMGL) for disease prediction.
To effectively exploit the rich information across multi-modality associated
with diseases, amodal-attentional multi-modal fusion is proposed to integrate
the features of each modality by leveraging the correlation and complementarity
between the modalities. Furthermore, instead of defining the adjacency matrix
manually as existing methods, the latent graph structure can be captured
through a novel way of adaptive graph learning. It could be jointly optimized
with the prediction model, thus revealing the intrinsic connections among
samples. Unlike the previous transductive methods, our model is also applicable
to the scenario of inductive learning for those unseen data. An extensive group
of experiments on two disease prediction problems is then carefully designed
and presented, demonstrating that MMGL obtains more favorable performances. In
addition, we also visualize and analyze the learned graph structure to provide
more reliable decision support for doctors in real medical applications and
inspiration for disease research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SparseBERT: Rethinking the Importance Analysis in Self-attention. (arXiv:2102.12871v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Han Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiahui Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaozhe Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1">James T. Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12871">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based models are popularly used in natural language processing
(NLP). Its core component, self-attention, has aroused widespread interest. To
understand the self-attention mechanism, a direct method is to visualize the
attention map of a pre-trained model. Based on the patterns observed, a series
of efficient Transformers with different sparse attention masks have been
proposed. From a theoretical perspective, universal approximability of
Transformer-based models is also recently proved. However, the above
understanding and analysis of self-attention is based on a pre-trained model.
To rethink the importance analysis in self-attention, we study the significance
of different positions in attention matrix during pre-training. A surprising
result is that diagonal elements in the attention map are the least important
compared with other attention positions. We provide a proof showing that these
diagonal elements can indeed be removed without deteriorating model
performance. Furthermore, we propose a Differentiable Attention Mask (DAM)
algorithm, which further guides the design of the SparseBERT. Extensive
experiments verify our interesting findings and illustrate the effect of the
proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Forecasting directional movements of stock prices for intraday trading using LSTM and random forests. (arXiv:2004.10178v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1">Pushpendu Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Neufeld_A/0/1/0/all/0/1">Ariel Neufeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahoo_J/0/1/0/all/0/1">Jajati Keshari Sahoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.10178">
                                    <div class="article-summary-box-inner">
                                        <span>We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as
training methodologies to analyze their effectiveness in forecasting
out-of-sample directional movements of constituent stocks of the S&amp;P 500 from
January 1993 till December 2018 for intraday trading. We introduce a
multi-feature setting consisting not only of the returns with respect to the
closing prices, but also with respect to the opening prices and intraday
returns. As trading strategy, we use Krauss et al. (2017) and Fischer &amp; Krauss
(2018) as benchmark. On each trading day, we buy the 10 stocks with the highest
probability and sell short the 10 stocks with the lowest probability to
outperform the market in terms of intraday returns -- all with equal monetary
weight. Our empirical results show that the multi-feature setting provides a
daily return, prior to transaction costs, of 0.64% using LSTM networks, and
0.54% using random forests. Hence we outperform the single-feature setting in
Fischer &amp; Krauss (2018) and Krauss et al. (2017) consisting only of the daily
returns with respect to the closing prices, having corresponding daily returns
of 0.41% and of 0.39% with respect to LSTM and random forests, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Adversarial Examples Through Deep Neural Network&#x27;s Response Surface and Uncertainty Regions. (arXiv:2107.00003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1">Juan Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_B/0/1/0/all/0/1">Bowei Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamhoua_C/0/1/0/all/0/1">Charles Kamhoua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00003">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network (DNN) is a popular model implemented in many systems to
handle complex tasks such as image classification, object recognition, natural
language processing etc. Consequently DNN structural vulnerabilities become
part of the security vulnerabilities in those systems. In this paper we study
the root cause of DNN adversarial examples. We examine the DNN response surface
to understand its classification boundary. Our study reveals the structural
problem of DNN classification boundary that leads to the adversarial examples.
Existing attack algorithms can generate from a handful to a few hundred
adversarial examples given one clean image. We show there are infinitely many
adversarial images given one clean sample, all within a small neighborhood of
the clean sample. We then define DNN uncertainty regions and show
transferability of adversarial examples is not universal. We also argue that
generalization error, the large sample theoretical guarantee established for
DNN, cannot adequately capture the phenomenon of adversarial examples. We need
new theory to measure DNN robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online learning of windmill time series using Long Short-term Cognitive Networks. (arXiv:2107.00425v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morales_Hernandez_A/0/1/0/all/0/1">Alejandro Morales-Hern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Napoles_G/0/1/0/all/0/1">Gonzalo N&#xe1;poles</a>, <a href="http://arxiv.org/find/cs/1/au:+Jastrzebska_A/0/1/0/all/0/1">Agnieszka Jastrzebska</a>, <a href="http://arxiv.org/find/cs/1/au:+Salgueiro_Y/0/1/0/all/0/1">Yamisleydi Salgueiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Vanhoof_K/0/1/0/all/0/1">Koen Vanhoof</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00425">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting windmill time series is often the basis of other processes such
as anomaly detection, health monitoring, or maintenance scheduling. The amount
of data generated on windmill farms makes online learning the most viable
strategy to follow. Such settings require retraining the model each time a new
batch of data is available. However, update the model with the new information
is often very expensive to perform using traditional Recurrent Neural Networks
(RNNs). In this paper, we use Long Short-term Cognitive Networks (LSTCNs) to
forecast windmill time series in online settings. These recently introduced
neural systems consist of chained Short-term Cognitive Network blocks, each
processing a temporal data chunk. The learning algorithm of these blocks is
based on a very fast, deterministic learning rule that makes LSTCNs suitable
for online learning tasks. The numerical simulations using a case study with
four windmills showed that our approach reported the lowest forecasting errors
with respect to a simple RNN, a Long Short-term Memory, a Gated Recurrent Unit,
and a Hidden Markov Model. What is perhaps more important is that the LSTCN
approach is significantly faster than these state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection. (arXiv:1907.09693v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1">Zeyi Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhaomin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Sixu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Naibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bingsheng He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.09693">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has been a hot research topic in enabling the
collaborative training of machine learning models among different organizations
under the privacy restrictions. As researchers try to support more machine
learning models with different privacy-preserving approaches, there is a
requirement in developing systems and infrastructures to ease the development
of various federated learning algorithms. Similar to deep learning systems such
as PyTorch and TensorFlow that boost the development of deep learning,
federated learning systems (FLSs) are equivalently important, and face
challenges from various aspects such as effectiveness, efficiency, and privacy.
In this survey, we conduct a comprehensive review on federated learning
systems. To achieve smooth flow and guide future research, we introduce the
definition of federated learning systems and analyze the system components.
Moreover, we provide a thorough categorization for federated learning systems
according to six different aspects, including data distribution, machine
learning model, privacy mechanism, communication architecture, scale of
federation and motivation of federation. The categorization can help the design
of federated learning systems as shown in our case studies. By systematically
summarizing the existing federated learning systems, we present the design
factors, case studies, and future research opportunities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Dirichlet-process-means for $f$-separable distortion measures. (arXiv:1901.11331v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_M/0/1/0/all/0/1">Masahiro Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_K/0/1/0/all/0/1">Kazuho Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.11331">
                                    <div class="article-summary-box-inner">
                                        <span>DP-means clustering was obtained as an extension of $K$-means clustering.
While it is implemented with a simple and efficient algorithm, it can estimate
the number of clusters simultaneously. However, DP-means is specifically
designed for the average distortion measure. Therefore, it is vulnerable to
outliers in data, and can cause large maximum distortion in clusters. In this
work, we extend the objective function of the DP-means to $f$-separable
distortion measures and propose a unified learning algorithm to overcome the
above problems by selecting the function $f$. Further, the influence function
of the estimated cluster center is analyzed to evaluate the robustness against
outliers. We demonstrate the performance of the generalized method by numerical
experiments using real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble. (arXiv:2107.00591v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1">Younggyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00591">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advance in deep offline reinforcement learning (RL) has made it
possible to train strong robotic agents from offline datasets. However,
depending on the quality of the trained agents and the application being
considered, it is often desirable to fine-tune such agents via further online
interactions. In this paper, we observe that state-action distribution shift
may lead to severe bootstrap error during fine-tuning, which destroys the good
initial policy obtained via offline RL. To address this issue, we first propose
a balanced replay scheme that prioritizes samples encountered online while also
encouraging the use of near-on-policy samples from the offline dataset.
Furthermore, we leverage multiple Q-functions trained pessimistically offline,
thereby preventing overoptimism concerning unfamiliar actions at novel states
during the initial training phase. We show that the proposed method improves
sample-efficiency and final performance of the fine-tuned robotic agents on
various locomotion and manipulation tasks. Our code is available at:
https://github.com/shlee94/Off2OnRL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Molecular Graphs with Tiered Graph Autoencoders and Graph Prediction. (arXiv:1910.11390v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Daniel T. Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.11390">
                                    <div class="article-summary-box-inner">
                                        <span>Tiered graph autoencoders provide the architecture and mechanisms for
learning tiered latent representations and latent spaces for molecular graphs
that explicitly represent and utilize groups (e.g., functional groups). This
enables the utilization and exploration of tiered molecular latent spaces,
either individually - the node (atom) tier, the group tier, or the graph
(molecule) tier - or jointly, as well as navigation across the tiers. In this
paper, we discuss the use of tiered graph autoencoders together with graph
prediction for molecular graphs. We show features of molecular graphs used, and
groups in molecular graphs identified for some sample molecules. We briefly
review graph prediction and the QM9 dataset for background information, and
discuss the use of tiered graph embeddings for graph prediction, particularly
weighted group pooling. We find that functional groups and ring groups
effectively capture and represent the chemical essence of molecular graphs
(structures). Further, tiered graph autoencoders and graph prediction together
provide effective, efficient and interpretable deep learning for molecular
graphs, with the former providing unsupervised, transferable learning and the
latter providing supervised, task-optimized learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demon: Improved Neural Network Training with Momentum Decay. (arXiv:1910.04952v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">John Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.04952">
                                    <div class="article-summary-box-inner">
                                        <span>Momentum is a widely used technique for gradient-based optimizers in deep
learning. In this paper, we propose a decaying momentum (\textsc{Demon}) rule.
We conduct the first large-scale empirical analysis of momentum decay methods
for modern neural network optimization, in addition to the most popular
learning rate decay schedules. Across 28 relevant combinations of models,
epochs, datasets, and optimizers, \textsc{Demon} achieves the highest number of
Top-1 and Top-3 finishes at 39\% and 85\% respectively, almost doubling the
second-placed learning rate cosine schedule at 17\% and 60\%, respectively.
\textsc{Demon} also outperforms other widely used schedulers including, but not
limited to, the learning rate step schedule, linear schedule, OneCycle
schedule, and exponential schedule. Compared with the widely used learning rate
step schedule, \textsc{Demon} is observed to be less sensitive to parameter
tuning, which is critical to training neural networks in practice. Results are
demonstrated across a variety of settings and architectures, including image
classification, generative models, and language models. \textsc{Demon} is easy
to implement, requires no additional tuning, and incurs almost no extra
computational overhead compared to the vanilla counterparts. Code is readily
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation. (arXiv:2107.00644v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1">Nicklas Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00644">
                                    <div class="article-summary-box-inner">
                                        <span>While agents trained by Reinforcement Learning (RL) can solve increasingly
challenging tasks directly from visual observations, generalizing learned
skills to novel environments remains very challenging. Extensive use of data
augmentation is a promising technique for improving generalization in RL, but
it is often found to decrease sample efficiency and can even lead to
divergence. In this paper, we investigate causes of instability when using data
augmentation in common off-policy RL algorithms. We identify two problems, both
rooted in high-variance Q-targets. Based on our findings, we propose a simple
yet effective technique for stabilizing this class of algorithms under
augmentation. We perform extensive empirical evaluation of image-based RL using
both ConvNets and Vision Transformers (ViT) on a family of benchmarks based on
DeepMind Control Suite, as well as in robotic manipulation tasks. Our method
greatly improves stability and sample efficiency of ConvNets under
augmentation, and achieves generalization results competitive with
state-of-the-art methods for image-based RL. We further show that our method
scales to RL with ViT-based architectures, and that data augmentation may be
especially important in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Sparsification for Deep Neural Networks. (arXiv:1910.03201v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yognjin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.03201">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have relieved a great deal of burden on human experts in
relation to feature engineering. However, comparable efforts are instead
required to determine effective architectures. In addition, as the sizes of
networks have grown overly large, a considerable amount of resources is also
invested in reducing the sizes. The sparsification of an over-complete model
addresses these problems as it removes redundant components and connections. In
this study, we propose a fully differentiable sparsification method for deep
neural networks which allows parameters to be zero during training via
stochastic gradient descent. Thus, the proposed method can learn the sparsified
structure and weights of a network in an end-to-end manner. The method is
directly applicable to various modern deep neural networks and imposes minimum
modification to existing models. To the best of our knowledge, this is the
first fully [sub-]differentiable sparsification method that zeroes out
parameters. It provides a foundation for future structure learning and model
compression methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaiem_S/0/1/0/all/0/1">Salah Zaiem</a>, <a href="http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/eess/1/au:+Essid_S/0/1/0/all/0/1">Slim Essid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00594">
                                    <div class="article-summary-box-inner">
                                        <span>Through solving pretext tasks, self-supervised learning leverages unlabeled
data to extract useful latent representations replacing traditional input
features in the downstream task. In various application domains, including
computer vision, natural language processing and audio/speech signal
processing, a wide range of features where engineered through decades of
research efforts. As it turns out, learning to predict such features has proven
to be a particularly relevant pretext task leading to building useful
self-supervised representations that prove to be effective for downstream
tasks. However, methods and common practices for combining such pretext tasks,
where each task targets a different group of features for better performance on
the downstream task have not been explored and understood properly. In fact,
the process relies almost exclusively on a computationally heavy experimental
procedure, which becomes intractable with the increase of the number of pretext
tasks. This paper introduces a method to select a group of pretext tasks among
a set of candidates. The method we propose estimates properly calibrated
weights for the partial losses corresponding to the considered pretext tasks
during the self-supervised training process. The experiments conducted on
speaker recognition and automatic speech recognition validate our approach, as
the groups selected and weighted with our method perform better than classic
baselines, thus facilitating the selection and combination of relevant
pseudo-labels for self-supervised representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DVS-Attacks: Adversarial Attacks on Dynamic Vision Sensors for Spiking Neural Networks. (arXiv:2107.00415v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchisio_A/0/1/0/all/0/1">Alberto Marchisio</a>, <a href="http://arxiv.org/find/cs/1/au:+Pira_G/0/1/0/all/0/1">Giacomo Pira</a>, <a href="http://arxiv.org/find/cs/1/au:+Martina_M/0/1/0/all/0/1">Maurizio Martina</a>, <a href="http://arxiv.org/find/cs/1/au:+Masera_G/0/1/0/all/0/1">Guido Masera</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafique_M/0/1/0/all/0/1">Muhammad Shafique</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00415">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking Neural Networks (SNNs), despite being energy-efficient when
implemented on neuromorphic hardware and coupled with event-based Dynamic
Vision Sensors (DVS), are vulnerable to security threats, such as adversarial
attacks, i.e., small perturbations added to the input for inducing a
misclassification. Toward this, we propose DVS-Attacks, a set of stealthy yet
efficient adversarial attack methodologies targeted to perturb the event
sequences that compose the input of the SNNs. First, we show that noise filters
for DVS can be used as defense mechanisms against adversarial attacks.
Afterwards, we implement several attacks and test them in the presence of two
types of noise filters for DVS cameras. The experimental results show that the
filters can only partially defend the SNNs against our proposed DVS-Attacks.
Using the best settings for the noise filters, our proposed Mask Filter-Aware
Dash Attack reduces the accuracy by more than 20% on the DVS-Gesture dataset
and by more than 65% on the MNIST dataset, compared to the original clean
frames. The source code of all the proposed DVS-Attacks and noise filters is
released at https://github.com/albertomarchisio/DVS-Attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Secure Quantized Training for Deep Learning. (arXiv:2107.00501v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_M/0/1/0/all/0/1">Marcel Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1">Ke Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00501">
                                    <div class="article-summary-box-inner">
                                        <span>We have implemented training of neural networks in secure multi-party
computation (MPC) using quantization commonly used in the said setting. To the
best of our knowledge, we are the first to present an MNIST classifier purely
trained in MPC that comes within 0.2 percent of the accuracy of the same
convolutional neural network trained via plaintext computation. More
concretely, we have trained a network with two convolution and two dense layers
to 99.2% accuracy in 25 epochs. This took 3.5 hours in our MPC implementation
(under one hour for 99% accuracy).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Networks as Geometric Chaotic Maps. (arXiv:1912.05081v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravela_S/0/1/0/all/0/1">Sai Ravela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.05081">
                                    <div class="article-summary-box-inner">
                                        <span>The use of artificial neural networks as models of chaotic dynamics has been
rapidly expanding. Still, a theoretical understanding of how neural networks
learn chaos is lacking. Here, we employ a geometric perspective to show that
neural networks can efficiently model chaotic dynamics by becoming structurally
chaotic themselves. We first confirm neural network&#x27;s efficiency in emulating
chaos by showing that a parsimonious neural network trained only on few data
points can reconstruct strange attractors, extrapolate outside training data
boundaries, and accurately predict local divergence rates. We then posit that
the trained network&#x27;s map comprises sequential geometric stretching, rotation,
and compression operations. These geometric operations indicate topological
mixing and chaos, explaining why neural networks are naturally suitable to
emulate chaotic dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using AntiPatterns to avoid MLOps Mistakes. (arXiv:2107.00079v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muralidhar_N/0/1/0/all/0/1">Nikhil Muralidhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Muthiah_S/0/1/0/all/0/1">Sathappah Muthiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Butler_P/0/1/0/all/0/1">Patrick Butler</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1">Manish Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Burne_K/0/1/0/all/0/1">Katy Burne</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weipeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_D/0/1/0/all/0/1">David Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Arunachalam_P/0/1/0/all/0/1">Prakash Arunachalam</a>, <a href="http://arxiv.org/find/cs/1/au:+McCormick_H/0/1/0/all/0/1">Hays &#x27;Skip&#x27; McCormick</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_N/0/1/0/all/0/1">Naren Ramakrishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00079">
                                    <div class="article-summary-box-inner">
                                        <span>We describe lessons learned from developing and deploying machine learning
models at scale across the enterprise in a range of financial analytics
applications. These lessons are presented in the form of antipatterns. Just as
design patterns codify best software engineering practices, antipatterns
provide a vocabulary to describe defective practices and methodologies. Here we
catalog and document numerous antipatterns in financial ML operations (MLOps).
Some antipatterns are due to technical errors, while others are due to not
having sufficient knowledge of the surrounding context in which ML results are
used. By providing a common vocabulary to discuss these situations, our intent
is that antipatterns will support better documentation of issues, rapid
communication between stakeholders, and faster resolution of problems. In
addition to cataloging antipatterns, we describe solutions, best practices, and
future directions toward MLOps maturity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Model Drift Estimation with Batch Normalization Statistics for Dataset Shift Detection and Model Selection. (arXiv:2107.00191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1">Wonju Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_S/0/1/0/all/0/1">Seok-Yong Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jooeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Minje Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechil_K/0/1/0/all/0/1">Kirill Chechil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00191">
                                    <div class="article-summary-box-inner">
                                        <span>While many real-world data streams imply that they change frequently in a
nonstationary way, most of deep learning methods optimize neural networks on
training data, and this leads to severe performance degradation when dataset
shift happens. However, it is less possible to annotate or inspect newly
streamed data by humans, and thus it is desired to measure model drift at
inference time in an unsupervised manner. In this paper, we propose a novel
method of model drift estimation by exploiting statistics of batch
normalization layer on unlabeled test data. To remedy possible sampling error
of streamed input data, we adopt low-rank approximation to each
representational layer. We show the effectiveness of our method not only on
dataset shift detection but also on model selection when there are multiple
candidate models among model zoo or training trajectories in an unsupervised
way. We further demonstrate the consistency of our method by comparing model
drift scores between different network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Background Knowledge in Schema Matching: Strategy vs. Data. (arXiv:2107.00001v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Portisch_J/0/1/0/all/0/1">Jan Portisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Hladik_M/0/1/0/all/0/1">Michael Hladik</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulheim_H/0/1/0/all/0/1">Heiko Paulheim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00001">
                                    <div class="article-summary-box-inner">
                                        <span>The use of external background knowledge can be beneficial for the task of
matching schemas or ontologies automatically. In this paper, we exploit six
general-purpose knowledge graphs as sources of background knowledge for the
matching task. The background sources are evaluated by applying three different
exploitation strategies. We find that explicit strategies still outperform
latent ones and that the choice of the strategy has a greater impact on the
final alignment than the actual background dataset on which the strategy is
applied. While we could not identify a universally superior resource, BabelNet
achieved consistently good results. Our best matcher configuration with
BabelNet performs very competitively when compared to other matching systems
even though no dataset-specific optimizations were made.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inverse Design of Grating Couplers Using the Policy Gradient Method from Reinforcement Learning. (arXiv:2107.00088v1 [physics.comp-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Hooten_S/0/1/0/all/0/1">Sean Hooten</a>, <a href="http://arxiv.org/find/physics/1/au:+Vaerenbergh_T/0/1/0/all/0/1">Thomas Van Vaerenbergh</a>, <a href="http://arxiv.org/find/physics/1/au:+Beausoleil_R/0/1/0/all/0/1">Raymond G. Beausoleil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00088">
                                    <div class="article-summary-box-inner">
                                        <span>We present a proof-of-concept technique for the inverse design of
electromagnetic devices motivated by the policy gradient method in
reinforcement learning, named PHORCED (PHotonic Optimization using REINFORCE
Criteria for Enhanced Design). This technique uses a probabilistic generative
neural network interfaced with an electromagnetic solver to assist in the
design of photonic devices, such as grating couplers. We show that PHORCED
obtains better performing grating coupler designs than local gradient-based
inverse design via the adjoint method, while potentially providing faster
convergence over competing state-of-the-art generative methods. Furthermore, we
implement transfer learning with PHORCED, demonstrating that a neural network
trained to optimize 8$^\circ$ grating couplers can then be re-trained on
grating couplers with alternate scattering angles while requiring &gt;$10\times$
fewer simulations than control cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audiovisual Singing Voice Separation. (arXiv:2107.00231v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bochen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhiyao Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00231">
                                    <div class="article-summary-box-inner">
                                        <span>Separating a song into vocal and accompaniment components is an active
research topic, and recent years witnessed an increased performance from
supervised training using deep learning techniques. We propose to apply the
visual information corresponding to the singers&#x27; vocal activities to further
improve the quality of the separated vocal signals. The video frontend model
takes the input of mouth movement and fuses it into the feature embeddings of
an audio-based separation framework. To facilitate the network to learn
audiovisual correlation of singing activities, we add extra vocal signals
irrelevant to the mouth movement to the audio mixture during training. We
create two audiovisual singing performance datasets for training and
evaluation, respectively, one curated from audition recordings on the Internet,
and the other recorded in house. The proposed method outperforms audio-based
methods in terms of separation quality on most test recordings. This advantage
is especially pronounced when there are backing vocals in the accompaniment,
which poses a great challenge for audio-only methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Generative Adversarial Imitation Learning via Local Lipschitzness. (arXiv:2107.00116v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Memarian_F/0/1/0/all/0/1">Farzan Memarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_A/0/1/0/all/0/1">Abolfazl Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00116">
                                    <div class="article-summary-box-inner">
                                        <span>We explore methodologies to improve the robustness of generative adversarial
imitation learning (GAIL) algorithms to observation noise. Towards this
objective, we study the effect of local Lipschitzness of the discriminator and
the generator on the robustness of policies learned by GAIL. In many robotics
applications, the learned policies by GAIL typically suffer from a degraded
performance at test time since the observations from the environment might be
corrupted by noise. Hence, robustifying the learned policies against the
observation noise is of critical importance. To this end, we propose a
regularization method to induce local Lipschitzness in the generator and the
discriminator of adversarial imitation learning methods. We show that the
modified objective leads to learning significantly more robust policies.
Moreover, we demonstrate -- both theoretically and experimentally -- that
training a locally Lipschitz discriminator leads to a locally Lipschitz
generator, thereby improving the robustness of the resultant policy. We perform
extensive experiments on simulated robot locomotion environments from the
MuJoCo suite that demonstrate the proposed method learns policies that
significantly outperform the state-of-the-art generative adversarial imitation
learning algorithm when applied to test scenarios with noise-corrupted
observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Nonparametric Function Estimation: Optimal Rate of Convergence and Cost of Adaptation. (arXiv:2107.00179v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cai_T/0/1/0/all/0/1">T. Tony Cai</a>, <a href="http://arxiv.org/find/math/1/au:+Wei_H/0/1/0/all/0/1">Hongji Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00179">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed minimax estimation and distributed adaptive estimation under
communication constraints for Gaussian sequence model and white noise model are
studied. The minimax rate of convergence for distributed estimation over a
given Besov class, which serves as a benchmark for the cost of adaptation, is
established. We then quantify the exact communication cost for adaptation and
construct an optimally adaptive procedure for distributed estimation over a
range of Besov classes. The results demonstrate significant differences between
nonparametric function estimation in the distributed setting and the
conventional centralized setting. For global estimation, adaptation in general
cannot be achieved for free in the distributed setting. The new technical tools
to obtain the exact characterization for the cost of adaptation can be of
independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sanity Checks for Lottery Tickets: Does Your Winning Ticket Really Win the Jackpot?. (arXiv:2107.00166v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaolong Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_M/0/1/0/all/0/1">Minghai Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00166">
                                    <div class="article-summary-box-inner">
                                        <span>There have been long-standing controversies and inconsistencies over the
experiment setup and criteria for identifying the &quot;winning ticket&quot; in
literature. To reconcile such, we revisit the definition of lottery ticket
hypothesis, with comprehensive and more rigorous conditions. Under our new
definition, we show concrete evidence to clarify whether the winning ticket
exists across the major DNN architectures and/or applications. Through
extensive experiments, we perform quantitative analysis on the correlations
between winning tickets and various experimental factors, and empirically study
the patterns of our observations. We find that the key training
hyperparameters, such as learning rate and training epochs, as well as the
architecture characteristics such as capacities and residual connections, are
all highly correlated with whether and when the winning tickets can be
identified. Based on our analysis, we summarize a guideline for parameter
settings in regards of specific architecture characteristics, which we hope to
catalyze the research progress on the topic of lottery ticket hypothesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FCMI: Feature Correlation based Missing Data Imputation. (arXiv:2107.00100v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1">Prateek Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mani_K/0/1/0/all/0/1">Kumar Divya Mani</a>, <a href="http://arxiv.org/find/cs/1/au:+Johri_P/0/1/0/all/0/1">Prashant Johri</a>, <a href="http://arxiv.org/find/cs/1/au:+Arya_D/0/1/0/all/0/1">Dikhsa Arya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00100">
                                    <div class="article-summary-box-inner">
                                        <span>Processed data are insightful, and crude data are obtuse. A serious threat to
data reliability is missing values. Such data leads to inaccurate analysis and
wrong predictions. We propose an efficient technique to impute the missing
value in the dataset based on correlation called FCMI (Feature Correlation
based Missing Data Imputation). We have considered the correlation of the
attributes of the dataset, and that is our central idea. Our proposed algorithm
picks the highly correlated attributes of the dataset and uses these attributes
to build a regression model whose parameters are optimized such that the
correlation of the dataset is maintained. Experiments conducted on both
classification and regression datasets show that the proposed imputation
technique outperforms existing imputation algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regressing Location on Text for Probabilistic Geocoding. (arXiv:2107.00080v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Radford_B/0/1/0/all/0/1">Benjamin J. Radford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00080">
                                    <div class="article-summary-box-inner">
                                        <span>Text data are an important source of detailed information about social and
political events. Automated systems parse large volumes of text data to infer
or extract structured information that describes actors, actions, dates, times,
and locations. One of these sub-tasks is geocoding: predicting the geographic
coordinates associated with events or locations described by a given text. We
present an end-to-end probabilistic model for geocoding text data.
Additionally, we collect a novel data set for evaluating the performance of
geocoding systems. We compare the model-based solution, called ELECTRo-map, to
the current state-of-the-art open source system for geocoding texts for event
data. Finally, we discuss the benefits of end-to-end model-based geocoding,
including principled uncertainty estimation and the ability of these models to
leverage contextual information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedMix: Approximation of Mixup under Mean Augmented Federated Learning. (arXiv:2107.00233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1">Tehrim Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Sumin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00233">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) allows edge devices to collectively learn a model
without directly sharing data within each device, thus preserving privacy and
eliminating the need to store data globally. While there are promising results
under the assumption of independent and identically distributed (iid) local
data, current state-of-the-art algorithms suffer from performance degradation
as the heterogeneity of local data across clients increases. To resolve this
issue, we propose a simple framework, Mean Augmented Federated Learning (MAFL),
where clients send and receive averaged local data, subject to the privacy
requirements of target applications. Under our framework, we propose a new
augmentation algorithm, named FedMix, which is inspired by a phenomenal yet
simple data augmentation method, Mixup, but does not require local raw data to
be directly shared among devices. Our method shows greatly improved performance
in the standard benchmark datasets of FL, under highly non-iid federated
settings, compared to conventional algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Knowledge Distillation in Federated Learning. (arXiv:2107.00051v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Wanning Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00051">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation has caught a lot of attention in Federated Learning
(FL) recently. It has the advantage for FL to train on heterogeneous clients
which have different data size and data structure. However, data samples across
all devices are usually not independent and identically distributed
(non-i.i.d), posing additional challenges to the convergence and speed of
federated learning. As FL randomly asks the clients to join the training
process and each client only learns from local non-i.i.d data, which makes
learning processing even slower. In order to solve this problem, an intuitive
idea is using the global model to guide local training. In this paper, we
propose a novel global knowledge distillation method, named FedGKD, which
learns the knowledge from past global models to tackle down the local bias
training problem. By learning from global knowledge and consistent with current
local models, FedGKD learns a global knowledge model in FL. To demonstrate the
effectiveness of the proposed method, we conduct extensive experiments on
various CV datasets (CIFAR-10/100) and settings (non-i.i.d data). The
evaluation results show that FedGKD outperforms previous state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaXpert: Adapting Neural Architecture for Growing Data. (arXiv:2107.00254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1">Shuaicheng Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiaxiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guanghui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00254">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world applications, data often come in a growing manner, where the
data volume and the number of classes may increase dynamically. This will bring
a critical challenge for learning: given the increasing data volume or the
number of classes, one has to instantaneously adjust the neural model capacity
to obtain promising performance. Existing methods either ignore the growing
nature of data or seek to independently search an optimal architecture for a
given dataset, and thus are incapable of promptly adjusting the architectures
for the changed data. To address this, we present a neural architecture
adaptation method, namely Adaptation eXpert (AdaXpert), to efficiently adjust
previous architectures on the growing data. Specifically, we introduce an
architecture adjuster to generate a suitable architecture for each data
snapshot, based on the previous architecture and the different extent between
current and previous data distributions. Furthermore, we propose an adaptation
condition to determine the necessity of adjustment, thereby avoiding
unnecessary and time-consuming adjustments. Extensive experiments on two growth
scenarios (increasing data volume and number of classes) demonstrate the
effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascade Decoders-Based Autoencoders for Image Reconstruction. (arXiv:2107.00002v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Honggui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Galayko_D/0/1/0/all/0/1">Dimitri Galayko</a>, <a href="http://arxiv.org/find/cs/1/au:+Trocan_M/0/1/0/all/0/1">Maria Trocan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sawan_M/0/1/0/all/0/1">Mohamad Sawan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00002">
                                    <div class="article-summary-box-inner">
                                        <span>Autoencoders are composed of coding and decoding units, hence they hold the
inherent potential of high-performance data compression and signal compressed
sensing. The main disadvantages of current autoencoders comprise the following
several aspects: the research objective is not data reconstruction but feature
representation; the performance evaluation of data recovery is neglected; it is
hard to achieve lossless data reconstruction by pure autoencoders, even by pure
deep learning. This paper aims for image reconstruction of autoencoders,
employs cascade decoders-based autoencoders, perfects the performance of image
reconstruction, approaches gradually lossless image recovery, and provides
solid theory and application basis for autoencoders-based image compression and
compressed sensing. The proposed serial decoders-based autoencoders include the
architectures of multi-level decoders and the related optimization algorithms.
The cascade decoders consist of general decoders, residual decoders,
adversarial decoders and their combinations. It is evaluated by the
experimental results that the proposed autoencoders outperform the classical
autoencoders in the performance of image reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLIP-It! Language-Guided Video Summarization. (arXiv:2107.00650v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_M/0/1/0/all/0/1">Medhini Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00650">
                                    <div class="article-summary-box-inner">
                                        <span>A generic video summary is an abridged version of a video that conveys the
whole story and features the most important scenes. Yet the importance of
scenes in a video is often subjective, and users should have the option of
customizing the summary by using natural language to specify what is important
to them. Further, existing models for fully automatic generic summarization
have not exploited available language models, which can serve as an effective
prior for saliency. This work introduces CLIP-It, a single framework for
addressing both generic and query-focused video summarization, typically
approached separately in the literature. We propose a language-guided
multimodal transformer that learns to score frames in a video based on their
importance relative to one another and their correlation with a user-defined
query (for query-focused summarization) or an automatically generated dense
video caption (for generic video summarization). Our model can be extended to
the unsupervised setting by training without ground-truth supervision. We
outperform baselines and prior work by a significant margin on both standard
video summarization datasets (TVSum and SumMe) and a query-focused video
summarization dataset (QFVS). Particularly, we achieve large improvements in
the transfer setting, attesting to our method&#x27;s strong generalization
capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Compression Towards Machine Vision: Network Architecture Design and Optimization. (arXiv:2107.00328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shurun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shiqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yan Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00328">
                                    <div class="article-summary-box-inner">
                                        <span>The research of visual signal compression has a long history. Fueled by deep
learning, exciting progress has been made recently. Despite achieving better
compression performance, existing end-to-end compression algorithms are still
designed towards better signal quality in terms of rate-distortion
optimization. In this paper, we show that the design and optimization of
network architecture could be further improved for compression towards machine
vision. We propose an inverted bottleneck structure for end-to-end compression
towards machine vision, which specifically accounts for efficient
representation of the semantic information. Moreover, we quest the capability
of optimization by incorporating the analytics accuracy into the optimization
process, and the optimality is further explored with generalized rate-accuracy
optimization in an iterative manner. We use object detection as a showcase for
end-to-end compression towards machine vision, and extensive experiments show
that the proposed scheme achieves significant BD-rate savings in terms of
analysis performance. Moreover, the promise of the scheme is also demonstrated
with strong generalization capability towards other machine vision tasks, due
to the enabling of signal-level reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Orthogonal Fusion: Multimodal Prognostic Biomarker Discovery Integrating Radiology, Pathology, Genomic, and Clinical Data. (arXiv:2107.00648v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Braman_N/0/1/0/all/0/1">Nathaniel Braman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_J/0/1/0/all/0/1">Jacob W. H. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Goossens_E/0/1/0/all/0/1">Emery T. Goossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Willis_C/0/1/0/all/0/1">Caleb Willis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpe_M/0/1/0/all/0/1">Martin C. Stumpe</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkataraman_J/0/1/0/all/0/1">Jagadish Venkataraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00648">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical decision-making in oncology involves multimodal data such as
radiology scans, molecular profiling, histopathology slides, and clinical
factors. Despite the importance of these modalities individually, no deep
learning framework to date has combined them all to predict patient prognosis.
Here, we predict the overall survival (OS) of glioma patients from diverse
multimodal data with a Deep Orthogonal Fusion (DOF) model. The model learns to
combine information from multiparametric MRI exams, biopsy-based modalities
(such as H&amp;E slide images and/or DNA sequencing), and clinical variables into a
comprehensive multimodal risk score. Prognostic embeddings from each modality
are learned and combined via attention-gated tensor fusion. To maximize the
information gleaned from each modality, we introduce a multimodal
orthogonalization (MMO) loss term that increases model performance by
incentivizing constituent embeddings to be more complementary. DOF predicts OS
in glioma patients with a median C-index of 0.788 +/- 0.067, significantly
outperforming (p&#x3D;0.023) the best performing unimodal model with a median
C-index of 0.718 +/- 0.064. The prognostic model significantly stratifies
glioma patients by OS within clinical subsets, adding further granularity to
prognostic clinical grading and molecular subtyping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-07-08T08:00:22.023Z">2021-07-08T08:00:22.023Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>