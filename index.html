 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-14">2021-06-14</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding. (arXiv:2105.05596v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhiyuan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaoyan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yuejia Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05596">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent
entities, relations, and others) between two KGs. The existing methods can be
divided into the embedding-based models, and the conventional reasoning and
lexical matching based systems. The former compute the similarity of entities
via their cross-KG embeddings, but they usually rely on an ideal supervised
learning setting for good performance and lack appropriate reasoning to avoid
logically wrong mappings; while the latter address the reasoning issue but are
poor at utilizing the KG graph structures and the entity contexts. In this
study, we aim at combining the above two solutions and thus propose an
iterative framework named PRASE which is based on probabilistic reasoning and
semantic embedding. It learns the KG embeddings via entity mappings from a
probabilistic reasoning system named PARIS, and feeds the resultant entity
mappings and embeddings back into PARIS for augmentation. The PRASE framework
is compatible with different embedding-based models, and our experiments on
multiple datasets have demonstrated its state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KLUE: Korean Language Understanding Evaluation. (arXiv:2105.09680v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sungjoon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1">Jihyung Moon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungdong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1">Won Ik Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jiyoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jangwon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chisung Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Junseong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yongsook Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_T/0/1/0/all/0/1">Taehwan Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joohong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Juhyun Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Sungwon Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1">Younghoon Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1">Inkwon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1">Sangwoo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dongjun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Myeonghwa Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1">Seongbo Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_S/0/1/0/all/0/1">Seungwon Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sunkyoung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1">Kyungtae Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jongwon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kyumin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jamin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seonghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_L/0/1/0/all/0/1">Lucy Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1">Alice Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1">Jung-Woo Ha</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09680">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE
is a collection of 8 Korean natural language understanding (NLU) tasks,
including Topic Classification, SemanticTextual Similarity, Natural Language
Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing,
Machine Reading Comprehension, and Dialogue State Tracking. We build all of the
tasks from scratch from diverse source corpora while respecting copyrights, to
ensure accessibility for anyone without any restrictions. With ethical
considerations in mind, we carefully design annotation protocols. Along with
the benchmark tasks and data, we provide suitable evaluation metrics and
fine-tuning recipes for pretrained language models for each task. We
furthermore release the pretrained language models (PLM), KLUE-BERT and
KLUE-RoBERTa, to help reproducing baseline models on KLUE and thereby
facilitate future research. We make a few interesting observations from the
preliminary experiments using the proposed KLUE benchmark suite, already
demonstrating the usefulness of this new benchmark suite. First, we find
KLUE-RoBERTa-large outperforms other baselines, including multilingual PLMs and
existing open-source Korean PLMs. Second, we see minimal degradation in
performance even when we replace personally identifiable information from the
pretraining corpus, suggesting that privacy and NLU capability are not at odds
with each other. Lastly, we find that using BPE tokenization in combination
with morpheme-level pre-tokenization is effective in tasks involving
morpheme-level tagging, detection and generation. In addition to accelerating
Korean NLP research, our comprehensive documentation on creating KLUE will
facilitate creating similar resources for other languages in the future. KLUE
is available at https://klue-benchmark.com.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised and Unsupervised Sense Annotation via Translations. (arXiv:2106.06462v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1">Bradley Hauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1">Grzegorz Kondrak</a>, <a href="http://arxiv.org/find/cs/1/au:+Luan_Y/0/1/0/all/0/1">Yixing Luan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mallik_A/0/1/0/all/0/1">Arnob Mallik</a>, <a href="http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1">Lili Mou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06462">
                                    <div class="article-summary-box-inner">
                                        <span>Acquisition of multilingual training data continues to be a challenge in word
sense disambiguation (WSD). To address this problem, unsupervised approaches
have been developed in recent years that automatically generate sense
annotations suitable for training supervised WSD systems. We present three new
methods to creating sense-annotated corpora, which leverage translations,
parallel corpora, lexical resources, and contextual and synset embeddings. Our
semi-supervised method applies machine translation to transfer existing sense
annotations to other languages. Our two unsupervised methods use a
knowledge-based WSD system to annotate a parallel corpus, and refine the
resulting sense annotations by identifying lexical translations. We obtain
state-of-the-art results on standard WSD benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WAX-ML: A Python library for machine learning and feedback loops on streaming data. (arXiv:2106.06524v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Serie_E/0/1/0/all/0/1">Emmanuel S&#xe9;ri&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06524">
                                    <div class="article-summary-box-inner">
                                        <span>Wax is what you put on a surfboard to avoid slipping. It is an essential tool
to go surfing... We introduce WAX-ML a research-oriented Python library
providing tools to design powerful machine learning algorithms and feedback
loops working on streaming data. It strives to complement JAX with tools
dedicated to time series. WAX-ML makes JAX-based programs easy to use for
end-users working with pandas and xarray for data manipulation. It provides a
simple mechanism for implementing feedback loops, allows the implementation of
online learning and reinforcement learning algorithms with functions, and makes
them easy to integrate by end-users working with the object-oriented
reinforcement learning framework from the Gym library. It is released with an
Apache open-source license on GitHub at https://github.com/eserie/wax-ml.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">N-Best ASR Transformer: Enhancing SLU Performance using Multiple ASR Hypotheses. (arXiv:2106.06519v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1">Karthik Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamdev_P/0/1/0/all/0/1">Pakhi Bamdev</a>, <a href="http://arxiv.org/find/cs/1/au:+B_J/0/1/0/all/0/1">Jaivarsan B</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1">Amresh Venugopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tushar_A/0/1/0/all/0/1">Abhinav Tushar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06519">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken Language Understanding (SLU) systems parse speech into semantic
structures like dialog acts and slots. This involves the use of an Automatic
Speech Recognizer (ASR) to transcribe speech into multiple text alternatives
(hypotheses). Transcription errors, common in ASRs, impact downstream SLU
performance negatively. Approaches to mitigate such errors involve using richer
information from the ASR, either in form of N-best hypotheses or word-lattices.
We hypothesize that transformer models learn better with a simpler utterance
representation using the concatenation of the N-best ASR alternatives, where
each alternative is separated by a special delimiter [SEP]. In our work, we
test our hypothesis by using concatenated N-best ASR alternatives as the input
to transformer encoder models, namely BERT and XLM-RoBERTa, and achieve
performance equivalent to the prior state-of-the-art model on DSTC2 dataset. We
also show that our approach significantly outperforms the prior
state-of-the-art when subjected to the low data regime. Additionally, this
methodology is accessible to users of third-party ASR APIs which do not provide
word-lattice information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UnNatural Language Inference. (arXiv:2101.00010v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1">Koustuv Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1">Prasanna Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Adina Williams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00010">
                                    <div class="article-summary-box-inner">
                                        <span>Recent investigations into the inner-workings of state-of-the-art large-scale
pre-trained Transformer-based Natural Language Understanding (NLU) models
indicate that they appear to know humanlike syntax, at least to some extent. We
provide novel evidence that complicates this claim: we find that
state-of-the-art Natural Language Inference (NLI) models assign the same labels
to permuted examples as they do to the original, i.e. they are largely
invariant to random word-order permutations. This behavior notably differs from
that of humans; we struggle with ungrammatical sentences. To measure the
severity of this issue, we propose a suite of metrics and investigate which
properties of particular permutations lead models to be word-order invariant.
In the MNLI dataset, for example, we find almost all (98.7%) examples contain
at least one permutation which elicits the gold label. Models are sometimes
even able to assign gold labels to permutations that they originally failed to
predict correctly. We provide a comprehensive empirical evaluation of this
phenomenon, and further show that this issue exists for both Transformers and
pre-Transformer RNN / ConvNet based encoders, as well as across multiple
languages (English and Mandarin Chinese). Our code and data are available at
https://github.com/facebookresearch/unlu.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What is Multimodality?. (arXiv:2103.06304v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1">Letitia Parcalabescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Trost_N/0/1/0/all/0/1">Nils Trost</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06304">
                                    <div class="article-summary-box-inner">
                                        <span>The last years have shown rapid developments in the field of multimodal
machine learning, combining e.g., vision, text or speech. In this position
paper we explain how the field uses outdated definitions of multimodality that
prove unfit for the machine learning era. We propose a new task-relative
definition of (multi)modality in the context of multimodal machine learning
that focuses on representations and information that are relevant for a given
machine learning task. With our new definition of multimodality we aim to
provide a missing foundation for multimodal research, an important component of
language grounding and a crucial milestone towards NLU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HMM-Free Encoder Pre-Training for Streaming RNN Transducer. (arXiv:2104.10764v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Huang_L/0/1/0/all/0/1">Lu Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Jingyu Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1">Yufeng Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hou_J/0/1/0/all/0/1">Junfeng Hou</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1">Jinkun Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_Z/0/1/0/all/0/1">Zejun Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10764">
                                    <div class="article-summary-box-inner">
                                        <span>This work describes an encoder pre-training procedure using frame-wise label
to improve the training of streaming recurrent neural network transducer
(RNN-T) model. Streaming RNN-T trained from scratch usually performs worse than
non-streaming RNN-T. Although it is common to address this issue through
pre-training components of RNN-T with other criteria or frame-wise alignment
guidance, the alignment is not easily available in end-to-end manner. In this
work, frame-wise alignment, used to pre-train streaming RNN-T&#x27;s encoder, is
generated without using a HMM-based system. Therefore an all-neural framework
equipping HMM-free encoder pre-training is constructed. This is achieved by
expanding the spikes of CTC model to their left/right blank frames, and two
expanding strategies are proposed. To our best knowledge, this is the first
work to simulate HMM-based frame-wise label using CTC model for pre-training.
Experiments conducted on LibriSpeech and MLS English tasks show the proposed
pre-training procedure, compared with random initialization, reduces the WER by
relatively 5%~11% and the emission latency by 60 ms. Besides, the method is
lexicon-free, so it is friendly to new languages without manually designed
lexicon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Cross-Document Event Coreference Resolution Across Multiple Corpora. (arXiv:2011.12249v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bugert_M/0/1/0/all/0/1">Michael Bugert</a>, <a href="http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1">Nils Reimers</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12249">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-document event coreference resolution (CDCR) is an NLP task in which
mentions of events need to be identified and clustered throughout a collection
of documents. CDCR aims to benefit downstream multi-document applications, but
despite recent progress on corpora and system development, downstream
improvements from applying CDCR have not been shown yet. We make the
observation that every CDCR system to date was developed, trained, and tested
only on a single respective corpus. This raises strong concerns on their
generalizability -- a must-have for downstream applications where the magnitude
of domains or event mentions is likely to exceed those found in a curated
corpus. To investigate this assumption, we define a uniform evaluation setup
involving three CDCR corpora: ECB+, the Gun Violence Corpus and the Football
Coreference Corpus (which we reannotate on token level to make our analysis
possible). We compare a corpus-independent, feature-based system against a
recent neural system developed for ECB+. Whilst being inferior in absolute
numbers, the feature-based system shows more consistent performance across all
corpora whereas the neural system is hit-and-miss. Via model introspection, we
find that the importance of event actions, event time, etc. for resolving
coreference in practice varies greatly between the corpora. Additional analysis
shows that several systems overfit on the structure of the ECB+ corpus. We
conclude with recommendations on how to achieve generally applicable CDCR
systems in the future -- the most important being that evaluation on multiple
CDCR corpora is strongly necessary. To facilitate future research, we release
our dataset, annotation guidelines, and system implementation to the public.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Discussion on Building Practical NLP Leaderboards: The Case of Machine Translation. (arXiv:2106.06292v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santy_S/0/1/0/all/0/1">Sebastin Santy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_P/0/1/0/all/0/1">Prasanta Bhattacharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06292">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in AI and ML applications have benefited from rapid progress
in NLP research. Leaderboards have emerged as a popular mechanism to track and
accelerate progress in NLP through competitive model development. While this
has increased interest and participation, the over-reliance on single, and
accuracy-based metrics have shifted focus from other important metrics that
might be equally pertinent to consider in real-world contexts. In this paper,
we offer a preliminary discussion of the risks associated with focusing
exclusively on accuracy metrics and draw on recent discussions to highlight
prescriptive suggestions on how to develop more practical and effective
leaderboards that can better reflect the real-world utility of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Language Models for Continuously Evolving Content. (arXiv:2106.06297v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hombaiah_S/0/1/0/all/0/1">Spurthi Amba Hombaiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mingyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1">Michael Bendersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1">Marc Najork</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06297">
                                    <div class="article-summary-box-inner">
                                        <span>The content on the web is in a constant state of flux. New entities, issues,
and ideas continuously emerge, while the semantics of the existing conversation
topics gradually shift. In recent years, pre-trained language models like BERT
greatly improved the state-of-the-art for a large spectrum of content
understanding tasks. Therefore, in this paper, we aim to study how these
language models can be adapted to better handle continuously evolving web
content. In our study, we first analyze the evolution of 2013 - 2019 Twitter
data, and unequivocally confirm that a BERT model trained on past tweets would
heavily deteriorate when directly applied to data from later years. Then, we
investigate two possible sources of the deterioration: the semantic shift of
existing tokens and the sub-optimal or failed understanding of new tokens. To
this end, we both explore two different vocabulary composition methods, as well
as propose three sampling methods which help in efficient incremental training
for BERT-like models. Compared to a new model trained from scratch offline, our
incremental training (a) reduces the training costs, (b) achieves better
performance on evolving content, and (c) is suitable for online deployment. The
superiority of our methods is validated using two downstream tasks. We
demonstrate significant improvements when incrementally evolving the model from
a particular base year, on the task of Country Hashtag Prediction, as well as
on the OffensEval 2019 task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards unsupervised phone and word segmentation using self-supervised vector-quantized neural networks. (arXiv:2012.07551v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1">Herman Kamper</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekerk_B/0/1/0/all/0/1">Benjamin van Niekerk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07551">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate segmenting and clustering speech into low-bitrate phone-like
sequences without supervision. We specifically constrain pretrained
self-supervised vector-quantized (VQ) neural networks so that blocks of
contiguous feature vectors are assigned to the same code, thereby giving a
variable-rate segmentation of the speech into discrete units. Two segmentation
methods are considered. In the first, features are greedily merged until a
prespecified number of segments are reached. The second uses dynamic
programming to optimize a squared error with a penalty term to encourage fewer
but longer segments. We show that these VQ segmentation methods can be used
without alteration across a wide range of tasks: unsupervised phone
segmentation, ABX phone discrimination, same-different word discrimination, and
as inputs to a symbolic word segmentation algorithm. The penalized dynamic
programming method generally performs best. While performance on individual
tasks is only comparable to the state-of-the-art in some cases, in all tasks a
reasonable competing approach is outperformed at a substantially lower bitrate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning for Text Classification with Information Disentanglement Based Regularization. (arXiv:2104.05489v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yufan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanzhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuezhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Diyi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05489">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning has become increasingly important as it enables NLP models
to constantly learn and gain knowledge over time. Previous continual learning
methods are mainly designed to preserve knowledge from previous tasks, without
much emphasis on how to well generalize models to new tasks. In this work, we
propose an information disentanglement based regularization method for
continual learning on text classification. Our proposed method first
disentangles text hidden spaces into representations that are generic to all
tasks and representations specific to each individual task, and further
regularizes these representations differently to better constrain the knowledge
required to generalize. We also introduce two simple auxiliary tasks: next
sentence prediction and task-id prediction, for learning better generic and
specific representation spaces. Experiments conducted on large-scale benchmarks
demonstrate the effectiveness of our method in continual text classification
tasks with various sequences and lengths over state-of-the-art baselines. We
have publicly released our code at https://github.com/GT-SALT/IDBR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs. (arXiv:2106.06363v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scialom_T/0/1/0/all/0/1">Thomas Scialom</a>, <a href="http://arxiv.org/find/cs/1/au:+Dray_P/0/1/0/all/0/1">Paul-Alexis Dray</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1">Sylvain Lamprier</a>, <a href="http://arxiv.org/find/cs/1/au:+Piwowarski_B/0/1/0/all/0/1">Benjamin Piwowarski</a>, <a href="http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1">Jacopo Staiano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06363">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the discrete nature of words, language GANs require to be optimized
from rewards provided by discriminator networks, via reinforcement learning
methods. This is a much harder setting than for continuous tasks, which enjoy
gradient flows from discriminators to generators, usually leading to dramatic
learning instabilities. However, we claim that this can be solved by making
discriminator and generator networks cooperate to produce output sequences
during training. These cooperative outputs, inherently built to obtain higher
discrimination scores, not only provide denser rewards for training, but also
form a more compact artificial set for discriminator training, hence improving
its accuracy and stability. In this paper, we show that our SelfGAN framework,
built on this cooperative principle, outperforms Teacher Forcing and obtains
state-of-the-art results on two challenging tasks, Summarization and Question
Generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment. (arXiv:2106.06381v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1">Zewen Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Li Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bo Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shaohan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xian-Ling Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heyan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06381">
                                    <div class="article-summary-box-inner">
                                        <span>The cross-lingual language models are typically pretrained with masked
language modeling on multilingual text or parallel sentences. In this paper, we
introduce denoising word alignment as a new cross-lingual pre-training task.
Specifically, the model first self-labels word alignments for parallel
sentences. Then we randomly mask tokens in a bitext pair. Given a masked token,
the model uses a pointer network to predict the aligned token in the other
language. We alternately perform the above two steps in an
expectation-maximization manner. Experimental results show that our method
improves cross-lingual transferability on various datasets, especially on the
token-level tasks, such as question answering, and structured prediction.
Moreover, the model can serve as a pretrained word aligner, which achieves
reasonably low error rates on the alignment benchmarks. The code and pretrained
parameters are available at https://github.com/CZWin32768/XLM-Align.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xingyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Muchao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1">Quanzeng You</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fenglong Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06471">
                                    <div class="article-summary-box-inner">
                                        <span>Medical report generation is one of the most challenging tasks in medical
image analysis. Although existing approaches have achieved promising results,
they either require a predefined template database in order to retrieve
sentences or ignore the hierarchical nature of medical report generation. To
address these issues, we propose MedWriter that incorporates a novel
hierarchical retrieval mechanism to automatically extract both report and
sentence-level templates for clinically accurate report generation. MedWriter
first employs the Visual-Language Retrieval~(VLR) module to retrieve the most
relevant reports for the given images. To guarantee the logical coherence
between sentences, the Language-Language Retrieval~(LLR) module is introduced
to retrieve relevant sentences based on the previous generated description. At
last, a language decoder fuses image features and features from retrieved
reports and sentences to generate meaningful medical reports. We verified the
effectiveness of our model by automatic evaluation and human evaluation on two
datasets, i.e., Open-I and MIMIC-CXR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-Shot Controlled Generation with Encoder-Decoder Transformers. (arXiv:2106.06411v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1">Devamanyu Hazarika</a>, <a href="http://arxiv.org/find/cs/1/au:+Namazifar_M/0/1/0/all/0/1">Mahdi Namazifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1">Dilek Hakkani-T&#xfc;r</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06411">
                                    <div class="article-summary-box-inner">
                                        <span>Controlling neural network-based models for natural language generation (NLG)
has broad applications in numerous areas such as machine translation, document
summarization, and dialog systems. Approaches that enable such control in a
zero-shot manner would be of great importance as, among other reasons, they
remove the need for additional annotated data and training. In this work, we
propose novel approaches for controlling encoder-decoder transformer-based NLG
models in a zero-shot manner. This is done by introducing three control knobs;
namely, attention biasing, decoder mixing, and context augmentation, that are
applied to these models at generation time. These knobs control the generation
process by directly manipulating trained NLG models (e.g., biasing
cross-attention layers) to realize the desired attributes in the generated
outputs. We show that not only are these NLG models robust to such
manipulations, but also their behavior could be controlled without an impact on
their generation performance. These results, to the best of our knowledge, are
the first of their kind. Through these control knobs, we also investigate the
role of transformer decoder&#x27;s self-attention module and show strong evidence
that its primary role is maintaining fluency of sentences generated by these
models. Based on this hypothesis, we show that alternative architectures for
transformer decoders could be viable options. We also study how this hypothesis
could lead to more efficient ways for training encoder-decoder transformer
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Explanation of Dialogue Response Generation. (arXiv:2106.06528v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1">Yi-Lin Tuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1">Connor Pryor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1">Lise Getoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06528">
                                    <div class="article-summary-box-inner">
                                        <span>In comparison to the interpretation of classification models, the explanation
of sequence generation models is also an important problem, however it has seen
little attention. In this work, we study model-agnostic explanations of a
representative text generation task -- dialogue response generation. Dialog
response generation is challenging with its open-ended sentences and multiple
acceptable responses. To gain insights into the reasoning process of a
generation model, we propose anew method, local explanation of response
generation (LERG) that regards the explanations as the mutual interaction of
segments in input and output sentences. LERG views the sequence prediction as
uncertainty estimation of a human response and then creates explanations by
perturbing the input and calculating the certainty change over the human
response. We show that LERG adheres to desired properties of explanations for
text generation including unbiased approximation, consistency and cause
identification. Empirically, our results show that our method consistently
improves other widely used methods on proposed automatic- and human- evaluation
metrics for this new task by 4.4-12.8%. Our analysis demonstrates that LERG can
extract both explicit and implicit relations between input and output segments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Should Agents Ask Questions For Situated Learning? An Annotated Dialogue Corpus. (arXiv:2106.06504v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gervits_F/0/1/0/all/0/1">Felix Gervits</a>, <a href="http://arxiv.org/find/cs/1/au:+Roque_A/0/1/0/all/0/1">Antonio Roque</a>, <a href="http://arxiv.org/find/cs/1/au:+Briggs_G/0/1/0/all/0/1">Gordon Briggs</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheutz_M/0/1/0/all/0/1">Matthias Scheutz</a>, <a href="http://arxiv.org/find/cs/1/au:+Marge_M/0/1/0/all/0/1">Matthew Marge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06504">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent agents that are confronted with novel concepts in situated
environments will need to ask their human teammates questions to learn about
the physical world. To better understand this problem, we need data about
asking questions in situated task-based interactions. To this end, we present
the Human-Robot Dialogue Learning (HuRDL) Corpus - a novel dialogue corpus
collected in an online interactive virtual environment in which human
participants play the role of a robot performing a collaborative
tool-organization task. We describe the corpus data and a corresponding
annotation scheme to offer insight into the form and content of questions that
humans ask to facilitate learning in a situated environment. We provide the
corpus as an empirically-grounded resource for improving question generation in
situated intelligent agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chao Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Ye Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1">Zarana Parekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yunhsuan Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1">Tom Duerig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05918">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained representations are becoming crucial for many NLP and perception
tasks. While representation learning in NLP has transitioned to training on raw
text without human annotations, visual and vision-language representations
still rely heavily on curated training datasets that are expensive or require
expert knowledge. For vision applications, representations are mostly learned
using datasets with explicit class labels such as ImageNet or OpenImages. For
vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all
involve a non-trivial data collection (and cleaning) process. This costly
curation process limits the size of datasets and hence hinders the scaling of
trained models. In this paper, we leverage a noisy dataset of over one billion
image alt-text pairs, obtained without expensive filtering or post-processing
steps in the Conceptual Captions dataset. A simple dual-encoder architecture
learns to align visual and language representations of the image and text pairs
using a contrastive loss. We show that the scale of our corpus can make up for
its noise and leads to state-of-the-art representations even with such a simple
learning scheme. Our visual representation achieves strong performance when
transferred to classification tasks such as ImageNet and VTAB. The aligned
visual and language representations enables zero-shot image classification and
also set new state-of-the-art results on Flickr30K and MSCOCO image-text
retrieval benchmarks, even when compared with more sophisticated
cross-attention models. The representations also enable cross-modality search
with complex text and text + image queries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spoken Style Learning with Multi-modal Hierarchical Context Encoding for Conversational Text-to-Speech Synthesis. (arXiv:2106.06233v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingbei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yi Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1">Chao Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1">Dan Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06233">
                                    <div class="article-summary-box-inner">
                                        <span>For conversational text-to-speech (TTS) systems, it is vital that the systems
can adjust the spoken styles of synthesized speech according to different
content and spoken styles in historical conversations. However, the study about
learning spoken styles from historical conversations is still in its infancy.
Only the transcripts of the historical conversations are considered, which
neglects the spoken styles in historical speeches. Moreover, only the
interactions of the global aspect between speakers are modeled, missing the
party aspect self interactions inside each speaker. In this paper, to achieve
better spoken style learning for conversational TTS, we propose a spoken style
learning approach with multi-modal hierarchical context encoding. The textual
information and spoken styles in the historical conversations are processed
through multiple hierarchical recurrent neural networks to learn the spoken
style related features in global and party aspects. The attention mechanism is
further employed to summarize these features into a conversational context
encoding. Experimental results demonstrate the effectiveness of our proposed
approach, which outperform a baseline method using context encoding learnt only
from the transcripts in global aspects, with MOS score on the naturalness of
synthesized speech increasing from 3.138 to 3.408 and ABX preference rate
exceeding the baseline method by 36.45%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Calibrate Before Use: Improving Few-Shot Performance of Language Models. (arXiv:2102.09690v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tony Z. Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1">Eric Wallace</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09690">
                                    <div class="article-summary-box-inner">
                                        <span>GPT-3 can perform numerous tasks when provided a natural language prompt that
contains a few training examples. We show that this type of few-shot learning
can be unstable: the choice of prompt format, training examples, and even the
order of the training examples can cause accuracy to vary from near chance to
near state-of-the-art. We demonstrate that this instability arises from the
bias of language models towards predicting certain answers, e.g., those that
are placed near the end of the prompt or are common in the pre-training data.
To mitigate this, we first estimate the model&#x27;s bias towards each answer by
asking for its prediction when given the training prompt and a content-free
test input such as &quot;N/A&quot;. We then fit calibration parameters that cause the
prediction for this input to be uniform across answers. On a diverse set of
tasks, this contextual calibration procedure substantially improves GPT-3 and
GPT-2&#x27;s average accuracy (up to 30.0% absolute) and reduces variance across
different choices of the prompt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sprachsynthese -- State-of-the-Art in englischer und deutscher Sprache. (arXiv:2106.06230v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1">Ren&#xe9; Peinl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06230">
                                    <div class="article-summary-box-inner">
                                        <span>Reading text aloud is an important feature for modern computer applications.
It not only facilitates access to information for visually impaired people, but
is also a pleasant convenience for non-impaired users. In this article, the
state of the art of speech synthesis is presented separately for
mel-spectrogram generation and vocoders. It concludes with an overview of
available data sets for English and German with a discussion of the
transferability of the good speech synthesis results from English to German
language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word Substitution. (arXiv:2106.06361v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1">Fanchao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Sophia Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06361">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies show that neural natural language processing (NLP) models are
vulnerable to backdoor attacks. Injected with backdoors, models perform
normally on benign examples but produce attacker-specified predictions when the
backdoor is activated, presenting serious security threats to real-world
applications. Since existing textual backdoor attacks pay little attention to
the invisibility of backdoors, they can be easily detected and blocked. In this
work, we present invisible backdoors that are activated by a learnable
combination of word substitution. We show that NLP models can be injected with
backdoors that lead to a nearly 100% attack success rate, whereas being highly
invisible to existing defense strategies and even human inspections. The
results raise a serious alarm to the security of NLP models, which requires
further research to be resolved. All the data and code of this paper are
released at https://github.com/thunlp/BkdAtk-LWS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentence Extraction-Based Machine Reading Comprehension for Vietnamese. (arXiv:2105.09043v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Do_P/0/1/0/all/0/1">Phong Nguyen-Thuan Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Nhat Duy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1">Tin Van Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Anh Gia-Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan Luu-Thuy Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09043">
                                    <div class="article-summary-box-inner">
                                        <span>The development of natural language processing (NLP) in general and machine
reading comprehension in particular has attracted the great attention of the
research community. In recent years, there are a few datasets for machine
reading comprehension tasks in Vietnamese with large sizes, such as UIT-ViQuAD
and UIT-ViNewsQA. However, the datasets are not diverse in answers to serve the
research. In this paper, we introduce UIT-ViWikiQA, the first dataset for
evaluating sentence extraction-based machine reading comprehension in the
Vietnamese language. The UIT-ViWikiQA dataset is converted from the UIT-ViQuAD
dataset, consisting of comprises 23.074 question-answers based on 5.109
passages of 174 Wikipedia Vietnamese articles. We propose a conversion
algorithm to create the dataset for sentence extraction-based machine reading
comprehension and three types of approaches for sentence extraction-based
machine reading comprehension in Vietnamese. Our experiments show that the best
machine model is XLM-R_Large, which achieves an exact match (EM) of 85.97% and
an F1-score of 88.77% on our dataset. Besides, we analyze experimental results
in terms of the question type in Vietnamese and the effect of context on the
performance of the MRC models, thereby showing the challenges from the
UIT-ViWikiQA dataset that we propose to the language processing community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedNLP: An interpretable NLP System to Decode Federal Reserve Communications. (arXiv:2106.06247v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jean Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Youn_H/0/1/0/all/0/1">Hoyoul Luis Youn</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_N/0/1/0/all/0/1">Nicholas Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1">Josiah Poon</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Soyeon Caren Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06247">
                                    <div class="article-summary-box-inner">
                                        <span>The Federal Reserve System (the Fed) plays a significant role in affecting
monetary policy and financial conditions worldwide. Although it is important to
analyse the Fed&#x27;s communications to extract useful information, it is generally
long-form and complex due to the ambiguous and esoteric nature of content. In
this paper, we present FedNLP, an interpretable multi-component Natural
Language Processing system to decode Federal Reserve communications. This
system is designed for end-users to explore how NLP techniques can assist their
holistic understanding of the Fed&#x27;s communications with NO coding. Behind the
scenes, FedNLP uses multiple NLP models from traditional machine learning
algorithms to deep neural network architectures in each downstream task. The
demonstration shows multiple results at once including sentiment analysis,
summary of the document, prediction of the Federal Funds Rate movement and
visualization for interpreting the prediction model&#x27;s result.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HUI-Audio-Corpus-German: A high quality TTS dataset. (arXiv:2106.06309v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puchtler_P/0/1/0/all/0/1">Pascal Puchtler</a>, <a href="http://arxiv.org/find/cs/1/au:+Wirth_J/0/1/0/all/0/1">Johannes Wirth</a>, <a href="http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1">Ren&#xe9; Peinl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06309">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing availability of audio data on the internet lead to a multitude
of datasets for development and training of text to speech applications, based
on neural networks. Highly differing quality of voice, low sampling rates, lack
of text normalization and disadvantageous alignment of audio samples to
corresponding transcript sentences still limit the performance of deep neural
networks trained on this task. Additionally, data resources in languages like
German are still very limited. We introduce the &quot;HUI-Audio-Corpus-German&quot;, a
large, open-source dataset for TTS engines, created with a processing pipeline,
which produces high quality audio to transcription alignments and decreases
manual effort needed for creation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving RNN-T ASR Performance with Date-Time and Location Awareness. (arXiv:2106.06183v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ray_S/0/1/0/all/0/1">Swayambhu Nath Ray</a>, <a href="http://arxiv.org/find/eess/1/au:+Mitra_S/0/1/0/all/0/1">Soumyajit Mitra</a>, <a href="http://arxiv.org/find/eess/1/au:+Bilgi_R/0/1/0/all/0/1">Raghavendra Bilgi</a>, <a href="http://arxiv.org/find/eess/1/au:+Garimella_S/0/1/0/all/0/1">Sri Garimella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06183">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore the benefits of incorporating context into a
Recurrent Neural Network (RNN-T) based Automatic Speech Recognition (ASR) model
to improve the speech recognition for virtual assistants. Specifically, we use
meta information extracted from the time at which the utterance is spoken and
the approximate location information to make ASR context aware. We show that
these contextual information, when used individually, improves overall
performance by as much as 3.48% relative to the baseline and when the contexts
are combined, the model learns complementary features and the recognition
improves by 4.62%. On specific domains, these contextual signals show
improvements as high as 11.5%, without any significant degradation on others.
We ran experiments with models trained on data of sizes 30K hours and 10K
hours. We show that the scale of improvement with the 10K hours dataset is much
higher than the one obtained with 30K hours dataset. Our results indicate that
with limited data to train the ASR model, contextual signals can improve the
performance significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1">Andreas Waldis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1">Luca Mazzola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06216">
                                    <div class="article-summary-box-inner">
                                        <span>Entity Recognition (ER) within a text is a fundamental exercise in Natural
Language Processing, enabling further depending tasks such as Knowledge
Extraction, Text Summarisation, or Keyphrase Extraction. An entity consists of
single words or of a consecutive sequence of terms, constituting the basic
building blocks for communication. Mainstream ER approaches are mainly limited
to flat structures, concentrating on the outermost entities while ignoring the
inner ones. This paper introduces a partly-layered network architecture that
deals with the complexity of overlapping and nested cases. The proposed
architecture consists of two parts: (1) a shared Sequence Layer and (2) a
stacked component with multiple Tagging Layers. The adoption of such an
architecture has the advantage of preventing overfit to a specific word-length,
thus maintaining performance for longer entities despite their lower frequency.
To verify the proposed architecture&#x27;s effectiveness, we train and evaluate this
architecture to recognise two kinds of entities - Concepts (CR) and Named
Entities (NER). Our approach achieves state-of-the-art NER performances, while
it outperforms previous CR approaches. Considering these promising results, we
see the possibility to evolve the architecture for other cases such as the
extraction of events or the detection of argumentative components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards User-Driven Neural Machine Translation. (arXiv:2106.06200v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Huan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1">Liang Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Baosong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dayiheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haibo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Weihua Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Degen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jinsong Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06200">
                                    <div class="article-summary-box-inner">
                                        <span>A good translation should not only translate the original content
semantically, but also incarnate personal traits of the original text. For a
real-world neural machine translation (NMT) system, these user traits (e.g.,
topic preference, stylistic characteristics and expression habits) can be
preserved in user behavior (e.g., historical inputs). However, current NMT
systems marginally consider the user behavior due to: 1) the difficulty of
modeling user portraits in zero-shot scenarios, and 2) the lack of
user-behavior annotated parallel dataset. To fill this gap, we introduce a
novel framework called user-driven NMT. Specifically, a cache-based module and
a user-driven contrastive learning method are proposed to offer NMT the ability
to capture potential user traits from their historical inputs under a zero-shot
learning fashion. Furthermore, we contribute the first Chinese-English parallel
corpus annotated with user behavior called UDT-Corpus. Experimental results
confirm that the proposed user-driven NMT can generate user-specific
translations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection. (arXiv:2106.06213v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weld_H/0/1/0/all/0/1">Henry Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guanghao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jean Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tongshu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kunze Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xinghong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_S/0/1/0/all/0/1">Siqu Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1">Josiah Poon</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Soyeon Caren Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06213">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional toxicity detection models have focused on the single utterance
level without deeper understanding of context. We introduce CONDA, a new
dataset for in-game toxic language detection enabling joint intent
classification and slot filling analysis, which is the core task of Natural
Language Understanding (NLU). The dataset consists of 45K utterances from 12K
conversations from the chat logs of 1.9K completed Dota 2 matches. We propose a
robust dual semantic-level toxicity framework, which handles utterance and
token-level patterns, and rich contextual chatting history. Accompanying the
dataset is a thorough in-game toxicity analysis, which provides comprehensive
understanding of context at utterance, token, and dual levels. Inspired by NLU,
we also apply its metrics to the toxicity detection tasks for assessing
toxicity and game-specific aspects. We evaluate strong NLU models on CONDA,
providing fine-grained results for different intent classes and slot classes.
Furthermore, we examine the coverage of toxicity nature in our dataset by
comparing it with other toxicity datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Paraphrasing to Semantic Parsing: Unsupervised Semantic Parsing via Synchronous Semantic Decoding. (arXiv:2106.06228v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1">Chunlei Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xianpei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Le Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weipeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiansong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1">Xunliang Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06228">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic parsing is challenging due to the structure gap and the semantic gap
between utterances and logical forms. In this paper, we propose an unsupervised
semantic parsing method - Synchronous Semantic Decoding (SSD), which can
simultaneously resolve the semantic gap and the structure gap by jointly
leveraging paraphrasing and grammar constrained decoding. Specifically, we
reformulate semantic parsing as a constrained paraphrasing problem: given an
utterance, our model synchronously generates its canonical utterance and
meaning representation. During synchronous decoding: the utterance paraphrasing
is constrained by the structure of the logical form, therefore the canonical
utterance can be paraphrased controlledly; the semantic decoding is guided by
the semantics of the canonical utterance, therefore its logical form can be
generated unsupervisedly. Experimental results show that SSD is a promising
approach and can achieve competitive unsupervised semantic parsing performance
on multiple datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data. (arXiv:2106.06169v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Haoyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Nan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06169">
                                    <div class="article-summary-box-inner">
                                        <span>Maintaining consistent personas is essential for dialogue agents. Although
tremendous advancements have been brought, the limited-scale of annotated
persona-dense data are still barriers towards training robust and consistent
persona-based dialogue models. In this work, we show how the challenges can be
addressed by disentangling persona-based dialogue generation into two sub-tasks
with a novel BERT-over-BERT (BoB) model. Specifically, the model consists of a
BERT-based encoder and two BERT-based decoders, where one decoder is for
response generation, and another is for consistency understanding. In
particular, to learn the ability of consistency understanding from large-scale
non-dialogue inference data, we train the second decoder in an unlikelihood
manner. Under different limited data settings, both automatic and human
evaluations demonstrate that the proposed model outperforms strong baselines in
response quality and persona consistency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TellMeWhy: A Dataset for Answering Why-Questions in Narratives. (arXiv:2106.06132v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1">Yash Kumar Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1">Nathanael Chambers</a>, <a href="http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1">Raymond Mooney</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06132">
                                    <div class="article-summary-box-inner">
                                        <span>Answering questions about why characters perform certain actions is central
to understanding and reasoning about narratives. Despite recent progress in QA,
it is not clear if existing models have the ability to answer &quot;why&quot; questions
that may require commonsense knowledge external to the input narrative. In this
work, we introduce TellMeWhy, a new crowd-sourced dataset that consists of more
than 30k questions and free-form answers concerning why characters in short
narratives perform the actions described. For a third of this dataset, the
answers are not present within the narrative. Given the limitations of
automated evaluation for this task, we also present a systematized human
evaluation interface for this dataset. Our evaluation of state-of-the-art
models show that they are far below human performance on answering such
questions. They are especially worse on questions whose answers are external to
the narrative, thus providing a challenge for future QA and narrative
understanding research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spoken Term Detection Methods for Sparse Transcription in Very Low-resource Settings. (arXiv:2106.06160v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ferrand_E/0/1/0/all/0/1">&#xc9;ric Le Ferrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Bird_S/0/1/0/all/0/1">Steven Bird</a>, <a href="http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1">Laurent Besacier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06160">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the efficiency of two very different spoken term detection
approaches for transcription when the available data is insufficient to train a
robust ASR system. This work is grounded in very low-resource language
documentation scenario where only few minutes of recording have been
transcribed for a given language so far.Experiments on two oral languages show
that a pretrained universal phone recognizer, fine-tuned with only a few
minutes of target language speech, can be used for spoken term detection with a
better overall performance than a dynamic time warping approach. In addition,
we show that representing phoneme recognition ambiguity in a graph structure
can further boost the recall while maintaining high precision in the low
resource spoken term detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing. (arXiv:2106.06004v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jayanthi_S/0/1/0/all/0/1">Sai Muralidhar Jayanthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nerella_K/0/1/0/all/0/1">Kavya Nerella</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1">Khyathi Raghavi Chandu</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1">Alan W Black</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06004">
                                    <div class="article-summary-box-inner">
                                        <span>The NLP community has witnessed steep progress in a variety of tasks across
the realms of monolingual and multilingual language processing recently. These
successes, in conjunction with the proliferating mixed language interactions on
social media have boosted interest in modeling code-mixed texts. In this work,
we present CodemixedNLP, an open-source library with the goals of bringing
together the advances in code-mixed NLP and opening it up to a wider machine
learning community. The library consists of tools to develop and benchmark
versatile model architectures that are tailored for mixed texts, methods to
expand training sets, techniques to quantify mixing styles, and fine-tuned
state-of-the-art models for 7 tasks in Hinglish. We believe this work has a
potential to foster a distributed yet collaborative and sustainable ecosystem
in an otherwise dispersed space of code-mixing research. The toolkit is
designed to be simple, easily extensible, and resourceful to both researchers
as well as practitioners.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing Political Prudence of Open-domain Chatbots. (arXiv:2106.06157v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1">Yejin Bang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1">Nayeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1">Etsuko Ishii</a>, <a href="http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1">Andrea Madotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1">Pascale Fung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06157">
                                    <div class="article-summary-box-inner">
                                        <span>Politically sensitive topics are still a challenge for open-domain chatbots.
However, dealing with politically sensitive content in a responsible,
non-partisan, and safe behavior way is integral for these chatbots. Currently,
the main approach to handling political sensitivity is by simply changing such
a topic when it is detected. This is safe but evasive and results in a chatbot
that is less engaging. In this work, as a first step towards a politically safe
chatbot, we propose a group of metrics for assessing their political prudence.
We then conduct political prudence analysis of various chatbots and discuss
their behavior from multiple angles through our automatic metric and human
evaluation metrics. The testsets and codebase are released to promote research
in this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking. (arXiv:2106.06052v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhiyi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ethayarajh_K/0/1/0/all/0/1">Kawin Ethayarajh</a>, <a href="http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1">Tristan Thrush</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Somya Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Ledell Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Robin Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Adina Williams</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06052">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Dynaboard, an evaluation-as-a-service framework for hosting
benchmarks and conducting holistic model comparison, integrated with the
Dynabench platform. Our platform evaluates NLP models directly instead of
relying on self-reported metrics or predictions on a single dataset. Under this
paradigm, models are submitted to be evaluated in the cloud, circumventing the
issues of reproducibility, accessibility, and backwards compatibility that
often hinder benchmarking in NLP. This allows users to interact with uploaded
models in real time to assess their quality, and permits the collection of
additional metrics such as memory use, throughput, and robustness, which --
despite their importance to practitioners -- have traditionally been absent
from leaderboards. On each task, models are ranked according to the Dynascore,
a novel utility-based aggregation of these statistics, which users can
customize to better reflect their preferences, placing more/less weight on a
particular axis of evaluation or dataset. As state-of-the-art NLP models push
the limits of traditional benchmarks, Dynaboard offers a standardized solution
for a more diverse and comprehensive evaluation of model quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comprehensive solution to retrieval-based chatbot construction. (arXiv:2106.06139v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1">Kristen Moore</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1">Shenjun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1">Torsten Rudolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisher_N/0/1/0/all/0/1">Nils Fisher</a>, <a href="http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1">Brandon Victor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1">Neha Jindal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06139">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present the results of our experiments in training and
deploying a self-supervised retrieval-based chatbot trained with contrastive
learning for assisting customer support agents. In contrast to most existing
research papers in this area where the focus is on solving just one component
of a deployable chatbot, we present an end-to-end set of solutions to take the
reader from an unlabelled chatlogs to a deployed chatbot. This set of solutions
includes creating a self-supervised dataset and a weakly labelled dataset from
chatlogs, as well as a systematic approach to selecting a fixed list of canned
responses. We present a hierarchical-based RNN architecture for the response
selection model, chosen for its ability to cache intermediate utterance
embeddings, which helped to meet deployment inference speed requirements. We
compare the performance of this architecture across 3 different learning
objectives: self-supervised contrastive learning, binary classification, and
multi-class classification. We find that using a self-supervised contrastive
learning model outperforms training the binary and multi-class classification
models on a weakly labelled dataset. Our results validate that the
self-supervised contrastive learning approach can be effectively used for a
real-world chatbot scenario.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1">Jerome Abdelnour</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1">Jean Rouat</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1">Giampiero Salvi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06147">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of the Acoustic Question Answering (AQA) task is to answer a
free-form text question about the content of an acoustic scene. It was inspired
by the Visual Question Answering (VQA) task. In this paper, based on the
previously introduced CLEAR dataset, we propose a new benchmark for AQA that
emphasizes the specific challenges of acoustic inputs, e.g. variable duration
scenes. We also introduce NAAQA, a neural architecture that leverages specific
properties of acoustic inputs. The usage of time and frequency 1D convolutions
to process 2D spectro-temporal representations of acoustic content shows
promising results and enables reductions in model complexity. NAAQA achieves
91.6% of accuracy on the AQA task with about 7 times fewer parameters than the
previously explored VQA model. We provide a detailed analysis of the results
for the different question types. The effectiveness of coordinate maps in this
acoustic context was also studied and we show that time coordinate maps augment
temporal localization capabilities which enhance performance of the network by
about 17 percentage points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging Subword Gaps in Pretrain-Finetune Paradigm for Natural Language Generation. (arXiv:2106.06125v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Baosong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dayiheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haibo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Weihua Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haiying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jinsong Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06125">
                                    <div class="article-summary-box-inner">
                                        <span>A well-known limitation in pretrain-finetune paradigm lies in its
inflexibility caused by the one-size-fits-all vocabulary. This potentially
weakens the effect when applying pretrained models into natural language
generation (NLG) tasks, especially for the subword distributions between
upstream and downstream tasks with significant discrepancy. Towards approaching
this problem, we extend the vanilla pretrain-finetune pipeline with an extra
embedding transfer step. Specifically, a plug-and-play embedding generator is
introduced to produce the representation of any input token, according to
pre-trained embeddings of its morphologically similar ones. Thus, embeddings of
mismatch tokens in downstream tasks can also be efficiently initialized. We
conduct experiments on a variety of NLG tasks under the pretrain-finetune
fashion. Experimental results and extensive analyses show that the proposed
strategy offers us opportunities to feel free to transfer the vocabulary,
leading to more efficient and better performed downstream NLG models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1">Kai Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaojie Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Hanning Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shucheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1">Bo Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06090">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has become the dominant approach in coping with various tasks
in Natural LanguageProcessing (NLP). Although text inputs are typically
represented as a sequence of tokens, there isa rich variety of NLP problems
that can be best expressed with a graph structure. As a result, thereis a surge
of interests in developing new deep learning techniques on graphs for a large
numberof NLP tasks. In this survey, we present a comprehensive overview onGraph
Neural Networks(GNNs) for Natural Language Processing. We propose a new
taxonomy of GNNs for NLP, whichsystematically organizes existing research of
GNNs for NLP along three axes: graph construction,graph representation
learning, and graph based encoder-decoder models. We further introducea large
number of NLP applications that are exploiting the power of GNNs and summarize
thecorresponding benchmark datasets, evaluation metrics, and open-source codes.
Finally, we discussvarious outstanding challenges for making the full use of
GNNs for NLP as well as future researchdirections. To the best of our
knowledge, this is the first comprehensive overview of Graph NeuralNetworks for
Natural Language Processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Analysis of Syntactic Agreement Mechanisms in Neural Language Models. (arXiv:2106.06087v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Finlayson_M/0/1/0/all/0/1">Matthew Finlayson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_A/0/1/0/all/0/1">Aaron Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Shieber_S/0/1/0/all/0/1">Stuart Shieber</a>, <a href="http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1">Sebastian Gehrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1">Tal Linzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1">Yonatan Belinkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06087">
                                    <div class="article-summary-box-inner">
                                        <span>Targeted syntactic evaluations have demonstrated the ability of language
models to perform subject-verb agreement given difficult contexts. To elucidate
the mechanisms by which the models accomplish this behavior, this study applies
causal mediation analysis to pre-trained neural language models. We investigate
the magnitude of models&#x27; preferences for grammatical inflections, as well as
whether neurons process subject-verb agreement similarly across sentences with
different syntactic structures. We uncover similarities and differences across
architectures and model sizes -- notably, that larger models do not necessarily
learn stronger preferences. We also observe two distinct mechanisms for
producing subject-verb agreement depending on the syntactic structure of the
input sentence. Finally, we find that language models rely on similar sets of
neurons when given sentences with similar syntactic structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-lingual Emotion Detection. (arXiv:2106.06017v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassan_S/0/1/0/all/0/1">Sabit Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaar_S/0/1/0/all/0/1">Shaden Shaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Darwish_K/0/1/0/all/0/1">Kareem Darwish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06017">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion detection is of great importance for understanding humans.
Constructing annotated datasets to train automated models can be expensive. We
explore the efficacy of cross-lingual approaches that would use data from a
source language to build models for emotion detection in a target language. We
compare three approaches, namely: i) using inherently multilingual models; ii)
translating training data into the target language; and iii) using an
automatically tagged parallel corpus. In our study, we consider English as the
source language with Arabic and Spanish as target languages. We study the
effectiveness of different classification models such as BERT and SVMs trained
with different features. Our BERT-based monolingual models that are trained on
target language data surpass state-of-the-art (SOTA) by 4% and 5% absolute
Jaccard score for Arabic and Spanish respectively. Next, we show that using
cross-lingual approaches with English data alone, we can achieve more than 90%
and 80% relative effectiveness of the Arabic and Spanish BERT models
respectively. Lastly, we use LIME to interpret the differences between models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Hierarchical Structures with Continuous Recursive Neural Networks. (arXiv:2106.06038v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1">Jishnu Ray Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1">Cornelia Caragea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06038">
                                    <div class="article-summary-box-inner">
                                        <span>Recursive Neural Networks (RvNNs), which compose sequences according to their
underlying hierarchical syntactic structure, have performed well in several
natural language processing tasks compared to similar models without structural
biases. However, traditional RvNNs are incapable of inducing the latent
structure in a plain text sequence on their own. Several extensions have been
proposed to overcome this limitation. Nevertheless, these extensions tend to
rely on surrogate gradients or reinforcement learning at the cost of higher
bias or variance. In this work, we propose Continuous Recursive Neural Network
(CRvNN) as a backpropagation-friendly alternative to address the aforementioned
limitations. This is done by incorporating a continuous relaxation to the
induced structure. We demonstrate that CRvNN achieves strong performance in
challenging synthetic tasks such as logical inference and ListOps. We also show
that CRvNN performs comparably or better than prior latent structure models on
real-world tasks such as sentiment analysis and natural language inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Sense Per Translation. (arXiv:2106.06082v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1">Bradley Hauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1">Grzegorz Kondrak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06082">
                                    <div class="article-summary-box-inner">
                                        <span>The idea of using lexical translations to define sense inventories has a long
history in lexical semantics. We propose a theoretical framework which allows
us to answer the question of why this apparently reasonable idea failed to
produce useful results. We formally prove several propositions on how the
translations of a word relate to its senses, as well as on the relationship
between synonymy and polysemy. We empirically validate our theoretical findings
on BabelNet, and demonstrate how they could be used to perform unsupervised
word sense disambiguation of a substantial fraction of the lexicon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic, Structure-Aware Algorithms for Improved Variety, Accuracy, and Coverage of AMR Alignments. (arXiv:2106.06002v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blodgett_A/0/1/0/all/0/1">Austin Blodgett</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1">Nathan Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06002">
                                    <div class="article-summary-box-inner">
                                        <span>We present algorithms for aligning components of Abstract Meaning
Representation (AMR) graphs to spans in English sentences. We leverage
unsupervised learning in combination with heuristics, taking the best of both
worlds from previous AMR aligners. Our unsupervised models, however, are more
sensitive to graph substructures, without requiring a separate syntactic parse.
Our approach covers a wider variety of AMR substructures than previously
considered, achieves higher coverage of nodes and edges, and does so with
higher accuracy. We will release our LEAMR datasets and aligner for use in
research on AMR parsing, generation, and evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1">Lalith Bharadwaj B</a>, <a href="http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1">Rohit Boddeda</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Sai Vardhan K</a>, <a href="http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1">Madhu G</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05690">
                                    <div class="article-summary-box-inner">
                                        <span>The issue of COVID-19, increasing with a massive mortality rate. This led to
the WHO declaring it as a pandemic. In this situation, it is crucial to perform
efficient and fast diagnosis. The reverse transcript polymerase chain reaction
(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is
time-consuming and instead chest CT (or Chest X-ray) can be used for a fast and
accurate diagnosis. Automated diagnosis is considered to be important as it
reduces human effort and provides accurate and low-cost tests. The
contributions of our research are three-fold. First, it is aimed to analyse the
behaviour and performance of variant vision models ranging from Inception to
NAS networks with the appropriate fine-tuning procedure. Second, the behaviour
of these models is visually analysed by plotting CAMs for individual networks
and determining classification performance with AUCROC curves. Thirdly, stacked
ensembles techniques are imparted to provide higher generalisation on combining
the fine-tuned models, in which six ensemble neural networks are designed by
combining the existing fine-tuned networks. Implying these stacked ensembles
provides a great generalization to the models. The ensemble model designed by
combining all the fine-tuned networks obtained a state-of-the-art accuracy
score of 99.17%. The precision and recall for the COVID-19 class are 99.99% and
89.79% respectively, which resembles the robustness of the stacked ensembles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Weakly Supervised Action Segmentation Using Mutual Consistency. (arXiv:1904.03116v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1">Yaser Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1">Mohsen Fayyaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Minciullo_L/0/1/0/all/0/1">Luca Minciullo</a>, <a href="http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1">Gianpiero Francesca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.03116">
                                    <div class="article-summary-box-inner">
                                        <span>Action segmentation is the task of predicting the actions for each frame of a
video. As obtaining the full annotation of videos for action segmentation is
expensive, weakly supervised approaches that can learn only from transcripts
are appealing. In this paper, we propose a novel end-to-end approach for weakly
supervised action segmentation based on a two-branch neural network. The two
branches of our network predict two redundant but different representations for
action segmentation and we propose a novel mutual consistency (MuCon) loss that
enforces the consistency of the two redundant representations. Using the MuCon
loss together with a loss for transcript prediction, our proposed approach
achieves the accuracy of state-of-the-art approaches while being $14$ times
faster to train and $20$ times faster during inference. The MuCon loss proves
beneficial even in the fully supervised setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pedestrian Attribute Recognition in Video Surveillance Scenarios Based on View-attribute Attention Localization. (arXiv:2106.06485v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weichen Chen</a> (1) <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xinyi Yu</a> (1) <a href="http://arxiv.org/find/cs/1/au:+Ou_L/0/1/0/all/0/1">Linlin Ou</a> (1) ((1) Collage of Information Engineering, Zhejiang University of Technology, Hangzhou, China)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06485">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian attribute recognition in surveillance scenarios is still a
challenging task due to inaccurate localization of specific attributes. In this
paper, we propose a novel view-attribute localization method based on attention
(VALA), which relies on the strong relevance between attributes and views to
capture specific view-attributes and to localize attribute-corresponding areas
by attention mechanism. A specific view-attribute is composed by the extracted
attribute feature and four view scores which are predicted by view predictor as
the confidences for attribute from different views. View-attribute is then
delivered back to shallow network layers for supervising deep feature
extraction. To explore the location of a view-attribute, regional attention is
introduced to aggregate spatial information of the input attribute feature in
height and width direction for constraining the image into a narrow range.
Moreover, the inter-channel dependency of view-feature is embedded in the above
two spatial directions. An attention attribute-specific region is gained after
fining the narrow range by balancing the ratio of channel dependencies between
height and width branches. The final view-attribute recognition outcome is
obtained by combining the output of regional attention with the view scores
from view predictor. Experiments on three wide datasets (RAP, RAPv2, PETA, and
PA-100K) demonstrate the effectiveness of our approach compared with
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Neural Networks: A Survey. (arXiv:2102.04906v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yizeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Le Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Honghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yulin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04906">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic neural network is an emerging research topic in deep learning.
Compared to static models which have fixed computational graphs and parameters
at the inference stage, dynamic networks can adapt their structures or
parameters to different inputs, leading to notable advantages in terms of
accuracy, computational efficiency, adaptiveness, etc. In this survey, we
comprehensively review this rapidly developing area by dividing dynamic
networks into three main categories: 1) instance-wise dynamic models that
process each instance with data-dependent architectures or parameters; 2)
spatial-wise dynamic networks that conduct adaptive computation with respect to
different spatial locations of image data and 3) temporal-wise dynamic models
that perform adaptive inference along the temporal dimension for sequential
data such as videos and texts. The important research problems of dynamic
networks, e.g., architecture design, decision making scheme, optimization
technique and applications, are reviewed systematically. Finally, we discuss
the open problems in this field together with interesting future research
directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViT-Inception-GAN for Image Colourising. (arXiv:2106.06321v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bana_T/0/1/0/all/0/1">Tejas Bana</a>, <a href="http://arxiv.org/find/cs/1/au:+Loya_J/0/1/0/all/0/1">Jatan Loya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1">Siddhant Kulkarni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06321">
                                    <div class="article-summary-box-inner">
                                        <span>Studies involving colourising images has been garnering researchers&#x27; keen
attention over time, assisted by significant advances in various Machine
Learning techniques and compute power availability. Traditionally, colourising
images have been an intricate task that gave a substantial degree of freedom
during the assignment of chromatic information. In our proposed method, we
attempt to colourise images using Vision Transformer - Inception - Generative
Adversarial Network (ViT-I-GAN), which has an Inception-v3 fusion embedding in
the generator. For a stable and robust network, we have used Vision Transformer
(ViT) as the discriminator. We trained the model on the Unsplash and the COCO
dataset for demonstrating the improvement made by the Inception-v3 embedding.
We have compared the results between ViT-GANs with and without Inception-v3
embedding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Genetic U-Net: Automatically Designed Deep Networks for Retinal Vessel Segmentation Using a Genetic Algorithm. (arXiv:2010.15560v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wei_J/0/1/0/all/0/1">Jiahong Wei</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_Z/0/1/0/all/0/1">Zhun Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15560">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, many methods based on hand-designed convolutional neural networks
(CNNs) have achieved promising results in automatic retinal vessel
segmentation. However, these CNNs remain constrained in capturing retinal
vessels in complex fundus images. To improve their segmentation performance,
these CNNs tend to have many parameters, which may lead to overfitting and high
computational complexity. Moreover, the manual design of competitive CNNs is
time-consuming and requires extensive empirical knowledge. Herein, a novel
automated design method, called Genetic U-Net, is proposed to generate a
U-shaped CNN that can achieve better retinal vessel segmentation but with fewer
architecture-based parameters, thereby addressing the above issues. First, we
devised a condensed but flexible search space based on a U-shaped
encoder-decoder. Then, we used an improved genetic algorithm to identify
better-performing architectures in the search space and investigated the
possibility of finding a superior network architecture with fewer parameters.
The experimental results show that the architecture obtained using the proposed
method offered a superior performance with less than 1% of the number of the
original U-Net parameters in particular and with significantly fewer parameters
than other state-of-the-art models. Furthermore, through in-depth investigation
of the experimental results, several effective operations and patterns of
networks to generate superior retinal vessel segmentations were identified.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning via Persistency of Excitation. (arXiv:2106.02078v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1">Kaustubh Sridhar</a>, <a href="http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1">Oleg Sokolsky</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1">James Weimer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02078">
                                    <div class="article-summary-box-inner">
                                        <span>Improving adversarial robustness of neural networks remains a major
challenge. Fundamentally, training a network is a parameter estimation problem.
In adaptive control theory, maintaining persistency of excitation (PoE) is
integral to ensuring convergence of parameter estimates in dynamical systems to
their robust optima. In this work, we show that network training using gradient
descent is equivalent to a dynamical system parameter estimation problem.
Leveraging this relationship, we prove a sufficient condition for PoE of
gradient descent is achieved when the learning rate is less than the inverse of
the Lipschitz constant of the gradient of loss function. We provide an
efficient technique for estimating the corresponding Lipschitz constant using
extreme value theory and demonstrate that by only scaling the learning rate
schedule we can increase adversarial accuracy by up to 15% points on benchmark
datasets. Our approach also universally increases the adversarial accuracy by
0.1% to 0.3% points in various state-of-the-art adversarially trained models on
the AutoAttack benchmark, where every small margin of improvement is
significant.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refining Pseudo Labels with Clustering Consensus over Generations for Unsupervised Object Re-identification. (arXiv:2106.06133v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yixiao Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06133">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised object re-identification targets at learning discriminative
representations for object retrieval without any annotations. Clustering-based
methods conduct training with the generated pseudo labels and currently
dominate this research direction. However, they still suffer from the issue of
pseudo label noise. To tackle the challenge, we propose to properly estimate
pseudo label similarities between consecutive training generations with
clustering consensus and refine pseudo labels with temporally propagated and
ensembled pseudo labels. To the best of our knowledge, this is the first
attempt to leverage the spirit of temporal ensembling to improve classification
with dynamically changing classes over generations. The proposed pseudo label
refinery strategy is simple yet effective and can be seamlessly integrated into
existing clustering-based unsupervised re-identification methods. With our
proposed approach, state-of-the-art method can be further boosted with up to
8.8% mAP improvements on the challenging MSMT17 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object Segmentation Without Labels with Large-Scale Generative Models. (arXiv:2006.04988v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1">Andrey Voynov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morozov_S/0/1/0/all/0/1">Stanislav Morozov</a>, <a href="http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1">Artem Babenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04988">
                                    <div class="article-summary-box-inner">
                                        <span>The recent rise of unsupervised and self-supervised learning has dramatically
reduced the dependency on labeled data, providing effective image
representations for transfer to downstream vision tasks. Furthermore, recent
works employed these representations in a fully unsupervised setup for image
classification, reducing the need for human labels on the fine-tuning stage as
well. This work demonstrates that large-scale unsupervised models can also
perform a more challenging object segmentation task, requiring neither
pixel-level nor image-level labeling. Namely, we show that recent unsupervised
GANs allow to differentiate between foreground/background pixels, providing
high-quality saliency masks. By extensive comparison on standard benchmarks, we
outperform existing unsupervised alternatives for object segmentation,
achieving new state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks. (arXiv:2002.11318v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1">Sandesh Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amit Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Subrahmanyam_K/0/1/0/all/0/1">K V Subrahmanyam</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.11318">
                                    <div class="article-summary-box-inner">
                                        <span>(Non-)robustness of neural networks to small, adversarial pixel-wise
perturbations, and as more recently shown, to even random spatial
transformations (e.g., translations, rotations) entreats both theoretical and
empirical understanding. Spatial robustness to random translations and
rotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)
and training augmentation, whereas adversarial robustness is typically achieved
by adversarial training. In this paper, we prove a quantitative trade-off
between spatial and adversarial robustness in a simple statistical setting. We
complement this empirically by showing that: (a) as the spatial robustness of
equivariant models improves by training augmentation with progressively larger
transformations, their adversarial robustness worsens progressively, and (b) as
the state-of-the-art robust models are adversarially trained with progressively
larger pixel-wise perturbations, their spatial robustness drops progressively.
Towards achieving pareto-optimality in this trade-off, we propose a method
based on curriculum learning that trains gradually on more difficult
perturbations (both spatial and adversarial) to improve spatial and adversarial
robustness simultaneously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets. (arXiv:2106.06442v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1">Xiu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1">Shan You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Mingkai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1">Chen Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06442">
                                    <div class="article-summary-box-inner">
                                        <span>In one-shot weight sharing for NAS, the weights of each operation (at each
layer) are supposed to be identical for all architectures (paths) in the
supernet. However, this rules out the possibility of adjusting operation
weights to cater for different paths, which limits the reliability of the
evaluation results. In this paper, instead of counting on a single supernet, we
introduce $K$-shot supernets and take their weights for each operation as a
dictionary. The operation weight for each path is represented as a convex
combination of items in a dictionary with a simplex code. This enables a matrix
approximation of the stand-alone weight matrix with a higher rank ($K&gt;1$). A
\textit{simplex-net} is introduced to produce architecture-customized code for
each path. As a result, all paths can adaptively learn how to share weights in
the $K$-shot supernets and acquire corresponding weights for better evaluation.
$K$-shot supernets and simplex-net can be iteratively trained, and we further
extend the search to the channel dimension. Extensive experiments on benchmark
datasets validate that K-shot NAS significantly improves the evaluation
accuracy of paths and thus brings in impressive performance improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1">Dominic Masters</a>, <a href="http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1">Antoine Labatie</a>, <a href="http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1">Zach Eaton-Rosen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03640">
                                    <div class="article-summary-box-inner">
                                        <span>Much recent research has been dedicated to improving the efficiency of
training and inference for image classification. This effort has commonly
focused on explicitly improving theoretical efficiency, often measured as
ImageNet validation accuracy per FLOP. These theoretical savings have, however,
proven challenging to achieve in practice, particularly on high-performance
training accelerators.

In this work, we focus on improving the practical efficiency of the
state-of-the-art EfficientNet models on a new class of accelerator, the
Graphcore IPU. We do this by extending this family of models in the following
ways: (i) generalising depthwise convolutions to group convolutions; (ii)
adding proxy-normalized activations to match batch normalization performance
with batch-independent statistics; (iii) reducing compute by lowering the
training resolution and inexpensively fine-tuning at higher resolution. We find
that these three methods improve the practical efficiency for both training and
inference. Our code will be made available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Calibration and Auto-Refinement for Light Field Cameras. (arXiv:2106.06181v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anisimov_Y/0/1/0/all/0/1">Yuriy Anisimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Reis_G/0/1/0/all/0/1">Gerd Reis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06181">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to create an accurate three-dimensional reconstruction of a
captured scene draws attention to the principles of light fields. This paper
presents an approach for light field camera calibration and rectification,
based on pairwise pattern-based parameters extraction. It is followed by a
correspondence-based algorithm for camera parameters refinement from arbitrary
scenes using the triangulation filter and nonlinear optimization. The
effectiveness of our approach is validated on both real and synthetic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Young-min Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1">Young-chul Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kwangjin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1">Moongu Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00100">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a highly practical fully online multi-object
tracking and segmentation (MOTS) method that uses instance segmentation results
as an input. The proposed method is based on the Gaussian mixture probability
hypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a
mask-based affinity fusion (MAF) model to achieve high-performance online
tracking. The HDA consists of two associations: segment-to-track and
track-to-track associations. One affinity, for position and motion, is computed
by using the GMPHD filter, and the other affinity, for appearance is computed
by using the responses from a single object tracker such as a kernalized
correlation filter. These two affinities are simply fused by using a
score-level fusion method such as min-max normalization referred to as MAF. In
addition, to reduce the number of false positive segments, we adopt mask
IoU-based merging (mask merging). The proposed MOTS framework with the key
modules: HDA, MAF, and mask merging, is easily extensible to simultaneously
track multiple types of objects with CPU only execution in parallel processing.
In addition, the developed framework only requires simple parameter tuning
unlike many existing MOTS methods that need intensive hyperparameter
optimization. In the experiments on the two popular MOTS datasets, the key
modules show some improvements. For instance, ID-switch decreases by more than
half compared to a baseline method in the training sets. In conclusion, our
tracker achieves state-of-the-art MOTS performance in the test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AugNet: End-to-End Unsupervised Visual Representation Learning with Image Augmentation. (arXiv:2106.06250v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingxiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Z/0/1/0/all/0/1">Zhanguo Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haonan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bitao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Liufang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhecheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06250">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the achievements in artificial intelligence so far were accomplished
by supervised learning which requires numerous annotated training data and thus
costs innumerable manpower for labeling. Unsupervised learning is one of the
effective solutions to overcome such difficulties. In our work, we propose
AugNet, a new deep learning training paradigm to learn image features from a
collection of unlabeled pictures. We develop a method to construct the
similarities between pictures as distance metrics in the embedding space by
leveraging the inter-correlation between augmented versions of samples. Our
experiments demonstrate that the method is able to represent the image in low
dimensional space and performs competitively in downstream tasks such as image
classification and image similarity comparison. Specifically, we achieved over
60% and 27% accuracy on the STL10 and CIFAR100 datasets with unsupervised
clustering, respectively. Moreover, unlike many deep-learning-based image
retrieval algorithms, our approach does not require access to external
annotated datasets to train the feature extractor, but still shows comparable
or even better feature representation ability and easy-to-use characteristics.
In our evaluations, the method outperforms all the state-of-the-art image
retrieval algorithms on some out-of-domain image datasets. The code for the
model implementation is available at
https://github.com/chenmingxiang110/AugNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image Forensic Technique Based on JPEG Ghosts. (arXiv:2106.06439v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_D/0/1/0/all/0/1">Divakar Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06439">
                                    <div class="article-summary-box-inner">
                                        <span>The unprecedented growth in the easy availability of photo-editing tools has
endangered the power of digital images.An image was supposed to be worth more
than a thousand words,but now this can be said only if it can be authenticated
orthe integrity of the image can be proved to be intact. In thispaper, we
propose a digital image forensic technique for JPEG images. It can detect any
forgery in the image if the forged portion called a ghost image is having a
compression quality different from that of the cover image. It is based on
resaving the JPEG image at different JPEG qualities, and the detection of the
forged portion is maximum when it is saved at the same JPEG quality as the
cover image. Also, we can precisely predictthe JPEG quality of the cover image
by analyzing the similarity using Structural Similarity Index Measure (SSIM) or
the energyof the images. The first maxima in SSIM or the first minima inenergy
correspond to the cover image JPEG quality. We created adataset for varying
JPEG compression qualities of the ghost and the cover images and validated the
scalability of the experimental results.We also, experimented with varied
attack scenarios, e.g. high-quality ghost image embedded in low quality of
cover image,low-quality ghost image embedded in high-quality of cover image,and
ghost image and cover image both at the same quality.The proposed method is
able to localize the tampered portions accurately even for forgeries as small
as 10x10 sized pixel blocks.Our technique is also robust against other attack
scenarios like copy-move forgery, inserting text into image, rescaling
(zoom-out/zoom-in) ghost image and then pasting on cover image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shallow Optical Flow Three-Stream CNN for Macro- and Micro-Expression Spotting from Long Videos. (arXiv:2106.06489v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liong_G/0/1/0/all/0/1">Gen-Bing Liong</a>, <a href="http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1">John See</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1">Lai-Kuan Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06489">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expressions vary from the visible to the subtle. In recent years, the
analysis of micro-expressions $-$ a natural occurrence resulting from the
suppression of one&#x27;s true emotions, has drawn the attention of researchers with
a broad range of potential applications. However, spotting microexpressions in
long videos becomes increasingly challenging when intertwined with normal or
macro-expressions. In this paper, we propose a shallow optical flow
three-stream CNN (SOFTNet) model to predict a score that captures the
likelihood of a frame being in an expression interval. By fashioning the
spotting task as a regression problem, we introduce pseudo-labeling to
facilitate the learning process. We demonstrate the efficacy and efficiency of
the proposed approach on the recent MEGC 2020 benchmark, where state-of-the-art
performance is achieved on CAS(ME)$^{2}$ with equally promising results on SAMM
Long Videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance-Level Task Parameters: A Robust Multi-task Weighting Framework. (arXiv:2106.06129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasu_P/0/1/0/all/0/1">Pavan Kumar Anasosalu Vasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Shreyas Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1">Oncel Tuzel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06129">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have shown that deep neural networks benefit from multi-task
learning by learning a shared representation across several related tasks.
However, performance of such systems depend on relative weighting between
various losses involved during training. Prior works on loss weighting schemes
assume that instances are equally easy or hard for all tasks. In order to break
this assumption, we let the training process dictate the optimal weighting of
tasks for every instance in the dataset. More specifically, we equip every
instance in the dataset with a set of learnable parameters (instance-level task
parameters) where the cardinality is equal to the number of tasks learned by
the model. These parameters model the weighting of each task for an instance.
They are updated by gradient descent and do not require hand-crafted rules. We
conduct extensive experiments on SURREAL and CityScapes datasets, for human
shape and pose estimation, depth estimation and semantic segmentation tasks. In
these tasks, our approach outperforms recent dynamic loss weighting approaches,
e.g. reducing surface estimation errors by 8.97% on SURREAL. When applied to
datasets where one or more tasks can have noisy annotations, the proposed
method learns to prioritize learning from clean labels for a given task, e.g.
reducing surface estimation errors by up to 60%. We also show that we can
reliably detect corrupt labels for a given task as a by-product from learned
instance-level task parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1">Michael L. Iuzzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1">Michael C. Mozer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1">Samy Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09808">
                                    <div class="article-summary-box-inner">
                                        <span>Although deep feedforward neural networks share some characteristics with the
primate visual system, a key distinction is their dynamics. Deep nets typically
operate in serial stages wherein each layer completes its computation before
processing begins in subsequent layers. In contrast, biological systems have
cascaded dynamics: information propagates from neurons at all layers in
parallel but transmission occurs gradually over time, leading to speed-accuracy
trade offs even in feedforward architectures. We explore the consequences of
biologically inspired parallel hardware by constructing cascaded ResNets in
which each residual block has propagation delays but all blocks update in
parallel in a stateful manner. Because information transmitted through skip
connections avoids delays, the functional depth of the architecture increases
over time, yielding anytime predictions that improve with internal-processing
time. We introduce a temporal-difference training loss that achieves a strictly
superior speed-accuracy profile over standard losses and enables the cascaded
architecture to outperform state-of-the-art anytime-prediction methods. The
cascaded architecture has intriguing properties, including: it classifies
typical instances more rapidly than atypical instances; it is more robust to
both persistent and transient noise than is a conventional ResNet; and its
time-varying output trace provides a signal that can be exploited to improve
information processing and inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Compositional Shape Priors for Few-Shot 3D Reconstruction. (arXiv:2106.06440v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Michalkiewicz_M/0/1/0/all/0/1">Mateusz Michalkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsogkas_S/0/1/0/all/0/1">Stavros Tsogkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Parisot_S/0/1/0/all/0/1">Sarah Parisot</a>, <a href="http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1">Mahsa Baktashmotlagh</a>, <a href="http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1">Anders Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1">Eugene Belilovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06440">
                                    <div class="article-summary-box-inner">
                                        <span>The impressive performance of deep convolutional neural networks in
single-view 3D reconstruction suggests that these models perform non-trivial
reasoning about the 3D structure of the output space. Recent work has
challenged this belief, showing that, on standard benchmarks, complex
encoder-decoder architectures perform similarly to nearest-neighbor baselines
or simple linear decoder models that exploit large amounts of per-category
data. However, building large collections of 3D shapes for supervised training
is a laborious process; a more realistic and less constraining task is
inferring 3D shapes for categories with few available training examples,
calling for a model that can successfully generalize to novel object classes.
In this work we experimentally demonstrate that naive baselines fail in this
few-shot learning setting, in which the network must learn informative shape
priors for inference of new categories. We propose three ways to learn a
class-specific global shape prior, directly from data. Using these techniques,
we are able to capture multi-scale information about the 3D shape, and account
for intra-class variability by virtue of an implicit compositional structure.
Experiments on the popular ShapeNet dataset show that our method outperforms a
zero-shot baseline by over 40%, and the current state-of-the-art by over 10%,
in terms of relative performance, in the few-shot setting.12</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xingyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Muchao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1">Quanzeng You</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fenglong Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06471">
                                    <div class="article-summary-box-inner">
                                        <span>Medical report generation is one of the most challenging tasks in medical
image analysis. Although existing approaches have achieved promising results,
they either require a predefined template database in order to retrieve
sentences or ignore the hierarchical nature of medical report generation. To
address these issues, we propose MedWriter that incorporates a novel
hierarchical retrieval mechanism to automatically extract both report and
sentence-level templates for clinically accurate report generation. MedWriter
first employs the Visual-Language Retrieval~(VLR) module to retrieve the most
relevant reports for the given images. To guarantee the logical coherence
between sentences, the Language-Language Retrieval~(LLR) module is introduced
to retrieve relevant sentences based on the previous generated description. At
last, a language decoder fuses image features and features from retrieved
reports and sentences to generate meaningful medical reports. We verified the
effectiveness of our model by automatic evaluation and human evaluation on two
datasets, i.e., Open-I and MIMIC-CXR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What is Multimodality?. (arXiv:2103.06304v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1">Letitia Parcalabescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Trost_N/0/1/0/all/0/1">Nils Trost</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06304">
                                    <div class="article-summary-box-inner">
                                        <span>The last years have shown rapid developments in the field of multimodal
machine learning, combining e.g., vision, text or speech. In this position
paper we explain how the field uses outdated definitions of multimodality that
prove unfit for the machine learning era. We propose a new task-relative
definition of (multi)modality in the context of multimodal machine learning
that focuses on representations and information that are relevant for a given
machine learning task. With our new definition of multimodality we aim to
provide a missing foundation for multimodal research, an important component of
language grounding and a crucial milestone towards NLU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chao Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Ye Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1">Zarana Parekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yunhsuan Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1">Tom Duerig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05918">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained representations are becoming crucial for many NLP and perception
tasks. While representation learning in NLP has transitioned to training on raw
text without human annotations, visual and vision-language representations
still rely heavily on curated training datasets that are expensive or require
expert knowledge. For vision applications, representations are mostly learned
using datasets with explicit class labels such as ImageNet or OpenImages. For
vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all
involve a non-trivial data collection (and cleaning) process. This costly
curation process limits the size of datasets and hence hinders the scaling of
trained models. In this paper, we leverage a noisy dataset of over one billion
image alt-text pairs, obtained without expensive filtering or post-processing
steps in the Conceptual Captions dataset. A simple dual-encoder architecture
learns to align visual and language representations of the image and text pairs
using a contrastive loss. We show that the scale of our corpus can make up for
its noise and leads to state-of-the-art representations even with such a simple
learning scheme. Our visual representation achieves strong performance when
transferred to classification tasks such as ImageNet and VTAB. The aligned
visual and language representations enables zero-shot image classification and
also set new state-of-the-art results on Flickr30K and MSCOCO image-text
retrieval benchmarks, even when compared with more sophisticated
cross-attention models. The representations also enable cross-modality search
with complex text and text + image queries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1">Karrar Al-Kaabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1">Reza Monsefi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06420">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning algorithms aim to learn a distance function that brings the
semantically similar data items together and keeps dissimilar ones at a
distance. The traditional Mahalanobis distance learning is equivalent to find a
linear projection. In contrast, Deep Metric Learning (DML) methods are proposed
that automatically extract features from data and learn a non-linear
transformation from input space to a semantically embedding space. Recently,
many DML methods are proposed focused to enhance the discrimination power of
the learned metric by providing novel sampling strategies or loss functions.
This approach is very helpful when both the training and test examples are
coming from the same set of categories. However, it is less effective in many
applications of DML such as image retrieval and person-reidentification. Here,
the DML should learn general semantic concepts from observed classes and employ
them to rank or identify objects from unseen categories. Neglecting the
generalization ability of the learned representation and just emphasizing to
learn a more discriminative embedding on the observed classes may lead to the
overfitting problem. To address this limitation, we propose a framework to
enhance the generalization power of existing DML methods in a Zero-Shot
Learning (ZSL) setting by general yet discriminative representation learning
and employing a class adversarial neural network. To learn a more general
representation, we propose to employ feature maps of intermediate layers in a
deep neural network and enhance their discrimination power through an attention
mechanism. Besides, a class adversarial network is utilized to enforce the deep
model to seek class invariant features for the DML task. We evaluate our work
on widely used machine vision datasets in a ZSL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liangqiong Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Paul Pu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yingda Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Feifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06047">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is an emerging research paradigm enabling collaborative
training of machine learning models among different organizations while keeping
data private at each institution. Despite recent progress, there remain
fundamental challenges such as lack of convergence and potential for
catastrophic forgetting in federated learning across real-world heterogeneous
devices. In this paper, we demonstrate that attention-based architectures
(e.g., Transformers) are fairly robust to distribution shifts and hence improve
federated learning over heterogeneous data. Concretely, we conduct the first
rigorous empirical investigation of different neural architectures across a
range of federated algorithms, real-world benchmarks, and heterogeneous data
splits. Our experiments show that simply replacing convolutional networks with
Transformers can greatly reduce catastrophic forgetting of previous devices,
accelerate convergence, and reach a better global model, especially when
dealing with heterogeneous data. We will release our code and pretrained models
at https://github.com/Liangqiong/ViT-FL-main to encourage future exploration in
robust architectures as an alternative to current research efforts on the
optimization front.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Black-box Explanation of Object Detectors via Saliency Maps. (arXiv:2006.03204v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Petsiuk_V/0/1/0/all/0/1">Vitali Petsiuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rajiv Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1">Varun Manjunatha</a>, <a href="http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1">Vlad I. Morariu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1">Ashutosh Mehra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1">Vicente Ordonez</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03204">
                                    <div class="article-summary-box-inner">
                                        <span>We propose D-RISE, a method for generating visual explanations for the
predictions of object detectors. Utilizing the proposed similarity metric that
accounts for both localization and categorization aspects of object detection
allows our method to produce saliency maps that show image areas that most
affect the prediction. D-RISE can be considered &quot;black-box&quot; in the software
testing sense, as it only needs access to the inputs and outputs of an object
detector. Compared to gradient-based methods, D-RISE is more general and
agnostic to the particular type of object detector being tested, and does not
need knowledge of the inner workings of the model. We show that D-RISE can be
easily applied to different object detectors including one-stage detectors such
as YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed
analysis of the generated visual explanations to highlight the utilization of
context and possible biases learned by object detectors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-based Partial Face Recognition. (arXiv:2106.06415v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1">Stefan H&#xf6;rmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zeyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1">Martin Knoche</a>, <a href="http://arxiv.org/find/cs/1/au:+Teepe_T/0/1/0/all/0/1">Torben Teepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1">Gerhard Rigoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06415">
                                    <div class="article-summary-box-inner">
                                        <span>Photos of faces captured in unconstrained environments, such as large crowds,
still constitute challenges for current face recognition approaches as often
faces are occluded by objects or people in the foreground. However, few studies
have addressed the task of recognizing partial faces. In this paper, we propose
a novel approach to partial face recognition capable of recognizing faces with
different occluded areas. We achieve this by combining attentional pooling of a
ResNet&#x27;s intermediate feature maps with a separate aggregation module. We
further adapt common losses to partial faces in order to ensure that the
attention maps are diverse and handle occluded parts. Our thorough analysis
demonstrates that we outperform all baselines under multiple benchmark
protocols, including naturally and synthetically occluded partial faces. This
suggests that our method successfully focuses on the relevant parts of the
occluded face.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Twins: Revisiting the Design of Spatial Attention in Vision Transformers. (arXiv:2104.13840v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Haibing Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaolin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1">Huaxia Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13840">
                                    <div class="article-summary-box-inner">
                                        <span>Very recently, a variety of vision transformer architectures for dense
prediction tasks have been proposed and they show that the design of spatial
attention is critical to their success in these tasks. In this work, we revisit
the design of the spatial attention and demonstrate that a carefully-devised
yet simple spatial attention mechanism performs favourably against the
state-of-the-art schemes. As a result, we propose two vision transformer
architectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures
are highly-efficient and easy to implement, only involving matrix
multiplications that are highly optimized in modern deep learning frameworks.
More importantly, the proposed architectures achieve excellent performance on a
wide range of visual tasks including imagelevel classification as well as dense
detection and segmentation. The simplicity and strong performance suggest that
our proposed architectures may serve as stronger backbones for many vision
tasks. Our code will be released soon at
https://github.com/Meituan-AutoML/Twins .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation. (arXiv:2106.06056v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huichen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06056">
                                    <div class="article-summary-box-inner">
                                        <span>Boundary based blackbox attack has been recognized as practical and
effective, given that an attacker only needs to access the final model
prediction. However, the query efficiency of it is in general high especially
for high dimensional image data. In this paper, we show that such efficiency
highly depends on the scale at which the attack is applied, and attacking at
the optimal scale significantly improves the efficiency. In particular, we
propose a theoretical framework to analyze and show three key characteristics
to improve the query efficiency. We prove that there exists an optimal scale
for projective gradient estimation. Our framework also explains the
satisfactory performance achieved by existing boundary black-box attacks. Based
on our theoretical framework, we propose Progressive-Scale enabled projective
Boundary Attack (PSBA) to improve the query efficiency via progressive scaling
techniques. In particular, we employ Progressive-GAN to optimize the scale of
projections, which we call PSBA-PGAN. We evaluate our approach on both spatial
and frequency scales. Extensive experiments on MNIST, CIFAR-10, CelebA, and
ImageNet against different models including a real-world face recognition API
show that PSBA-PGAN significantly outperforms existing baseline attacks in
terms of query efficiency and attack success rate. We also observe relatively
stable optimal scales for different models and datasets. The code is publicly
available at https://github.com/AI-secure/PSBA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Online Monitoring and Data-driven Control: A Study of Segmentation Algorithms for Laser Powder Bed Fusion Processes. (arXiv:2011.09065v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nettekoven_A/0/1/0/all/0/1">Alexander Nettekoven</a>, <a href="http://arxiv.org/find/eess/1/au:+Fish_S/0/1/0/all/0/1">Scott Fish</a>, <a href="http://arxiv.org/find/eess/1/au:+Beaman_J/0/1/0/all/0/1">Joseph Beaman</a>, <a href="http://arxiv.org/find/eess/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09065">
                                    <div class="article-summary-box-inner">
                                        <span>An increasing number of laser powder bed fusion machines use off-axis
infrared cameras to improve online monitoring and data-driven control
capabilities. However, there is still a severe lack of algorithmic solutions to
properly process the infrared images from these cameras that has led to several
key limitations: a lack of online monitoring capabilities for the laser tracks,
insufficient pre-processing of the infrared images for data-driven methods, and
large memory requirements for storing the infrared images. To address these
limitations, we study over 30 segmentation algorithms that segment each
infrared image into a foreground and background. By evaluating each algorithm
based on its segmentation accuracy, computational speed, and spatter detection
characteristics, we identify promising algorithmic solutions. The identified
algorithms can be readily applied to the laser powder bed fusion machines to
address each of the above limitations and thus, significantly improve process
control.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1">Kwan Ho Ryan Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaodong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chong You</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Haozhi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1">John Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10446">
                                    <div class="article-summary-box-inner">
                                        <span>This work attempts to provide a plausible theoretical framework that aims to
interpret modern deep (convolutional) networks from the principles of data
compression and discriminative representation. We argue that for
high-dimensional multi-class data, the optimal linear discriminative
representation maximizes the coding rate difference between the whole dataset
and the average of all the subsets. We show that the basic iterative gradient
ascent scheme for optimizing the rate reduction objective naturally leads to a
multi-layer deep network, named ReduNet, which shares common characteristics of
modern deep networks. The deep layered architectures, linear and nonlinear
operators, and even parameters of the network are all explicitly constructed
layer-by-layer via forward propagation, although they are amenable to
fine-tuning via back propagation. All components of so-obtained &#x60;&#x60;white-box&#x27;&#x27;
network have precise optimization, statistical, and geometric interpretation.
Moreover, all linear operators of the so-derived network naturally become
multi-channel convolutions when we enforce classification to be rigorously
shift-invariant. The derivation in the invariant setting suggests a trade-off
between sparsity and invariance, and also indicates that such a deep
convolution network is significantly more efficient to construct and learn in
the spectral domain. Our preliminary simulations and experiments clearly verify
the effectiveness of both the rate reduction objective and the associated
ReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Modeling of Probabilities for Coding the Octree Representation of Point Clouds. (arXiv:2106.06482v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1">Emre Can Kaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1">Ioan Tabus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06482">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a novel lossless point cloud compression algorithm that
uses a neural network for estimating the coding probabilities for the occupancy
status of voxels, depending on wide three dimensional contexts around the voxel
to be encoded. The point cloud is represented as an octree, with each
resolution layer being sequentially encoded and decoded using arithmetic
coding, starting from the lowest resolution, until the final resolution is
reached. The occupancy probability of each voxel of the splitting pattern at
each node of the octree is modeled by a neural network, having at its input the
already encoded occupancy status of several octree nodes (belonging to the past
and current resolutions), corresponding to a 3D context surrounding the node to
be encoded. The algorithm has a fast and a slow version, the fast version
selecting differently several voxels of the context, which allows an increased
parallelization by sending larger batches of templates to be estimated by the
neural network, at both encoder and decoder. The proposed algorithms yield
state-of-the-art results on benchmark datasets. The implementation will be made
available at https://github.com/marmus12/nnctx</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimSwap: An Efficient Framework For High Fidelity Face Swapping. (arXiv:2106.06340v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Renwang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuanhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1">Bingbing Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yanhao Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06340">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an efficient framework, called Simple Swap (SimSwap), aiming for
generalized and high fidelity face swapping. In contrast to previous approaches
that either lack the ability to generalize to arbitrary identity or fail to
preserve attributes like facial expression and gaze direction, our framework is
capable of transferring the identity of an arbitrary source face into an
arbitrary target face while preserving the attributes of the target face. We
overcome the above defects in the following two ways. First, we present the ID
Injection Module (IIM) which transfers the identity information of the source
face into the target face at feature level. By using this module, we extend the
architecture of an identity-specific face swapping algorithm to a framework for
arbitrary face swapping. Second, we propose the Weak Feature Matching Loss
which efficiently helps our framework to preserve the facial attributes in an
implicit way. Extensive experiments on wild faces demonstrate that our SimSwap
is able to achieve competitive identity performance while preserving attributes
better than previous state-of-the-art methods. The code is already available on
github: https://github.com/neuralchen/SimSwap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search without Training. (arXiv:2006.04647v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1">Joseph Mellor</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1">Jack Turner</a>, <a href="http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1">Amos Storkey</a>, <a href="http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1">Elliot J. Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04647">
                                    <div class="article-summary-box-inner">
                                        <span>The time and effort involved in hand-designing deep neural networks is
immense. This has prompted the development of Neural Architecture Search (NAS)
techniques to automate this design. However, NAS algorithms tend to be slow and
expensive; they need to train vast numbers of candidate networks to inform the
search process. This could be alleviated if we could partially predict a
network&#x27;s trained accuracy from its initial state. In this work, we examine the
overlap of activations between datapoints in untrained networks and motivate
how this can give a measure which is usefully indicative of a network&#x27;s trained
performance. We incorporate this measure into a simple algorithm that allows us
to search for powerful networks without any training in a matter of seconds on
a single GPU, and verify its effectiveness on NAS-Bench-101, NAS-Bench-201,
NATS-Bench, and Network Design Spaces. Our approach can be readily combined
with more expensive search methods; we examine a simple adaptation of
regularised evolutionary search. Code for reproducing our experiments is
available at https://github.com/BayesWatch/nas-without-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KRADA: Known-region-aware Domain Alignment for Open World Semantic Segmentation. (arXiv:2106.06237v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1">Chenhong Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gong_C/0/1/0/all/0/1">Chen Gong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheung_W/0/1/0/all/0/1">William Cheung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06237">
                                    <div class="article-summary-box-inner">
                                        <span>In semantic segmentation, we aim to train a pixel-level classifier to assign
category labels to all pixels in an image, where labeled training images and
unlabeled test images are from the same distribution and share the same label
set. However, in an open world, the unlabeled test images probably contain
unknown categories and have different distributions from the labeled images.
Hence, in this paper, we consider a new, more realistic, and more challenging
problem setting where the pixel-level classifier has to be trained with labeled
images and unlabeled open-world images -- we name it open world semantic
segmentation (OSS). In OSS, the trained classifier is expected to identify
unknown-class pixels and classify known-class pixels well. To solve OSS, we
first investigate which distribution that unknown-class pixels obey. Then,
motivated by the goodness-of-fit test, we use statistical measurements to show
how a pixel fits the distribution of an unknown class and select highly-fitted
pixels to form the unknown region in each image. Eventually, we propose an
end-to-end learning framework, known-region-aware domain alignment (KRADA), to
distinguish unknown classes while aligning distributions of known classes in
labeled and unlabeled open-world images. The effectiveness of KRADA has been
verified on two synthetic tasks and one COVID-19 segmentation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recovery of Meteorites Using an Autonomous Drone and Machine Learning. (arXiv:2106.06523v1 [astro-ph.EP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Citron_R/0/1/0/all/0/1">Robert I. Citron</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Jenniskens_P/0/1/0/all/0/1">Peter Jenniskens</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Watkins_C/0/1/0/all/0/1">Christopher Watkins</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sinha_S/0/1/0/all/0/1">Sravanthi Sinha</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Shah_A/0/1/0/all/0/1">Amar Shah</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Raissi_C/0/1/0/all/0/1">Chedy Raissi</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Devillepoix_H/0/1/0/all/0/1">Hadrien Devillepoix</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Albers_J/0/1/0/all/0/1">Jim Albers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06523">
                                    <div class="article-summary-box-inner">
                                        <span>The recovery of freshly fallen meteorites from tracked and triangulated
meteors is critical to determining their source asteroid families. However,
locating meteorite fragments in strewn fields remains a challenge with very few
meteorites being recovered from the meteors triangulated in past and ongoing
meteor camera networks. We examined if locating meteorites can be automated
using machine learning and an autonomous drone. Drones can be programmed to fly
a grid search pattern and take systematic pictures of the ground over a large
survey area. Those images can be analyzed using a machine learning classifier
to identify meteorites in the field among many other features. Here, we
describe a proof-of-concept meteorite classifier that deploys off-line a
combination of different convolution neural networks to recognize meteorites
from images taken by drones in the field. The system was implemented in a
conceptual drone setup and tested in the suspected strewn field of a recent
meteorite fall near Walker Lake, Nevada.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A modular framework for object-based saccadic decisions in dynamic scenes. (arXiv:2106.06073v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roth_N/0/1/0/all/0/1">Nicolas Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Bideau_P/0/1/0/all/0/1">Pia Bideau</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellwich_O/0/1/0/all/0/1">Olaf Hellwich</a>, <a href="http://arxiv.org/find/cs/1/au:+Rolfs_M/0/1/0/all/0/1">Martin Rolfs</a>, <a href="http://arxiv.org/find/cs/1/au:+Obermayer_K/0/1/0/all/0/1">Klaus Obermayer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06073">
                                    <div class="article-summary-box-inner">
                                        <span>Visually exploring the world around us is not a passive process. Instead, we
actively explore the world and acquire visual information over time. Here, we
present a new model for simulating human eye-movement behavior in dynamic
real-world scenes. We model this active scene exploration as a sequential
decision making process. We adapt the popular drift-diffusion model (DDM) for
perceptual decision making and extend it towards multiple options, defined by
objects present in the scene. For each possible choice, the model integrates
evidence over time and a decision (saccadic eye movement) is triggered as soon
as evidence crosses a decision threshold. Drawing this explicit connection
between decision making and object-based scene perception is highly relevant in
the context of active viewing, where decisions are made continuously while
interacting with an external environment. We validate our model with a
carefully designed ablation study and explore influences of our model
parameters. A comparison on the VidCom dataset supports the plausibility of the
proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaussian Bounding Boxes and Probabilistic Intersection-over-Union for Object Detection. (arXiv:2106.06072v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Llerena_J/0/1/0/all/0/1">Jeffri M. Llerena</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeni_L/0/1/0/all/0/1">Luis Felipe Zeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Kristen_L/0/1/0/all/0/1">Lucas N. Kristen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1">Claudio Jung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06072">
                                    <div class="article-summary-box-inner">
                                        <span>Most object detection methods use bounding boxes to encode and represent the
object shape and location. In this work, we explore a fuzzy representation of
object regions using Gaussian distributions, which provides an implicit binary
representation as (potentially rotated) ellipses. We also present a similarity
measure for the Gaussian distributions based on the Hellinger Distance, which
can be viewed as a Probabilistic Intersection-over-Union (ProbIoU). Our
experimental results show that the proposed Gaussian representations are closer
to annotated segmentation masks in publicly available datasets, and that loss
functions based on ProbIoU can be successfully used to regress the parameters
of the Gaussian representation. Furthermore, we present a simple mapping scheme
from traditional (or rotated) bounding boxes to Gaussian representations,
allowing the proposed ProbIoU-based losses to be seamlessly integrated into any
object detector.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming Difficulty in Obtaining Dark-skinned Subjects for Remote-PPG by Synthetic Augmentation. (arXiv:2106.06007v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ba_Y/0/1/0/all/0/1">Yunhao Ba</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karinca_K/0/1/0/all/0/1">Kerim Doruk Karinca</a>, <a href="http://arxiv.org/find/cs/1/au:+Bozkurt_O/0/1/0/all/0/1">Oyku Deniz Bozkurt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadambi_A/0/1/0/all/0/1">Achuta Kadambi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06007">
                                    <div class="article-summary-box-inner">
                                        <span>Camera-based remote photoplethysmography (rPPG) provides a non-contact way to
measure physiological signals (e.g., heart rate) using facial videos. Recent
deep learning architectures have improved the accuracy of such physiological
measurement significantly, yet they are restricted by the diversity of the
annotated videos. The existing datasets MMSE-HR, AFRL, and UBFC-RPPG contain
roughly 10%, 0%, and 5% of dark-skinned subjects respectively. The unbalanced
training sets result in a poor generalization capability to unseen subjects and
lead to unwanted bias toward different demographic groups. In Western academia,
it is regrettably difficult in a university setting to collect data on these
dark-skinned subjects. Here we show a first attempt to overcome the lack of
dark-skinned subjects by synthetic augmentation. A joint optimization framework
is utilized to translate real videos from light-skinned subjects to dark skin
tones while retaining their pulsatile signals. In the experiment, our method
exhibits around 31% reduction in mean absolute error for the dark-skinned group
and 46% improvement on bias mitigation for all the groups, as compared with the
previous work trained with just real samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Unsupervised Domain Adaptation for Visual Recognition. (arXiv:2106.06112v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06112">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) aims to learn a well-performed model in
an unlabeled target domain by leveraging labeled data from one or multiple
related source domains. It remains a great challenge due to 1) the lack of
annotations in the target domain and 2) the rich discrepancy between the
distributions of source and target data. We propose Spectral UDA (SUDA), an
efficient yet effective UDA technique that works in the spectral space and is
generic across different visual recognition tasks in detection, classification
and segmentation. SUDA addresses UDA challenges from two perspectives. First,
it mitigates inter-domain discrepancies by a spectrum transformer (ST) that
maps source and target images into spectral space and learns to enhance
domain-invariant spectra while suppressing domain-variant spectra
simultaneously. To this end, we design novel adversarial multi-head spectrum
attention that leverages contextual information to identify domain-variant and
domain-invariant spectra effectively. Second, it mitigates the lack of
annotations in target domain by introducing multi-view spectral learning which
aims to learn comprehensive yet confident target representations by maximizing
the mutual information among multiple ST augmentations capturing different
spectral views of each target sample. Extensive experiments over different
visual tasks (e.g., detection, classification and segmentation) show that SUDA
achieves superior accuracy and it is also complementary with state-of-the-art
UDA methods with consistent performance boosts but little extra computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Part-aware Panoptic Segmentation. (arXiv:2106.06351v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geus_D/0/1/0/all/0/1">Daan de Geus</a>, <a href="http://arxiv.org/find/cs/1/au:+Meletis_P/0/1/0/all/0/1">Panagiotis Meletis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chenyang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1">Xiaoxiao Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubbelman_G/0/1/0/all/0/1">Gijs Dubbelman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06351">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce the new scene understanding task of Part-aware
Panoptic Segmentation (PPS), which aims to understand a scene at multiple
levels of abstraction, and unifies the tasks of scene parsing and part parsing.
For this novel task, we provide consistent annotations on two commonly used
datasets: Cityscapes and Pascal VOC. Moreover, we present a single metric to
evaluate PPS, called Part-aware Panoptic Quality (PartPQ). For this new task,
using the metric and annotations, we set multiple baselines by merging results
of existing state-of-the-art methods for panoptic segmentation and part
segmentation. Finally, we conduct several experiments that evaluate the
importance of the different levels of abstraction in this single task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyGAD: An Intuitive Genetic Algorithm Python Library. (arXiv:2106.06158v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gad_A/0/1/0/all/0/1">Ahmed Fawzy Gad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06158">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces PyGAD, an open-source easy-to-use Python library for
building the genetic algorithm. PyGAD supports a wide range of parameters to
give the user control over everything in its life cycle. This includes, but is
not limited to, population, gene value range, gene data type, parent selection,
crossover, and mutation. PyGAD is designed as a general-purpose optimization
library that allows the user to customize the fitness function. Its usage
consists of 3 main steps: build the fitness function, create an instance of the
pygad.GA class, and calling the pygad.GA.run() method. The library supports
training deep learning models created either with PyGAD itself or with
frameworks like Keras and PyTorch. Given its stable state, PyGAD is also in
active development to respond to the user&#x27;s requested features and enhancement
received on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD
comes with documentation https://pygad.readthedocs.io for further details and
examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Deep Learning Architectures for Fast Identification of Bacterial Strains in Resource-Constrained Devices. (arXiv:2106.06505v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garcia_R/0/1/0/all/0/1">R. Gallardo Garc&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1">S. Jarqu&#xed;n Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1">B. Beltr&#xe1;n Mart&#xed;nez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gracidas_C/0/1/0/all/0/1">C. Hern&#xe1;ndez Gracidas</a>, <a href="http://arxiv.org/find/cs/1/au:+Torres_R/0/1/0/all/0/1">R. Mart&#xed;nez Torres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06505">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents twelve fine-tuned deep learning architectures to solve the
bacterial classification problem over the Digital Image of Bacterial Species
Dataset. The base architectures were mainly published as mobile or efficient
solutions to the ImageNet challenge, and all experiments presented in this work
consisted of making several modifications to the original designs, in order to
make them able to solve the bacterial classification problem by using
fine-tuning and transfer learning techniques. This work also proposes a novel
data augmentation technique for this dataset, which is based on the idea of
artificial zooming, strongly increasing the performance of every tested
architecture, even doubling it in some cases. In order to get robust and
complete evaluations, all experiments were performed with 10-fold
cross-validation and evaluated with five different metrics: top-1 and top-5
accuracy, precision, recall, and F1 score. This paper presents a complete
comparison of the twelve different architectures, cross-validated with the
original and the augmented version of the dataset, the results are also
compared with several literature methods. Overall, eight of the eleven
architectures surpassed the 0.95 scores in top-1 accuracy with our data
augmentation method, being 0.9738 the highest top-1 accuracy. The impact of the
data augmentation technique is reported with relative improvement scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compositional Video Synthesis with Action Graphs. (arXiv:2006.15327v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1">Amir Bar</a>, <a href="http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1">Roei Herzig</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1">Amir Globerson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15327">
                                    <div class="article-summary-box-inner">
                                        <span>Videos of actions are complex signals containing rich compositional structure
in space and time. Current video generation methods lack the ability to
condition the generation on multiple coordinated and potentially simultaneous
timed actions. To address this challenge, we propose to represent the actions
in a graph structure called Action Graph and present the new &#x60;&#x60;Action Graph To
Video&#x27;&#x27; synthesis task. Our generative model for this task (AG2Vid)
disentangles motion and appearance features, and by incorporating a scheduling
mechanism for actions facilitates a timely and coordinated video generation. We
train and evaluate AG2Vid on the CATER and Something-Something V2 datasets, and
show that the resulting videos have better visual quality and semantic
consistency compared to baselines. Finally, our model demonstrates zero-shot
abilities by synthesizing novel compositions of the learned actions. For code
and pretrained models, see the project page https://roeiherz.github.io/AG2Video</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Semantic Scene Completion: a Survey. (arXiv:2103.07466v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roldao_L/0/1/0/all/0/1">Luis Roldao</a>, <a href="http://arxiv.org/find/cs/1/au:+Charette_R/0/1/0/all/0/1">Raoul de Charette</a>, <a href="http://arxiv.org/find/cs/1/au:+Verroust_Blondet_A/0/1/0/all/0/1">Anne Verroust-Blondet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07466">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic Scene Completion (SSC) aims to jointly estimate the complete
geometry and semantics of a scene, assuming partial sparse input. In the last
years following the multiplication of large-scale 3D datasets, SSC has gained
significant momentum in the research community because it holds unresolved
challenges. Specifically, SSC lies in the ambiguous completion of large
unobserved areas and the weak supervision signal of the ground truth. This led
to a substantially increasing number of papers on the matter. This survey aims
to identify, compare and analyze the techniques providing a critical analysis
of the SSC literature on both methods and datasets. Throughout the paper, we
provide an in-depth analysis of the existing works covering all choices made by
the authors while highlighting the remaining avenues of research. SSC
performance of the SoA on the most popular datasets is also evaluated and
analyzed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinghan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Boloor_A/0/1/0/all/0/1">Adith Boloor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Ayan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1">Yevgeniy Vorobeychik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08844">
                                    <div class="article-summary-box-inner">
                                        <span>There is considerable evidence that deep neural networks are vulnerable to
adversarial perturbations applied directly to their digital inputs. However, it
remains an open question whether this translates to vulnerabilities in real
systems. For example, an attack on self-driving cars would in practice entail
modifying the driving environment, which then impacts the video inputs to the
car&#x27;s controller, thereby indirectly leading to incorrect driving decisions.
Such attacks require accounting for system dynamics and tracking viewpoint
changes. We propose a scalable approach for finding adversarial modifications
of a simulated autonomous driving environment using a differentiable
approximation for the mapping from environmental modifications (rectangles on
the road) to the corresponding video inputs to the controller neural network.
Given the parameters of the rectangles, our proposed differentiable mapping
composites them onto pre-recorded video streams of the original environment,
accounting for geometric and color variations. Moreover, we propose a multiple
trajectory sampling approach that enables our attacks to be robust to a car&#x27;s
self-correcting behavior. When combined with a neural network-based controller,
our approach allows the design of adversarial modifications through end-to-end
gradient-based optimization. Using the Carla autonomous driving simulator, we
show that our approach is significantly more scalable and far more effective at
identifying autonomous vehicle vulnerabilities in simulation experiments than a
state-of-the-art approach based on Bayesian Optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast, Accurate Barcode Detection in Ultra High-Resolution Images. (arXiv:2102.06868v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Quenum_J/0/1/0/all/0/1">Jerome Quenum</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kehan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zakhor_A/0/1/0/all/0/1">Avideh Zakhor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06868">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection in Ultra High-Resolution (UHR) images has long been a
challenging problem in computer vision due to the varying scales of the
targeted objects. When it comes to barcode detection, resizing UHR input images
to smaller sizes often leads to the loss of pertinent information, while
processing them directly is highly inefficient and computationally expensive.
In this paper, we propose using semantic segmentation to achieve a fast and
accurate detection of barcodes of various scales in UHR images. Our pipeline
involves a modified Region Proposal Network (RPN) on images of size greater
than 10k$\times$10k and a newly proposed Y-Net segmentation network, followed
by a post-processing workflow for fitting a bounding box around each segmented
barcode mask. The end-to-end system has a latency of 16 milliseconds, which is
$2.5\times$ faster than YOLOv4 and $5.9\times$ faster than Mask R-CNN. In terms
of accuracy, our method outperforms YOLOv4 and Mask R-CNN by a $mAP$ of 5.5%
and 47.1% respectively, on a synthetic dataset. We have made available the
generated synthetic barcode dataset and its code at
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Real-World Blind Face Restoration with Generative Facial Prior. (arXiv:2101.04061v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xintao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Honglun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1">Ying Shan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04061">
                                    <div class="article-summary-box-inner">
                                        <span>Blind face restoration usually relies on facial priors, such as facial
geometry prior or reference prior, to restore realistic and faithful details.
However, very low-quality inputs cannot offer accurate geometric prior while
high-quality references are inaccessible, limiting the applicability in
real-world scenarios. In this work, we propose GFP-GAN that leverages rich and
diverse priors encapsulated in a pretrained face GAN for blind face
restoration. This Generative Facial Prior (GFP) is incorporated into the face
restoration process via novel channel-split spatial feature transform layers,
which allow our method to achieve a good balance of realness and fidelity.
Thanks to the powerful generative facial prior and delicate designs, our
GFP-GAN could jointly restore facial details and enhance colors with just a
single forward pass, while GAN inversion methods require expensive
image-specific optimization at inference. Extensive experiments show that our
method achieves superior performance to prior art on both synthetic and
real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridge the Gap Between Model-based and Model-free Human Reconstruction. (arXiv:2106.06313v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Lixiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jianke Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06313">
                                    <div class="article-summary-box-inner">
                                        <span>It is challenging to directly estimate the geometry of human from a single
image due to the high diversity and complexity of body shapes with the various
clothing styles. Most of model-based approaches are limited to predict the
shape and pose of a minimally clothed body with over-smoothing surface.
Although capturing the fine detailed geometries, the model-free methods are
lack of the fixed mesh topology. To address these issues, we propose a novel
topology-preserved human reconstruction approach by bridging the gap between
model-based and model-free human reconstruction. We present an end-to-end
neural network that simultaneously predicts the pixel-aligned implicit surface
and the explicit mesh model built by graph convolutional neural network.
Moreover, an extra graph convolutional neural network is employed to estimate
the vertex offsets between the implicit surface and parametric mesh model.
Finally, we suggest an efficient implicit registration method to refine the
neural network output in implicit space. Experiments on DeepHuman dataset
showed that our approach is effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions. (arXiv:2104.02710v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jennifer J. Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Karigo_T/0/1/0/all/0/1">Tomomi Karigo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Dipam Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1">Sharada P. Mohanty</a>, <a href="http://arxiv.org/find/cs/1/au:+Wild_B/0/1/0/all/0/1">Benjamin Wild</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Quan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1">David J. Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1">Pietro Perona</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1">Ann Kennedy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02710">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent behavior modeling aims to understand the interactions that occur
between agents. We present a multi-agent dataset from behavioral neuroscience,
the Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists
of trajectory data of social interactions, recorded from videos of freely
behaving mice in a standard resident-intruder assay. To help accelerate
behavioral studies, the CalMS21 dataset provides benchmarks to evaluate the
performance of automated behavior classification methods in three settings: (1)
for training on large behavioral datasets all annotated by a single annotator,
(2) for style transfer to learn inter-annotator differences in behavior
definitions, and (3) for learning of new behaviors of interest given limited
training data. The dataset consists of 6 million frames of unlabeled tracked
poses of interacting mice, as well as over 1 million frames with tracked poses
and corresponding frame-level behavior annotations. The challenge of our
dataset is to be able to classify behaviors accurately using both labeled and
unlabeled tracking data, as well as being able to generalize to new settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Survey of Image Based Graph Neural Networks. (arXiv:2106.06307v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nazir_U/0/1/0/all/0/1">Usman Nazir</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Taj_M/0/1/0/all/0/1">Murtaza Taj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06307">
                                    <div class="article-summary-box-inner">
                                        <span>In this survey paper, we analyze image based graph neural networks and
propose a three-step classification approach. We first convert the image into
superpixels using the Quickshift algorithm so as to reduce 30% of the input
data. The superpixels are subsequently used to generate a region adjacency
graph. Finally, the graph is passed through a state-of-art graph convolutional
neural network to get classification scores. We also analyze the spatial and
spectral convolution filtering techniques in graph neural networks.
Spectral-based models perform better than spatial-based models and classical
CNN with lesser compute cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">View Generalization for Single Image Textured 3D Models. (arXiv:2106.06533v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattad_A/0/1/0/all/0/1">Anand Bhattad</a>, <a href="http://arxiv.org/find/cs/1/au:+Dundar_A/0/1/0/all/0/1">Aysegul Dundar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guilin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1">Andrew Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06533">
                                    <div class="article-summary-box-inner">
                                        <span>Humans can easily infer the underlying 3D geometry and texture of an object
only from a single 2D image. Current computer vision methods can do this, too,
but suffer from view generalization problems - the models inferred tend to make
poor predictions of appearance in novel views. As for generalization problems
in machine learning, the difficulty is balancing single-view accuracy (cf.
training error; bias) with novel view accuracy (cf. test error; variance). We
describe a class of models whose geometric rigidity is easily controlled to
manage this tradeoff. We describe a cycle consistency loss that improves view
generalization (roughly, a model from a generated view should predict the
original view well). View generalization of textures requires that models share
texture information, so a car seen from the back still has headlights because
other cars have headlights. We describe a cycle consistency loss that
encourages model textures to be aligned, so as to encourage sharing. We compare
our method against the state-of-the-art method and show both qualitative and
quantitative improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jansson_Y/0/1/0/all/0/1">Ylva Jansson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindeberg_T/0/1/0/all/0/1">Tony Lindeberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06418">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to handle large scale variations is crucial for many real world
visual tasks. A straightforward approach for handling scale in a deep network
is to process an image at several scales simultaneously in a set of scale
channels. Scale invariance can then, in principle, be achieved by using weight
sharing between the scale channels together with max or average pooling over
the outputs from the scale channels. The ability of such scale channel networks
to generalise to scales not present in the training set over significant scale
ranges has, however, not previously been explored.

In this paper, we present a systematic study of this methodology by
implementing different types of scale channel networks and evaluating their
ability to generalise to previously unseen scales. We develop a formalism for
analysing the covariance and invariance properties of scale channel networks,
and explore how different design choices, unique to scaling transformations,
affect the overall performance of scale channel networks. We first show that
two previously proposed scale channel network designs do not generalise well to
scales not present in the training set. We explain theoretically and
demonstrate experimentally why generalisation fails in these cases.

We then propose a new type of foveated scale channel architecture}, where the
scale channels process increasingly larger parts of the image with decreasing
resolution. This new type of scale channel network is shown to generalise
extremely well, provided sufficient image resolution and the absence of
boundary effects. Our proposed FovMax and FovAvg networks perform almost
identically over a scale range of 8, also when training on single scale
training data, and do also give improved performance when learning from
datasets with large scale variations in the small sample regime.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Intra-Batch Connections for Deep Metric Learning. (arXiv:2102.07753v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seidenschwarz_J/0/1/0/all/0/1">Jenny Seidenschwarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1">Ismail Elezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1">Laura Leal-Taix&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07753">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of metric learning is to learn a function that maps samples to a
lower-dimensional space where similar samples lie closer than dissimilar ones.
Particularly, deep metric learning utilizes neural networks to learn such a
mapping. Most approaches rely on losses that only take the relations between
pairs or triplets of samples into account, which either belong to the same
class or two different classes. However, these methods do not explore the
embedding space in its entirety. To this end, we propose an approach based on
message passing networks that takes all the relations in a mini-batch into
account. We refine embedding vectors by exchanging messages among all samples
in a given batch allowing the training process to be aware of its overall
structure. Since not all samples are equally important to predict a decision
boundary, we use an attention mechanism during message passing to allow samples
to weigh the importance of each neighbor accordingly. We achieve
state-of-the-art results on clustering and image retrieval on the CUB-200-2011,
Cars196, Stanford Online Products, and In-Shop Clothes datasets. To facilitate
further research, we make available the code and the models at
https://github.com/dvl-tum/intra_batch_connections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A deep learning approach to clustering visual arts. (arXiv:2106.06234v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castellano_G/0/1/0/all/0/1">Giovanna Castellano</a>, <a href="http://arxiv.org/find/cs/1/au:+Vessio_G/0/1/0/all/0/1">Gennaro Vessio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06234">
                                    <div class="article-summary-box-inner">
                                        <span>Clustering artworks is difficult for several reasons. On the one hand,
recognizing meaningful patterns based on domain knowledge and visual perception
is extremely hard. On the other hand, applying traditional clustering and
feature reduction techniques to the highly dimensional pixel space can be
ineffective. To address these issues, in this paper we propose DELIUS: a DEep
learning approach to cLustering vIsUal artS. The method uses a pre-trained
convolutional network to extract features and then feeds these features into a
deep embedded clustering model, where the task of mapping the raw input data to
a latent space is jointly optimized with the task of finding a set of cluster
centroids in this latent space. Quantitative and qualitative experimental
results show the effectiveness of the proposed method. DELIUS can be useful for
several tasks related to art analysis, in particular visual link retrieval and
historical knowledge discovery in painting datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A self-adapting super-resolution structures framework for automatic design of GAN. (arXiv:2106.06011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yibo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haidi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yiming Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shunyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06011">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of deep learning, the single super-resolution image
reconstruction network models are becoming more and more complex. Small changes
in hyperparameters of the models have a greater impact on model performance. In
the existing works, experts have gradually explored a set of optimal model
parameters based on empirical values or performing brute-force search. In this
paper, we introduce a new super-resolution image reconstruction generative
adversarial network framework, and a Bayesian optimization method used to
optimizing the hyperparameters of the generator and discriminator. The
generator is made by self-calibrated convolution, and discriminator is made by
convolution lays. We have defined the hyperparameters such as the number of
network layers and the number of neurons. Our method adopts Bayesian
optimization as a optimization policy of GAN in our model. Not only can find
the optimal hyperparameter solution automatically, but also can construct a
super-resolution image reconstruction network, reducing the manual workload.
Experiments show that Bayesian optimization can search the optimal solution
earlier than the other two optimization algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Antipodal Robotic Grasping using Generative Residual Convolutional Neural Network. (arXiv:1909.04810v4 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumra_S/0/1/0/all/0/1">Sulabh Kumra</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Shirin Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahin_F/0/1/0/all/0/1">Ferat Sahin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.04810">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a modular robotic system to tackle the problem of
generating and performing antipodal robotic grasps for unknown objects from
n-channel image of the scene. We propose a novel Generative Residual
Convolutional Neural Network (GR-ConvNet) model that can generate robust
antipodal grasps from n-channel input at real-time speeds (~20ms). We evaluate
the proposed model architecture on standard datasets and a diverse set of
household objects. We achieved state-of-the-art accuracy of 97.7% and 94.6% on
Cornell and Jacquard grasping datasets respectively. We also demonstrate a
grasp success rate of 95.4% and 93% on household and adversarial objects
respectively using a 7 DoF robotic arm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiPointNet: Binary Neural Network for Point Clouds. (arXiv:2010.05501v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_H/0/1/0/all/0/1">Haotong Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhongang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mingyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yifu Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haiyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xianglong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hao Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05501">
                                    <div class="article-summary-box-inner">
                                        <span>To alleviate the resource constraint for real-time point cloud applications
that run on edge devices, in this paper we present BiPointNet, the first model
binarization approach for efficient deep learning on point clouds. We discover
that the immense performance drop of binarized models for point clouds mainly
stems from two challenges: aggregation-induced feature homogenization that
leads to a degradation of information entropy, and scale distortion that
hinders optimization and invalidates scale-sensitive structures. With
theoretical justifications and in-depth analysis, our BiPointNet introduces
Entropy-Maximizing Aggregation (EMA) to modulate the distribution before
aggregation for the maximum information entropy, and Layer-wise Scale Recovery
(LSR) to efficiently restore feature representation capacity. Extensive
experiments show that BiPointNet outperforms existing binarization methods by
convincing margins, at the level even comparable with the full precision
counterpart. We highlight that our techniques are generic, guaranteeing
significant improvements on various fundamental tasks and mainstream backbones.
Moreover, BiPointNet gives an impressive 14.7x speedup and 18.9x storage saving
on real-world resource-constrained devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-Time Global Illumination Decomposition of Videos. (arXiv:1908.01961v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1">Abhimitra Meka</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiei_M/0/1/0/all/0/1">Mohammad Shafiei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1">Michael Zollhoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Richardt_C/0/1/0/all/0/1">Christian Richardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01961">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the first approach for the decomposition of a monocular color
video into direct and indirect illumination components in real time. We
retrieve, in separate layers, the contribution made to the scene appearance by
the scene reflectance, the light sources and the reflections from various
coherent scene regions to one another. Existing techniques that invert global
light transport require image capture under multiplexed controlled lighting, or
only enable the decomposition of a single image at slow off-line frame rates.
In contrast, our approach works for regular videos and produces temporally
coherent decomposition layers at real-time frame rates. At the core of our
approach are several sparsity priors that enable the estimation of the
per-pixel direct and indirect illumination layers based on a small set of
jointly estimated base reflectance colors. The resulting variational
decomposition problem uses a new formulation based on sparse and dense sets of
non-linear equations that we solve efficiently using a novel alternating
data-parallel optimization strategy. We evaluate our approach qualitatively and
quantitatively, and show improvements over the state of the art in this field,
in both quality and runtime. In addition, we demonstrate various real-time
appearance editing applications for videos with consistent illumination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conterfactual Generative Zero-Shot Semantic Segmentation. (arXiv:2106.06360v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1">Feihong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Ping Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06360">
                                    <div class="article-summary-box-inner">
                                        <span>zero-shot learning is an essential part of computer vision. As a classical
downstream task, zero-shot semantic segmentation has been studied because of
its applicant value. One of the popular zero-shot semantic segmentation methods
is based on the generative model Most new proposed works added structures on
the same architecture to enhance this model. However, we found that, from the
view of causal inference, the result of the original model has been influenced
by spurious statistical relationships. Thus the performance of the prediction
shows severe bias. In this work, we consider counterfactual methods to avoid
the confounder in the original model. Based on this method, we proposed a new
framework for zero-shot semantic segmentation. Our model is compared with
baseline models on two real-world datasets, Pascal-VOC and Pascal-Context. The
experiment results show proposed models can surpass previous confounded models
and can still make use of additional structures to improve the performance. We
also design a simple structure based on Graph Convolutional Networks (GCN) in
this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Generalising Neural Implicit Representations. (arXiv:2101.12690v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costain_T/0/1/0/all/0/1">Theo W. Costain</a>, <a href="http://arxiv.org/find/cs/1/au:+Prisacariu_V/0/1/0/all/0/1">Victor Adrian Prisacariu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12690">
                                    <div class="article-summary-box-inner">
                                        <span>Neural implicit representations have shown substantial improvements in
efficiently storing 3D data, when compared to conventional formats. However,
the focus of existing work has mainly been on storage and subsequent
reconstruction. In this work, we show that training neural representations for
reconstruction tasks alongside conventional tasks can produce more general
encodings that admit equal quality reconstructions to single task training,
whilst improving results on conventional tasks when compared to single task
encodings. We reformulate the semantic segmentation task, creating a more
representative task for implicit representation contexts, and through
multi-task experiments on reconstruction, classification, and segmentation,
show our approach learns feature rich encodings that admit equal performance
for each task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation Disentanglement for Multi-modal brain MR Analysis. (arXiv:2102.11456v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1">Jiahong Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Pohl_K/0/1/0/all/0/1">Kilian M. Pohl</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qingyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaharchuk_G/0/1/0/all/0/1">Greg Zaharchuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11456">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-modal MRIs are widely used in neuroimaging applications since different
MR sequences provide complementary information about brain structures. Recent
works have suggested that multi-modal deep learning analysis can benefit from
explicitly disentangling anatomical (shape) and modality (appearance)
information into separate image presentations. In this work, we challenge
mainstream strategies by showing that they do not naturally lead to
representation disentanglement both in theory and in practice. To address this
issue, we propose a margin loss that regularizes the similarity in
relationships of the representations across subjects and modalities. To enable
robust training, we further use a conditional convolution to design a single
model for encoding images of all modalities. Lastly, we propose a fusion
function to combine the disentangled anatomical representations as a set of
modality-invariant features for downstream tasks. We evaluate the proposed
method on three multi-modal neuroimaging datasets. Experiments show that our
proposed method can achieve superior disentangled representations compared to
existing disentanglement strategies. Results also indicate that the fused
anatomical representation has potential in the downstream task of zero-dose PET
reconstruction and brain tumor segmentation. The code is available at
\url{https://github.com/ouyangjiahong/representation-disentanglement}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Next Local Appearance for Video Anomaly Detection. (arXiv:2106.06059v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_P/0/1/0/all/0/1">Pankaj Raj Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilodeau_G/0/1/0/all/0/1">Guillaume-Alexandre Bilodeau</a>, <a href="http://arxiv.org/find/cs/1/au:+Seoud_L/0/1/0/all/0/1">Lama Seoud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06059">
                                    <div class="article-summary-box-inner">
                                        <span>We present a local anomaly detection method in videos. As opposed to most
existing methods that are computationally expensive and are not very
generalizable across different video scenes, we propose an adversarial
framework that learns the temporal local appearance variations by predicting
the appearance of a normally behaving object in the next frame of a scene by
only relying on its current and past appearances. In the presence of an
abnormally behaving object, the reconstruction error between the real and the
predicted next appearance of that object indicates the likelihood of an
anomaly. Our method is competitive with the existing state-of-the-art while
being significantly faster for both training and inference and being better at
generalizing to unseen video scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Step-Wise Hierarchical Alignment Network for Image-Text Matching. (arXiv:2106.06509v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Zhong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kexin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoran Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06509">
                                    <div class="article-summary-box-inner">
                                        <span>Image-text matching plays a central role in bridging the semantic gap between
vision and language. The key point to achieve precise visual-semantic alignment
lies in capturing the fine-grained cross-modal correspondence between image and
text. Most previous methods rely on single-step reasoning to discover the
visual-semantic interactions, which lacks the ability of exploiting the
multi-level information to locate the hierarchical fine-grained relevance.
Different from them, in this work, we propose a step-wise hierarchical
alignment network (SHAN) that decomposes image-text matching into multi-step
cross-modal reasoning process. Specifically, we first achieve local-to-local
alignment at fragment level, following by performing global-to-local and
global-to-global alignment at context level sequentially. This progressive
alignment strategy supplies our model with more complementary and sufficient
semantic clues to understand the hierarchical correlations between image and
text. The experimental results on two benchmark datasets demonstrate the
superiority of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Small Object Detection for Near Real-Time Egocentric Perception in a Manual Assembly Scenario. (arXiv:2106.06403v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tavakoli_H/0/1/0/all/0/1">Hooman Tavakoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Walunj_S/0/1/0/all/0/1">Snehal Walunj</a>, <a href="http://arxiv.org/find/cs/1/au:+Pahlevannejad_P/0/1/0/all/0/1">Parsha Pahlevannejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Plociennik_C/0/1/0/all/0/1">Christiane Plociennik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruskowski_M/0/1/0/all/0/1">Martin Ruskowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06403">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting small objects in video streams of head-worn augmented reality
devices in near real-time is a huge challenge: training data is typically
scarce, the input video stream can be of limited quality, and small objects are
notoriously hard to detect. In industrial scenarios, however, it is often
possible to leverage contextual knowledge for the detection of small objects.
Furthermore, CAD data of objects are typically available and can be used to
generate synthetic training data. We describe a near real-time small object
detection pipeline for egocentric perception in a manual assembly scenario: We
generate a training data set based on CAD data and realistic backgrounds in
Unity. We then train a YOLOv4 model for a two-stage detection process: First,
the context is recognized, then the small object of interest is detected. We
evaluate our pipeline on the augmented reality device Microsoft Hololens 2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MlTr: Multi-label Classification with Transformer. (arXiv:2106.06195v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xing Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hezheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiangyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1">Dong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1">Nian Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Honglin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06195">
                                    <div class="article-summary-box-inner">
                                        <span>The task of multi-label image classification is to recognize all the object
labels presented in an image. Though advancing for years, small objects,
similar objects and objects with high conditional probability are still the
main bottlenecks of previous convolutional neural network(CNN) based models,
limited by convolutional kernels&#x27; representational capacity. Recent vision
transformer networks utilize the self-attention mechanism to extract the
feature of pixel granularity, which expresses richer local semantic
information, while is insufficient for mining global spatial dependence. In
this paper, we point out the three crucial problems that CNN-based methods
encounter and explore the possibility of conducting specific transformer
modules to settle them. We put forward a Multi-label Transformer
architecture(MlTr) constructed with windows partitioning, in-window pixel
attention, cross-window attention, particularly improving the performance of
multi-label image classification tasks. The proposed MlTr shows
state-of-the-art results on various prevalent multi-label datasets such as
MS-COCO, Pascal-VOC, and NUS-WIDE with 88.5%, 95.8%, and 65.5% respectively.
The code will be available soon at https://github.com/starmemda/MlTr/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Team RUC_AIM3 Technical Report at ActivityNet 2021: Entities Object Localization. (arXiv:2106.06138v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruan_L/0/1/0/all/0/1">Ludan Ruan</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jieting Chen</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yuqing Song</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shizhe Chen</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qin Jin</a> (1) ((1) Renmin University of China, (2) INRIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06138">
                                    <div class="article-summary-box-inner">
                                        <span>Entities Object Localization (EOL) aims to evaluate how grounded or faithful
a description is, which consists of caption generation and object grounding.
Previous works tackle this problem by jointly training the two modules in a
framework, which limits the complexity of each module. Therefore, in this work,
we propose to divide these two modules into two stages and improve them
respectively to boost the whole system performance. For the caption generation,
we propose a Unified Multi-modal Pre-training Model (UMPM) to generate event
descriptions with rich objects for better localization. For the object
grounding, we fine-tune the state-of-the-art detection model MDETR and design a
post processing method to make the grounding results more faithful. Our overall
system achieves the state-of-the-art performances on both sub-tasks in Entities
Object Localization challenge at Activitynet 2021, with 72.57 localization
accuracy on the testing set of sub-task I and 0.2477 F1_all_per_sent on the
hidden testing set of sub-task II.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm. (arXiv:2106.06027v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingkang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06027">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse adversarial attacks can fool deep neural networks (DNNs) by only
perturbing a few pixels (regularized by l_0 norm). Recent efforts combine it
with another l_infty imperceptible on the perturbation magnitudes. The
resultant sparse and imperceptible attacks are practically relevant, and
indicate an even higher vulnerability of DNNs that we usually imagined.
However, such attacks are more challenging to generate due to the optimization
difficulty by coupling the l_0 regularizer and box constraints with a
non-convex objective. In this paper, we address this challenge by proposing a
homotopy algorithm, to jointly tackle the sparsity and the perturbation bound
in one unified framework. Each iteration, the main step of our algorithm is to
optimize an l_0-regularized adversarial loss, by leveraging the nonmonotone
Accelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is
followed by an l_0 change control step, and an optional post-attack step
designed to escape bad local minima. We also extend the algorithm to handling
the structural sparsity regularizer. We extensively examine the effectiveness
of our proposed homotopy attack for both targeted and non-targeted attack
scenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art
methods, our homotopy attack leads to significantly fewer perturbations, e.g.,
reducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted
attack), at similar maximal perturbation magnitudes, when still achieving 100%
attack success rates. Our codes are available at:
https://github.com/VITA-Group/SparseADV_Homotopy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Within-layer Diversity Reduces Generalization Gap. (arXiv:2106.06012v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1">Firas Laakom</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1">Jenni Raitoharju</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06012">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are composed of multiple layers arranged in a hierarchical
structure jointly trained with a gradient-based optimization, where the errors
are back-propagated from the last layer back to the first one. At each
optimization step, neurons at a given layer receive feedback from neurons
belonging to higher layers of the hierarchy. In this paper, we propose to
complement this traditional &#x27;between-layer&#x27; feedback with additional
&#x27;within-layer&#x27; feedback to encourage diversity of the activations within the
same layer. To this end, we measure the pairwise similarity between the outputs
of the neurons and use it to model the layer&#x27;s overall diversity. By penalizing
similarities and promoting diversity, we encourage each neuron to learn a
distinctive representation and, thus, to enrich the data representation learned
within the layer and to increase the total capacity of the model. We
theoretically study how the within-layer activation diversity affects the
generalization performance of a neural network and prove that increasing the
diversity of hidden activations reduces the estimation error. In addition to
the theoretical guarantees, we present an empirical study on three datasets
confirming that the proposed approach enhances the performance of
state-of-the-art neural network models and decreases the generalization gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the Precise Feature for Cluster Assignment. (arXiv:2106.06159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1">Yanhai Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xinghui Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1">Feng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Junyu Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06159">
                                    <div class="article-summary-box-inner">
                                        <span>Clustering is one of the fundamental tasks in computer vision and pattern
recognition. Recently, deep clustering methods (algorithms based on deep
learning) have attracted wide attention with their impressive performance. Most
of these algorithms combine deep unsupervised representation learning and
standard clustering together. However, the separation of representation
learning and clustering will lead to suboptimal solutions because the two-stage
strategy prevents representation learning from adapting to subsequent tasks
(e.g., clustering according to specific cues). To overcome this issue, efforts
have been made in the dynamic adaption of representation and cluster
assignment, whereas current state-of-the-art methods suffer from heuristically
constructed objectives with representation and cluster assignment alternatively
optimized. To further standardize the clustering problem, we audaciously
formulate the objective of clustering as finding a precise feature as the cue
for cluster assignment. Based on this, we propose a general-purpose deep
clustering framework which radically integrates representation learning and
clustering into a single pipeline for the first time. The proposed framework
exploits the powerful ability of recently developed generative models for
learning intrinsic features, and imposes an entropy minimization on the
distribution of the cluster assignment by a dedicated variational algorithm.
Experimental results show that the performance of the proposed method is
superior, or at least comparable to, the state-of-the-art methods on the
handwritten digit recognition, fashion recognition, face recognition and object
recognition benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Vision with Sparse Mixture of Experts. (arXiv:2106.05974v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1">Carlos Riquelme</a>, <a href="http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1">Joan Puigcerver</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1">Basil Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1">Maxim Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1">Rodolphe Jenatton</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_A/0/1/0/all/0/1">Andr&#xe9; Susano Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1">Daniel Keysers</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05974">
                                    <div class="article-summary-box-inner">
                                        <span>Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent
scalability in Natural Language Processing. In Computer Vision, however, almost
all performant networks are &quot;dense&quot;, that is, every input is processed by every
parameter. We present a Vision MoE (V-MoE), a sparse version of the Vision
Transformer, that is scalable and competitive with the largest dense networks.
When applied to image recognition, V-MoE matches the performance of
state-of-the-art networks, while requiring as little as half of the compute at
inference time. Further, we propose an extension to the routing algorithm that
can prioritize subsets of each input across the entire batch, leading to
adaptive per-image compute. This allows V-MoE to trade-off performance and
compute smoothly at test-time. Finally, we demonstrate the potential of V-MoE
to scale vision models, and train a 15B parameter model that attains 90.35% on
ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds. (arXiv:2106.06020v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1">Maurice Weiler</a>, <a href="http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1">Patrick Forr&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Verlinde_E/0/1/0/all/0/1">Erik Verlinde</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06020">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the vast success of deep convolutional networks, there is a
great interest in generalizing convolutions to non-Euclidean manifolds. A major
complication in comparison to flat spaces is that it is unclear in which
alignment a convolution kernel should be applied on a manifold. The underlying
reason for this ambiguity is that general manifolds do not come with a
canonical choice of reference frames (gauge). Kernels and features therefore
have to be expressed relative to arbitrary coordinates. We argue that the
particular choice of coordinatization should not affect a network&#x27;s inference
-- it should be coordinate independent. A simultaneous demand for coordinate
independence and weight sharing is shown to result in a requirement on the
network to be equivariant under local gauge transformations (changes of local
reference frames). The ambiguity of reference frames depends thereby on the
G-structure of the manifold, such that the necessary level of gauge
equivariance is prescribed by the corresponding structure group G. Coordinate
independent convolutions are proven to be equivariant w.r.t. those isometries
that are symmetries of the G-structure. The resulting theory is formulated in a
coordinate free fashion in terms of fiber bundles. To exemplify the design of
coordinate independent convolutions, we implement a convolutional network on
the M\&quot;obius strip. The generality of our differential geometric formulation of
convolutional networks is demonstrated by an extensive literature review which
explains a large number of Euclidean CNNs, spherical CNNs and CNNs on general
surfaces as specific instances of coordinate independent convolutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anytime Ranking on Document-Ordered Indexes. (arXiv:2104.08976v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mackenzie_J/0/1/0/all/0/1">Joel Mackenzie</a>, <a href="http://arxiv.org/find/cs/1/au:+Petri_M/0/1/0/all/0/1">Matthias Petri</a>, <a href="http://arxiv.org/find/cs/1/au:+Moffat_A/0/1/0/all/0/1">Alistair Moffat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08976">
                                    <div class="article-summary-box-inner">
                                        <span>Inverted indexes continue to be a mainstay of text search engines, allowing
efficient querying of large document collections. While there are a number of
possible organizations, document-ordered indexes are the most common, since
they are amenable to various query types, support index updates, and allow for
efficient dynamic pruning operations. One disadvantage with document-ordered
indexes is that high-scoring documents can be distributed across the document
identifier space, meaning that index traversal algorithms that terminate early
might put search effectiveness at risk. The alternative is impact-ordered
indexes, which primarily support top-k disjunctions, but also allow for anytime
query processing, where the search can be terminated at any time, with search
quality improving as processing latency increases. Anytime query processing can
be used to effectively reduce high-percentile tail latency which is essential
for operational scenarios in which a service level agreement (SLA) imposes
response time requirements. In this work, we show how document-ordered indexes
can be organized such that they can be queried in an anytime fashion, enabling
strict latency control with effective early termination. Our experiments show
that processing document-ordered topical segments selected by a simple score
estimator outperforms existing anytime algorithms, and allows query runtimes to
be accurately limited in order to comply with SLA requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Knowledge Gain during Web Search based on Multimedia Resource Consumption. (arXiv:2106.06244v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Otto_C/0/1/0/all/0/1">Christian Otto</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Ran Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pardi_G/0/1/0/all/0/1">Georg Pardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoyer_J/0/1/0/all/0/1">Johannes von Hoyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rokicki_M/0/1/0/all/0/1">Markus Rokicki</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1">Anett Hoppe</a>, <a href="http://arxiv.org/find/cs/1/au:+Holtz_P/0/1/0/all/0/1">Peter Holtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kammerer_Y/0/1/0/all/0/1">Yvonne Kammerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Dietze_S/0/1/0/all/0/1">Stefan Dietze</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06244">
                                    <div class="article-summary-box-inner">
                                        <span>In informal learning scenarios the popularity of multimedia content, such as
video tutorials or lectures, has significantly increased. Yet, the users&#x27;
interactions, navigation behavior, and consequently learning outcome, have not
been researched extensively. Related work in this field, also called search as
learning, has focused on behavioral or text resource features to predict
learning outcome and knowledge gain. In this paper, we investigate whether we
can exploit features representing multimedia resource consumption to predict of
knowledge gain (KG) during Web search from in-session data, that is without
prior knowledge about the learner. For this purpose, we suggest a set of
multimedia features related to image and video consumption. Our feature
extraction is evaluated in a lab study with 113 participants where we collected
data for a given search as learning task on the formation of thunderstorms and
lightning. We automatically analyze the monitored log data and utilize
state-of-the-art computer vision methods to extract features about the seen
multimedia resources. Experimental results demonstrate that multimedia features
can improve KG prediction. Finally, we provide an analysis on feature
importance (text and multimedia) for KG prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation. (arXiv:2106.06471v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xingyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1">Muchao Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Q/0/1/0/all/0/1">Quanzeng You</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Fenglong Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06471">
                                    <div class="article-summary-box-inner">
                                        <span>Medical report generation is one of the most challenging tasks in medical
image analysis. Although existing approaches have achieved promising results,
they either require a predefined template database in order to retrieve
sentences or ignore the hierarchical nature of medical report generation. To
address these issues, we propose MedWriter that incorporates a novel
hierarchical retrieval mechanism to automatically extract both report and
sentence-level templates for clinically accurate report generation. MedWriter
first employs the Visual-Language Retrieval~(VLR) module to retrieve the most
relevant reports for the given images. To guarantee the logical coherence
between sentences, the Language-Language Retrieval~(LLR) module is introduced
to retrieve relevant sentences based on the previous generated description. At
last, a language decoder fuses image features and features from retrieved
reports and sentences to generate meaningful medical reports. We verified the
effectiveness of our model by automatic evaluation and human evaluation on two
datasets, i.e., Open-I and MIMIC-CXR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Large-Scale Rich Context Query and Recommendation Dataset in Online Knowledge-Sharing. (arXiv:2106.06467v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hao_B/0/1/0/all/0/1">Bin Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Weizhi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shaoyun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xinxing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1">Houzhi Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yiqun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shaoping Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06467">
                                    <div class="article-summary-box-inner">
                                        <span>Data plays a vital role in machine learning studies. In the research of
recommendation, both user behaviors and side information are helpful to model
users. So, large-scale real scenario datasets with abundant user behaviors will
contribute a lot. However, it is not easy to get such datasets as most of them
are only hold and protected by companies. In this paper, a new large-scale
dataset collected from a knowledge-sharing platform is presented, which is
composed of around 100M interactions collected within 10 days, 798K users, 165K
questions, 554K answers, 240K authors, 70K topics, and more than 501K user
query keywords. There are also descriptions of users, answers, questions,
authors, and topics, which are anonymous. Note that each user&#x27;s latest query
keywords have not been included in previous open datasets, which reveal users&#x27;
explicit information needs.

We characterize the dataset and demonstrate its potential applications for
recommendation study. Multiple experiments show the dataset can be used to
evaluate algorithms in general top-N recommendation, sequential recommendation,
and context-aware recommendation. This dataset can also be used to integrate
search and recommendation and recommendation with negative feedback. Besides,
tasks beyond recommendation, such as user gender prediction, most valuable
answerer identification, and high-quality answer recognition, can also use this
dataset. To the best of our knowledge, this is the largest real-world
interaction dataset for personalized recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1">Karrar Al-Kaabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1">Reza Monsefi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06420">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning algorithms aim to learn a distance function that brings the
semantically similar data items together and keeps dissimilar ones at a
distance. The traditional Mahalanobis distance learning is equivalent to find a
linear projection. In contrast, Deep Metric Learning (DML) methods are proposed
that automatically extract features from data and learn a non-linear
transformation from input space to a semantically embedding space. Recently,
many DML methods are proposed focused to enhance the discrimination power of
the learned metric by providing novel sampling strategies or loss functions.
This approach is very helpful when both the training and test examples are
coming from the same set of categories. However, it is less effective in many
applications of DML such as image retrieval and person-reidentification. Here,
the DML should learn general semantic concepts from observed classes and employ
them to rank or identify objects from unseen categories. Neglecting the
generalization ability of the learned representation and just emphasizing to
learn a more discriminative embedding on the observed classes may lead to the
overfitting problem. To address this limitation, we propose a framework to
enhance the generalization power of existing DML methods in a Zero-Shot
Learning (ZSL) setting by general yet discriminative representation learning
and employing a class adversarial neural network. To learn a more general
representation, we propose to employ feature maps of intermediate layers in a
deep neural network and enhance their discrimination power through an attention
mechanism. Besides, a class adversarial network is utilized to enforce the deep
model to seek class invariant features for the DML task. We evaluate our work
on widely used machine vision datasets in a ZSL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation. (arXiv:2106.06165v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziwei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06165">
                                    <div class="article-summary-box-inner">
                                        <span>The sequential patterns within the user interactions are pivotal for
representing the user&#x27;s preference and capturing latent relationships among
items. The recent advancements of sequence modeling by Transformers advocate
the community to devise more effective encoders for the sequential
recommendation. Most existing sequential methods assume users are
deterministic. However, item-item transitions might fluctuate significantly in
several item aspects and exhibit randomness of user interests. This
\textit{stochastic characteristics} brings up a solid demand to include
uncertainties in representing sequences and items. Additionally, modeling
sequences and items with uncertainties expands users&#x27; and items&#x27; interaction
spaces, thus further alleviating cold-start problems.

In this work, we propose a Distribution-based Transformer for Sequential
Recommendation (DT4SR), which injects uncertainties into sequential modeling.
We use Elliptical Gaussian distributions to describe items and sequences with
uncertainty. We describe the uncertainty in items and sequences as Elliptical
Gaussian distribution. And we adopt Wasserstein distance to measure the
similarity between distributions. We devise two novel Trans-formers for
modeling mean and covariance, which guarantees the positive-definite property
of distributions. The proposed method significantly outperforms the
state-of-the-art methods. The experiments on three benchmark datasets also
demonstrate its effectiveness in alleviating cold-start issues. The code is
available inhttps://github.com/DyGRec/DT4SR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1">Andreas Waldis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1">Luca Mazzola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06216">
                                    <div class="article-summary-box-inner">
                                        <span>Entity Recognition (ER) within a text is a fundamental exercise in Natural
Language Processing, enabling further depending tasks such as Knowledge
Extraction, Text Summarisation, or Keyphrase Extraction. An entity consists of
single words or of a consecutive sequence of terms, constituting the basic
building blocks for communication. Mainstream ER approaches are mainly limited
to flat structures, concentrating on the outermost entities while ignoring the
inner ones. This paper introduces a partly-layered network architecture that
deals with the complexity of overlapping and nested cases. The proposed
architecture consists of two parts: (1) a shared Sequence Layer and (2) a
stacked component with multiple Tagging Layers. The adoption of such an
architecture has the advantage of preventing overfit to a specific word-length,
thus maintaining performance for longer entities despite their lower frequency.
To verify the proposed architecture&#x27;s effectiveness, we train and evaluate this
architecture to recognise two kinds of entities - Concepts (CR) and Named
Entities (NER). Our approach achieves state-of-the-art NER performances, while
it outperforms previous CR approaches. Considering these promising results, we
see the possibility to evolve the architecture for other cases such as the
extraction of events or the detection of argumentative components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DebiasGAN: Eliminating Position Bias in News Recommendation with Adversarial Learning. (arXiv:2106.06258v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06258">
                                    <div class="article-summary-box-inner">
                                        <span>News recommendation is important for improving news reading experience of
users. Users&#x27; news click behaviors are widely used for inferring user interests
and predicting future clicks. However, click behaviors are heavily affected by
the biases brought by the positions of news displayed on the webpage. It is
important to eliminate the effect of position biases on the recommendation
model to accurately target user interests. In this paper, we propose a news
recommendation method named DebiasGAN that can effectively eliminate the effect
of position biases via adversarial learning. We use a bias-aware click model to
capture the influence of position bias on click behaviors, and we use a
bias-invariant click model with random candidate news positions to estimate the
ideally unbiased click scores. We apply adversarial learning techniques to the
hidden representations learned by the two models to help the bias-invariant
click model capture the bias-independent interest of users on news.
Experimental results on two real-world datasets show that DebiasGAN can
effectively improve the accuracy of news recommendation by eliminating position
biases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IoT Virtualization with ML-based Information Extraction. (arXiv:2106.06022v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1">Martin Bauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06022">
                                    <div class="article-summary-box-inner">
                                        <span>For IoT to reach its full potential, the sharing and reuse of information in
different applications and across verticals is of paramount importance.
However, there are a plethora of IoT platforms using different representations,
protocols and interaction patterns. To address this issue, the Fed4IoT project
has developed an IoT virtualization platform that, on the one hand, integrates
information from many different source platforms and, on the other hand, makes
the information required by the respective users available in the target
platform of choice. To enable this, information is translated into a common,
neutral exchange format. The format of choice is NGSI-LD, which is being
standardized by the ETSI Industry Specification Group on Context Information
Management (ETSI ISG CIM). Thing Visors are the components that translate the
source information to NGSI-LD, which is then delivered to the target platform
and translated into the target format. ThingVisors can be implemented by hand,
but this requires significant human effort, especially considering the
heterogeneity of low level information produced by a multitude of sensors.
Thus, supporting the human developer and, ideally, fully automating the process
of extracting and enriching data and translating it to NGSI-LD is a crucial
step. Machine learning is a promising approach for this, but it typically
requires large amounts of hand-labelled data for training, an effort that makes
it unrealistic in many IoT scenarios. A programmatic labelling approach called
knowledge infusion that encodes expert knowledge is used for matching a schema
or ontology extracted from the data with a target schema or ontology, providing
the basis for annotating the data and facilitating the translation to NGSI-LD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Adversarial Attacks. (arXiv:2103.02014v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mladenovic_A/0/1/0/all/0/1">Andjela Mladenovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1">Avishek Joey Bose</a>, <a href="http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1">Hugo Berard</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William L. Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1">Pascal Vincent</a>, <a href="http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02014">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks expose important vulnerabilities of deep learning models,
yet little attention has been paid to settings where data arrives as a stream.
In this paper, we formalize the online adversarial attack problem, emphasizing
two key elements found in real-world use-cases: attackers must operate under
partial knowledge of the target model, and the decisions made by the attacker
are irrevocable since they operate on a transient data stream. We first
rigorously analyze a deterministic variant of the online threat model by
drawing parallels to the well-studied $k$-secretary problem in theoretical
computer science and propose Virtual+, a simple yet practical online algorithm.
Our main theoretical result show Virtual+ yields provably the best competitive
ratio over all single-threshold algorithms for $k&lt;5$ -- extending previous
analysis of the $k$-secretary problem. We also introduce the \textit{stochastic
$k$-secretary} -- effectively reducing online blackbox transfer attacks to a
$k$-secretary problem under noise -- and prove theoretical bounds on the
performance of \textit{any} online algorithms adapted to this setting. Finally,
we complement our theoretical results by conducting experiments on both MNIST
and CIFAR-10 with both vanilla and robust classifiers, revealing not only the
necessity of online algorithms in achieving near-optimal performance but also
the rich interplay of a given attack strategy towards online attack selection,
enabling simple strategies like FGSM to outperform classically strong whitebox
adversaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quynh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09612">
                                    <div class="article-summary-box-inner">
                                        <span>We give a simple proof for the global convergence of gradient descent in
training deep ReLU networks with the standard square loss, and show some of its
improvements over the state-of-the-art. In particular, while prior works
require all the hidden layers to be wide with width at least $\Omega(N^8)$ ($N$
being the number of training samples), we require a single wide layer of
linear, quadratic or cubic width depending on the type of initialization.
Unlike many recent proofs based on the Neural Tangent Kernel (NTK), our proof
need not track the evolution of the entire NTK matrix, or more generally, any
quantities related to the changes of activation patterns during training.
Instead, we only need to track the evolution of the output at the last hidden
layer, which can be done much more easily thanks to the Lipschitz property of
ReLU. Some highlights of our setting: (i) all the layers are trained with
standard gradient descent, (ii) the network has standard parameterization as
opposed to the NTK one, and (iii) the network has a single wide layer as
opposed to having all wide hidden layers as in most of NTK-related results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Stochastic Simulation with Interactive Neural Processes. (arXiv:2106.02770v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongxia Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1">Matteo Chinazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1">Alessandro Vespignani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi-An Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Rose Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02770">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic simulations such as large-scale, spatiotemporal, age-structured
epidemic models are computationally expensive at fine-grained resolution. We
propose Interactive Neural Process (INP), an interactive framework to
continuously learn a deep learning surrogate model and accelerate simulation.
Our framework is based on the novel integration of Bayesian active learning,
stochastic simulation and deep sequence modeling. In particular, we develop a
novel spatiotemporal neural process model to mimic the underlying process
dynamics. Our model automatically infers the latent process which describes the
intrinsic uncertainty of the simulator. This also gives rise to a new
acquisition function that can quantify the uncertainty of deep learning
predictions. We design Bayesian active learning algorithms to iteratively query
the simulator, gather more data, and continuously improve the model. We perform
theoretical analysis and demonstrate that our approach reduces sample
complexity compared with random sampling in high dimension. Empirically, we
demonstrate our framework can faithfully imitate the behavior of a complex
infectious disease simulator with a small number of examples, enabling rapid
simulation and scenario exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional and Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Remlinger_C/0/1/0/all/0/1">Carl Remlinger</a>, <a href="http://arxiv.org/find/stat/1/au:+Mikael_J/0/1/0/all/0/1">Joseph Mikael</a>, <a href="http://arxiv.org/find/stat/1/au:+Elie_R/0/1/0/all/0/1">Romuald Elie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05313">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce three new generative models for time series. Based on Euler
discretization and Wasserstein metrics, they are able to capture time marginal
distributions and temporal dynamics. Two of these methods rely on the
adaptation of generative adversarial networks (GANs) to time series. Both of
them outperform state-of-the-art benchmarks by capturing the underlying
temporal structure on synthetic time series. The third algorithm, called
Conditional Euler Generator (CEGEN), minimizes a dedicated distance between the
transition probability distributions over all time steps. In the context of Ito
processes, we provide theoretical guarantees that minimizing this criterion
implies accurate estimations of the drift and volatility parameters. We
demonstrate empirically that CEGEN outperforms state-of-the-art and GAN
generators on both marginal and temporal dynamics metrics. Besides, it
identifies accurate correlation structures in high dimension. When few data
points are available, we verify the effectiveness of CEGEN, when combined with
transfer learning methods on Monte Carlo simulations. Finally, we illustrate
the robustness of our method on various real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logic of Machine Learning. (arXiv:2006.09500v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1">Marina Sapir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09500">
                                    <div class="article-summary-box-inner">
                                        <span>I propose a new, logical, foundation for ML. ML is approached as a problem of
maximizing consistency of a hypothesis in a context of a given training set.
Nonjudgmental logic (NjL) with modalities &#x60;&#x60;It appears that&#x27;&#x27;, &#x60;&#x60;Assume that&#x27;&#x27;
is introduced to formalize and quantify the inconsistency. Many popular ML
algorithms (from hierarchical clustering to k-NN and SVM) are shown to
corroborate the conjecture. In addition, it is demonstrated that NjL allows to
formalize and solve several general learning problems which are not considered
as ML usually.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Modular Analysis of Provable Acceleration via Polyak&#x27;s Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun-Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chi-Heng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1">Jacob Abernethy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01618">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating a so-called &quot;momentum&quot; dynamic in gradient descent methods is
widely used in neural net training as it has been broadly observed that, at
least empirically, it often leads to significantly faster convergence. At the
same time, there are very few theoretical guarantees in the literature to
explain this apparent acceleration effect. Even for the classical strongly
convex quadratic problems, several existing results only show Polyak&#x27;s momentum
has an accelerated linear rate asymptotically. In this paper, we first revisit
the quadratic problems and show a non-asymptotic accelerated linear rate of
Polyak&#x27;s momentum. Then, we provably show that Polyak&#x27;s momentum achieves
acceleration for training a one-layer wide ReLU network and a deep linear
network, which are perhaps the two most popular canonical models for studying
optimization and deep learning in the literature. Prior work Du at al. 2019 and
Wu et al. 2019 showed that using vanilla gradient descent, and with an use of
over-parameterization, the error decays as $(1- \Theta(\frac{1}{ \kappa&#x27;}))^t$
after $t$ iterations, where $\kappa&#x27;$ is the condition number of a Gram Matrix.
Our result shows that with the appropriate choice of parameters Polyak&#x27;s
momentum has a rate of $(1-\Theta(\frac{1}{\sqrt{\kappa&#x27;}}))^t$. For the deep
linear network, prior work Hu et al. 2020 showed that vanilla gradient descent
has a rate of $(1-\Theta(\frac{1}{\kappa}))^t$, where $\kappa$ is the condition
number of a data matrix. Our result shows an acceleration rate $(1-
\Theta(\frac{1}{\sqrt{\kappa}}))^t$ is achievable by Polyak&#x27;s momentum. All the
results in this work are obtained from a modular analysis, which can be of
independent interest. This work establishes that momentum does indeed speed up
neural net training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymmetric Heavy Tails and Implicit Bias in Gaussian Noise Injections. (arXiv:2102.07006v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1">Alexander Camuto</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1">Xiaoyu Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_L/0/1/0/all/0/1">Lingjiong Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1">Chris Holmes</a>, <a href="http://arxiv.org/find/stat/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1">Umut &#x15e;im&#x15f;ekli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07006">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian noise injections (GNIs) are a family of simple and widely-used
regularisation methods for training neural networks, where one injects additive
or multiplicative Gaussian noise to the network activations at every iteration
of the optimisation algorithm, which is typically chosen as stochastic gradient
descent (SGD). In this paper we focus on the so-called &#x60;implicit effect&#x27; of
GNIs, which is the effect of the injected noise on the dynamics of SGD. We show
that this effect induces an asymmetric heavy-tailed noise on SGD gradient
updates. In order to model this modified dynamics, we first develop a
Langevin-like stochastic differential equation that is driven by a general
family of asymmetric heavy-tailed noise. Using this model we then formally
prove that GNIs induce an &#x60;implicit bias&#x27;, which varies depending on the
heaviness of the tails and the level of asymmetry. Our empirical results
confirm that different types of neural networks trained with GNIs are
well-modelled by the proposed dynamics and that the implicit effect of these
injections induces a bias that degrades the performance of networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Calibrate Before Use: Improving Few-Shot Performance of Language Models. (arXiv:2102.09690v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tony Z. Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1">Eric Wallace</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09690">
                                    <div class="article-summary-box-inner">
                                        <span>GPT-3 can perform numerous tasks when provided a natural language prompt that
contains a few training examples. We show that this type of few-shot learning
can be unstable: the choice of prompt format, training examples, and even the
order of the training examples can cause accuracy to vary from near chance to
near state-of-the-art. We demonstrate that this instability arises from the
bias of language models towards predicting certain answers, e.g., those that
are placed near the end of the prompt or are common in the pre-training data.
To mitigate this, we first estimate the model&#x27;s bias towards each answer by
asking for its prediction when given the training prompt and a content-free
test input such as &quot;N/A&quot;. We then fit calibration parameters that cause the
prediction for this input to be uniform across answers. On a diverse set of
tasks, this contextual calibration procedure substantially improves GPT-3 and
GPT-2&#x27;s average accuracy (up to 30.0% absolute) and reduces variance across
different choices of the prompt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">View Generalization for Single Image Textured 3D Models. (arXiv:2106.06533v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattad_A/0/1/0/all/0/1">Anand Bhattad</a>, <a href="http://arxiv.org/find/cs/1/au:+Dundar_A/0/1/0/all/0/1">Aysegul Dundar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guilin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_A/0/1/0/all/0/1">Andrew Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06533">
                                    <div class="article-summary-box-inner">
                                        <span>Humans can easily infer the underlying 3D geometry and texture of an object
only from a single 2D image. Current computer vision methods can do this, too,
but suffer from view generalization problems - the models inferred tend to make
poor predictions of appearance in novel views. As for generalization problems
in machine learning, the difficulty is balancing single-view accuracy (cf.
training error; bias) with novel view accuracy (cf. test error; variance). We
describe a class of models whose geometric rigidity is easily controlled to
manage this tradeoff. We describe a cycle consistency loss that improves view
generalization (roughly, a model from a generated view should predict the
original view well). View generalization of textures requires that models share
texture information, so a car seen from the back still has headlights because
other cars have headlights. We describe a cycle consistency loss that
encourages model textures to be aligned, so as to encourage sharing. We compare
our method against the state-of-the-art method and show both qualitative and
quantitative improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Contrastive Divergence Training of Energy Based Models. (arXiv:2012.01316v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yilun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01316">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive divergence is a popular method of training energy-based models,
but is known to have difficulties with training stability. We propose an
adaptation to improve contrastive divergence training by scrutinizing a
gradient term that is difficult to calculate and is often left out for
convenience. We show that this gradient term is numerically significant and in
practice is important to avoid training instabilities, while being tractable to
estimate. We further highlight how data augmentation and multi-scale processing
can be used to improve model robustness and generation quality. Finally, we
empirically evaluate stability of model architectures and show improved
performance on a host of benchmarks and use cases,such as image generation, OOD
detection, and compositional generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic bounds on neuron death in deep rectifier networks. (arXiv:2007.06192v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rister_B/0/1/0/all/0/1">Blaine Rister</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel L. Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06192">
                                    <div class="article-summary-box-inner">
                                        <span>Neuron death is a complex phenomenon with implications for model
trainability: the deeper the network, the lower the probability of finding a
valid initialization. In this work, we derive both upper and lower bounds on
the probability that a ReLU network is initialized to a trainable point, as a
function of model hyperparameters. We show that it is possible to increase the
depth of a network indefinitely, so long as the width increases as well.
Furthermore, our bounds are asymptotically tight under reasonable assumptions:
first, the upper bound coincides with the true probability for a single-layer
network with the largest possible input set. Second, the true probability
converges to our lower bound as the input set shrinks to a single point, or as
the network complexity grows under an assumption about the output variance. We
confirm these results by numerical simulation, showing rapid convergence to the
lower bound with increasing network depth. Then, motivated by the theory, we
propose a practical sign flipping scheme which guarantees that the ratio of
living data points in a $k$-layer network is at least $2^{-k}$. Finally, we
show how these issues are mitigated by network design features currently seen
in practice, such as batch normalization, residual connections, dense networks
and skip connections. This suggests that neuron death may provide insight into
the efficacy of various model architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantile Bandits for Best Arms Identification. (arXiv:2010.11568v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1">Cheng Soon Ong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11568">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a variant of the best arm identification task in stochastic
multi-armed bandits. Motivated by risk-averse decision-making problems, our
goal is to identify a set of $m$ arms with the highest $\tau$-quantile values
within a fixed budget. We prove asymmetric two-sided concentration inequalities
for order statistics and quantiles of random variables that have non-decreasing
hazard rate, which may be of independent interest. With these inequalities, we
analyse a quantile version of Successive Accepts and Rejects (Q-SAR). We derive
an upper bound for the probability of arm misidentification, the first
justification of a quantile based algorithm for fixed budget multiple best arms
identification. We show illustrative experiments for best arm identification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Best Arm Identification in Graphical Bilinear Bandits. (arXiv:2012.07641v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rizk_G/0/1/0/all/0/1">Geovani Rizk</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_A/0/1/0/all/0/1">Albert Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Colin_I/0/1/0/all/0/1">Igor Colin</a>, <a href="http://arxiv.org/find/cs/1/au:+Laraki_R/0/1/0/all/0/1">Rida Laraki</a>, <a href="http://arxiv.org/find/cs/1/au:+Chevaleyre_Y/0/1/0/all/0/1">Yann Chevaleyre</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07641">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new graphical bilinear bandit problem where a learner (or a
\emph{central entity}) allocates arms to the nodes of a graph and observes for
each edge a noisy bilinear reward representing the interaction between the two
end nodes. We study the best arm identification problem in which the learner
wants to find the graph allocation maximizing the sum of the bilinear rewards.
By efficiently exploiting the geometry of this bandit problem, we propose a
\emph{decentralized} allocation strategy based on random sampling with
theoretical guarantees. In particular, we characterize the influence of the
graph structure (e.g. star, complete or circle) on the convergence rate and
propose empirical experiments that confirm this dependency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous-Time Model-Based Reinforcement Learning. (arXiv:2102.04764v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yildiz_C/0/1/0/all/0/1">&#xc7;a&#x11f;atay Y&#x131;ld&#x131;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinonen_M/0/1/0/all/0/1">Markus Heinonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lahdesmaki_H/0/1/0/all/0/1">Harri L&#xe4;hdesm&#xe4;ki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04764">
                                    <div class="article-summary-box-inner">
                                        <span>Model-based reinforcement learning (MBRL) approaches rely on discrete-time
state transition models whereas physical systems and the vast majority of
control tasks operate in continuous-time. To avoid time-discretization
approximation of the underlying process, we propose a continuous-time MBRL
framework based on a novel actor-critic method. Our approach also infers the
unknown state evolution differentials with Bayesian neural ordinary
differential equations (ODE) to account for epistemic uncertainty. We implement
and test our method on a new ODE-RL suite that explicitly solves
continuous-time control systems. Our experiments illustrate that the model is
robust against irregular and noisy data, is sample-efficient, and can solve
control problems which pose challenges to discrete-time MBRL methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Learning and its Application for Time-Series Prediction. (arXiv:2106.03211v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Nhuong V. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Legitime_S/0/1/0/all/0/1">Sybille Legitime</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03211">
                                    <div class="article-summary-box-inner">
                                        <span>Extreme events are occurrences whose magnitude and potential cause extensive
damage on people, infrastructure, and the environment. Motivated by the extreme
nature of the current global health landscape, which is plagued by the
coronavirus pandemic, we seek to better understand and model extreme events.
Modeling extreme events is common in practice and plays an important role in
time-series prediction applications. Our goal is to (i) compare and investigate
the effect of some common extreme events modeling methods to explore which
method can be practical in reality and (ii) accelerate the deep learning
training process, which commonly uses deep recurrent neural network (RNN), by
implementing the asynchronous local Stochastic Gradient Descent (SGD) framework
among multiple compute nodes. In order to verify our distributed extreme events
modeling, we evaluate our proposed framework on a stock data set S\&amp;P500, with
a standard recurrent neural network. Our intuition is to explore the (best)
extreme events modeling method which could work well under the distributed deep
learning setting. Moreover, by using asynchronous distributed learning, we aim
to significantly reduce the communication cost among the compute nodes and
central server, which is the main bottleneck of almost all distributed learning
frameworks.

We implement our proposed work and evaluate its performance on representative
data sets, such as S&amp;P500 stock in $5$-year period. The experimental results
validate the correctness of the design principle and show a significant
training duration reduction upto $8$x, compared to the baseline single compute
node. Our results also show that our proposed work can achieve the same level
of test accuracy, compared to the baseline setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing the Travel and Charging Behavior of Electric Vehicles -- A Data-driven Approach. (arXiv:2106.06475v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baghali_S/0/1/0/all/0/1">Sina Baghali</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1">Samiul Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhaomiao Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06475">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing market penetration of electric vehicles (EVs) may pose
significant electricity demand on power systems. This electricity demand is
affected by the inherent uncertainties of EVs&#x27; travel behavior that makes
forecasting the daily charging demand (CD) very challenging. In this project,
we use the National House Hold Survey (NHTS) data to form sequences of trips,
and develop machine learning models to predict the parameters of the next trip
of the drivers, including trip start time, end time, and distance. These
parameters are later used to model the temporal charging behavior of EVs. The
simulation results show that the proposed modeling can effectively estimate the
daily CD pattern based on travel behavior of EVs, and simple machine learning
techniques can forecast the travel parameters with acceptable accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Selection Tutorial with Python Examples. (arXiv:2106.06437v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cunningham_P/0/1/0/all/0/1">Padraig Cunningham</a>, <a href="http://arxiv.org/find/cs/1/au:+Kathirgamanathan_B/0/1/0/all/0/1">Bahavathy Kathirgamanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Delany_S/0/1/0/all/0/1">Sarah Jane Delany</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06437">
                                    <div class="article-summary-box-inner">
                                        <span>In Machine Learning, feature selection entails selecting a subset of the
available features in a dataset to use for model development. There are many
motivations for feature selection, it may result in better models, it may
provide insight into the data and it may deliver economies in data gathering or
data processing. For these reasons feature selection has received a lot of
attention in data analytics research. In this paper we provide an overview of
the main methods and present practical examples with Python implementations.
While the main focus is on supervised feature selection techniques, we also
cover some feature transformation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making EfficientNet More Efficient: Exploring Batch-Independent Normalization, Group Convolutions and Reduced Resolution Training. (arXiv:2106.03640v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1">Dominic Masters</a>, <a href="http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1">Antoine Labatie</a>, <a href="http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1">Zach Eaton-Rosen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03640">
                                    <div class="article-summary-box-inner">
                                        <span>Much recent research has been dedicated to improving the efficiency of
training and inference for image classification. This effort has commonly
focused on explicitly improving theoretical efficiency, often measured as
ImageNet validation accuracy per FLOP. These theoretical savings have, however,
proven challenging to achieve in practice, particularly on high-performance
training accelerators.

In this work, we focus on improving the practical efficiency of the
state-of-the-art EfficientNet models on a new class of accelerator, the
Graphcore IPU. We do this by extending this family of models in the following
ways: (i) generalising depthwise convolutions to group convolutions; (ii)
adding proxy-normalized activations to match batch normalization performance
with batch-independent statistics; (iii) reducing compute by lowering the
training resolution and inexpensively fine-tuning at higher resolution. We find
that these three methods improve the practical efficiency for both training and
inference. Our code will be made available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise and Fluctuation of Finite Learning Rate Stochastic Gradient Descent. (arXiv:2012.03636v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_K/0/1/0/all/0/1">Kangqiao Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Ziyin_L/0/1/0/all/0/1">Liu Ziyin</a>, <a href="http://arxiv.org/find/stat/1/au:+Ueda_M/0/1/0/all/0/1">Masahito Ueda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03636">
                                    <div class="article-summary-box-inner">
                                        <span>In the vanishing learning rate regime, stochastic gradient descent (SGD) is
now relatively well understood. In this work, we propose to study the basic
properties of SGD and its variants in the non-vanishing learning rate regime.
The focus is on deriving exactly solvable results and discussing their
implications. The main contributions of this work are to derive the stationary
distribution for discrete-time SGD in a quadratic loss function with and
without momentum; in particular, one implication of our result is that the
fluctuation caused by discrete-time dynamics takes a distorted shape and is
dramatically larger than a continuous-time theory could predict. Examples of
applications of the proposed theory considered in this work include the
approximation error of variants of SGD, the effect of minibatch noise, the
optimal Bayesian inference, the escape rate from a sharp minimum, and the
stationary covariance of a few second-order methods including damped Newton&#x27;s
method, natural gradient descent, and Adam.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Collaboration. (arXiv:2105.02569v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1">Qingfeng Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02569">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new ensemble framework for supervised learning, called machine
collaboration (MaC), using a collection of base machines for prediction tasks.
Unlike bagging/stacking (a parallel &amp; independent framework) and boosting (a
sequential &amp; top-down framework), MaC is a type of circular &amp; interactive
learning framework. The circular &amp; interactive feature helps the base machines
to transfer information circularly and update their structures and parameters
accordingly. The theoretical result on the risk bound of the estimator from MaC
reveals that the circular &amp; interactive feature can help MaC reduce risk via a
parsimonious ensemble. We conduct extensive experiments on MaC using both
simulated data and 119 benchmark real datasets. The results demonstrate that in
most cases, MaC performs significantly better than several other
state-of-the-art methods, including classification and regression trees, neural
networks, stacking, and boosting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Autoencoders: A Harmonic Perspective. (arXiv:2105.14866v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1">Alexander Camuto</a>, <a href="http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1">Matthew Willetts</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14866">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we study Variational Autoencoders (VAEs) from the perspective of
harmonic analysis. By viewing a VAE&#x27;s latent space as a Gaussian Space, a
variety of measure space, we derive a series of results that show that the
encoder variance of a VAE controls the frequency content of the functions
parameterised by the VAE encoder and decoder neural networks. In particular we
demonstrate that larger encoder variances reduce the high frequency content of
these functions. Our analysis allows us to show that increasing this variance
effectively induces a soft Lipschitz constraint on the decoder network of a
VAE, which is a core contributor to the adversarial robustness of VAEs. We
further demonstrate that adding Gaussian noise to the input of a VAE allows us
to more finely control the frequency content and the Lipschitz constant of the
VAE encoder networks. To support our theoretical analysis we run experiments
with VAEs with small fully-connected neural networks and with larger
convolutional networks, demonstrating empirically that our theory holds for a
variety of neural network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Multi-Agent Behavior Dataset: Mouse Dyadic Social Interactions. (arXiv:2104.02710v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jennifer J. Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Karigo_T/0/1/0/all/0/1">Tomomi Karigo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_D/0/1/0/all/0/1">Dipam Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanty_S/0/1/0/all/0/1">Sharada P. Mohanty</a>, <a href="http://arxiv.org/find/cs/1/au:+Wild_B/0/1/0/all/0/1">Benjamin Wild</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Quan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1">David J. Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1">Pietro Perona</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1">Ann Kennedy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02710">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent behavior modeling aims to understand the interactions that occur
between agents. We present a multi-agent dataset from behavioral neuroscience,
the Caltech Mouse Social Interactions (CalMS21) Dataset. Our dataset consists
of trajectory data of social interactions, recorded from videos of freely
behaving mice in a standard resident-intruder assay. To help accelerate
behavioral studies, the CalMS21 dataset provides benchmarks to evaluate the
performance of automated behavior classification methods in three settings: (1)
for training on large behavioral datasets all annotated by a single annotator,
(2) for style transfer to learn inter-annotator differences in behavior
definitions, and (3) for learning of new behaviors of interest given limited
training data. The dataset consists of 6 million frames of unlabeled tracked
poses of interacting mice, as well as over 1 million frames with tracked poses
and corresponding frame-level behavior annotations. The challenge of our
dataset is to be able to classify behaviors accurately using both labeled and
unlabeled tracking data, as well as being able to generalize to new settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Integer Linear Programming Framework for Mining Constraints from Data. (arXiv:2006.10836v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_T/0/1/0/all/0/1">Tao Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10836">
                                    <div class="article-summary-box-inner">
                                        <span>Structured output prediction problems (e.g., sequential tagging, hierarchical
multi-class classification) often involve constraints over the output label
space. These constraints interact with the learned models to filter infeasible
solutions and facilitate in building an accountable system. However, although
constraints are useful, they are often based on hand-crafted rules. This raises
a question -- \emph{can we mine constraints and rules from data based on a
learning algorithm?}

In this paper, we present a general framework for mining constraints from
data. In particular, we consider the inference in structured output prediction
as an integer linear programming (ILP) problem. Then, given the coefficients of
the objective function and the corresponding solution, we mine the underlying
constraints by estimating the outer and inner polytopes of the feasible set. We
verify the proposed constraint mining algorithm in various synthetic and
real-world applications and demonstrate that the proposed approach successfully
identifies the feasible set at scale.

In particular, we show that our approach can learn to solve 9x9 Sudoku
puzzles and minimal spanning tree problems from examples without providing the
underlying rules. Our algorithm can also integrate with a neural network model
to learn the hierarchical label structure of a multi-label classification task.
Besides, we provide a theoretical analysis about the tightness of the polytopes
and the reliability of the mined constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks. (arXiv:2006.07869v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1">Georgios Papoudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1">Filippos Christianos</a>, <a href="http://arxiv.org/find/cs/1/au:+Schafer_L/0/1/0/all/0/1">Lukas Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1">Stefano V. Albrecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07869">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent deep reinforcement learning (MARL) suffers from a lack of
commonly-used evaluation tasks and criteria, making comparisons between
approaches difficult. In this work, we consistently evaluate and compare three
different classes of MARL algorithms (independent learning, centralised
multi-agent policy gradient, value decomposition) in a diverse range of
cooperative multi-agent learning tasks. Our experiments serve as a reference
for the expected performance of algorithms across different learning tasks, and
we provide insights regarding the effectiveness of different learning
approaches. We open-source EPyMARL, which extends the PyMARL
codebase~\citep{samvelyan19smac} to include additional algorithms and allow for
flexible configuration of algorithm implementation details such as parameter
sharing. Finally, we open-source two environments for multi-agent research
which focus on coordination under sparse rewards.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Reinforcement Learning for Air-to-Air Combat. (arXiv:2105.00990v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pope_A/0/1/0/all/0/1">Adrian P. Pope</a>, <a href="http://arxiv.org/find/cs/1/au:+Ide_J/0/1/0/all/0/1">Jaime S. Ide</a>, <a href="http://arxiv.org/find/cs/1/au:+Micovic_D/0/1/0/all/0/1">Daria Micovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_H/0/1/0/all/0/1">Henry Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenbluth_D/0/1/0/all/0/1">David Rosenbluth</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritholtz_L/0/1/0/all/0/1">Lee Ritholtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Twedt_J/0/1/0/all/0/1">Jason C. Twedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Walker_T/0/1/0/all/0/1">Thayne T. Walker</a>, <a href="http://arxiv.org/find/cs/1/au:+Alcedo_K/0/1/0/all/0/1">Kevin Alcedo</a>, <a href="http://arxiv.org/find/cs/1/au:+Javorsek_D/0/1/0/all/0/1">Daniel Javorsek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00990">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial Intelligence (AI) is becoming a critical component in the defense
industry, as recently demonstrated by DARPA&#x60;s AlphaDogfight Trials (ADT). ADT
sought to vet the feasibility of AI algorithms capable of piloting an F-16 in
simulated air-to-air combat. As a participant in ADT, Lockheed Martin&#x60;s (LM)
approach combines a hierarchical architecture with maximum-entropy
reinforcement learning (RL), integrates expert knowledge through reward
shaping, and supports modularity of policies. This approach achieved a $2^{nd}$
place finish in the final ADT event (among eight total competitors) and
defeated a graduate of the US Air Force&#x27;s (USAF) F-16 Weapons Instructor Course
in match play.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills. (arXiv:2104.07749v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chebotar_Y/0/1/0/all/0/1">Yevgen Chebotar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1">Karol Hausman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Ted Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalashnikov_D/0/1/0/all/0/1">Dmitry Kalashnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Varley_J/0/1/0/all/0/1">Jake Varley</a>, <a href="http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1">Alex Irpan</a>, <a href="http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1">Benjamin Eysenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1">Ryan Julian</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07749">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning useful robotic skills from previously
collected offline data without access to manually specified rewards or
additional online exploration, a setting that is becoming increasingly
important for scaling robot learning by reusing past robotic data. In
particular, we propose the objective of learning a functional understanding of
the environment by learning to reach any goal state in a given dataset. We
employ goal-conditioned Q-learning with hindsight relabeling and develop
several techniques that enable training in a particularly challenging offline
setting. We find that our method can operate on high-dimensional camera images
and learn a variety of skills on real robots that generalize to previously
unseen scenes and objects. We also show that our method can learn to reach
long-horizon goals across multiple episodes through goal chaining, and learn
rich representations that can help with downstream tasks through pre-training
or auxiliary objectives. The videos of our experiments can be found at
https://actionable-models.github.io</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Neighbor Sampling for Mixed CPU-GPU Training on Giant Graphs. (arXiv:2106.06150v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jialin Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1">Da Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1">Geroge Karypis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06150">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) are powerful tools for learning from graph data
and are widely used in various applications such as social network
recommendation, fraud detection, and graph search. The graphs in these
applications are typically large, usually containing hundreds of millions of
nodes. Training GNN models on such large graphs efficiently remains a big
challenge. Despite a number of sampling-based methods have been proposed to
enable mini-batch training on large graphs, these methods have not been proved
to work on truly industry-scale graphs, which require GPUs or mixed-CPU-GPU
training. The state-of-the-art sampling-based methods are usually not optimized
for these real-world hardware setups, in which data movement between CPUs and
GPUs is a bottleneck. To address this issue, we propose Global Neighborhood
Sampling that aims at training GNNs on giant graphs specifically for
mixed-CPU-GPU training. The algorithm samples a global cache of nodes
periodically for all mini-batches and stores them in GPUs. This global cache
allows in-GPU importance sampling of mini-batches, which drastically reduces
the number of nodes in a mini-batch, especially in the input layer, to reduce
data copy between CPU and GPU and mini-batch computation without compromising
the training convergence rate or model accuracy. We provide a highly efficient
implementation of this method and show that our implementation outperforms an
efficient node-wise neighbor sampling baseline by a factor of 2X-4X on giant
graphs. It outperforms an efficient implementation of LADIES with small layers
by a factor of 2X-14X while achieving much higher accuracy than LADIES.We also
theoretically analyze the proposed algorithm and show that with cached node
data of a proper size, it enjoys a comparable convergence rate as the
underlying node-wise sampling method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Recovery of Semantic Attributes. (arXiv:2103.11888v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ameen Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1">Tomer Galanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheltonozhskiy_E/0/1/0/all/0/1">Evgeniy Zheltonozhskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Baskin_C/0/1/0/all/0/1">Chaim Baskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11888">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of the extraction of semantic attributes, supervised
only with classification labels. For example, when learning to classify images
of birds into species, we would like to observe the emergence of features that
zoologists use to classify birds. To tackle this problem, we propose training a
neural network with discrete features in the last layer, which is followed by
two heads: a multi-layered perceptron (MLP) and a decision tree. Since decision
trees utilize simple binary decision stumps we expect those discrete features
to obtain semantic meaning. We present a theoretical analysis as well as a
practical method for learning in the intersection of two hypothesis classes.
Our results on multiple benchmarks show an improved ability to extract a set of
features that are highly correlated with the set of unseen attributes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved, Deterministic Smoothing for L_1 Certified Robustness. (arXiv:2103.10834v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Levine_A/0/1/0/all/0/1">Alexander Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1">Soheil Feizi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10834">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized smoothing is a general technique for computing sample-dependent
robustness guarantees against adversarial attacks for deep classifiers. Prior
works on randomized smoothing against L_1 adversarial attacks use additive
smoothing noise and provide probabilistic robustness guarantees. In this work,
we propose a non-additive and deterministic smoothing method, Deterministic
Smoothing with Splitting Noise (DSSN). To develop DSSN, we first develop SSN, a
randomized method which involves generating each noisy smoothing sample by
first randomly splitting the input space and then returning a representation of
the center of the subdivision occupied by the input sample. In contrast to
uniform additive smoothing, the SSN certification does not require the random
noise components used to be independent. Thus, smoothing can be done
effectively in just one dimension and can therefore be efficiently derandomized
for quantized data (e.g., images). To the best of our knowledge, this is the
first work to provide deterministic &quot;randomized smoothing&quot; for a norm-based
adversarial threat model while allowing for an arbitrary classifier (i.e., a
deep model) to be used as a base classifier and without requiring an
exponential number of smoothing samples. On CIFAR-10 and ImageNet datasets, we
provide substantially larger L_1 robustness certificates compared to prior
works, establishing a new state-of-the-art. The determinism of our method also
leads to significantly faster certificate computation. Code is available at:
https://github.com/alevine0/smoothingSplittingNoise</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning of Continuous-time Bayesian Networks through Interventions. (arXiv:2105.14742v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Linzner_D/0/1/0/all/0/1">Dominik Linzner</a>, <a href="http://arxiv.org/find/stat/1/au:+Koeppl_H/0/1/0/all/0/1">Heinz Koeppl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14742">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning structures and parameters of
Continuous-time Bayesian Networks (CTBNs) from time-course data under minimal
experimental resources. In practice, the cost of generating experimental data
poses a bottleneck, especially in the natural and social sciences. A popular
approach to overcome this is Bayesian optimal experimental design (BOED).
However, BOED becomes infeasible in high-dimensional settings, as it involves
integration over all possible experimental outcomes. We propose a novel
criterion for experimental design based on a variational approximation of the
expected information gain. We show that for CTBNs, a semi-analytical expression
for this criterion can be calculated for structure and parameter learning. By
doing so, we can replace sampling over experimental outcomes by solving the
CTBNs master-equation, for which scalable approximations exist. This alleviates
the computational burden of sampling possible experimental outcomes in
high-dimensions. We employ this framework in order to recommend interventional
sequences. In this context, we extend the CTBN model to conditional CTBNs in
order to incorporate interventions. We demonstrate the performance of our
criterion on synthetic and real-world data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">N-Best ASR Transformer: Enhancing SLU Performance using Multiple ASR Hypotheses. (arXiv:2106.06519v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1">Karthik Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamdev_P/0/1/0/all/0/1">Pakhi Bamdev</a>, <a href="http://arxiv.org/find/cs/1/au:+B_J/0/1/0/all/0/1">Jaivarsan B</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopal_A/0/1/0/all/0/1">Amresh Venugopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tushar_A/0/1/0/all/0/1">Abhinav Tushar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06519">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken Language Understanding (SLU) systems parse speech into semantic
structures like dialog acts and slots. This involves the use of an Automatic
Speech Recognizer (ASR) to transcribe speech into multiple text alternatives
(hypotheses). Transcription errors, common in ASRs, impact downstream SLU
performance negatively. Approaches to mitigate such errors involve using richer
information from the ASR, either in form of N-best hypotheses or word-lattices.
We hypothesize that transformer models learn better with a simpler utterance
representation using the concatenation of the N-best ASR alternatives, where
each alternative is separated by a special delimiter [SEP]. In our work, we
test our hypothesis by using concatenated N-best ASR alternatives as the input
to transformer encoder models, namely BERT and XLM-RoBERTa, and achieve
performance equivalent to the prior state-of-the-art model on DSTC2 dataset. We
also show that our approach significantly outperforms the prior
state-of-the-art when subjected to the low data regime. Additionally, this
methodology is accessible to users of third-party ASR APIs which do not provide
word-lattice information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Continual Adaptation with Active Self-Training. (arXiv:2106.06526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shiji Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lianzhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Heng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wenwu Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06526">
                                    <div class="article-summary-box-inner">
                                        <span>Models trained with offline data often suffer from continual distribution
shifts and expensive labeling in changing environments. This calls for a new
online learning paradigm where the learner can continually adapt to changing
environments with limited labels. In this paper, we propose a new online
setting -- Online Active Continual Adaptation, where the learner aims to
continually adapt to changing distributions using both unlabeled samples and
active queries of limited labels. To this end, we propose Online Self-Adaptive
Mirror Descent (OSAMD), which adopts an online teacher-student structure to
enable online self-training from unlabeled data, and a margin-based criterion
that decides whether to query the labels to track changing distributions.
Theoretically, we show that, in the separable case, OSAMD has an $O({T}^{1/2})$
dynamic regret bound under mild assumptions, which is even tighter than the
lower bound $\Omega(T^{2/3})$ of traditional online learning with full labels.
In the general case, we show a regret bound of $O({\alpha^*}^{1/3} {T}^{2/3} +
\alpha^* T)$, where $\alpha^*$ denotes the separability of domains and is
usually small. Our theoretical results show that OSAMD can fast adapt to
changing environments with active queries. Empirically, we demonstrate that
OSAMD achieves favorable regrets under changing environments with limited
labels on both simulated and real-world data, which corroborates our
theoretical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and Semantic Embedding. (arXiv:2105.05596v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1">Zhiyuan Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaoyan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yuejia Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1">Ningyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05596">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent
entities, relations, and others) between two KGs. The existing methods can be
divided into the embedding-based models, and the conventional reasoning and
lexical matching based systems. The former compute the similarity of entities
via their cross-KG embeddings, but they usually rely on an ideal supervised
learning setting for good performance and lack appropriate reasoning to avoid
logically wrong mappings; while the latter address the reasoning issue but are
poor at utilizing the KG graph structures and the entity contexts. In this
study, we aim at combining the above two solutions and thus propose an
iterative framework named PRASE which is based on probabilistic reasoning and
semantic embedding. It learns the KG embeddings via entity mappings from a
probabilistic reasoning system named PARIS, and feeds the resultant entity
mappings and embeddings back into PARIS for augmentation. The PRASE framework
is compatible with different embedding-based models, and our experiments on
multiple datasets have demonstrated its state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Trained One-class Classification for Unsupervised Anomaly Detection. (arXiv:2106.06115v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jinsung Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1">Kihyuk Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chun-Liang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1">Sercan O. Arik</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chen-Yu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1">Tomas Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06115">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly detection (AD), separating anomalies from normal data, has various
applications across domains, from manufacturing to healthcare. While most
previous works have shown to be effective for cases with fully or partially
labeled data, they are less practical for AD applications due to tedious data
labeling processes. In this work, we focus on unsupervised AD problems whose
entire training data are unlabeled and may contain both normal and anomalous
samples. To tackle this problem, we build a robust one-class classification
framework via data refinement. To refine the data accurately, we propose an
ensemble of one-class classifiers, each of which is trained on a disjoint
subset of training data. Moreover, we propose a self-training of deep
representation one-class classifiers (STOC) that iteratively refines the data
and deep representations. In experiments, we show the efficacy of our method
for unsupervised anomaly detection on benchmarks from image and tabular data
domains. For example, with a 10% anomaly ratio on CIFAR-10 data, the proposed
method outperforms state-of-the-art one-class classification method by 6.3 AUC
and 12.5 average precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-domain Multi-relational Link Prediction. (arXiv:2106.06171v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Phuc_L/0/1/0/all/0/1">Luu Huu Phuc</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1">Koh Takeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1">Seiji Okajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1">Arseny Tolmachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1">Tomoyoshi Takebayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1">Koji Maruhashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06171">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-relational graph is a ubiquitous and important data structure, allowing
flexible representation of multiple types of interactions and relations between
entities. Similar to other graph-structured data, link prediction is one of the
most important tasks on multi-relational graphs and is often used for knowledge
completion. When related graphs coexist, it is of great benefit to build a
larger graph via integrating the smaller ones. The integration requires
predicting hidden relational connections between entities belonged to different
graphs (inter-domain link prediction). However, this poses a real challenge to
existing methods that are exclusively designed for link prediction between
entities of the same graph only (intra-domain link prediction). In this study,
we propose a new approach to tackle the inter-domain link prediction problem by
softly aligning the entity distributions between different domains with optimal
transport and maximum mean discrepancy regularizers. Experiments on real-world
datasets show that optimal transport regularizer is beneficial and considerably
improves the performance of baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Free Learning for Two-Player Zero-Sum Partially Observable Markov Games with Perfect Recall. (arXiv:2106.06279v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kozuno_T/0/1/0/all/0/1">Tadashi Kozuno</a>, <a href="http://arxiv.org/find/stat/1/au:+Menard_P/0/1/0/all/0/1">Pierre M&#xe9;nard</a>, <a href="http://arxiv.org/find/stat/1/au:+Munos_R/0/1/0/all/0/1">R&#xe9;mi Munos</a>, <a href="http://arxiv.org/find/stat/1/au:+Valko_M/0/1/0/all/0/1">Michal Valko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06279">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of learning a Nash equilibrium (NE) in an imperfect
information game (IIG) through self-play. Precisely, we focus on two-player,
zero-sum, episodic, tabular IIG under the perfect-recall assumption where the
only feedback is realizations of the game (bandit feedback). In particular, the
dynamic of the IIG is not known -- we can only access it by sampling or
interacting with a game simulator. For this learning setting, we provide the
Implicit Exploration Online Mirror Descent (IXOMD) algorithm. It is a
model-free algorithm with a high-probability bound on the convergence rate to
the NE of order $1/\sqrt{T}$ where $T$ is the number of played games. Moreover,
IXOMD is computationally efficient as it needs to perform the updates only
along the sampled trajectory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning via Persistency of Excitation. (arXiv:2106.02078v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1">Kaustubh Sridhar</a>, <a href="http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1">Oleg Sokolsky</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1">James Weimer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02078">
                                    <div class="article-summary-box-inner">
                                        <span>Improving adversarial robustness of neural networks remains a major
challenge. Fundamentally, training a network is a parameter estimation problem.
In adaptive control theory, maintaining persistency of excitation (PoE) is
integral to ensuring convergence of parameter estimates in dynamical systems to
their robust optima. In this work, we show that network training using gradient
descent is equivalent to a dynamical system parameter estimation problem.
Leveraging this relationship, we prove a sufficient condition for PoE of
gradient descent is achieved when the learning rate is less than the inverse of
the Lipschitz constant of the gradient of loss function. We provide an
efficient technique for estimating the corresponding Lipschitz constant using
extreme value theory and demonstrate that by only scaling the learning rate
schedule we can increase adversarial accuracy by up to 15% points on benchmark
datasets. Our approach also universally increases the adversarial accuracy by
0.1% to 0.3% points in various state-of-the-art adversarially trained models on
the AutoAttack benchmark, where every small margin of improvement is
significant.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotics of representation learning in finite Bayesian neural networks. (arXiv:2106.00651v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zavatone_Veth_J/0/1/0/all/0/1">Jacob A. Zavatone-Veth</a>, <a href="http://arxiv.org/find/cs/1/au:+Canatar_A/0/1/0/all/0/1">Abdulkadir Canatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pehlevan_C/0/1/0/all/0/1">Cengiz Pehlevan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00651">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have suggested that finite Bayesian neural networks may
outperform their infinite cousins because finite networks can flexibly adapt
their internal representations. However, our theoretical understanding of how
the learned hidden layer representations of finite networks differ from the
fixed representations of infinite networks remains incomplete. Perturbative
finite-width corrections to the network prior and posterior have been studied,
but the asymptotics of learned features have not been fully characterized.
Here, we argue that the leading finite-width corrections to the average feature
kernels for any Bayesian network with linear readout and quadratic cost have a
largely universal form. We illustrate this explicitly for two classes of fully
connected networks: deep linear networks and networks with a single nonlinear
hidden layer. Our results begin to elucidate which features of data wide
Bayesian neural networks learn to represent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v2 [q-fin.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1">Junran Wu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1">Ke Xu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1">Xueyuan Chen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1">Shangzhe Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1">Jichang Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02522">
                                    <div class="article-summary-box-inner">
                                        <span>Stock prediction, with the purpose of forecasting the future price trends of
stocks, is crucial for maximizing profits from stock investments. While great
research efforts have been devoted to exploiting deep neural networks for
improved stock prediction, two major issues still exist in recent studies.
First, the capture of long-range dependencies in time series is not
sufficiently addressed. Second, the chaotic property of financial time series
fundamentally lowers prediction performance. In this study, we propose a novel
framework to address both issues regarding stock prediction. Specifically, in
terms of transforming time series into complex networks, we convert market
price series into graphs. Then, structural information, referring to
associations among temporal points and the node weights, is extracted from the
mapped graphs to resolve the problems regarding long-range dependencies and the
chaotic property. We take graph embeddings to represent the associations among
temporal points as the prediction model inputs. Node weights are used as a
priori knowledge to enhance the learning of temporal attention. The
effectiveness of our proposed framework is validated using real-world stock
data, and our approach obtains the best performance among several
state-of-the-art benchmarks. Moreover, in the conducted trading simulations,
our framework further obtains the highest cumulative profits. Our results
supplement the existing applications of complex network methods in the
financial realm and provide insightful implications for investment applications
regarding decision support in financial markets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction. (arXiv:2105.10446v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1">Kwan Ho Ryan Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaodong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chong You</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Haozhi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1">John Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10446">
                                    <div class="article-summary-box-inner">
                                        <span>This work attempts to provide a plausible theoretical framework that aims to
interpret modern deep (convolutional) networks from the principles of data
compression and discriminative representation. We argue that for
high-dimensional multi-class data, the optimal linear discriminative
representation maximizes the coding rate difference between the whole dataset
and the average of all the subsets. We show that the basic iterative gradient
ascent scheme for optimizing the rate reduction objective naturally leads to a
multi-layer deep network, named ReduNet, which shares common characteristics of
modern deep networks. The deep layered architectures, linear and nonlinear
operators, and even parameters of the network are all explicitly constructed
layer-by-layer via forward propagation, although they are amenable to
fine-tuning via back propagation. All components of so-obtained &#x60;&#x60;white-box&#x27;&#x27;
network have precise optimization, statistical, and geometric interpretation.
Moreover, all linear operators of the so-derived network naturally become
multi-channel convolutions when we enforce classification to be rigorously
shift-invariant. The derivation in the invariant setting suggests a trade-off
between sparsity and invariance, and also indicates that such a deep
convolution network is significantly more efficient to construct and learn in
the spectral domain. Our preliminary simulations and experiments clearly verify
the effectiveness of both the rate reduction objective and the associated
ReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scale-invariant scale-channel networks: Deep networks that generalise to previously unseen scales. (arXiv:2106.06418v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jansson_Y/0/1/0/all/0/1">Ylva Jansson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindeberg_T/0/1/0/all/0/1">Tony Lindeberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06418">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to handle large scale variations is crucial for many real world
visual tasks. A straightforward approach for handling scale in a deep network
is to process an image at several scales simultaneously in a set of scale
channels. Scale invariance can then, in principle, be achieved by using weight
sharing between the scale channels together with max or average pooling over
the outputs from the scale channels. The ability of such scale channel networks
to generalise to scales not present in the training set over significant scale
ranges has, however, not previously been explored.

In this paper, we present a systematic study of this methodology by
implementing different types of scale channel networks and evaluating their
ability to generalise to previously unseen scales. We develop a formalism for
analysing the covariance and invariance properties of scale channel networks,
and explore how different design choices, unique to scaling transformations,
affect the overall performance of scale channel networks. We first show that
two previously proposed scale channel network designs do not generalise well to
scales not present in the training set. We explain theoretically and
demonstrate experimentally why generalisation fails in these cases.

We then propose a new type of foveated scale channel architecture}, where the
scale channels process increasingly larger parts of the image with decreasing
resolution. This new type of scale channel network is shown to generalise
extremely well, provided sufficient image resolution and the absence of
boundary effects. Our proposed FovMax and FovAvg networks perform almost
identically over a scale range of 8, also when training on single scale
training data, and do also give improved performance when learning from
datasets with large scale variations in the small sample regime.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRLD-SP: A Deep Reinforcement Learning-based Dynamic Service Placement in Edge-Enabled Internet of Vehicles. (arXiv:2106.06291v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Talpur_A/0/1/0/all/0/1">Anum Talpur</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurusamy_M/0/1/0/all/0/1">Mohan Gurusamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06291">
                                    <div class="article-summary-box-inner">
                                        <span>The growth of 5G and edge computing has enabled the emergence of Internet of
Vehicles. It supports different types of services with different resource and
service requirements. However, limited resources at the edge, high mobility of
vehicles, increasing demand, and dynamicity in service request-types have made
service placement a challenging task. A typical static placement solution is
not effective as it does not consider the traffic mobility and service
dynamics. Handling dynamics in IoV for service placement is an important and
challenging problem which is the primary focus of our work in this paper. We
propose a Deep Reinforcement Learning-based Dynamic Service Placement (DRLD-SP)
framework with the objective of minimizing the maximum edge resource usage and
service delay while considering the vehicle&#x27;s mobility, varying demand, and
dynamics in the requests for different types of services. We use SUMO and
MATLAB to carry out simulation experiments. The experimental results show that
the proposed DRLD-SP approach is effective and outperforms other static and
dynamic placement approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Going Beyond Linear Transformers with Recurrent Fast Weight Programmers. (arXiv:2106.06295v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1">Kazuki Irie</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1">Imanol Schlag</a>, <a href="http://arxiv.org/find/cs/1/au:+Csordas_R/0/1/0/all/0/1">R&#xf3;bert Csord&#xe1;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06295">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers with linearised attention (&quot;linear Transformers&quot;) have
demonstrated the practical scalability and effectiveness of outer product-based
Fast Weight Programmers (FWPs) from the &#x27;90s. However, the original FWP
formulation is more general than the one of linear Transformers: a slow neural
network (NN) continually reprograms the weights of a fast NN with arbitrary NN
architectures. In existing linear Transformers, both NNs are feedforward and
consist of a single layer. Here we explore new variations by adding recurrence
to the slow and fast nets. We evaluate our novel recurrent FWPs (RFWPs) on two
synthetic algorithmic tasks (code execution and sequential ListOps),
Wikitext-103 language models, and on the Atari 2600 2D game environment. Our
models exhibit properties of Transformers and RNNs. In the reinforcement
learning setting, we report large improvements over LSTM in several Atari
games. Our code is public.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Catch-A-Waveform: Learning to Generate Audio from a Single Short Example. (arXiv:2106.06426v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Greshler_G/0/1/0/all/0/1">Gal Greshler</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1">Tamar Rott Shaham</a>, <a href="http://arxiv.org/find/cs/1/au:+Michaeli_T/0/1/0/all/0/1">Tomer Michaeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06426">
                                    <div class="article-summary-box-inner">
                                        <span>Models for audio generation are typically trained on hours of recordings.
Here, we illustrate that capturing the essence of an audio source is typically
possible from as little as a few tens of seconds from a single training signal.
Specifically, we present a GAN-based generative model that can be trained on
one short audio signal from any domain (e.g. speech, music, etc.) and does not
require pre-training or any other form of external supervision. Once trained,
our model can generate random samples of arbitrary duration that maintain
semantic similarity to the training waveform, yet exhibit new compositions of
its audio primitives. This enables a long line of interesting applications,
including generating new jazz improvisations or new a-cappella rap variants
based on a single short example, producing coherent modifications to famous
songs (e.g. adding a new verse to a Beatles song based solely on the original
recording), filling-in of missing parts (inpainting), extending the bandwidth
of a speech signal (super-resolution), and enhancing old recordings without
access to any clean training example. We show that in all cases, no more than
20 seconds of training audio commonly suffice for our model to achieve
state-of-the-art results. This is despite its complete lack of prior knowledge
about the nature of audio signals in general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Robustness through the Lens of Causality. (arXiv:2106.06196v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yonggang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Mingming Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1">Xinmei Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06196">
                                    <div class="article-summary-box-inner">
                                        <span>The adversarial vulnerability of deep neural networks has attracted
significant attention in machine learning. From a causal viewpoint, adversarial
attacks can be considered as a specific type of distribution change on natural
data. As causal reasoning has an instinct for modeling distribution change, we
propose to incorporate causality into mitigating adversarial vulnerability.
However, causal formulations of the intuition of adversarial attack and the
development of robust DNNs are still lacking in the literature. To bridge this
gap, we construct a causal graph to model the generation process of adversarial
examples and define the adversarial distribution to formalize the intuition of
adversarial attacks. From a causal perspective, we find that the label is
spuriously correlated with the style (content-independent) information when an
instance is given. The spurious correlation implies that the adversarial
distribution is constructed via making the statistical conditional association
between style information and labels drastically different from that in natural
distribution. Thus, DNNs that fit the spurious correlation are vulnerable to
the adversarial distribution. Inspired by the observation, we propose the
adversarial distribution alignment method to eliminate the difference between
the natural distribution and the adversarial distribution. Extensive
experiments demonstrate the efficacy of the proposed method. Our method can be
seen as the first attempt to leverage causality for mitigating adversarial
vulnerability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guarantees for Tuning the Step Size using a Learning-to-Learn Approach. (arXiv:2006.16495v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1">Xiang Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yuan_S/0/1/0/all/0/1">Shuai Yuan</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_C/0/1/0/all/0/1">Chenwei Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Ge_R/0/1/0/all/0/1">Rong Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16495">
                                    <div class="article-summary-box-inner">
                                        <span>Choosing the right parameters for optimization algorithms is often the key to
their success in practice. Solving this problem using a learning-to-learn
approach -- using meta-gradient descent on a meta-objective based on the
trajectory that the optimizer generates -- was recently shown to be effective.
However, the meta-optimization problem is difficult. In particular, the
meta-gradient can often explode/vanish, and the learned optimizer may not have
good generalization performance if the meta-objective is not chosen carefully.
In this paper we give meta-optimization guarantees for the learning-to-learn
approach on a simple problem of tuning the step size for quadratic loss. Our
results show that the na\&quot;ive objective suffers from meta-gradient
explosion/vanishing problem. Although there is a way to design the
meta-objective so that the meta-gradient remains polynomially bounded,
computing the meta-gradient directly using backpropagation leads to numerical
issues. We also characterize when it is necessary to compute the meta-objective
on a separate validation set to ensure the generalization performance of the
learned optimizer. Finally, we verify our results empirically and show that a
similar phenomenon appears even for more complicated learned optimizers
parametrized by neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Game Theoretic Neural Optimizer. (arXiv:2105.03788v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guan-Horng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianrong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1">Evangelos A. Theodorou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03788">
                                    <div class="article-summary-box-inner">
                                        <span>The connection between training deep neural networks (DNNs) and optimal
control theory (OCT) has attracted considerable attention as a principled tool
of algorithmic design. Despite few attempts being made, they have been limited
to architectures where the layer propagation resembles a Markovian dynamical
system. This casts doubts on their flexibility to modern networks that heavily
rely on non-Markovian dependencies between layers (e.g. skip connections in
residual networks). In this work, we propose a novel dynamic game perspective
by viewing each layer as a player in a dynamic game characterized by the DNN
itself. Through this lens, different classes of optimizers can be seen as
matching different types of Nash equilibria, depending on the implicit
information structure of each (p)layer. The resulting method, called Dynamic
Game Theoretic Neural Optimizer (DGNOpt), not only generalizes OCT-inspired
optimizers to richer network class; it also motivates a new training principle
by solving a multi-player cooperative game. DGNOpt shows convergence
improvements over existing methods on image classification datasets with
residual and inception networks. Our work marries strengths from both OCT and
game theory, paving ways to new algorithmic opportunities from robust optimal
control and bandit-based optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Anomaly Detection Ensembles using Item Response Theory. (arXiv:2106.06243v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kandanaarachchi_S/0/1/0/all/0/1">Sevvandi Kandanaarachchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06243">
                                    <div class="article-summary-box-inner">
                                        <span>Constructing an ensemble from a heterogeneous set of unsupervised anomaly
detection methods is challenging because the class labels or the ground truth
is unknown. Thus, traditional ensemble techniques that use the response
variable or the class labels cannot be used to construct an ensemble for
unsupervised anomaly detection.

We use Item Response Theory (IRT) -- a class of models used in educational
psychometrics to assess student and test question characteristics -- to
construct an unsupervised anomaly detection ensemble. IRT&#x27;s latent trait
computation lends itself to anomaly detection because the latent trait can be
used to uncover the hidden ground truth. Using a novel IRT mapping to the
anomaly detection problem, we construct an ensemble that can downplay noisy,
non-discriminatory methods and accentuate sharper methods. We demonstrate the
effectiveness of the IRT ensemble on an extensive data repository, by comparing
its performance to other ensemble techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Robustness of Average Losses for Partial-Label Learning. (arXiv:2106.06152v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1">Jiaqi Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Miao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xin Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06152">
                                    <div class="article-summary-box-inner">
                                        <span>Partial-label (PL) learning is a typical weakly supervised classification
problem, where a PL of an instance is a set of candidate labels such that a
fixed but unknown candidate is the true label. For PL learning, there are two
lines of research: (a) the identification-based strategy (IBS) purifies each
label set and extracts the true label; (b) the average-based strategy (ABS)
treats all candidates equally for training. In the past two decades, IBS was a
much hotter topic than ABS, since it was believed that IBS is more promising.
In this paper, we theoretically analyze ABS and find it also promising in the
sense of the robustness of its loss functions. Specifically, we consider five
problem settings for the generation of clean or noisy PLs, and we prove that
average PL losses with bounded multi-class losses are always robust under mild
assumptions on the domination of true labels, while average PL losses with
unbounded multi-class losses (e.g., the cross-entropy loss) may not be robust.
We also conduct experiments to validate our theoretical findings. Note that IBS
is heuristic, and we cannot prove its robustness by a similar proof technique;
hence, ABS is more advantageous from a theoretical point of view, and it is
worth paying attention to the design of more advanced PL learning methods
following ABS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proxy-Normalizing Activations to Match Batch Normalization while Removing Batch Dependence. (arXiv:2106.03743v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Labatie_A/0/1/0/all/0/1">Antoine Labatie</a>, <a href="http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1">Dominic Masters</a>, <a href="http://arxiv.org/find/cs/1/au:+Eaton_Rosen_Z/0/1/0/all/0/1">Zach Eaton-Rosen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03743">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the reasons for the performance degradation incurred with
batch-independent normalization. We find that the prototypical techniques of
layer normalization and instance normalization both induce the appearance of
failure modes in the neural network&#x27;s pre-activations: (i) layer normalization
induces a collapse towards channel-wise constant functions; (ii) instance
normalization induces a lack of variability in instance statistics, symptomatic
of an alteration of the expressivity. To alleviate failure mode (i) without
aggravating failure mode (ii), we introduce the technique &quot;Proxy Normalization&quot;
that normalizes post-activations using a proxy distribution. When combined with
layer normalization or group normalization, this batch-independent
normalization emulates batch normalization&#x27;s behavior and consistently matches
or exceeds its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Twins: Revisiting the Design of Spatial Attention in Vision Transformers. (arXiv:2104.13840v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zhi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Haibing Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaolin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1">Huaxia Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13840">
                                    <div class="article-summary-box-inner">
                                        <span>Very recently, a variety of vision transformer architectures for dense
prediction tasks have been proposed and they show that the design of spatial
attention is critical to their success in these tasks. In this work, we revisit
the design of the spatial attention and demonstrate that a carefully-devised
yet simple spatial attention mechanism performs favourably against the
state-of-the-art schemes. As a result, we propose two vision transformer
architectures, namely, Twins-PCPVT and Twins-SVT. Our proposed architectures
are highly-efficient and easy to implement, only involving matrix
multiplications that are highly optimized in modern deep learning frameworks.
More importantly, the proposed architectures achieve excellent performance on a
wide range of visual tasks including imagelevel classification as well as dense
detection and segmentation. The simplicity and strong performance suggest that
our proposed architectures may serve as stronger backbones for many vision
tasks. Our code will be released soon at
https://github.com/Meituan-AutoML/Twins .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Moreau-Yosida $f$-divergences. (arXiv:2102.13416v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Terjek_D/0/1/0/all/0/1">D&#xe1;vid Terj&#xe9;k</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13416">
                                    <div class="article-summary-box-inner">
                                        <span>Variational representations of $f$-divergences are central to many machine
learning algorithms, with Lipschitz constrained variants recently gaining
attention. Inspired by this, we define the Moreau-Yosida approximation of
$f$-divergences with respect to the Wasserstein-$1$ metric. The corresponding
variational formulas provide a generalization of a number of recent results,
novel special cases of interest and a relaxation of the hard Lipschitz
constraint. Additionally, we prove that the so-called tight variational
representation of $f$-divergences can be to be taken over the quotient space of
Lipschitz functions, and give a characterization of functions achieving the
supremum in the variational representation. On the practical side, we propose
an algorithm to calculate the tight convex conjugate of $f$-divergences
compatible with automatic differentiation frameworks. As an application of our
results, we propose the Moreau-Yosida $f$-GAN, providing an implementation of
the variational formulas for the Kullback-Leibler, reverse Kullback-Leibler,
$\chi^2$, reverse $\chi^2$, squared Hellinger, Jensen-Shannon, Jeffreys,
triangular discrimination and total variation divergences as GANs trained on
CIFAR-10, leading to competitive results and a simple solution to the problem
of uniqueness of the optimal critic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Performance FPGA-based Accelerator for Bayesian Neural Networks. (arXiv:2105.09163v2 [cs.AR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Hongxiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1">Martin Ferianc</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1">Miguel Rodrigues</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hongyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1">Xinyu Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luk_W/0/1/0/all/0/1">Wayne Luk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09163">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks (NNs) have demonstrated their potential in a wide range of
applications such as image recognition, decision making or recommendation
systems. However, standard NNs are unable to capture their model uncertainty
which is crucial for many safety-critical applications including healthcare and
autonomous vehicles. In comparison, Bayesian neural networks (BNNs) are able to
express uncertainty in their prediction via a mathematical grounding.
Nevertheless, BNNs have not been as widely used in industrial practice, mainly
because of their expensive computational cost and limited hardware performance.
This work proposes a novel FPGA-based hardware architecture to accelerate BNNs
inferred through Monte Carlo Dropout. Compared with other state-of-the-art BNN
accelerators, the proposed accelerator can achieve up to 4 times higher energy
efficiency and 9 times better compute efficiency. Considering partial Bayesian
inference, an automatic framework is proposed, which explores the trade-off
between hardware and algorithmic performance. Extensive experiments are
conducted to demonstrate that our proposed framework can effectively find the
optimal points in the design space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Extend Molecular Scaffolds with Structural Motifs. (arXiv:2103.03864v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maziarz_K/0/1/0/all/0/1">Krzysztof Maziarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Jackson_Flux_H/0/1/0/all/0/1">Henry Jackson-Flux</a>, <a href="http://arxiv.org/find/cs/1/au:+Cameron_P/0/1/0/all/0/1">Pashmina Cameron</a>, <a href="http://arxiv.org/find/cs/1/au:+Sirockin_F/0/1/0/all/0/1">Finton Sirockin</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1">Nadine Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefl_N/0/1/0/all/0/1">Nikolaus Stiefl</a>, <a href="http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1">Marwin Segler</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1">Marc Brockschmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03864">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in deep learning-based modeling of molecules promise to
accelerate in silico drug discovery. A plethora of generative models is
available, building molecules either atom-by-atom and bond-by-bond or
fragment-by-fragment. However, many drug discovery projects require a fixed
scaffold to be present in the generated molecule, and incorporating that
constraint has only recently been explored. In this work, we propose a new
graph-based model that naturally supports scaffolds as initial seed of the
generative procedure, which is possible because our model is not conditioned on
the generation history. At the same time, our generation procedure can flexibly
choose between adding individual atoms and entire fragments. We show that
training using a randomized generation order is necessary for good performance
when extending scaffolds, and that the results are further improved by
increasing the fragment vocabulary size. Our model pushes the state-of-the-art
of graph-based molecule generation, while being an order of magnitude faster to
train and sample from than existing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Shapley Value of Classifiers in Ensemble Games. (arXiv:2101.02153v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rozemberczki_B/0/1/0/all/0/1">Benedek Rozemberczki</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1">Rik Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02153">
                                    <div class="article-summary-box-inner">
                                        <span>What is the value of an individual model in an ensemble of binary
classifiers? We answer this question by introducing a class of transferable
utility cooperative games called \textit{ensemble games}. In machine learning
ensembles, pre-trained models cooperate to make classification decisions. To
quantify the importance of models in these ensemble games, we define
\textit{Troupe} -- an efficient algorithm which allocates payoffs based on
approximate Shapley values of the classifiers. We argue that the Shapley value
of models in these games is an effective decision metric for choosing a high
performing subset of models from the ensemble. Our analytical findings prove
that our Shapley value estimation scheme is precise and scalable; its
performance increases with size of the dataset and ensemble. Empirical results
on real world graph classification tasks demonstrate that our algorithm
produces high quality estimates of the Shapley value. We find that Shapley
values can be utilized for ensemble pruning, and that adversarial models
receive a low valuation. Complex classifiers are frequently found to be
responsible for both correct and incorrect classification decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RNN with Particle Flow for Probabilistic Spatio-temporal Forecasting. (arXiv:2106.06064v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1">Soumyasundar Pal</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1">Liheng Ma</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1">Yingxue Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Coates_M/0/1/0/all/0/1">Mark Coates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06064">
                                    <div class="article-summary-box-inner">
                                        <span>Spatio-temporal forecasting has numerous applications in analyzing wireless,
traffic, and financial networks. Many classical statistical models often fall
short in handling the complexity and high non-linearity present in time-series
data. Recent advances in deep learning allow for better modelling of spatial
and temporal dependencies. While most of these models focus on obtaining
accurate point forecasts, they do not characterize the prediction uncertainty.
In this work, we consider the time-series data as a random realization from a
nonlinear state-space model and target Bayesian inference of the hidden states
for probabilistic forecasting. We use particle flow as the tool for
approximating the posterior distribution of the states, as it is shown to be
highly effective in complex, high-dimensional settings. Thorough
experimentation on several real world time-series datasets demonstrates that
our approach provides better characterization of uncertainty while maintaining
comparable accuracy to the state-of-the art point forecasting methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Binary Classification from Multiple Unlabeled Datasets via Surrogate Set Classification. (arXiv:2102.00678v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_N/0/1/0/all/0/1">Nan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_S/0/1/0/all/0/1">Shida Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00678">
                                    <div class="article-summary-box-inner">
                                        <span>To cope with high annotation costs, training a classifier only from weakly
supervised data has attracted a great deal of attention these days. Among
various approaches, strengthening supervision from completely unsupervised
classification is a promising direction, which typically employs class priors
as the only supervision and trains a binary classifier from unlabeled (U)
datasets. While existing risk-consistent methods are theoretically grounded
with high flexibility, they can learn only from two U sets. In this paper, we
propose a new approach for binary classification from $m$ U-sets for $m\ge2$.
Our key idea is to consider an auxiliary classification task called surrogate
set classification (SSC), which is aimed at predicting from which U set each
observed data is drawn. SSC can be solved by a standard (multi-class)
classification method, and we use the SSC solution to obtain the final binary
classifier through a certain linear-fractional transformation. We built our
method in a flexible and efficient end-to-end deep learning framework and prove
it to be classifier-consistent. Through experiments, we demonstrate the
superiority of our proposed method over state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surface Warping Incorporating Machine Learning Assisted Domain Likelihood Estimation: A New Paradigm in Mine Geology Modelling and Automation. (arXiv:2103.03923v2 [physics.geo-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Leung_R/0/1/0/all/0/1">Raymond Leung</a>, <a href="http://arxiv.org/find/physics/1/au:+Balamurali_M/0/1/0/all/0/1">Mehala Balamurali</a>, <a href="http://arxiv.org/find/physics/1/au:+Lowe_A/0/1/0/all/0/1">Alexander Lowe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03923">
                                    <div class="article-summary-box-inner">
                                        <span>This paper illustrates an application of machine learning (ML) within a
complex system that performs grade estimation. In surface mining, assay
measurements taken from production drilling often provide useful information
that allows initially inaccurate surfaces created using sparse exploration data
to be revised and subsequently improved. Recently, a Bayesian warping technique
has been proposed to reshape modeled surfaces using geochemical and spatial
constraints imposed by newly acquired blasthole data. This paper focuses on
incorporating machine learning into this warping framework to make the
likelihood computation generalizable. The technique works by adjusting the
position of vertices on the surface to maximize the integrity of modeled
geological boundaries with respect to sparse geochemical observations. Its
foundation is laid by a Bayesian derivation in which the geological domain
likelihood given the chemistry, p(g|c), plays a similar role to p(y(c)|g). This
observation allows a manually calibrated process centered around the latter to
be automated since ML techniques may be used to estimate the former in a
data-driven way. Machine learning performance is evaluated for gradient
boosting, neural network, random forest and other classifiers in a binary and
multi-class context using precision and recall rates. Once ML likelihood
estimators are integrated in the surface warping framework, surface shaping
performance is evaluated using unseen data by examining the categorical
distribution of test samples located above and below the warped surface.
Large-scale validation experiments are performed to assess the overall efficacy
of ML assisted surface warping as a fully integrated component within an ore
grade estimation system where the posterior mean is obtained via Gaussian
Process inference with a Matern 3/2 kernel.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Archimedean Copulas. (arXiv:2102.11351v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ng_Y/0/1/0/all/0/1">Yuting Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Ali Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Elkhalil_K/0/1/0/all/0/1">Khalil Elkhalil</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11351">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new generative modeling technique for learning multidimensional
cumulative distribution functions (CDFs) in the form of copulas. Specifically,
we consider certain classes of copulas known as Archimedean and hierarchical
Archimedean copulas, popular for their parsimonious representation and ability
to model different tail dependencies. We consider their representation as
mixture models with Laplace transforms of latent random variables from
generative neural networks. This alternative representation allows for
computational efficiencies and easy sampling, especially in high dimensions. We
describe multiple methods for optimizing the network parameters. Finally, we
present empirical results that demonstrate the efficacy of our proposed method
in learning multidimensional CDFs and its computational efficiency compared to
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Infinite-dimensional Folded-in-time Deep Neural Networks. (arXiv:2101.02966v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stelzer_F/0/1/0/all/0/1">Florian Stelzer</a> (1, 2 and 3), <a href="http://arxiv.org/find/cs/1/au:+Yanchuk_S/0/1/0/all/0/1">Serhiy Yanchuk</a> (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany, (3) Institute of Computer Science, University of Tartu, Estonia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02966">
                                    <div class="article-summary-box-inner">
                                        <span>The method recently introduced in arXiv:2011.10115 realizes a deep neural
network with just a single nonlinear element and delayed feedback. It is
applicable for the description of physically implemented neural networks. In
this work, we present an infinite-dimensional generalization, which allows for
a more rigorous mathematical analysis and a higher flexibility in choosing the
weight functions. Precisely speaking, the weights are described by Lebesgue
integrable functions instead of step functions. We also provide a functional
back-propagation algorithm, which enables gradient descent training of the
weights. In addition, with a slight modification, our concept realizes
recurrent neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap. (arXiv:2103.03236v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Swamy_G/0/1/0/all/0/1">Gokul Swamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhury_S/0/1/0/all/0/1">Sanjiban Choudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagnell_J/0/1/0/all/0/1">J. Andrew Bagnell</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03236">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a unifying view of a large family of previous imitation learning
algorithms through the lens of moment matching. At its core, our classification
scheme is based on whether the learner attempts to match (1) reward or (2)
action-value moments of the expert&#x27;s behavior, with each option leading to
differing algorithmic approaches. By considering adversarially chosen
divergences between learner and expert behavior, we are able to derive bounds
on policy performance that apply for all algorithms in each of these classes,
the first to our knowledge. We also introduce the notion of moment
recoverability, implicit in many previous analyses of imitation learning, which
allows us to cleanly delineate how well each algorithmic family is able to
mitigate compounding errors. We derive three novel algorithm templates (AdVIL,
AdRIL, and DAeQuIL) with strong guarantees, simple implementation, and
competitive empirical performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signal Processing on Higher-Order Networks: Livin&#x27; on the Edge ... and Beyond. (arXiv:2101.05510v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schaub_M/0/1/0/all/0/1">Michael T. Schaub</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Seby_J/0/1/0/all/0/1">Jean-Baptiste Seby</a>, <a href="http://arxiv.org/find/cs/1/au:+Roddenberry_T/0/1/0/all/0/1">T. Mitchell Roddenberry</a>, <a href="http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1">Santiago Segarra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05510">
                                    <div class="article-summary-box-inner">
                                        <span>In this tutorial, we provide a didactic treatment of the emerging topic of
signal processing on higher-order networks. Drawing analogies from discrete and
graph signal processing, we introduce the building blocks for processing data
on simplicial complexes and hypergraphs, two common higher-order network
abstractions that can incorporate polyadic relationships. We provide brief
introductions to simplicial complexes and hypergraphs, with a special emphasis
on the concepts needed for the processing of signals supported on these
structures. Specifically, we discuss Fourier analysis, signal denoising, signal
interpolation, node embeddings, and nonlinear processing through neural
networks, using these two higher-order network models. In the context of
simplicial complexes, we specifically focus on signal processing using the
Hodge Laplacian matrix, a multi-relational operator that leverages the special
structure of simplicial complexes and generalizes desirable properties of the
Laplacian matrix in graph signal processing. For hypergraphs, we present both
matrix and tensor representations, and discuss the trade-offs in adopting one
or the other. We also highlight limitations and potential research avenues,
both to inform practitioners and to motivate the contribution of new
researchers to the area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision. (arXiv:2102.05918v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1">Chao Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Ye Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Parekh_Z/0/1/0/all/0/1">Zarana Parekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Yunhsuan Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Duerig_T/0/1/0/all/0/1">Tom Duerig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05918">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained representations are becoming crucial for many NLP and perception
tasks. While representation learning in NLP has transitioned to training on raw
text without human annotations, visual and vision-language representations
still rely heavily on curated training datasets that are expensive or require
expert knowledge. For vision applications, representations are mostly learned
using datasets with explicit class labels such as ImageNet or OpenImages. For
vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all
involve a non-trivial data collection (and cleaning) process. This costly
curation process limits the size of datasets and hence hinders the scaling of
trained models. In this paper, we leverage a noisy dataset of over one billion
image alt-text pairs, obtained without expensive filtering or post-processing
steps in the Conceptual Captions dataset. A simple dual-encoder architecture
learns to align visual and language representations of the image and text pairs
using a contrastive loss. We show that the scale of our corpus can make up for
its noise and leads to state-of-the-art representations even with such a simple
learning scheme. Our visual representation achieves strong performance when
transferred to classification tasks such as ImageNet and VTAB. The aligned
visual and language representations enables zero-shot image classification and
also set new state-of-the-art results on Flickr30K and MSCOCO image-text
retrieval benchmarks, even when compared with more sophisticated
cross-attention models. The representations also enable cross-modality search
with complex text and text + image queries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Theory of Label Propagation for Subpopulation Shift. (arXiv:2102.11203v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Ruiqi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11203">
                                    <div class="article-summary-box-inner">
                                        <span>One of the central problems in machine learning is domain adaptation. Unlike
past theoretical work, we consider a new model for subpopulation shift in the
input or representation space. In this work, we propose a provably effective
framework for domain adaptation based on label propagation. In our analysis, we
use a simple but realistic expansion assumption, proposed in
\citet{wei2021theoretical}. Using a teacher classifier trained on the source
domain, our algorithm not only propagates to the target domain but also
improves upon the teacher. By leveraging existing generalization bounds, we
also obtain end-to-end finite-sample guarantees on the entire algorithm. In
addition, we extend our theoretical framework to a more general setting of
source-to-target transfer based on a third unlabeled dataset, which can be
easily applied in various learning scenarios. Inspired by our theory, we adapt
consistency-based semi-supervised learning methods to domain adaptation
settings and gain significant improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Zeroth-Order Block Coordinate Descent Algorithm for Huge-Scale Black-Box Optimization. (arXiv:2102.10707v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cai_H/0/1/0/all/0/1">HanQin Cai</a>, <a href="http://arxiv.org/find/math/1/au:+Lou_Y/0/1/0/all/0/1">Yuchen Lou</a>, <a href="http://arxiv.org/find/math/1/au:+McKenzie_D/0/1/0/all/0/1">Daniel McKenzie</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10707">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the zeroth-order optimization problem in the huge-scale setting,
where the dimension of the problem is so large that performing even basic
vector operations on the decision variables is infeasible. In this paper, we
propose a novel algorithm, coined ZO-BCD, that exhibits favorable overall query
complexity and has a much smaller per-iteration computational complexity. In
addition, we discuss how the memory footprint of ZO-BCD can be reduced even
further by the clever use of circulant measurement matrices. As an application
of our new method, we propose the idea of crafting adversarial attacks on
neural network based classifiers in a wavelet domain, which can result in
problem dimensions of over 1.7 million. In particular, we show that crafting
adversarial examples to audio classifiers in a wavelet domain can achieve the
state-of-the-art attack success rate of 97.9%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Abstract Representations through Lossy Compression of Multi-Modal Signals. (arXiv:2101.11376v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilmot_C/0/1/0/all/0/1">Charles Wilmot</a>, <a href="http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1">Jochen Triesch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11376">
                                    <div class="article-summary-box-inner">
                                        <span>A key competence for open-ended learning is the formation of increasingly
abstract representations useful for driving complex behavior. Abstract
representations ignore specific details and facilitate generalization. Here we
consider the learning of abstract representations in a multi-modal setting with
two or more input modalities. We treat the problem as a lossy compression
problem and show that generic lossy compression of multimodal sensory input
naturally extracts abstract representations that tend to strip away modalitiy
specific details and preferentially retain information that is shared across
the different modalities. Furthermore, we propose an architecture to learn
abstract representations by identifying and retaining only the information that
is shared across multiple modalities while discarding any modality specific
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Two-Way Matrix Reordering for Relational Data Analysis. (arXiv:2103.14203v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1">Chihiro Watanabe</a>, <a href="http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1">Taiji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14203">
                                    <div class="article-summary-box-inner">
                                        <span>Matrix reordering is a task to permute the rows and columns of a given
observed matrix such that the resulting reordered matrix shows meaningful or
interpretable structural patterns. Most existing matrix reordering techniques
share the common processes of extracting some feature representations from an
observed matrix in a predefined manner, and applying matrix reordering based on
it. However, in some practical cases, we do not always have prior knowledge
about the structural pattern of an observed matrix. To address this problem, we
propose a new matrix reordering method, called deep two-way matrix reordering
(DeepTMR), using a neural network model. The trained network can automatically
extract nonlinear row/column features from an observed matrix, which can then
be used for matrix reordering. Moreover, the proposed DeepTMR provides the
denoised mean matrix of a given observed matrix as an output of the trained
network. This denoised mean matrix can be used to visualize the global
structure of the reordered observed matrix. We demonstrate the effectiveness of
the proposed DeepTMR by applying it to both synthetic and practical datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Certifying L-infinity Robustness using Neural Networks with L-inf-dist Neurons. (arXiv:2102.05363v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bohang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhou Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Di He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05363">
                                    <div class="article-summary-box-inner">
                                        <span>It is well-known that standard neural networks, even with a high
classification accuracy, are vulnerable to small $\ell_\infty$-norm bounded
adversarial perturbations. Although many attempts have been made, most previous
works either can only provide empirical verification of the defense to a
particular attack method, or can only develop a certified guarantee of the
model robustness in limited scenarios. In this paper, we seek for a new
approach to develop a theoretically principled neural network that inherently
resists $\ell_\infty$ perturbations. In particular, we design a novel neuron
that uses $\ell_\infty$-distance as its basic operation (which we call
$\ell_\infty$-dist neuron), and show that any neural network constructed with
$\ell_\infty$-dist neurons (called $\ell_{\infty}$-dist net) is naturally a
1-Lipschitz function with respect to $\ell_\infty$-norm. This directly provides
a rigorous guarantee of the certified robustness based on the margin of
prediction outputs. We then prove that such networks have enough expressive
power to approximate any 1-Lipschitz function with robust generalization
guarantee. We further provide a holistic training strategy that can greatly
alleviate optimization difficulties. Experimental results show that using
$\ell_{\infty}$-dist nets as basic building blocks, we consistently achieve
state-of-the-art performance on commonly used datasets: 93.09% certified
accuracy on MNIST ($\epsilon&#x3D;0.3$), 35.42% on CIFAR-10 ($\epsilon&#x3D;8/255$) and
16.31% on TinyImageNet ($\epsilon&#x3D;1/255$).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Profiling for Adversarial Training: On the Ruin of Problematic Data. (arXiv:2102.07437v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Chengyu Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1">Jingbo Shang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07437">
                                    <div class="article-summary-box-inner">
                                        <span>There are multiple intriguing problems hovering in adversarial training,
including robustness-accuracy trade-off, robust overfitting, and robustness
overestimation. These problems pose great challenges to both reliable
evaluation and practical deployment. Here, we show that these problems share
one common cause -- low quality samples in the dataset. We first identify an
intrinsic property of the data called \emph{problematic score} and then design
controlled experiments to investigate its connections with these problems.
Specifically, we find that when problematic data is removed, robust overfitting
and robustness overestimation can be largely alleviated; and
robustness-accuracy trade-off becomes less significant. These observations not
only verify our intuition about data quality but also open new opportunities to
advance adversarial training. Interestingly, simply removing problematic data
from adversarial training, while making the training set smaller, yields better
robustness for leading adversarial training strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SparseBERT: Rethinking the Importance Analysis in Self-attention. (arXiv:2102.12871v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Han Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiahui Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiaozhe Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1">James T. Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12871">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based models are popularly used in natural language processing
(NLP). Its core component, self-attention, has aroused widespread interest. To
understand the self-attention mechanism, a direct method is to visualize the
attention map of a pre-trained model. Based on the patterns observed, a series
of efficient Transformers with different sparse attention masks have been
proposed. From a theoretical perspective, universal approximability of
Transformer-based models is also recently proved. However, the above
understanding and analysis of self-attention is based on a pre-trained model.
To rethink the importance analysis in self-attention, we study the significance
of different positions in attention matrix during pre-training. A surprising
result is that diagonal elements in the attention map are the least important
compared with other attention positions. We provide a proof showing that these
diagonal elements can indeed be removed without deteriorating model
performance. Furthermore, we propose a Differentiable Attention Mask (DAM)
algorithm, which further guides the design of the SparseBERT. Extensive
experiments verify our interesting findings and illustrate the effect of the
proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demystifying Assumptions in Learning to Discover Novel Classes. (arXiv:2102.04002v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1">Haoang Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenjing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1">Long Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04002">
                                    <div class="article-summary-box-inner">
                                        <span>In learning to discover novel classes (L2DNC), we are given labeled data from
seen classes and unlabeled data from unseen classes, and we train clustering
models for the unseen classes. However, the rigorous definition of L2DNC is
unexplored, which results in that its implicit assumptions are still unclear.
In this paper, we demystify assumptions behind L2DNC and find that high-level
semantic features should be shared among the seen and unseen classes. This
naturally motivates us to link L2DNC to meta-learning that has exactly the same
assumption as L2DNC. Based on this finding, L2DNC is not only theoretically
solvable, but can also be empirically solved by meta-learning algorithms after
slight modifications. This L2DNC methodology significantly reduces the amount
of unlabeled data needed for training and makes it more practical, as
demonstrated in experiments. The use of very limited data is also justified by
the application scenario of L2DNC: since it is unnatural to label only
seen-class data, L2DNC is sampling instead of labeling in causality. Therefore,
unseen-class data should be collected on the way of collecting seen-class data,
which is why they are novel and first need to be clustered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MagNet: A Neural Network for Directed Graphs. (arXiv:2102.11391v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xitong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yixuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Brugnone_N/0/1/0/all/0/1">Nathan Brugnone</a>, <a href="http://arxiv.org/find/cs/1/au:+Perlmutter_M/0/1/0/all/0/1">Michael Perlmutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirn_M/0/1/0/all/0/1">Matthew Hirn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11391">
                                    <div class="article-summary-box-inner">
                                        <span>The prevalence of graph-based data has spurred the rapid development of graph
neural networks (GNNs) and related machine learning algorithms. Yet, despite
the many datasets naturally modeled as directed graphs, including citation,
website, and traffic networks, the vast majority of this research focuses on
undirected graphs. In this paper, we propose MagNet, a spectral GNN for
directed graphs based on a complex Hermitian matrix known as the magnetic
Laplacian. This matrix encodes undirected geometric structure in the magnitude
of its entries and directional information in their phase. A &quot;charge&quot; parameter
attunes spectral information to variation among directed cycles. We apply our
network to a variety of directed graph node classification and link prediction
tasks showing that MagNet performs well on all tasks and that its performance
exceeds all other methods on a majority of such tasks. The underlying
principles of MagNet are such that it can be adapted to other spectral GNN
architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variance Reduced Training with Stratified Sampling for Forecasting Models. (arXiv:2103.02062v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yucheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1">Youngsuk Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lifan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">Dean Foster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02062">
                                    <div class="article-summary-box-inner">
                                        <span>In large-scale time series forecasting, one often encounters the situation
where the temporal patterns of time series, while drifting over time, differ
from one another in the same dataset. In this paper, we provably show under
such heterogeneity, training a forecasting model with commonly used stochastic
optimizers (e.g. SGD) potentially suffers large variance on gradient
estimation, and thus incurs long-time training. We show that this issue can be
efficiently alleviated via stratification, which allows the optimizer to sample
from pre-grouped time series strata. For better trading-off gradient variance
and computation complexity, we further propose SCott (Stochastic Stratified
Control Variate Gradient Descent), a variance reduced SGD-style optimizer that
utilizes stratified sampling via control variate. In theory, we provide the
convergence guarantee of SCott on smooth non-convex objectives. Empirically, we
evaluate SCott and other baseline optimizers on both synthetic and real-world
time series forecasting problems, and demonstrate SCott converges faster with
respect to both iterations and wall clock time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Asymptotics for Sequential Experiments. (arXiv:2101.09855v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wager_S/0/1/0/all/0/1">Stefan Wager</a>, <a href="http://arxiv.org/find/math/1/au:+Xu_K/0/1/0/all/0/1">Kuang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09855">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new diffusion-asymptotic analysis for sequentially randomized
experiments, including those that arise in solving multi-armed bandit problems.
In an experiment with $ n $ time steps, we let the mean reward gaps between
actions scale to the order $1/\sqrt{n}$ so as to preserve the difficulty of the
learning task as $n$ grows. In this regime, we show that the behavior of a
class of sequentially randomized Markov experiments converges to a diffusion
limit, given as the solution of a stochastic differential equation. The
diffusion limit thus enables us to derive refined, instance-specific
characterization of the stochastic dynamics of adaptive experiments. As an
application of this framework, we use the diffusion limit to obtain several new
insights on the regret and belief evolution of Thompson sampling. We show that
a version of Thompson sampling with an asymptotically uninformative prior
variance achieves nearly-optimal instance-specific regret scaling when the
reward gaps are relatively large. We also demonstrate that, in this regime, the
posterior beliefs underlying Thompson sampling are highly unstable over time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting to Misspecification in Contextual Bandits with Offline Regression Oracles. (arXiv:2102.13240v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1">Sanath Kumar Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadad_V/0/1/0/all/0/1">Vitor Hadad</a>, <a href="http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1">Susan Athey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13240">
                                    <div class="article-summary-box-inner">
                                        <span>Computationally efficient contextual bandits are often based on estimating a
predictive model of rewards given contexts and arms using past data. However,
when the reward model is not well-specified, the bandit algorithm may incur
unexpected regret, so recent work has focused on algorithms that are robust to
misspecification. We propose a simple family of contextual bandit algorithms
that adapt to misspecification error by reverting to a good safe policy when
there is evidence that misspecification is causing a regret increase. Our
algorithm requires only an offline regression oracle to ensure regret
guarantees that gracefully degrade in terms of a measure of the average
misspecification level. Compared to prior work, we attain similar regret
guarantees, but we do no rely on a master algorithm, and do not require more
robust oracles like online or constrained regression oracles (e.g., Foster et
al. (2020a); Krishnamurthy et al. (2020)). This allows us to design algorithms
for more general function approximation classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design. (arXiv:2103.02438v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Foster_A/0/1/0/all/0/1">Adam Foster</a>, <a href="http://arxiv.org/find/stat/1/au:+Ivanova_D/0/1/0/all/0/1">Desi R. Ivanova</a>, <a href="http://arxiv.org/find/stat/1/au:+Malik_I/0/1/0/all/0/1">Ilyas Malik</a>, <a href="http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02438">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Deep Adaptive Design (DAD), a method for amortizing the cost of
adaptive Bayesian experimental design that allows experiments to be run in
real-time. Traditional sequential Bayesian optimal experimental design
approaches require substantial computation at each stage of the experiment.
This makes them unsuitable for most real-world applications, where decisions
must typically be made quickly. DAD addresses this restriction by learning an
amortized design network upfront and then using this to rapidly run (multiple)
adaptive experiments at deployment time. This network represents a design
policy which takes as input the data from previous steps, and outputs the next
design using a single forward pass; these design decisions can be made in
milliseconds during the live experiment. To train the network, we introduce
contrastive information bounds that are suitable objectives for the sequential
setting, and propose a customized network architecture that exploits key
symmetries. We demonstrate that DAD successfully amortizes the process of
experimental design, outperforming alternative strategies on a number of
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Competitions and Online Learning with Strategic Forecasters. (arXiv:2102.08358v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frongillo_R/0/1/0/all/0/1">Rafael Frongillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_R/0/1/0/all/0/1">Robert Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Thilagar_A/0/1/0/all/0/1">Anish Thilagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Waggoner_B/0/1/0/all/0/1">Bo Waggoner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08358">
                                    <div class="article-summary-box-inner">
                                        <span>Winner-take-all competitions in forecasting and machine-learning suffer from
distorted incentives. Witkowski et al. 2018 identified this problem and
proposed ELF, a truthful mechanism to select a winner. We show that, from a
pool of $n$ forecasters, ELF requires $\Theta(n\log n)$ events or test data
points to select a near-optimal forecaster with high probability. We then show
that standard online learning algorithms select an $\epsilon$-optimal
forecaster using only $O(\log(n) / \epsilon^2)$ events, by way of a strong
approximate-truthfulness guarantee. This bound matches the best possible even
in the nonstrategic setting. We then apply these mechanisms to obtain the first
no-regret guarantee for non-myopic strategic experts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lower-Bounded Proper Losses for Weakly Supervised Classification. (arXiv:2103.02893v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yoshida_S/0/1/0/all/0/1">Shuhei M. Yoshida</a>, <a href="http://arxiv.org/find/stat/1/au:+Takenouchi_T/0/1/0/all/0/1">Takashi Takenouchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02893">
                                    <div class="article-summary-box-inner">
                                        <span>This paper discusses the problem of weakly supervised classification, in
which instances are given weak labels that are produced by some
label-corruption process. The goal is to derive conditions under which loss
functions for weak-label learning are proper and lower-bounded -- two essential
requirements for the losses used in class-probability estimation. To this end,
we derive a representation theorem for proper losses in supervised learning,
which dualizes the Savage representation. We use this theorem to characterize
proper weak-label losses and find a condition for them to be lower-bounded.
From these theoretical findings, we derive a novel regularization scheme called
generalized logit squeezing, which makes any proper weak-label loss bounded
from below, without losing properness. Furthermore, we experimentally
demonstrate the effectiveness of our proposed approach, as compared to improper
or unbounded losses. The results highlight the importance of properness and
lower-boundedness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards an efficient approach for the nonconvex $\ell_p$ ball projection: algorithm and analysis. (arXiv:2101.01350v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Yang_X/0/1/0/all/0/1">Xiangyu Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_J/0/1/0/all/0/1">Jiashan Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01350">
                                    <div class="article-summary-box-inner">
                                        <span>This paper primarily focuses on computing the Euclidean projection of a
vector onto the $\ell_{p}$ ball in which $p\in(0,1)$. Such a problem emerges as
the core building block in statistical machine learning and signal processing
tasks because of its ability to promote sparsity. However, efficient numerical
algorithms for finding the projections are still not available, particularly in
large-scale optimization. To meet this challenge, we first derive the
first-order necessary optimality conditions of this problem using Fr\&#x27;echet
normal cone. Based on this characterization, we develop a novel numerical
approach for computing the stationary point through solving a sequence of
projections onto the reweighted $\ell_{1}$-balls. This method is practically
simple to implement and computationally efficient. Moreover, the proposed
algorithm is shown to converge uniquely under mild conditions and has a
worst-case $O(1/\sqrt{k})$ convergence rate. Numerical experiments demonstrate
the efficiency of our proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Anytime Prediction with Parallel Cascaded Networks and a Temporal-Difference Loss. (arXiv:2102.09808v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iuzzolino_M/0/1/0/all/0/1">Michael L. Iuzzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1">Michael C. Mozer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1">Samy Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09808">
                                    <div class="article-summary-box-inner">
                                        <span>Although deep feedforward neural networks share some characteristics with the
primate visual system, a key distinction is their dynamics. Deep nets typically
operate in serial stages wherein each layer completes its computation before
processing begins in subsequent layers. In contrast, biological systems have
cascaded dynamics: information propagates from neurons at all layers in
parallel but transmission occurs gradually over time, leading to speed-accuracy
trade offs even in feedforward architectures. We explore the consequences of
biologically inspired parallel hardware by constructing cascaded ResNets in
which each residual block has propagation delays but all blocks update in
parallel in a stateful manner. Because information transmitted through skip
connections avoids delays, the functional depth of the architecture increases
over time, yielding anytime predictions that improve with internal-processing
time. We introduce a temporal-difference training loss that achieves a strictly
superior speed-accuracy profile over standard losses and enables the cascaded
architecture to outperform state-of-the-art anytime-prediction methods. The
cascaded architecture has intriguing properties, including: it classifies
typical instances more rapidly than atypical instances; it is more robust to
both persistent and transient noise than is a conventional ResNet; and its
time-varying output trace provides a signal that can be exploited to improve
information processing and inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSPM: A Modularized and Scalable Multi-Agent Reinforcement Learning-based System for Financial Portfolio Management. (arXiv:2102.03502v3 [q-fin.PM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Huang_Z/0/1/0/all/0/1">Zhenhan Huang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Tanaka_F/0/1/0/all/0/1">Fumihide Tanaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03502">
                                    <div class="article-summary-box-inner">
                                        <span>Financial portfolio management is one of the most applicable problems in
reinforcement learning (RL) owing to its sequential decision-making nature.
Existing RL-based approaches, while inspiring, often lack scalability,
reusability, or profundity of intake information to accommodate the
ever-changing capital markets. In this paper, we propose MSPM, a modularized
and scalable, multi-agent RL-based system for financial portfolio management.
MSPM involves two asynchronously updated units: an Evolving Agent Module (EAM)
and Strategic Agent Module (SAM). A self-sustained EAM produces
signal-comprised information for a specific asset using heterogeneous data
inputs, and each EAM employs its reusability to have connections to multiple
SAMs. An SAM is responsible for asset reallocation in a portfolio using
profound information from the connected EAMs. With the elaborate architecture
and the multi-step condensation of volatile market information, MSPM aims to
provide a customizable, stable, and dedicated solution to portfolio management,
unlike existing approaches. We also tackle the data-shortage issue of
newly-listed stocks by transfer learning, and validate the indispensability of
EAM with four different portfolios. Experiments on 8-year U.S. stock market
data prove the effectiveness of MSPM in profit accumulation, by its
outperformance over existing benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UnNatural Language Inference. (arXiv:2101.00010v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1">Koustuv Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1">Prasanna Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1">Adina Williams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00010">
                                    <div class="article-summary-box-inner">
                                        <span>Recent investigations into the inner-workings of state-of-the-art large-scale
pre-trained Transformer-based Natural Language Understanding (NLU) models
indicate that they appear to know humanlike syntax, at least to some extent. We
provide novel evidence that complicates this claim: we find that
state-of-the-art Natural Language Inference (NLI) models assign the same labels
to permuted examples as they do to the original, i.e. they are largely
invariant to random word-order permutations. This behavior notably differs from
that of humans; we struggle with ungrammatical sentences. To measure the
severity of this issue, we propose a suite of metrics and investigate which
properties of particular permutations lead models to be word-order invariant.
In the MNLI dataset, for example, we find almost all (98.7%) examples contain
at least one permutation which elicits the gold label. Models are sometimes
even able to assign gold labels to permutations that they originally failed to
predict correctly. We provide a comprehensive empirical evaluation of this
phenomenon, and further show that this issue exists for both Transformers and
pre-Transformer RNN / ConvNet based encoders, as well as across multiple
languages (English and Mandarin Chinese). Our code and data are available at
https://github.com/facebookresearch/unlu.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Public Data for Practical Private Query Release. (arXiv:2102.08598v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Terrance Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vietri_G/0/1/0/all/0/1">Giuseppe Vietri</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1">Jonathan Ullman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08598">
                                    <div class="article-summary-box-inner">
                                        <span>In many statistical problems, incorporating priors can significantly improve
performance. However, the use of prior knowledge in differentially private
query release has remained underexplored, despite such priors commonly being
available in the form of public datasets, such as previous US Census releases.
With the goal of releasing statistics about a private dataset, we present
PMW^Pub, which -- unlike existing baselines -- leverages public data drawn from
a related distribution as prior information. We provide a theoretical analysis
and an empirical evaluation on the American Community Survey (ACS) and ADULT
datasets, which shows that our method outperforms state-of-the-art methods.
Furthermore, PMW^Pub scales well to high-dimensional data domains, where
running many existing methods would be computationally infeasible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Task Reinforcement Learning with Context-based Representations. (arXiv:2102.06177v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1">Shagun Sodhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Amy Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06177">
                                    <div class="article-summary-box-inner">
                                        <span>The benefit of multi-task learning over single-task learning relies on the
ability to use relations across tasks to improve performance on any single
task. While sharing representations is an important mechanism to share
information across tasks, its success depends on how well the structure
underlying the tasks is captured. In some real-world situations, we have access
to metadata, or additional information about a task, that may not provide any
new insight in the context of a single task setup alone but inform relations
across multiple tasks. While this metadata can be useful for improving
multi-task learning performance, effectively incorporating it can be an
additional challenge. We posit that an efficient approach to knowledge transfer
is through the use of multiple context-dependent, composable representations
shared across a family of tasks. In this framework, metadata can help to learn
interpretable representations and provide the context to inform which
representations to compose and how to compose them. We use the proposed
approach to obtain state-of-the-art results in Meta-World, a challenging
multi-task benchmark consisting of 50 distinct robotic manipulation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-Sample Analysis of Off-Policy Natural Actor-Critic Algorithm. (arXiv:2102.09318v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1">Sajad Khodadadian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zaiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguluri_S/0/1/0/all/0/1">Siva Theja Maguluri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09318">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we provide finite-sample convergence guarantees for an
off-policy variant of the natural actor-critic (NAC) algorithm based on
Importance Sampling. In particular, we show that the algorithm converges to a
global optimal policy with a sample complexity of
$\mathcal{O}(\epsilon^{-3}\log^2(1/\epsilon))$ under an appropriate choice of
stepsizes. In order to overcome the issue of large variance due to Importance
Sampling, we propose the $Q$-trace algorithm for the critic, which is inspired
by the V-trace algorithm \cite{espeholt2018impala}. This enables us to
explicitly control the bias and variance, and characterize the trade-off
between them. As an advantage of off-policy sampling, a major feature of our
result is that we do not need any additional assumptions, beyond the ergodicity
of the Markov chain induced by the behavior policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Catastrophic Fisher Explosion: Early Phase Fisher Matrix Impacts Generalization. (arXiv:2012.14193v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jastrzebski_S/0/1/0/all/0/1">Stanislaw Jastrzebski</a>, <a href="http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1">Devansh Arpit</a>, <a href="http://arxiv.org/find/cs/1/au:+Astrand_O/0/1/0/all/0/1">Oliver Astrand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerg_G/0/1/0/all/0/1">Giancarlo Kerg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1">Richard Socher</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1">Krzysztof Geras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14193">
                                    <div class="article-summary-box-inner">
                                        <span>The early phase of training a deep neural network has a dramatic effect on
the local curvature of the loss function. For instance, using a small learning
rate does not guarantee stable optimization because the optimization trajectory
has a tendency to steer towards regions of the loss surface with increasing
local curvature. We ask whether this tendency is connected to the widely
observed phenomenon that the choice of the learning rate strongly influences
generalization. We first show that stochastic gradient descent (SGD) implicitly
penalizes the trace of the Fisher Information Matrix (FIM), a measure of the
local curvature, from the start of training. We argue it is an implicit
regularizer in SGD by showing that explicitly penalizing the trace of the FIM
can significantly improve generalization. We highlight that poor final
generalization coincides with the trace of the FIM attaining a large value
early in training, to which we refer as catastrophic Fisher explosion. Finally,
to gain insight into the regularization effect of penalizing the trace of the
FIM, we show that it limits memorization by reducing the learning speed of
examples with noisy labels more than that of the examples with clean labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Particle Dual Averaging: Optimization of Mean Field Neural Networks with Global Convergence Rate Analysis. (arXiv:2012.15477v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1">Atsushi Nitanda</a>, <a href="http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1">Denny Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1">Taiji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15477">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the particle dual averaging (PDA) method, which generalizes the
dual averaging method in convex optimization to the optimization over
probability distributions with quantitative runtime guarantee. The algorithm
consists of an inner loop and outer loop: the inner loop utilizes the Langevin
algorithm to approximately solve for a stationary distribution, which is then
optimized in the outer loop. The method can thus be interpreted as an extension
of the Langevin algorithm to naturally handle nonlinear functional on the
probability space. An important application of the proposed method is the
optimization of neural network in the mean field regime, which is theoretically
attractive due to the presence of nonlinear feature learning, but quantitative
convergence rate can be challenging to obtain. By adapting finite-dimensional
convex optimization theory into the space of distributions, we analyze PDA in
regularized empirical / expected risk minimization, and establish quantitative
global convergence in learning two-layer mean field neural networks under more
general settings. Our theoretical results are supported by numerical
simulations on neural networks with reasonable size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Divergence Regulated Encoder Network for Joint Dimensionality Reduction and Classification. (arXiv:2012.15764v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peeples_J/0/1/0/all/0/1">Joshua Peeples</a>, <a href="http://arxiv.org/find/cs/1/au:+Walker_S/0/1/0/all/0/1">Sarah Walker</a>, <a href="http://arxiv.org/find/cs/1/au:+McCurley_C/0/1/0/all/0/1">Connor McCurley</a>, <a href="http://arxiv.org/find/cs/1/au:+Zare_A/0/1/0/all/0/1">Alina Zare</a>, <a href="http://arxiv.org/find/cs/1/au:+Keller_J/0/1/0/all/0/1">James Keller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15764">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate performing joint dimensionality reduction and
classification using a novel histogram neural network. Motivated by a popular
dimensionality reduction approach, t-Distributed Stochastic Neighbor Embedding
(t-SNE), our proposed method incorporates a classification loss computed on
samples in a low-dimensional embedding space. We compare the learned sample
embeddings against coordinates found by t-SNE in terms of classification
accuracy and qualitative assessment. We also explore use of various divergence
measures in the t-SNE objective. The proposed method has several advantages
such as readily embedding out-of-sample points and reducing feature
dimensionality while retaining class discriminability. Our results show that
the proposed approach maintains and/or improves classification performance and
reveals characteristics of features produced by neural networks that may be
helpful for other applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scene-Agnostic Multi-Microphone Speech Dereverberation. (arXiv:2010.11875v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yemini_Y/0/1/0/all/0/1">Yochai Yemini</a>, <a href="http://arxiv.org/find/eess/1/au:+Fetaya_E/0/1/0/all/0/1">Ethan Fetaya</a>, <a href="http://arxiv.org/find/eess/1/au:+Maron_H/0/1/0/all/0/1">Haggai Maron</a>, <a href="http://arxiv.org/find/eess/1/au:+Gannot_S/0/1/0/all/0/1">Sharon Gannot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11875">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks (NNs) have been widely applied in speech processing tasks,
and, in particular, those employing microphone arrays. Nevertheless, most
existing NN architectures can only deal with fixed and position-specific
microphone arrays. In this paper, we present an NN architecture that can cope
with microphone arrays whose number and positions of the microphones are
unknown, and demonstrate its applicability in the speech dereverberation task.
To this end, our approach harnesses recent advances in deep learning on
set-structured data to design an architecture that enhances the reverberant
log-spectrum. We use noisy and noiseless versions of a simulated reverberant
dataset to test the proposed architecture. Our experiments on the noisy data
show that the proposed scene-agnostic setup outperforms a powerful scene-aware
framework, sometimes even with fewer microphones. With the noiseless dataset we
show that, in most cases, our method outperforms the position-aware network as
well as the state-of-the-art weighted linear prediction error (WPE) algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonparametric Learning of Two-Layer ReLU Residual Units. (arXiv:2008.07648v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhunxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Linyun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1">Chunchuan Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Shay B. Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.07648">
                                    <div class="article-summary-box-inner">
                                        <span>We describe an algorithm that learns two-layer residual units with rectified
linear unit (ReLU) activation: suppose the input $\mathbf{x}$ is from a
distribution with support space $\mathbb{R}^d$ and the ground-truth generative
model is such a residual unit, given by \[\mathbf{y}&#x3D;
\boldsymbol{B}^\ast\left[\left(\boldsymbol{A}^\ast\mathbf{x}\right)^+ +
\mathbf{x}\right]\text{,}\] where ground-truth network parameters
$\boldsymbol{A}^\ast \in \mathbb{R}^{d\times d}$ is a nonnegative full-rank
matrix and $\boldsymbol{B}^\ast \in \mathbb{R}^{m\times d}$ is full-rank with
$m \geq d$ and for $\mathbf{c} \in \mathbb{R}^d$, $[\mathbf{c}^{+}]_i &#x3D;
\max\{0, c_i\}$. We design layer-wise objectives as functionals whose analytic
minimizers express the exact ground-truth network in terms of its parameters
and nonlinearities. Following this objective landscape, learning residual units
from finite samples can be formulated using convex optimization of a
nonparametric function: for each layer, we first formulate the corresponding
empirical risk minimization (ERM) as a positive semi-definite quadratic program
(QP), then we show the solution space of the QP can be equivalently determined
by a set of linear inequalities, which can then be efficiently solved by linear
programming (LP). We further prove the statistical strong consistency of our
algorithm, and demonstrate the robustness and sample efficiency of our
algorithm by experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple and Efficient Hard Label Black-box Adversarial Attacks in Low Query Budget Regimes. (arXiv:2007.07210v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1">Satya Narayan Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1">Anit Kumar Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Willmott_D/0/1/0/all/0/1">Devin Willmott</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07210">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on the problem of black-box adversarial attacks, where the aim is to
generate adversarial examples for deep learning models solely based on
information limited to output label~(hard label) to a queried data input. We
propose a simple and efficient Bayesian Optimization~(BO) based approach for
developing black-box adversarial attacks. Issues with BO&#x27;s performance in high
dimensions are avoided by searching for adversarial examples in a structured
low-dimensional subspace. We demonstrate the efficacy of our proposed attack
method by evaluating both $\ell_\infty$ and $\ell_2$ norm constrained
untargeted and targeted hard label black-box attacks on three standard datasets
- MNIST, CIFAR-10 and ImageNet. Our proposed approach consistently achieves 2x
to 10x higher attack success rate while requiring 10x to 20x fewer queries
compared to the current state-of-the-art black-box adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Soft Actor-Critic: Off-Policy Reinforcement Learning for Addressing Value Estimation Errors. (arXiv:2001.02811v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jingliang Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1">Yang Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shengbo Eben Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yangang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_B/0/1/0/all/0/1">Bo Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.02811">
                                    <div class="article-summary-box-inner">
                                        <span>In reinforcement learning (RL), function approximation errors are known to
easily lead to the Q-value overestimations, thus greatly reducing policy
performance. This paper presents a distributional soft actor-critic (DSAC)
algorithm, which is an off-policy RL method for continuous control setting, to
improve the policy performance by mitigating Q-value overestimations. We first
discover in theory that learning a distribution function of state-action
returns can effectively mitigate Q-value overestimations because it is capable
of adaptively adjusting the update stepsize of the Q-value function. Then, a
distributional soft policy iteration (DSPI) framework is developed by embedding
the return distribution function into maximum entropy RL. Finally, we present a
deep off-policy actor-critic variant of DSPI, called DSAC, which directly
learns a continuous return distribution by keeping the variance of the
state-action returns within a reasonable range to address exploding and
vanishing gradient problems. We evaluate DSAC on the suite of MuJoCo continuous
control tasks, achieving the state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can we have it all? On the Trade-off between Spatial and Adversarial Robustness of Neural Networks. (arXiv:2002.11318v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1">Sandesh Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Amit Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Subrahmanyam_K/0/1/0/all/0/1">K V Subrahmanyam</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.11318">
                                    <div class="article-summary-box-inner">
                                        <span>(Non-)robustness of neural networks to small, adversarial pixel-wise
perturbations, and as more recently shown, to even random spatial
transformations (e.g., translations, rotations) entreats both theoretical and
empirical understanding. Spatial robustness to random translations and
rotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)
and training augmentation, whereas adversarial robustness is typically achieved
by adversarial training. In this paper, we prove a quantitative trade-off
between spatial and adversarial robustness in a simple statistical setting. We
complement this empirically by showing that: (a) as the spatial robustness of
equivariant models improves by training augmentation with progressively larger
transformations, their adversarial robustness worsens progressively, and (b) as
the state-of-the-art robust models are adversarially trained with progressively
larger pixel-wise perturbations, their spatial robustness drops progressively.
Towards achieving pareto-optimality in this trade-off, we propose a method
based on curriculum learning that trains gradually on more difficult
perturbations (both spatial and adversarial) to improve spatial and adversarial
robustness simultaneously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inference of Causal Effects when Control Variables are Unknown. (arXiv:2012.08154v3 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hult_L/0/1/0/all/0/1">Ludvig Hult</a>, <a href="http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1">Dave Zachariah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08154">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional methods in causal effect inferencetypically rely on specifying a
valid set of control variables. When this set is unknown or misspecified,
inferences will be erroneous. We propose a method for inferring average causal
effects when all potential confounders are observed, but thecontrol variables
are unknown. When the data-generating process belongs to the class of acyclical
linear structural causal models, we prove that themethod yields asymptotically
valid confidence intervals. Our results build upon a smooth characterization of
linear directed acyclic graphs. We verify the capability of the method to
produce valid confidence intervals for average causal effects using synthetic
data, even when the appropriate specification of control variables is unknown.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hutch++: Optimal Stochastic Trace Estimation. (arXiv:2010.09649v5 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meyer_R/0/1/0/all/0/1">Raphael A. Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Christopher Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09649">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of estimating the trace of a matrix $A$ that can only be
accessed through matrix-vector multiplication. We introduce a new randomized
algorithm, Hutch++, which computes a $(1 \pm \epsilon)$ approximation to
$tr(A)$ for any positive semidefinite (PSD) $A$ using just $O(1/\epsilon)$
matrix-vector products. This improves on the ubiquitous Hutchinson&#x27;s estimator,
which requires $O(1/\epsilon^2)$ matrix-vector products. Our approach is based
on a simple technique for reducing the variance of Hutchinson&#x27;s estimator using
a low-rank approximation step, and is easy to implement and analyze. Moreover,
we prove that, up to a logarithmic factor, the complexity of Hutch++ is optimal
amongst all matrix-vector query algorithms, even when queries can be chosen
adaptively. We show that it significantly outperforms Hutchinson&#x27;s method in
experiments. While our theory mainly requires $A$ to be positive semidefinite,
we provide generalized guarantees for general square matrices, and show
empirical gains in such applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Network Approximation for Smooth Functions. (arXiv:2001.03040v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jianfeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zuowei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03040">
                                    <div class="article-summary-box-inner">
                                        <span>This paper establishes optimal approximation error characterization of deep
ReLU networks for smooth functions in terms of both width and depth
simultaneously. To that end, we first prove that multivariate polynomials can
be approximated by deep ReLU networks of width $\mathcal{O}(N)$ and depth
$\mathcal{O}(L)$ with an approximation error $\mathcal{O}(N^{-L})$. Through
local Taylor expansions and their deep ReLU network approximations, we show
that deep ReLU networks of width $\mathcal{O}(N\ln N)$ and depth
$\mathcal{O}(L\ln L)$ can approximate $f\in C^s([0,1]^d)$ with a nearly optimal
approximation rate $\mathcal{O}(\|f\|_{C^s([0,1]^d)}N^{-2s/d}L^{-2s/d})$. Our
estimate is non-asymptotic in the sense that it is valid for arbitrary width
and depth specified by $N\in\mathbb{N}^+$ and $L\in\mathbb{N}^+$, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Value Alignment Verification. (arXiv:2012.01557v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1">Daniel S. Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jordan Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca D. Dragan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01557">
                                    <div class="article-summary-box-inner">
                                        <span>As humans interact with autonomous agents to perform increasingly
complicated, potentially risky tasks, it is important to be able to efficiently
evaluate an agent&#x27;s performance and correctness. In this paper we formalize and
theoretically analyze the problem of efficient value alignment verification:
how to efficiently test whether the behavior of another agent is aligned with a
human&#x27;s values. The goal is to construct a kind of &quot;driver&#x27;s test&quot; that a human
can give to any agent which will verify value alignment via a minimal number of
queries. We study alignment verification problems with both idealized humans
that have an explicit reward function as well as problems where they have
implicit values. We analyze verification of exact value alignment for rational
agents and propose and analyze heuristic and approximate value alignment
verification tests in a wide range of gridworlds and a continuous autonomous
driving domain. Finally, we prove that there exist sufficient conditions such
that we can verify exact and approximate alignment across an infinite set of
test environments via a constant-query-complexity alignment test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Knowledge Distillation Ensemble Framework for Predicting Short and Long-term Hospitalisation Outcomes from Electronic Health Records Data. (arXiv:2011.09361v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ibrahim_Z/0/1/0/all/0/1">Zina M Ibrahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bean_D/0/1/0/all/0/1">Daniel Bean</a>, <a href="http://arxiv.org/find/cs/1/au:+Searle_T/0/1/0/all/0/1">Thomas Searle</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Honghan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shek_A/0/1/0/all/0/1">Anthony Shek</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraljevic_Z/0/1/0/all/0/1">Zeljko Kraljevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Galloway_J/0/1/0/all/0/1">James Galloway</a>, <a href="http://arxiv.org/find/cs/1/au:+Norton_S/0/1/0/all/0/1">Sam Norton</a>, <a href="http://arxiv.org/find/cs/1/au:+Teo_J/0/1/0/all/0/1">James T Teo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1">Richard JB Dobson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09361">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to perform accurate prognosis of patients is crucial for
proactive clinical decision making, informed resource management and
personalised care. Existing outcome prediction models suffer from a low recall
of infrequent positive outcomes. We present a highly-scalable and robust
machine learning framework to automatically predict adversity represented by
mortality and ICU admission from time-series vital signs and laboratory results
obtained within the first 24 hours of hospital admission. The stacked platform
comprises two components: a) an unsupervised LSTM Autoencoder that learns an
optimal representation of the time-series, using it to differentiate the less
frequent patterns which conclude with an adverse event from the majority
patterns that do not, and b) a gradient boosting model, which relies on the
constructed representation to refine prediction, incorporating static features
of demographics, admission details and clinical summaries. The model is used to
assess a patient&#x27;s risk of adversity over time and provides visual
justifications of its prediction based on the patient&#x27;s static features and
dynamic signals. Results of three case studies for predicting mortality and ICU
admission show that the model outperforms all existing outcome prediction
models, achieving PR-AUC of 0.891 (95$%$ CI: 0.878 - 0.969) in predicting
mortality in ICU and general ward settings and 0.908 (95$%$ CI: 0.870-0.935) in
predicting ICU admission.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Possibility results for graph clustering: A novel consistency axiom. (arXiv:1806.06142v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strazzeri_F/0/1/0/all/0/1">Fabio Strazzeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_Garcia_R/0/1/0/all/0/1">Rub&#xe9;n J. S&#xe1;nchez-Garc&#xed;a</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1806.06142">
                                    <div class="article-summary-box-inner">
                                        <span>Kleinberg introduced three natural clustering properties, or axioms, and
showed they cannot be simultaneously satisfied by any clustering algorithm. We
present a new clustering property, Monotonic Consistency, which avoids the
well-known problematic behaviour of Kleinberg&#x27;s Consistency axiom, and the
impossibility result. Namely, we describe a clustering algorithm, Morse
Clustering, inspired by Morse Theory in Differential Topology, which satisfies
Kleinberg&#x27;s original axioms with Consistency replaced by Monotonic Consistency.
Morse clustering uncovers the underlying flow structure on a set or graph and
returns a partition into trees representing basins of attraction of critical
vertices. We also generalise Kleinberg&#x27;s axiomatic approach to sparse graphs,
showing an impossibility result for Consistency, and a possibility result for
Monotonic Consistency and Morse clustering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Distribution-Dependent Analysis of Meta-Learning. (arXiv:2011.00344v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Konobeev_M/0/1/0/all/0/1">Mikhail Konobeev</a>, <a href="http://arxiv.org/find/stat/1/au:+Kuzborskij_I/0/1/0/all/0/1">Ilja Kuzborskij</a>, <a href="http://arxiv.org/find/stat/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00344">
                                    <div class="article-summary-box-inner">
                                        <span>A key problem in the theory of meta-learning is to understand how the task
distributions influence transfer risk, the expected error of a meta-learner on
a new task drawn from the unknown task distribution. In this paper, focusing on
fixed design linear regression with Gaussian noise and a Gaussian task (or
parameter) distribution, we give distribution-dependent lower bounds on the
transfer risk of any algorithm, while we also show that a novel, weighted
version of the so-called biased regularized regression method is able to match
these lower bounds up to a fixed constant factor. Notably, the weighting is
derived from the covariance of the Gaussian task distribution. Altogether, our
results provide a precise characterization of the difficulty of meta-learning
in this Gaussian setting. While this problem setting may appear simple, we show
that it is rich enough to unify the &quot;parameter sharing&quot; and &quot;representation
learning&quot; streams of meta-learning; in particular, representation learning is
obtained as the special case when the covariance matrix of the task
distribution is unknown. For this case we propose to adopt the EM method, which
is shown to enjoy efficient updates in our case. The paper is completed by an
empirical study of EM. In particular, our experimental results show that the EM
algorithm can attain the lower bound as the number of tasks grows, while the
algorithm is also successful in competing with its alternatives when used in a
representation learning context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Represent Your Own Policies: Reinforcement Learning with Policy-extended Value Function Approximator. (arXiv:2010.09536v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hongyao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1">Zhaopeng Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jianye Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Graves_D/0/1/0/all/0/1">Daniel Graves</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Hangyu Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wulong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Changmin Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09536">
                                    <div class="article-summary-box-inner">
                                        <span>We study Policy-extended Value Function Approximator (PeVFA) in Reinforcement
Learning (RL), which extends conventional value function approximator (VFA) to
take as input not only the state (and action) but also an explicit policy
representation. Such an extension enables PeVFA to preserve values of multiple
policies at the same time and brings an appealing characteristic, i.e.,
\emph{value generalization among policies}. We formally analyze the value
generalization under Generalized Policy Iteration (GPI). From theoretical and
empirical lens, we show that generalized value estimates offered by PeVFA may
have lower initial approximation error to true values of successive policies,
which is expected to improve consecutive value approximation during GPI. Based
on above clues, we introduce a new form of GPI with PeVFA which leverages the
value generalization along policy improvement path. Moreover, we propose a
representation learning framework for RL policy, providing several approaches
to learn effective policy embeddings from policy network parameters or
state-action pairs. In our experiments, we evaluate the efficacy of value
generalization offered by PeVFA and policy representation learning in several
OpenAI Gym continuous control tasks. For a representative instance of algorithm
implementation, Proximal Policy Optimization (PPO) re-implemented under the
paradigm of GPI with PeVFA achieves about 40\% performance improvement on its
vanilla counterpart in most environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">K-shot NAS: Learnable Weight-Sharing for NAS with K-shot Supernets. (arXiv:2106.06442v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1">Xiu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1">Shan You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Mingkai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1">Chen Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06442">
                                    <div class="article-summary-box-inner">
                                        <span>In one-shot weight sharing for NAS, the weights of each operation (at each
layer) are supposed to be identical for all architectures (paths) in the
supernet. However, this rules out the possibility of adjusting operation
weights to cater for different paths, which limits the reliability of the
evaluation results. In this paper, instead of counting on a single supernet, we
introduce $K$-shot supernets and take their weights for each operation as a
dictionary. The operation weight for each path is represented as a convex
combination of items in a dictionary with a simplex code. This enables a matrix
approximation of the stand-alone weight matrix with a higher rank ($K&gt;1$). A
\textit{simplex-net} is introduced to produce architecture-customized code for
each path. As a result, all paths can adaptively learn how to share weights in
the $K$-shot supernets and acquire corresponding weights for better evaluation.
$K$-shot supernets and simplex-net can be iteratively trained, and we further
extend the search to the channel dimension. Extensive experiments on benchmark
datasets validate that K-shot NAS significantly improves the evaluation
accuracy of paths and thus brings in impressive performance improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Black-box Explanation of Object Detectors via Saliency Maps. (arXiv:2006.03204v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Petsiuk_V/0/1/0/all/0/1">Vitali Petsiuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rajiv Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Manjunatha_V/0/1/0/all/0/1">Varun Manjunatha</a>, <a href="http://arxiv.org/find/cs/1/au:+Morariu_V/0/1/0/all/0/1">Vlad I. Morariu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1">Ashutosh Mehra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1">Vicente Ordonez</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03204">
                                    <div class="article-summary-box-inner">
                                        <span>We propose D-RISE, a method for generating visual explanations for the
predictions of object detectors. Utilizing the proposed similarity metric that
accounts for both localization and categorization aspects of object detection
allows our method to produce saliency maps that show image areas that most
affect the prediction. D-RISE can be considered &quot;black-box&quot; in the software
testing sense, as it only needs access to the inputs and outputs of an object
detector. Compared to gradient-based methods, D-RISE is more general and
agnostic to the particular type of object detector being tested, and does not
need knowledge of the inner workings of the model. We show that D-RISE can be
easily applied to different object detectors including one-stage detectors such
as YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed
analysis of the generated visual explanations to highlight the utilization of
context and possible biases learned by object detectors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the optimal regularizer for inverse problems. (arXiv:2106.06513v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Alberti_G/0/1/0/all/0/1">Giovanni S. Alberti</a>, <a href="http://arxiv.org/find/stat/1/au:+Vito_E/0/1/0/all/0/1">Ernesto De Vito</a>, <a href="http://arxiv.org/find/stat/1/au:+Lassas_M/0/1/0/all/0/1">Matti Lassas</a>, <a href="http://arxiv.org/find/stat/1/au:+Ratti_L/0/1/0/all/0/1">Luca Ratti</a>, <a href="http://arxiv.org/find/stat/1/au:+Santacesaria_M/0/1/0/all/0/1">Matteo Santacesaria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06513">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider the linear inverse problem $y&#x3D;Ax+\epsilon$, where
$A\colon X\to Y$ is a known linear operator between the separable Hilbert
spaces $X$ and $Y$, $x$ is a random variable in $X$ and $\epsilon$ is a
zero-mean random process in $Y$. This setting covers several inverse problems
in imaging including denoising, deblurring, and X-ray tomography. Within the
classical framework of regularization, we focus on the case where the
regularization functional is not given a priori but learned from data. Our
first result is a characterization of the optimal generalized Tikhonov
regularizer, with respect to the mean squared error. We find that it is
completely independent of the forward operator $A$ and depends only on the mean
and covariance of $x$. Then, we consider the problem of learning the
regularizer from a finite training set in two different frameworks: one
supervised, based on samples of both $x$ and $y$, and one unsupervised, based
only on samples of $x$. In both cases, we prove generalization bounds, under
some weak assumptions on the distribution of $x$ and $\epsilon$, including the
case of sub-Gaussian variables. Our bounds hold in infinite-dimensional spaces,
thereby showing that finer and finer discretizations do not make this learning
problem harder. The results are validated through numerical simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Classification Using Staked Ensembles: A Comprehensive Analysis. (arXiv:2010.05690v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+B_L/0/1/0/all/0/1">Lalith Bharadwaj B</a>, <a href="http://arxiv.org/find/cs/1/au:+Boddeda_R/0/1/0/all/0/1">Rohit Boddeda</a>, <a href="http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1">Sai Vardhan K</a>, <a href="http://arxiv.org/find/cs/1/au:+G_M/0/1/0/all/0/1">Madhu G</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05690">
                                    <div class="article-summary-box-inner">
                                        <span>The issue of COVID-19, increasing with a massive mortality rate. This led to
the WHO declaring it as a pandemic. In this situation, it is crucial to perform
efficient and fast diagnosis. The reverse transcript polymerase chain reaction
(RTPCR) test is conducted to detect the presence of SARS-CoV-2. This test is
time-consuming and instead chest CT (or Chest X-ray) can be used for a fast and
accurate diagnosis. Automated diagnosis is considered to be important as it
reduces human effort and provides accurate and low-cost tests. The
contributions of our research are three-fold. First, it is aimed to analyse the
behaviour and performance of variant vision models ranging from Inception to
NAS networks with the appropriate fine-tuning procedure. Second, the behaviour
of these models is visually analysed by plotting CAMs for individual networks
and determining classification performance with AUCROC curves. Thirdly, stacked
ensembles techniques are imparted to provide higher generalisation on combining
the fine-tuned models, in which six ensemble neural networks are designed by
combining the existing fine-tuned networks. Implying these stacked ensembles
provides a great generalization to the models. The ensemble model designed by
combining all the fine-tuned networks obtained a state-of-the-art accuracy
score of 99.17%. The precision and recall for the COVID-19 class are 99.99% and
89.79% respectively, which resembles the robustness of the stacked ensembles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Unified Quadrature Framework for Large-Scale Kernel Machines. (arXiv:2011.01668v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fanghui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yudong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1">Johan A.K. Suykens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01668">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we develop a quadrature framework for large-scale kernel
machines via a numerical integration representation. Considering that the
integration domain and measure of typical kernels, e.g., Gaussian kernels,
arc-cosine kernels, are fully symmetric, we leverage deterministic fully
symmetric interpolatory rules to efficiently compute quadrature nodes and
associated weights for kernel approximation. The developed interpolatory rules
are able to reduce the number of needed nodes while retaining a high
approximation accuracy. Further, we randomize the above deterministic rules by
the classical Monte-Carlo sampling and control variates techniques with two
merits: 1) The proposed stochastic rules make the dimension of the feature
mapping flexibly varying, such that we can control the discrepancy between the
original and approximate kernels by tuning the dimnension. 2) Our stochastic
rules have nice statistical properties of unbiasedness and variance reduction
with fast convergence rate. In addition, we elucidate the relationship between
our deterministic/stochastic interpolatory rules and current quadrature rules
for kernel approximation, including the sparse grids quadrature and stochastic
spherical-radial rules, thereby unifying these methods under our framework.
Experimental results on several benchmark datasets show that our methods
compare favorably with other representative kernel approximation based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Compositional Shape Priors for Few-Shot 3D Reconstruction. (arXiv:2106.06440v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Michalkiewicz_M/0/1/0/all/0/1">Mateusz Michalkiewicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsogkas_S/0/1/0/all/0/1">Stavros Tsogkas</a>, <a href="http://arxiv.org/find/cs/1/au:+Parisot_S/0/1/0/all/0/1">Sarah Parisot</a>, <a href="http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1">Mahsa Baktashmotlagh</a>, <a href="http://arxiv.org/find/cs/1/au:+Eriksson_A/0/1/0/all/0/1">Anders Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1">Eugene Belilovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06440">
                                    <div class="article-summary-box-inner">
                                        <span>The impressive performance of deep convolutional neural networks in
single-view 3D reconstruction suggests that these models perform non-trivial
reasoning about the 3D structure of the output space. Recent work has
challenged this belief, showing that, on standard benchmarks, complex
encoder-decoder architectures perform similarly to nearest-neighbor baselines
or simple linear decoder models that exploit large amounts of per-category
data. However, building large collections of 3D shapes for supervised training
is a laborious process; a more realistic and less constraining task is
inferring 3D shapes for categories with few available training examples,
calling for a model that can successfully generalize to novel object classes.
In this work we experimentally demonstrate that naive baselines fail in this
few-shot learning setting, in which the network must learn informative shape
priors for inference of new categories. We propose three ways to learn a
class-specific global shape prior, directly from data. Using these techniques,
we are able to capture multi-scale information about the 3D shape, and account
for intra-class variability by virtue of an implicit compositional structure.
Experiments on the popular ShapeNet dataset show that our method outperforms a
zero-shot baseline by over 40%, and the current state-of-the-art by over 10%,
in terms of relative performance, in the few-shot setting.12</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPPL: Probabilistic Programming with Fast Exact Symbolic Inference. (arXiv:2010.03485v3 [cs.PL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saad_F/0/1/0/all/0/1">Feras A. Saad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1">Martin C. Rinard</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansinghka_V/0/1/0/all/0/1">Vikash K. Mansinghka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03485">
                                    <div class="article-summary-box-inner">
                                        <span>We present the Sum-Product Probabilistic Language (SPPL), a new probabilistic
programming language that automatically delivers exact solutions to a broad
range of probabilistic inference queries. SPPL translates probabilistic
programs into sum-product expressions, a new symbolic representation and
associated semantic domain that extends standard sum-product networks to
support mixed-type distributions, numeric transformations, logical formulas,
and pointwise and set-valued constraints. We formalize SPPL via a novel
translation strategy from probabilistic programs to sum-product expressions and
give sound exact algorithms for conditioning on and computing probabilities of
events. SPPL imposes a collection of restrictions on probabilistic programs to
ensure they can be translated into sum-product expressions, which allow the
system to leverage new techniques for improving the scalability of translation
and inference by automatically exploiting probabilistic structure. We implement
a prototype of SPPL with a modular architecture and evaluate it on benchmarks
the system targets, showing that it obtains up to 3500x speedups over
state-of-the-art symbolic systems on tasks such as verifying the fairness of
decision tree classifiers, smoothing hidden Markov models, conditioning
transformed random variables, and computing rare event probabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable?. (arXiv:2010.14986v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kopetzki_A/0/1/0/all/0/1">Anna-Kathrin Kopetzki</a>, <a href="http://arxiv.org/find/cs/1/au:+Charpentier_B/0/1/0/all/0/1">Bertrand Charpentier</a>, <a href="http://arxiv.org/find/cs/1/au:+Zugner_D/0/1/0/all/0/1">Daniel Z&#xfc;gner</a>, <a href="http://arxiv.org/find/cs/1/au:+Giri_S/0/1/0/all/0/1">Sandhya Giri</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14986">
                                    <div class="article-summary-box-inner">
                                        <span>Dirichlet-based uncertainty (DBU) models are a recent and promising class of
uncertainty-aware models. DBU models predict the parameters of a Dirichlet
distribution to provide fast, high-quality uncertainty estimates alongside with
class predictions. In this work, we present the first large-scale, in-depth
study of the robustness of DBU models under adversarial attacks. Our results
suggest that uncertainty estimates of DBU models are not robust w.r.t. three
important tasks: (1) indicating correctly and wrongly classified samples; (2)
detecting adversarial examples; and (3) distinguishing between in-distribution
(ID) and out-of-distribution (OOD) data. Additionally, we explore the first
approaches to make DBU models more robust. While adversarial training has a
minor effect, our median smoothing based approach significantly increases
robustness of DBU models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training. (arXiv:2009.03294v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shengjie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Keyulu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Di He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03294">
                                    <div class="article-summary-box-inner">
                                        <span>Normalization is known to help the optimization of deep neural networks.
Curiously, different architectures require specialized normalization methods.
In this paper, we study what normalization is effective for Graph Neural
Networks (GNNs). First, we adapt and evaluate the existing methods from other
domains to GNNs. Faster convergence is achieved with InstanceNorm compared to
BatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm
serves as a preconditioner for GNNs, but such preconditioning effect is weaker
with BatchNorm due to the heavy batch noise in graph datasets. Second, we show
that the shift operation in InstanceNorm results in an expressiveness
degradation of GNNs for highly regular graphs. We address this issue by
proposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm
converge faster compared to GNNs using other normalization. GraphNorm also
improves the generalization of GNNs, achieving better performance on graph
classification benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Model Selection in Contextual Bandits with Many Classes via Offline Oracles. (arXiv:2106.06483v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_S/0/1/0/all/0/1">Sanath Kumar Krishnamurthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1">Susan Athey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06483">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of model selection for contextual bandits, in which the
algorithm must balance the bias-variance trade-off for model estimation while
also balancing the exploration-exploitation trade-off. In this paper, we
propose the first reduction of model selection in contextual bandits to offline
model selection oracles, allowing for flexible general purpose algorithms with
computational requirements no worse than those for model selection for
regression. Our main result is a new model selection guarantee for stochastic
contextual bandits. When one of the classes in our set is realizable, up to a
logarithmic dependency on the number of classes, our algorithm attains optimal
realizability-based regret bounds for that class under one of two conditions:
if the time-horizon is large enough, or if an assumption that helps with
detecting misspecification holds. Hence our algorithm adapts to the complexity
of this unknown class. Even when this realizable class is known, we prove
improved regret guarantees in early rounds by relying on simpler model classes
for those rounds and hence further establish the importance of model selection
in contextual bandits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search without Training. (arXiv:2006.04647v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mellor_J/0/1/0/all/0/1">Joseph Mellor</a>, <a href="http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1">Jack Turner</a>, <a href="http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1">Amos Storkey</a>, <a href="http://arxiv.org/find/cs/1/au:+Crowley_E/0/1/0/all/0/1">Elliot J. Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04647">
                                    <div class="article-summary-box-inner">
                                        <span>The time and effort involved in hand-designing deep neural networks is
immense. This has prompted the development of Neural Architecture Search (NAS)
techniques to automate this design. However, NAS algorithms tend to be slow and
expensive; they need to train vast numbers of candidate networks to inform the
search process. This could be alleviated if we could partially predict a
network&#x27;s trained accuracy from its initial state. In this work, we examine the
overlap of activations between datapoints in untrained networks and motivate
how this can give a measure which is usefully indicative of a network&#x27;s trained
performance. We incorporate this measure into a simple algorithm that allows us
to search for powerful networks without any training in a matter of seconds on
a single GPU, and verify its effectiveness on NAS-Bench-101, NAS-Bench-201,
NATS-Bench, and Network Design Spaces. Our approach can be readily combined
with more expensive search methods; we examine a simple adaptation of
regularised evolutionary search. Code for reproducing our experiments is
available at https://github.com/BayesWatch/nas-without-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAC-Learning for Strategic Classification. (arXiv:2012.03310v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sundaram_R/0/1/0/all/0/1">Ravi Sundaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1">Anil Vullikanti</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haifeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1">Fan Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03310">
                                    <div class="article-summary-box-inner">
                                        <span>The study of strategic or adversarial manipulation of testing data to fool a
classifier has attracted much recent attention. Most previous works have
focused on two extreme situations where any testing data point either is
completely adversarial or always equally prefers the positive label. In this
paper, we generalize both of these through a unified framework for strategic
classification, and introduce the notion of strategic VC-dimension (SVC) to
capture the PAC-learnability in our general strategic setup. SVC provably
generalizes the recent concept of adversarial VC-dimension (AVC) introduced by
Cullina et al. arXiv:1806.01471. We instantiate our framework for the
fundamental strategic linear classification problem. We fully characterize: (1)
the statistical learnability of linear classifiers by pinning down its SVC; (2)
its computational tractability by pinning down the complexity of the empirical
risk minimization problem. Interestingly, the SVC of linear classifiers is
always upper bounded by its standard VC-dimension. This characterization also
strictly generalizes the AVC bound for linear classifiers in arXiv:1806.01471.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Limitations of Large Width in Neural Networks: A Deep Gaussian Process Perspective. (arXiv:2106.06529v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06529">
                                    <div class="article-summary-box-inner">
                                        <span>Large width limits have been a recent focus of deep learning research: modulo
computational practicalities, do wider networks outperform narrower ones?
Answering this question has been challenging, as conventional networks gain
representational power with width, potentially masking any negative effects.
Our analysis in this paper decouples capacity and width via the generalization
of neural networks to Deep Gaussian Processes (Deep GP), a class of
hierarchical models that subsume neural nets. In doing so, we aim to understand
how width affects standard neural networks once they have sufficient capacity
for a given modeling task. Our theoretical and empirical results on Deep GP
suggest that large width is generally detrimental to hierarchical models.
Surprisingly, we prove that even nonparametric Deep GP converge to Gaussian
processes, effectively becoming shallower without any increase in
representational power. The posterior, which corresponds to a mixture of
data-adaptable basis functions, becomes less data-dependent with width. Our
tail analysis demonstrates that width and depth have opposite effects: depth
accentuates a model&#x27;s non-Gaussianity, while width makes models increasingly
Gaussian. We find there is a &quot;sweet spot&quot; that maximizes test set performance
before the limiting GP behavior prevents adaptability, occurring at width &#x3D; 1
or width &#x3D; 2 for nonparametric Deep GP. These results make strong predictions
about the same phenomenon in conventional neural networks: we show empirically
that many neural network architectures need 10 - 500 hidden units for
sufficient capacity - depending on the dataset - but further width degrades
test performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boussioux_L/0/1/0/all/0/1">L&#xe9;onard Boussioux</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_C/0/1/0/all/0/1">Cynthia Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guenais_T/0/1/0/all/0/1">Th&#xe9;o Gu&#xe9;nais</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1">Dimitris Bertsimas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06125">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a machine learning (ML) framework for tropical cyclone
intensity and track forecasting, combining multiple distinct ML techniques and
utilizing diverse data sources. Our framework, which we refer to as Hurricast
(HURR), is built upon the combination of distinct data processing techniques
using gradient-boosted trees and novel encoder-decoder architectures, including
CNN, GRU and Transformers components. We propose a deep-feature extractor
methodology to mix spatial-temporal data with statistical data efficiently. Our
multimodal framework unleashes the potential of making forecasts based on a
wide range of data sources, including historical storm data, and visual data
such as reanalysis atmospheric images. We evaluate our models with current
operational forecasts in North Atlantic and Eastern Pacific basins on 2016-2019
for 24-hour lead time, and show our models consistently outperform
statistical-dynamical models and compete with the best dynamical models, while
computing forecasts in seconds. Furthermore, the inclusion of Hurricast into an
operational forecast consensus model leads to a significant improvement of 5% -
15% over NHC&#x27;s official forecast, thus highlighting the complementary
properties with existing approaches. In summary, our work demonstrates that
combining different data sources and distinct machine learning methodologies
can lead to superior tropical cyclone forecasting. We hope that this work opens
the door for further use of machine learning in meteorological forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing. (arXiv:2106.06362v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kinnunen_T/0/1/0/all/0/1">Tomi Kinnunen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nautsch_A/0/1/0/all/0/1">Andreas Nautsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahidullah_M/0/1/0/all/0/1">Md Sahidullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_N/0/1/0/all/0/1">Nicholas Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Todisco_M/0/1/0/all/0/1">Massimiliano Todisco</a>, <a href="http://arxiv.org/find/cs/1/au:+Delgado_H/0/1/0/all/0/1">H&#xe9;ctor Delgado</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamagishi_J/0/1/0/all/0/1">Junichi Yamagishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kong Aik Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06362">
                                    <div class="article-summary-box-inner">
                                        <span>Whether it be for results summarization, or the analysis of classifier
fusion, some means to compare different classifiers can often provide
illuminating insight into their behaviour, (dis)similarity or complementarity.
We propose a simple method to derive 2D representation from detection scores
produced by an arbitrary set of binary classifiers in response to a common
dataset. Based upon rank correlations, our method facilitates a visual
comparison of classifiers with arbitrary scores and with close relation to
receiver operating characteristic (ROC) and detection error trade-off (DET)
analyses. While the approach is fully versatile and can be applied to any
detection task, we demonstrate the method using scores produced by automatic
speaker verification and voice anti-spoofing systems. The former are produced
by a Gaussian mixture model system trained with VoxCeleb data whereas the
latter stem from submissions to the ASVspoof 2019 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nystr\&quot;om landmark sampling and regularized Christoffel functions. (arXiv:1905.12346v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fanuel_M/0/1/0/all/0/1">Micha&#xeb;l Fanuel</a>, <a href="http://arxiv.org/find/cs/1/au:+Schreurs_J/0/1/0/all/0/1">Joachim Schreurs</a>, <a href="http://arxiv.org/find/cs/1/au:+Suykens_J/0/1/0/all/0/1">Johan A.K. Suykens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.12346">
                                    <div class="article-summary-box-inner">
                                        <span>Selecting diverse and important items, called landmarks, from a large set is
a problem of interest in machine learning. As a specific example, in order to
deal with large training sets, kernel methods often rely on low rank matrix
Nystr\&quot;om approximations based on the selection or sampling of landmarks. In
this context, we propose a deterministic and a randomized adaptive algorithm
for selecting landmark points within a training data set, which are related to
the minima of a sequence of kernelized Christoffel functions. Beyond the known
connection between Christoffel functions and leverage scores, a connection of
our method with determinantal point processes (DPPs) is also explained. Namely,
our construction promotes diversity among important landmark points in a way
similar to DPPs. Also, we explain how our randomized adaptive algorithm can
influence the accuracy of Kernel Ridge Regression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Environment Inference for Invariant Learning. (arXiv:2010.07249v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1">Elliot Creager</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobsen_J/0/1/0/all/0/1">J&#xf6;rn-Henrik Jacobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07249">
                                    <div class="article-summary-box-inner">
                                        <span>Learning models that gracefully handle distribution shifts is central to
research on domain generalization, robust optimization, and fairness. A
promising formulation is domain-invariant learning, which identifies the key
issue of learning which features are domain-specific versus domain-invariant.
An important assumption in this area is that the training examples are
partitioned into &quot;domains&quot; or &quot;environments&quot;. Our focus is on the more common
setting where such partitions are not provided. We propose EIIL, a general
framework for domain-invariant learning that incorporates Environment Inference
to directly infer partitions that are maximally informative for downstream
Invariant Learning. We show that EIIL outperforms invariant learning methods on
the CMNIST benchmark without using environment labels, and significantly
outperforms ERM on worst-group performance in the Waterbirds and CivilComments
datasets. Finally, we establish connections between EIIL and algorithmic
fairness, which enables EIIL to improve accuracy and calibration in a fair
prediction problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revealing the Structure of Deep Neural Networks via Convex Duality. (arXiv:2002.09773v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ergen_T/0/1/0/all/0/1">Tolga Ergen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilanci_M/0/1/0/all/0/1">Mert Pilanci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.09773">
                                    <div class="article-summary-box-inner">
                                        <span>We study regularized deep neural networks (DNNs) and introduce a convex
analytic framework to characterize the structure of the hidden layers. We show
that a set of optimal hidden layer weights for a norm regularized DNN training
problem can be explicitly found as the extreme points of a convex set. For the
special case of deep linear networks, we prove that each optimal weight matrix
aligns with the previous layers via duality. More importantly, we apply the
same characterization to deep ReLU networks with whitened data and prove the
same weight alignment holds. As a corollary, we also prove that norm
regularized deep ReLU networks yield spline interpolation for one-dimensional
datasets which was previously known only for two-layer networks. Furthermore,
we provide closed-form solutions for the optimal layer weights when data is
rank-one or whitened. The same analysis also applies to architectures with
batch normalization even for arbitrary data. Therefore, we obtain a complete
explanation for a recent empirical observation termed Neural Collapse where
class means collapse to the vertices of a simplex equiangular tight frame.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finding Physical Adversarial Examples for Autonomous Driving with Fast and Differentiable Image Compositing. (arXiv:2010.08844v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinghan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Boloor_A/0/1/0/all/0/1">Adith Boloor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1">Ayan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1">Yevgeniy Vorobeychik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08844">
                                    <div class="article-summary-box-inner">
                                        <span>There is considerable evidence that deep neural networks are vulnerable to
adversarial perturbations applied directly to their digital inputs. However, it
remains an open question whether this translates to vulnerabilities in real
systems. For example, an attack on self-driving cars would in practice entail
modifying the driving environment, which then impacts the video inputs to the
car&#x27;s controller, thereby indirectly leading to incorrect driving decisions.
Such attacks require accounting for system dynamics and tracking viewpoint
changes. We propose a scalable approach for finding adversarial modifications
of a simulated autonomous driving environment using a differentiable
approximation for the mapping from environmental modifications (rectangles on
the road) to the corresponding video inputs to the controller neural network.
Given the parameters of the rectangles, our proposed differentiable mapping
composites them onto pre-recorded video streams of the original environment,
accounting for geometric and color variations. Moreover, we propose a multiple
trajectory sampling approach that enables our attacks to be robust to a car&#x27;s
self-correcting behavior. When combined with a neural network-based controller,
our approach allows the design of adversarial modifications through end-to-end
gradient-based optimization. Using the Carla autonomous driving simulator, we
show that our approach is significantly more scalable and far more effective at
identifying autonomous vehicle vulnerabilities in simulation experiments than a
state-of-the-art approach based on Bayesian Optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Mechanical Analysis of Neural Network Pruning. (arXiv:2006.16617v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Acharyya_R/0/1/0/all/0/1">Rupam Acharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Chattoraj_A/0/1/0/all/0/1">Ankani Chattoraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Shouman Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Stefankovic_D/0/1/0/all/0/1">Daniel Stefankovic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16617">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning architectures with a huge number of parameters are often
compressed using pruning techniques to ensure computational efficiency of
inference during deployment. Despite multitude of empirical advances, there is
a lack of theoretical understanding of the effectiveness of different pruning
methods. We inspect different pruning techniques under the statistical
mechanics formulation of a teacher-student framework and derive their
generalization error (GE) bounds. It has been shown that Determinantal Point
Process (DPP) based node pruning method is notably superior to competing
approaches when tested on real datasets. Using GE bounds in the aforementioned
setup we provide theoretical guarantees for their empirical observations.
Another consistent finding in literature is that sparse neural networks (edge
pruned) generalize better than dense neural networks (node pruned) for a fixed
number of parameters. We use our theoretical setup to prove this finding and
show that even the baseline random edge pruning method performs better than the
DPP node pruning method. We also validate this empirically on real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asynchronous \epsilon-Greedy Bayesian Optimisation. (arXiv:2010.07615v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ath_G/0/1/0/all/0/1">George De Ath</a>, <a href="http://arxiv.org/find/cs/1/au:+Everson_R/0/1/0/all/0/1">Richard M. Everson</a>, <a href="http://arxiv.org/find/cs/1/au:+Fieldsend_J/0/1/0/all/0/1">Jonathan E. Fieldsend</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07615">
                                    <div class="article-summary-box-inner">
                                        <span>Batch Bayesian optimisation (BO) is a successful technique for the
optimisation of expensive black-box functions. Asynchronous BO can reduce
wallclock time by starting a new evaluation as soon as another finishes, thus
maximising resource utilisation. To maximise resource allocation, we develop a
novel asynchronous BO method, AEGiS (Asynchronous $\epsilon$-Greedy Global
Search) that combines greedy search, exploiting the surrogate&#x27;s mean
prediction, with Thompson sampling and random selection from the approximate
Pareto set describing the trade-off between exploitation (surrogate mean
prediction) and exploration (surrogate posterior variance). We demonstrate
empirically the efficacy of AEGiS on synthetic benchmark problems,
meta-surrogate hyperparameter tuning problems and real-world problems, showing
that AEGiS generally outperforms existing methods for asynchronous BO. When a
single worker is available performance is no worse than BO using expected
improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-Driven Multiscale Design of Cellular Composites with Multiclass Microstructures for Natural Frequency Maximization. (arXiv:2106.06478v1 [cs.CE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Beek_A/0/1/0/all/0/1">Anton van Beek</a>, <a href="http://arxiv.org/find/cs/1/au:+Da_D/0/1/0/all/0/1">Daicong Da</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_Y/0/1/0/all/0/1">Yu-Chin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Ping Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06478">
                                    <div class="article-summary-box-inner">
                                        <span>For natural frequency optimization of engineering structures, cellular
composites have been shown to possess an edge over solid. However, existing
multiscale design methods for cellular composites are either computationally
exhaustive or confined to a single class of microstructures. In this paper, we
propose a data-driven topology optimization (TO) approach to enable the
multiscale design of cellular structures with various choices of microstructure
classes. The key component is a newly proposed latent-variable Gaussian process
(LVGP) model through which different classes of microstructures are mapped into
a low-dimensional continuous latent space. It provides an interpretable
distance metric between classes and captures their effects on the homogenized
stiffness tensors. By introducing latent vectors as design variables, a
differentiable transition of stiffness matrix between classes can be easily
achieved with an analytical gradient. After integrating LVGP with the
density-based TO, an efficient data-driven cellular composite optimization
process is developed to enable concurrent exploration of microstructure
concepts and the associated volume fractions for natural frequency
optimization. Examples reveal that the proposed cellular designs with
multiclass microstructures achieve higher natural frequencies than both
single-scale and single-class designs. This framework can be easily extended to
other multi-scale TO problems, such as thermal compliance and dynamic response
optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signed Graph Metric Learning via Gershgorin Disc Perfect Alignment. (arXiv:2006.08816v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1">Gene Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08816">
                                    <div class="article-summary-box-inner">
                                        <span>Given a convex and differentiable objective $Q(\M)$ for a real symmetric
matrix $\M$ in the positive definite (PD) cone -- used to compute Mahalanobis
distances -- we propose a fast general metric learning framework that is
entirely projection-free. We first assume that $\M$ resides in a space $\cS$ of
generalized graph Laplacian matrices corresponding to balanced signed graphs.
$\M \in \cS$ that is also PD is called a graph metric matrix. Unlike low-rank
metric matrices common in the literature, $\cS$ includes the important
diagonal-only matrices as a special case. The key theorem to circumvent full
eigen-decomposition and enable fast metric matrix optimization is Gershgorin
disc perfect alignment (GDPA): given $\M \in \cS$ and diagonal matrix $\S$,
where $S_{ii} &#x3D; 1/v_i$ and $\v$ is $\M$&#x27;s first eigenvector, we prove that
Gershgorin disc left-ends of similarity transform $\B &#x3D; \S \M \S^{-1}$ are
perfectly aligned at the smallest eigenvalue $\lambda_{\min}$. Using this
theorem, we replace the PD cone constraint in the metric learning problem with
tightest possible linear constraints per iteration, so that the alternating
optimization of the diagonal / off-diagonal terms in $\M$ can be solved
efficiently as linear programs via the Frank-Wolfe method. We update $\v$ using
Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) with warm
start as entries in $\M$ are optimized successively. Experiments show that our
graph metric optimization is significantly faster than cone-projection schemes,
and produces competitive binary classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overfitting in Bayesian Optimization: an empirical study and early-stopping solution. (arXiv:2104.08166v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makarova_A/0/1/0/all/0/1">Anastasia Makarova</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Huibin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1">Valerio Perrone</a>, <a href="http://arxiv.org/find/cs/1/au:+Klein_A/0/1/0/all/0/1">Aaron Klein</a>, <a href="http://arxiv.org/find/cs/1/au:+Faddoul_J/0/1/0/all/0/1">Jean Baptiste Faddoul</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1">Matthias Seeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1">Cedric Archambeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08166">
                                    <div class="article-summary-box-inner">
                                        <span>Tuning machine learning models with Bayesian optimization (BO) is a
successful strategy to find good hyperparameters. BO defines an iterative
procedure where a cross-validated metric is evaluated on promising
hyperparameters. In practice, however, an improvement of the validation metric
may not translate in better predictive performance on a test set, especially
when tuning models trained on small datasets. In other words, unlike
conventional wisdom dictates, BO can overfit. In this paper, we carry out the
first systematic investigation of overfitting in BO and demonstrate that this
issue is serious, yet often overlooked in practice. We propose a novel
criterion to early stop BO, which aims to maintain the solution quality while
saving the unnecessary iterations that can lead to overfitting. Experiments on
real-world hyperparameter optimization problems show that our approach
effectively meets these goals and is more adaptive comparing to baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularized Softmax Deep Multi-Agent $Q$-Learning. (arXiv:2103.11883v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Ling Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashid_T/0/1/0/all/0/1">Tabish Rashid</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Bei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longbo Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11883">
                                    <div class="article-summary-box-inner">
                                        <span>Tackling overestimation in $Q$-learning is an important problem that has been
extensively studied in single-agent reinforcement learning, but has received
comparatively little attention in the multi-agent setting. In this work, we
empirically demonstrate that QMIX, a popular $Q$-learning algorithm for
cooperative multi-agent reinforcement learning (MARL), suffers from a more
severe overestimation in practice than previously acknowledged, and is not
mitigated by existing approaches. We rectify this with a novel
regularization-based update scheme that penalizes large joint action-values
that deviate from a baseline and demonstrate its effectiveness in stabilizing
learning. Furthermore, we propose to employ a softmax operator, which we
efficiently approximate in a novel way in the multi-agent setting, to further
reduce the potential overestimation bias. Our approach, Regularized Softmax
(RES) Deep Multi-Agent $Q$-Learning, is general and can be applied to any
$Q$-learning based MARL algorithm. We demonstrate that, when applied to QMIX,
RES avoids severe overestimation and significantly improves performance,
yielding state-of-the-art results in a variety of cooperative multi-agent
tasks, including the challenging StarCraft II micromanagement benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models. (arXiv:2104.07788v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rozemberczki_B/0/1/0/all/0/1">Benedek Rozemberczki</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_P/0/1/0/all/0/1">Paul Scherer</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yixuan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Panagopoulos_G/0/1/0/all/0/1">George Panagopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedel_A/0/1/0/all/0/1">Alexander Riedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Astefanoaei_M/0/1/0/all/0/1">Maria Astefanoaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiss_O/0/1/0/all/0/1">Oliver Kiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Beres_F/0/1/0/all/0/1">Ferenc Beres</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_G/0/1/0/all/0/1">Guzm&#xe1;n L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Collignon_N/0/1/0/all/0/1">Nicolas Collignon</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_R/0/1/0/all/0/1">Rik Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07788">
                                    <div class="article-summary-box-inner">
                                        <span>We present PyTorch Geometric Temporal a deep learning framework combining
state-of-the-art machine learning algorithms for neural spatiotemporal signal
processing. The main goal of the library is to make temporal geometric deep
learning available for researchers and machine learning practitioners in a
unified easy-to-use framework. PyTorch Geometric Temporal was created with
foundations on existing libraries in the PyTorch eco-system, streamlined neural
network layer definitions, temporal snapshot generators for batching, and
integrated benchmark datasets. These features are illustrated with a
tutorial-like case study. Experiments demonstrate the predictive performance of
the models implemented in the library on real world problems such as
epidemiological forecasting, ridehail demand prediction and web-traffic
management. Our sensitivity analysis of runtime shows that the framework can
potentially operate on web-scale datasets with rich temporal features and
spatial structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizable Episodic Memory for Deep Reinforcement Learning. (arXiv:2103.06469v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jianing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1">Guangxiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhizhou Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06469">
                                    <div class="article-summary-box-inner">
                                        <span>Episodic memory-based methods can rapidly latch onto past successful
strategies by a non-parametric memory and improve sample efficiency of
traditional reinforcement learning. However, little effort is put into the
continuous domain, where a state is never visited twice, and previous episodic
methods fail to efficiently aggregate experience across trajectories. To
address this problem, we propose Generalizable Episodic Memory (GEM), which
effectively organizes the state-action values of episodic memory in a
generalizable manner and supports implicit planning on memorized trajectories.
GEM utilizes a double estimator to reduce the overestimation bias induced by
value propagation in the planning process. Empirical evaluation shows that our
method significantly outperforms existing trajectory-based methods on various
MuJoCo continuous control tasks. To further show the general applicability, we
evaluate our method on Atari games with discrete action space, which also shows
a significant improvement over baseline algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying and Reducing Bias in Maximum Likelihood Estimation of Structured Anomalies. (arXiv:2007.07878v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chitra_U/0/1/0/all/0/1">Uthsav Chitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_K/0/1/0/all/0/1">Kimberly Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jasper C.H. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Raphael_B/0/1/0/all/0/1">Benjamin J. Raphael</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07878">
                                    <div class="article-summary-box-inner">
                                        <span>Anomaly estimation, or the problem of finding a subset of a dataset that
differs from the rest of the dataset, is a classic problem in machine learning
and data mining. In both theoretical work and in applications, the anomaly is
assumed to have a specific structure defined by membership in an
$\textit{anomaly family}$. For example, in temporal data the anomaly family may
be time intervals, while in network data the anomaly family may be connected
subgraphs. The most prominent approach for anomaly estimation is to compute the
Maximum Likelihood Estimator (MLE) of the anomaly; however, it was recently
observed that for normally distributed data, the MLE is a $\textit{biased}$
estimator for some anomaly families. In this work, we demonstrate that in the
normal means setting, the bias of the MLE depends on the size of the anomaly
family. We prove that if the number of sets in the anomaly family that contain
the anomaly is sub-exponential, then the MLE is asymptotically unbiased. We
also provide empirical evidence that the converse is true: if the number of
such sets is exponential, then the MLE is asymptotically biased. Our analysis
unifies a number of earlier results on the bias of the MLE for specific anomaly
families. Next, we derive a new anomaly estimator using a mixture model, and we
prove that our anomaly estimator is asymptotically unbiased regardless of the
size of the anomaly family. We illustrate the advantages of our estimator
versus the MLE on disease outbreak and highway traffic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Young-min Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1">Young-chul Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kwangjin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1">Moongu Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00100">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a highly practical fully online multi-object
tracking and segmentation (MOTS) method that uses instance segmentation results
as an input. The proposed method is based on the Gaussian mixture probability
hypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a
mask-based affinity fusion (MAF) model to achieve high-performance online
tracking. The HDA consists of two associations: segment-to-track and
track-to-track associations. One affinity, for position and motion, is computed
by using the GMPHD filter, and the other affinity, for appearance is computed
by using the responses from a single object tracker such as a kernalized
correlation filter. These two affinities are simply fused by using a
score-level fusion method such as min-max normalization referred to as MAF. In
addition, to reduce the number of false positive segments, we adopt mask
IoU-based merging (mask merging). The proposed MOTS framework with the key
modules: HDA, MAF, and mask merging, is easily extensible to simultaneously
track multiple types of objects with CPU only execution in parallel processing.
In addition, the developed framework only requires simple parameter tuning
unlike many existing MOTS methods that need intensive hyperparameter
optimization. In the experiments on the two popular MOTS datasets, the key
modules show some improvements. For instance, ID-switch decreases by more than
half compared to a baseline method in the training sets. In conclusion, our
tracker achieves state-of-the-art MOTS performance in the test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Symbolic Regression that Scales. (arXiv:2106.06427v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biggio_L/0/1/0/all/0/1">Luca Biggio</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendinelli_T/0/1/0/all/0/1">Tommaso Bendinelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Neitz_A/0/1/0/all/0/1">Alexander Neitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1">Aurelien Lucchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Parascandolo_G/0/1/0/all/0/1">Giambattista Parascandolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06427">
                                    <div class="article-summary-box-inner">
                                        <span>Symbolic equations are at the core of scientific discovery. The task of
discovering the underlying equation from a set of input-output pairs is called
symbolic regression. Traditionally, symbolic regression methods use
hand-designed strategies that do not improve with experience. In this paper, we
introduce the first symbolic regression method that leverages large scale
pre-training. We procedurally generate an unbounded set of equations, and
simultaneously pre-train a Transformer to predict the symbolic equation from a
corresponding set of input-output-pairs. At test time, we query the model on a
new set of points and use its output to guide the search for the equation. We
show empirically that this approach can re-discover a set of well-known
physical equations, and that it improves over time with more data and compute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online and Distribution-Free Robustness: Regression and Contextual Bandits with Huber Contamination. (arXiv:2010.04157v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sitan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1">Frederic Koehler</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Yau_M/0/1/0/all/0/1">Morris Yau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04157">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we revisit two classic high-dimensional online learning
problems, namely linear regression and contextual bandits, from the perspective
of adversarial robustness. Existing works in algorithmic robust statistics make
strong distributional assumptions that ensure that the input data is evenly
spread out or comes from a nice generative model. Is it possible to achieve
strong robustness guarantees even without distributional assumptions
altogether, where the sequence of tasks we are asked to solve is adaptively and
adversarially chosen?

We answer this question in the affirmative for both linear regression and
contextual bandits. In fact our algorithms succeed where conventional methods
fail. In particular we show strong lower bounds against Huber regression and
more generally any convex M-estimator. Our approach is based on a novel
alternating minimization scheme that interleaves ordinary least-squares with a
simple convex program that finds the optimal reweighting of the distribution
under a spectral constraint. Our results obtain essentially optimal dependence
on the contamination level $\eta$, reach the optimal breakdown point, and
naturally apply to infinite dimensional settings where the feature vectors are
represented implicitly via a kernel map.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coded-InvNet for Resilient Prediction Serving Systems. (arXiv:2106.06445v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1">Tuan Dinh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kangwook Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06445">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by a new coded computation algorithm for invertible functions, we
propose Coded-InvNet a new approach to design resilient prediction serving
systems that can gracefully handle stragglers or node failures. Coded-InvNet
leverages recent findings in the deep learning literature such as invertible
neural networks, Manifold Mixup, and domain translation algorithms, identifying
interesting research directions that span across machine learning and systems.
Our experimental results show that Coded-InvNet can outperform existing
approaches, especially when the compute resource overhead is as low as 10%. For
instance, without knowing which of the ten workers is going to fail, our
algorithm can design a backup task so that it can correctly recover the missing
prediction result with an accuracy of 85.9%, significantly outperforming the
previous SOTA by 32.5%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compositional Video Synthesis with Action Graphs. (arXiv:2006.15327v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1">Amir Bar</a>, <a href="http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1">Roei Herzig</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1">Amir Globerson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15327">
                                    <div class="article-summary-box-inner">
                                        <span>Videos of actions are complex signals containing rich compositional structure
in space and time. Current video generation methods lack the ability to
condition the generation on multiple coordinated and potentially simultaneous
timed actions. To address this challenge, we propose to represent the actions
in a graph structure called Action Graph and present the new &#x60;&#x60;Action Graph To
Video&#x27;&#x27; synthesis task. Our generative model for this task (AG2Vid)
disentangles motion and appearance features, and by incorporating a scheduling
mechanism for actions facilitates a timely and coordinated video generation. We
train and evaluate AG2Vid on the CATER and Something-Something V2 datasets, and
show that the resulting videos have better visual quality and semantic
consistency compared to baselines. Finally, our model demonstrates zero-shot
abilities by synthesizing novel compositions of the learned actions. For code
and pretrained models, see the project page https://roeiherz.github.io/AG2Video</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. (arXiv:2102.10618v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sushant Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jabbari_S/0/1/0/all/0/1">Shahin Jabbari</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1">Sohini Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Himabindu Lakkaraju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10618">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning black boxes are increasingly being deployed in critical
domains such as healthcare and criminal justice, there has been a growing
emphasis on developing techniques for explaining these black boxes in a post
hoc manner. In this work, we analyze two popular post hoc interpretation
techniques: SmoothGrad which is a gradient based method, and a variant of LIME
which is a perturbation based method. More specifically, we derive explicit
closed form expressions for the explanations output by these two methods and
show that they both converge to the same explanation in expectation, i.e., when
the number of perturbed samples used by these methods is large. We then
leverage this connection to establish other desirable properties, such as
robustness, for these techniques. We also derive finite sample complexity
bounds for the number of perturbations required for these methods to converge
to their expected explanation. Finally, we empirically validate our theory
using extensive experimentation on both synthetic and real world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Complexity in Decentralized Training. (arXiv:2006.08085v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yucheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08085">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralization is a promising method of scaling up parallel machine
learning systems. In this paper, we provide a tight lower bound on the
iteration complexity for such methods in a stochastic non-convex setting. Our
lower bound reveals a theoretical gap in known convergence rates of many
existing decentralized training algorithms, such as D-PSGD. We prove by
construction this lower bound is tight and achievable. Motivated by our
insights, we further propose DeTAG, a practical gossip-style decentralized
algorithm that achieves the lower bound with only a logarithm gap. Empirically,
we compare DeTAG with other decentralized algorithms on image classification
tasks, and we show DeTAG enjoys faster convergence compared to baselines,
especially on unshuffled data and in sparse networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WAX-ML: A Python library for machine learning and feedback loops on streaming data. (arXiv:2106.06524v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Serie_E/0/1/0/all/0/1">Emmanuel S&#xe9;ri&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06524">
                                    <div class="article-summary-box-inner">
                                        <span>Wax is what you put on a surfboard to avoid slipping. It is an essential tool
to go surfing... We introduce WAX-ML a research-oriented Python library
providing tools to design powerful machine learning algorithms and feedback
loops working on streaming data. It strives to complement JAX with tools
dedicated to time series. WAX-ML makes JAX-based programs easy to use for
end-users working with pandas and xarray for data manipulation. It provides a
simple mechanism for implementing feedback loops, allows the implementation of
online learning and reinforcement learning algorithms with functions, and makes
them easy to integrate by end-users working with the object-oriented
reinforcement learning framework from the Gym library. It is released with an
Apache open-source license on GitHub at https://github.com/eserie/wax-ml.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Robust Mean Estimation under Coordinate-level Corruption. (arXiv:2002.04137v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zifan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jongho Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1">Theodoros Rekatsinas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1">Christos Tzamos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04137">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of robust mean estimation and introduce a novel Hamming
distance-based measure of distribution shift for coordinate-level corruptions.
We show that this measure yields adversary models that capture more realistic
corruptions than those used in prior works, and present an
information-theoretic analysis of robust mean estimation in these settings. We
show that for structured distributions, methods that leverage the structure
yield information theoretically more accurate mean estimation. We also focus on
practical algorithms for robust mean estimation and study when data
cleaning-inspired approaches that first fix corruptions in the input data and
then perform robust mean estimation can match the information theoretic bounds
of our analysis. We finally demonstrate experimentally that this two-step
approach outperforms structure-agnostic robust estimation and provides accurate
mean estimation even for high-magnitude corruption.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupled Greedy Learning of CNNs for Synchronous and Asynchronous Distributed Learning. (arXiv:2106.06401v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1">Eugene Belilovsky</a> (MILA), <a href="http://arxiv.org/find/cs/1/au:+Leconte_L/0/1/0/all/0/1">Louis Leconte</a> (MLIA, CMAP), <a href="http://arxiv.org/find/cs/1/au:+Caccia_L/0/1/0/all/0/1">Lucas Caccia</a> (MILA), <a href="http://arxiv.org/find/cs/1/au:+Eickenberg_M/0/1/0/all/0/1">Michael Eickenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1">Edouard Oyallon</a> (MLIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06401">
                                    <div class="article-summary-box-inner">
                                        <span>A commonly cited inefficiency of neural network training using
back-propagation is the update locking problem: each layer must wait for the
signal to propagate through the full network before updating. Several
alternatives that can alleviate this issue have been proposed. In this context,
we consider a simple alternative based on minimal feedback, which we call
Decoupled Greedy Learning (DGL). It is based on a classic greedy relaxation of
the joint training objective, recently shown to be effective in the context of
Convolutional Neural Networks (CNNs) on large-scale image classification. We
consider an optimization of this objective that permits us to decouple the
layer training, allowing for layers or modules in networks to be trained with a
potentially linear parallelization. With the use of a replay buffer we show
that this approach can be extended to asynchronous settings, where modules can
operate and continue to update with possibly large communication delays. To
address bandwidth and memory issues we propose an approach based on online
vector quantization. This allows to drastically reduce the communication
bandwidth between modules and required memory for replay buffers. We show
theoretically and empirically that this approach converges and compare it to
the sequential solvers. We demonstrate the effectiveness of DGL against
alternative approaches on the CIFAR-10 dataset and on the large-scale ImageNet
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring the sensitivity of Gaussian processes to kernel choice. (arXiv:2106.06510v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Stephenson_W/0/1/0/all/0/1">William T. Stephenson</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1">Soumya Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1">Tin D. Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Yurochkin_M/0/1/0/all/0/1">Mikhail Yurochkin</a>, <a href="http://arxiv.org/find/stat/1/au:+Deshpande_S/0/1/0/all/0/1">Sameer K. Deshpande</a>, <a href="http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1">Tamara Broderick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06510">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) are used to make medical and scientific decisions,
including in cardiac care and monitoring of carbon dioxide emissions. But the
choice of GP kernel is often somewhat arbitrary. In particular, uncountably
many kernels typically align with qualitative prior knowledge (e.g. function
smoothness or stationarity). But in practice, data analysts choose among a
handful of convenient standard kernels (e.g. squared exponential). In the
present work, we ask: Would decisions made with a GP differ under other,
qualitatively interchangeable kernels? We show how to formulate this
sensitivity analysis as a constrained optimization problem over a
finite-dimensional space. We can then use standard optimizers to identify
substantive changes in relevant decisions made with a GP. We demonstrate in
both synthetic and real-world examples that decisions made with a GP can
exhibit substantial sensitivity to kernel choice, even when prior draws are
qualitatively interchangeable to a user.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Rates for Averaged Stochastic Gradient Descent under Neural Tangent Kernel Regime. (arXiv:2006.12297v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1">Atsushi Nitanda</a>, <a href="http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1">Taiji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12297">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze the convergence of the averaged stochastic gradient descent for
overparameterized two-layer neural networks for regression problems. It was
recently found that a neural tangent kernel (NTK) plays an important role in
showing the global convergence of gradient-based methods under the NTK regime,
where the learning dynamics for overparameterized neural networks can be almost
characterized by that for the associated reproducing kernel Hilbert space
(RKHS). However, there is still room for a convergence rate analysis in the NTK
regime. In this study, we show that the averaged stochastic gradient descent
can achieve the minimax optimal convergence rate, with the global convergence
guarantee, by exploiting the complexities of the target function and the RKHS
associated with the NTK. Moreover, we show that the target function specified
by the NTK of a ReLU network can be learned at the optimal convergence rate
through a smooth approximation of a ReLU network under certain conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Weakly Supervised Action Segmentation Using Mutual Consistency. (arXiv:1904.03116v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Souri_Y/0/1/0/all/0/1">Yaser Souri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1">Mohsen Fayyaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Minciullo_L/0/1/0/all/0/1">Luca Minciullo</a>, <a href="http://arxiv.org/find/cs/1/au:+Francesca_G/0/1/0/all/0/1">Gianpiero Francesca</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.03116">
                                    <div class="article-summary-box-inner">
                                        <span>Action segmentation is the task of predicting the actions for each frame of a
video. As obtaining the full annotation of videos for action segmentation is
expensive, weakly supervised approaches that can learn only from transcripts
are appealing. In this paper, we propose a novel end-to-end approach for weakly
supervised action segmentation based on a two-branch neural network. The two
branches of our network predict two redundant but different representations for
action segmentation and we propose a novel mutual consistency (MuCon) loss that
enforces the consistency of the two redundant representations. Using the MuCon
loss together with a loss for transcript prediction, our proposed approach
achieves the accuracy of state-of-the-art approaches while being $14$ times
faster to train and $20$ times faster during inference. The MuCon loss proves
beneficial even in the fully supervised setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploration-Exploitation Motivated Variational Auto-Encoder for Recommender Systems. (arXiv:2006.03573v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1">Yizi Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_M/0/1/0/all/0/1">Meimei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03573">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have witnessed rapid developments on collaborative filtering
techniques for improving the performance of recommender systems due to the
growing need of companies to help users discover new and relevant items.
However, the majority of existing literature focuses on delivering items which
match the user model learned from users&#x27; past preferences. A good
recommendation model is expected to recommend items that are known to enjoy and
items that are novel to try. In this work, we introduce an
exploitation-exploration motivated variational auto-encoder (XploVAE) to
collaborative filtering. To facilitate personalized recommendations, we
construct user-specific subgraphs, which contain the first-order proximity
capturing observed user-item interactions for exploitation and the high-order
proximity for exploration. A hierarchical latent space model is utilized to
learn the personalized item embedding for a given user, along with the
population distribution of all user subgraphs. Finally, experimental results on
various real-world datasets clearly demonstrate the effectiveness of our
proposed model on leveraging the exploitation and exploration recommendation
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Neural Hidden Markov Models with a Continuous latent state space. (arXiv:2106.06536v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1">Firas Jarboui</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06536">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new procedure to neuralize unsupervised Hidden Markov Models
in the continuous case. This provides higher flexibility to solve problems with
underlying latent variables. This approach is evaluated on both synthetic and
real data. On top of generating likely model parameters with comparable
performances to off-the-shelf neural architecture (LSTMs, GRUs,..), the
obtained results are easily interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probability Paths and the Structure of Predictions over Time. (arXiv:2106.06515v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhiyuan/0/1/0/all/0/1">Zhiyuan</a> (Jerry)Lin, <a href="http://arxiv.org/find/cs/1/au:+Sheng_H/0/1/0/all/0/1">Hao Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1">Sharad Goel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06515">
                                    <div class="article-summary-box-inner">
                                        <span>In settings ranging from weather forecasts to political prognostications to
financial projections, probability estimates of future binary outcomes often
evolve over time. For example, the estimated likelihood of rain on a specific
day changes by the hour as new information becomes available. Given a
collection of such probability paths, we introduce a Bayesian framework --
which we call the Gaussian latent information martingale, or GLIM -- for
modeling the structure of dynamic predictions over time. Suppose, for example,
that the likelihood of rain in a week is 50%, and consider two hypothetical
scenarios. In the first, one expects the forecast is equally likely to become
either 25% or 75% tomorrow; in the second, one expects the forecast to stay
constant for the next several days. A time-sensitive decision-maker might
select a course of action immediately in the latter scenario, but may postpone
their decision in the former, knowing that new information is imminent. We
model these trajectories by assuming predictions update according to a latent
process of information flow, which is inferred from historical data. In
contrast to general methods for time series analysis, this approach preserves
the martingale structure of probability paths and better quantifies future
uncertainties around probability paths. We show that GLIM outperforms three
popular baseline methods, producing better estimated posterior probability path
distributions measured by three different metrics. By elucidating the dynamic
structure of predictions over time, we hope to help individuals make more
informed choices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An adaptive cognitive sensor node for ECG monitoring in the Internet of Medical Things. (arXiv:2106.06498v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scrugli_M/0/1/0/all/0/1">Matteo Antonio Scrugli</a>, <a href="http://arxiv.org/find/cs/1/au:+Loi_D/0/1/0/all/0/1">Daniela Loi</a>, <a href="http://arxiv.org/find/cs/1/au:+Raffo_L/0/1/0/all/0/1">Luigi Raffo</a>, <a href="http://arxiv.org/find/cs/1/au:+Meloni_P/0/1/0/all/0/1">Paolo Meloni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06498">
                                    <div class="article-summary-box-inner">
                                        <span>The Internet of Medical Things (IoMT) paradigm is becoming mainstream in
multiple clinical trials and healthcare procedures. It relies on novel very
accurate and compact sensing devices and communication infrastructures, opening
previously unmatched possibilities of implementing data collection and
continuous patient monitoring. Nevertheless, to fully exploit the potential of
this technology, some steps forwards are needed. First, the edge-computing
paradigm must be added to the picture. A certain level of near-sensor
processing has to be enabled, to improve the scalability, portability,
reliability, responsiveness of the IoMT nodes. Second, novel, increasingly
accurate, data analysis algorithms, such as those based on artificial
intelligence and Deep Learning, must be exploited. To reach these objectives,
designers, programmers of IoMT nodes, have to face challenging optimization
tasks, in order to execute fairly complex computing tasks on low-power wearable
and portable processing systems, with tight power and battery lifetime budgets.
In this work, we explore the implementation of cognitive data analysis
algorithm on resource-constrained computing platforms. To minimize power
consumption, we add an adaptivity layer that dynamically manages the hardware
and software configuration of the device to adapt it at runtime to the required
operating mode. We have assessed our approach on a use-case using a
convolutional neural network to classify electrocardiogram (ECG) traces on a
low-power microcontroller. Our experimental results show that adapting the node
setup to the workload at runtime can save up to 50% power consumption and a
quantized neural network reaches an accuracy value higher than 98% for
arrhythmia disorders detection on MIT-BIH Arrhythmia dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object Segmentation Without Labels with Large-Scale Generative Models. (arXiv:2006.04988v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Voynov_A/0/1/0/all/0/1">Andrey Voynov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morozov_S/0/1/0/all/0/1">Stanislav Morozov</a>, <a href="http://arxiv.org/find/cs/1/au:+Babenko_A/0/1/0/all/0/1">Artem Babenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04988">
                                    <div class="article-summary-box-inner">
                                        <span>The recent rise of unsupervised and self-supervised learning has dramatically
reduced the dependency on labeled data, providing effective image
representations for transfer to downstream vision tasks. Furthermore, recent
works employed these representations in a fully unsupervised setup for image
classification, reducing the need for human labels on the fine-tuning stage as
well. This work demonstrates that large-scale unsupervised models can also
perform a more challenging object segmentation task, requiring neither
pixel-level nor image-level labeling. Namely, we show that recent unsupervised
GANs allow to differentiate between foreground/background pixels, providing
high-quality saliency masks. By extensive comparison on standard benchmarks, we
outperform existing unsupervised alternatives for object segmentation,
achieving new state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recovery of Meteorites Using an Autonomous Drone and Machine Learning. (arXiv:2106.06523v1 [astro-ph.EP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Citron_R/0/1/0/all/0/1">Robert I. Citron</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Jenniskens_P/0/1/0/all/0/1">Peter Jenniskens</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Watkins_C/0/1/0/all/0/1">Christopher Watkins</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sinha_S/0/1/0/all/0/1">Sravanthi Sinha</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Shah_A/0/1/0/all/0/1">Amar Shah</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Raissi_C/0/1/0/all/0/1">Chedy Raissi</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Devillepoix_H/0/1/0/all/0/1">Hadrien Devillepoix</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Albers_J/0/1/0/all/0/1">Jim Albers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06523">
                                    <div class="article-summary-box-inner">
                                        <span>The recovery of freshly fallen meteorites from tracked and triangulated
meteors is critical to determining their source asteroid families. However,
locating meteorite fragments in strewn fields remains a challenge with very few
meteorites being recovered from the meteors triangulated in past and ongoing
meteor camera networks. We examined if locating meteorites can be automated
using machine learning and an autonomous drone. Drones can be programmed to fly
a grid search pattern and take systematic pictures of the ground over a large
survey area. Those images can be analyzed using a machine learning classifier
to identify meteorites in the field among many other features. Here, we
describe a proof-of-concept meteorite classifier that deploys off-line a
combination of different convolution neural networks to recognize meteorites
from images taken by drones in the field. The system was implemented in a
conceptual drone setup and tested in the suspected strewn field of a recent
meteorite fall near Walker Lake, Nevada.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Probabilistic Model for Blind Source Separation via Legendre Transformation. (arXiv:1909.11294v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Luo_S/0/1/0/all/0/1">Simon Luo</a>, <a href="http://arxiv.org/find/stat/1/au:+Azizi_L/0/1/0/all/0/1">Lamiae Azizi</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Mahito Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11294">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel blind source separation (BSS) method, called information
geometric blind source separation (IGBSS). Our formulation is based on the
log-linear model equipped with a hierarchically structured sample space, which
has theoretical guarantees to uniquely recover a set of source signals by
minimizing the KL divergence from a set of mixed signals. Source signals,
received signals, and mixing matrices are realized as different layers in our
hierarchical sample space. Our empirical results have demonstrated on images
and time series data that our approach is superior to well established
techniques and is able to separate signals with complex interactions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Polyhedral Verification of Recurrent Neural Networks. (arXiv:2005.13300v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ryou_W/0/1/0/all/0/1">Wonryong Ryou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiayu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1">Mislav Balunovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_A/0/1/0/all/0/1">Andrei Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.13300">
                                    <div class="article-summary-box-inner">
                                        <span>We present a scalable and precise verifier for recurrent neural networks,
called Prover based on two novel ideas: (i) a method to compute a set of
polyhedral abstractions for the non-convex and nonlinear recurrent update
functions by combining sampling, optimization, and Fermat&#x27;s theorem, and (ii) a
gradient descent based algorithm for abstraction refinement guided by the
certification problem that combines multiple abstractions for each neuron.
Using Prover, we present the first study of certifying a non-trivial use case
of recurrent neural networks, namely speech classification. To achieve this, we
additionally develop custom abstractions for the non-linear speech
preprocessing pipeline. Our evaluation shows that Prover successfully verifies
several challenging recurrent models in computer vision, speech, and motion
sensor data classification beyond the reach of prior work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Gradient Bayesian Robust Optimization for Imitation Learning. (arXiv:2106.06499v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Javed_Z/0/1/0/all/0/1">Zaynah Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1">Daniel S. Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Satvik Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jerry Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1">Ashwin Balakrishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrik_M/0/1/0/all/0/1">Marek Petrik</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca D. Dragan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1">Ken Goldberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06499">
                                    <div class="article-summary-box-inner">
                                        <span>The difficulty in specifying rewards for many real-world problems has led to
an increased focus on learning rewards from human feedback, such as
demonstrations. However, there are often many different reward functions that
explain the human feedback, leaving agents with uncertainty over what the true
reward function is. While most policy optimization approaches handle this
uncertainty by optimizing for expected performance, many applications demand
risk-averse behavior. We derive a novel policy gradient-style robust
optimization approach, PG-BROIL, that optimizes a soft-robust objective that
balances expected performance and risk. To the best of our knowledge, PG-BROIL
is the first policy optimization algorithm robust to a distribution of reward
hypotheses which can scale to continuous MDPs. Results suggest that PG-BROIL
can produce a family of behaviors ranging from risk-neutral to risk-averse and
outperforms state-of-the-art imitation learning algorithms when learning from
ambiguous demonstrations by hedging against uncertainty, rather than seeking to
uniquely identify the demonstrator&#x27;s reward function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally Sparse Networks for Interpretable Predictions. (arXiv:2106.06468v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Junchen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindenbaum_O/0/1/0/all/0/1">Ofir Lindenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Kluger_Y/0/1/0/all/0/1">Yuval Kluger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06468">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the enormous success of neural networks, they are still hard to
interpret and often overfit when applied to low-sample-size (LSS) datasets. To
tackle these obstacles, we propose a framework for training locally sparse
neural networks where the local sparsity is learned via a sample-specific
gating mechanism that identifies the subset of most relevant features for each
measurement. The sample-specific sparsity is predicted via a \textit{gating}
network, which is trained in tandem with the \textit{prediction} network. By
learning these subsets and weights of a prediction model, we obtain an
interpretable neural network that can handle LSS data and can remove nuisance
variables, which are irrelevant for the supervised learning task. Using both
synthetic and real-world datasets, we demonstrate that our method outperforms
state-of-the-art models when predicting the target function with far fewer
features per instance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invariant Information Bottleneck for Domain Generalization. (arXiv:2106.06333v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yifei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yezhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wenzhen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1">Colorado J. Reed</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06333">
                                    <div class="article-summary-box-inner">
                                        <span>The main challenge for domain generalization (DG) is to overcome the
potential distributional shift between multiple training domains and unseen
test domains. One popular class of DG algorithms aims to learn representations
that have an invariant causal relation across the training domains. However,
certain features, called \emph{pseudo-invariant features}, may be invariant in
the training domain but not the test domain and can substantially decreases the
performance of existing algorithms. To address this issue, we propose a novel
algorithm, called Invariant Information Bottleneck (IIB), that learns a
minimally sufficient representation that is invariant across training and
testing domains. By minimizing the mutual information between the
representation and inputs, IIB alleviates its reliance on pseudo-invariant
features, which is desirable for DG. To verify the effectiveness of the IIB
principle, we conduct extensive experiments on large-scale DG benchmarks. The
results show that IIB outperforms invariant learning baseline (e.g. IRM) by an
average of 2.8\% and 3.8\% accuracy over two evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dictionary and prior learning with unrolled algorithms for unsupervised inverse problems. (arXiv:2106.06338v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malezieux_B/0/1/0/all/0/1">Beno&#xee;t Mal&#xe9;zieux</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1">Thomas Moreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowalski_M/0/1/0/all/0/1">Matthieu Kowalski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06338">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse problems consist in recovering a signal given noisy observations. One
classical resolution approach is to leverage sparsity and integrate prior
knowledge of the signal to the reconstruction algorithm to get a plausible
solution. Still, this prior might not be sufficiently adapted to the data. In
this work, we study Dictionary and Prior learning from degraded measurements as
a bi-level problem, and we take advantage of unrolled algorithms to solve
approximate formulations of Synthesis and Analysis. We provide an empirical and
theoretical analysis of automatic differentiation for Dictionary Learning to
understand better the pros and cons of unrolling in this context. We find that
unrolled algorithms speed up the recovery process for a small number of
iterations by improving the gradient estimation. Then we compare Analysis and
Synthesis by evaluating the performance of unrolled algorithms for inverse
problems, without access to any ground truth data for several classes of
dictionaries and priors. While Analysis can achieve good results,Synthesis is
more robust and performs better. Finally, we illustrate our method on pattern
and structure learning tasks from degraded measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous Herded Gibbs Sampling. (arXiv:2106.06430v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wolf_L/0/1/0/all/0/1">Laura M. Wolf</a>, <a href="http://arxiv.org/find/stat/1/au:+Baum_M/0/1/0/all/0/1">Marcus Baum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06430">
                                    <div class="article-summary-box-inner">
                                        <span>Herding is a technique to sequentially generate deterministic samples from a
probability distribution. In this work, we propose a continuous herded Gibbs
sampler, that combines kernel herding on continuous densities with Gibbs
sampling. Our algorithm allows for deterministically sampling from
high-dimensional multivariate probability densities, without directly sampling
from the joint density. Experiments with Gaussian mixture densities indicate
that the L2 error decreases similarly to kernel herding, while the computation
time is significantly lower, i.e., linear in the number of dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topological Detection of Trojaned Neural Networks. (arXiv:2106.06469v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Songzhu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yikai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_H/0/1/0/all/0/1">Hubert Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Goswami_M/0/1/0/all/0/1">Mayank Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06469">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are known to have security issues. One particular threat
is the Trojan attack. It occurs when the attackers stealthily manipulate the
model&#x27;s behavior through Trojaned training samples, which can later be
exploited.

Guided by basic neuroscientific principles we discover subtle -- yet critical
-- structural deviation characterizing Trojaned models. In our analysis we use
topological tools. They allow us to model high-order dependencies in the
networks, robustly compare different networks, and localize structural
abnormalities. One interesting observation is that Trojaned models develop
short-cuts from input to output layers.

Inspired by these observations, we devise a strategy for robust detection of
Trojaned models. Compared to standard baselines it displays better performance
on multiple benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Driven Adaptive Prior. (arXiv:2106.06406v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1">Sang-gil Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1">Heeseung Kim</a>, <a href="http://arxiv.org/find/stat/1/au:+Shin_C/0/1/0/all/0/1">Chaehun Shin</a>, <a href="http://arxiv.org/find/stat/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1">Qi Meng</a>, <a href="http://arxiv.org/find/stat/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06406">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models have been recently proposed to
generate high-quality samples by estimating the gradient of the data density.
The framework assumes the prior noise as a standard Gaussian distribution,
whereas the corresponding data distribution may be more complicated than the
standard Gaussian distribution, which potentially introduces inefficiency in
denoising the prior noise into the data sample because of the discrepancy
between the data and the prior. In this paper, we propose PriorGrad to improve
the efficiency of the conditional diffusion model (for example, a vocoder using
a mel-spectrogram as the condition) by applying an adaptive prior derived from
the data statistics based on the conditional information. We formulate the
training and sampling procedures of PriorGrad and demonstrate the advantages of
an adaptive prior through a theoretical analysis. Focusing on the audio domain,
we consider the recently proposed diffusion-based audio generative models based
on both the spectral and time domains and show that PriorGrad achieves a faster
convergence leading to data and parameter efficiency and improved quality, and
thereby demonstrating the efficiency of a data-driven adaptive prior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Reinforcement Learning as Anti-Exploration. (arXiv:2106.06431v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1">Shideh Rezaeifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dadashi_R/0/1/0/all/0/1">Robert Dadashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1">Nino Vieillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussenot_L/0/1/0/all/0/1">L&#xe9;onard Hussenot</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1">Olivier Bachem</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1">Olivier Pietquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06431">
                                    <div class="article-summary-box-inner">
                                        <span>Offline Reinforcement Learning (RL) aims at learning an optimal control from
a fixed dataset, without interactions with the system. An agent in this setting
should avoid selecting actions whose consequences cannot be predicted from the
data. This is the converse of exploration in RL, which favors such actions. We
thus take inspiration from the literature on bonus-based exploration to design
a new offline RL agent. The core idea is to subtract a prediction-based
exploration bonus from the reward, instead of adding it for exploration. This
allows the policy to stay close to the support of the dataset. We connect this
approach to a more common regularization of the learned policy towards the
data. Instantiated with a bonus based on the prediction error of a variational
autoencoder, we show that our agent is competitive with the state of the art on
a set of continuous control locomotion and manipulation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JKOnet: Proximal Optimal Transport Modeling of Population Dynamics. (arXiv:2106.06345v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bunne_C/0/1/0/all/0/1">Charlotte Bunne</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Papaxanthos_L/0/1/0/all/0/1">Laetitia Meng-Papaxanthos</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuturi_M/0/1/0/all/0/1">Marco Cuturi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06345">
                                    <div class="article-summary-box-inner">
                                        <span>Consider a heterogeneous population of points evolving with time. While the
population evolves, both in size and nature, we can observe it periodically,
through snapshots taken at different timestamps. Each of these snapshots is
formed by sampling points from the population at that time, and then creating
features to recover point clouds. While these snapshots describe the
population&#x27;s evolution on aggregate, they do not provide directly insights on
individual trajectories. This scenario is encountered in several applications,
notably single-cell genomics experiments, tracking of particles, or when
studying crowd motion. In this paper, we propose to model that dynamic as
resulting from the celebrated Jordan-Kinderlehrer-Otto (JKO) proximal scheme.
The JKO scheme posits that the configuration taken by a population at time $t$
is one that trades off a decrease w.r.t. an energy (the model we seek to learn)
penalized by an optimal transport distance w.r.t. the previous configuration.
To that end, we propose JKOnet, a neural architecture that combines an energy
model on measures, with (small) optimal displacements solved with input convex
neural networks (ICNN). We demonstrate the applicability of our model to
explain and predict population dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding Generalization via Decomposing Excess Risk Dynamics. (arXiv:2106.06153v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teng_J/0/1/0/all/0/1">Jiaye Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianhao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yang Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06153">
                                    <div class="article-summary-box-inner">
                                        <span>Generalization is one of the critical issues in machine learning. However,
traditional methods like uniform convergence are not powerful enough to fully
explain generalization because they may yield vacuous bounds even in
overparameterized linear regression regimes. An alternative solution is to
analyze the generalization dynamics to derive algorithm-dependent bounds, e.g.,
stability. Unfortunately, the stability-based bound is still far from
explaining the remarkable generalization ability of neural networks due to the
coarse-grained analysis of the signal and noise. Inspired by the observation
that neural networks show a slow convergence rate when fitting noise, we
propose decomposing the excess risk dynamics and applying stability-based bound
only on the variance part (which measures how the model performs on pure
noise). We provide two applications for the framework, including a linear case
(overparameterized linear regression with gradient descent) and a non-linear
case (matrix recovery with gradient flow). Under the decomposition framework,
the new bound accords better with the theoretical and empirical evidence
compared to the stability-based bound and uniform convergence bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preferential Temporal Difference Learning. (arXiv:2106.06508v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anand_N/0/1/0/all/0/1">Nishanth Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06508">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal-Difference (TD) learning is a general and very useful tool for
estimating the value function of a given policy, which in turn is required to
find good policies. Generally speaking, TD learning updates states whenever
they are visited. When the agent lands in a state, its value can be used to
compute the TD-error, which is then propagated to other states. However, it may
be interesting, when computing updates, to take into account other information
than whether a state is visited or not. For example, some states might be more
important than others (such as states which are frequently seen in a successful
trajectory). Or, some states might have unreliable value estimates (for
example, due to partial observability or lack of data), making their values
less desirable as targets. We propose an approach to re-weighting states used
in TD updates, both when they are the input and when they provide the target
for the update. We prove that our approach converges with linear function
approximation and illustrate its desirable empirical behaviour compared to
other TD-style methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label Noise SGD Provably Prefers Flat Global Minimizers. (arXiv:2106.06530v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damian_A/0/1/0/all/0/1">Alex Damian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06530">
                                    <div class="article-summary-box-inner">
                                        <span>In overparametrized models, the noise in stochastic gradient descent (SGD)
implicitly regularizes the optimization trajectory and determines which local
minimum SGD converges to. Motivated by empirical studies that demonstrate that
training with noisy labels improves generalization, we study the implicit
regularization effect of SGD with label noise. We show that SGD with label
noise converges to a stationary point of a regularized loss $L(\theta) +\lambda
R(\theta)$, where $L(\theta)$ is the training loss, $\lambda$ is an effective
regularization parameter depending on the step size, strength of the label
noise, and the batch size, and $R(\theta)$ is an explicit regularizer that
penalizes sharp minimizers. Our analysis uncovers an additional regularization
effect of large learning rates beyond the linear scaling rule that penalizes
large eigenvalues of the Hessian more than small ones. We also prove extensions
to classification with general loss functions, SGD with momentum, and SGD with
general noise covariance, significantly strengthening the prior work of Blanc
et al. to global convergence and large learning rates and of HaoChen et al. to
general models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Survey of Image Based Graph Neural Networks. (arXiv:2106.06307v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nazir_U/0/1/0/all/0/1">Usman Nazir</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Taj_M/0/1/0/all/0/1">Murtaza Taj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06307">
                                    <div class="article-summary-box-inner">
                                        <span>In this survey paper, we analyze image based graph neural networks and
propose a three-step classification approach. We first convert the image into
superpixels using the Quickshift algorithm so as to reduce 30% of the input
data. The superpixels are subsequently used to generate a region adjacency
graph. Finally, the graph is passed through a state-of-art graph convolutional
neural network to get classification scores. We also analyze the spatial and
spectral convolution filtering techniques in graph neural networks.
Spectral-based models perform better than spatial-based models and classical
CNN with lesser compute cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Can Knowledge Bring to Machine Learning? -- A Survey of Low-shot Learning for Structured Data. (arXiv:2106.06410v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapman_A/0/1/0/all/0/1">Adriane Chapman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1">Guihua Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hall_D/0/1/0/all/0/1">Dame Wendy Hall</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06410">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised machine learning has several drawbacks that make it difficult to
use in many situations. Drawbacks include: heavy reliance on massive training
data, limited generalizability and poor expressiveness of high-level semantics.
Low-shot Learning attempts to address these drawbacks. Low-shot learning allows
the model to obtain good predictive power with very little or no training data,
where structured knowledge plays a key role as a high-level semantic
representation of human. This article will review the fundamental factors of
low-shot learning technologies, with a focus on the operation of structured
knowledge under different low-shot conditions. We also introduce other
techniques relevant to low-shot learning. Finally, we point out the limitations
of low-shot learning, the prospects and gaps of industrial applications, and
future research directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonmyopic Multifidelity Active Search. (arXiv:2106.06356v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Modiri_A/0/1/0/all/0/1">Arghavan Modiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1">Roman Garnett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06356">
                                    <div class="article-summary-box-inner">
                                        <span>Active search is a learning paradigm where we seek to identify as many
members of a rare, valuable class as possible given a labeling budget. Previous
work on active search has assumed access to a faithful (and expensive) oracle
reporting experimental results. However, some settings offer access to cheaper
surrogates such as computational simulation that may aid in the search. We
propose a model of multifidelity active search, as well as a novel,
computationally efficient policy for this setting that is motivated by
state-of-the-art classical policies. Our policy is nonmyopic and budget aware,
allowing for a dynamic tradeoff between exploration and exploitation. We
evaluate the performance of our solution on real-world datasets and demonstrate
significantly better performance than natural benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order Matters: Probabilistic Modeling of Node Sequence for Graph Generation. (arXiv:2106.06189v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1">Xiaohui Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/stat/1/au:+Hu_J/0/1/0/all/0/1">Jiajing Hu</a>, <a href="http://arxiv.org/find/stat/1/au:+Ruiz_F/0/1/0/all/0/1">Francisco J. R. Ruiz</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1">Liping Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06189">
                                    <div class="article-summary-box-inner">
                                        <span>A graph generative model defines a distribution over graphs. One type of
generative model is constructed by autoregressive neural networks, which
sequentially add nodes and edges to generate a graph. However, the likelihood
of a graph under the autoregressive model is intractable, as there are numerous
sequences leading to the given graph; this makes maximum likelihood estimation
challenging. Instead, in this work we derive the exact joint probability over
the graph and the node ordering of the sequential process. From the joint, we
approximately marginalize out the node orderings and compute a lower bound on
the log-likelihood using variational inference. We train graph generative
models by maximizing this bound, without using the ad-hoc node orderings of
previous methods. Our experiments show that the log-likelihood bound is
significantly tighter than the bound of previous schemes. Moreover, the models
fitted with the proposed algorithm can generate high-quality graphs that match
the structures of target graphs not seen during training. We have made our code
publicly available at
\hyperref[https://github.com/tufts-ml/graph-generation-vi]{https://github.com/tufts-ml/graph-generation-vi}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Record Similarity for Practical Vertical Federated Learning. (arXiv:2106.06312v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhaomin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qinbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Bingsheng He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06312">
                                    <div class="article-summary-box-inner">
                                        <span>As the privacy of machine learning has drawn increasing attention, federated
learning is introduced to enable collaborative learning without revealing raw
data. Notably, \textit{vertical federated learning} (VFL), where parties share
the same set of samples but only hold partial features, has a wide range of
real-world applications. However, existing studies in VFL rarely study the
&#x60;&#x60;record linkage&#x27;&#x27; process. They either design algorithms assuming the data
from different parties have been linked or use simple linkage methods like
exact-linkage or top1-linkage. These approaches are unsuitable for many
applications, such as the GPS location and noisy titles requiring fuzzy
matching. In this paper, we design a novel similarity-based VFL framework,
FedSim, which is suitable for more real-world applications and achieves higher
performance on traditional VFL tasks. Moreover, we theoretically analyze the
privacy risk caused by sharing similarities. Our experiments on three synthetic
datasets and five real-world datasets with various similarity metrics show that
FedSim consistently outperforms other state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keyframe-Focused Visual Imitation Learning. (arXiv:2106.06452v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1">Chuan Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jierui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1">Jianing Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1">Dinesh Jayaraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06452">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning trains control policies by mimicking pre-recorded expert
demonstrations. In partially observable settings, imitation policies must rely
on observation histories, but many seemingly paradoxical results show better
performance for policies that only access the most recent observation. Recent
solutions ranging from causal graph learning to deep information bottlenecks
have shown promising results, but failed to scale to realistic settings such as
visual imitation. We propose a solution that outperforms these prior approaches
by upweighting demonstration keyframes corresponding to expert action
changepoints. This simple approach easily scales to complex visual imitation
settings. Our experimental results demonstrate consistent performance
improvements over all baselines on image-based Gym MuJoCo continuous control
tasks. Finally, on the CARLA photorealistic vision-based urban driving
simulator, we resolve a long-standing issue in behavioral cloning for driving
by demonstrating effective imitation from observation histories. Supplementary
materials and code at: \url{https://tinyurl.com/imitation-keyframes}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Within-layer Diversity Reduces Generalization Gap. (arXiv:2106.06012v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laakom_F/0/1/0/all/0/1">Firas Laakom</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitoharju_J/0/1/0/all/0/1">Jenni Raitoharju</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06012">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are composed of multiple layers arranged in a hierarchical
structure jointly trained with a gradient-based optimization, where the errors
are back-propagated from the last layer back to the first one. At each
optimization step, neurons at a given layer receive feedback from neurons
belonging to higher layers of the hierarchy. In this paper, we propose to
complement this traditional &#x27;between-layer&#x27; feedback with additional
&#x27;within-layer&#x27; feedback to encourage diversity of the activations within the
same layer. To this end, we measure the pairwise similarity between the outputs
of the neurons and use it to model the layer&#x27;s overall diversity. By penalizing
similarities and promoting diversity, we encourage each neuron to learn a
distinctive representation and, thus, to enrich the data representation learned
within the layer and to increase the total capacity of the model. We
theoretically study how the within-layer activation diversity affects the
generalization performance of a neural network and prove that increasing the
diversity of hidden activations reduces the estimation error. In addition to
the theoretical guarantees, we present an empirical study on three datasets
confirming that the proposed approach enhances the performance of
state-of-the-art neural network models and decreases the generalization gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Language Models for Continuously Evolving Content. (arXiv:2106.06297v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hombaiah_S/0/1/0/all/0/1">Spurthi Amba Hombaiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mingyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1">Michael Bendersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1">Marc Najork</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06297">
                                    <div class="article-summary-box-inner">
                                        <span>The content on the web is in a constant state of flux. New entities, issues,
and ideas continuously emerge, while the semantics of the existing conversation
topics gradually shift. In recent years, pre-trained language models like BERT
greatly improved the state-of-the-art for a large spectrum of content
understanding tasks. Therefore, in this paper, we aim to study how these
language models can be adapted to better handle continuously evolving web
content. In our study, we first analyze the evolution of 2013 - 2019 Twitter
data, and unequivocally confirm that a BERT model trained on past tweets would
heavily deteriorate when directly applied to data from later years. Then, we
investigate two possible sources of the deterioration: the semantic shift of
existing tokens and the sub-optimal or failed understanding of new tokens. To
this end, we both explore two different vocabulary composition methods, as well
as propose three sampling methods which help in efficient incremental training
for BERT-like models. Compared to a new model trained from scratch offline, our
incremental training (a) reduces the training costs, (b) achieves better
performance on evolving content, and (c) is suitable for online deployment. The
superiority of our methods is validated using two downstream tasks. We
demonstrate significant improvements when incrementally evolving the model from
a particular base year, on the task of Country Hashtag Prediction, as well as
on the OffensEval 2019 task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViT-Inception-GAN for Image Colourising. (arXiv:2106.06321v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bana_T/0/1/0/all/0/1">Tejas Bana</a>, <a href="http://arxiv.org/find/cs/1/au:+Loya_J/0/1/0/all/0/1">Jatan Loya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1">Siddhant Kulkarni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06321">
                                    <div class="article-summary-box-inner">
                                        <span>Studies involving colourising images has been garnering researchers&#x27; keen
attention over time, assisted by significant advances in various Machine
Learning techniques and compute power availability. Traditionally, colourising
images have been an intricate task that gave a substantial degree of freedom
during the assignment of chromatic information. In our proposed method, we
attempt to colourise images using Vision Transformer - Inception - Generative
Adversarial Network (ViT-I-GAN), which has an Inception-v3 fusion embedding in
the generator. For a stable and robust network, we have used Vision Transformer
(ViT) as the discriminator. We trained the model on the Unsplash and the COCO
dataset for demonstrating the improvement made by the Inception-v3 embedding.
We have compared the results between ViT-GANs with and without Inception-v3
embedding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Transformer Networks: Learning Meta-path Graphs to Improve GNNs. (arXiv:2106.06218v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Seongjun Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_M/0/1/0/all/0/1">Minbyul Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1">Sungdong Yoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Sean S. Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_R/0/1/0/all/0/1">Raehyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jaewoo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunwoo J. Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06218">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have been widely applied to various fields due
to their powerful representations of graph-structured data. Despite the success
of GNNs, most existing GNNs are designed to learn node representations on the
fixed and homogeneous graphs. The limitations especially become problematic
when learning representations on a misspecified graph or a heterogeneous graph
that consists of various types of nodes and edges. To address this limitations,
we propose Graph Transformer Networks (GTNs) that are capable of generating new
graph structures, which preclude noisy connections and include useful
connections (e.g., meta-paths) for tasks, while learning effective node
representations on the new graphs in an end-to-end fashion. We further propose
enhanced version of GTNs, Fast Graph Transformer Networks (FastGTNs), that
improve scalability of graph transformations. Compared to GTNs, FastGTNs are
230x faster and use 100x less memory while allowing the identical graph
transformations as GTNs. In addition, we extend graph transformations to the
semantic proximity of nodes allowing non-local operations beyond meta-paths.
Extensive experiments on both homogeneous graphs and heterogeneous graphs show
that GTNs and FastGTNs with non-local operations achieve the state-of-the-art
performance for node classification tasks. The code is available:
https://github.com/seongjunyun/Graph_Transformer_Networks</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">States of confusion: Eye and Head tracking reveal surgeons&#x27; confusion during arthroscopic surgery. (arXiv:2106.06261v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hosp_B/0/1/0/all/0/1">Benedikt Hosp</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1">Myat Su Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddawy_p/0/1/0/all/0/1">peter Haddawy</a>, <a href="http://arxiv.org/find/cs/1/au:+Watcharporas_R/0/1/0/all/0/1">Ratthapoom Watcharporas</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_ngasoonsong_p/0/1/0/all/0/1">paphon Sa-ngasoonsong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasneci_E/0/1/0/all/0/1">Enkelejda Kasneci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06261">
                                    <div class="article-summary-box-inner">
                                        <span>During arthroscopic surgeries, surgeons are faced with challenges like
cognitive re-projection of the 2D screen output into the 3D operating site or
navigation through highly similar tissue. Training of these cognitive processes
takes much time and effort for young surgeons, but is necessary and crucial for
their education. In this study we want to show how to recognize states of
confusion of young surgeons during an arthroscopic surgery, by looking at their
eye and head movements and feeding them to a machine learning model. With an
accuracy of over 94\% and detection speed of 0.039 seconds, our model is a step
towards online diagnostic and training systems for the perceptual-cognitive
processes of surgeons during arthroscopic surgeries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Conditional Gaussian Mixture Model for Constrained Clustering. (arXiv:2106.06385v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1">Laura Manduchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chin_Cheong_K/0/1/0/all/0/1">Kieran Chin-Cheong</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_H/0/1/0/all/0/1">Holger Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Wellmann_S/0/1/0/all/0/1">Sven Wellmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1">Julia E. Vogt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06385">
                                    <div class="article-summary-box-inner">
                                        <span>Constrained clustering has gained significant attention in the field of
machine learning as it can leverage prior information on a growing amount of
only partially labeled data. Following recent advances in deep generative
models, we propose a novel framework for constrained clustering that is
intuitive, interpretable, and can be trained efficiently in the framework of
stochastic gradient variational inference. By explicitly integrating domain
knowledge in the form of probabilistic relations, our proposed model (DC-GMM)
uncovers the underlying distribution of data conditioned on prior clustering
preferences, expressed as pairwise constraints. These constraints guide the
clustering process towards a desirable partition of the data by indicating
which samples should or should not belong to the same cluster. We provide
extensive experiments to demonstrate that DC-GMM shows superior clustering
performances and robustness compared to state-of-the-art deep constrained
clustering methods on a wide range of data sets. We further demonstrate the
usefulness of our approach on two challenging real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HPO-B: A Large-Scale Reproducible Benchmark for Black-Box HPO based on OpenML. (arXiv:2106.06257v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arango_S/0/1/0/all/0/1">Sebastian Pineda Arango</a>, <a href="http://arxiv.org/find/cs/1/au:+Jomaa_H/0/1/0/all/0/1">Hadi S. Jomaa</a>, <a href="http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1">Martin Wistuba</a>, <a href="http://arxiv.org/find/cs/1/au:+Grabocka_J/0/1/0/all/0/1">Josif Grabocka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06257">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperparameter optimization (HPO) is a core problem for the machine learning
community and remains largely unsolved due to the significant computational
resources required to evaluate hyperparameter configurations. As a result, a
series of recent related works have focused on the direction of transfer
learning for quickly fine-tuning hyperparameters on a dataset. Unfortunately,
the community does not have a common large-scale benchmark for comparing HPO
algorithms. Instead, the de facto practice consists of empirical protocols on
arbitrary small-scale meta-datasets that vary inconsistently across
publications, making reproducibility a challenge. To resolve this major
bottleneck and enable a fair and fast comparison of black-box HPO methods on a
level playing field, we propose HPO-B, a new large-scale benchmark in the form
of a collection of meta-datasets. Our benchmark is assembled and preprocessed
from the OpenML repository and consists of 176 search spaces (algorithms)
evaluated sparsely on 196 datasets with a total of 6.4 million hyperparameter
evaluations. For ensuring reproducibility on our benchmark, we detail explicit
experimental protocols, splits, and evaluation measures for comparing methods
for both non-transfer, as well as, transfer learning HPO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Learnability via Gradient Method for Two-Layer ReLU Neural Networks in Teacher-Student Setting. (arXiv:2106.06251v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Akiyama_S/0/1/0/all/0/1">Shunta Akiyama</a>, <a href="http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1">Taiji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06251">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning empirically achieves high performance in many applications, but
its training dynamics has not been fully understood theoretically. In this
paper, we explore theoretical analysis on training two-layer ReLU neural
networks in a teacher-student regression model, in which a student network
learns an unknown teacher network through its outputs. We show that with a
specific regularization and sufficient over-parameterization, the student
network can identify the parameters of the teacher network with high
probability via gradient descent with a norm dependent stepsize even though the
objective function is highly non-convex. The key theoretical tool is the
measure representation of the neural networks and a novel application of a dual
certificate argument for sparse estimation on a measure space. We analyze the
global minima and global convergence property in the measure space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks. (arXiv:2106.06235v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gurel_N/0/1/0/all/0/1">Nezihe Merve G&#xfc;rel</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xiangyu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rimanic_L/0/1/0/all/0/1">Luka Rimanic</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06235">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great successes achieved by deep neural networks (DNNs), recent
studies show that they are vulnerable against adversarial examples, which aim
to mislead DNNs by adding small adversarial perturbations. Several defenses
have been proposed against such attacks, while many of them have been
adaptively attacked. In this work, we aim to enhance the ML robustness from a
different perspective by leveraging domain knowledge: We propose a Knowledge
Enhanced Machine Learning Pipeline (KEMLP) to integrate domain knowledge (i.e.,
logic relationships among different predictions) into a probabilistic graphical
model via first-order logic rules. In particular, we develop KEMLP by
integrating a diverse set of weak auxiliary models based on their logical
relationships to the main DNN model that performs the target task.
Theoretically, we provide convergence results and prove that, under mild
conditions, the prediction of KEMLP is more robust than that of the main DNN
model. Empirically, we take road sign recognition as an example and leverage
the relationships between road signs and their shapes and contents as domain
knowledge. We show that compared with adversarial training and other baselines,
KEMLP achieves higher robustness against physical attacks, $\mathcal{L}_p$
bounded attacks, unforeseen attacks, and natural corruptions under both
whitebox and blackbox settings, while still maintaining high clean accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nested and Balanced Entity Recognition using Multi-Task Learning. (arXiv:2106.06216v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1">Andreas Waldis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazzola_L/0/1/0/all/0/1">Luca Mazzola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06216">
                                    <div class="article-summary-box-inner">
                                        <span>Entity Recognition (ER) within a text is a fundamental exercise in Natural
Language Processing, enabling further depending tasks such as Knowledge
Extraction, Text Summarisation, or Keyphrase Extraction. An entity consists of
single words or of a consecutive sequence of terms, constituting the basic
building blocks for communication. Mainstream ER approaches are mainly limited
to flat structures, concentrating on the outermost entities while ignoring the
inner ones. This paper introduces a partly-layered network architecture that
deals with the complexity of overlapping and nested cases. The proposed
architecture consists of two parts: (1) a shared Sequence Layer and (2) a
stacked component with multiple Tagging Layers. The adoption of such an
architecture has the advantage of preventing overfit to a specific word-length,
thus maintaining performance for longer entities despite their lower frequency.
To verify the proposed architecture&#x27;s effectiveness, we train and evaluate this
architecture to recognise two kinds of entities - Concepts (CR) and Named
Entities (NER). Our approach achieves state-of-the-art NER performances, while
it outperforms previous CR approaches. Considering these promising results, we
see the possibility to evolve the architecture for other cases such as the
extraction of events or the detection of argumentative components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Complexity of Sparse Tensor PCA. (arXiv:2106.06308v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choo_D/0/1/0/all/0/1">Davin Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+dOrsi_T/0/1/0/all/0/1">Tommaso d&#x27;Orsi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06308">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of sparse tensor principal component analysis: given a
tensor $\pmb Y &#x3D; \pmb W + \lambda x^{\otimes p}$ with $\pmb W \in
\otimes^p\mathbb{R}^n$ having i.i.d. Gaussian entries, the goal is to recover
the $k$-sparse unit vector $x \in \mathbb{R}^n$. The model captures both sparse
PCA (in its Wigner form) and tensor PCA.

For the highly sparse regime of $k \leq \sqrt{n}$, we present a family of
algorithms that smoothly interpolates between a simple polynomial-time
algorithm and the exponential-time exhaustive search algorithm. For any $1 \leq
t \leq k$, our algorithms recovers the sparse vector for signal-to-noise ratio
$\lambda \geq \tilde{\mathcal{O}} (\sqrt{t} \cdot (k/t)^{p/2})$ in time
$\tilde{\mathcal{O}}(n^{p+t})$, capturing the state-of-the-art guarantees for
the matrix settings (in both the polynomial-time and sub-exponential time
regimes).

Our results naturally extend to the case of $r$ distinct $k$-sparse signals
with disjoint supports, with guarantees that are independent of the number of
spikes. Even in the restricted case of sparse PCA, known algorithms only
recover the sparse vectors for $\lambda \geq \tilde{\mathcal{O}}(k \cdot r)$
while our algorithms require $\lambda \geq \tilde{\mathcal{O}}(k)$.

Finally, by analyzing the low-degree likelihood ratio, we complement these
algorithmic results with rigorous evidence illustrating the trade-offs between
signal-to-noise ratio and running time. This lower bound captures the known
lower bounds for both sparse PCA and tensor PCA. In this general model, we
observe a more intricate three-way trade-off between the number of samples $n$,
the sparsity $k$, and the tensor power $p$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KRADA: Known-region-aware Domain Alignment for Open World Semantic Segmentation. (arXiv:2106.06237v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1">Chenhong Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gong_C/0/1/0/all/0/1">Chen Gong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheung_W/0/1/0/all/0/1">William Cheung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06237">
                                    <div class="article-summary-box-inner">
                                        <span>In semantic segmentation, we aim to train a pixel-level classifier to assign
category labels to all pixels in an image, where labeled training images and
unlabeled test images are from the same distribution and share the same label
set. However, in an open world, the unlabeled test images probably contain
unknown categories and have different distributions from the labeled images.
Hence, in this paper, we consider a new, more realistic, and more challenging
problem setting where the pixel-level classifier has to be trained with labeled
images and unlabeled open-world images -- we name it open world semantic
segmentation (OSS). In OSS, the trained classifier is expected to identify
unknown-class pixels and classify known-class pixels well. To solve OSS, we
first investigate which distribution that unknown-class pixels obey. Then,
motivated by the goodness-of-fit test, we use statistical measurements to show
how a pixel fits the distribution of an unknown class and select highly-fitted
pixels to form the unknown region in each image. Eventually, we propose an
end-to-end learning framework, known-region-aware domain alignment (KRADA), to
distinguish unknown classes while aligning distributions of known classes in
labeled and unlabeled open-world images. The effectiveness of KRADA has been
verified on two synthetic tasks and one COVID-19 segmentation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Approach to Lifelong Learning: The Plastic Support Structure. (arXiv:2106.06298v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kanaan_G/0/1/0/all/0/1">Georges Kanaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kai Wen Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fenaux_L/0/1/0/all/0/1">Lucas Fenaux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06298">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel approach to lifelong learning, introducing a compact
encapsulated support structure which endows a network with the capability to
expand its capacity as needed to learn new tasks while preventing the loss of
learned tasks. This is achieved by splitting neurons with high semantic drift
and constructing an adjacent network to encode the new tasks at hand. We call
this the Plastic Support Structure (PSS), it is a compact structure to learn
new tasks that cannot be efficiently encoded in the existing structure of the
network. We validate the PSS on public datasets against existing lifelong
learning architectures, showing it performs similarly to them but without prior
knowledge of the task and in some cases with fewer parameters and in a more
understandable fashion where the PSS is an encapsulated container for specific
features related to specific tasks, thus making it an ideal &quot;add-on&quot; solution
for endowing a network to learn more tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Courteous Behavior of Automated Vehicles at Unsignalized Intersections via Reinforcement Learning. (arXiv:2106.06369v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shengchao Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Welschehold_T/0/1/0/all/0/1">Tim Welschehold</a>, <a href="http://arxiv.org/find/cs/1/au:+Buscher_D/0/1/0/all/0/1">Daniel B&#xfc;scher</a>, <a href="http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1">Wolfram Burgard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06369">
                                    <div class="article-summary-box-inner">
                                        <span>The transition from today&#x27;s mostly human-driven traffic to a purely automated
one will be a gradual evolution, with the effect that we will likely experience
mixed traffic in the near future. Connected and automated vehicles can benefit
human-driven ones and the whole traffic system in different ways, for example
by improving collision avoidance and reducing traffic waves. Many studies have
been carried out to improve intersection management, a significant bottleneck
in traffic, with intelligent traffic signals or exclusively automated vehicles.
However, the problem of how to improve mixed traffic at unsignalized
intersections has received less attention. In this paper, we propose a novel
approach to optimizing traffic flow at intersections in mixed traffic
situations using deep reinforcement learning. Our reinforcement learning agent
learns a policy for a centralized controller to let connected autonomous
vehicles at unsignalized intersections give up their right of way and yield to
other vehicles to optimize traffic flow. We implemented our approach and tested
it in the traffic simulator SUMO based on simulated and real traffic data. The
experimental evaluation demonstrates that our method significantly improves
traffic flow through unsignalized intersections in mixed traffic settings and
also provides better performance on a wide range of traffic situations compared
to the state-of-the-art traffic signal controller for the corresponding
signalized intersection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework to Enhance Generalization of Deep Metric Learning methods using General Discriminative Feature Learning and Class Adversarial Neural Networks. (arXiv:2106.06420v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Kaabi_K/0/1/0/all/0/1">Karrar Al-Kaabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Monsefi_R/0/1/0/all/0/1">Reza Monsefi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabihzadeh_D/0/1/0/all/0/1">Davood Zabihzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06420">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning algorithms aim to learn a distance function that brings the
semantically similar data items together and keeps dissimilar ones at a
distance. The traditional Mahalanobis distance learning is equivalent to find a
linear projection. In contrast, Deep Metric Learning (DML) methods are proposed
that automatically extract features from data and learn a non-linear
transformation from input space to a semantically embedding space. Recently,
many DML methods are proposed focused to enhance the discrimination power of
the learned metric by providing novel sampling strategies or loss functions.
This approach is very helpful when both the training and test examples are
coming from the same set of categories. However, it is less effective in many
applications of DML such as image retrieval and person-reidentification. Here,
the DML should learn general semantic concepts from observed classes and employ
them to rank or identify objects from unseen categories. Neglecting the
generalization ability of the learned representation and just emphasizing to
learn a more discriminative embedding on the observed classes may lead to the
overfitting problem. To address this limitation, we propose a framework to
enhance the generalization power of existing DML methods in a Zero-Shot
Learning (ZSL) setting by general yet discriminative representation learning
and employing a class adversarial neural network. To learn a more general
representation, we propose to employ feature maps of intermediate layers in a
deep neural network and enhance their discrimination power through an attention
mechanism. Besides, a class adversarial network is utilized to enforce the deep
model to seek class invariant features for the DML task. We evaluate our work
on widely used machine vision datasets in a ZSL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation. (arXiv:2106.06326v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chi_H/0/1/0/all/0/1">Haoang Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenjing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_L/0/1/0/all/0/1">Long Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_W/0/1/0/all/0/1">William K. Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1">James T. Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06326">
                                    <div class="article-summary-box-inner">
                                        <span>In few-shot domain adaptation (FDA), classifiers for the target domain are
trained with accessible labeled data in the source domain (SD) and few labeled
data in the target domain (TD). However, data usually contain private
information in the current era, e.g., data distributed on personal phones.
Thus, the private information will be leaked if we directly access data in SD
to train a target-domain classifier (required by FDA methods). In this paper,
to thoroughly prevent the privacy leakage in SD, we consider a very challenging
problem setting, where the classifier for the TD has to be trained using few
labeled target data and a well-trained SD classifier, named few-shot hypothesis
adaptation (FHA). In FHA, we cannot access data in SD, as a result, the private
information in SD will be protected well. To this end, we propose a target
orientated hypothesis adaptation network (TOHAN) to solve the FHA problem,
where we generate highly-compatible unlabeled data (i.e., an intermediate
domain) to help train a target-domain classifier. TOHAN maintains two deep
networks simultaneously, where one focuses on learning an intermediate domain
and the other takes care of the intermediate-to-target distributional
adaptation and the target-risk minimization. Experimental results show that
TOHAN outperforms competitive baselines significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Risk Adaptation in Distributional Reinforcement Learning. (arXiv:2106.06317v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schubert_F/0/1/0/all/0/1">Frederik Schubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1">Theresa Eimer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1">Marius Lindauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06317">
                                    <div class="article-summary-box-inner">
                                        <span>The use of Reinforcement Learning (RL) agents in practical applications
requires the consideration of suboptimal outcomes, depending on the familiarity
of the agent with its environment. This is especially important in
safety-critical environments, where errors can lead to high costs or damage. In
distributional RL, the risk-sensitivity can be controlled via different
distortion measures of the estimated return distribution. However, these
distortion functions require an estimate of the risk level, which is difficult
to obtain and depends on the current state. In this work, we demonstrate the
suboptimality of a static risk level estimation and propose a method to
dynamically select risk levels at each environment step. Our method ARA
(Automatic Risk Adaptation) estimates the appropriate risk level in both known
and unknown environments using a Random Network Distillation error. We show
reduced failure rates by up to a factor of 7 and improved generalization
performance by up to 14% compared to both risk-aware and risk-agnostic agents
in several locomotion environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GDI: Rethinking What Makes Reinforcement Learning Different From Supervised Learning. (arXiv:2106.06232v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jiajun Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Changnan Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yue Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06232">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Q Network (DQN) firstly kicked the door of deep reinforcement learning
(DRL) via combining deep learning (DL) with reinforcement learning (RL), which
has noticed that the distribution of the acquired data would change during the
training process. DQN found this property might cause instability for training,
so it proposed effective methods to handle the downside of the property.
Instead of focusing on the unfavourable aspects, we find it critical for RL to
ease the gap between the estimated data distribution and the ground truth data
distribution while supervised learning (SL) fails to do so. From this new
perspective, we extend the basic paradigm of RL called the Generalized Policy
Iteration (GPI) into a more generalized version, which is called the
Generalized Data Distribution Iteration (GDI). We see massive RL algorithms and
techniques can be unified into the GDI paradigm, which can be considered as one
of the special cases of GDI. We provide theoretical proof of why GDI is better
than GPI and how it works. Several practical algorithms based on GDI have been
proposed to verify the effectiveness and extensiveness of it. Empirical
experiments prove our state-of-the-art (SOTA) performance on Arcade Learning
Environment (ALE), wherein our algorithm has achieved 9620.98% mean human
normalized score (HNS), 1146.39% median HNS and 22 human world record
breakthroughs (HWRB) using only 200 training frames. Our work aims to lead the
RL research to step into the journey of conquering the human world records and
seek real superhuman agents on both performance and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Selection for Bayesian Autoencoders. (arXiv:2106.06245v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tran_B/0/1/0/all/0/1">Ba-Hien Tran</a>, <a href="http://arxiv.org/find/stat/1/au:+Rossi_S/0/1/0/all/0/1">Simone Rossi</a>, <a href="http://arxiv.org/find/stat/1/au:+Milios_D/0/1/0/all/0/1">Dimitrios Milios</a>, <a href="http://arxiv.org/find/stat/1/au:+Michiardi_P/0/1/0/all/0/1">Pietro Michiardi</a>, <a href="http://arxiv.org/find/stat/1/au:+Bonilla_E/0/1/0/all/0/1">Edwin V. Bonilla</a>, <a href="http://arxiv.org/find/stat/1/au:+Filippone_M/0/1/0/all/0/1">Maurizio Filippone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06245">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a novel method for carrying out model selection for Bayesian
autoencoders (BAEs) by means of prior hyper-parameter optimization. Inspired by
the common practice of type-II maximum likelihood optimization and its
equivalence to Kullback-Leibler divergence minimization, we propose to optimize
the distributional sliced-Wasserstein distance (DSWD) between the output of the
autoencoder and the empirical data distribution. The advantages of this
formulation are that we can estimate the DSWD based on samples and handle
high-dimensional problems. We carry out posterior estimation of the BAE
parameters via stochastic gradient Hamiltonian Monte Carlo and turn our BAE
into a generative model by fitting a flexible Dirichlet mixture model in the
latent space. Consequently, we obtain a powerful alternative to variational
autoencoders, which are the preferred choice in modern applications of
autoencoders for representation learning with uncertainty. We evaluate our
approach qualitatively and quantitatively using a vast experimental campaign on
a number of unsupervised learning tasks and show that, in small-data regimes
where priors matter, our approach provides state-of-the-art results,
outperforming multiple competitive baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DG-LMC: A Turn-key and Scalable Synchronous Distributed MCMC Algorithm. (arXiv:2106.06300v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Plassier_V/0/1/0/all/0/1">Vincent Plassier</a>, <a href="http://arxiv.org/find/stat/1/au:+Vono_M/0/1/0/all/0/1">Maxime Vono</a>, <a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1">Alain Durmus</a>, <a href="http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1">Eric Moulines</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06300">
                                    <div class="article-summary-box-inner">
                                        <span>Performing reliable Bayesian inference on a big data scale is becoming a
keystone in the modern era of machine learning. A workhorse class of methods to
achieve this task are Markov chain Monte Carlo (MCMC) algorithms and their
design to handle distributed datasets has been the subject of many works.
However, existing methods are not completely either reliable or computationally
efficient. In this paper, we propose to fill this gap in the case where the
dataset is partitioned and stored on computing nodes within a cluster under a
master/slaves architecture. We derive a user-friendly centralised distributed
MCMC algorithm with provable scaling in high-dimensional settings. We
illustrate the relevance of the proposed methodology on both synthetic and real
data experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Reinforcement Learning with Linear Function Approximation. (arXiv:2106.06239v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amani_S/0/1/0/all/0/1">Sanae Amani</a>, <a href="http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1">Christos Thrampoulidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06239">
                                    <div class="article-summary-box-inner">
                                        <span>Safety in reinforcement learning has become increasingly important in recent
years. Yet, existing solutions either fail to strictly avoid choosing unsafe
actions, which may lead to catastrophic results in safety-critical systems, or
fail to provide regret guarantees for settings where safety constraints need to
be learned. In this paper, we address both problems by first modeling safety as
an unknown linear cost function of states and actions, which must always fall
below a certain threshold. We then present algorithms, termed SLUCB-QVI and
RSLUCB-QVI, for episodic Markov decision processes (MDPs) with linear function
approximation. We show that SLUCB-QVI and RSLUCB-QVI, while with \emph{no
safety violation}, achieve a
$\tilde{\mathcal{O}}\left(\kappa\sqrt{d^3H^3T}\right)$ regret, nearly matching
that of state-of-the-art unsafe algorithms, where $H$ is the duration of each
episode, $d$ is the dimension of the feature mapping, $\kappa$ is a constant
characterizing the safety constraints, and $T$ is the total number of action
plays. We further present numerical simulations that corroborate our
theoretical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TrafficStream: A Streaming Traffic Flow Forecasting Framework Based on Graph Neural Networks and Continual Learning. (arXiv:2106.06273v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Junshan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1">Kunqing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06273">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid growth of traffic sensors deployed, a massive amount of
traffic flow data are collected, revealing the long-term evolution of traffic
flows and the gradual expansion of traffic networks. How to accurately
forecasting these traffic flow attracts the attention of researchers as it is
of great significance for improving the efficiency of transportation systems.
However, existing methods mainly focus on the spatial-temporal correlation of
static networks, leaving the problem of efficiently learning models on networks
with expansion and evolving patterns less studied. To tackle this problem, we
propose a Streaming Traffic Flow Forecasting Framework, TrafficStream, based on
Graph Neural Networks (GNNs) and Continual Learning (CL), achieving accurate
predictions and high efficiency. Firstly, we design a traffic pattern fusion
method, cleverly integrating the new patterns that emerged during the long-term
period into the model. A JS-divergence-based algorithm is proposed to mine new
traffic patterns. Secondly, we introduce CL to consolidate the knowledge
learned previously and transfer them to the current model. Specifically, we
adopt two strategies: historical data replay and parameter smoothing. We
construct a streaming traffic dataset to verify the efficiency and
effectiveness of our model. Extensive experiments demonstrate its excellent
potential to extract traffic patterns with high efficiency on long-term
streaming network scene. The source code is available at
https://github.com/AprLie/TrafficStream.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LocoProp: Enhancing BackProp via Local Loss Optimization. (arXiv:2106.06199v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amid_E/0/1/0/all/0/1">Ehsan Amid</a>, <a href="http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1">Rohan Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Warmuth_M/0/1/0/all/0/1">Manfred K. Warmuth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06199">
                                    <div class="article-summary-box-inner">
                                        <span>We study a local loss construction approach for optimizing neural networks.
We start by motivating the problem as minimizing a squared loss between the
pre-activations of each layer and a local target, plus a regularizer term on
the weights. The targets are chosen so that the first gradient descent step on
the local objectives recovers vanilla BackProp, while the exact solution to
each problem results in a preconditioned gradient update. We improve the local
loss construction by forming a Bregman divergence in each layer tailored to the
transfer function which keeps the local problem convex w.r.t. the weights. The
generalized local problem is again solved iteratively by taking small gradient
descent steps on the weights, for which the first step recovers BackProp. We
run several ablations and show that our construction consistently improves
convergence, reducing the gap between first-order and second-order methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Probabilistic Koopman: Long-term time-series forecasting under periodic uncertainties. (arXiv:2106.06033v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1">Alex Mallen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lange_H/0/1/0/all/0/1">Henning Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1">J. Nathan Kutz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06033">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic forecasting of complex phenomena is paramount to various
scientific disciplines and applications. Despite the generality and importance
of the problem, general mathematical techniques that allow for stable long-term
forecasts with calibrated uncertainty measures are lacking. For most time
series models, the difficulty of obtaining accurate probabilistic future time
step predictions increases with the prediction horizon. In this paper, we
introduce a surprisingly simple approach that characterizes time-varying
distributions and enables reasonably accurate predictions thousands of
timesteps into the future. This technique, which we call Deep Probabilistic
Koopman (DPK), is based on recent advances in linear Koopman operator theory,
and does not require time stepping for future time predictions. Koopman models
also tend to have a small parameter footprint (often less than 10,000
parameters). We demonstrate the long-term forecasting performance of these
models on a diversity of domains, including electricity demand forecasting,
atmospheric chemistry, and neuroscience. For electricity demand modeling, our
domain-agnostic technique outperforms all of 177 domain-specific competitors in
the most recent Global Energy Forecasting Competition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Pool in Graph Neural Networks for Extrapolation. (arXiv:2106.06210v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ko_J/0/1/0/all/0/1">Jihoon Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1">Taehyung Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1">Kijung Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06210">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) are one of the most popular approaches to using
deep learning on graph-structured data, and they have shown state-of-the-art
performances on a variety of tasks. However, according to a recent study, a
careful choice of pooling functions, which are used for the aggregation or
readout operation in GNNs, is crucial for enabling GNNs to extrapolate. Without
the ideal combination of pooling functions, which varies across tasks, GNNs
completely fail to generalize to out-of-distribution data, while the number of
possible combinations grows exponentially with the number of layers. In this
paper, we present GNP, a $L^p$ norm-like pooling function that is trainable
end-to-end for any given task. Notably, GNP generalizes most of the widely-used
pooling functions. We verify experimentally that simply replacing all pooling
functions with GNP enables GNNs to extrapolate well on many node-level,
graph-level, and set-related tasks; and GNP sometimes performs even better than
optimal combinations of existing pooling functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Taylor Expansion of Discount Factors. (arXiv:2106.06170v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yunhao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rowland_M/0/1/0/all/0/1">Mark Rowland</a>, <a href="http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1">R&#xe9;mi Munos</a>, <a href="http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1">Michal Valko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06170">
                                    <div class="article-summary-box-inner">
                                        <span>In practical reinforcement learning (RL), the discount factor used for
estimating value functions often differs from that used for defining the
evaluation objective. In this work, we study the effect that this discrepancy
of discount factors has during learning, and discover a family of objectives
that interpolate value functions of two distinct discount factors. Our analysis
suggests new ways for estimating value functions and performing policy
optimization updates, which demonstrate empirical performance gains. This
framework also leads to new insights on commonly-used deep RL heuristic
modifications to policy optimization algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial purification with Score-based generative models. (arXiv:2106.06041v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jongmin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06041">
                                    <div class="article-summary-box-inner">
                                        <span>While adversarial training is considered as a standard defense method against
adversarial attacks for image classifiers, adversarial purification, which
purifies attacked images into clean images with a standalone purification
model, has shown promises as an alternative defense method. Recently, an
Energy-Based Model (EBM) trained with Markov-Chain Monte-Carlo (MCMC) has been
highlighted as a purification model, where an attacked image is purified by
running a long Markov-chain using the gradients of the EBM. Yet, the
practicality of the adversarial purification using an EBM remains questionable
because the number of MCMC steps required for such purification is too large.
In this paper, we propose a novel adversarial purification method based on an
EBM trained with Denoising Score-Matching (DSM). We show that an EBM trained
with DSM can quickly purify attacked images within a few steps. We further
introduce a simple yet effective randomized purification scheme that injects
random noises into images before purification. This process screens the
adversarial perturbations imposed on images by the random noises and brings the
images to the regime where the EBM can denoise well. We show that our
purification method is robust against various attacks and demonstrate its
state-of-the-art performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing the Effectiveness of Syntactic Structure to Learn Code Edit Representations. (arXiv:2106.06110v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qureshi_S/0/1/0/all/0/1">Syed Arbaaz Qureshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1">Sonu Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhagwan_R/0/1/0/all/0/1">Ranjita Bhagwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Rahul Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06110">
                                    <div class="article-summary-box-inner">
                                        <span>In recent times, it has been shown that one can use code as data to aid
various applications such as automatic commit message generation, automatic
generation of pull request descriptions and automatic program repair. Take for
instance the problem of commit message generation. Treating source code as a
sequence of tokens, state of the art techniques generate commit messages using
neural machine translation models. However, they tend to ignore the syntactic
structure of programming languages.

Previous work, i.e., code2seq has used structural information from Abstract
Syntax Tree (AST) to represent source code and they use it to automatically
generate method names. In this paper, we elaborate upon this state of the art
approach and modify it to represent source code edits. We determine the effect
of using such syntactic structure for the problem of classifying code edits.
Inspired by the code2seq approach, we evaluate how using structural information
from AST, i.e., paths between AST leaf nodes can help with the task of code
edit classification on two datasets of fine-grained syntactic edits.

Our experiments shows that attempts of adding syntactic structure does not
result in any improvements over less sophisticated methods. The results suggest
that techniques such as code2seq, while promising, have a long way to go before
they can be generically applied to learning code edit representations. We hope
that these results will benefit other researchers and inspire them to work
further on this problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Optimization Kernel: Towards Robust Deep Learning. (arXiv:2106.06097v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lyu_Y/0/1/0/all/0/1">Yueming Lyu</a>, <a href="http://arxiv.org/find/stat/1/au:+Tsang_I/0/1/0/all/0/1">Ivor Tsang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06097">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies show a close connection between neural networks (NN) and
kernel methods. However, most of these analyses (e.g., NTK) focus on the
influence of (infinite) width instead of the depth of NN models. There remains
a gap between theory and practical network designs that benefit from the depth.
This paper first proposes a novel kernel family named Neural Optimization
Kernel (NOK). Our kernel is defined as the inner product between two $T$-step
updated functionals in RKHS w.r.t. a regularized optimization problem.
Theoretically, we proved the monotonic descent property of our update rule for
both convex and non-convex problems, and a $O(1/T)$ convergence rate of our
updates for convex problems. Moreover, we propose a data-dependent structured
approximation of our NOK, which builds the connection between training deep NNs
and kernel methods associated with NOK. The resultant computational graph is a
ResNet-type finite width NN. Our structured approximation preserved the
monotonic descent property and $O(1/T)$ convergence rate. Namely, a $T$-layer
NN performs $T$-step monotonic descent updates. Notably, we show our
$T$-layered structured NN with ReLU maintains a $O(1/T)$ convergence rate
w.r.t. a convex regularized problem, which explains the success of ReLU on
training deep NN from a NN architecture optimization perspective. For the
unsupervised learning and the shared parameter case, we show the equivalence of
training structured NN with GD and performing functional gradient descent in
RKHS associated with a fixed (data-dependent) NOK at an infinity-width regime.
For finite NOKs, we prove generalization bounds. Remarkably, we show that
overparameterized deep NN (NOK) can increase the expressive power to reduce
empirical risk and reduce the generalization bound at the same time. Extensive
experiments verify the robustness of our structured NOK blocks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HIFI: Anomaly Detection for Multivariate Time Series with High-order Feature Interactions. (arXiv:2106.06167v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Liwei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuanhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1">Kai Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06167">
                                    <div class="article-summary-box-inner">
                                        <span>Monitoring complex systems results in massive multivariate time series data,
and anomaly detection of these data is very important to maintain the normal
operation of the systems. Despite the recent emergence of a large number of
anomaly detection algorithms for multivariate time series, most of them ignore
the correlation modeling among multivariate, which can often lead to poor
anomaly detection results. In this work, we propose a novel anomaly detection
model for multivariate time series with \underline{HI}gh-order
\underline{F}eature \underline{I}nteractions (HIFI). More specifically, HIFI
builds multivariate feature interaction graph automatically and uses the graph
convolutional neural network to achieve high-order feature interactions, in
which the long-term temporal dependencies are modeled by attention mechanisms
and a variational encoding technique is utilized to improve the model
performance and robustness. Extensive experiments on three publicly available
datasets demonstrate the superiority of our framework compared with
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the Precise Feature for Cluster Assignment. (arXiv:2106.06159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1">Yanhai Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xinghui Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1">Feng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Junyu Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06159">
                                    <div class="article-summary-box-inner">
                                        <span>Clustering is one of the fundamental tasks in computer vision and pattern
recognition. Recently, deep clustering methods (algorithms based on deep
learning) have attracted wide attention with their impressive performance. Most
of these algorithms combine deep unsupervised representation learning and
standard clustering together. However, the separation of representation
learning and clustering will lead to suboptimal solutions because the two-stage
strategy prevents representation learning from adapting to subsequent tasks
(e.g., clustering according to specific cues). To overcome this issue, efforts
have been made in the dynamic adaption of representation and cluster
assignment, whereas current state-of-the-art methods suffer from heuristically
constructed objectives with representation and cluster assignment alternatively
optimized. To further standardize the clustering problem, we audaciously
formulate the objective of clustering as finding a precise feature as the cue
for cluster assignment. Based on this, we propose a general-purpose deep
clustering framework which radically integrates representation learning and
clustering into a single pipeline for the first time. The proposed framework
exploits the powerful ability of recently developed generative models for
learning intrinsic features, and imposes an entropy minimization on the
distribution of the cluster assignment by a dedicated variational algorithm.
Experimental results show that the performance of the proposed method is
superior, or at least comparable to, the state-of-the-art methods on the
handwritten digit recognition, fashion recognition, face recognition and object
recognition benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Generative-Contrastive Representation Learning. (arXiv:2106.06162v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Saehoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungwoong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06162">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised representation learning has recently received lots of interest
due to its powerful generalizability through effectively leveraging large-scale
unlabeled data. There are two prevalent approaches for this, contrastive
learning and generative pre-training, where the former learns representations
from instance-wise discrimination tasks and the latter learns them from
estimating the likelihood. These seemingly orthogonal approaches have their own
strengths and weaknesses. Contrastive learning tends to extract semantic
information and discards details irrelevant for classifying objects, making the
representations effective for discriminative tasks while degrading robustness
to out-of-distribution data. On the other hand, the generative pre-training
directly estimates the data distribution, so the representations tend to be
robust but not optimal for discriminative tasks. In this paper, we show that we
could achieve the best of both worlds by a hybrid training scheme.
Specifically, we demonstrated that a transformer-based encoder-decoder
architecture trained with both contrastive and generative losses can learn
highly discriminative and robust representations without hurting the generative
performance. We extensively validate our approach on various tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Homophily a Necessity for Graph Neural Networks?. (arXiv:2106.06134v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Neil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06134">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have shown great prowess in learning
representations suitable for numerous graph-based machine learning tasks. When
applied to semi-supervised node classification, GNNs are widely believed to
work well due to the homophily assumption (&#x60;&#x60;like attracts like&#x27;&#x27;), and fail to
generalize to heterophilous graphs where dissimilar nodes connect. Recent works
design new architectures to overcome such heterophily-related limitations,
citing poor baseline performance and new architecture improvements on a few
heterophilous graph benchmark datasets as evidence for this notion. In our
experiments, we empirically find that standard graph convolutional networks
(GCNs) can actually achieve better performance than such carefully designed
methods on some commonly used heterophilous graphs. This motivates us to
reconsider whether homophily is truly necessary for good GNN performance. We
find that this claim is not quite true, and in fact, GCNs can achieve strong
performance on heterophilous graphs under certain conditions. Our work
carefully characterizes these conditions, and provides supporting theoretical
understanding and empirical observations. Finally, we examine existing
heterophilous graphs benchmarks and reconcile how the GCN (under)performs on
them based on this understanding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NAAQA: A Neural Architecture for Acoustic Question Answering. (arXiv:2106.06147v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdelnour_J/0/1/0/all/0/1">Jerome Abdelnour</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouat_J/0/1/0/all/0/1">Jean Rouat</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvi_G/0/1/0/all/0/1">Giampiero Salvi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06147">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of the Acoustic Question Answering (AQA) task is to answer a
free-form text question about the content of an acoustic scene. It was inspired
by the Visual Question Answering (VQA) task. In this paper, based on the
previously introduced CLEAR dataset, we propose a new benchmark for AQA that
emphasizes the specific challenges of acoustic inputs, e.g. variable duration
scenes. We also introduce NAAQA, a neural architecture that leverages specific
properties of acoustic inputs. The usage of time and frequency 1D convolutions
to process 2D spectro-temporal representations of acoustic content shows
promising results and enables reductions in model complexity. NAAQA achieves
91.6% of accuracy on the AQA task with about 7 times fewer parameters than the
previously explored VQA model. We provide a detailed analysis of the results
for the different question types. The effectiveness of coordinate maps in this
acoustic context was also studied and we show that time coordinate maps augment
temporal localization capabilities which enhance performance of the network by
about 17 percentage points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generate, Annotate, and Learn: Generative Models Advance Self-Training and Knowledge Distillation. (arXiv:2106.06168v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xuanli He</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassar_I/0/1/0/all/0/1">Islam Nassar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiros_J/0/1/0/all/0/1">Jamie Kiros</a>, <a href="http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1">Gholamreza Haffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06168">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-Supervised Learning (SSL) has seen success in many application domains,
but this success often hinges on the availability of task-specific unlabeled
data. Knowledge distillation (KD) has enabled compressing deep networks and
ensembles, achieving the best results when distilling knowledge on fresh
task-specific unlabeled examples. However, task-specific unlabeled data can be
challenging to find. We present a general framework called &quot;generate, annotate,
and learn (GAL)&quot; that uses unconditional generative models to synthesize
in-domain unlabeled data, helping advance SSL and KD on different tasks. To
obtain strong task-specific generative models, we adopt generic generative
models, pretrained on open-domain data, and fine-tune them on inputs from
specific tasks. Then, we use existing classifiers to annotate generated
unlabeled examples with soft pseudo labels, which are used for additional
training. When self-training is combined with samples generated from
GPT2-large, fine-tuned on the inputs of each GLUE task, we outperform a strong
RoBERTa-large baseline on the GLUE benchmark. Moreover, KD on GPT-2 samples
yields a new state-of-the-art for 6-layer transformers on the GLUE leaderboard.
Finally, self-training with GAL offers significant gains on image
classification on CIFAR-10 and four tabular tasks from the UCI repository</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning. (arXiv:2106.06135v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1">Daochen Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jingru Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wenye Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1">Xiangru Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Ji Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06135">
                                    <div class="article-summary-box-inner">
                                        <span>Games are abstractions of the real world, where artificial agents learn to
compete and cooperate with other agents. While significant achievements have
been made in various perfect- and imperfect-information games, DouDizhu (a.k.a.
Fighting the Landlord), a three-player card game, is still unsolved. DouDizhu
is a very challenging domain with competition, collaboration, imperfect
information, large state space, and particularly a massive set of possible
actions where the legal actions vary significantly from turn to turn.
Unfortunately, modern reinforcement learning algorithms mainly focus on simple
and small action spaces, and not surprisingly, are shown not to make
satisfactory progress in DouDizhu. In this work, we propose a conceptually
simple yet effective DouDizhu AI system, namely DouZero, which enhances
traditional Monte-Carlo methods with deep neural networks, action encoding, and
parallel actors. Starting from scratch in a single server with four GPUs,
DouZero outperformed all the existing DouDizhu AI programs in days of training
and was ranked the first in the Botzone leaderboard among 344 AI agents.
Through building DouZero, we show that classic Monte-Carlo methods can be made
to deliver strong results in a hard domain with a complex action space. The
code and an online demo are released at https://github.com/kwai/DouZero with
the hope that this insight could motivate future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomalous Sound Detection Using a Binary Classification Model and Class Centroids. (arXiv:2106.06151v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuroyanagi_I/0/1/0/all/0/1">Ibuki Kuroyanagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_T/0/1/0/all/0/1">Tomoki Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1">Kazuya Takeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1">Tomoki Toda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06151">
                                    <div class="article-summary-box-inner">
                                        <span>An anomalous sound detection system to detect unknown anomalous sounds
usually needs to be built using only normal sound data. Moreover, it is
desirable to improve the system by effectively using a small amount of
anomalous sound data, which will be accumulated through the system&#x27;s operation.
As one of the methods to meet these requirements, we focus on a binary
classification model that is developed by using not only normal data but also
outlier data in the other domains as pseudo-anomalous sound data, which can be
easily updated by using anomalous data. In this paper, we implement a new loss
function based on metric learning to learn the distance relationship from each
class centroid in feature space for the binary classification model. The
proposed multi-task learning of the binary classification and the metric
learning makes it possible to build the feature space where the within-class
variance is minimized and the between-class variance is maximized while keeping
normal and anomalous classes linearly separable. We also investigate the
effectiveness of additionally using anomalous sound data for further improving
the binary classification model. Our results showed that multi-task learning
using binary classification and metric learning to consider the distance from
each class centroid in the feature space is effective, and performance can be
significantly improved by using even a small amount of anomalous data during
training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyGAD: An Intuitive Genetic Algorithm Python Library. (arXiv:2106.06158v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gad_A/0/1/0/all/0/1">Ahmed Fawzy Gad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06158">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces PyGAD, an open-source easy-to-use Python library for
building the genetic algorithm. PyGAD supports a wide range of parameters to
give the user control over everything in its life cycle. This includes, but is
not limited to, population, gene value range, gene data type, parent selection,
crossover, and mutation. PyGAD is designed as a general-purpose optimization
library that allows the user to customize the fitness function. Its usage
consists of 3 main steps: build the fitness function, create an instance of the
pygad.GA class, and calling the pygad.GA.run() method. The library supports
training deep learning models created either with PyGAD itself or with
frameworks like Keras and PyTorch. Given its stable state, PyGAD is also in
active development to respond to the user&#x27;s requested features and enhancement
received on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD
comes with documentation https://pygad.readthedocs.io for further details and
examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comprehensive solution to retrieval-based chatbot construction. (arXiv:2106.06139v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moore_K/0/1/0/all/0/1">Kristen Moore</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1">Shenjun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhen He</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudolf_T/0/1/0/all/0/1">Torsten Rudolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisher_N/0/1/0/all/0/1">Nils Fisher</a>, <a href="http://arxiv.org/find/cs/1/au:+Victor_B/0/1/0/all/0/1">Brandon Victor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jindal_N/0/1/0/all/0/1">Neha Jindal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06139">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present the results of our experiments in training and
deploying a self-supervised retrieval-based chatbot trained with contrastive
learning for assisting customer support agents. In contrast to most existing
research papers in this area where the focus is on solving just one component
of a deployable chatbot, we present an end-to-end set of solutions to take the
reader from an unlabelled chatlogs to a deployed chatbot. This set of solutions
includes creating a self-supervised dataset and a weakly labelled dataset from
chatlogs, as well as a systematic approach to selecting a fixed list of canned
responses. We present a hierarchical-based RNN architecture for the response
selection model, chosen for its ability to cache intermediate utterance
embeddings, which helped to meet deployment inference speed requirements. We
compare the performance of this architecture across 3 different learning
objectives: self-supervised contrastive learning, binary classification, and
multi-class classification. We find that using a self-supervised contrastive
learning model outperforms training the binary and multi-class classification
models on a weakly labelled dataset. Our results validate that the
self-supervised contrastive learning approach can be effectively used for a
real-world chatbot scenario.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DORO: Distributional and Outlier Robust Optimization. (arXiv:2106.06142v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_R/0/1/0/all/0/1">Runtian Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_C/0/1/0/all/0/1">Chen Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1">J. Zico Kolter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06142">
                                    <div class="article-summary-box-inner">
                                        <span>Many machine learning tasks involve subpopulation shift where the testing
data distribution is a subpopulation of the training distribution. For such
settings, a line of recent work has proposed the use of a variant of empirical
risk minimization(ERM) known as distributionally robust optimization (DRO). In
this work, we apply DRO to real, large-scale tasks with subpopulation shift,
and observe that DRO performs relatively poorly, and moreover has severe
instability. We identify one direct cause of this phenomenon: sensitivity of
DRO to outliers in the datasets. To resolve this issue, we propose the
framework of DORO, for Distributional and Outlier Robust Optimization. At the
core of this approach is a refined risk function which prevents DRO from
overfitting to potential outliers. We instantiate DORO for the Cressie-Read
family of R\&#x27;enyi divergence, and delve into two specific instances of this
family: CVaR and $\chi^2$-DRO. We theoretically prove the effectiveness of the
proposed method, and empirically show that DORO improves the performance and
stability of DRO with experiments on large modern datasets, thereby positively
addressing the open question raised by Hashimoto et al., 2018.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse Bayesian Learning via Stepwise Regression. (arXiv:2106.06095v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ament_S/0/1/0/all/0/1">Sebastian Ament</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1">Carla Gomes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06095">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse Bayesian Learning (SBL) is a powerful framework for attaining sparsity
in probabilistic models. Herein, we propose a coordinate ascent algorithm for
SBL termed Relevance Matching Pursuit (RMP) and show that, as its noise
variance parameter goes to zero, RMP exhibits a surprising connection to
Stepwise Regression. Further, we derive novel guarantees for Stepwise
Regression algorithms, which also shed light on RMP. Our guarantees for Forward
Regression improve on deterministic and probabilistic results for Orthogonal
Matching Pursuit with noise. Our analysis of Backward Regression on determined
systems culminates in a bound on the residual of the optimal solution to the
subset selection problem that, if satisfied, guarantees the optimality of the
result. To our knowledge, this bound is the first that can be computed in
polynomial time and depends chiefly on the smallest singular value of the
matrix. We report numerical experiments using a variety of feature selection
algorithms. Notably, RMP and its limiting variant are both efficient and
maintain strong performance with correlated features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Performance FPGA-based Accelerator for Bayesian Recurrent Neural Networks. (arXiv:2106.06048v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1">Martin Ferianc</a>, <a href="http://arxiv.org/find/cs/1/au:+Que_Z/0/1/0/all/0/1">Zhiqiang Que</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Hongxiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luk_W/0/1/0/all/0/1">Wayne Luk</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1">Miguel Rodrigues</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06048">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have demonstrated their great performance in a wide range of
tasks. Especially in time-series analysis, recurrent architectures based on
long-short term memory (LSTM) cells have manifested excellent capability to
model time dependencies in real-world data. However, standard recurrent
architectures cannot estimate their uncertainty which is essential for
safety-critical applications such as in medicine. In contrast, Bayesian
recurrent neural networks (RNNs) are able to provide uncertainty estimation
with improved accuracy. Nonetheless, Bayesian RNNs are computationally and
memory demanding, which limits their practicality despite their advantages. To
address this issue, we propose an FPGA-based hardware design to accelerate
Bayesian LSTM-based RNNs. To further improve the overall algorithmic-hardware
performance, a co-design framework is proposed to explore the most optimal
algorithmic-hardware configurations for Bayesian RNNs. We conduct extensive
experiments on health-related tasks to demonstrate the improvement of our
design and the effectiveness of our framework. Compared with GPU
implementation, our FPGA-based design can achieve up to 10 times speedup with
nearly 106 times higher energy efficiency. To the best of our knowledge, this
is the first work targeting the acceleration of Bayesian RNNs on FPGAs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance-Level Task Parameters: A Robust Multi-task Weighting Framework. (arXiv:2106.06129v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasu_P/0/1/0/all/0/1">Pavan Kumar Anasosalu Vasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1">Shreyas Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuzel_O/0/1/0/all/0/1">Oncel Tuzel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06129">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have shown that deep neural networks benefit from multi-task
learning by learning a shared representation across several related tasks.
However, performance of such systems depend on relative weighting between
various losses involved during training. Prior works on loss weighting schemes
assume that instances are equally easy or hard for all tasks. In order to break
this assumption, we let the training process dictate the optimal weighting of
tasks for every instance in the dataset. More specifically, we equip every
instance in the dataset with a set of learnable parameters (instance-level task
parameters) where the cardinality is equal to the number of tasks learned by
the model. These parameters model the weighting of each task for an instance.
They are updated by gradient descent and do not require hand-crafted rules. We
conduct extensive experiments on SURREAL and CityScapes datasets, for human
shape and pose estimation, depth estimation and semantic segmentation tasks. In
these tasks, our approach outperforms recent dynamic loss weighting approaches,
e.g. reducing surface estimation errors by 8.97% on SURREAL. When applied to
datasets where one or more tasks can have noisy annotations, the proposed
method learns to prioritize learning from clean labels for a given task, e.g.
reducing surface estimation errors by up to 60%. We also show that we can
reliably detect corrupt labels for a given task as a by-product from learned
instance-level task parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Adaptive Nonlinear Control: Theory and Algorithms. (arXiv:2106.06098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1">Guanya Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1">Kamyar Azizzadenesheli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1">Soon-Jo Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06098">
                                    <div class="article-summary-box-inner">
                                        <span>We present an online multi-task learning approach for adaptive nonlinear
control, which we call Online Meta-Adaptive Control (OMAC). The goal is to
control a nonlinear system subject to adversarial disturbance and unknown
$\textit{environment-dependent}$ nonlinear dynamics, under the assumption that
the environment-dependent dynamics can be well captured with some shared
representation. Our approach is motivated by robot control, where a robotic
system encounters a sequence of new environmental conditions that it must
quickly adapt to. A key emphasis is to integrate online representation learning
with established methods from control theory, in order to arrive at a unified
framework that yields both control-theoretic and learning-theoretic guarantees.
We provide instantiations of our approach under varying conditions, leading to
the first non-asymptotic end-to-end convergence guarantee for multi-task
adaptive nonlinear control. OMAC can also be integrated with deep
representation learning. Experiments show that OMAC significantly outperforms
conventional adaptive control approaches which do not learn the shared
representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially Private Federated Learning via Inexact ADMM. (arXiv:2106.06127v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ryu_M/0/1/0/all/0/1">Minseok Ryu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kibaek Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06127">
                                    <div class="article-summary-box-inner">
                                        <span>Differential privacy (DP) techniques can be applied to the federated learning
model to protect data privacy against inference attacks to communication among
the learning agents. The DP techniques, however, hinder achieving a greater
learning performance while ensuring strong data privacy. In this paper we
develop a DP inexact alternating direction method of multipliers algorithm that
solves a sequence of trust-region subproblems with the objective perturbation
by random noises generated from a Laplace distribution. We show that our
algorithm provides $\bar{\epsilon}$-DP for every iteration and
$\mathcal{O}(1/T)$ rate of convergence in expectation, where $T$ is the number
of iterations. Using MNIST and FEMNIST datasets for the image classification,
we demonstrate that our algorithm reduces the testing error by at most $22\%$
compared with the existing DP algorithm, while achieving the same level of data
privacy. The numerical experiment also shows that our algorithm converges
faster than the existing algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monotonic Neural Network: combining Deep Learning with Domain Knowledge for Chiller Plants Energy Optimization. (arXiv:2106.06143v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ma_F/0/1/0/all/0/1">Fanhe Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1">Faen Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Ben_S/0/1/0/all/0/1">Shenglan Ben</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_S/0/1/0/all/0/1">Shuxin Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_P/0/1/0/all/0/1">Pengcheng Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_C/0/1/0/all/0/1">Changsheng Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_F/0/1/0/all/0/1">Fengyi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06143">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we are interested in building a domain knowledge based deep
learning framework to solve the chiller plants energy optimization problems.
Compared to the hotspot applications of deep learning (e.g. image
classification and NLP), it is difficult to collect enormous data for deep
network training in real-world physical systems. Most existing methods reduce
the complex systems into linear model to facilitate the training on small
samples. To tackle the small sample size problem, this paper considers domain
knowledge in the structure and loss design of deep network to build a nonlinear
model with lower redundancy function space. Specifically, the energy
consumption estimation of most chillers can be physically viewed as an
input-output monotonic problem. Thus, we can design a Neural Network with
monotonic constraints to mimic the physical behavior of the system. We verify
the proposed method in a cooling system of a data center, experimental results
show the superiority of our framework in energy optimization compared to the
existing ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Large-scale Teacher-Student Training for On-device Acoustic Models. (arXiv:2106.06126v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_R/0/1/0/all/0/1">Rupak Vignesh Swaminathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_S/0/1/0/all/0/1">Sree Hari Krishnan Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1">Chunchuan Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouchtaris_A/0/1/0/all/0/1">Athanasios Mouchtaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunzmann_S/0/1/0/all/0/1">Siegfried Kunzmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06126">
                                    <div class="article-summary-box-inner">
                                        <span>We present results from Alexa speech teams on semi-supervised learning (SSL)
of acoustic models (AM) with experiments spanning over 3000 hours of GPU time,
making our study one of the largest of its kind. We discuss SSL for AMs in a
small footprint setting, showing that a smaller capacity model trained with 1
million hours of unsupervised data can outperform a baseline supervised system
by 14.3% word error rate reduction (WERR). When increasing the supervised data
to seven-fold, our gains diminish to 7.1% WERR; to improve SSL efficiency at
larger supervised data regimes, we employ a step-wise distillation into a
smaller model, obtaining a WERR of 14.4%. We then switch to SSL using larger
student models in low data regimes; while learning efficiency with unsupervised
data is higher, student models may outperform teacher models in such a setting.
We develop a theoretical sketch to explain this behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive-Scale Boundary Blackbox Attack via Projective Gradient Estimation. (arXiv:2106.06056v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Huichen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaolu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06056">
                                    <div class="article-summary-box-inner">
                                        <span>Boundary based blackbox attack has been recognized as practical and
effective, given that an attacker only needs to access the final model
prediction. However, the query efficiency of it is in general high especially
for high dimensional image data. In this paper, we show that such efficiency
highly depends on the scale at which the attack is applied, and attacking at
the optimal scale significantly improves the efficiency. In particular, we
propose a theoretical framework to analyze and show three key characteristics
to improve the query efficiency. We prove that there exists an optimal scale
for projective gradient estimation. Our framework also explains the
satisfactory performance achieved by existing boundary black-box attacks. Based
on our theoretical framework, we propose Progressive-Scale enabled projective
Boundary Attack (PSBA) to improve the query efficiency via progressive scaling
techniques. In particular, we employ Progressive-GAN to optimize the scale of
projections, which we call PSBA-PGAN. We evaluate our approach on both spatial
and frequency scales. Extensive experiments on MNIST, CIFAR-10, CelebA, and
ImageNet against different models including a real-world face recognition API
show that PSBA-PGAN significantly outperforms existing baseline attacks in
terms of query efficiency and attack success rate. We also observe relatively
stable optimal scales for different models and datasets. The code is publicly
available at https://github.com/AI-secure/PSBA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradual Domain Adaptation in the Wild:When Intermediate Distributions are Absent. (arXiv:2106.06080v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abnar_S/0/1/0/all/0/1">Samira Abnar</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghiasi_G/0/1/0/all/0/1">Golnaz Ghiasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1">Mostafa Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalchbrenner_N/0/1/0/all/0/1">Nal Kalchbrenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Sedghi_H/0/1/0/all/0/1">Hanie Sedghi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06080">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on the problem of domain adaptation when the goal is shifting the
model towards the target distribution, rather than learning domain invariant
representations. It has been shown that under the following two assumptions:
(a) access to samples from intermediate distributions, and (b) samples being
annotated with the amount of change from the source distribution, self-training
can be successfully applied on gradually shifted samples to adapt the model
toward the target distribution. We hypothesize having (a) is enough to enable
iterative self-training to slowly adapt the model to the target distribution,
by making use of an implicit curriculum. In the case where (a) does not hold,
we observe that iterative self-training falls short. We propose GIFT, a method
that creates virtual samples from intermediate distributions by interpolating
representations of examples from source and target domains. We evaluate an
iterative-self-training method on datasets with natural distribution shifts,
and show that when applied on top of other domain adaptation methods, it
improves the performance of the model on the target dataset. We run an analysis
on a synthetic dataset to show that in the presence of (a)
iterative-self-training naturally forms a curriculum of samples. Furthermore,
we show that when (a) does not hold, GIFT performs better than iterative
self-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergence and Alignment of Gradient Descentwith Random Back propagation Weights. (arXiv:2106.06044v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Song_G/0/1/0/all/0/1">Ganlin Song</a>, <a href="http://arxiv.org/find/stat/1/au:+Xu_R/0/1/0/all/0/1">Ruitu Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Lafferty_J/0/1/0/all/0/1">John Lafferty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06044">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic gradient descent with backpropagation is the workhorse of
artificial neural networks. It has long been recognized that backpropagation
fails to be a biologically plausible algorithm. Fundamentally, it is a
non-local procedure -- updating one neuron&#x27;s synaptic weights requires
knowledge of synaptic weights or receptive fields of downstream neurons. This
limits the use of artificial neural networks as a tool for understanding the
biological principles of information processing in the brain. Lillicrap et al.
(2016) propose a more biologically plausible &quot;feedback alignment&quot; algorithm
that uses random and fixed backpropagation weights, and show promising
simulations. In this paper we study the mathematical properties of the feedback
alignment procedure by analyzing convergence and alignment for two-layer
networks under squared error loss. In the overparameterized setting, we prove
that the error converges to zero exponentially fast, and also that
regularization is necessary in order for the parameters to become aligned with
the random backpropagation weights. Simulations are given that are consistent
with this analysis and suggest further generalizations. These results
contribute to our understanding of how biologically plausible algorithms might
carry out weight learning in a manner different from Hebbian learning, with
performance that is comparable with the full non-local backpropagation
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Optimisation with Formal Guarantees. (arXiv:2106.06067v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brausse_F/0/1/0/all/0/1">Franz Brau&#xdf;e</a>, <a href="http://arxiv.org/find/cs/1/au:+Khasidashvili_Z/0/1/0/all/0/1">Zurab Khasidashvili</a>, <a href="http://arxiv.org/find/cs/1/au:+Korovin_K/0/1/0/all/0/1">Konstantin Korovin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06067">
                                    <div class="article-summary-box-inner">
                                        <span>Application domains of Bayesian optimization include optimizing black-box

functions or very complex functions. The functions we are interested in
describe

complex real-world systems applied in industrial settings. Even though

they do have explicit representations, standard optimization

techniques fail to provide validated solutions and correctness

guarantees for them.

In this paper we present a combination of Bayesian optimisation and SMT-based
constraint solving to achieve safe and stable solutions with optimality
guarantees.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Verifying Quantized Neural Networks using SMT-Based Model Checking. (arXiv:2106.05997v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sena_L/0/1/0/all/0/1">Luiz Sena</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xidan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Alves_E/0/1/0/all/0/1">Erickson Alves</a>, <a href="http://arxiv.org/find/cs/1/au:+Bessa_I/0/1/0/all/0/1">Iury Bessa</a>, <a href="http://arxiv.org/find/cs/1/au:+Manino_E/0/1/0/all/0/1">Edoardo Manino</a>, <a href="http://arxiv.org/find/cs/1/au:+Cordeiro_L/0/1/0/all/0/1">Lucas Cordeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05997">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial Neural Networks (ANNs) are being deployed on an increasing number
of safety-critical applications, including autonomous cars and medical
diagnosis. However, concerns about their reliability have been raised due to
their black-box nature and apparent fragility to adversarial attacks. Here, we
develop and evaluate a symbolic verification framework using incremental model
checking (IMC) and satisfiability modulo theories (SMT) to check for
vulnerabilities in ANNs. More specifically, we propose several ANN-related
optimizations for IMC, including invariant inference via interval analysis and
the discretization of non-linear activation functions. With this, we can
provide guarantees on the safe behavior of ANNs implemented both in
floating-point and fixed-point (quantized) arithmetic. In this regard, our
verification approach was able to verify and produce adversarial examples for
52 test cases spanning image classification and general machine learning
applications. For small- to medium-sized ANN, our approach completes most of
its verification runs in minutes. Moreover, in contrast to most
state-of-the-art methods, our approach is not restricted to specific choices of
activation functions or non-quantized representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Framework for Constructing Nonconvex Regularizations. (arXiv:2106.06123v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhou_Z/0/1/0/all/0/1">Zhiyong Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06123">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past decades, many individual nonconvex methods have been proposed
to achieve better sparse recovery performance in various scenarios. However,
how to construct a valid nonconvex regularization function remains open in
practice. In this paper, we fill in this gap by presenting a unified framework
for constructing the nonconvex regularization based on the probability density
function. Meanwhile, a new nonconvex sparse recovery method constructed via the
Weibull distribution is studied.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedBABU: Towards Enhanced Representation for Federated Image Classification. (arXiv:2106.06042v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jaehoon Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sangmook Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Se-Young Yun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06042">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has evolved to improve a single global model under data
heterogeneity (as a curse) or to develop multiple personalized models using
data heterogeneity (as a blessing). However, there has been little research
considering both directions simultaneously. In this paper, we first investigate
the relationship between them by analyzing Federated Averaging at the client
level and determine that a better federated global model performance does not
constantly improve personalization. To elucidate the cause of this
personalization performance degradation problem, we decompose the entire
network into the body (i.e., extractor), related to universality, and the head
(i.e., classifier), related to personalization. We then point out that this
problem stems from training the head. Based on this observation, we propose a
novel federated learning algorithm, coined as FedBABU, which updates only the
body of the model during federated training (i.e., the head is randomly
initialized and never updated), and the head is fine-tuned for personalization
during the evaluation process. Extensive experiments show consistent
performance improvements and an efficient personalization of FedBABU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Multidisciplinary Design Optimization with Neural Networks. (arXiv:2106.06092v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Becdelievre_J/0/1/0/all/0/1">Jean de Becdelievre</a>, <a href="http://arxiv.org/find/cs/1/au:+Kroo_I/0/1/0/all/0/1">Ilan Kroo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06092">
                                    <div class="article-summary-box-inner">
                                        <span>The design of complex engineering systems leads to solving very large
optimization problems involving different disciplines. Strategies allowing
disciplines to optimize in parallel by providing sub-objectives and splitting
the problem into smaller parts, such as Collaborative Optimization, are
promising solutions.However, most of them have slow convergence which reduces
their practical use. Earlier efforts to fasten convergence by learning
surrogate models have not yet succeeded at sufficiently improving the
competitiveness of these strategies.This paper shows that, in the case of
Collaborative Optimization, faster and more reliable convergence can be
obtained by solving an interesting instance of binary classification: on top of
the target label, the training data of one of the two classes contains the
distance to the decision boundary and its derivative. Leveraging this
information, we propose to train a neural network with an asymmetric loss
function, a structure that guarantees Lipshitz continuity, and a regularization
towards respecting basic distance function properties. The approach is
demonstrated on a toy learning example, and then applied to a multidisciplinary
aircraft design problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Twin Neural Network Regression is a Semi-Supervised Regression Algorithm. (arXiv:2106.06124v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wetzel_S/0/1/0/all/0/1">Sebastian J. Wetzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Melko_R/0/1/0/all/0/1">Roger G. Melko</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamblyn_I/0/1/0/all/0/1">Isaac Tamblyn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06124">
                                    <div class="article-summary-box-inner">
                                        <span>Twin neural network regression (TNNR) is a semi-supervised regression
algorithm, it can be trained on unlabelled data points as long as other,
labelled anchor data points, are present. TNNR is trained to predict
differences between the target values of two different data points rather than
the targets themselves. By ensembling predicted differences between the targets
of an unseen data point and all training data points, it is possible to obtain
a very accurate prediction for the original regression problem. Since any loop
of predicted differences should sum to zero, loops can be supplied to the
training data, even if the data points themselves within loops are unlabelled.
Semi-supervised training improves TNNR performance, which is already state of
the art, significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline. (arXiv:2106.06054v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sumon Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1">Hridesh Rajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06054">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, many incidents have been reported where machine learning
models exhibited discrimination among people based on race, sex, age, etc.
Research has been conducted to measure and mitigate unfairness in machine
learning models. For a machine learning task, it is a common practice to build
a pipeline that includes an ordered set of data preprocessing stages followed
by a classifier. However, most of the research on fairness has considered a
single classifier based prediction task. What are the fairness impacts of the
preprocessing stages in machine learning pipeline? Furthermore, studies showed
that often the root cause of unfairness is ingrained in the data itself, rather
than the model. But no research has been conducted to measure the unfairness
caused by a specific transformation made in the data preprocessing stage. In
this paper, we introduced the causal method of fairness to reason about the
fairness impact of data preprocessing stages in ML pipeline. We leveraged
existing metrics to define the fairness measures of the stages. Then we
conducted a detailed fairness evaluation of the preprocessing stages in 37
pipelines collected from three different sources. Our results show that certain
data transformers are causing the model to exhibit unfairness. We identified a
number of fairness patterns in several categories of data transformers.
Finally, we showed how the local fairness of a preprocessing stage composes in
the global fairness of the pipeline. We used the fairness composition to choose
appropriate downstream transformer that mitigates unfairness in the machine
learning pipeline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Transformer: Predicting Samples of Unseen, Future Domains. (arXiv:2106.06057v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Johannes Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06057">
                                    <div class="article-summary-box-inner">
                                        <span>The data distribution commonly evolves over time leading to problems such as
concept drift that often decrease classifier performance. We seek to predict
unseen data (and their labels) allowing us to tackle challenges due to a
non-constant data distribution in a \emph{proactive} manner rather than
detecting and reacting to already existing changes that might already have led
to errors. To this end, we learn a domain transformer in an unsupervised manner
that allows generating data of unseen domains. Our approach first matches
independently learned latent representations of two given domains obtained from
an auto-encoder using a Cycle-GAN. In turn, a transformation of the original
samples can be learned that can be applied iteratively to extrapolate to unseen
domains. Our evaluation on CNNs on image data confirms the usefulness of the
approach. It also achieves very good results on the well-known problem of
unsupervised domain adaption, where labels but not samples have to be
predicted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Nonmyopic Approach to Cost-Constrained Bayesian Optimization. (arXiv:2106.06079v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Eric Hans Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1">David Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1">Valerio Perrone</a>, <a href="http://arxiv.org/find/cs/1/au:+Seeger_M/0/1/0/all/0/1">Matthias Seeger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06079">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is a popular method for optimizing
expensive-to-evaluate black-box functions. BO budgets are typically given in
iterations, which implicitly assumes each evaluation has the same cost. In
fact, in many BO applications, evaluation costs vary significantly in different
regions of the search space. In hyperparameter optimization, the time spent on
neural network training increases with layer size; in clinical trials, the
monetary cost of drug compounds vary; and in optimal control, control actions
have differing complexities. Cost-constrained BO measures convergence with
alternative cost metrics such as time, money, or energy, for which the sample
efficiency of standard BO methods is ill-suited. For cost-constrained BO, cost
efficiency is far more important than sample efficiency. In this paper, we
formulate cost-constrained BO as a constrained Markov decision process (CMDP),
and develop an efficient rollout approximation to the optimal CMDP policy that
takes both the cost and future iterations into account. We validate our method
on a collection of hyperparameter optimization problems as well as a sensor set
selection application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting Expert Annotation Differences in Animal Behavior. (arXiv:2106.06114v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tjandrasuwita_M/0/1/0/all/0/1">Megan Tjandrasuwita</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jennifer J. Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1">Ann Kennedy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Swarat Chaudhuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06114">
                                    <div class="article-summary-box-inner">
                                        <span>Hand-annotated data can vary due to factors such as subjective differences,
intra-rater variability, and differing annotator expertise. We study
annotations from different experts who labelled the same behavior classes on a
set of animal behavior videos, and observe a variation in annotation styles. We
propose a new method using program synthesis to help interpret annotation
differences for behavior analysis. Our model selects relevant trajectory
features and learns a temporal filter as part of a program, which corresponds
to estimated importance an annotator places on that feature at each timestamp.
Our experiments on a dataset from behavioral neuroscience demonstrate that
compared to baseline approaches, our method is more accurate at capturing
annotator labels and learns interpretable temporal filters. We believe that our
method can lead to greater reproducibility of behavior annotations used in
scientific studies. We plan to release our code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FiSH: Fair Spatial Hotspots. (arXiv:2106.06049v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+P_D/0/1/0/all/0/1">Deepak P</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1">Sowmya S Sundaram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06049">
                                    <div class="article-summary-box-inner">
                                        <span>Pervasiveness of tracking devices and enhanced availability of spatially
located data has deepened interest in using them for various policy
interventions, through computational data analysis tasks such as spatial hot
spot detection. In this paper, we consider, for the first time to our best
knowledge, fairness in detecting spatial hot spots. We motivate the need for
ensuring fairness through statistical parity over the collective population
covered across chosen hot spots. We then characterize the task of identifying a
diverse set of solutions in the noteworthiness-fairness trade-off spectrum, to
empower the user to choose a trade-off justified by the policy domain. Being a
novel task formulation, we also develop a suite of evaluation metrics for fair
hot spots, motivated by the need to evaluate pertinent aspects of the task. We
illustrate the computational infeasibility of identifying fair hot spots using
naive and/or direct approaches and devise a method, codenamed {\it FiSH}, for
efficiently identifying high-quality, fair and diverse sets of spatial hot
spots. FiSH traverses the tree-structured search space using heuristics that
guide it towards identifying effective and fair sets of spatial hot spots.
Through an extensive empirical analysis over a real-world dataset from the
domain of human development, we illustrate that FiSH generates high-quality
solutions at fast response times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven battery operation for energy arbitrage using rainbow deep reinforcement learning. (arXiv:2106.06061v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Harrold_D/0/1/0/all/0/1">Daniel J. B. Harrold</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jun Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zhong Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06061">
                                    <div class="article-summary-box-inner">
                                        <span>As the world seeks to become more sustainable, intelligent solutions are
needed to increase the penetration of renewable energy. In this paper, the
model-free deep reinforcement learning algorithm Rainbow Deep Q-Networks is
used to control a battery in a small microgrid to perform energy arbitrage and
more efficiently utilise solar and wind energy sources. The grid operates with
its own demand and renewable generation based on a dataset collected at Keele
University, as well as using dynamic energy pricing from a real wholesale
energy market. Four scenarios are tested including using demand and price
forecasting produced with local weather data. The algorithm and its
subcomponents are evaluated against two continuous control benchmarks with
Rainbow able to outperform all other method. This research shows the importance
of using the distributional approach for reinforcement learning when working
with complex environments and reward functions, as well as how it can be used
to visualise and contextualise the agent&#x27;s behaviour for real-world
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Decentralized Adaptive Momentum Method for Solving a Class of Min-Max Optimization Problems. (arXiv:2106.06075v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Barazandeh_B/0/1/0/all/0/1">Babak Barazandeh</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_T/0/1/0/all/0/1">Tianjian Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Michailidis_G/0/1/0/all/0/1">George Michailidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06075">
                                    <div class="article-summary-box-inner">
                                        <span>Min-max saddle point games have recently been intensely studied, due to their
wide range of applications, including training Generative Adversarial
Networks~(GANs). However, most of the recent efforts for solving them are
limited to special regimes such as convex-concave games. Further, it is
customarily assumed that the underlying optimization problem is solved either
by a single machine or in the case of multiple machines connected in
centralized fashion, wherein each one communicates with a central node. The
latter approach becomes challenging, when the underlying communications network
has low bandwidth. In addition, privacy considerations may dictate that certain
nodes can communicate with a subset of other nodes. Hence, it is of interest to
develop methods that solve min-max games in a decentralized manner. To that
end, we develop a decentralized adaptive momentum (ADAM)-type algorithm for
solving min-max optimization problem under the condition that the objective
function satisfies a Minty Variational Inequality condition, which is a
generalization to convex-concave case. The proposed method overcomes
shortcomings of recent non-adaptive gradient-based decentralized algorithms for
min-max optimization problems that do not perform well in practice and require
careful tuning. In this paper, we obtain non-asymptotic rates of convergence of
the proposed algorithm (coined DADAM$^3$) for finding a (stochastic)
first-order Nash equilibrium point and subsequently evaluate its performance on
training GANs. The extensive empirical evaluation shows that DADAM$^3$
outperforms recently developed methods, including decentralized optimistic
stochastic gradient for solving such min-max problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Ensemble Approach Towards Adversarial Robustness. (arXiv:2106.05996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1">Haifeng Qian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05996">
                                    <div class="article-summary-box-inner">
                                        <span>It is a known phenomenon that adversarial robustness comes at a cost to
natural accuracy. To improve this trade-off, this paper proposes an ensemble
approach that divides a complex robust-classification task into simpler
subtasks. Specifically, fractal divide derives multiple training sets from the
training data, and fractal aggregation combines inference outputs from multiple
classifiers that are trained on those sets. The resulting ensemble classifiers
have a unique property that ensures robustness for an input if certain
don&#x27;t-care conditions are met. The new techniques are evaluated on MNIST and
Fashion-MNIST, with no adversarial training. The MNIST classifier has 99%
natural accuracy, 70% measured robustness and 36.9% provable robustness, within
L2 distance of 2. The Fashion-MNIST classifier has 90% natural accuracy, 54.5%
measured robustness and 28.2% provable robustness, within L2 distance of 1.5.
Both results are new state of the art, and we also present new state-of-the-art
binary results on challenging label-pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Hierarchical Structures with Continuous Recursive Neural Networks. (arXiv:2106.06038v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_J/0/1/0/all/0/1">Jishnu Ray Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1">Cornelia Caragea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06038">
                                    <div class="article-summary-box-inner">
                                        <span>Recursive Neural Networks (RvNNs), which compose sequences according to their
underlying hierarchical syntactic structure, have performed well in several
natural language processing tasks compared to similar models without structural
biases. However, traditional RvNNs are incapable of inducing the latent
structure in a plain text sequence on their own. Several extensions have been
proposed to overcome this limitation. Nevertheless, these extensions tend to
rely on surrogate gradients or reinforcement learning at the cost of higher
bias or variance. In this work, we propose Continuous Recursive Neural Network
(CRvNN) as a backpropagation-friendly alternative to address the aforementioned
limitations. This is done by incorporating a continuous relaxation to the
induced structure. We demonstrate that CRvNN achieves strong performance in
challenging synthetic tasks such as logical inference and ListOps. We also show
that CRvNN performs comparably or better than prior latent structure models on
real-world tasks such as sentiment analysis and natural language inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liangqiong Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuyin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Paul Pu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yingda Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Feifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeli_E/0/1/0/all/0/1">Ehsan Adeli</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06047">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is an emerging research paradigm enabling collaborative
training of machine learning models among different organizations while keeping
data private at each institution. Despite recent progress, there remain
fundamental challenges such as lack of convergence and potential for
catastrophic forgetting in federated learning across real-world heterogeneous
devices. In this paper, we demonstrate that attention-based architectures
(e.g., Transformers) are fairly robust to distribution shifts and hence improve
federated learning over heterogeneous data. Concretely, we conduct the first
rigorous empirical investigation of different neural architectures across a
range of federated algorithms, real-world benchmarks, and heterogeneous data
splits. Our experiments show that simply replacing convolutional networks with
Transformers can greatly reduce catastrophic forgetting of previous devices,
accelerate convergence, and reach a better global model, especially when
dealing with heterogeneous data. We will release our code and pretrained models
at https://github.com/Liangqiong/ViT-FL-main to encourage future exploration in
robust architectures as an alternative to current research efforts on the
optimization front.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Variational Gaussian Processes via Harmonic Kernel Decomposition. (arXiv:2106.05992v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Shengyang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiaxin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1">Andrew Gordon Wilson</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1">Roger Grosse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05992">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new scalable variational Gaussian process approximation which
provides a high fidelity approximation while retaining general applicability.
We propose the harmonic kernel decomposition (HKD), which uses Fourier series
to decompose a kernel as a sum of orthogonal kernels. Our variational
approximation exploits this orthogonality to enable a large number of inducing
points at a low computational cost. We demonstrate that, on a range of
regression and classification problems, our approach can exploit input space
symmetries such as translations and reflections, and it significantly
outperforms standard variational methods in scalability and accuracy. Notably,
our approach achieves state-of-the-art results on CIFAR-10 among pure GP
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthesising Reinforcement Learning Policies through Set-Valued Inductive Rule Learning. (arXiv:2106.06009v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Coppens_Y/0/1/0/all/0/1">Youri Coppens</a>, <a href="http://arxiv.org/find/cs/1/au:+Steckelmacher_D/0/1/0/all/0/1">Denis Steckelmacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1">Catholijn M. Jonker</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowe_A/0/1/0/all/0/1">Ann Now&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06009">
                                    <div class="article-summary-box-inner">
                                        <span>Today&#x27;s advanced Reinforcement Learning algorithms produce black-box
policies, that are often difficult to interpret and trust for a person. We
introduce a policy distilling algorithm, building on the CN2 rule mining
algorithm, that distills the policy into a rule-based decision system. At the
core of our approach is the fact that an RL process does not just learn a
policy, a mapping from states to actions, but also produces extra
meta-information, such as action values indicating the quality of alternative
actions. This meta-information can indicate whether more than one action is
near-optimal for a certain state. We extend CN2 to make it able to leverage
knowledge about equally-good actions to distill the policy into fewer rules,
increasing its interpretability by a person. Then, to ensure that the rules
explain a valid, non-degenerate policy, we introduce a refinement algorithm
that fine-tunes the rules to obtain good performance when executed in the
environment. We demonstrate the applicability of our algorithm on the Mario AI
benchmark, a complex task that requires modern reinforcement learning
algorithms including neural networks. The explanations we produce capture the
learned policy in only a few rules, that allow a person to understand what the
black-box agent learned. Source code:
https://gitlab.ai.vub.ac.be/yocoppen/svcn2</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework. (arXiv:2106.06046v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">Mohit Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Moser_B/0/1/0/all/0/1">Bernhard A. Moser</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_L/0/1/0/all/0/1">Lukas Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Freudenthaler_B/0/1/0/all/0/1">Bernhard Freudenthaler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06046">
                                    <div class="article-summary-box-inner">
                                        <span>Guidelines and principles of trustworthy AI should be adhered to in practice
during the development of AI systems. This work suggests a novel information
theoretic trustworthy AI framework based on the hypothesis that information
theory enables taking into account the ethical AI principles during the
development of machine learning and deep learning models via providing a way to
study and optimize the inherent tradeoffs between trustworthy AI principles. A
unified approach to &quot;privacy-preserving interpretable and transferable
learning&quot; is presented via introducing the information theoretic measures for
privacy-leakage, interpretability, and transferability. A technique based on
variational optimization, employing conditionally deep autoencoders, is
developed for practically calculating the defined information theoretic
measures for privacy-leakage, interpretability, and transferability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Framework for Sensing and Modeling Interference in IoT Frequency Bands. (arXiv:2106.06010v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Homssi_B/0/1/0/all/0/1">Bassel Al Homssi</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Hourani_A/0/1/0/all/0/1">Akram Al-Hourani</a>, <a href="http://arxiv.org/find/cs/1/au:+Krusevac_Z/0/1/0/all/0/1">Zarko Krusevac</a>, <a href="http://arxiv.org/find/cs/1/au:+Rowe_W/0/1/0/all/0/1">Wayne S T Rowe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06010">
                                    <div class="article-summary-box-inner">
                                        <span>Spectrum scarcity has surfaced as a prominent concern in wireless radio
communications with the emergence of new technologies over the past few years.
As a result, there is growing need for better understanding of the spectrum
occupancy with newly emerging access technologies supporting the Internet of
Things. In this paper, we present a framework to capture and model the traffic
behavior of short-time spectrum occupancy for IoT applications in the shared
bands to determine the existing interference. The proposed capturing method
utilizes a software defined radio to monitor the short bursts of IoT
transmissions by capturing the time series data which is converted to power
spectral density to extract the observed occupancy. Furthermore, we propose the
use of an unsupervised machine learning technique to enhance conventionally
implemented energy detection methods. Our experimental results show that the
temporal and frequency behavior of the spectrum can be well-captured using the
combination of two models, namely, semi-Markov chains and a
Poisson-distribution arrival rate. We conduct an extensive measurement campaign
in different urban environments and incorporate the spatial effect on the IoT
shared spectrum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse and Imperceptible Adversarial Attack via a Homotopy Algorithm. (arXiv:2106.06027v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingkang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06027">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse adversarial attacks can fool deep neural networks (DNNs) by only
perturbing a few pixels (regularized by l_0 norm). Recent efforts combine it
with another l_infty imperceptible on the perturbation magnitudes. The
resultant sparse and imperceptible attacks are practically relevant, and
indicate an even higher vulnerability of DNNs that we usually imagined.
However, such attacks are more challenging to generate due to the optimization
difficulty by coupling the l_0 regularizer and box constraints with a
non-convex objective. In this paper, we address this challenge by proposing a
homotopy algorithm, to jointly tackle the sparsity and the perturbation bound
in one unified framework. Each iteration, the main step of our algorithm is to
optimize an l_0-regularized adversarial loss, by leveraging the nonmonotone
Accelerated Proximal Gradient Method (nmAPG) for nonconvex programming; it is
followed by an l_0 change control step, and an optional post-attack step
designed to escape bad local minima. We also extend the algorithm to handling
the structural sparsity regularizer. We extensively examine the effectiveness
of our proposed homotopy attack for both targeted and non-targeted attack
scenarios, on CIFAR-10 and ImageNet datasets. Compared to state-of-the-art
methods, our homotopy attack leads to significantly fewer perturbations, e.g.,
reducing 42.91% on CIFAR-10 and 75.03% on ImageNet (average case, targeted
attack), at similar maximal perturbation magnitudes, when still achieving 100%
attack success rates. Our codes are available at:
https://github.com/VITA-Group/SparseADV_Homotopy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A self-adapting super-resolution structures framework for automatic design of GAN. (arXiv:2106.06011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yibo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haidi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yiming Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shunyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06011">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of deep learning, the single super-resolution image
reconstruction network models are becoming more and more complex. Small changes
in hyperparameters of the models have a greater impact on model performance. In
the existing works, experts have gradually explored a set of optimal model
parameters based on empirical values or performing brute-force search. In this
paper, we introduce a new super-resolution image reconstruction generative
adversarial network framework, and a Bayesian optimization method used to
optimizing the hyperparameters of the generator and discriminator. The
generator is made by self-calibrated convolution, and discriminator is made by
convolution lays. We have defined the hyperparameters such as the number of
network layers and the number of neurons. Our method adopts Bayesian
optimization as a optimization policy of GAN in our model. Not only can find
the optimal hyperparameter solution automatically, but also can construct a
super-resolution image reconstruction network, reducing the manual workload.
Experiments show that Bayesian optimization can search the optimal solution
earlier than the other two optimization algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coordinate Independent Convolutional Networks -- Isometry and Gauge Equivariant Convolutions on Riemannian Manifolds. (arXiv:2106.06020v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1">Maurice Weiler</a>, <a href="http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1">Patrick Forr&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Verlinde_E/0/1/0/all/0/1">Erik Verlinde</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06020">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the vast success of deep convolutional networks, there is a
great interest in generalizing convolutions to non-Euclidean manifolds. A major
complication in comparison to flat spaces is that it is unclear in which
alignment a convolution kernel should be applied on a manifold. The underlying
reason for this ambiguity is that general manifolds do not come with a
canonical choice of reference frames (gauge). Kernels and features therefore
have to be expressed relative to arbitrary coordinates. We argue that the
particular choice of coordinatization should not affect a network&#x27;s inference
-- it should be coordinate independent. A simultaneous demand for coordinate
independence and weight sharing is shown to result in a requirement on the
network to be equivariant under local gauge transformations (changes of local
reference frames). The ambiguity of reference frames depends thereby on the
G-structure of the manifold, such that the necessary level of gauge
equivariance is prescribed by the corresponding structure group G. Coordinate
independent convolutions are proven to be equivariant w.r.t. those isometries
that are symmetries of the G-structure. The resulting theory is formulated in a
coordinate free fashion in terms of fiber bundles. To exemplify the design of
coordinate independent convolutions, we implement a convolutional network on
the M\&quot;obius strip. The generality of our differential geometric formulation of
convolutional networks is demonstrated by an extensive literature review which
explains a large number of Euclidean CNNs, spherical CNNs and CNNs on general
surfaces as specific instances of coordinate independent convolutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DECORE: Deep Compression with Reinforcement Learning. (arXiv:2106.06091v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alwani_M/0/1/0/all/0/1">Manoj Alwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Madhavan_V/0/1/0/all/0/1">Vashisht Madhavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06091">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has become an increasingly popular and powerful option for
modern pattern recognition systems. However, many deep neural networks have
millions to billions of parameters, making them untenable for real-world
applications with constraints on memory or latency. As a result, powerful
network compression techniques are a must for the widespread adoption of deep
learning. We present DECORE, a reinforcement learning approach to automate the
network compression process. Using a simple policy gradient method to learn
which neurons or channels to keep or remove, we are able to achieve compression
rates 3x to 5x greater than contemporary approaches. In contrast with other
architecture search methods, DECORE is simple and quick to train, requiring
only a few hours of training on 1 GPU. When applied to standard network
architectures on different datasets, our approach achieves 11x to 103x
compression on different architectures while maintaining accuracies similar to
those of the original, large networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Vision with Sparse Mixture of Experts. (arXiv:2106.05974v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Riquelme_C/0/1/0/all/0/1">Carlos Riquelme</a>, <a href="http://arxiv.org/find/cs/1/au:+Puigcerver_J/0/1/0/all/0/1">Joan Puigcerver</a>, <a href="http://arxiv.org/find/cs/1/au:+Mustafa_B/0/1/0/all/0/1">Basil Mustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1">Maxim Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1">Rodolphe Jenatton</a>, <a href="http://arxiv.org/find/cs/1/au:+Pinto_A/0/1/0/all/0/1">Andr&#xe9; Susano Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1">Daniel Keysers</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05974">
                                    <div class="article-summary-box-inner">
                                        <span>Sparsely-gated Mixture of Experts networks (MoEs) have demonstrated excellent
scalability in Natural Language Processing. In Computer Vision, however, almost
all performant networks are &quot;dense&quot;, that is, every input is processed by every
parameter. We present a Vision MoE (V-MoE), a sparse version of the Vision
Transformer, that is scalable and competitive with the largest dense networks.
When applied to image recognition, V-MoE matches the performance of
state-of-the-art networks, while requiring as little as half of the compute at
inference time. Further, we propose an extension to the routing algorithm that
can prioritize subsets of each input across the entire batch, leading to
adaptive per-image compute. This allows V-MoE to trade-off performance and
compute smoothly at test-time. Finally, we demonstrate the potential of V-MoE
to scale vision models, and train a 15B parameter model that attains 90.35% on
ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChemRL-GEM: Geometry Enhanced Molecular Representation Learning for Property Prediction. (arXiv:2106.06130v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xiaomin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lihang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jieqiong Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Donglong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanzhuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingbo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06130">
                                    <div class="article-summary-box-inner">
                                        <span>Effective molecular representation learning is of great importance to
facilitate molecular property prediction, which is a fundamental task for the
drug and material industry. Recent advances in graph neural networks (GNNs)
have shown great promise in applying GNNs for molecular representation
learning. Moreover, a few recent studies have also demonstrated successful
applications of self-supervised learning methods to pre-train the GNNs to
overcome the problem of insufficient labeled molecules. However, existing GNNs
and pre-training strategies usually treat molecules as topological graph data
without fully utilizing the molecular geometry information. Whereas, the
three-dimensional (3D) spatial structure of a molecule, a.k.a molecular
geometry, is one of the most critical factors for determining molecular
physical, chemical, and biological properties. To this end, we propose a novel
Geometry Enhanced Molecular representation learning method (GEM) for Chemical
Representation Learning (ChemRL). At first, we design a geometry-based GNN
architecture that simultaneously models atoms, bonds, and bond angles in a
molecule. To be specific, we devised double graphs for a molecule: The first
one encodes the atom-bond relations; The second one encodes bond-angle
relations. Moreover, on top of the devised GNN architecture, we propose several
novel geometry-level self-supervised learning strategies to learn spatial
knowledge by utilizing the local and global molecular 3D structures. We compare
ChemRL-GEM with various state-of-the-art (SOTA) baselines on different
molecular benchmarks and exhibit that ChemRL-GEM can significantly outperform
all baselines in both regression and classification tasks. For example, the
experimental results show an overall improvement of $8.8\%$ on average compared
to SOTA baselines on the regression tasks, demonstrating the superiority of the
proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Neural Networks for Natural Language Processing: A Survey. (arXiv:2106.06090v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1">Kai Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xiaojie Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Hanning Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shucheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1">Bo Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06090">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has become the dominant approach in coping with various tasks
in Natural LanguageProcessing (NLP). Although text inputs are typically
represented as a sequence of tokens, there isa rich variety of NLP problems
that can be best expressed with a graph structure. As a result, thereis a surge
of interests in developing new deep learning techniques on graphs for a large
numberof NLP tasks. In this survey, we present a comprehensive overview onGraph
Neural Networks(GNNs) for Natural Language Processing. We propose a new
taxonomy of GNNs for NLP, whichsystematically organizes existing research of
GNNs for NLP along three axes: graph construction,graph representation
learning, and graph based encoder-decoder models. We further introducea large
number of NLP applications that are exploiting the power of GNNs and summarize
thecorresponding benchmark datasets, evaluation metrics, and open-source codes.
Finally, we discussvarious outstanding challenges for making the full use of
GNNs for NLP as well as future researchdirections. To the best of our
knowledge, this is the first comprehensive overview of Graph NeuralNetworks for
Natural Language Processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Sequences as Distributions with Uncertainty for Sequential Recommendation. (arXiv:2106.06165v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Ziwei Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06165">
                                    <div class="article-summary-box-inner">
                                        <span>The sequential patterns within the user interactions are pivotal for
representing the user&#x27;s preference and capturing latent relationships among
items. The recent advancements of sequence modeling by Transformers advocate
the community to devise more effective encoders for the sequential
recommendation. Most existing sequential methods assume users are
deterministic. However, item-item transitions might fluctuate significantly in
several item aspects and exhibit randomness of user interests. This
\textit{stochastic characteristics} brings up a solid demand to include
uncertainties in representing sequences and items. Additionally, modeling
sequences and items with uncertainties expands users&#x27; and items&#x27; interaction
spaces, thus further alleviating cold-start problems.

In this work, we propose a Distribution-based Transformer for Sequential
Recommendation (DT4SR), which injects uncertainties into sequential modeling.
We use Elliptical Gaussian distributions to describe items and sequences with
uncertainty. We describe the uncertainty in items and sequences as Elliptical
Gaussian distribution. And we adopt Wasserstein distance to measure the
similarity between distributions. We devise two novel Trans-formers for
modeling mean and covariance, which guarantees the positive-definite property
of distributions. The proposed method significantly outperforms the
state-of-the-art methods. The experiments on three benchmark datasets also
demonstrate its effectiveness in alleviating cold-start issues. The code is
available inhttps://github.com/DyGRec/DT4SR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Multi-Object Tracking and Segmentation with GMPHD Filter and Mask-based Affinity Fusion. (arXiv:2009.00100v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Young-min Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_Y/0/1/0/all/0/1">Young-chul Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1">Kwangjin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_M/0/1/0/all/0/1">Moongu Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1">Witold Pedrycz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00100">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a highly practical fully online multi-object
tracking and segmentation (MOTS) method that uses instance segmentation results
as an input. The proposed method is based on the Gaussian mixture probability
hypothesis density (GMPHD) filter, a hierarchical data association (HDA), and a
mask-based affinity fusion (MAF) model to achieve high-performance online
tracking. The HDA consists of two associations: segment-to-track and
track-to-track associations. One affinity, for position and motion, is computed
by using the GMPHD filter, and the other affinity, for appearance is computed
by using the responses from a single object tracker such as a kernalized
correlation filter. These two affinities are simply fused by using a
score-level fusion method such as min-max normalization referred to as MAF. In
addition, to reduce the number of false positive segments, we adopt mask
IoU-based merging (mask merging). The proposed MOTS framework with the key
modules: HDA, MAF, and mask merging, is easily extensible to simultaneously
track multiple types of objects with CPU only execution in parallel processing.
In addition, the developed framework only requires simple parameter tuning
unlike many existing MOTS methods that need intensive hyperparameter
optimization. In the experiments on the two popular MOTS datasets, the key
modules show some improvements. For instance, ID-switch decreases by more than
half compared to a baseline method in the training sets. In conclusion, our
tracker achieves state-of-the-art MOTS performance in the test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Abstract Representations through Lossy Compression of Multi-Modal Signals. (arXiv:2101.11376v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilmot_C/0/1/0/all/0/1">Charles Wilmot</a>, <a href="http://arxiv.org/find/cs/1/au:+Triesch_J/0/1/0/all/0/1">Jochen Triesch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11376">
                                    <div class="article-summary-box-inner">
                                        <span>A key competence for open-ended learning is the formation of increasingly
abstract representations useful for driving complex behavior. Abstract
representations ignore specific details and facilitate generalization. Here we
consider the learning of abstract representations in a multi-modal setting with
two or more input modalities. We treat the problem as a lossy compression
problem and show that generic lossy compression of multimodal sensory input
naturally extracts abstract representations that tend to strip away modalitiy
specific details and preferentially retain information that is shared across
the different modalities. Furthermore, we propose an architecture to learn
abstract representations by identifying and retaining only the information that
is shared across multiple modalities while discarding any modality specific
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shallow Optical Flow Three-Stream CNN for Macro- and Micro-Expression Spotting from Long Videos. (arXiv:2106.06489v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liong_G/0/1/0/all/0/1">Gen-Bing Liong</a>, <a href="http://arxiv.org/find/cs/1/au:+See_J/0/1/0/all/0/1">John See</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1">Lai-Kuan Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06489">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expressions vary from the visible to the subtle. In recent years, the
analysis of micro-expressions $-$ a natural occurrence resulting from the
suppression of one&#x27;s true emotions, has drawn the attention of researchers with
a broad range of potential applications. However, spotting microexpressions in
long videos becomes increasingly challenging when intertwined with normal or
macro-expressions. In this paper, we propose a shallow optical flow
three-stream CNN (SOFTNet) model to predict a score that captures the
likelihood of a frame being in an expression interval. By fashioning the
spotting task as a regression problem, we introduce pseudo-labeling to
facilitate the learning process. We demonstrate the efficacy and efficiency of
the proposed approach on the recent MEGC 2020 benchmark, where state-of-the-art
performance is achieved on CAS(ME)$^{2}$ with equally promising results on SAMM
Long Videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-11">2021-06-11</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AUGNLG: Few-shot Natural Language Generation using Self-trained Data Augmentation. (arXiv:2106.05589v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinnuo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoyin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Bum Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungjin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05589">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Generation (NLG) is a key component in a task-oriented
dialogue system, which converts the structured meaning representation (MR) to
the natural language. For large-scale conversational systems, where it is
common to have over hundreds of intents and thousands of slots, neither
template-based approaches nor model-based approaches are scalable. Recently,
neural NLGs started leveraging transfer learning and showed promising results
in few-shot settings. This paper proposes AUGNLG, a novel data augmentation
approach that combines a self-trained neural retrieval model with a few-shot
learned NLU model, to automatically create MR-to-Text data from open-domain
texts. The proposed system mostly outperforms the state-of-the-art methods on
the FewShotWOZ data in both BLEU and Slot Error Rate. We further confirm
improved results on the FewShotSGD data and provide comprehensive analysis
results on key components of our system. Our code and data are available at
https://github.com/XinnuoXu/AugNLG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding. (arXiv:2010.13105v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seongbin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gyuwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seongjin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangmin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13105">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end approaches open a new way for more accurate and efficient spoken
language understanding (SLU) systems by alleviating the drawbacks of
traditional pipeline systems. Previous works exploit textual information for an
SLU model via pre-training with automatic speech recognition or fine-tuning
with knowledge distillation. To utilize textual information more effectively,
this work proposes a two-stage textual knowledge distillation method that
matches utterance-level representations and predicted logits of two modalities
during pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a
speech encoder because it captures general and rich features. Furthermore, we
improve the performance, especially in a low-resource scenario, with data
augmentation methods by randomly masking spans of discrete audio tokens and
contextualized hidden representations. Consequently, we push the
state-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy
in the full dataset setting and 99.5% in the 10% subset setting. Throughout the
ablation studies, we empirically verify that all used methods are crucial to
the final performance, providing the best practice for spoken language
understanding. Code is available at https://github.com/clovaai/textual-kd-slu.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linguistically Informed Masking for Representation Learning in the Patent Domain. (arXiv:2106.05768v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1">Sophia Althammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1">Mark Buckley</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1">Sebastian Hofst&#xe4;tter</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1">Allan Hanbury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05768">
                                    <div class="article-summary-box-inner">
                                        <span>Domain-specific contextualized language models have demonstrated substantial
effectiveness gains for domain-specific downstream tasks, like similarity
matching, entity recognition or information retrieval. However successfully
applying such models in highly specific language domains requires domain
adaptation of the pre-trained models. In this paper we propose the empirically
motivated Linguistically Informed Masking (LIM) method to focus
domain-adaptative pre-training on the linguistic patterns of patents, which use
a highly technical sublanguage. We quantify the relevant differences between
patent, scientific and general-purpose language and demonstrate for two
different language models (BERT and SciBERT) that domain adaptation with LIM
leads to systematically improved representations by evaluating the performance
of the domain-adapted representations of patent language on two independent
downstream tasks, the IPC classification and similarity matching. We
demonstrate the impact of balancing the learning from different information
sources during domain adaptation for the patent domain. We make the source code
as well as the domain-adaptive pre-trained patent language models publicly
available at https://github.com/sophiaalthammer/patent-lim.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures. (arXiv:2106.05822v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1">Ivan Chelombiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1">Daniel Justus</a>, <a href="http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1">Douglas Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1">Anastasia Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1">Frithjof Gressmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Koliousis_A/0/1/0/all/0/1">Alexandros Koliousis</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05822">
                                    <div class="article-summary-box-inner">
                                        <span>Attention based language models have become a critical component in
state-of-the-art natural language processing systems. However, these models
have significant computational requirements, due to long training times, dense
operations and large parameter count. In this work we demonstrate a set of
modifications to the structure of a Transformer layer, producing a more
efficient architecture. First, we add a convolutional module to complement the
self-attention module, decoupling the learning of local and global
interactions. Secondly, we rely on grouped transformations to reduce the
computational cost of dense feed-forward layers and convolutions, while
preserving the expressivity of the model. We apply the resulting architecture
to language representation learning and demonstrate its superior performance
compared to BERT models of different scales. We further highlight its improved
efficiency, both in terms of floating-point operations (FLOPs) and
time-to-train.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Multi-Granularity Training for Non-Autoregressive Translation. (arXiv:2106.05546v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Liang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Longyue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuebo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1">Derek F. Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05546">
                                    <div class="article-summary-box-inner">
                                        <span>Non-autoregressive translation (NAT) significantly accelerates the inference
process via predicting the entire target sequence. However, recent studies show
that NAT is weak at learning high-mode of knowledge such as one-to-many
translations. We argue that modes can be divided into various granularities
which can be learned from easy to hard. In this study, we empirically show that
NAT models are prone to learn fine-grained lower-mode knowledge, such as words
and phrases, compared with sentences. Based on this observation, we propose
progressive multi-granularity training for NAT. More specifically, to make the
most of the training data, we break down the sentence-level examples into three
types, i.e. words, phrases, sentences, and with the training goes, we
progressively increase the granularities. Experiments on Romanian-English,
English-German, Chinese-English, and Japanese-English demonstrate that our
approach improves the phrase translation accuracy and model reordering ability,
therefore resulting in better translation quality against strong NAT baselines.
Also, we show that more deterministic fine-grained knowledge can further
enhance performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering. (arXiv:2106.05346v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1">Devendra Singh Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1">Chris Dyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1">Dani Yogatama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05346">
                                    <div class="article-summary-box-inner">
                                        <span>We present an end-to-end differentiable training method for
retrieval-augmented open-domain question answering systems that combine
information from multiple retrieved documents when generating answers. We model
retrieval decisions as latent variables over sets of relevant documents. Since
marginalizing over sets of retrieved documents is computationally hard, we
approximate this using an expectation-maximization algorithm. We iteratively
estimate the value of our latent variable (the set of relevant documents for a
given question) and then use this estimate to update the retriever and reader
parameters. We hypothesize that such end-to-end training allows training
signals to flow to the reader and then to the retriever better than staged-wise
training. This results in a retriever that is able to select more relevant
documents for a question and a reader that is trained on more accurate
documents to generate an answer. Experiments on three benchmark datasets
demonstrate that our proposed method outperforms all existing approaches of
comparable size by 2-3% absolute exact match points, achieving new
state-of-the-art results. Our results also demonstrate the feasibility of
learning to retrieve to improve answer generation without explicit supervision
of retrieval decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Eye of the Beholder: Improved Relation Generalization for Text-based Reinforcement Learning Agents. (arXiv:2106.05387v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1">Keerthiram Murugesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1">Subhajit Chaudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1">Kartik Talamadupula</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05387">
                                    <div class="article-summary-box-inner">
                                        <span>Text-based games (TBGs) have become a popular proving ground for the
demonstration of learning-based agents that make decisions in quasi real-world
settings. The crux of the problem for a reinforcement learning agent in such
TBGs is identifying the objects in the world, and those objects&#x27; relations with
that world. While the recent use of text-based resources for increasing an
agent&#x27;s knowledge and improving its generalization have shown promise, we posit
in this paper that there is much yet to be learned from visual representations
of these same worlds. Specifically, we propose to retrieve images that
represent specific instances of text observations from the world and train our
agents on such images. This improves the agent&#x27;s overall understanding of the
game &#x27;scene&#x27; and objects&#x27; relationships to the world around them, and the
variety of visual representations on offer allow the agent to generate a better
generalization of a relationship. We show that incorporating such images
improves the performance of agents in various TBG settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information. (arXiv:2106.05707v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aly_R/0/1/0/all/0/1">Rami Aly</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhijiang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlichtkrull_M/0/1/0/all/0/1">Michael Schlichtkrull</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>, <a href="http://arxiv.org/find/cs/1/au:+Christodoulopoulos_C/0/1/0/all/0/1">Christos Christodoulopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Cocarascu_O/0/1/0/all/0/1">Oana Cocarascu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_A/0/1/0/all/0/1">Arpit Mittal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05707">
                                    <div class="article-summary-box-inner">
                                        <span>Fact verification has attracted a lot of attention in the machine learning
and natural language processing communities, as it is one of the key methods
for detecting misinformation. Existing large-scale benchmarks for this task
have focused mostly on textual sources, i.e. unstructured information, and thus
ignored the wealth of information available in structured formats, such as
tables. In this paper we introduce a novel dataset and benchmark, Fact
Extraction and VERification Over Unstructured and Structured information
(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated
with evidence in the form of sentences and/or cells from tables in Wikipedia,
as well as a label indicating whether this evidence supports, refutes, or does
not provide enough information to reach a verdict. Furthermore, we detail our
efforts to track and minimize the biases present in the dataset and could be
exploited by models, e.g. being able to predict the label without using
evidence. Finally, we develop a baseline for verifying claims against text and
tables which predicts both the correct evidence and verdict for 18% of the
claims.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DT-grams: Structured Dependency Grammar Stylometry for Cross-Language Authorship Attribution. (arXiv:2106.05677v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murauer_B/0/1/0/all/0/1">Benjamin Murauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Specht_G/0/1/0/all/0/1">G&#xfc;nther Specht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05677">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-language authorship attribution problems rely on either translation to
enable the use of single-language features, or language-independent feature
extraction methods. Until recently, the lack of datasets for this problem
hindered the development of the latter, and single-language solutions were
performed on machine-translated corpora. In this paper, we present a novel
language-independent feature for authorship analysis based on dependency graphs
and universal part of speech tags, called DT-grams (dependency tree grams),
which are constructed by selecting specific sub-parts of the dependency graph
of sentences. We evaluate DT-grams by performing cross-language authorship
attribution on untranslated datasets of bilingual authors, showing that, on
average, they achieve a macro-averaged F1 score of 0.081 higher than previous
methods across five different language pairs. Additionally, by providing
results for a diverse set of features for comparison, we provide a baseline on
the previously undocumented task of untranslated cross-language authorship
attribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data. (arXiv:2101.07597v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yao Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1">Kenichi Kumatani</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shujie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Michael Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuedong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07597">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a unified pre-training approach called UniSpeech to
learn speech representations with both unlabeled and labeled data, in which
supervised phonetic CTC learning and phonetically-aware contrastive
self-supervised learning are conducted in a multi-task learning manner. The
resultant representations can capture information more correlated with phonetic
structures and improve the generalization across languages and domains. We
evaluate the effectiveness of UniSpeech for cross-lingual representation
learning on public CommonVoice corpus. The results show that UniSpeech
outperforms self-supervised pretraining and supervised transfer learning for
speech recognition by a maximum of 13.4% and 17.8% relative phone error rate
reductions respectively (averaged over all testing languages). The
transferability of UniSpeech is also demonstrated on a domain-shift speech
recognition task, i.e., a relative word error rate reduction of 6% against the
previous approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ruddit: Norms of Offensiveness for English Reddit Comments. (arXiv:2106.05664v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1">Rishav Hada</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudhir_S/0/1/0/all/0/1">Sohi Sudhir</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1">Pushkar Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1">Helen Yannakoudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1">Saif M. Mohammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1">Ekaterina Shutova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05664">
                                    <div class="article-summary-box-inner">
                                        <span>On social media platforms, hateful and offensive language negatively impact
the mental well-being of users and the participation of people from diverse
backgrounds. Automatic methods to detect offensive language have largely relied
on datasets with categorical labels. However, comments can vary in their degree
of offensiveness. We create the first dataset of English language Reddit
comments that has \textit{fine-grained, real-valued scores} between -1
(maximally supportive) and 1 (maximally offensive). The dataset was annotated
using \emph{Best--Worst Scaling}, a form of comparative annotation that has
been shown to alleviate known biases of using rating scales. We show that the
method produces highly reliable offensiveness scores. Finally, we evaluate the
ability of widely-used neural models to predict offensiveness scores on this
new dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DESCGEN: A Distantly Supervised Datasetfor Generating Abstractive Entity Descriptions. (arXiv:2106.05365v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Weijia Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1">Mandar Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05365">
                                    <div class="article-summary-box-inner">
                                        <span>Short textual descriptions of entities provide summaries of their key
attributes and have been shown to be useful sources of background knowledge for
tasks such as entity linking and question answering. However, generating entity
descriptions, especially for new and long-tail entities, can be challenging
since relevant information is often scattered across multiple sources with
varied content and style. We introduce DESCGEN: given mentions spread over
multiple documents, the goal is to generate an entity summary description.
DESCGEN consists of 37K entity descriptions from Wikipedia and Fandom, each
paired with nine evidence documents on average. The documents were collected
using a combination of entity linking and hyperlinks to the Wikipedia and
Fandom entity pages, which together provide high-quality distant supervision.
The resulting summaries are more abstractive than those found in existing
datasets and provide a better proxy for the challenge of describing new and
emerging entities. We also propose a two-stage extract-then-generate baseline
and show that there exists a large gap (19.9% in ROUGE-L) between
state-of-the-art models and human performance, suggesting that the data will
support significant future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Word frequency-rank relationship in tagged texts. (arXiv:2102.10992v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chacoma_A/0/1/0/all/0/1">A. Chacoma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanette_D/0/1/0/all/0/1">D. H. Zanette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10992">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze the frequency-rank relationship in sub-vocabularies corresponding
to three different grammatical classes (nouns, verbs, and others) in a
collection of literary works in English, whose words have been automatically
tagged according to their grammatical role. Comparing with a null hypothesis
which assumes that words belonging to each class are uniformly distributed
across the frequency-ranked vocabulary of the whole work, we disclose
statistically significant differences between the three classes. This results
point to the fact that frequency-rank relationships may reflect linguistic
features associated with grammatical function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Programming Puzzles. (arXiv:2106.05784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1">Tal Schuster</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1">Ashwin Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1">Oleksandr Polozov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1">Adam Tauman Kalai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05784">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new type of programming challenge called programming puzzles,
as an objective and comprehensive evaluation of program synthesis, and release
an open-source dataset of Python Programming Puzzles (P3). Each puzzle is
defined by a short Python program $f$, and the goal is to find an input $x$
which makes $f$ output &quot;True&quot;. The puzzles are objective in that each one is
specified entirely by the source code of its verifier $f$, so evaluating $f(x)$
is all that is needed to test a candidate solution $x$. They do not require an
answer key or input/output examples, nor do they depend on natural language
understanding. The dataset is comprehensive in that it spans problems of a
range of difficulties and domains, ranging from trivial string manipulation
problems that are immediately obvious to human programmers (but not necessarily
to AI), to classic programming puzzles (e.g., Towers of Hanoi), to
interview/competitive-programming problems (e.g., dynamic programming), to
longstanding open problems in algorithms and mathematics (e.g., factoring). The
objective nature of P3 readily supports self-supervised bootstrapping. We
develop baseline enumerative program synthesis and GPT-3 solvers that are
capable of solving easy puzzles -- even without access to any reference
solutions -- by learning from their own past solutions. Based on a small user
study, we find puzzle difficulty to correlate between human programmers and the
baseline AI solvers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Perturb Word Embeddings for Out-of-distribution QA. (arXiv:2105.02692v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seanie Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Minki Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02692">
                                    <div class="article-summary-box-inner">
                                        <span>QA models based on pretrained language mod-els have achieved remarkable
performance onv arious benchmark datasets.However, QA models do not generalize
well to unseen data that falls outside the training distribution, due to
distributional shifts.Data augmentation(DA) techniques which drop/replace words
have shown to be effective in regularizing the model from overfitting to the
training data.Yet, they may adversely affect the QA tasks since they incur
semantic changes that may lead to wrong answers for the QA task. To tackle this
problem, we propose a simple yet effective DA method based on a stochastic
noise generator, which learns to perturb the word embedding of the input
questions and context without changing their semantics. We validate the
performance of the QA models trained with our word embedding perturbation on a
single source dataset, on five different target domains.The results show that
our method significantly outperforms the baselineDA methods. Notably, the model
trained with ours outperforms the model trained with more than 240K
artificially generated QA pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relative Positional Encoding for Transformers with Linear Complexity. (arXiv:2105.08399v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1">Antoine Liutkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1">Ond&#x159;ej C&#xed;fka</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shih-Lun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1">Umut &#x15e;im&#x15f;ekli</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08399">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in Transformer models allow for unprecedented sequence
lengths, due to linear space and time complexity. In the meantime, relative
positional encoding (RPE) was proposed as beneficial for classical Transformers
and consists in exploiting lags instead of absolute positions for inference.
Still, RPE is not available for the recent linear-variants of the Transformer,
because it requires the explicit computation of the attention matrix, which is
precisely what is avoided by such methods. In this paper, we bridge this gap
and present Stochastic Positional Encoding as a way to generate PE that can be
used as a replacement to the classical additive (sinusoidal) PE and provably
behaves like RPE. The main theoretical contribution is to make a connection
between positional encoding and cross-covariance structures of correlated
Gaussian processes. We illustrate the performance of our approach on the
Long-Range Arena benchmark and on music generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AlloST: Low-resource Speech Translation without Source Transcription. (arXiv:2105.00171v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yao-Fei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-Shin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hsin-Min Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00171">
                                    <div class="article-summary-box-inner">
                                        <span>The end-to-end architecture has made promising progress in speech translation
(ST). However, the ST task is still challenging under low-resource conditions.
Most ST models have shown unsatisfactory results, especially in the absence of
word information from the source speech utterance. In this study, we survey
methods to improve ST performance without using source transcription, and
propose a learning framework that utilizes a language-independent universal
phone recognizer. The framework is based on an attention-based
sequence-to-sequence model, where the encoder generates the phonetic embeddings
and phone-aware acoustic representations, and the decoder controls the fusion
of the two embedding streams to produce the target token sequence. In addition
to investigating different fusion strategies, we explore the specific usage of
byte pair encoding (BPE), which compresses a phone sequence into a
syllable-like segmented sequence. Due to the conversion of symbols, a segmented
sequence represents not only pronunciation but also language-dependent
information lacking in phones. Experiments conducted on the Fisher
Spanish-English and Taigi-Mandarin drama corpora show that our method
outperforms the conformer-based baseline, and the performance is close to that
of the existing best method using source transcription.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations. (arXiv:2106.01093v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Ruisheng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yanbin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Su Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Kai Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01093">
                                    <div class="article-summary-box-inner">
                                        <span>This work aims to tackle the challenging heterogeneous graph encoding problem
in the text-to-SQL task. Previous methods are typically node-centric and merely
utilize different weight matrices to parameterize edge types, which 1) ignore
the rich semantics embedded in the topological structure of edges, and 2) fail
to distinguish local and non-local relations for each node. To this end, we
propose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying
relational features without constructing meta-paths. By virtue of the line
graph, messages propagate more efficiently through not only connections between
nodes, but also the topology of directed edges. Furthermore, both local and
non-local relations are integrated distinctively during the graph iteration. We
also design an auxiliary task called graph pruning to improve the
discriminative capability of the encoder. Our framework achieves
state-of-the-art results (62.8% with Glove, 72.0% with Electra) on the
cross-domain text-to-SQL benchmark Spider at the time of writing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Populist Paragraphs in Text: A machine-learning approach. (arXiv:2106.03161v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ulinskaite_J/0/1/0/all/0/1">Jogil&#x117; Ulinskait&#x117;</a>, <a href="http://arxiv.org/find/cs/1/au:+Pukelis_L/0/1/0/all/0/1">Lukas Pukelis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03161">
                                    <div class="article-summary-box-inner">
                                        <span>Abstract: In this paper we present an approach to develop a
text-classification model which would be able to identify populist content in
text. The developed BERT-based model is largely successful in identifying
populist content in text and produces only a negligible amount of False
Negatives, which makes it well-suited as a content analysis automation tool,
which shortlists potentially relevant content for human validation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Replacement and Combination for Hybrid ASR Systems. (arXiv:2104.04298v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1">Peter Vieting</a>, <a href="http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1">Christoph L&#xfc;scher</a>, <a href="http://arxiv.org/find/eess/1/au:+Michel_W/0/1/0/all/0/1">Wilfried Michel</a>, <a href="http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04298">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic modeling of raw waveform and learning feature extractors as part of
the neural network classifier has been the goal of many studies in the area of
automatic speech recognition (ASR). Recently, one line of research has focused
on frameworks that can be pre-trained on audio-only data in an unsupervised
fashion and aim at improving downstream ASR tasks. In this work, we investigate
the usefulness of one of these front-end frameworks, namely wav2vec, for hybrid
ASR systems. In addition to deploying a pre-trained feature extractor, we
explore how to make use of an existing acoustic model (AM) trained on the same
task with different features as well. Another neural front-end which is only
trained together with the supervised ASR loss as well as traditional Gammatone
features are applied for comparison. Moreover, it is shown that the AM can be
retrofitted with i-vectors for speaker adaptation. Finally, the described
features are combined in order to further advance the performance. With the
final best system, we obtain a relative improvement of 4% and 6% over our
previous best model on the LibriSpeech test-clean and test-other sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures. (arXiv:2104.05379v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1">Nick Rossenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1">Mohammad Zeineldeen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1">Benedikt Hilmes</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05379">
                                    <div class="article-summary-box-inner">
                                        <span>Recent publications on automatic-speech-recognition (ASR) have a strong focus
on attention encoder-decoder (AED) architectures which work well for large
datasets, but tend to overfit when applied in low resource scenarios. One
solution to tackle this issue is to generate synthetic data with a trained
text-to-speech system (TTS) if additional text is available. This was
successfully applied in many publications with AED systems. We present a novel
approach of silence correction in the data pre-processing for TTS systems which
increases the robustness when training on corpora targeted for ASR
applications. In this work we do not only show the successful application of
synthetic data for AED systems, but also test the same method on a highly
optimized state-of-the-art Hybrid ASR system and a competitive monophone based
system using connectionist-temporal-classification (CTC). We show that for the
later systems the addition of synthetic data only has a minor effect, but they
still outperform the AED systems by a large margin on LibriSpeech-100h. We
achieve a final word-error-rate of 3.3%/10.0% with a Hybrid system on the
clean/noisy test-sets, surpassing any previous state-of-the-art systems that do
not include unlabeled audio data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Static Word Embeddings and Contextual Representations for Bilingual Lexicon Induction. (arXiv:2106.03084v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jinpeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_B/0/1/0/all/0/1">Baijun Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_N/0/1/0/all/0/1">Nini Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_X/0/1/0/all/0/1">Xiangyu Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Min Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yangbin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Weihua Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03084">
                                    <div class="article-summary-box-inner">
                                        <span>Bilingual Lexicon Induction (BLI) aims to map words in one language to their
translations in another, and is typically through learning linear projections
to align monolingual word representation spaces. Two classes of word
representations have been explored for BLI: static word embeddings and
contextual representations, but there is no studies to combine both. In this
paper, we propose a simple yet effective mechanism to combine the static word
embeddings and the contextual representations to utilize the advantages of both
paradigms. We test the combination mechanism on various language pairs under
the supervised and unsupervised BLI benchmark settings. Experiments show that
our mechanism consistently improves performances over robust BLI baselines on
all language pairs by averagely improving 3.2 points in the supervised setting,
and 3.1 points in the unsupervised setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeBenchmark: A Reproducible Framework for Assessing Self-Supervised Representation Learning from Speech. (arXiv:2104.11462v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evain_S/0/1/0/all/0/1">Solene Evain</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Ha Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hang Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Boito_M/0/1/0/all/0/1">Marcely Zanon Boito</a>, <a href="http://arxiv.org/find/cs/1/au:+Mdhaffar_S/0/1/0/all/0/1">Salima Mdhaffar</a>, <a href="http://arxiv.org/find/cs/1/au:+Alisamir_S/0/1/0/all/0/1">Sina Alisamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1">Ziyi Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomashenko_N/0/1/0/all/0/1">Natalia Tomashenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinarelli_M/0/1/0/all/0/1">Marco Dinarelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Allauzen_A/0/1/0/all/0/1">Alexandre Allauzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Esteve_Y/0/1/0/all/0/1">Yannick Esteve</a>, <a href="http://arxiv.org/find/cs/1/au:+Lecouteux_B/0/1/0/all/0/1">Benjamin Lecouteux</a>, <a href="http://arxiv.org/find/cs/1/au:+Portet_F/0/1/0/all/0/1">Francois Portet</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossato_S/0/1/0/all/0/1">Solange Rossato</a>, <a href="http://arxiv.org/find/cs/1/au:+Ringeval_F/0/1/0/all/0/1">Fabien Ringeval</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwab_D/0/1/0/all/0/1">Didier Schwab</a>, <a href="http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1">Laurent Besacier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11462">
                                    <div class="article-summary-box-inner">
                                        <span>Self-Supervised Learning (SSL) using huge unlabeled data has been
successfully explored for image and natural language processing. Recent works
also investigated SSL from speech. They were notably successful to improve
performance on downstream tasks such as automatic speech recognition (ASR).
While these works suggest it is possible to reduce dependence on labeled data
for building efficient speech systems, their evaluation was mostly made on ASR
and using multiple and heterogeneous experimental settings (most of them for
English). This questions the objective comparison of SSL approaches and the
evaluation of their impact on building speech systems. In this paper, we
propose LeBenchmark: a reproducible framework for assessing SSL from speech. It
not only includes ASR (high and low resource) tasks but also spoken language
understanding, speech translation and emotion recognition. We also focus on
speech technologies in a language different than English: French. SSL models of
different sizes are trained from carefully sourced and documented datasets.
Experiments show that SSL is beneficial for most but not all tasks which
confirms the need for exhaustive and reliable benchmarks to evaluate its real
impact. LeBenchmark is shared with the scientific community for reproducible
research in SSL from speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SA2SL: From Aspect-Based Sentiment Analysis to Social Listening System for Business Intelligence. (arXiv:2105.15079v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1">Luong Luc Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_P/0/1/0/all/0/1">Phuc Huynh Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kim Thi-Thanh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tham Thi Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_S/0/1/0/all/0/1">Sieu Khai Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1">Luan Thanh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1">Tin Van Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Kiet Van Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15079">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a process of building a social listening system
based on aspect-based sentiment analysis in Vietnamese from creating a dataset
to building a real application. Firstly, we create UIT-ViSFD, a Vietnamese
Smartphone Feedback Dataset as a new benchmark corpus built based on a strict
annotation schemes for evaluating aspect-based sentiment analysis, consisting
of 11,122 human-annotated comments for mobile e-commerce, which is freely
available for research purposes. We also present a proposed approach based on
the Bi-LSTM architecture with the fastText word embeddings for the Vietnamese
aspect based sentiment task. Our experiments show that our approach achieves
the best performances with the F1-score of 84.48% for the aspect task and
63.06% for the sentiment task, which performs several conventional machine
learning and deep learning systems. Last but not least, we build SA2SL, a
social listening system based on the best performance model on our dataset,
which will inspire more social listening systems in future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Code Generation from Natural Language with Less Prior and More Monolingual Data. (arXiv:2101.00259v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1">Sajad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Keyi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yanshuai Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00259">
                                    <div class="article-summary-box-inner">
                                        <span>Training datasets for semantic parsing are typically small due to the higher
expertise required for annotation than most other NLP tasks. As a result,
models for this application usually need additional prior knowledge to be built
into the architecture or algorithm. The increased dependency on human experts
hinders automation and raises the development and maintenance costs in
practice. This work investigates whether a generic transformer-based seq2seq
model can achieve competitive performance with minimal code-generation-specific
inductive bias design. By exploiting a relatively sizeable monolingual corpus
of the target programming language, which is cheap to mine from the web, we
achieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.
Both are SOTA to the best of our knowledge. This positive evidence highlights a
potentially easier path toward building accurate semantic parsers in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Text Specific and Blackbox Fairness Algorithms in Multimodal Clinical NLP. (arXiv:2011.09625v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">John Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Berlot_Attwell_I/0/1/0/all/0/1">Ian Berlot-Attwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1">Safwan Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xindi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudzicz_F/0/1/0/all/0/1">Frank Rudzicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09625">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical machine learning is increasingly multimodal, collected in both
structured tabular formats and unstructured forms such as freetext. We propose
a novel task of exploring fairness on a multimodal clinical dataset, adopting
equalized odds for the downstream medical prediction tasks. To this end, we
investigate a modality-agnostic fairness algorithm - equalized odds post
processing - and compare it to a text-specific fairness algorithm: debiased
clinical word embeddings. Despite the fact that debiased word embeddings do not
explicitly address equalized odds of protected groups, we show that a
text-specific approach to fairness may simultaneously achieve a good balance of
performance and classical notions of fairness. We hope that our paper inspires
future contributions at the critical intersection of clinical NLP and fairness.
The full source code is available here:
https://github.com/johntiger1/multimodal_fairness</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeurST: Neural Speech Translation Toolkit. (arXiv:2012.10018v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chengqi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10018">
                                    <div class="article-summary-box-inner">
                                        <span>NeurST is an open-source toolkit for neural speech translation. The toolkit
mainly focuses on end-to-end speech translation, which is easy to use, modify,
and extend to advanced speech translation research and products. NeurST aims at
facilitating the speech translation research for NLP researchers and building
reliable benchmarks for this field. It provides step-by-step recipes for
feature extraction, data preprocessing, distributed training, and evaluation.
In this paper, we will introduce the framework design of NeurST and show
experimental results for different benchmark datasets, which can be regarded as
reliable baselines for future research. The toolkit is publicly available at
https://github.com/bytedance/neurst/ and we will continuously update the
performance of NeurST with other counterparts and studies at
https://st-benchmark.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Cognitive Regularizer for Language Modeling. (arXiv:2105.07144v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1">Clara Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07144">
                                    <div class="article-summary-box-inner">
                                        <span>The uniform information density (UID) hypothesis, which posits that speakers
behaving optimally tend to distribute information uniformly across a linguistic
signal, has gained traction in psycholinguistics as an explanation for certain
syntactic, morphological, and prosodic choices. In this work, we explore
whether the UID hypothesis can be operationalized as an inductive bias for
statistical language modeling. Specifically, we augment the canonical MLE
objective for training language models with a regularizer that encodes UID. In
experiments on ten languages spanning five language families, we find that
using UID regularization consistently improves perplexity in language models,
having a larger effect when training data is limited. Moreover, via an analysis
of generated sequences, we find that UID-regularized language models have other
desirable properties, e.g., they generate text that is more lexically diverse.
Our results not only suggest that UID is a reasonable inductive bias for
language modeling, but also provide an alternative validation of the UID
hypothesis using modern-day NLP tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR. (arXiv:2104.01393v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lam_T/0/1/0/all/0/1">Tsz Kin Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohta_M/0/1/0/all/0/1">Mayumi Ohta</a>, <a href="http://arxiv.org/find/cs/1/au:+Schamoni_S/0/1/0/all/0/1">Shigehiko Schamoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1">Stefan Riezler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01393">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an on-the-fly data augmentation method for automatic speech
recognition (ASR) that uses alignment information to generate effective
training samples. Our method, called Aligned Data Augmentation (ADA) for ASR,
replaces transcribed tokens and the speech representations in an aligned manner
to generate previously unseen training pairs. The speech representations are
sampled from an audio dictionary that has been extracted from the training
corpus and inject speaker variations into the training examples. The
transcribed tokens are either predicted by a language model such that the
augmented data pairs are semantically close to the original data, or randomly
sampled. Both strategies result in training pairs that improve robustness in
ASR training. Our experiments on a Seq-to-Seq architecture show that ADA can be
applied on top of SpecAugment, and achieves about 9-23% and 4-15% relative
improvements in WER over SpecAugment alone on LibriSpeech 100h and LibriSpeech
960h test datasets, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KARI: KAnari/QCRI&#x27;s End-to-End systems for the INTERSPEECH 2021 Indian Languages Code-Switching Challenge. (arXiv:2106.05885v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hussein_A/0/1/0/all/0/1">Amir Hussein</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Ahmed Ali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05885">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present the Kanari/QCRI (KARI) system and the modeling
strategies used to participate in the Interspeech 2021 Code-switching (CS)
challenge for low-resource Indian languages. The subtask involved developing a
speech recognition system for two CS datasets: Hindi-English and
Bengali-English, collected in a real-life scenario. To tackle the CS
challenges, we use transfer learning for incorporating the publicly available
monolingual Hindi, Bengali, and English speech data. In this work, we study the
effectiveness of two steps transfer learning protocol for low-resourced CS
data: monolingual pretraining, followed by fine-tuning. For acoustic modeling,
we develop an end-to-end convolution-augmented transformer (Conformer). We show
that selecting the percentage of each monolingual data affects model biases
towards using one language character set over the other in a CS scenario. The
models pretrained on well-aligned and accurate monolingual data showed
robustness against misalignment between the segments and the transcription.
Finally, we develop word-level n-gram language models (LM) to rescore ASR
recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1">Austin Botelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertie Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate detection and classification of online hate is a difficult task.
Implicit hate is particularly challenging as such content tends to have unusual
syntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This
problem is heightened with multimodal content, such as memes (combinations of
text and images), as they are often harder to decipher than unimodal content
(e.g., text alone). This paper evaluates the role of semantic and multimodal
context for detecting implicit and explicit hate. We show that both text- and
visual- enrichment improves model performance, with the multimodal model
(0.771) outperforming other models&#x27; F1 scores (0.544, 0.737, and 0.754). While
the unimodal-text context-aware (transformer) model was the most accurate on
the subtask of implicit hate detection, the multimodal model outperformed it
overall because of a lower propensity towards false positives. We find that all
models perform better on content with full annotator agreement and that
multimodal models are best at classifying the content where annotators
disagree. To conduct these investigations, we undertook high-quality annotation
of a sample of 5,000 multimodal entries. Tweets were annotated for primary
category, modality, and strategy. We make this corpus, along with the codebook,
code, and final model, freely available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1">Devaraja Adiga</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1">Rishabh Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1">Amrith Krishna</a>, <a href="http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05852">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the
various linguistic peculiarities present in the language. The Sanskrit language
is lexically productive, undergoes euphonic assimilation of phones at the word
boundaries and exhibits variations in spelling conventions and in
pronunciations. In this work, we propose the first large scale study of
automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact
of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR
dataset for Sanskrit, which faithfully captures several of the linguistic
characteristics expressed by the language. We investigate the role of different
acoustic model and language model units in ASR systems for Sanskrit. We also
propose a new modelling unit, inspired by the syllable level unit selection,
that captures character sequences from one vowel in the word to the next vowel.
We also highlight the importance of choosing graphemic representations for
Sanskrit and show the impact of this choice on word error rates (WER). Finally,
we extend these insights from Sanskrit ASR for building ASR systems in two
other Indic languages, Gujarati and Telugu. For both these languages, our
experimental results show that the use of phonetic based graphemic
representations in ASR results in performance improvements as compared to ASR
systems that use native scripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wanrong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Eric Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1">An Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1">Miguel Eckstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05970">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic evaluations for natural language generation (NLG) conventionally
rely on token-level or embedding-level comparisons with the text references.
This is different from human language processing, for which visual imaginations
often improve comprehension. In this work, we propose ImaginE, an
imagination-based automatic evaluation metric for natural language generation.
With the help of CLIP and DALL-E, two cross-modal models pre-trained on
large-scale image-text pairs, we automatically generate an image as the
embodied imagination for the text snippet and compute the imagination
similarity using contextual embeddings. Experiments spanning several text
generation tasks demonstrate that adding imagination with our ImaginE displays
great potential in introducing multi-modal information into NLG evaluation, and
improves existing automatic metrics&#x27; correlations with human similarity
judgments in many circumstances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel Deep Learning-Driven Sarcasm Detection from Pop Culture Text and English Humor Literature. (arXiv:2106.05752v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Sourav Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolya_A/0/1/0/all/0/1">Anup Kumar Kolya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05752">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcasm is a sophisticated way of wrapping any immanent truth, mes-sage, or
even mockery within a hilarious manner. The advent of communications using
social networks has mass-produced new avenues of socialization. It can be
further said that humor, irony, sarcasm, and wit are the four chariots of being
socially funny in the modern days. In this paper, we manually extract the
sarcastic word distribution features of a benchmark pop culture sarcasm corpus,
containing sarcastic dialogues and monologues. We generate input sequences
formed of the weighted vectors from such words. We further propose an
amalgamation of four parallel deep long-short term networks (pLSTM), each with
distinctive activation classifier. These modules are primarily aimed at
successfully detecting sarcasm from the text corpus. Our proposed model for
detecting sarcasm peaks a training accuracy of 98.95% when trained with the
discussed dataset. Consecutively, it obtains the highest of 98.31% overall
validation accuracy on two handpicked Project Gutenberg English humor
literature among all the test cases. Our approach transcends previous
state-of-the-art works on several sarcasm corpora and results in a new gold
standard performance for sarcasm detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation. (arXiv:2106.05894v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1">Prakhar Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1">Yulia Tsvetkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1">Jeffrey P. Bigham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05894">
                                    <div class="article-summary-box-inner">
                                        <span>Open-domain neural dialogue models have achieved high performance in response
ranking and evaluation tasks. These tasks are formulated as a binary
classification of responses given in a dialogue context, and models generally
learn to make predictions based on context-response content similarity.
However, over-reliance on content similarity makes the models less sensitive to
the presence of inconsistencies, incorrect time expressions and other factors
important for response appropriateness and coherence. We propose approaches for
automatically creating adversarial negative training data to help ranking and
evaluation models learn features beyond content similarity. We propose
mask-and-fill and keyword-guided approaches that generate negative examples for
training more robust dialogue systems. These generated adversarial responses
have high content similarity with the contexts but are either incoherent,
inappropriate or not fluent. Our approaches are fully data-driven and can be
easily incorporated in existing models and datasets. Experiments on
classification, ranking and evaluation tasks across multiple datasets
demonstrate that our approaches outperform strong baselines in providing
informative negative examples for training dialogue systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Marginal Utility Diminishes: Exploring the Minimum Knowledge for BERT Knowledge Distillation. (arXiv:2106.05691v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuanxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fandong Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05691">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, knowledge distillation (KD) has shown great success in BERT
compression. Instead of only learning from the teacher&#x27;s soft label as in
conventional KD, researchers find that the rich information contained in the
hidden layers of BERT is conducive to the student&#x27;s performance. To better
exploit the hidden knowledge, a common practice is to force the student to
deeply mimic the teacher&#x27;s hidden states of all the tokens in a layer-wise
manner. In this paper, however, we observe that although distilling the
teacher&#x27;s hidden state knowledge (HSK) is helpful, the performance gain
(marginal utility) diminishes quickly as more HSK is distilled. To understand
this effect, we conduct a series of analysis. Specifically, we divide the HSK
of BERT into three dimensions, namely depth, length and width. We first
investigate a variety of strategies to extract crucial knowledge for each
single dimension and then jointly compress the three dimensions. In this way,
we show that 1) the student&#x27;s performance can be improved by extracting and
distilling the crucial HSK, and 2) using a tiny fraction of HSK can achieve the
same performance as extensive HSK distillation. Based on the second finding, we
further propose an efficient KD paradigm to compress BERT, which does not
require loading the teacher during the training of student. For two kinds of
student models and computing devices, the proposed KD paradigm gives rise to
training speedup of 2.7x ~ 3.4x.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Cheng-I Jeff Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alexander H. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shiyu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yi-Lun Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Sung Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1">Kaizhi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1">Sameer Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1">David Cox</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1">James Glass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05933">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work on speech self-supervised learning (speech SSL) demonstrated the
benefits of scale in learning rich and transferable representations for
Automatic Speech Recognition (ASR) with limited parallel data. It is then
natural to investigate the existence of sparse and transferrable subnetworks in
pre-trained speech SSL models that can achieve even better low-resource ASR
performance. However, directly applying widely adopted pruning methods such as
the Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost
needed. Moreover, contrary to what LTH predicts, the discovered subnetworks
yield minimal performance gain compared to the original dense network. In this
work, we propose Prune-Adjust- Re-Prune (PARP), which discovers and finetunes
subnetworks for much better ASR performance, while only requiring a single
downstream finetuning run. PARP is inspired by our surprising observation that
subnetworks pruned for pre-training tasks only needed to be slightly adjusted
to achieve a sizeable performance boost in downstream ASR tasks. Extensive
experiments on low-resource English and multi-lingual ASR show (1) sparse
subnetworks exist in pre-trained speech SSL, and (2) the computational
advantage and performance gain of PARP over baseline pruning methods. On the
10min Librispeech split without LM decoding, PARP discovers subnetworks from
wav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full
model. We demonstrate PARP mitigates performance degradation in cross-lingual
mask transfer, and investigate the possibility of discovering a single
subnetwork for 10 spoken languages in one run.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VT-SSum: A Benchmark Dataset for Video Transcript Segmentation and Summarization. (arXiv:2106.05606v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1">Tengchao Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Lei Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasilijevic_M/0/1/0/all/0/1">Momcilo Vasilijevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05606">
                                    <div class="article-summary-box-inner">
                                        <span>Video transcript summarization is a fundamental task for video understanding.
Conventional approaches for transcript summarization are usually built upon the
summarization data for written language such as news articles, while the domain
discrepancy may degrade the model performance on spoken text. In this paper, we
present VT-SSum, a benchmark dataset with spoken language for video transcript
segmentation and summarization, which includes 125K transcript-summary pairs
from 9,616 videos. VT-SSum takes advantage of the videos from VideoLectures.NET
by leveraging the slides content as the weak supervision to generate the
extractive summary for video transcripts. Experiments with a state-of-the-art
deep learning approach show that the model trained with VT-SSum brings a
significant improvement on the AMI spoken text summarization benchmark. VT-SSum
will be publicly available to support the future research of video transcript
segmentation and summarization tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Template-guided Hybrid Pointer Network for Knowledge-basedTask-oriented Dialogue Systems. (arXiv:2106.05830v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dingmin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Ziyao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wanwei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1">Li Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Yunzhe Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Min Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05830">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing neural network based task-oriented dialogue systems follow
encoder-decoder paradigm, where the decoder purely depends on the source texts
to generate a sequence of words, usually suffering from instability and poor
readability. Inspired by the traditional template-based generation approaches,
we propose a template-guided hybrid pointer network for the knowledge-based
task-oriented dialogue system, which retrieves several potentially relevant
answers from a pre-constructed domain-specific conversational repository as
guidance answers, and incorporates the guidance answers into both the encoding
and decoding processes. Specifically, we design a memory pointer network model
with a gating mechanism to fully exploit the semantic correlation between the
retrieved answers and the ground-truth response. We evaluate our model on four
widely used task-oriented datasets, including one simulated and three manually
created datasets. The experimental results demonstrate that the proposed model
achieves significantly better performance than the state-of-the-art methods
over different automatic evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Mingliang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1">Zeqian Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05630">
                                    <div class="article-summary-box-inner">
                                        <span>Symbolic music understanding, which refers to the understanding of music from
the symbolic data (e.g., MIDI format, but not audio), covers many music
applications such as genre classification, emotion classification, and music
pieces matching. While good music representations are beneficial for these
applications, the lack of training data hinders representation learning.
Inspired by the success of pre-training models in natural language processing,
in this paper, we develop MusicBERT, a large-scale pre-trained model for music
understanding. To this end, we construct a large-scale symbolic music corpus
that contains more than 1 million music songs. Since symbolic music contains
more structural (e.g., bar, position) and diverse information (e.g., tempo,
instrument, and pitch), simply adopting the pre-training techniques from NLP to
symbolic music only brings marginal gains. Therefore, we design several
mechanisms, including OctupleMIDI encoding and bar-level masking strategy, to
enhance pre-training with symbolic music data. Experiments demonstrate the
advantages of MusicBERT on four music understanding tasks, including melody
completion, accompaniment suggestion, genre classification, and style
classification. Ablation studies also verify the effectiveness of our designs
of OctupleMIDI encoding and bar-level masking strategy in MusicBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Unsupervised Pretraining Objectives for Machine Translation. (arXiv:2106.05634v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baziotis_C/0/1/0/all/0/1">Christos Baziotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1">Ivan Titov</a>, <a href="http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1">Alexandra Birch</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddow_B/0/1/0/all/0/1">Barry Haddow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05634">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised cross-lingual pretraining has achieved strong results in neural
machine translation (NMT), by drastically reducing the need for large parallel
data. Most approaches adapt masked-language modeling (MLM) to
sequence-to-sequence architectures, by masking parts of the input and
reconstructing them in the decoder. In this work, we systematically compare
masking with alternative objectives that produce inputs resembling real (full)
sentences, by reordering and replacing words based on their context. We
pretrain models with different methods on English$\leftrightarrow$German,
English$\leftrightarrow$Nepali and English$\leftrightarrow$Sinhala monolingual
data, and evaluate them on NMT. In (semi-) supervised NMT, varying the
pretraining objective leads to surprisingly small differences in the finetuned
performance, whereas unsupervised NMT is much more sensitive to it. To
understand these results, we thoroughly study the pretrained models using a
series of probes and verify that they encode and use information in different
ways. We conclude that finetuning on parallel data is mostly sensitive to few
properties that are shared by most models, such as a strong decoder, in
contrast to unsupervised NMT that also requires models with strong
cross-lingual abilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Text Classification and StackedHeterogeneous Embeddings for Named Entity Recognition in SMM4H 2021. (arXiv:2106.05823v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaseen_U/0/1/0/all/0/1">Usama Yaseen</a>, <a href="http://arxiv.org/find/cs/1/au:+Langer_S/0/1/0/all/0/1">Stefan Langer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05823">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents our findings from participating in the SMM4H Shared Task
2021. We addressed Named Entity Recognition (NER) and Text Classification. To
address NER we explored BiLSTM-CRF with Stacked Heterogeneous Embeddings and
linguistic features. We investigated various machine learning algorithms
(logistic regression, Support Vector Machine (SVM) and Neural Networks) to
address text classification. Our proposed approaches can be generalized to
different languages and we have shown its effectiveness for English and
Spanish. Our text classification submissions (team:MIC-NLP) have achieved
competitive performance with F1-score of $0.46$ and $0.90$ on ADE
Classification (Task 1a) and Profession Classification (Task 7a) respectively.
In the case of NER, our submissions scored F1-score of $0.50$ and $0.82$ on ADE
Span Detection (Task 1b) and Profession Span detection (Task 7b) respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CogAlign: Learning to Align Textual Neural Representations to Cognitive Language Processing Signals. (arXiv:2106.05544v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yuqi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1">Deyi Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05544">
                                    <div class="article-summary-box-inner">
                                        <span>Most previous studies integrate cognitive language processing signals (e.g.,
eye-tracking or EEG data) into neural models of natural language processing
(NLP) just by directly concatenating word embeddings with cognitive features,
ignoring the gap between the two modalities (i.e., textual vs. cognitive) and
noise in cognitive features. In this paper, we propose a CogAlign approach to
these issues, which learns to align textual neural representations to cognitive
features. In CogAlign, we use a shared encoder equipped with a modality
discriminator to alternatively encode textual and cognitive inputs to capture
their differences and commonalities. Additionally, a text-aware attention
mechanism is proposed to detect task-related information and to avoid using
noise in cognitive features. Experimental results on three NLP tasks, namely
named entity recognition, sentiment analysis and relation extraction, show that
CogAlign achieves significant improvements with multiple cognitive features
over state-of-the-art models on public datasets. Moreover, our model is able to
transfer cognitive information to other datasets that do not have any cognitive
processing signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving multi-speaker TTS prosody variance with a residual encoder and normalizing flows. (arXiv:2106.05762v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valles_Perez_I/0/1/0/all/0/1">Iv&#xe1;n Vall&#xe9;s-P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_J/0/1/0/all/0/1">Julian Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Beringer_G/0/1/0/all/0/1">Grzegorz Beringer</a>, <a href="http://arxiv.org/find/cs/1/au:+Barra_Chicote_R/0/1/0/all/0/1">Roberto Barra-Chicote</a>, <a href="http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1">Jasha Droppo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05762">
                                    <div class="article-summary-box-inner">
                                        <span>Text-to-speech systems recently achieved almost indistinguishable quality
from human speech. However, the prosody of those systems is generally flatter
than natural speech, producing samples with low expressiveness. Disentanglement
of speaker id and prosody is crucial in text-to-speech systems to improve on
naturalness and produce more variable syntheses. This paper proposes a new
neural text-to-speech model that approaches the disentanglement problem by
conditioning a Tacotron2-like architecture on flow-normalized speaker
embeddings, and by substituting the reference encoder with a new learned latent
distribution responsible for modeling the intra-sentence variability due to the
prosody. By removing the reference encoder dependency, the speaker-leakage
problem typically happening in this kind of systems disappears, producing more
distinctive syntheses at inference time. The new model achieves significantly
higher prosody variance than the baseline in a set of quantitative prosody
features, as well as higher speaker distinctiveness, without decreasing the
speaker intelligibility. Finally, we observe that the normalized speaker
embeddings enable much richer speaker interpolations, substantially improving
the distinctiveness of the new interpolated speakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition. (arXiv:2106.05642v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Binbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhendong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wenjing Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xin Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05642">
                                    <div class="article-summary-box-inner">
                                        <span>The unified streaming and non-streaming two-pass (U2) end-to-end model for
speech recognition has shown great performance in terms of streaming
capability, accuracy, real-time factor (RTF), and latency. In this paper, we
present U2++, an enhanced version of U2 to further improve the accuracy. The
core idea of U2++ is to use the forward and the backward information of the
labeling sequences at the same time at training to learn richer information,
and combine the forward and backward prediction at decoding to give more
accurate recognition results. We also proposed a new data augmentation method
called SpecSub to help the U2++ model to be more accurate and robust. Our
experiments show that, compared with U2, U2++ shows faster convergence at
training, better robustness to the decoding method, as well as consistent 5\% -
8\% word error rate reduction gain over U2. On the experiment of AISHELL-1, we
achieve a 4.63\% character error rate (CER) with a non-streaming setup and
5.05\% with a streaming setup with 320ms latency by U2++. To the best of our
knowledge, 5.05\% is the best-published streaming result on the AISHELL-1 test
set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Construction of Context-Aware Sentiment Lexicon in the Financial Domain Using Direction-Dependent Words. (arXiv:2106.05723v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jihye Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hye Jin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Sungzoon Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05723">
                                    <div class="article-summary-box-inner">
                                        <span>Increasing attention has been drawn to the sentiment analysis of financial
documents. The most popular examples of such documents include analyst reports
and economic news, the analysis of which is frequently used to capture the
trends in market sentiments. On the other hand, the significance of the role
sentiment analysis plays in the financial domain has given rise to the efforts
to construct a financial domain-specific sentiment lexicon. Sentiment lexicons
lend a hand for solving various text mining tasks, such as unsupervised
classification of text data, while alleviating the arduous human labor required
for manual labeling. One of the challenges in the construction of an effective
sentiment lexicon is that the semantic orientation of a word may change
depending on the context in which it appears. For instance, the word &#x60;&#x60;profit&quot;
usually conveys positive sentiments; however, when the word is juxtaposed with
another word &#x60;&#x60;decrease,&quot; the sentiment associated with the phrase &#x60;&#x60;profit
decreases&quot; now becomes negative. Hence, the sentiment of a given word may shift
as one begins to consider the context surrounding the word. In this paper, we
address this issue by incorporating context when building sentiment lexicon
from a given corpus. Specifically, we construct a lexicon named Senti-DD for
the Sentiment lexicon composed of Direction-Dependent words, which expresses
each term a pair of a directional word and a direction-dependent word.
Experiment results show that higher classification performance is achieved with
Senti-DD, proving the effectiveness of our method for automatically
constructing a context-aware sentiment lexicon in the financial domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shades of BLEU, Flavours of Success: The Case of MultiWOZ. (arXiv:2106.05555v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nekvinda_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Nekvinda</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1">Ond&#x159;ej Du&#x161;ek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05555">
                                    <div class="article-summary-box-inner">
                                        <span>The MultiWOZ dataset (Budzianowski et al.,2018) is frequently used for
benchmarking context-to-response abilities of task-oriented dialogue systems.
In this work, we identify inconsistencies in data preprocessing and reporting
of three corpus-based metrics used on this dataset, i.e., BLEU score and Inform
&amp; Success rates. We point out a few problems of the MultiWOZ benchmark such as
unsatisfactory preprocessing, insufficient or under-specified evaluation
metrics, or rigid database. We re-evaluate 7 end-to-end and 6 policy
optimization models in as-fair-as-possible setups, and we show that their
reported scores cannot be directly compared. To facilitate comparison of future
systems, we release our stand-alone standardized evaluation scripts. We also
give basic recommendations for corpus-based benchmarking in future works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Input Augmentation Improves Constrained Beam Search for Neural Machine Translation: NTT at WAT 2021. (arXiv:2106.05450v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chousa_K/0/1/0/all/0/1">Katsuki Chousa</a>, <a href="http://arxiv.org/find/cs/1/au:+Morishita_M/0/1/0/all/0/1">Makoto Morishita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05450">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes our systems that were submitted to the restricted
translation task at WAT 2021. In this task, the systems are required to output
translated sentences that contain all given word constraints. Our system
combined input augmentation and constrained beam search algorithms. Through
experiments, we found that this combination significantly improves translation
accuracy and can save inference time while containing all the constraints in
the output. For both En-&gt;Ja and Ja-&gt;En, our systems obtained the best
evaluation performances in automatic evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutions and Self-Attention: Re-interpreting Relative Positions in Pre-trained Language Models. (arXiv:2106.05505v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1">Tyler A. Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yifan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weijian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05505">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we detail the relationship between convolutions and
self-attention in natural language tasks. We show that relative position
embeddings in self-attention layers are equivalent to recently-proposed dynamic
lightweight convolutions, and we consider multiple new ways of integrating
convolutions into Transformer self-attention. Specifically, we propose
composite attention, which unites previous relative position embedding methods
under a convolutional framework. We conduct experiments by training BERT with
composite attention, finding that convolutions consistently improve performance
on multiple downstream tasks, replacing absolute position embeddings. To inform
future work, we present results comparing lightweight convolutions, dynamic
convolutions, and depthwise-separable convolutions in language model
pre-training, considering multiple injection points for convolutions in
self-attention layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1">Richard Antonello</a>, <a href="http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1">Javier Turek</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1">Vy Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1">Alexander Huth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05426">
                                    <div class="article-summary-box-inner">
                                        <span>How related are the representations learned by neural language models,
translation models, and language tagging tasks? We answer this question by
adapting an encoder-decoder transfer learning method from computer vision to
investigate the structure among 100 different feature spaces extracted from
hidden representations of various networks trained on language tasks. This
method reveals a low-dimensional structure where language models and
translation models smoothly interpolate between word embeddings, syntactic and
semantic tasks, and future word embeddings. We call this low-dimensional
structure a language representation embedding because it encodes the
relationships between representations needed to process language for a variety
of NLP tasks. We find that this representation embedding can predict how well
each individual feature space maps to human brain responses to natural language
stimuli recorded using fMRI. Additionally, we find that the principal dimension
of this structure can be used to create a metric which highlights the brain&#x27;s
natural language processing hierarchy. This suggests that the embedding
captures some part of the brain&#x27;s natural language representation structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGGGEN: Ordering and Aggregating while Generating. (arXiv:2106.05580v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinnuo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1">Ond&#x159;ej Du&#x161;ek</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1">Verena Rieser</a>, <a href="http://arxiv.org/find/cs/1/au:+Konstas_I/0/1/0/all/0/1">Ioannis Konstas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05580">
                                    <div class="article-summary-box-inner">
                                        <span>We present AGGGEN (pronounced &#x27;again&#x27;), a data-to-text model which
re-introduces two explicit sentence planning stages into neural data-to-text
systems: input ordering and input aggregation. In contrast to previous work
using sentence planning, our model is still end-to-end: AGGGEN performs
sentence planning at the same time as generating text by learning latent
alignments (via semantic facts) between input representation and target text.
Experiments on the WebNLG and E2E challenge data show that by using fact-based
alignments our approach is more interpretable, expressive, robust to noise, and
easier to control, while retaining the advantages of end-to-end systems in
terms of fluency. Our code is available at https://github.com/XinnuoXu/AggGen.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grover&#x27;s Algorithm for Question Answering. (arXiv:2106.05299v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Correia_A/0/1/0/all/0/1">A. D. Correia</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Moortgat_M/0/1/0/all/0/1">M. Moortgat</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Stoof_H/0/1/0/all/0/1">H. T. C. Stoof</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05299">
                                    <div class="article-summary-box-inner">
                                        <span>Grover&#x27;s algorithm, a well-know quantum search algorithm, allows one to find
the correct item in a database, with quadratic speedup. In this paper we adapt
Grover&#x27;s algorithm to the problem of finding a correct answer to a natural
language question in English, thus contributing to the growing field of Quantum
Natural Language Processing. Using a grammar that can be interpreted as tensor
contractions, each word is represented as a quantum state that serves as input
to the quantum circuit. We here introduce a quantum measurement to contract the
representations of words, resulting in the representation of larger text
fragments. Using this framework, a representation for the question is found
that contains all the possible answers in equal quantum superposition, and
allows for the building of an oracle that can detect a correct answer, being
agnostic to the specific question. Furthermore, we show that our construction
can deal with certain types of ambiguous phrases by keeping the various
different meanings in quantum superposition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation to improve robustness of image captioning solutions. (arXiv:2106.05437v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1">Shashank Bujimalla</a>, <a href="http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1">Mahesh Subedar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1">Omesh Tickoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05437">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the impact of motion blur, a common quality flaw in
real world images, on a state-of-the-art two-stage image captioning solution,
and notice a degradation in solution performance as blur intensity increases.
We investigate techniques to improve the robustness of the solution to motion
blur using training data augmentation at each or both stages of the solution,
i.e., object detection and captioning, and observe improved results. In
particular, augmenting both the stages reduces the CIDEr-D degradation for high
motion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to
6.8 on Vizwiz dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Robust are Model Rankings: A Leaderboard Customization Approach for Equitable Evaluation. (arXiv:2106.05532v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1">Anjana Arunkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05532">
                                    <div class="article-summary-box-inner">
                                        <span>Models that top leaderboards often perform unsatisfactorily when deployed in
real world applications; this has necessitated rigorous and expensive
pre-deployment model testing. A hitherto unexplored facet of model performance
is: Are our leaderboards doing equitable evaluation? In this paper, we
introduce a task-agnostic method to probe leaderboards by weighting samples
based on their &#x60;difficulty&#x27; level. We find that leaderboards can be
adversarially attacked and top performing models may not always be the best
models. We subsequently propose alternate evaluation metrics. Our experiments
on 10 models show changes in model ranking and an overall reduction in
previously reported performance -- thus rectifying the overestimation of AI
systems&#x27; capabilities. Inspired by behavioral testing principles, we further
develop a prototype of a visual analytics tool that enables leaderboard
revamping through customization, based on an end user&#x27;s focus area. This helps
users analyze models&#x27; strengths and weaknesses, and guides them in the
selection of a model best suited for their application scenario. In a user
study, members of various commercial product development teams, covering 5
focus areas, find that our prototype reduces pre-deployment development and
testing effort by 41% on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Information Bottleneck for Effective Low-Resource Fine-Tuning. (arXiv:2106.05469v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1">Rabeeh Karimi Mahabadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1">Yonatan Belinkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1">James Henderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05469">
                                    <div class="article-summary-box-inner">
                                        <span>While large-scale pretrained language models have obtained impressive results
when fine-tuned on a wide variety of tasks, they still often suffer from
overfitting in low-resource scenarios. Since such models are general-purpose
feature extractors, many of these features are inevitably irrelevant for a
given target task. We propose to use Variational Information Bottleneck (VIB)
to suppress irrelevant features when fine-tuning on low-resource target tasks,
and show that our method successfully reduces overfitting. Moreover, we show
that our VIB model finds sentence representations that are more robust to
biases in natural language inference datasets, and thereby obtains better
generalization to out-of-domain datasets. Evaluation on seven low-resource
datasets in different tasks shows that our method significantly improves
transfer learning in low-resource scenarios, surpassing prior work. Moreover,
it improves generalization on 13 out of 15 out-of-domain natural language
inference benchmarks. Our code is publicly available in
https://github.com/rabeehk/vibert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Free TextSpotter for Real-Time and Mobile End-to-End Text Detection and Recognition. (arXiv:2106.05611v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoshihashi_R/0/1/0/all/0/1">Ryota Yoshihashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_T/0/1/0/all/0/1">Tomohiro Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Doi_K/0/1/0/all/0/1">Kenji Doi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fujino_T/0/1/0/all/0/1">Takumi Fujino</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamashita_N/0/1/0/all/0/1">Naoaki Yamashita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05611">
                                    <div class="article-summary-box-inner">
                                        <span>In the deployment of scene-text spotting systems on mobile platforms,
lightweight models with low computation are preferable. In concept, end-to-end
(E2E) text spotting is suitable for such purposes because it performs text
detection and recognition in a single model. However, current state-of-the-art
E2E methods rely on heavy feature extractors, recurrent sequence modellings,
and complex shape aligners to pursue accuracy, which means their computations
are still heavy. We explore the opposite direction: How far can we go without
bells and whistles in E2E text spotting? To this end, we propose a
text-spotting method that consists of simple convolutions and a few
post-processes, named Context-Free TextSpotter. Experiments using standard
benchmarks show that Context-Free TextSpotter achieves real-time text spotting
on a GPU with only three million parameters, which is the smallest and fastest
among existing deep text spotters, with an acceptable transcription quality
degradation compared to heavier ones. Further, we demonstrate that our text
spotter can run on a smartphone with affordable latency, which is valuable for
building stand-alone OCR applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit-PDF: Non-Parametric Representation of Probability Distributions on the Rotation Manifold. (arXiv:2106.05965v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1">Kieran Murphy</a>, <a href="http://arxiv.org/find/cs/1/au:+Esteves_C/0/1/0/all/0/1">Carlos Esteves</a>, <a href="http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1">Varun Jampani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1">Srikumar Ramalingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1">Ameesh Makadia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05965">
                                    <div class="article-summary-box-inner">
                                        <span>Single image pose estimation is a fundamental problem in many vision and
robotics tasks, and existing deep learning approaches suffer by not completely
modeling and handling: i) uncertainty about the predictions, and ii) symmetric
objects with multiple (sometimes infinite) correct poses. To this end, we
introduce a method to estimate arbitrary, non-parametric distributions on
SO(3). Our key idea is to represent the distributions implicitly, with a neural
network that estimates the probability given the input image and a candidate
pose. Grid sampling or gradient ascent can be used to find the most likely
pose, but it is also possible to evaluate the probability at any pose, enabling
reasoning about symmetries and uncertainty. This is the most general way of
representing distributions on manifolds, and to showcase the rich expressive
power, we introduce a dataset of challenging symmetric and nearly-symmetric
objects. We require no supervision on pose uncertainty -- the model trains only
with a single pose per example. Nonetheless, our implicit model is highly
expressive to handle complex distributions over 3D poses, while still obtaining
accurate pose estimation on standard non-ambiguous environments, achieving
state-of-the-art performance on Pascal3D+ and ModelNet10-SO(3) benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Adder Neural Networks. (arXiv:2105.14202v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14202">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with cheap addition operation, multiplication operation is of much
higher computation complexity. The widely-used convolutions in deep neural
networks are exactly cross-correlation to measure the similarity between input
feature and convolution filters, which involves massive multiplications between
float values. In this paper, we present adder networks (AdderNets) to trade
these massive multiplications in deep neural networks, especially convolutional
neural networks (CNNs), for much cheaper additions to reduce computation costs.
In AdderNets, we take the $\ell_1$-norm distance between filters and input
feature as the output response. The influence of this new similarity measure on
the optimization of neural network have been thoroughly analyzed. To achieve a
better performance, we develop a special training approach for AdderNets by
investigating the $\ell_p$-norm. We then propose an adaptive learning rate
strategy to enhance the training procedure of AdderNets according to the
magnitude of each neuron&#x27;s gradient. As a result, the proposed AdderNets can
achieve 75.7% Top-1 accuracy 92.3% Top-5 accuracy using ResNet-50 on the
ImageNet dataset without any multiplication in convolutional layer. Moreover,
we develop a theoretical foundation for AdderNets, by showing that both the
single hidden layer AdderNet and the width-bounded deep AdderNet with ReLU
activation functions are universal function approximators. These results match
those of the traditional neural networks using the more complex multiplication
units. An approximation bound for AdderNets with a single hidden layer is also
presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoviLearn: A Machine Learning Integrated Smart X-Ray Device in Healthcare Cyber-Physical System for Automatic Initial Screening of COVID-19. (arXiv:2106.05861v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Das_D/0/1/0/all/0/1">Debanjan Das</a>, <a href="http://arxiv.org/find/eess/1/au:+Samal_C/0/1/0/all/0/1">Chirag Samal</a>, <a href="http://arxiv.org/find/eess/1/au:+Ukey_D/0/1/0/all/0/1">Deewanshu Ukey</a>, <a href="http://arxiv.org/find/eess/1/au:+Chowdhary_G/0/1/0/all/0/1">Gourav Chowdhary</a>, <a href="http://arxiv.org/find/eess/1/au:+Mohanty_S/0/1/0/all/0/1">Saraju P. Mohanty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05861">
                                    <div class="article-summary-box-inner">
                                        <span>The pandemic of novel Coronavirus Disease 2019 (COVID-19) is widespread all
over the world causing serious health problems as well as serious impact on the
global economy. Reliable and fast testing of the COVID-19 has been a challenge
for researchers and healthcare practitioners. In this work we present a novel
machine learning (ML) integrated X-ray device in Healthcare Cyber-Physical
System (H-CPS) or smart healthcare framework (called CoviLearn) to allow
healthcare practitioners to perform automatic initial screening of COVID-19
patients. We propose convolutional neural network (CNN) models of X-ray images
integrated into an X-ray device for automatic COVID-19 detection. The proposed
CoviLearn device will be useful in detecting if a person is COVID-19 positive
or negative by considering the chest X-ray image of individuals. CoviLearn will
be useful tool doctors to detect potential COVID-19 infections instantaneously
without taking more intrusive healthcare data samples, such as saliva and
blood. COVID-19 attacks the endothelium tissues that support respiratory tract,
X-rays images can be used to analyze the health of a patient lungs. As all
healthcare centers have X-ray machines, it could be possible to use proposed
CoviLearn X-rays to test for COVID-19 without the especial test kits. Our
proposed automated analysis system CoviLearn which has 99% accuracy will be
able to save valuable time of medical professionals as the X-ray machines come
with a drawback as it needed a radiology expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D-CNN for Facial Micro- and Macro-expression Spotting on Long Video Sequences using Temporal Oriented Reference Frame. (arXiv:2105.06340v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yap_C/0/1/0/all/0/1">Chuin Hong Yap</a>, <a href="http://arxiv.org/find/cs/1/au:+Yap_M/0/1/0/all/0/1">Moi Hoon Yap</a>, <a href="http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1">Adrian K. Davison</a>, <a href="http://arxiv.org/find/cs/1/au:+Cunningham_R/0/1/0/all/0/1">Ryan Cunningham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06340">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expression spotting is the preliminary step for micro- and
macro-expression analysis. The task of reliably spotting such expressions in
video sequences is currently unsolved. The current best systems depend upon
optical flow methods to extract regional motion features, before categorisation
of that motion into a specific class of facial movement. Optical flow is
susceptible to drift error, which introduces a serious problem for motions with
long-term dependencies, such as high frame-rate macro-expression. We propose a
purely deep learning solution which, rather than track frame differential
motion, compares via a convolutional model, each frame with two temporally
local reference frames. Reference frames are sampled according to calculated
micro- and macro-expression durations. We show that our solution achieves
state-of-the-art performance (F1-score of 0.126) in a dataset of high
frame-rate (200 fps) long video sequences (SAMM-LV) and is competitive in a low
frame-rate (30 fps) dataset (CAS(ME)2). In this paper, we document our deep
learning model and parameters, including how we use local contrast
normalisation, which we show is critical for optimal results. We surpass a
limitation in existing methods, and advance the state of deep learning in the
domain of facial expression spotting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning ordered pooling weights in image classification. (arXiv:2007.01243v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1">J.I.Forcen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1">Miguel Pagola</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1">Edurne Barrenechea</a>, <a href="http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1">Humberto Bustince</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01243">
                                    <div class="article-summary-box-inner">
                                        <span>Spatial pooling is an important step in computer vision systems like
Convolutional Neural Networks or the Bag-of-Words method. The spatial pooling
purpose is to combine neighbouring descriptors to obtain a single descriptor
for a given region (local or global). The resultant combined vector must be as
discriminant as possible, in other words, must contain relevant information,
while removing irrelevant and confusing details. Maximum and average are the
most common aggregation functions used in the pooling step. To improve the
aggregation of relevant information without degrading their discriminative
power for image classification, we introduce a simple but effective scheme
based on Ordered Weighted Average (OWA) aggregation operators. We present a
method to learn the weights of the OWA aggregation operator in a Bag-of-Words
framework and in Convolutional Neural Networks, and provide an extensive
evaluation showing that OWA based pooling outperforms classical aggregation
operators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-resolution Outlier Pooling for Sorghum Classification. (arXiv:2106.05748v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_C/0/1/0/all/0/1">Chao Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Dulay_J/0/1/0/all/0/1">Justin Dulay</a>, <a href="http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1">Gregory Rolwes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauli_D/0/1/0/all/0/1">Duke Pauli</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakoor_N/0/1/0/all/0/1">Nadia Shakoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1">Abby Stylianou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05748">
                                    <div class="article-summary-box-inner">
                                        <span>Automated high throughput plant phenotyping involves leveraging sensors, such
as RGB, thermal and hyperspectral cameras (among others), to make large scale
and rapid measurements of the physical properties of plants for the purpose of
better understanding the difference between crops and facilitating rapid plant
breeding programs. One of the most basic phenotyping tasks is to determine the
cultivar, or species, in a particular sensor product. This simple phenotype can
be used to detect errors in planting and to learn the most differentiating
features between cultivars. It is also a challenging visual recognition task,
as a large number of highly related crops are grown simultaneously, leading to
a classification problem with low inter-class variance. In this paper, we
introduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum
captured by a state-of-the-art gantry system, a multi-resolution network
architecture that learns both global and fine-grained features on the crops,
and a new global pooling strategy called Dynamic Outlier Pooling which
outperforms standard global pooling strategies on this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1">Hakan Bilen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08259">
                                    <div class="article-summary-box-inner">
                                        <span>In many machine learning problems, large-scale datasets have become the
de-facto standard to train state-of-the-art deep networks at the price of heavy
computation load. In this paper, we focus on condensing large training sets
into significantly smaller synthetic sets which can be used to train deep
neural networks from scratch with minimum drop in performance. Inspired from
the recent training set synthesis methods, we propose Differentiable Siamese
Augmentation that enables effective use of data augmentation to synthesize more
informative synthetic images and thus achieves better performance when training
networks with augmentations. Experiments on multiple image classification
benchmarks demonstrate that the proposed method obtains substantial gains over
the state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show
with only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%
relative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We
also explore the use of our method in continual learning and neural
architecture search, and show promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Light Image and Video Enhancement Using Deep Learning: A Survey. (arXiv:2104.10729v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chongyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chunle Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Linghao Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jinwei Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10729">
                                    <div class="article-summary-box-inner">
                                        <span>Low-light image enhancement (LLIE) aims at improving the perception or
interpretability of an image captured in an environment with poor illumination.
Recent advances in this area are dominated by deep learning-based solutions,
where many learning strategies, network structures, loss functions, training
data, etc. have been employed. In this paper, we provide a comprehensive survey
to cover various aspects ranging from algorithm taxonomy to unsolved open
issues. To examine the generalization of existing methods, we propose a
large-scale low-light image and video dataset, in which the images and videos
are taken by different mobile phones&#x27; cameras under diverse illumination
conditions. Besides, for the first time, we provide a unified online platform
that covers many popular LLIE methods, of which the results can be produced
through a user-friendly web interface. In addition to qualitative and
quantitative evaluation of existing methods on publicly available and our
proposed datasets, we also validate their performance in face detection in the
dark. This survey together with the proposed dataset and online platform could
serve as a reference source for future study and promote the development of
this research field. The proposed platform and the collected methods, datasets,
and evaluation metrics are publicly available and will be regularly updated at
https://github.com/Li-Chongyi/Lighting-the-Darkness-in-the-Deep-Learning-Era-Open.
Our low-light image and video dataset is also available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To The Point: Correspondence-driven monocular 3D category reconstruction. (arXiv:2106.05662v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1">Filippos Kokkinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkinos_I/0/1/0/all/0/1">Iasonas Kokkinos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05662">
                                    <div class="article-summary-box-inner">
                                        <span>We present To The Point (TTP), a method for reconstructing 3D objects from a
single image using 2D to 3D correspondences learned from weak supervision. We
recover a 3D shape from a 2D image by first regressing the 2D positions
corresponding to the 3D template vertices and then jointly estimating a rigid
camera transform and non-rigid template deformation that optimally explain the
2D positions through the 3D shape projection. By relying on 3D-2D
correspondences we use a simple per-sample optimization problem to replace
CNN-based regression of camera pose and non-rigid deformation and thereby
obtain substantially more accurate 3D reconstructions. We treat this
optimization as a differentiable layer and train the whole system in an
end-to-end manner. We report systematic quantitative improvements on multiple
categories and provide qualitative results comprising diverse shape, pose and
texture prediction examples. Project website:
https://fkokkinos.github.io/to_the_point/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Co-occurrence of deep convolutional features for image search. (arXiv:2003.13827v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1">J.I.Forcen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1">Miguel Pagola</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1">Edurne Barrenechea</a>, <a href="http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1">Humberto Bustince</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13827">
                                    <div class="article-summary-box-inner">
                                        <span>Image search can be tackled using deep features from pre-trained
Convolutional Neural Networks (CNN). The feature map from the last
convolutional layer of a CNN encodes descriptive information from which a
discriminative global descriptor can be obtained. We propose a new
representation of co-occurrences from deep convolutional features to extract
additional relevant information from this last convolutional layer. Combining
this co-occurrence map with the feature map, we achieve an improved image
representation. We present two different methods to get the co-occurrence
representation, the first one based on direct aggregation of activations, and
the second one, based on a trainable co-occurrence representation. The image
descriptors derived from our methodology improve the performance in very
well-known image retrieval datasets as we prove in the experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Persistent Homology Topological Features to Characterize Medical Images: Case Studies on Lung and Brain Cancers. (arXiv:2012.12102v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moon_C/0/1/0/all/0/1">Chul Moon</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1">Guanghua Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12102">
                                    <div class="article-summary-box-inner">
                                        <span>Tumor shape is a key factor that affects tumor growth and metastasis. This
paper proposes a topological feature computed by persistent homology to
characterize tumor progression from digital pathology and radiology images and
examines its effect on the time-to-event data. The proposed topological
features are invariant to scale-preserving transformation and can summarize
various tumor shape patterns. The topological features are represented in
functional space and used as functional predictors in a functional Cox
proportional hazards model. The proposed model enables interpretable inference
about the association between topological shape features and survival risks.
Two case studies are conducted using consecutive 143 lung cancer and 77 brain
tumor patients. The results of both studies show that the topological features
predict survival prognosis after adjusting clinical variables, and the
predicted high-risk groups have significantly (at the level of 0.01) worse
survival outcomes than the low-risk groups. Also, the topological shape
features found to be positively associated with survival hazards are irregular
and heterogeneous shape patterns, which are known to be related to tumor
progression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consistent Instance False Positive Improves Fairness in Face Recognition. (arXiv:2106.05519v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xingkun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuge Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_P/0/1/0/all/0/1">Pengcheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaoxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhen Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05519">
                                    <div class="article-summary-box-inner">
                                        <span>Demographic bias is a significant challenge in practical face recognition
systems. Existing methods heavily rely on accurate demographic annotations.
However, such annotations are usually unavailable in real scenarios. Moreover,
these methods are typically designed for a specific demographic group and are
not general enough. In this paper, we propose a false positive rate penalty
loss, which mitigates face recognition bias by increasing the consistency of
instance False Positive Rate (FPR). Specifically, we first define the instance
FPR as the ratio between the number of the non-target similarities above a
unified threshold and the total number of the non-target similarities. The
unified threshold is estimated for a given total FPR. Then, an additional
penalty term, which is in proportion to the ratio of instance FPR overall FPR,
is introduced into the denominator of the softmax-based loss. The larger the
instance FPR, the larger the penalty. By such unequal penalties, the instance
FPRs are supposed to be consistent. Compared with the previous debiasing
methods, our method requires no demographic annotations. Thus, it can mitigate
the bias among demographic groups divided by various attributes, and these
attributes are not needed to be previously predefined during training.
Extensive experimental results on popular benchmarks demonstrate the
superiority of our method over state-of-the-art competitors. Code and trained
models are available at https://github.com/Tencent/TFace.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SVMA: A GAN-based model for Monocular 3D Human Pose Estimation. (arXiv:2106.05616v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yicheng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yongqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiahui Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05616">
                                    <div class="article-summary-box-inner">
                                        <span>Recovering 3D human pose from 2D joints is a highly unconstrained problem,
especially without any video or multi-view information. We present an
unsupervised GAN-based model to recover 3D human pose from 2D joint locations
extracted from a single image. Our model uses a GAN to learn the mapping of
distribution from 2D poses to 3D poses, not the simple 2D-3D correspondence.
Considering the reprojection constraint, our model can estimate the camera so
that we can reproject the estimated 3D pose to the original 2D pose. Based on
this reprojection method, we can rotate and reproject the generated pose to get
our &quot;new&quot; 2D pose and then use a weight sharing generator to estimate the &quot;new&quot;
3D pose and a &quot;new&quot; camera. Through the above estimation process, we can define
the single-view-multi-angle consistency loss during training to simulate
multi-view consistency, which means the 3D poses and cameras estimated from two
angles of a single view should be able to be mixed to generate rich 2D
reprojections, and the 2D reprojections reprojected from the same 3D pose
should be consistent. The experimental results on Human3.6M show that our
method outperforms all the state-of-the-art methods, and results on
MPI-INF-3DHP show that our method outperforms state-of-the-art by approximately
15.0%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification. (arXiv:2106.05517v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weifeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_C/0/1/0/all/0/1">Chao Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05517">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning (FSL) aims to learn a classifier that can be easily adapted
to accommodate new tasks not seen during training, given only a few examples.
To handle the limited-data problem in few-shot regimes, recent methods tend to
collectively use a set of local features to densely represent an image instead
of using a mixed global feature. They generally explore a unidirectional
query-to-support paradigm in FSL, e.g., find the nearest/optimal support
feature for each query feature and aggregate these local matches for a joint
classification. In this paper, we propose a new method Mutual Centralized
Learning (MCL) to fully affiliate the two disjoint sets of dense features in a
bidirectional paradigm. We associate each local feature with a particle that
can bidirectionally random walk in a discrete feature space by the
affiliations. To estimate the class probability, we propose the features&#x27;
accessibility that measures the expected number of visits to the support
features of that class in a Markov process. We relate our method to learning a
centrality on an affiliation network and demonstrate its capability to be
plugged in existing methods by highlighting centralized local features.
Experiments show that our method achieves the state-of-the-art on both
miniImageNet and tieredImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised 3D Hand Pose Estimation from monocular RGB via Contrastive Learning. (arXiv:2106.05953v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1">Adrian Spurr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahiya_A/0/1/0/all/0/1">Aneesh Dahiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xucong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05953">
                                    <div class="article-summary-box-inner">
                                        <span>Acquiring accurate 3D annotated data for hand pose estimation is a
notoriously difficult problem. This typically requires complex multi-camera
setups and controlled conditions, which in turn creates a domain gap that is
hard to bridge to fully unconstrained settings. Encouraged by the success of
contrastive learning on image classification tasks, we propose a new
self-supervised method for the structured regression task of 3D hand pose
estimation. Contrastive learning makes use of unlabeled data for the purpose of
representation learning via a loss formulation that encourages the learned
feature representations to be invariant under any image transformation. For 3D
hand pose estimation, it too is desirable to have invariance to appearance
transformation such as color jitter. However, the task requires equivariance
under affine transformations, such as rotation and translation. To address this
issue, we propose an equivariant contrastive objective and demonstrate its
effectiveness in the context of 3D hand pose estimation. We experimentally
investigate the impact of invariant and equivariant contrastive objectives and
show that learning equivariant features leads to better representations for the
task of 3D hand pose estimation. Furthermore, we show that a standard
ResNet-152, trained on additional unlabeled data, attains an improvement of
$7.6\%$ in PA-EPE on FreiHAND and thus achieves state-of-the-art performance
without any task specific, specialized architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AlphaNet: Improved Training of Supernets with Alpha-Divergence. (arXiv:2102.07954v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1">Chengyue Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Meng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1">Vikas Chandra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07954">
                                    <div class="article-summary-box-inner">
                                        <span>Weight-sharing neural architecture search (NAS) is an effective technique for
automating efficient neural architecture design. Weight-sharing NAS builds a
supernet that assembles all the architectures as its sub-networks and jointly
trains the supernet with the sub-networks. The success of weight-sharing NAS
heavily relies on distilling the knowledge of the supernet to the sub-networks.
However, we find that the widely used distillation divergence, i.e., KL
divergence, may lead to student sub-networks that over-estimate or
under-estimate the uncertainty of the teacher supernet, leading to inferior
performance of the sub-networks. In this work, we propose to improve the
supernet training with a more generalized alpha-divergence. By adaptively
selecting the alpha-divergence, we simultaneously prevent the over-estimation
or under-estimation of the uncertainty of the teacher model. We apply the
proposed alpha-divergence based supernets training to both slimmable neural
networks and weight-sharing NAS, and demonstrate significant improvements.
Specifically, our discovered model family, AlphaNet, outperforms prior-art
models on a wide range of FLOPs regimes, including BigNAS, Once-for-All
networks, and AttentiveNAS. We achieve ImageNet top-1 accuracy of 80.0% with
only 444M FLOPs. Our code and pretrained models are available at
https://github.com/facebookresearch/AlphaNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion. (arXiv:2012.02177v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duzceker_A/0/1/0/all/0/1">Arda D&#xfc;z&#xe7;eker</a>, <a href="http://arxiv.org/find/cs/1/au:+Galliani_S/0/1/0/all/0/1">Silvano Galliani</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogel_C/0/1/0/all/0/1">Christoph Vogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Speciale_P/0/1/0/all/0/1">Pablo Speciale</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusmanu_M/0/1/0/all/0/1">Mihai Dusmanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02177">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an online multi-view depth prediction approach on posed video
streams, where the scene geometry information computed in the previous time
steps is propagated to the current time step in an efficient and geometrically
plausible way. The backbone of our approach is a real-time capable, lightweight
encoder-decoder that relies on cost volumes computed from pairs of images. We
extend it by placing a ConvLSTM cell at the bottleneck layer, which compresses
an arbitrary amount of past information in its states. The novelty lies in
propagating the hidden state of the cell by accounting for the viewpoint
changes between time steps. At a given time step, we warp the previous hidden
state into the current camera plane using the previous depth prediction. Our
extension brings only a small overhead of computation time and memory
consumption, while improving the depth predictions significantly. As a result,
we outperform the existing state-of-the-art multi-view stereo methods on most
of the evaluated metrics in hundreds of indoor scenes while maintaining a
real-time performance. Code available:
https://github.com/ardaduz/deep-video-mvs</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation. (arXiv:2106.05969v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhengyi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1">Ryo Hachiuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Ye Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris Kitani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05969">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method for object-aware 3D egocentric pose estimation that
tightly integrates kinematics modeling, dynamics modeling, and scene object
information. Unlike prior kinematics or dynamics-based approaches where the two
components are used disjointly, we synergize the two approaches via
dynamics-regulated training. At each timestep, a kinematic model is used to
provide a target pose using video evidence and simulation state. Then, a
prelearned dynamics model attempts to mimic the kinematic pose in a physics
simulator. By comparing the pose instructed by the kinematic model against the
pose generated by the dynamics model, we can use their misalignment to further
improve the kinematic model. By factoring in the 6DoF pose of objects (e.g.,
chairs, boxes) in the scene, we demonstrate for the first time, the ability to
estimate physically-plausible 3D human-object interactions using a single
wearable camera. We evaluate our egocentric pose estimation method in both
controlled laboratory settings and real-world scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to See by Looking at Noise. (arXiv:2106.05963v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baradad_M/0/1/0/all/0/1">Manel Baradad</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1">Jonas Wulff</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tongzhou Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05963">
                                    <div class="article-summary-box-inner">
                                        <span>Current vision systems are trained on huge datasets, and these datasets come
with costs: curation is expensive, they inherit human biases, and there are
concerns over privacy and usage rights. To counter these costs, interest has
surged in learning from cheaper data sources, such as unlabeled images. In this
paper we go a step further and ask if we can do away with real image datasets
entirely, instead learning from noise processes. We investigate a suite of
image generation models that produce images from simple random processes. These
are then used as training data for a visual representation learner with a
contrastive loss. We study two types of noise processes, statistical image
models and deep generative models under different random initializations. Our
findings show that it is important for the noise to capture certain structural
properties of real data but that good performance can be achieved even with
processes that are far from realistic. We also find that diversity is a key
property to learn good representations. Datasets, models, and code are
available at https://mbaradad.github.io/learning_with_noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A numerical framework for elastic surface matching, comparison, and interpolation. (arXiv:2006.11652v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bauer_M/0/1/0/all/0/1">Martin Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Charon_N/0/1/0/all/0/1">Nicolas Charon</a>, <a href="http://arxiv.org/find/cs/1/au:+Harms_P/0/1/0/all/0/1">Philipp Harms</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_H/0/1/0/all/0/1">Hsi-Wei Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11652">
                                    <div class="article-summary-box-inner">
                                        <span>Surface comparison and matching is a challenging problem in computer vision.
While reparametrization-invariant Sobolev metrics provide meaningful elastic
distances and point correspondences via the geodesic boundary value problem,
solving this problem numerically tends to be difficult. Square root normal
fields (SRNF) considerably simplify the computation of certain elastic
distances between parametrized surfaces. Yet they leave open the issue of
finding optimal reparametrizations, which induce elastic distances between
unparametrized surfaces. This issue has concentrated much effort in recent
years and led to the development of several numerical frameworks. In this
paper, we take an alternative approach which bypasses the direct estimation of
reparametrizations: we relax the geodesic boundary constraint using an
auxiliary parametrization-blind varifold fidelity metric. This reformulation
has several notable benefits. By avoiding altogether the need for
reparametrizations, it provides the flexibility to deal with simplicial meshes
of arbitrary topologies and sampling patterns. Moreover, the problem lends
itself to a coarse-to-fine multi-resolution implementation, which makes the
algorithm scalable to large meshes. Furthermore, this approach extends readily
to higher-order feature maps such as square root curvature fields and is also
able to include surface textures in the matching problem. We demonstrate these
advantages on several examples, synthetic and real.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning. (arXiv:2106.05682v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">Youngtaek Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05682">
                                    <div class="article-summary-box-inner">
                                        <span>The capability of the traditional semi-supervised learning (SSL) methods is
far from real-world application since they do not consider (1) class imbalance
and (2) class distribution mismatch between labeled and unlabeled data. This
paper addresses such a relatively under-explored problem, imbalanced
semi-supervised learning, where heavily biased pseudo-labels can harm the model
performance. Interestingly, we find that the semantic pseudo-labels from a
similarity-based classifier in feature space and the traditional pseudo-labels
from the linear classifier show the complementary property. To this end, we
propose a general pseudo-labeling framework to address the bias motivated by
this observation. The key idea is to class-adaptively blend the semantic
pseudo-label to the linear one, depending on the current pseudo-label
distribution. Thereby, the increased semantic pseudo-label component suppresses
the false positives in the majority classes and vice versa. We term the novel
pseudo-labeling framework for imbalanced SSL as Distribution-Aware
Semantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT
and STL10-LT shows that DASO consistently outperforms both recently proposed
re-balancing methods for label and pseudo-label. Moreover, we demonstrate that
typical SSL algorithms can effectively benefit from unlabeled data with DASO,
especially when (1) class imbalance and (2) class distribution mismatch exist
and even on recent real-world Semi-Aves benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatially Invariant Unsupervised 3D Object Segmentation with Graph Neural Networks. (arXiv:2106.05607v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_K/0/1/0/all/0/1">Kee Siong Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Miaomiao Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05607">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we tackle the problem of unsupervised 3D object segmentation
from a point cloud without RGB information. In particular, we propose a
framework,~{\bf SPAIR3D}, to model a point cloud as a spatial mixture model and
jointly learn the multiple-object representation and segmentation in 3D via
Variational Autoencoders (VAE). Inspired by SPAIR, we adopt an
object-specification scheme that describes each object&#x27;s location relative to
its local voxel grid cell rather than the point cloud as a whole. To model the
spatial mixture model on point clouds, we derive the~\emph{Chamfer Likelihood},
which fits naturally into the variational training pipeline. We further design
a new spatially invariant graph neural network to generate a varying number of
3D points as a decoder within our VAE.~Experimental results demonstrate
that~{\bf SPAIR3D} is capable of detecting and segmenting variable number of
objects without appearance information across diverse scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantized Conditional COT-GAN for Video Prediction. (arXiv:2106.05658v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Xu_T/0/1/0/all/0/1">Tianlin Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Acciaio_B/0/1/0/all/0/1">Beatrice Acciaio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05658">
                                    <div class="article-summary-box-inner">
                                        <span>Causal Optimal Transport (COT) results from imposing a temporal causality
constraint on classic optimal transport problems, which naturally generates a
new concept of distances between distributions on path spaces. The first
application of the COT theory for sequential learning was given in Xu et al.
(2020), where COT-GAN was introduced as an adversarial algorithm to train
implicit generative models optimized for producing sequential data. Relying on
Xu et al. (2020), the contribution of the present paper is twofold. First, we
develop a conditional version of COT-GAN suitable for sequence prediction. This
means that the dataset is now used in order to learn how a sequence will evolve
given the observation of its past evolution. Second, we improve on the
convergence results by working with modifications of the empirical measures via
a specific type of quantization due to Backhoff et al. (2020). The resulting
quantized conditional COT-GAN algorithm is illustrated with an application for
video prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal Discrete Representation Learning. (arXiv:2106.05438v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alexander H. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1">SouYoung Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Cheng-I Jeff Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouditchenko_A/0/1/0/all/0/1">Andrew Rouditchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliva_A/0/1/0/all/0/1">Aude Oliva</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1">James Glass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05438">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in representation learning have demonstrated an ability to
represent information from different modalities such as video, text, and audio
in a single high-level embedding vector. In this work we present a
self-supervised learning framework that is able to learn a representation that
captures finer levels of granularity across different modalities such as
concepts or events represented by visual objects or spoken words. Our framework
relies on a discretized embedding space created via vector quantization that is
shared across different modalities. Beyond the shared embedding space, we
propose a Cross-Modal Code Matching objective that forces the representations
from different views (modalities) to have a similar distribution over the
discrete embedding space such that cross-modal objects/actions localization can
be performed without direct supervision. In our experiments we show that the
proposed discretized multi-modal fine-grained representation (e.g.,
pixel/word/frame) can complement high-level summary representations (e.g.,
video/sentence/waveform) for improved performance on cross-modal retrieval
tasks. We also observe that the discretized representation uses individual
clusters to represent the same semantic concept across modalities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Match What Matters: Generative Implicit Feature Replay for Continual Learning. (arXiv:2106.05350v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thandiackal_K/0/1/0/all/0/1">Kevin Thandiackal</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Portenier_T/0/1/0/all/0/1">Tiziano Portenier</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Giovannini_A/0/1/0/all/0/1">Andrea Giovannini</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Gabrani_M/0/1/0/all/0/1">Maria Gabrani</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Goksel_O/0/1/0/all/0/1">Orcun Goksel</a> (2 and 3) ((1) IBM Research Europe, (2) ETH Zurich, (3) Uppsala University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05350">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are prone to catastrophic forgetting when trained
incrementally on different tasks. In order to prevent forgetting, most existing
methods retain a small subset of previously seen samples, which in turn can be
used for joint training with new tasks. While this is indeed effective, it may
not always be possible to store such samples, e.g., due to data protection
regulations. In these cases, one can instead employ generative models to create
artificial samples or features representing memories from previous tasks.
Following a similar direction, we propose GenIFeR (Generative Implicit Feature
Replay) for class-incremental learning. The main idea is to train a generative
adversarial network (GAN) to generate images that contain realistic features.
While the generator creates images at full resolution, the discriminator only
sees the corresponding features extracted by the continually trained
classifier. Since the classifier compresses raw images into features that are
actually relevant for classification, the GAN can match this target
distribution more accurately. On the other hand, allowing the generator to
create full resolution images has several benefits: In contrast to previous
approaches, the feature extractor of the classifier does not have to be frozen.
In addition, we can employ augmentations on generated images, which not only
boosts classification performance, but also mitigates discriminator overfitting
during GAN training. We empirically show that GenIFeR is superior to both
conventional generative image and feature replay. In particular, we
significantly outperform the state-of-the-art in generative replay for various
settings on the CIFAR-100 and CUB-200 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving Robust Neural Architectures to Defend from Adversarial Attacks. (arXiv:1906.11667v3 [cs.NE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1">Shashank Kotyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1">Danilo Vasconcellos Vargas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.11667">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are prone to misclassify slightly modified input images.
Recently, many defences have been proposed, but none have improved the
robustness of neural networks consistently. Here, we propose to use adversarial
attacks as a function evaluation to search for neural architectures that can
resist such attacks automatically. Experiments on neural architecture search
algorithms from the literature show that although accurate, they are not able
to find robust architectures. A significant reason for this lies in their
limited search space. By creating a novel neural architecture search with
options for dense layers to connect with convolution layers and vice-versa as
well as the addition of concatenation layers in the search, we were able to
evolve an architecture that is inherently accurate on adversarial samples.
Interestingly, this inherent robustness of the evolved architecture rivals
state-of-the-art defences such as adversarial training while being trained only
on the non-adversarial samples. Moreover, the evolved architecture makes use of
some peculiar traits which might be useful for developing even more robust
ones. Thus, the results here confirm that more robust architectures exist as
well as opens up a new realm of feasibilities for the development and
exploration of neural networks.

Code available at this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResMLP: Feedforward networks for image classification with data-efficient training. (arXiv:2105.03404v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1">Hugo Touvron</a>, <a href="http://arxiv.org/find/cs/1/au:+Bojanowski_P/0/1/0/all/0/1">Piotr Bojanowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Caron_M/0/1/0/all/0/1">Mathilde Caron</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Nouby_A/0/1/0/all/0/1">Alaaeldin El-Nouby</a>, <a href="http://arxiv.org/find/cs/1/au:+Grave_E/0/1/0/all/0/1">Edouard Grave</a>, <a href="http://arxiv.org/find/cs/1/au:+Izacard_G/0/1/0/all/0/1">Gautier Izacard</a>, <a href="http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1">Armand Joulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1">Gabriel Synnaeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Verbeek_J/0/1/0/all/0/1">Jakob Verbeek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegou_H/0/1/0/all/0/1">Herv&#xe9; J&#xe9;gou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03404">
                                    <div class="article-summary-box-inner">
                                        <span>We present ResMLP, an architecture built entirely upon multi-layer
perceptrons for image classification. It is a simple residual network that
alternates (i) a linear layer in which image patches interact, independently
and identically across channels, and (ii) a two-layer feed-forward network in
which channels interact independently per patch. When trained with a modern
training strategy using heavy data-augmentation and optionally distillation, it
attains surprisingly good accuracy/complexity trade-offs on ImageNet. We also
train ResMLP models in a self-supervised setup, to further remove priors from
employing a labelled dataset. Finally, by adapting our model to machine
translation we achieve surprisingly good results.

We share pre-trained models and our code based on the Timm library.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Motion Modelling helps Semi-supervised Hand Pose Estimation. (arXiv:2106.05954v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Spurr_A/0/1/0/all/0/1">Adrian Spurr</a>, <a href="http://arxiv.org/find/cs/1/au:+Molchanov_P/0/1/0/all/0/1">Pavlo Molchanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_U/0/1/0/all/0/1">Umar Iqbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1">Jan Kautz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1">Otmar Hilliges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05954">
                                    <div class="article-summary-box-inner">
                                        <span>Hand pose estimation is difficult due to different environmental conditions,
object- and self-occlusion as well as diversity in hand shape and appearance.
Exhaustively covering this wide range of factors in fully annotated datasets
has remained impractical, posing significant challenges for generalization of
supervised methods. Embracing this challenge, we propose to combine ideas from
adversarial training and motion modelling to tap into unlabeled videos. To this
end we propose what to the best of our knowledge is the first motion model for
hands and show that an adversarial formulation leads to better generalization
properties of the hand pose estimator via semi-supervised training on unlabeled
video sequences. In this setting, the pose predictor must produce a valid
sequence of hand poses, as determined by a discriminative adversary. This
adversary reasons both on the structural as well as temporal domain,
effectively exploiting the spatio-temporal structure in the task. The main
advantage of our approach is that we can make use of unpaired videos and joint
sequence data both of which are much easier to attain than paired training
data. We perform extensive evaluation, investigating essential components
needed for the proposed framework and empirically demonstrate in two
challenging settings that the proposed approach leads to significant
improvements in pose estimation accuracy. In the lowest label setting, we
attain an improvement of $40\%$ in absolute mean joint error.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concealed Object Detection. (arXiv:2102.10274v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1">Ge-Peng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10274">
                                    <div class="article-summary-box-inner">
                                        <span>We present the first systematic study on concealed object detection (COD),
which aims to identify objects that are &quot;perfectly&quot; embedded in their
background. The high intrinsic similarities between the concealed objects and
their background make COD far more challenging than traditional object
detection/segmentation. To better understand this task, we collect a
large-scale dataset, called COD10K, which consists of 10,000 images covering
concealed objects in diverse real-world scenarios from 78 object categories.
Further, we provide rich annotations including object categories, object
boundaries, challenging attributes, object-level labels, and instance-level
annotations. Our COD10K is the largest COD dataset to date, with the richest
annotations, which enables comprehensive concealed object understanding and can
even be used to help progress several other vision tasks, such as detection,
segmentation, classification, etc. Motivated by how animals hunt in the wild,
we also design a simple but strong baseline for COD, termed the Search
Identification Network (SINet). Without any bells and whistles, SINet
outperforms 12 cutting-edge baselines on all datasets tested, making them
robust, general architectures that could serve as catalysts for future research
in COD. Finally, we provide some interesting findings and highlight several
potential applications and future directions. To spark research in this new
field, our code, dataset, and online demo are available on our project page:
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemSegLoss: A python package of loss functions for semantic segmentation. (arXiv:2106.05844v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jadon_S/0/1/0/all/0/1">Shruti Jadon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05844">
                                    <div class="article-summary-box-inner">
                                        <span>Image Segmentation has been an active field of research as it has a wide
range of applications, ranging from automated disease detection to self-driving
cars. In recent years, various research papers proposed different loss
functions used in case of biased data, sparse segmentation, and unbalanced
dataset. In this paper, we introduce SemSegLoss, a python package consisting of
some of the well-known loss functions widely used for image segmentation. It is
developed with the intent to help researchers in the development of novel loss
functions and perform an extensive set of experiments on model architectures
for various applications. The ease-of-use and flexibility of the presented
package have allowed reducing the development time and increased evaluation
strategies of machine learning models for semantic segmentation. Furthermore,
different applications that use image segmentation can use SemSegLoss because
of the generality of its functions. This wide range of applications will lead
to the development and growth of AI across all industries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CALTeC: Content-Adaptive Linear Tensor Completion for Collaborative Intelligence. (arXiv:2106.05531v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Dhondea_A/0/1/0/all/0/1">Ashiv Dhondea</a>, <a href="http://arxiv.org/find/eess/1/au:+Cohen_R/0/1/0/all/0/1">Robert A. Cohen</a>, <a href="http://arxiv.org/find/eess/1/au:+Bajic_I/0/1/0/all/0/1">Ivan V. Baji&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05531">
                                    <div class="article-summary-box-inner">
                                        <span>In collaborative intelligence, an artificial intelligence (AI) model is
typically split between an edge device and the cloud. Feature tensors produced
by the edge sub-model are sent to the cloud via an imperfect communication
channel. At the cloud side, parts of the feature tensor may be missing due to
packet loss. In this paper we propose a method called Content-Adaptive Linear
Tensor Completion (CALTeC) to recover the missing feature data. The proposed
method is fast, data-adaptive, does not require pre-training, and produces
better results than existing methods for tensor data recovery in collaborative
intelligence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Landmark and Structure Learning for Automatic Evaluation of Developmental Dysplasia of the Hip. (arXiv:2106.05458v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xindi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wufeng Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shengfeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuhao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shuangping Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1">Ning Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1">Dong Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1">Ning Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05458">
                                    <div class="article-summary-box-inner">
                                        <span>The ultrasound (US) screening of the infant hip is vital for the early
diagnosis of developmental dysplasia of the hip (DDH). The US diagnosis of DDH
refers to measuring alpha and beta angles that quantify hip joint development.
These two angles are calculated from key anatomical landmarks and structures of
the hip. However, this measurement process is not trivial for sonographers and
usually requires a thorough understanding of complex anatomical structures. In
this study, we propose a multi-task framework to learn the relationships among
landmarks and structures jointly and automatically evaluate DDH. Our multi-task
networks are equipped with three novel modules. Firstly, we adopt Mask R-CNN as
the basic framework to detect and segment key anatomical structures and add one
landmark detection branch to form a new multi-task framework. Secondly, we
propose a novel shape similarity loss to refine the incomplete anatomical
structure prediction robustly and accurately. Thirdly, we further incorporate
the landmark-structure consistent prior to ensure the consistency of the bony
rim estimated from the segmented structure and the detected landmark. In our
experiments, 1,231 US images of the infant hip from 632 patients are collected,
of which 247 images from 126 patients are tested. The average errors in alpha
and beta angles are 2.221 degrees and 2.899 degrees. About 93% and 85%
estimates of alpha and beta angles have errors less than 5 degrees,
respectively. Experimental results demonstrate that the proposed method can
accurately and robustly realize the automatic evaluation of DDH, showing great
potential for clinical application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An adaptive Origin-Destination flows cluster-detecting method to identify urban mobility trends. (arXiv:2106.05436v1 [cs.CG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Mengyuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1">Luliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_Z/0/1/0/all/0/1">Zihan Kan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_T/0/1/0/all/0/1">Tao Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingquan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chaokui Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05436">
                                    <div class="article-summary-box-inner">
                                        <span>Origin-Destination (OD) flow, as an abstract representation of the object&#x60;s
movement or interaction, has been used to reveal the urban mobility and
human-land interaction pattern. As an important spatial analysis approach, the
clustering methods of point events have been extended to OD flows to identify
the dominant trends and spatial structures of urban mobility. However, the
existing methods for OD flow cluster-detecting are limited both in specific
spatial scale and the uncertain result due to different parameters setting,
which is difficult for complicated OD flows clustering under spatial
heterogeneity. To address these limitations, in this paper, we proposed a novel
OD flows cluster-detecting method based on the OPTICS algorithm which can
identify OD flow clusters with various aggregation scales. The method can
adaptively determine parameter value from the dataset without prior knowledge
and artificial intervention. Experiments indicated that our method outperformed
three state-of-the-art methods with more accurate and complete of clusters and
less noise. As a case study, our method is applied to identify the potential
routes for public transport service settings by detecting OD flow clusters
within urban travel data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers. (arXiv:2106.05392v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patrick_M/0/1/0/all/0/1">Mandela Patrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1">Dylan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1">Yuki M. Asano</a>, <a href="http://arxiv.org/find/cs/1/au:+Metze_I/0/1/0/all/0/1">Ishan Misra Florian Metze</a>, <a href="http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1">Christoph Feichtenhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1">Andrea Vedaldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1">Jo\&#xe3;o F. Henriques</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05392">
                                    <div class="article-summary-box-inner">
                                        <span>In video transformers, the time dimension is often treated in the same way as
the two spatial dimensions. However, in a scene where objects or the camera may
move, a physical point imaged at one location in frame $t$ may be entirely
unrelated to what is found at that location in frame $t+k$. These temporal
correspondences should be modeled to facilitate learning about dynamic scenes.
To this end, we propose a new drop-in block for video transformers --
trajectory attention -- that aggregates information along implicitly determined
motion paths. We additionally propose a new method to address the quadratic
dependence of computation and memory on the input size, which is particularly
important for high resolution or long videos. While these ideas are useful in a
range of settings, we apply them to the specific task of video action
recognition with a transformer model and obtain state-of-the-art results on the
Kinetics, Something--Something V2, and Epic-Kitchens datasets. Code and models
are available at: https://github.com/facebookresearch/Motionformer</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. (arXiv:2106.05970v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wanrong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Eric Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_A/0/1/0/all/0/1">An Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1">Miguel Eckstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05970">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic evaluations for natural language generation (NLG) conventionally
rely on token-level or embedding-level comparisons with the text references.
This is different from human language processing, for which visual imaginations
often improve comprehension. In this work, we propose ImaginE, an
imagination-based automatic evaluation metric for natural language generation.
With the help of CLIP and DALL-E, two cross-modal models pre-trained on
large-scale image-text pairs, we automatically generate an image as the
embodied imagination for the text snippet and compute the imagination
similarity using contextual embeddings. Experiments spanning several text
generation tasks demonstrate that adding imagination with our ImaginE displays
great potential in introducing multi-modal information into NLG evaluation, and
improves existing automatic metrics&#x27; correlations with human similarity
judgments in many circumstances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CondLaneNet: a Top-to-down Lane Detection Framework Based on Conditional Convolution. (arXiv:2105.05003v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Siyu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1">Ping Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05003">
                                    <div class="article-summary-box-inner">
                                        <span>Modern deep-learning-based lane detection methods are successful in most
scenarios but struggling for lane lines with complex topologies. In this work,
we propose CondLaneNet, a novel top-to-down lane detection framework that
detects the lane instances first and then dynamically predicts the line shape
for each instance. Aiming to resolve lane instance-level discrimination
problem, we introduce a conditional lane detection strategy based on
conditional convolution and row-wise formulation. Further, we design the
Recurrent Instance Module(RIM) to overcome the problem of detecting lane lines
with complex topologies such as dense lines and fork lines. Benefit from the
end-to-end pipeline which requires little post-process, our method has
real-time efficiency. We extensively evaluate our method on three benchmarks of
lane detection. Results show that our method achieves state-of-the-art
performance on all three benchmark datasets. Moreover, our method has the
coexistence of accuracy and efficiency, e.g. a 78.14 F1 score and 220 FPS on
CULane. Our code is available at
https://github.com/aliyun/conditional-lane-detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Transformers with Patch Diversification. (arXiv:2104.12753v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1">Chengyue Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Meng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1">Vikas Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12753">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformer has demonstrated promising performance on challenging
computer vision tasks. However, directly training the vision transformers may
yield unstable and sub-optimal results. Recent works propose to improve the
performance of the vision transformers by modifying the transformer structures,
e.g., incorporating convolution layers. In contrast, we investigate an
orthogonal approach to stabilize the vision transformer training without
modifying the networks. We observe the instability of the training can be
attributed to the significant similarity across the extracted patch
representations. More specifically, for deep vision transformers, the
self-attention blocks tend to map different patches into similar latent
representations, yielding information loss and performance degradation. To
alleviate this problem, in this work, we introduce novel loss functions in
vision transformer training to explicitly encourage diversity across patch
representations for more discriminative feature extraction. We empirically show
that our proposed techniques stabilize the training and allow us to train wider
and deeper vision transformers. We further show the diversified features
significantly benefit the downstream tasks in transfer learning. For semantic
segmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and
ADE20k. Our code will be made publicly available soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1">Sophia Bano</a>, <a href="http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1">Alessandro Casella</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1">Francisco Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1">Sara Moccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1">George Attilakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1">Ruwan Wimalasundera</a>, <a href="http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1">Anna L. David</a>, <a href="http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1">Dario Paladini</a>, <a href="http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1">Jan Deprest</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1">Leonardo S. Mattos</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05923">
                                    <div class="article-summary-box-inner">
                                        <span>Fetoscopy laser photocoagulation is a widely used procedure for the treatment
of Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic
multiple pregnancies due to placental vascular anastomoses. This procedure is
particularly challenging due to limited field of view, poor manoeuvrability of
the fetoscope, poor visibility due to fluid turbidity, variability in light
source, and unusual position of the placenta. This may lead to increased
procedural time and incomplete ablation, resulting in persistent TTTS.
Computer-assisted intervention may help overcome these challenges by expanding
the fetoscopic field of view through video mosaicking and providing better
visualization of the vessel network. However, the research and development in
this domain remain limited due to unavailability of high-quality data to encode
the intra- and inter-procedure variability. Through the Fetoscopic Placental
Vessel Segmentation and Registration (FetReg) challenge, we present a
large-scale multi-centre dataset for the development of generalized and robust
semantic segmentation and video mosaicking algorithms for the fetal environment
with a focus on creating drift-free mosaics from long duration fetoscopy
videos. In this paper, we provide an overview of the FetReg dataset, challenge
tasks, evaluation metrics and baseline methods for both segmentation and
registration. Baseline methods results on the FetReg dataset shows that our
dataset poses interesting challenges, which can be modelled and competed for
through our crowd-sourcing initiative of the FetReg challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in Computed Tomography. (arXiv:2105.14711v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1">Yang Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Ce Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hui_Y/0/1/0/all/0/1">Yuan Hui</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_S/0/1/0/all/0/1">Shiwei Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_M/0/1/0/all/0/1">Mengke Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Quan_Q/0/1/0/all/0/1">Quan Quan</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1">Shuxin Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hao_Y/0/1/0/all/0/1">You Hao</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1">Pengbo Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_H/0/1/0/all/0/1">Honghu Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_C/0/1/0/all/0/1">Chunpeng Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1">Xinbao Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1">S. Kevin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14711">
                                    <div class="article-summary-box-inner">
                                        <span>Spine-related diseases have high morbidity and cause a huge burden of social
cost. Spine imaging is an essential tool for noninvasively visualizing and
assessing spinal pathology. Segmenting vertebrae in computed tomography (CT)
images is the basis of quantitative medical image analysis for clinical
diagnosis and surgery planning of spine diseases. Current publicly available
annotated datasets on spinal vertebrae are small in size. Due to the lack of a
large-scale annotated spine image dataset, the mainstream deep learning-based
segmentation methods, which are data-driven, are heavily restricted. In this
paper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated
from multiple sources for vertebra segmentation, which contains 1,005 CT
volumes with over 11,100 labeled vertebrae belonging to different spinal
conditions. Based on this dataset, we conduct several spinal vertebrae
segmentation experiments to set the first benchmark. We believe that this
large-scale dataset will facilitate further research in many spine-related
image analysis tasks, including but not limited to vertebrae segmentation,
labeling, 3D spine reconstruction from biplanar radiographs, image
super-resolution, and enhancement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure Guided Lane Detection. (arXiv:2105.05403v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jinming Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Ke Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Junfeng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaoming Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1">Xiaolin Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05403">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, lane detection has made great progress with the rapid development
of deep neural networks and autonomous driving. However, there exist three
mainly problems including characterizing lanes, modeling the structural
relationship between scenes and lanes, and supporting more attributes (e.g.,
instance and type) of lanes. In this paper, we propose a novel structure guided
framework to solve these problems simultaneously. In the framework, we first
introduce a new lane representation to characterize each instance. Then a
topdown vanishing point guided anchoring mechanism is proposed to produce
intensive anchors, which efficiently capture various lanes. Next, multi-level
structural constraints are used to improve the perception of lanes. In the
process, pixel-level perception with binary segmentation is introduced to
promote features around anchors and restore lane details from bottom up, a
lane-level relation is put forward to model structures (i.e., parallel) around
lanes, and an image-level attention is used to adaptively attend different
regions of the image from the perspective of scenes. With the help of
structural guidance, anchors are effectively classified and regressed to obtain
precise locations and shapes. Extensive experiments on public benchmark
datasets show that the proposed approach outperforms state-of-the-art methods
with 117 FPS on a single GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases. (arXiv:2103.10697v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1">St&#xe9;phane d&#x27;Ascoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1">Hugo Touvron</a>, <a href="http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1">Matthew Leavitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1">Ari Morcos</a>, <a href="http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1">Giulio Biroli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1">Levent Sagun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10697">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional architectures have proven extremely successful for vision
tasks. Their hard inductive biases enable sample-efficient learning, but come
at the cost of a potentially lower performance ceiling. Vision Transformers
(ViTs) rely on more flexible self-attention layers, and have recently
outperformed CNNs for image classification. However, they require costly
pre-training on large external datasets or distillation from pre-trained
convolutional networks. In this paper, we ask the following question: is it
possible to combine the strengths of these two architectures while avoiding
their respective limitations? To this end, we introduce gated positional
self-attention (GPSA), a form of positional self-attention which can be
equipped with a &#x60;&#x60;soft&quot; convolutional inductive bias. We initialise the GPSA
layers to mimic the locality of convolutional layers, then give each attention
head the freedom to escape locality by adjusting a gating parameter regulating
the attention paid to position versus content information. The resulting
convolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet,
while offering a much improved sample efficiency. We further investigate the
role of locality in learning by first quantifying how it is encouraged in
vanilla self-attention layers, then analysing how it is escaped in GPSA layers.
We conclude by presenting various ablations to better understand the success of
the ConViT. Our code and models are released publicly at
https://github.com/facebookresearch/convit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Min-Fong Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao-Yun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min-Hung Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yu-Syuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1">Hsien-Kai Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yi-Min Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hung-Jen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1">Kevin Jou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11014">
                                    <div class="article-summary-box-inner">
                                        <span>Network spaces have been known as a critical factor in both handcrafted
network designs or defining search spaces for Neural Architecture Search (NAS).
However, an effective space involves tremendous prior knowledge and/or manual
effort, and additional constraints are required to discover efficiency-aware
architectures. In this paper, we define a new problem, Network Space Search
(NSS), as searching for favorable network spaces instead of a single
architecture. We propose an NSS method to directly search for efficient-aware
network spaces automatically, reducing the manual effort and immense cost in
discovering satisfactory ones. The resultant network spaces, named Elite
Spaces, are discovered from Expanded Search Space with minimal human expertise
imposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front
under various complexity constraints and can be further served as NAS search
spaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an
averagely 2.3% lower error rate and 3.7% closer to target constraint than the
baseline with around 90% fewer samples required to find satisfactory networks).
Moreover, our NSS approach is capable of searching for superior spaces in
future unexplored spaces, revealing great potential in searching for network
spaces automatically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MLP-Mixer: An all-MLP Architecture for Vision. (arXiv:2105.01601v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1">Ilya Tolstikhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1">Thomas Unterthiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Yung_J/0/1/0/all/0/1">Jessica Yung</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1">Andreas Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1">Daniel Keysers</a>, <a href="http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1">Jakob Uszkoreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1">Mario Lucic</a>, <a href="http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1">Alexey Dosovitskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01601">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) are the go-to model for computer vision.
Recently, attention-based networks, such as the Vision Transformer, have also
become popular. In this paper we show that while convolutions and attention are
both sufficient for good performance, neither of them are necessary. We present
MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).
MLP-Mixer contains two types of layers: one with MLPs applied independently to
image patches (i.e. &quot;mixing&quot; the per-location features), and one with MLPs
applied across patches (i.e. &quot;mixing&quot; spatial information). When trained on
large datasets, or with modern regularization schemes, MLP-Mixer attains
competitive scores on image classification benchmarks, with pre-training and
inference cost comparable to state-of-the-art models. We hope that these
results spark further research beyond the realms of well established CNNs and
Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisImages: a Corpus of Visualizations in the Images of Visualization Publications. (arXiv:2007.04584v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_D/0/1/0/all/0/1">Dazhen Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yihong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1">Xinhuan Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengye Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1">Siwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1">Weiwei Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yingcai Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04584">
                                    <div class="article-summary-box-inner">
                                        <span>Images in visualization publications contain rich information, e.g., novel
visualization designs and common combinations of visualizations. A systematic
collection of these images can contribute to the community in many aspects,
such as literature analysis and automated tasks for visualization. In this
paper, we build and make public a dataset, VisImages, which collects 12,267
images with captions from 1,397 papers in IEEE InfoVis and VAST. Based on a
refined taxonomy for visualizations in publications, the dataset includes
35,096 annotated visualizations, as well as their positions. We demonstrate the
usefulness of VisImages through three use cases: 1) exploring and analyzing the
evolution of visualizations with VisImages Explorer, 2) training and
benchmarking models for visualization classification, and 3) localizing and
recognizing visualizations in the images automatically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving state estimation through projection post-processing for activity recognition in football. (arXiv:2102.03310v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ciszewski_M/0/1/0/all/0/1">Micha&#x142; Ciszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohl_J/0/1/0/all/0/1">Jakob S&#xf6;hl</a>, <a href="http://arxiv.org/find/cs/1/au:+Jongbloed_G/0/1/0/all/0/1">Geurt Jongbloed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03310">
                                    <div class="article-summary-box-inner">
                                        <span>The past decade has seen an increased interest in human activity recognition.
Most commonly, the raw data coming from sensors attached to body parts are
unannotated, which creates a need for fast labelling method. Part of the
procedure is choosing or designing an appropriate performance measure. We
propose a new performance measure, the Locally Time-Shifted Measure, which
addresses the issue of timing uncertainty of state transitions in the
classification result. Our main contribution is a novel post-processing method
for binary activity recognition. It improves the accuracy of the classification
methods, by correcting for unrealistically short activities in the estimate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping Plato&#x27;s Cave: 3D Shape From Adversarial Rendering. (arXiv:1811.11606v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Henzler_P/0/1/0/all/0/1">Philipp Henzler</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1">Niloy Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1">Tobias Ritschel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.11606">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce PlatonicGAN to discover the 3D structure of an object class from
an unstructured collection of 2D images, i.e., where no relation between photos
is known, except that they are showing instances of the same category. The key
idea is to train a deep neural network to generate 3D shapes which, when
rendered to images, are indistinguishable from ground truth images (for a
discriminator) under various camera poses. Discriminating 2D images instead of
3D shapes allows tapping into unstructured 2D photo collections instead of
relying on curated (e.g., aligned, annotated, etc.) 3D data sets. To establish
constraints between 2D image observation and their 3D interpretation, we
suggest a family of rendering layers that are effectively differentiable. This
family includes visual hull, absorption-only (akin to x-ray), and
emission-absorption. We can successfully reconstruct 3D shapes from
unstructured 2D images and extensively evaluate PlatonicGAN on a range of
synthetic and real data sets achieving consistent improvements over baseline
methods. We further show that PlatonicGAN can be combined with 3D supervision
to improve on and in some cases even surpass the quality of 3D-supervised
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Deep Supervised Anomaly Detection: Reinforcement Learning from Partially Labeled Anomaly Data. (arXiv:2009.06847v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1">Guansong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1">Anton van den Hengel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Longbing Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06847">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of anomaly detection with a small set of partially
labeled anomaly examples and a large-scale unlabeled dataset. This is a common
scenario in many important applications. Existing related methods either
exclusively fit the limited anomaly examples that typically do not span the
entire set of anomalies, or proceed with unsupervised learning from the
unlabeled data. We propose here instead a deep reinforcement learning-based
approach that enables an end-to-end optimization of the detection of both
labeled and unlabeled anomalies. This approach learns the known abnormality by
automatically interacting with an anomaly-biased simulation environment, while
continuously extending the learned abnormality to novel classes of anomaly
(i.e., unknown anomalies) by actively exploring possible anomalies in the
unlabeled data. This is achieved by jointly optimizing the exploitation of the
small labeled anomaly data and the exploration of the rare unlabeled anomalies.
Extensive experiments on 48 real-world datasets show that our model
significantly outperforms five state-of-the-art competing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-Enhanced Cross-Task Network for Analysing Multiple Attributes of Lung Nodules in CT. (arXiv:2103.03931v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1">Xiaohang Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Bi_L/0/1/0/all/0/1">Lei Bi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Ashnil Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Fulham_M/0/1/0/all/0/1">Michael Fulham</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1">Jinman Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03931">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate characterisation of visual attributes such as spiculation,
lobulation, and calcification of lung nodules is critical in cancer management.
The characterisation of these attributes is often subjective, which may lead to
high inter- and intra-observer variability. Furthermore, lung nodules are often
heterogeneous in the cross-sectional image slices of a 3D volume. Current
state-of-the-art methods that score multiple attributes rely on deep
learning-based multi-task learning (MTL) schemes. These methods, however,
extract shared visual features across attributes and then examine each
attribute without explicitly leveraging their inherent intercorrelations.
Furthermore, current methods either treat each slice with equal importance
without considering their relevance or heterogeneity, which limits performance.
In this study, we address these challenges with a new convolutional neural
network (CNN)-based MTL model that incorporates multiple attention-based
learning modules to simultaneously score 9 visual attributes of lung nodules in
computed tomography (CT) image volumes. Our model processes entire nodule
volumes of arbitrary depth and uses a slice attention module to filter out
irrelevant slices. We also introduce cross-attribute and attribute
specialisation attention modules that learn an optimal amalgamation of
meaningful representations to leverage relationships between attributes. We
demonstrate that our model outperforms previous state-of-the-art methods at
scoring attributes using the well-known public LIDC-IDRI dataset of pulmonary
nodules from over 1,000 patients. Our model also performs competitively when
repurposed for benign-malignant classification. Our attention modules also
provide easy-to-interpret weights that offer insights into the predictions of
the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v1 [eess.SP] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1">Udaya S.K.P. Miriya Thanthrige</a>, <a href="http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1">Peter Jung</a>, <a href="http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1">Aydin Sezgin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03686">
                                    <div class="article-summary-box-inner">
                                        <span>We address the detection of material defects, which are inside a layered
material structure using compressive sensing based multiple-output (MIMO)
wireless radar. Here, the strong clutter due to the reflection of the layered
structure&#x27;s surface often makes the detection of the defects challenging. Thus,
sophisticated signal separation methods are required for improved defect
detection. In many scenarios, the number of defects that we are interested in
is limited and the signaling response of the layered structure can be modeled
as a low-rank structure. Therefore, we propose joint rank and sparsity
minimization for defect detection. In particular, we propose a non-convex
approach based on the iteratively reweighted nuclear and $\ell_1-$norm (a
double-reweighted approach) to obtain a higher accuracy compared to the
conventional nuclear norm and $\ell_1-$norm minimization. To this end, an
iterative algorithm is designed to estimate the low-rank and sparse
contributions. Further, we propose deep learning to learn the parameters of the
algorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of
convergence of the algorithm. Our numerical results show that the proposed
approach outperforms the conventional approaches in terms of mean square errors
of the recovered low-rank and sparse components and the speed of convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1">Rhea Sanjay Sukthanker</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiwu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Suryansh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Endsjo_E/0/1/0/all/0/1">Erik Goron Endsjo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14535">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a new neural architecture search (NAS) problem of
Symmetric Positive Definite (SPD) manifold networks, aiming to automate the
design of SPD neural architectures. To address this problem, we first introduce
a geometrically rich and diverse SPD neural architecture search space for an
efficient SPD cell design. Further, we model our new NAS problem with a
one-shot training process of a single supernet. Based on the supernet modeling,
we exploit a differentiable NAS algorithm on our relaxed continuous search
space for SPD neural architecture search. Statistical evaluation of our method
on drone, action, and emotion recognition tasks mostly provides better results
than the state-of-the-art SPD networks and traditional NAS algorithms.
Empirical results show that our algorithm excels in discovering better
performing SPD network design and provides models that are more than three
times lighter than searched by the state-of-the-art NAS algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Curation of Large-Scale Datasets for Audio-Visual Representation Learning. (arXiv:2101.10803v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_J/0/1/0/all/0/1">Jiwan Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gunhee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Breuel_T/0/1/0/all/0/1">Thomas Breuel</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yale Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10803">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale datasets are the cornerstone of representation learning. Existing
self-supervised approaches extract learning signals by making certain
assumptions about the data, e.g., spatio-temporal continuity and multimodal
correspondence. However, finding large amounts of data that satisfy such
assumptions is not straightforward, and this restricts the community to rely on
datasets collected through laborious annotation and/or manual filtering
processes. In this paper, we propose a subset optimization approach for
automatic dataset curation. Focusing on audio-visual representation learning,
we find a subset that provides the maximum mutual information between audio and
visual channels in videos. We show that self-supervised models trained on our
data, despite being automatically constructed, achieve competitive downstream
performances compared to existing datasets that require annotation and/or
manual filtering. The most significant benefit of our approach is scalability.
We release a dataset of 100M videos with high audio-visual correspondence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Youwei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08435">
                                    <div class="article-summary-box-inner">
                                        <span>Since the Lipschitz properties of CNN are widely considered to be related to
adversarial robustness, we theoretically characterize the $\ell_1$ norm and
$\ell_\infty$ norm of 2D multi-channel convolutional layers and provide
efficient methods to compute the exact $\ell_1$ norm and $\ell_\infty$ norm.
Based on our theorem, we propose a novel regularization method termed norm
decay, which can effectively reduce the norms of convolutional layers and
fully-connected layers. Experiments show that norm-regularization methods,
including norm decay, weight decay, and singular value clipping, can improve
generalization of CNNs. However, they can slightly hurt adversarial robustness.
Observing this unexpected phenomenon, we compute the norms of layers in the
CNNs trained with three different adversarial training frameworks and
surprisingly find that adversarially robust CNNs have comparable or even larger
layer norms than their non-adversarially robust counterparts. Furthermore, we
prove that under a mild assumption, adversarially robust classifiers can be
achieved, and can have an arbitrarily large Lipschitz constant. For this
reason, enforcing small norms on CNN layers may be neither necessary nor
effective in achieving adversarial robustness. The code is available at
https://github.com/youweiliang/norm_robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Information Plane Analyses of Neural Network Classifiers -- A Review. (arXiv:2003.09671v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1">Bernhard C. Geiger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.09671">
                                    <div class="article-summary-box-inner">
                                        <span>We review the current literature concerned with information plane analyses of
neural network classifiers. While the underlying information bottleneck theory
and the claim that information-theoretic compression is causally linked to
generalization are plausible, empirical evidence was found to be both
supporting and conflicting. We review this evidence together with a detailed
analysis of how the respective information quantities were estimated. Our
survey suggests that compression visualized in information planes is not
necessarily information-theoretic, but is rather often compatible with
geometric compression of the latent representations. This insight gives the
information plane a renewed justification.

Aside from this, we shed light on the problem of estimating mutual
information in deterministic neural networks and its consequences.
Specifically, we argue that even in feed-forward neural networks the data
processing inequality need not hold for estimates of mutual information.
Similarly, while a fitting phase, in which the mutual information between the
latent representation and the target increases, is necessary (but not
sufficient) for good classification performance, depending on the specifics of
mutual information estimation such a fitting phase need not be visible in the
information plane.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Hyperspectral Mixed Noise Removal Via Spatial-Spectral Constrained Deep Image Prior. (arXiv:2008.09753v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yi-Si Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xi-Le Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tai-Xiang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yu-Bang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yi Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09753">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, convolutional neural network (CNN)-based methods are proposed for
hyperspectral images (HSIs) denoising. Among them, unsupervised methods such as
the deep image prior (DIP) have received much attention because these methods
do not require any training data. However, DIP suffers from the
semi-convergence behavior, i.e., the iteration of DIP needs to terminate by
referring to the ground-truth image at the optimal iteration point. In this
paper, we propose the spatial-spectral constrained deep image prior (S2DIP) for
HSI mixed noise removal. Specifically, we incorporate DIP with a
spatial-spectral total variation (SSTV) term to fully preserve the
spatial-spectral local smoothness of the HSI and an $\ell_1$-norm term to
capture the complex sparse noise. The proposed S2DIP jointly leverages the
expressive power brought from the deep CNN without any training data and
exploits the HSI and noise structures via hand-crafted priors. Thus, our method
avoids the semi-convergence behavior, showing higher stabilities than DIP.
Meanwhile, our method largely enhances the HSI denoising ability of DIP. To
tackle the proposed denoising model, we develop an alternating direction
multiplier method algorithm. Extensive experiments demonstrate that the
proposed S2DIP outperforms optimization-based and supervised CNN-based
state-of-the-art HSI denoising methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation. (arXiv:2103.03240v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1">Kieran A. Murphy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1">Varun Jampani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1">Srikumar Ramalingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1">Ameesh Makadia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03240">
                                    <div class="article-summary-box-inner">
                                        <span>Representational learning forms the backbone of most deep learning
applications, and the value of a learned representation is intimately tied to
its information content regarding different factors of variation. Finding good
representations depends on the nature of supervision and the learning
algorithm. We propose a novel algorithm that relies on a weak form of
supervision where the data is partitioned into sets according to certain
inactive factors of variation. Our key insight is that by seeking approximate
correspondence between elements of different sets, we learn strong
representations that exclude the inactive factors of variation and isolate the
active factors which vary within all sets. We demonstrate that the method can
work in a semi-supervised scenario, and that a portion of the unsupervised data
can belong to a different domain entirely. Further control over the content of
the learned representations is possible by folding in data augmentation to
suppress nuisance factors. We outperform competing baselines on the challenging
problem of synthetic-to-real object pose transfer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Attention on Pyramid Feature Maps for Image Captioning. (arXiv:2011.01385v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Litao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01385">
                                    <div class="article-summary-box-inner">
                                        <span>Generating natural sentences from images is a fundamental learning task for
visual-semantic understanding in multimedia. In this paper, we propose to apply
dual attention on pyramid image feature maps to fully explore the
visual-semantic correlations and improve the quality of generated sentences.
Specifically, with the full consideration of the contextual information
provided by the hidden state of the RNN controller, the pyramid attention can
better localize the visually indicative and semantically consistent regions in
images. On the other hand, the contextual information can help re-calibrate the
importance of feature components by learning the channel-wise dependencies, to
improve the discriminative power of visual features for better content
description. We conducted comprehensive experiments on three well-known
datasets: Flickr8K, Flickr30K and MS COCO, which achieved impressive results in
generating descriptive and smooth natural sentences from images. Using either
convolution visual features or more informative bottom-up attention features,
our composite captioning model achieves very promising performance in a
single-model mode. The proposed pyramid attention and dual attention methods
are highly modular, which can be inserted into various image captioning modules
to further improve the performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Curiously Effective Features for Image Quality Prediction. (arXiv:2106.05946v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1">S&#xf6;ren Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiegand_T/0/1/0/all/0/1">Thomas Wiegand</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosse_S/0/1/0/all/0/1">Sebastian Bosse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05946">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of visual quality prediction models is commonly assumed to be
closely tied to their ability to capture perceptually relevant image aspects.
Models are thus either based on sophisticated feature extractors carefully
designed from extensive domain knowledge or optimized through feature learning.
In contrast to this, we find feature extractors constructed from random noise
to be sufficient to learn a linear regression model whose quality predictions
reach high correlations with human visual quality ratings, on par with a model
with learned features. We analyze this curious result and show that besides the
quality of feature extractors also their quantity plays a crucial role - with
top performances only being achieved in highly overparameterized models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamal_U/0/1/0/all/0/1">Uday Kamal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zunaed_M/0/1/0/all/0/1">Mohammad Zunaed</a>, <a href="http://arxiv.org/find/cs/1/au:+Nizam_N/0/1/0/all/0/1">Nusrat Binta Nizam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1">Taufiq Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05915">
                                    <div class="article-summary-box-inner">
                                        <span>Thoracic disease detection from chest radiographs using deep learning methods
has been an active area of research in the last decade. Most previous methods
attempt to focus on the diseased organs of the image by identifying spatial
regions responsible for significant contributions to the model&#x27;s prediction. In
contrast, expert radiologists first locate the prominent anatomical structures
before determining if those regions are anomalous. Therefore, integrating
anatomical knowledge within deep learning models could bring substantial
improvement in automatic disease classification. This work proposes an
anatomy-aware attention-based architecture named Anatomy X-Net, that
prioritizes the spatial features guided by the pre-identified anatomy regions.
We leverage a semi-supervised learning method using the JSRT dataset containing
organ-level annotation to obtain the anatomical segmentation masks (for lungs
and heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses
the pre-trained DenseNet-121 as the backbone network with two corresponding
structured modules, the Anatomy Aware Attention (AAA) and Probabilistic
Weighted Average Pooling (PWAP), in a cohesive framework for anatomical
attention learning. Our proposed method sets new state-of-the-art performance
on the official NIH test set with an AUC score of 0.8439, proving the efficacy
of utilizing the anatomy segmentation knowledge to improve the thoracic disease
classification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020
on the Stanford CheXpert dataset, improving on existing methods that
demonstrate the generalizability of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">1-Point RANSAC-Based Method for Ground Object Pose Estimation. (arXiv:2008.03718v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jeong-Kyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Baik_Y/0/1/0/all/0/1">Young-Ki Baik</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Hankyu Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kang Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Duck Hoon Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03718">
                                    <div class="article-summary-box-inner">
                                        <span>Solving Perspective-n-Point (PnP) problems is a traditional way of estimating
object poses. Given outlier-contaminated data, a pose of an object is
calculated with PnP algorithms of n &#x3D; {3, 4} in the RANSAC-based scheme.
However, the computational complexity considerably increases along with n and
the high complexity imposes a severe strain on devices which should estimate
multiple object poses in real time. In this paper, we propose an efficient
method based on 1-point RANSAC for estimating a pose of an object on the
ground. In the proposed method, a pose is calculated with 1-DoF
parameterization by using a ground object assumption and a 2D object bounding
box as an additional observation, thereby achieving the fastest performance
among the RANSAC-based methods. In addition, since the method suffers from the
errors of the additional information, we propose a hierarchical robust
estimation method for polishing a rough pose estimate and discovering more
inliers in a coarse-to-fine manner. The experiments in synthetic and real-world
datasets demonstrate the superiority of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition. (arXiv:2104.03841v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Massiceti_D/0/1/0/all/0/1">Daniela Massiceti</a>, <a href="http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1">Luisa Zintgraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronskill_J/0/1/0/all/0/1">John Bronskill</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_L/0/1/0/all/0/1">Lida Theodorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Harris_M/0/1/0/all/0/1">Matthew Tobias Harris</a>, <a href="http://arxiv.org/find/cs/1/au:+Cutrell_E/0/1/0/all/0/1">Edward Cutrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Morrison_C/0/1/0/all/0/1">Cecily Morrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Stumpf_S/0/1/0/all/0/1">Simone Stumpf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03841">
                                    <div class="article-summary-box-inner">
                                        <span>Object recognition has made great advances in the last decade, but
predominately still relies on many high-quality training examples per object
category. In contrast, learning new objects from only a few examples could
enable many impactful applications from robotics to user personalization. Most
few-shot learning research, however, has been driven by benchmark datasets that
lack the high variation that these applications will face when deployed in the
real-world. To close this gap, we present the ORBIT dataset and benchmark,
grounded in a real-world application of teachable object recognizers for people
who are blind/low-vision. The dataset contains 3,822 videos of 486 objects
recorded by people who are blind/low-vision on their mobile phones, and the
benchmark reflects a realistic, highly challenging recognition problem,
providing a rich playground to drive research in robustness to few-shot,
high-variation conditions. We set the first state-of-the-art on the benchmark
and show that there is massive scope for further innovation, holding the
potential to impact a broad range of real-world vision applications including
tools for the blind/low-vision community. The dataset is available at
https://bit.ly/2OyElCj and the code to run the benchmark at
https://bit.ly/39YgiUW.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Robustness of Human Pose Estimation. (arXiv:1908.06401v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1">Sahil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1">Naman Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Abhishek Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Arjun Jain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.06401">
                                    <div class="article-summary-box-inner">
                                        <span>This paper provides a comprehensive and exhaustive study of adversarial
attacks on human pose estimation models and the evaluation of their robustness.
Besides highlighting the important differences between well-studied
classification and human pose-estimation systems w.r.t. adversarial attacks, we
also provide deep insights into the design choices of pose-estimation systems
to shape future work. We benchmark the robustness of several 2D single person
pose-estimation architectures trained on multiple datasets, MPII and COCO. In
doing so, we also explore the problem of attacking non-classification networks
including regression based networks, which has been virtually unexplored in the
past.

\par We find that compared to classification and semantic segmentation, human
pose estimation architectures are relatively robust to adversarial attacks with
the single-step attacks being surprisingly ineffective. Our study shows that
the heatmap-based pose-estimation models are notably robust than their direct
regression-based systems and that the systems which explicitly model
anthropomorphic semantics of human body fare better than their other
counterparts. Besides, targeted attacks are more difficult to obtain than
un-targeted ones and some body-joints are easier to fool than the others. We
present visualizations of universal perturbations to facilitate unprecedented
insights into their workings on pose-estimation. Additionally, we show them to
generalize well across different networks. Finally we perform a user study
about perceptibility of these examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning by Watching. (arXiv:2106.05966v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jimuyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1">Eshed Ohn-Bar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05966">
                                    <div class="article-summary-box-inner">
                                        <span>When in a new situation or geographical location, human drivers have an
extraordinary ability to watch others and learn maneuvers that they themselves
may have never performed. In contrast, existing techniques for learning to
drive preclude such a possibility as they assume direct access to an
instrumented ego-vehicle with fully known observations and expert driver
actions. However, such measurements cannot be directly accessed for the non-ego
vehicles when learning by watching others. Therefore, in an application where
data is regarded as a highly valuable asset, current approaches completely
discard the vast portion of the training data that can be potentially obtained
through indirect observation of surrounding vehicles. Motivated by this key
insight, we propose the Learning by Watching (LbW) framework which enables
learning a driving policy without requiring full knowledge of neither the state
nor expert actions. To increase its data, i.e., with new perspectives and
maneuvers, LbW makes use of the demonstrations of other vehicles in a given
scene by (1) transforming the ego-vehicle&#x27;s observations to their points of
view, and (2) inferring their expert actions. Our LbW agent learns more robust
driving policies while enabling data-efficient learning, including quick
adaptation of the policy to rare and novel scenarios. In particular, LbW drives
robustly even with a fraction of available driving data required by existing
methods, achieving an average success rate of 92% on the original CARLA
benchmark with only 30 minutes of total driving data and 82% with only 10
minutes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Feature Alignment: Learn to Convert Text Recognizer to Text Spotter. (arXiv:2106.05920v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuanzhi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Dezhi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Mengchao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongpan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Canjie Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05920">
                                    <div class="article-summary-box-inner">
                                        <span>Text recognition is a popular research subject with many associated
challenges. Despite the considerable progress made in recent years, the text
recognition task itself is still constrained to solve the problem of reading
cropped line text images and serves as a subtask of optical character
recognition (OCR) systems. As a result, the final text recognition result is
limited by the performance of the text detector. In this paper, we propose a
simple, elegant and effective paradigm called Implicit Feature Alignment (IFA),
which can be easily integrated into current text recognizers, resulting in a
novel inference mechanism called IFAinference. This enables an ordinary text
recognizer to process multi-line text such that text detection can be
completely freed. Specifically, we integrate IFA into the two most prevailing
text recognition streams (attention-based and CTC-based) and propose
attention-guided dense prediction (ADP) and Extended CTC (ExCTC). Furthermore,
the Wasserstein-based Hollow Aggregation Cross-Entropy (WH-ACE) is proposed to
suppress negative predictions to assist in training ADP and ExCTC. We
experimentally demonstrate that IFA achieves state-of-the-art performance on
end-to-end document recognition tasks while maintaining the fastest speed, and
ADP and ExCTC complement each other on the perspective of different application
scenarios. Code will be available at
https://github.com/WangTianwei/Implicit-feature-alignment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Space-time Mixing Attention for Video Transformer. (arXiv:2106.05968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1">Adrian Bulat</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Rua_J/0/1/0/all/0/1">Juan-Manuel Perez-Rua</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1">Swathikiran Sudhakaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1">Brais Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1">Georgios Tzimiropoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05968">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is on video recognition using Transformers. Very recent attempts
in this area have demonstrated promising results in terms of recognition
accuracy, yet they have been also shown to induce, in many cases, significant
computational overheads due to the additional modelling of the temporal
information. In this work, we propose a Video Transformer model the complexity
of which scales linearly with the number of frames in the video sequence and
hence induces \textit{no overhead} compared to an image-based Transformer
model. To achieve this, our model makes two approximations to the full
space-time attention used in Video Transformers: (a) It restricts time
attention to a local temporal window and capitalizes on the Transformer&#x27;s depth
to obtain full temporal coverage of the video sequence. (b) It uses efficient
space-time mixing to attend \textit{jointly} spatial and temporal locations
without inducing any additional cost on top of a spatial-only attention model.
We also show how to integrate 2 very lightweight mechanisms for global
temporal-only attention which provide additional accuracy improvements at
minimal computational cost. We demonstrate that our model produces very high
recognition accuracy on the most popular video recognition datasets while at
the same time being significantly more efficient than other Video Transformer
models. Code will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAT: Cross Attention in Vision Transformer. (arXiv:2106.05786v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hezheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xing Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiangyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1">Dong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qing Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Wei Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05786">
                                    <div class="article-summary-box-inner">
                                        <span>Since Transformer has found widespread use in NLP, the potential of
Transformer in CV has been realized and has inspired many new approaches.
However, the computation required for replacing word tokens with image patches
for Transformer after the tokenization of the image is vast(e.g., ViT), which
bottlenecks model training and inference. In this paper, we propose a new
attention mechanism in Transformer termed Cross Attention, which alternates
attention inner the image patch instead of the whole image to capture local
information and apply attention between image patches which are divided from
single-channel feature maps capture global information. Both operations have
less computation than standard self-attention in Transformer. By alternately
applying attention inner patch and between patches, we implement cross
attention to maintain the performance with lower computational cost and build a
hierarchical network called Cross Attention Transformer(CAT) for other vision
tasks. Our base model achieves state-of-the-arts on ImageNet-1K, and improves
the performance of other methods on COCO and ADE20K, illustrating that our
network has the potential to serve as general backbones. The code and models
are available at \url{https://github.com/linhezheng19/CAT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?. (arXiv:2106.05961v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1">Weijian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05961">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding classifier decision under novel environments is central to the
community, and a common practice is evaluating it on labeled test sets.
However, in real-world testing, image annotations are difficult and expensive
to obtain, especially when the test environment is changing. A natural question
then arises: given a trained classifier, can we evaluate its accuracy on
varying unlabeled test sets? In this work, we train semantic classification and
rotation prediction in a multi-task way. On a series of datasets, we report an
interesting finding, i.e., the semantic classification accuracy exhibits a
strong linear relationship with the accuracy of the rotation prediction task
(Pearson&#x27;s Correlation r &gt; 0.88). This finding allows us to utilize linear
regression to estimate classifier performance from the accuracy of rotation
prediction which can be obtained on the test set through the freely generated
rotation labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1">Ekdeep Singh Lubana</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1">Robert P. Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1">Hidenori Tanaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05956">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by BatchNorm, there has been an explosion of normalization layers in
deep learning. Recent works have identified a multitude of beneficial
properties in BatchNorm to explain its success. However, given the pursuit of
alternative normalization techniques, these properties need to be generalized
so that any given layer&#x27;s success/failure can be accurately predicted. In this
work, we take a first step towards this goal by extending known properties of
BatchNorm in randomly initialized deep neural networks (DNNs) to nine recently
proposed normalization layers. Our primary findings follow: (i) Similar to
BatchNorm, activations-based normalization layers can avoid exploding
activations in ResNets; (ii) Use of GroupNorm ensures rank of activations is at
least $\Omega(\sqrt{\frac{\text{width}}{\text{Group Size}}})$, thus explaining
why LayerNorm witnesses slow optimization speed; (iii) Small group sizes result
in large gradient norm in earlier layers, hence justifying training instability
issues in Instance Normalization and illustrating a speed-stability tradeoff in
GroupNorm. Overall, our analysis reveals several general mechanisms that
explain the success of normalization techniques in deep learning, providing us
with a compass to systematically explore the vast design space of DNN
normalization layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enforcing Morphological Information in Fully Convolutional Networks to Improve Cell Instance Segmentation in Fluorescence Microscopy Images. (arXiv:2106.05843v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zamora_Cardenas_W/0/1/0/all/0/1">Willard Zamora-Cardenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendez_M/0/1/0/all/0/1">Mauro Mendez</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderon_Ramirez_S/0/1/0/all/0/1">Saul Calderon-Ramirez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_M/0/1/0/all/0/1">Martin Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Monge_G/0/1/0/all/0/1">Gerardo Monge</a>, <a href="http://arxiv.org/find/cs/1/au:+Quiros_S/0/1/0/all/0/1">Steve Quiros</a>, <a href="http://arxiv.org/find/cs/1/au:+Elizondo_D/0/1/0/all/0/1">David Elizondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Elizondo_D/0/1/0/all/0/1">David Elizondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_Cabello_M/0/1/0/all/0/1">Miguel A. Molina-Cabello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05843">
                                    <div class="article-summary-box-inner">
                                        <span>Cell instance segmentation in fluorescence microscopy images is becoming
essential for cancer dynamics and prognosis. Data extracted from cancer
dynamics allows to understand and accurately model different metabolic
processes such as proliferation. This enables customized and more precise
cancer treatments. However, accurate cell instance segmentation, necessary for
further cell tracking and behavior analysis, is still challenging in scenarios
with high cell concentration and overlapping edges. Within this framework, we
propose a novel cell instance segmentation approach based on the well-known
U-Net architecture. To enforce the learning of morphological information per
pixel, a deep distance transformer (DDT) acts as a back-bone model. The DDT
output is subsequently used to train a top-model. The following top-models are
considered: a three-class (\emph{e.g.,} foreground, background and cell border)
U-net, and a watershed transform. The obtained results suggest a performance
boost over traditional U-Net architectures. This opens an interesting research
line around the idea of injecting morphological information into a fully
convolutional model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations. (arXiv:2106.05967v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1">Wouter Van Gansbeke</a>, <a href="http://arxiv.org/find/cs/1/au:+Vandenhende_S/0/1/0/all/0/1">Simon Vandenhende</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1">Stamatios Georgoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05967">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive self-supervised learning has outperformed supervised pretraining
on many downstream tasks like segmentation and object detection. However,
current methods are still primarily applied to curated datasets like ImageNet.
In this paper, we first study how biases in the dataset affect existing
methods. Our results show that current contrastive approaches work surprisingly
well across: (i) object- versus scene-centric, (ii) uniform versus long-tailed
and (iii) general versus domain-specific datasets. Second, given the generality
of the approach, we try to realize further gains with minor modifications. We
show that learning additional invariances -- through the use of multi-scale
cropping, stronger augmentations and nearest neighbors -- improves the
representations. Finally, we observe that MoCo learns spatially structured
representations when trained with a multi-crop strategy. The representations
can be used for semantic segment retrieval and video instance segmentation
without finetuning. Moreover, the results are on par with specialized models.
We hope this work will serve as a useful study for other researchers. The code
and models will be available at
https://github.com/wvangansbeke/Revisiting-Contrastive-SSL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1">Austin Botelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertie Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate detection and classification of online hate is a difficult task.
Implicit hate is particularly challenging as such content tends to have unusual
syntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This
problem is heightened with multimodal content, such as memes (combinations of
text and images), as they are often harder to decipher than unimodal content
(e.g., text alone). This paper evaluates the role of semantic and multimodal
context for detecting implicit and explicit hate. We show that both text- and
visual- enrichment improves model performance, with the multimodal model
(0.771) outperforming other models&#x27; F1 scores (0.544, 0.737, and 0.754). While
the unimodal-text context-aware (transformer) model was the most accurate on
the subtask of implicit hate detection, the multimodal model outperformed it
overall because of a lower propensity towards false positives. We find that all
models perform better on content with full annotator agreement and that
multimodal models are best at classifying the content where annotators
disagree. To conduct these investigations, we undertook high-quality annotation
of a sample of 5,000 multimodal entries. Tweets were annotated for primary
category, modality, and strategy. We make this corpus, along with the codebook,
code, and final model, freely available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pivotal Tuning for Latent-based Editing of Real Images. (arXiv:2106.05744v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roich_D/0/1/0/all/0/1">Daniel Roich</a>, <a href="http://arxiv.org/find/cs/1/au:+Mokady_R/0/1/0/all/0/1">Ron Mokady</a>, <a href="http://arxiv.org/find/cs/1/au:+Bermano_A/0/1/0/all/0/1">Amit H. Bermano</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05744">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, a surge of advanced facial editing techniques have been proposed
that leverage the generative power of a pre-trained StyleGAN. To successfully
edit an image this way, one must first project (or invert) the image into the
pre-trained generator&#x27;s domain. As it turns out, however, StyleGAN&#x27;s latent
space induces an inherent tradeoff between distortion and editability, i.e.
between maintaining the original appearance and convincingly altering some of
its attributes. Practically, this means it is still challenging to apply
ID-preserving facial latent-space editing to faces which are out of the
generator&#x27;s domain. In this paper, we present an approach to bridge this gap.
Our technique slightly alters the generator, so that an out-of-domain image is
faithfully mapped into an in-domain latent code. The key idea is pivotal tuning
- a brief training process that preserves the editing quality of an in-domain
latent region, while changing its portrayed identity and appearance. In Pivotal
Tuning Inversion (PTI), an initial inverted latent code serves as a pivot,
around which the generator is fined-tuned. At the same time, a regularization
term keeps nearby identities intact, to locally contain the effect. This
surgical training process ends up altering appearance features that represent
mostly identity, without affecting editing capabilities. We validate our
technique through inversion and editing metrics, and show preferable scores to
state-of-the-art methods. We further qualitatively demonstrate our technique by
applying advanced edits (such as pose, age, or expression) to numerous images
of well-known and recognizable identities. Finally, we demonstrate resilience
to harder cases, including heavy make-up, elaborate hairstyles and/or headwear,
which otherwise could not have been successfully inverted and edited by
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The 2021 Hotel-ID to Combat Human Trafficking Competition Dataset. (arXiv:2106.05746v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamath_R/0/1/0/all/0/1">Rashmi Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1">Greg Rolwes</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_S/0/1/0/all/0/1">Samuel Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1">Abby Stylianou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05746">
                                    <div class="article-summary-box-inner">
                                        <span>Hotel recognition is an important task for human trafficking investigations
since victims are often photographed in hotel rooms. Identifying these hotels
is vital to trafficking investigations since they can help track down current
and future victims who might be taken to the same places. Hotel recognition is
a challenging fine grained visual classification task as there can be little
similarity between different rooms within the same hotel, and high similarity
between rooms from different hotels (especially if they are from the same
chain). Hotel recognition to combat human trafficking poses additional
challenges as investigative images are often low quality, contain uncommon
camera angles and are highly occluded. Here, we present the 2021 Hotel-ID
dataset to help raise awareness for this problem and generate novel approaches.
The dataset consists of hotel room images that have been crowd-sourced and
uploaded through the TraffickCam mobile application. The quality of these
images is similar to investigative images and hence models trained on these
images have good chances of accurately narrowing down on the correct hotel.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Medical Segmentation Decathlon. (arXiv:2106.05735v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1">Michela Antonelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1">Annika Reinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1">Spyridon Bakas</a>, <a href="http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1">Keyvan Farahani</a>, <a href="http://arxiv.org/find/cs/1/au:+AnnetteKopp-Schneider/0/1/0/all/0/1">AnnetteKopp-Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>, <a href="http://arxiv.org/find/cs/1/au:+Litjens_G/0/1/0/all/0/1">Geert Litjens</a>, <a href="http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1">Bjoern Menze</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1">Olaf Ronneberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1">Ronald M.Summers</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1">Bram van Ginneken</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1">Michel Bilello</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilic_P/0/1/0/all/0/1">Patrick Bilic</a>, <a href="http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1">Patrick F. Christ</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_R/0/1/0/all/0/1">Richard K. G. Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Gollub_M/0/1/0/all/0/1">Marc J. Gollub</a>, <a href="http://arxiv.org/find/cs/1/au:+Heckers_S/0/1/0/all/0/1">Stephan H. Heckers</a>, <a href="http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1">William R. Jarnagin</a>, <a href="http://arxiv.org/find/cs/1/au:+McHugo_M/0/1/0/all/0/1">Maureen K. McHugo</a>, <a href="http://arxiv.org/find/cs/1/au:+Napel_S/0/1/0/all/0/1">Sandy Napel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pernicka_J/0/1/0/all/0/1">Jennifer S. Goli Pernicka</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhode_K/0/1/0/all/0/1">Kawal Rhode</a>, <a href="http://arxiv.org/find/cs/1/au:+Tobon_Gomez_C/0/1/0/all/0/1">Catalina Tobon-Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Meakin_J/0/1/0/all/0/1">James A. Meakin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1">Manuel Wiesenfarth</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1">Byeonguk Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sihong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1">Laura Daza</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianjiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Baochun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yuanfeng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1">Fucang Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Namkug Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1">Ildoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1">Dorit Merhof</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1">Akshay Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1">Beomhee Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Perslev_M/0/1/0/all/0/1">Mathias Perslev</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaiifar_R/0/1/0/all/0/1">Ramin Rezaiifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1">Oliver Rippel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarasua_I/0/1/0/all/0/1">Ignacio Sarasua</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1">Jaemin Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>, et al. (9 additional authors not shown)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05735">
                                    <div class="article-summary-box-inner">
                                        <span>International challenges have become the de facto standard for comparative
assessment of image analysis algorithms given a specific task. Segmentation is
so far the most widely investigated medical image processing task, but the
various segmentation challenges have typically been organized in isolation,
such that algorithm development was driven by the need to tackle a single
specific clinical problem. We hypothesized that a method capable of performing
well on multiple tasks will generalize well to a previously unseen task and
potentially outperform a custom-designed solution. To investigate the
hypothesis, we organized the Medical Segmentation Decathlon (MSD) - a
biomedical image analysis challenge, in which algorithms compete in a multitude
of both tasks and modalities. The underlying data set was designed to explore
the axis of difficulties typically encountered when dealing with medical
images, such as small data sets, unbalanced labels, multi-site data and small
objects. The MSD challenge confirmed that algorithms with a consistent good
performance on a set of tasks preserved their good average performance on a
different set of previously unseen tasks. Moreover, by monitoring the MSD
winner for two years, we found that this algorithm continued generalizing well
to a wide range of other clinical problems, further confirming our hypothesis.
Three main conclusions can be drawn from this study: (1) state-of-the-art image
segmentation algorithms are mature, accurate, and generalize well when
retrained on unseen tasks; (2) consistent algorithmic performance across
multiple tasks is a strong surrogate of algorithmic generalizability; (3) the
training of accurate AI segmentation models is now commoditized to non AI
experts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Implicit Surface Point Prediction Networks. (arXiv:2106.05779v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_R/0/1/0/all/0/1">Rahul Venkatesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Karmali_T/0/1/0/all/0/1">Tejan Karmali</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Sarthak Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Aurobrata Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeni_L/0/1/0/all/0/1">L&#xe1;szl&#xf3; A. Jeni</a>, <a href="http://arxiv.org/find/cs/1/au:+Babu_R/0/1/0/all/0/1">R. Venkatesh Babu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Maneesh Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05779">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural representations of 3D shapes as implicit functions have been
shown to produce high fidelity models surpassing the resolution-memory
trade-off faced by the explicit representations using meshes and point clouds.
However, most such approaches focus on representing closed shapes. Unsigned
distance function (UDF) based approaches have been proposed recently as a
promising alternative to represent both open and closed shapes. However, since
the gradients of UDFs vanish on the surface, it is challenging to estimate
local (differential) geometric properties like the normals and tangent planes
which are needed for many downstream applications in vision and graphics. There
are additional challenges in computing these properties efficiently with a
low-memory footprint. This paper presents a novel approach that models such
surfaces using a new class of implicit representations called the closest
surface-point (CSP) representation. We show that CSP allows us to represent
complex surfaces of any topology (open or closed) with high fidelity. It also
allows for accurate and efficient computation of local geometric properties. We
further demonstrate that it leads to efficient implementation of downstream
algorithms like sphere-tracing for rendering the 3D surface as well as to
create explicit mesh-based representations. Extensive experimental evaluation
on the ShapeNet dataset validate the above contributions with results
surpassing the state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Co-part Segmentation through Assembly. (arXiv:2106.05897v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qingzhe Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Libin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Baoquan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05897">
                                    <div class="article-summary-box-inner">
                                        <span>Co-part segmentation is an important problem in computer vision for its rich
applications. We propose an unsupervised learning approach for co-part
segmentation from images. For the training stage, we leverage motion
information embedded in videos and explicitly extract latent representations to
segment meaningful object parts. More importantly, we introduce a dual
procedure of part-assembly to form a closed loop with part-segmentation,
enabling an effective self-supervision. We demonstrate the effectiveness of our
approach with a host of extensive experiments, ranging from human bodies,
hands, quadruped, and robot arms. We show that our approach can achieve
meaningful and compact part segmentation, outperforming state-of-the-art
approaches on diverse benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Streaming Perception using Deep Reinforcement Learning. (arXiv:2106.05665v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anurag Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1">Akshay Nambi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Aditya Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+YVS_H/0/1/0/all/0/1">Harish YVS</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1">Tanuja Ganu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05665">
                                    <div class="article-summary-box-inner">
                                        <span>Executing computer vision models on streaming visual data, or streaming
perception is an emerging problem, with applications in self-driving, embodied
agents, and augmented/virtual reality. The development of such systems is
largely governed by the accuracy and latency of the processing pipeline. While
past work has proposed numerous approximate execution frameworks, their
decision functions solely focus on optimizing latency, accuracy, or energy,
etc. This results in sub-optimum decisions, affecting the overall system
performance. We argue that the streaming perception systems should holistically
maximize the overall system performance (i.e., considering both accuracy and
latency simultaneously). To this end, we describe a new approach based on deep
reinforcement learning to learn these tradeoffs at runtime for streaming
perception. This tradeoff optimization is formulated as a novel deep contextual
bandit problem and we design a new reward function that holistically integrates
latency and accuracy into a single metric. We show that our agent can learn a
competitive policy across multiple decision dimensions, which outperforms
state-of-the-art policies on public datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end lung nodule detection framework with model-based feature projection block. (arXiv:2106.05741v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drokin_I/0/1/0/all/0/1">Ivan Drokin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ericheva_E/0/1/0/all/0/1">Elena Ericheva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05741">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes novel end-to-end framework for detecting suspicious
pulmonary nodules in chest CT scans. The method core idea is a new nodule
segmentation architecture with a model-based feature projection block on
three-dimensional convolutions. This block acts as a preliminary feature
extractor for a two-dimensional U-Net-like convolutional network. Using the
proposed approach along with an axial, coronal, and sagittal projection
analysis makes it possible to abandon the widely used false positives reduction
step. The proposed method achieves SOTA on LUNA2016 with 0.959 average
sensitivity, and 0.936 sensitivity if the false-positive level per scan is
0.25. The paper describes the proposed approach and represents the experimental
results on LUNA2016 as well as ablation studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep neural network loses attention to adversarial images. (arXiv:2106.05657v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1">Shashank Kotyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1">Danilo Vasconcellos Vargas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05657">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial algorithms have shown to be effective against neural networks for
a variety of tasks. Some adversarial algorithms perturb all the pixels in the
image minimally for the image classification task in image classification. In
contrast, some algorithms perturb few pixels strongly. However, very little
information is available regarding why these adversarial samples so diverse
from each other exist. Recently, Vargas et al. showed that the existence of
these adversarial samples might be due to conflicting saliency within the
neural network. We test this hypothesis of conflicting saliency by analysing
the Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)
of original and few different types of adversarial samples. We also analyse how
different adversarial samples distort the attention of the neural network
compared to original samples. We show that in the case of Pixel Attack,
perturbed pixels either calls the network attention to themselves or divert the
attention from them. Simultaneously, the Projected Gradient Descent Attack
perturbs pixels so that intermediate layers inside the neural network lose
attention for the correct class. We also show that both attacks affect the
saliency map and activation maps differently. Thus, shedding light on why some
defences successful against some attacks remain vulnerable against other
attacks. We hope that this analysis will improve understanding of the existence
and the effect of adversarial samples and enable the community to develop more
robust neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MiDeCon: Unsupervised and Accurate Fingerprint and Minutia Quality Assessment based on Minutia Detection Confidence. (arXiv:2106.05601v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Terhorst_P/0/1/0/all/0/1">Philipp Terh&#xf6;rst</a>, <a href="http://arxiv.org/find/cs/1/au:+Boller_A/0/1/0/all/0/1">Andr&#xe9; Boller</a>, <a href="http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1">Naser Damer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1">Florian Kirchbuchner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1">Arjan Kuijper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05601">
                                    <div class="article-summary-box-inner">
                                        <span>An essential factor to achieve high accuracies in fingerprint recognition
systems is the quality of its samples. Previous works mainly proposed
supervised solutions based on image properties that neglects the minutiae
extraction process, despite that most fingerprint recognition techniques are
based on detected minutiae. Consequently, a fingerprint image might be assigned
a high quality even if the utilized minutia extractor produces unreliable
information. In this work, we propose a novel concept of assessing minutia and
fingerprint quality based on minutia detection confidence (MiDeCon). MiDeCon
can be applied to an arbitrary deep learning based minutia extractor and does
not require quality labels for learning. We propose using the detection
reliability of the extracted minutia as its quality indicator. By combining the
highest minutia qualities, MiDeCon also accurately determines the quality of a
full fingerprint. Experiments are conducted on the publicly available databases
of the FVC 2006 and compared against several baselines, such as NIST&#x27;s
widely-used fingerprint image quality software NFIQ1 and NFIQ2. The results
demonstrate a significantly stronger quality assessment performance of the
proposed MiDeCon-qualities as related works on both, minutia- and
fingerprint-level. The implementation is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset And Benchmark Of Underwater Object Detection For Robot Picking. (arXiv:2106.05681v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chongwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haojie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuchang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Ming Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xin Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05681">
                                    <div class="article-summary-box-inner">
                                        <span>Underwater object detection for robot picking has attracted a lot of
interest. However, it is still an unsolved problem due to several challenges.
We take steps towards making it more realistic by addressing the following
challenges. Firstly, the currently available datasets basically lack the test
set annotations, causing researchers must compare their method with other SOTAs
on a self-divided test set (from the training set). Training other methods lead
to an increase in workload and different researchers divide different datasets,
resulting there is no unified benchmark to compare the performance of different
algorithms. Secondly, these datasets also have other shortcomings, e.g., too
many similar images or incomplete labels. Towards these challenges we introduce
a dataset, Detecting Underwater Objects (DUO), and a corresponding benchmark,
based on the collection and re-annotation of all relevant datasets. DUO
contains a collection of diverse underwater images with more rational
annotations. The corresponding benchmark provides indicators of both efficiency
and accuracy of SOTAs (under the MMDtection framework) for academic research
and industrial applications, where JETSON AGX XAVIER is used to assess detector
speed to simulate the robot-embedded environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time. (arXiv:2106.05610v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenstat_D/0/1/0/all/0/1">David Eisenstat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1">Jakub &#x141;&#x105;cki</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jessica Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05610">
                                    <div class="article-summary-box-inner">
                                        <span>We study the widely used hierarchical agglomerative clustering (HAC)
algorithm on edge-weighted graphs. We define an algorithmic framework for
hierarchical agglomerative graph clustering that provides the first efficient
$\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as
complete- and WPGMA-linkage, as well as other measures. Furthermore, for
average-linkage, arguably the most popular variant of HAC, we provide an
algorithm that runs in $\tilde{O}(n\sqrt{m})$ time. For this variant, this is
the first exact algorithm that runs in subquadratic time, as long as
$m&#x3D;n^{2-\epsilon}$ for some constant $\epsilon &gt; 0$. We complement this result
with a simple $\epsilon$-close approximation algorithm for average-linkage in
our framework that runs in $\tilde{O}(m)$ time. As an application of our
algorithms, we consider clustering points in a metric space by first using
$k$-NN to generate a graph from the point set, and then running our algorithms
on the resulting weighted graph. We validate the performance of our algorithms
on publicly available datasets, and show that our approach can speed up
clustering of point datasets by a factor of 20.7--76.5x.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MST: Masked Self-Supervised Transformer for Visual Representation. (arXiv:2106.05656v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhaowen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yousong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chaoyang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_R/0/1/0/all/0/1">Rui Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Rui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1">Ming Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jinqiao Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05656">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer has been widely used for self-supervised pre-training in Natural
Language Processing (NLP) and achieved great success. However, it has not been
fully explored in visual self-supervised learning. Meanwhile, previous methods
only consider the high-level feature and learning representation from a global
perspective, which may fail to transfer to the downstream dense prediction
tasks focusing on local features. In this paper, we present a novel Masked
Self-supervised Transformer approach named MST, which can explicitly capture
the local context of an image while preserving the global semantic information.
Specifically, inspired by the Masked Language Modeling (MLM) in NLP, we propose
a masked token strategy based on the multi-head self-attention map, which
dynamically masks some tokens of local patches without damaging the crucial
structure for self-supervised learning. More importantly, the masked tokens
together with the remaining tokens are further recovered by a global image
decoder, which preserves the spatial information of the image and is more
friendly to the downstream dense prediction tasks. The experiments on multiple
datasets demonstrate the effectiveness and generality of the proposed method.
For instance, MST achieves Top-1 accuracy of 76.9% with DeiT-S only using
300-epoch pre-training by linear evaluation, which outperforms supervised
methods with the same epoch by 0.4% and its comparable variant DINO by 1.0\%.
For dense prediction tasks, MST also achieves 42.7% mAP on MS COCO object
detection and 74.04% mIoU on Cityscapes segmentation only with 100-epoch
pre-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Face mask detection using convolution neural network. (arXiv:2106.05728v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1">Riya Shah Rutva Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05728">
                                    <div class="article-summary-box-inner">
                                        <span>In the recent times, the Coronaviruses that are a big family of different
viruses have become very common, contagious and dangerous to the whole human
kind. It spreads human to human by exhaling the infection breath, which leaves
droplets of the virus on different surface which is then inhaled by other
person and catches the infection too. So it has become very important to
protect ourselves and the people around us from this situation. We can take
precautions such as social distancing, washing hands every two hours, using
sanitizer, maintaining social distance and the most important wearing a mask.
Public use of wearing a masks has become very common everywhere in the whole
world now. From that the most affected and devastating condition is of India
due to its extreme population in small area. This paper proposes a method to
detect the face mask is put on or not for offices, or any other work place with
a lot of people coming to work. We have used convolutional neural network for
the same. The model is trained on a real world dataset and tested with live
video streaming with a good accuracy. Further the accuracy of the model with
different hyper parameters and multiple people at different distance and
location of the frame is done.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Date Estimation in the Wild of Scanned Historical Photos: An Image Retrieval Approach. (arXiv:2106.05618v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1">Adri&#xe0; Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1">Lluis Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1">Oriol Ramos-Terrades</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05618">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel method for date estimation of historical
photographs from archival sources. The main contribution is to formulate the
date estimation as a retrieval task, where given a query, the retrieved images
are ranked in terms of the estimated date similarity. The closer are their
embedded representations the closer are their dates. Contrary to the
traditional models that design a neural network that learns a classifier or a
regressor, we propose a learning objective based on the nDCG ranking metric. We
have experimentally evaluated the performance of the method in two different
tasks: date estimation and date-sensitive image retrieval, using the DEW public
database, overcoming the baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervising the Transfer of Reasoning Patterns in VQA. (arXiv:2106.05597v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1">Corentin Kervadec</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1">Christian Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1">Grigory Antipov</a>, <a href="http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1">Moez Baccouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadri_M/0/1/0/all/0/1">Madiha Nadri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05597">
                                    <div class="article-summary-box-inner">
                                        <span>Methods for Visual Question Anwering (VQA) are notorious for leveraging
dataset biases rather than performing reasoning, hindering generalization. It
has been recently shown that better reasoning patterns emerge in attention
layers of a state-of-the-art VQA model when they are trained on perfect
(oracle) visual inputs. This provides evidence that deep neural networks can
learn to reason when training conditions are favorable enough. However,
transferring this learned knowledge to deployable models is a challenge, as
much of it is lost during the transfer. We propose a method for knowledge
transfer based on a regularization term in our loss function, supervising the
sequence of required reasoning operations. We provide a theoretical analysis
based on PAC-learning, showing that such program prediction can lead to
decreased sample complexity under mild hypotheses. We also demonstrate the
effectiveness of this approach experimentally on the GQA dataset and show its
complementarity to BERT-like self-supervised pre-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Dataset Benchmarks for Masked Identification using Contrastive Representation Learning. (arXiv:2106.05596v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seneviratne_S/0/1/0/all/0/1">Sachith Seneviratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasthuriaarachchi_N/0/1/0/all/0/1">Nuran Kasthuriaarachchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasnayaka_S/0/1/0/all/0/1">Sanka Rasnayaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05596">
                                    <div class="article-summary-box-inner">
                                        <span>The COVID-19 pandemic has drastically changed accepted norms globally. Within
the past year, masks have been used as a public health response to limit the
spread of the virus. This sudden change has rendered many face recognition
based access control, authentication and surveillance systems ineffective.
Official documents such as passports, driving license and national identity
cards are enrolled with fully uncovered face images. However, in the current
global situation, face matching systems should be able to match these reference
images with masked face images. As an example, in an airport or security
checkpoint it is safer to match the unmasked image of the identifying document
to the masked person rather than asking them to remove the mask. We find that
current facial recognition techniques are not robust to this form of occlusion.

To address this unique requirement presented due to the current circumstance,
we propose a set of re-purposed datasets and a benchmark for researchers to
use. We also propose a contrastive visual representation learning based
pre-training workflow which is specialized to masked vs unmasked face matching.
We ensure that our method learns robust features to differentiate people across
varying data collection scenarios. We achieve this by training over many
different datasets and validating our result by testing on various holdout
datasets. The specialized weights trained by our method outperform standard
face recognition features for masked to unmasked face matching. We believe the
provided synthetic mask generating code, our novel training approach and the
trained weights from the masked face models will help in adopting existing face
recognition systems to operate in the current global environment. We
open-source all contributions for broader use by the research community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Stage-wise Learning for Unsupervised Feature Representation Enhancement. (arXiv:2106.05554v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zefan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1">Bingbing Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wen Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05554">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised learning methods have recently shown their competitiveness
against supervised training. Typically, these methods use a single objective to
train the entire network. But one distinct advantage of unsupervised over
supervised learning is that the former possesses more variety and freedom in
designing the objective. In this work, we explore new dimensions of
unsupervised learning by proposing the Progressive Stage-wise Learning (PSL)
framework. For a given unsupervised task, we design multilevel tasks and define
different learning stages for the deep network. Early learning stages are
forced to focus on lowlevel tasks while late stages are guided to extract
deeper information through harder tasks. We discover that by progressive
stage-wise learning, unsupervised feature representation can be effectively
enhanced. Our extensive experiments show that PSL consistently improves results
for the leading unsupervised learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Validation of Simulation-Based Testing: Bypassing Domain Shift with Label-to-Image Synthesis. (arXiv:2106.05549v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenzweig_J/0/1/0/all/0/1">Julia Rosenzweig</a>, <a href="http://arxiv.org/find/cs/1/au:+Brito_E/0/1/0/all/0/1">Eduardo Brito</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobialka_H/0/1/0/all/0/1">Hans-Ulrich Kobialka</a>, <a href="http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1">Maram Akila</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_N/0/1/0/all/0/1">Nico M. Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1">Peter Schlicht</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jan David Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1">Fabian H&#xfc;ger</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1">Matthias Rottmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1">Sebastian Houben</a>, <a href="http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1">Tim Wirtz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05549">
                                    <div class="article-summary-box-inner">
                                        <span>Many machine learning applications can benefit from simulated data for
systematic validation - in particular if real-life data is difficult to obtain
or annotate. However, since simulations are prone to domain shift w.r.t.
real-life data, it is crucial to verify the transferability of the obtained
results. We propose a novel framework consisting of a generative label-to-image
synthesis model together with different transferability measures to inspect to
what extent we can transfer testing results of semantic segmentation models
from synthetic data to equivalent real-life data. With slight modifications,
our approach is extendable to, e.g., general multi-class classification tasks.
Grounded on the transferability analysis, our approach additionally allows for
extensive testing by incorporating controlled simulations. We validate our
approach empirically on a semantic segmentation task on driving scenes.
Transferability is tested using correlation analysis of IoU and a learned
discriminator. Although the latter can distinguish between real-life and
synthetic tests, in the former we observe surprisingly strong correlations of
0.7 for both cars and pedestrians.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor feature hallucination for few-shot learning. (arXiv:2106.05321v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lazarou_M/0/1/0/all/0/1">Michalis Lazarou</a>, <a href="http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1">Yannis Avrithis</a>, <a href="http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1">Tania Stathaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05321">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot classification addresses the challenge of classifying examples given
not just limited supervision but limited data as well. An attractive solution
is synthetic data generation. However, most such methods are overly
sophisticated, focusing on high-quality, realistic data in the input space. It
is unclear whether adapting them to the few-shot regime and using them for the
downstream task of classification is the right approach. Previous works on
synthetic data generation for few-shot classification focus on exploiting
complex models, e.g. a Wasserstein GAN with multiple regularizers or a network
that transfers latent diversities from known to novel classes.

We follow a different approach and investigate how a simple and
straightforward synthetic data generation method can be used effectively. We
make two contributions, namely we show that: (1) using a simple loss function
is more than enough for training a feature generator in the few-shot setting;
and (2) learning to generate tensor features instead of vector features is
superior. Extensive experiments on miniImagenet, CUB and CIFAR-FS datasets show
that our method sets a new state of the art, outperforming more sophisticated
few-shot data augmentation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AFAN: Augmented Feature Alignment Network for Cross-Domain Object Detection. (arXiv:2106.05499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongsong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shengcai Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05499">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation for object detection is a challenging problem
with many real-world applications. Unfortunately, it has received much less
attention than supervised object detection. Models that try to address this
task tend to suffer from a shortage of annotated training samples. Moreover,
existing methods of feature alignments are not sufficient to learn
domain-invariant representations. To address these limitations, we propose a
novel augmented feature alignment network (AFAN) which integrates intermediate
domain image generation and domain-adversarial training into a unified
framework. An intermediate domain image generator is proposed to enhance
feature alignments by domain-adversarial training with automatically generated
soft domain labels. The synthetic intermediate domain images progressively
bridge the domain divergence and augment the annotated source domain training
data. A feature pyramid alignment is designed and the corresponding feature
discriminator is used to align multi-scale convolutional features of different
semantic levels. Last but not least, we introduce a region feature alignment
and an instance discriminator to learn domain-invariant features for object
proposals. Our approach significantly outperforms the state-of-the-art methods
on standard benchmarks for both similar and dissimilar domain adaptations.
Further extensive experiments verify the effectiveness of each component and
demonstrate that the proposed network can learn domain-invariant
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yibo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haidi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yiming Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shunyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05545">
                                    <div class="article-summary-box-inner">
                                        <span>With the effective application of deep learning in computer vision,
breakthroughs have been made in the research of super-resolution images
reconstruction. However, many researches have pointed out that the
insufficiency of the neural network extraction on image features may bring the
deteriorating of newly reconstructed image. On the other hand, the generated
pictures are sometimes too artificial because of over-smoothing. In order to
solve the above problems, we propose a novel self-calibrated convolutional
generative adversarial networks. The generator consists of feature extraction
and image reconstruction. Feature extraction uses self-calibrated convolutions,
which contains four portions, and each portion has specific functions. It can
not only expand the range of receptive fields, but also obtain long-range
spatial and inter-channel dependencies. Then image reconstruction is performed,
and finally a super-resolution image is reconstructed. We have conducted
thorough experiments on different datasets including set5, set14 and BSD100
under the SSIM evaluation method. The experimental results prove the
effectiveness of the proposed network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving White-box Robustness of Pre-processing Defenses via Joint Adversarial Training. (arXiv:2106.05453v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dawei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Nannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05453">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are vulnerable to adversarial noise. A range of
adversarial defense techniques have been proposed to mitigate the interference
of adversarial noise, among which the input pre-processing methods are scalable
and show great potential to safeguard DNNs. However, pre-processing methods may
suffer from the robustness degradation effect, in which the defense reduces
rather than improving the adversarial robustness of a target model in a
white-box setting. A potential cause of this negative effect is that
adversarial training examples are static and independent to the pre-processing
model. To solve this problem, we investigate the influence of full adversarial
examples which are crafted against the full model, and find they indeed have a
positive impact on the robustness of defenses. Furthermore, we find that simply
changing the adversarial training examples in pre-processing methods does not
completely alleviate the robustness degradation effect. This is due to the
adversarial risk of the pre-processed model being neglected, which is another
cause of the robustness degradation effect. Motivated by above analyses, we
propose a method called Joint Adversarial Training based Pre-processing (JATP)
defense. Specifically, we formulate a feature similarity based adversarial risk
for the pre-processing model by using full adversarial examples found in a
feature space. Unlike standard adversarial training, we only update the
pre-processing model, which prompts us to introduce a pixel-wise loss to
improve its cross-model transferability. We then conduct a joint adversarial
training on the pre-processing model to minimize this overall risk. Empirical
results show that our method could effectively mitigate the robustness
degradation effect across different target models in comparison to previous
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1">Julio Hurtado</a>, <a href="http://arxiv.org/find/cs/1/au:+Raymond_Saez_A/0/1/0/all/0/1">Alain Raymond-Saez</a>, <a href="http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1">Alvaro Soto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05390">
                                    <div class="article-summary-box-inner">
                                        <span>When learning tasks over time, artificial neural networks suffer from a
problem known as Catastrophic Forgetting (CF). This happens when the weights of
a network are overwritten during the training of a new task causing forgetting
of old information. To address this issue, we propose MetA Reusable Knowledge
or MARK, a new method that fosters weight reusability instead of overwriting
when learning a new task. Specifically, MARK keeps a set of shared weights
among tasks. We envision these shared weights as a common Knowledge Base (KB)
that is not only used to learn new tasks, but also enriched with new knowledge
as the model learns new tasks. Key components behind MARK are two-fold. On the
one hand, a metalearning approach provides the key mechanism to incrementally
enrich the KB with new knowledge and to foster weight reusability among tasks.
On the other hand, a set of trainable masks provides the key mechanism to
selectively choose from the KB relevant weights to solve each task. By using
MARK, we achieve state of the art results in several popular benchmarks,
surpassing the best performing methods in terms of average accuracy by over 10%
on the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness
using 55% of the number of parameters. Furthermore, an ablation study provides
evidence that, indeed, MARK is learning reusable knowledge that is selectively
used by each task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline. (arXiv:2106.05304v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1">Ankit Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_H/0/1/0/all/0/1">Hei Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Newell_A/0/1/0/all/0/1">Alejandro Newell</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jia Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05304">
                                    <div class="article-summary-box-inner">
                                        <span>Processing point cloud data is an important component of many real-world
systems. As such, a wide variety of point-based approaches have been proposed,
reporting steady benchmark improvements over time. We study the key ingredients
of this progress and uncover two critical results. First, we find that
auxiliary factors like different evaluation schemes, data augmentation
strategies, and loss functions, which are independent of the model
architecture, make a large difference in performance. The differences are large
enough that they obscure the effect of architecture. When these factors are
controlled for, PointNet++, a relatively older network, performs competitively
with recent methods. Second, a very simple projection-based method, which we
refer to as SimpleView, performs surprisingly well. It achieves on par or
better results than sophisticated state-of-the-art methods on ModelNet40 while
being half the size of PointNet++. It also outperforms state-of-the-art methods
on ScanObjectNN, a real-world point cloud benchmark, and demonstrates better
cross-dataset generalization. Code is available at
https://github.com/princeton-vl/SimpleView.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-domain Contrastive Learning for Unsupervised Domain Adaptation. (arXiv:2106.05528v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zuxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1">Zejia Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingjing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Guo-Jun Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05528">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from
a fully-labeled source domain to a different unlabeled target domain. Most
existing UDA methods learn domain-invariant feature representations by
minimizing feature distances across domains. In this work, we build upon
contrastive self-supervised learning to align features so as to reduce the
domain discrepancy between training and testing sets. Exploring the same set of
categories shared by both domains, we introduce a simple yet effective
framework CDCL, for domain alignment. In particular, given an anchor image from
one domain, we minimize its distances to cross-domain samples from the same
class relative to those from different categories. Since target labels are
unavailable, we use a clustering-based approach with carefully initialized
centers to produce pseudo labels. In addition, we demonstrate that CDCL is a
general framework and can be adapted to the data-free setting, where the source
data are unavailable during training, with minimal modification. We conduct
experiments on two widely used domain adaptation benchmarks, i.e., Office-31
and VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance
on both datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plan2Scene: Converting Floorplans to 3D Scenes. (arXiv:2106.05375v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vidanapathirana_M/0/1/0/all/0/1">Madhawa Vidanapathirana</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qirui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1">Yasutaka Furukawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_A/0/1/0/all/0/1">Angel X. Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Savva_M/0/1/0/all/0/1">Manolis Savva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05375">
                                    <div class="article-summary-box-inner">
                                        <span>We address the task of converting a floorplan and a set of associated photos
of a residence into a textured 3D mesh model, a task which we call Plan2Scene.
Our system 1) lifts a floorplan image to a 3D mesh model; 2) synthesizes
surface textures based on the input photos; and 3) infers textures for
unobserved surfaces using a graph neural network architecture. To train and
evaluate our system we create indoor surface texture datasets, and augment a
dataset of floorplans and photos from prior work with rectified surface crops
and additional annotations. Our approach handles the challenge of producing
tileable textures for dominant surfaces such as floors, walls, and ceilings
from a sparse set of unaligned photos that only partially cover the residence.
Qualitative and quantitative evaluations show that our system produces
realistic 3D interior models, outperforming baseline approaches on a suite of
texture quality metrics and as measured by a holistic user study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Raman spectral analysis of mixtures with one-dimensional convolutional neural network. (arXiv:2106.05316v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mozaffari_M/0/1/0/all/0/1">M. Hamed Mozaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1">Li-Lin Tay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05316">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the combination of robust one-dimensional convolutional neural
networks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid
identification of unknown substances with good accuracy. Using this technique,
researchers can recognize a pure compound and distinguish it from unknown
substances in a mixture. The novelty of this approach is that the trained
neural network operates automatically without any pre- or post-processing of
data. Some studies have attempted to extend this technique to the
classification of pure compounds in an unknown mixture. However, the
application of 1-D CNNs has typically been restricted to binary classifications
of pure compounds. Here we will highlight a new approach in spectral
recognition and quantification of chemical components in a multicomponent
mixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this
purpose. The former is for rapid classification of components in a mixture
while the latter is for quantitative determination of those constituents. In
the proposed method, there is no limit to the number of compounds in a mixture.
A data augmentation method is also introduced by adding random baselines to the
Raman spectra. The experimental results revealed that the classification
accuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at
the same time, the RaMixNet II model may achieve a regression accuracy of 88%
for the quantification of each component.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DUET: Detection Utilizing Enhancement for Text in Scanned or Captured Documents. (arXiv:2106.05542v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1">Eun-Soo Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1">HyeongGwan Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1">Kyusam Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_Y/0/1/0/all/0/1">Yongkeun Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1">Soonhwan Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Min Soo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05542">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel deep neural model for text detection in document images.
For robust text detection in noisy scanned documents, the advantages of
multi-task learning are adopted by adding an auxiliary task of text
enhancement. Namely, our proposed model is designed to perform noise reduction
and text region enhancement as well as text detection. Moreover, we enrich the
training data for the model with synthesized document images that are fully
labeled for text detection and enhancement, thus overcome the insufficiency of
labeled document image data. For the effective exploitation of the synthetic
and real data, the training process is separated in two phases. The first phase
is training only synthetic data in a fully-supervised manner. Then real data
with only detection labels are added in the second phase. The enhancement task
for the real data is weakly-supervised with information from their detection
labels. Our methods are demonstrated in a real document dataset with
performances exceeding those of other text detection methods. Moreover,
ablations are conducted and the results confirm the effectiveness of the
synthetic data, auxiliary task, and weak-supervision. Whereas the existing text
detection studies mostly focus on the text in scenes, our proposed method is
optimized to the applications for the text in scanned documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Semantic Mapping from Arthroscopy using Out-of-distribution Pose and Depth and In-distribution Segmentation Training. (arXiv:2106.05525v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jonmohamadi_Y/0/1/0/all/0/1">Yaqub Jonmohamadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_S/0/1/0/all/0/1">Shahnewaz Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fengbei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_J/0/1/0/all/0/1">Jonathan Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Crawford_R/0/1/0/all/0/1">Ross Crawford</a>, <a href="http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Ajay K. Pandey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05525">
                                    <div class="article-summary-box-inner">
                                        <span>Minimally invasive surgery (MIS) has many documented advantages, but the
surgeon&#x27;s limited visual contact with the scene can be problematic. Hence,
systems that can help surgeons navigate, such as a method that can produce a 3D
semantic map, can compensate for the limitation above. In theory, we can borrow
3D semantic mapping techniques developed for robotics, but this requires
finding solutions to the following challenges in MIS: 1) semantic segmentation,
2) depth estimation, and 3) pose estimation. In this paper, we propose the
first 3D semantic mapping system from knee arthroscopy that solves the three
challenges above. Using out-of-distribution non-human datasets, where pose
could be labeled, we jointly train depth+pose estimators using selfsupervised
and supervised losses. Using an in-distribution human knee dataset, we train a
fully-supervised semantic segmentation system to label arthroscopic image
pixels into femur, ACL, and meniscus. Taking testing images from human knees,
we combine the results from these two systems to automatically create 3D
semantic maps of the human knee. The result of this work opens the pathway to
the generation of intraoperative 3D semantic mapping, registration with
pre-operative data, and robotic-assisted arthroscopy</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Very Compact Clusters with Structural Regularization via Similarity and Connectivity. (arXiv:2106.05430v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1">Won Hwa Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05430">
                                    <div class="article-summary-box-inner">
                                        <span>Clustering algorithms have significantly improved along with Deep Neural
Networks which provide effective representation of data. Existing methods are
built upon deep autoencoder and self-training process that leverages the
distribution of cluster assignments of samples. However, as the fundamental
objective of the autoencoder is focused on efficient data reconstruction, the
learnt space may be sub-optimal for clustering. Moreover, it requires highly
effective codes (i.e., representation) of data, otherwise the initial cluster
centers often cause stability issues during self-training. Many
state-of-the-art clustering algorithms use convolution operation to extract
efficient codes but their applications are limited to image data. In this
regard, we propose an end-to-end deep clustering algorithm, i.e., Very Compact
Clusters (VCC), for the general datasets, which takes advantage of
distributions of local relationships of samples near the boundary of clusters,
so that they can be properly separated and pulled to cluster centers to form
compact clusters. Experimental results on various datasets illustrate that our
proposed approach achieves better clustering performance over most of the
state-of-the-art clustering methods, and the data embeddings learned by VCC
without convolution for image data are even comparable with specialized
convolutional methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Sensor Pose Optimisation Using Rendering-based Visibility Models for Robust Cooperative Perception. (arXiv:2106.05308v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arnold_E/0/1/0/all/0/1">Eduardo Arnold</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozaffari_S/0/1/0/all/0/1">Sajjad Mozaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Dianati_M/0/1/0/all/0/1">Mehrdad Dianati</a>, <a href="http://arxiv.org/find/cs/1/au:+Jennings_P/0/1/0/all/0/1">Paul Jennings</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05308">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Sensor Networks can be used in a variety of perception applications
such as infrastructure support for autonomous driving in complex road segments.
The pose of the sensors in such networks directly determines the coverage of
the environment and objects therein, which impacts the performance of
applications such as object detection and tracking. Existing sensor pose
optimisation methods in the literature either maximise the coverage of ground
surfaces, or consider the visibility of the target objects as binary variables,
which cannot represent various degrees of visibility. Such formulations cannot
guarantee the visibility of the target objects as they fail to consider
occlusions. This paper proposes two novel sensor pose optimisation methods,
based on gradient-ascent and Integer Programming techniques, which maximise the
visibility of multiple target objects in cluttered environments. Both methods
consider a realistic visibility model based on a rendering engine that provides
pixel-level visibility information about the target objects. The proposed
methods are evaluated in a complex environment and compared to existing methods
in the literature. The evaluation results indicate that explicitly modelling
the visibility of target objects is critical to avoid occlusions in cluttered
environments. Furthermore, both methods significantly outperform existing
methods in terms of object visibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Video Person Re-identification via Noise and Hard frame Aware Clustering. (arXiv:2106.05441v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pengyu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamasaki_T/0/1/0/all/0/1">Toshihiko Yamasaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05441">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised video-based person re-identification (re-ID) methods extract
richer features from video tracklets than image-based ones. The
state-of-the-art methods utilize clustering to obtain pseudo-labels and train
the models iteratively. However, they underestimate the influence of two kinds
of frames in the tracklet: 1) noise frames caused by detection errors or heavy
occlusions exist in the tracklet, which may be allocated with unreliable labels
during clustering; 2) the tracklet also contains hard frames caused by pose
changes or partial occlusions, which are difficult to distinguish but
informative. This paper proposes a Noise and Hard frame Aware Clustering (NHAC)
method. NHAC consists of a graph trimming module and a node re-sampling module.
The graph trimming module obtains stable graphs by removing noise frame nodes
to improve the clustering accuracy. The node re-sampling module enhances the
training of hard frame nodes to learn rich tracklet information. Experiments
conducted on two video-based datasets demonstrate the effectiveness of the
proposed NHAC under the unsupervised re-ID setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RLCorrector: Reinforced Proofreading for Connectomics Image Segmentation. (arXiv:2106.05487v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1">Khoa Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_G/0/1/0/all/0/1">Ganghee Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_W/0/1/0/all/0/1">Won-ki Jeong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05487">
                                    <div class="article-summary-box-inner">
                                        <span>The segmentation of nanoscale electron microscopy (EM) images is crucial but
challenging in connectomics. Recent advances in deep learning have demonstrated
the significant potential of automatic segmentation for tera-scale EM images.
However, none of the existing segmentation methods are error-free, and they
require proofreading, which is typically implemented as an interactive,
semi-automatic process via manual intervention. Herein, we propose a fully
automatic proofreading method based on reinforcement learning. The main idea is
to model the human decision process in proofreading using a reinforcement agent
to achieve fully automatic proofreading. We systematically design the proposed
system by combining multiple reinforcement learning agents in a hierarchical
manner, where each agent focuses only on a specific task while preserving
dependency between agents. Furthermore, we also demonstrate that the episodic
task setting of reinforcement learning can efficiently manage a combination of
merge and split errors concurrently presented in the input. We demonstrate the
efficacy of the proposed system by comparing it with state-of-the-art
proofreading methods using various testing examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation to improve robustness of image captioning solutions. (arXiv:2106.05437v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bujimalla_S/0/1/0/all/0/1">Shashank Bujimalla</a>, <a href="http://arxiv.org/find/cs/1/au:+Subedar_M/0/1/0/all/0/1">Mahesh Subedar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tickoo_O/0/1/0/all/0/1">Omesh Tickoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05437">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the impact of motion blur, a common quality flaw in
real world images, on a state-of-the-art two-stage image captioning solution,
and notice a degradation in solution performance as blur intensity increases.
We investigate techniques to improve the robustness of the solution to motion
blur using training data augmentation at each or both stages of the solution,
i.e., object detection and captioning, and observe improved results. In
particular, augmenting both the stages reduces the CIDEr-D degradation for high
motion blur intensity from 68.7 to 11.7 on MS COCO dataset, and from 22.4 to
6.8 on Vizwiz dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity. (arXiv:2106.01300v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1">Tao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01300">
                                    <div class="article-summary-box-inner">
                                        <span>Personalized news recommendation methods are widely used in online news
services. These methods usually recommend news based on the matching between
news content and user interest inferred from historical behaviors. However,
these methods usually have difficulties in making accurate recommendations to
cold-start users, and tend to recommend similar news with those users have
read. In general, popular news usually contain important information and can
attract users with different interests. Besides, they are usually diverse in
content and topic. Thus, in this paper we propose to incorporate news
popularity information to alleviate the cold-start and diversity problems for
personalized news recommendation. In our method, the ranking score for
recommending a candidate news to a target user is the combination of a
personalized matching score and a news popularity score. The former is used to
capture the personalized user interest in news. The latter is used to measure
time-aware popularity of candidate news, which is predicted based on news
content, recency, and real-time CTR using a unified framework. Besides, we
propose a popularity-aware user encoder to eliminate the popularity bias in
user behaviors for accurate interest modeling. Experiments on two real-world
datasets show our method can effectively improve the accuracy and diversity for
news recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Position-wise Interaction Network for CTR Prediction. (arXiv:2106.05482v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Ke Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1">Qingtao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingjian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jia Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jun Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05482">
                                    <div class="article-summary-box-inner">
                                        <span>Click-through rate (CTR) prediction plays an important role in online
advertising and recommender systems. In practice, the training of CTR models
depends on click data which is intrinsically biased towards higher positions
since higher position has higher CTR by nature. Existing methods such as actual
position training with fixed position inference and inverse propensity weighted
training with no position inference alleviate the bias problem to some extend.
However, the different treatment of position information between training and
inference will inevitably lead to inconsistency and sub-optimal online
performance. Meanwhile, the basic assumption of these methods, i.e., the click
probability is the product of examination probability and relevance
probability, is oversimplified and insufficient to model the rich interaction
between position and other information. In this paper, we propose a Deep
Position-wise Interaction Network (DPIN) to efficiently combine all candidate
items and positions for estimating CTR at each position, achieving consistency
between offline and online as well as modeling the deep non-linear interaction
among position, user, context and item under the limit of serving performance.
Following our new treatment to the position bias in CTR prediction, we propose
a new evaluation metrics named PAUC (position-wise AUC) that is suitable for
measuring the ranking quality at a given position. Through extensive
experiments on a real world dataset, we show empirically that our method is
both effective and efficient in solving position bias problem. We have also
deployed our method in production and observed statistically significant
improvement over a highly optimized baseline in a rigorous A/B test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PARADE: Passage Representation Aggregation for Document Reranking. (arXiv:2008.09093v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Canjia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1">Andrew Yates</a>, <a href="http://arxiv.org/find/cs/1/au:+MacAvaney_S/0/1/0/all/0/1">Sean MacAvaney</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Ben He</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yingfei Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09093">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained transformer models, such as BERT and T5, have shown to be highly
effective at ad-hoc passage and document ranking. Due to inherent sequence
length limits of these models, they need to be run over a document&#x27;s passages,
rather than processing the entire document sequence at once. Although several
approaches for aggregating passage-level signals have been proposed, there has
yet to be an extensive comparison of these techniques. In this work, we explore
strategies for aggregating relevance signals from a document&#x27;s passages into a
final ranking score. We find that passage representation aggregation techniques
can significantly improve over techniques proposed in prior work, such as
taking the maximum passage score. We call this new approach PARADE. In
particular, PARADE can significantly improve results on collections with broad
information needs where relevance signals can be spread throughout the document
(such as TREC Robust04 and GOV2). Meanwhile, less complex aggregation
techniques may work better on collections with an information need that can
often be pinpointed to a single passage (such as TREC DL and TREC Genomics). We
also conduct efficiency analyses, and highlight several strategies for
improving transformer-based aggregation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Self-Attentive Neural Networks for Click-Through Rate Prediction. (arXiv:2101.03654v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yichen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanqiao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Feng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03654">
                                    <div class="article-summary-box-inner">
                                        <span>Click-through rate (CTR) prediction, whose aim is to predict the probability
of whether a user will click on an item, is an essential task for many online
applications. Due to the nature of data sparsity and high dimensionality in CTR
prediction, a key to making effective prediction is to model high-order feature
interaction among feature fields. To explicitly model high-order feature
interaction, an efficient way is to perform inner product of feature embeddings
with self-attentive neural networks. To better model complex feature
interaction, in this paper we propose a novel DisentanglEd Self-atTentIve
NEtwork (DESTINE) framework for CTR prediction that explicitly decouples the
computation of unary importance from pairwise interaction. Specifically, the
unary term models the general impact of one feature on all other features,
whereas the whitened pairwise interaction term contributes to learning the pure
importance score for each feature interaction. We conduct extensive experiments
framework using two real-world benchmark datasets. The results show that
DESTINE not only maintains computational efficiency but obtains performance
improvements over state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linguistically Informed Masking for Representation Learning in the Patent Domain. (arXiv:2106.05768v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Althammer_S/0/1/0/all/0/1">Sophia Althammer</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckley_M/0/1/0/all/0/1">Mark Buckley</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofstatter_S/0/1/0/all/0/1">Sebastian Hofst&#xe4;tter</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanbury_A/0/1/0/all/0/1">Allan Hanbury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05768">
                                    <div class="article-summary-box-inner">
                                        <span>Domain-specific contextualized language models have demonstrated substantial
effectiveness gains for domain-specific downstream tasks, like similarity
matching, entity recognition or information retrieval. However successfully
applying such models in highly specific language domains requires domain
adaptation of the pre-trained models. In this paper we propose the empirically
motivated Linguistically Informed Masking (LIM) method to focus
domain-adaptative pre-training on the linguistic patterns of patents, which use
a highly technical sublanguage. We quantify the relevant differences between
patent, scientific and general-purpose language and demonstrate for two
different language models (BERT and SciBERT) that domain adaptation with LIM
leads to systematically improved representations by evaluating the performance
of the domain-adapted representations of patent language on two independent
downstream tasks, the IPC classification and similarity matching. We
demonstrate the impact of balancing the learning from different information
sources during domain adaptation for the patent domain. We make the source code
as well as the domain-adaptive pre-trained patent language models publicly
available at https://github.com/sophiaalthammer/patent-lim.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GRASP: Graph Alignment through Spectral Signatures. (arXiv:2106.05729v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hermanns_J/0/1/0/all/0/1">Judith Hermanns</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsitsulin_A/0/1/0/all/0/1">Anton Tsitsulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Munkhoeva_M/0/1/0/all/0/1">Marina Munkhoeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1">Alex Bronstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Mottin_D/0/1/0/all/0/1">Davide Mottin</a>, <a href="http://arxiv.org/find/cs/1/au:+Karras_P/0/1/0/all/0/1">Panagiotis Karras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05729">
                                    <div class="article-summary-box-inner">
                                        <span>What is the best way to match the nodes of two graphs? This graph alignment
problem generalizes graph isomorphism and arises in applications from social
network analysis to bioinformatics. Some solutions assume that auxiliary
information on known matches or node or edge attributes is available, or
utilize arbitrary graph features. Such methods fare poorly in the pure form of
the problem, in which only graph structures are given. Other proposals
translate the problem to one of aligning node embeddings, yet, by doing so,
provide only a single-scale view of the graph.In this paper, we transfer the
shape-analysis concept of functional maps from the continuous to the discrete
case, and treat the graph alignment problem as a special case of the problem of
finding a mapping between functions on graphs. We present GRASP, a method that
first establishes a correspondence between functions derived from Laplacian
matrix eigenvectors, which capture multiscale structural characteristics,and
then exploits this correspondence to align nodes. Our experimental study,
featuring noise levels higher than anything used in previous studies, shows
that GRASP outperforms state-of-the-art methods for graph alignment across
noise levels and graph types.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Search -- Optimizing the Game of Information Seeking. (arXiv:1909.12425v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.12425">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents the emerging topic of dynamic search (DS). To position
dynamic search in a larger research landscape, the article discusses in detail
its relationship to related research topics and disciplines. The article
reviews approaches to modeling dynamics during information seeking, with an
emphasis on Reinforcement Learning (RL)-enabled methods. Details are given for
how different approaches are used to model interactions among the human user,
the search system, and the environment. The paper ends with a review of
evaluations of dynamic search systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Citation Recommendation for Research Papers via Knowledge Graphs. (arXiv:2106.05633v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brack_A/0/1/0/all/0/1">Arthur Brack</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoppe_A/0/1/0/all/0/1">Anett Hoppe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05633">
                                    <div class="article-summary-box-inner">
                                        <span>Citation recommendation for research papers is a valuable task that can help
researchers improve the quality of their work by suggesting relevant related
work. Current approaches for this task rely primarily on the text of the papers
and the citation network. In this paper, we propose to exploit an additional
source of information, namely research knowledge graphs (KG) that interlink
research papers based on mentioned scientific concepts. Our experimental
results demonstrate that the combination of information from research KGs with
existing state-of-the-art approaches is beneficial. Experimental results are
presented for the STM-KG (STM: Science, Technology, Medicine), which is an
automatically populated knowledge graph based on the scientific concepts
extracted from papers of ten domains. The proposed approach outperforms the
state of the art with a mean average precision of 20.6% (+0.8) for the top-50
retrieved results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing Non-Textual Content Elements to Detect Academic Plagiarism. (arXiv:2106.05764v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meuschke_N/0/1/0/all/0/1">Norman Meuschke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05764">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying academic plagiarism is a pressing problem, among others, for
research institutions, publishers, and funding organizations. Detection
approaches proposed so far analyze lexical, syntactical, and semantic text
similarity. These approaches find copied, moderately reworded, and literally
translated text. However, reliably detecting disguised plagiarism, such as
strong paraphrases, sense-for-sense translations, and the reuse of non-textual
content and ideas, is an open research problem.

The thesis addresses this problem by proposing plagiarism detection
approaches that implement a different concept: analyzing non-textual content in
academic documents, specifically citations, images, and mathematical content.

To validate the effectiveness of the proposed detection approaches, the
thesis presents five evaluations that use real cases of academic plagiarism and
exploratory searches for unknown cases.

The evaluation results show that non-textual content elements contain a high
degree of semantic information, are language-independent, and largely immutable
to the alterations that authors typically perform to conceal plagiarism.
Analyzing non-textual content complements text-based detection approaches and
increases the detection effectiveness, particularly for disguised forms of
academic plagiarism.

To demonstrate the benefit of combining non-textual and text-based detection
methods, the thesis describes the first plagiarism detection system that
integrates the analysis of citation-based, image-based, math-based, and
text-based document similarity. The system&#x27;s user interface employs
visualizations that significantly reduce the effort and time users must invest
in examining content similarity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Training of Multi-Document Reader and Retriever for Open-Domain Question Answering. (arXiv:2106.05346v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1">Devendra Singh Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1">Chris Dyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yogatama_D/0/1/0/all/0/1">Dani Yogatama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05346">
                                    <div class="article-summary-box-inner">
                                        <span>We present an end-to-end differentiable training method for
retrieval-augmented open-domain question answering systems that combine
information from multiple retrieved documents when generating answers. We model
retrieval decisions as latent variables over sets of relevant documents. Since
marginalizing over sets of retrieved documents is computationally hard, we
approximate this using an expectation-maximization algorithm. We iteratively
estimate the value of our latent variable (the set of relevant documents for a
given question) and then use this estimate to update the retriever and reader
parameters. We hypothesize that such end-to-end training allows training
signals to flow to the reader and then to the retriever better than staged-wise
training. This results in a retriever that is able to select more relevant
documents for a question and a reader that is trained on more accurate
documents to generate an answer. Experiments on three benchmark datasets
demonstrate that our proposed method outperforms all existing approaches of
comparable size by 2-3% absolute exact match points, achieving new
state-of-the-art results. Our results also demonstrate the feasibility of
learning to retrieve to improve answer generation without explicit supervision
of retrieval decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Mingliang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1">Zeqian Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05630">
                                    <div class="article-summary-box-inner">
                                        <span>Symbolic music understanding, which refers to the understanding of music from
the symbolic data (e.g., MIDI format, but not audio), covers many music
applications such as genre classification, emotion classification, and music
pieces matching. While good music representations are beneficial for these
applications, the lack of training data hinders representation learning.
Inspired by the success of pre-training models in natural language processing,
in this paper, we develop MusicBERT, a large-scale pre-trained model for music
understanding. To this end, we construct a large-scale symbolic music corpus
that contains more than 1 million music songs. Since symbolic music contains
more structural (e.g., bar, position) and diverse information (e.g., tempo,
instrument, and pitch), simply adopting the pre-training techniques from NLP to
symbolic music only brings marginal gains. Therefore, we design several
mechanisms, including OctupleMIDI encoding and bar-level masking strategy, to
enhance pre-training with symbolic music data. Experiments demonstrate the
advantages of MusicBERT on four music understanding tasks, including melody
completion, accompaniment suggestion, genre classification, and style
classification. Ablation studies also verify the effectiveness of our designs
of OctupleMIDI encoding and bar-level masking strategy in MusicBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super-Resolution Image Reconstruction Based on Self-Calibrated Convolutional GAN. (arXiv:2106.05545v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1">Yibo Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Haidi Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1">Yiming Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1">Shunyao Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05545">
                                    <div class="article-summary-box-inner">
                                        <span>With the effective application of deep learning in computer vision,
breakthroughs have been made in the research of super-resolution images
reconstruction. However, many researches have pointed out that the
insufficiency of the neural network extraction on image features may bring the
deteriorating of newly reconstructed image. On the other hand, the generated
pictures are sometimes too artificial because of over-smoothing. In order to
solve the above problems, we propose a novel self-calibrated convolutional
generative adversarial networks. The generator consists of feature extraction
and image reconstruction. Feature extraction uses self-calibrated convolutions,
which contains four portions, and each portion has specific functions. It can
not only expand the range of receptive fields, but also obtain long-range
spatial and inter-channel dependencies. Then image reconstruction is performed,
and finally a super-resolution image is reconstructed. We have conducted
thorough experiments on different datasets including set5, set14 and BSD100
under the SSIM evaluation method. The experimental results prove the
effectiveness of the proposed network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anatomy X-Net: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamal_U/0/1/0/all/0/1">Uday Kamal</a>, <a href="http://arxiv.org/find/eess/1/au:+Zunaed_M/0/1/0/all/0/1">Mohammad Zunaed</a>, <a href="http://arxiv.org/find/eess/1/au:+Nizam_N/0/1/0/all/0/1">Nusrat Binta Nizam</a>, <a href="http://arxiv.org/find/eess/1/au:+Hasan_T/0/1/0/all/0/1">Taufiq Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05915">
                                    <div class="article-summary-box-inner">
                                        <span>Thoracic disease detection from chest radiographs using deep learning methods
has been an active area of research in the last decade. Most previous methods
attempt to focus on the diseased organs of the image by identifying spatial
regions responsible for significant contributions to the model&#x27;s prediction. In
contrast, expert radiologists first locate the prominent anatomical structures
before determining if those regions are anomalous. Therefore, integrating
anatomical knowledge within deep learning models could bring substantial
improvement in automatic disease classification. This work proposes an
anatomy-aware attention-based architecture named Anatomy X-Net, that
prioritizes the spatial features guided by the pre-identified anatomy regions.
We leverage a semi-supervised learning method using the JSRT dataset containing
organ-level annotation to obtain the anatomical segmentation masks (for lungs
and heart) for the NIH and CheXpert datasets. The proposed Anatomy X-Net uses
the pre-trained DenseNet-121 as the backbone network with two corresponding
structured modules, the Anatomy Aware Attention (AAA) and Probabilistic
Weighted Average Pooling (PWAP), in a cohesive framework for anatomical
attention learning. Our proposed method sets new state-of-the-art performance
on the official NIH test set with an AUC score of 0.8439, proving the efficacy
of utilizing the anatomy segmentation knowledge to improve the thoracic disease
classification. Furthermore, the Anatomy X-Net yields an averaged AUC of 0.9020
on the Stanford CheXpert dataset, improving on existing methods that
demonstrate the generalizability of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition. (arXiv:2106.05933v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Cheng-I Jeff Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alexander H. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shiyu Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yi-Lun Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Sung Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1">Kaizhi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1">Sameer Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Cox_D/0/1/0/all/0/1">David Cox</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1">James Glass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05933">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work on speech self-supervised learning (speech SSL) demonstrated the
benefits of scale in learning rich and transferable representations for
Automatic Speech Recognition (ASR) with limited parallel data. It is then
natural to investigate the existence of sparse and transferrable subnetworks in
pre-trained speech SSL models that can achieve even better low-resource ASR
performance. However, directly applying widely adopted pruning methods such as
the Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost
needed. Moreover, contrary to what LTH predicts, the discovered subnetworks
yield minimal performance gain compared to the original dense network. In this
work, we propose Prune-Adjust- Re-Prune (PARP), which discovers and finetunes
subnetworks for much better ASR performance, while only requiring a single
downstream finetuning run. PARP is inspired by our surprising observation that
subnetworks pruned for pre-training tasks only needed to be slightly adjusted
to achieve a sizeable performance boost in downstream ASR tasks. Extensive
experiments on low-resource English and multi-lingual ASR show (1) sparse
subnetworks exist in pre-trained speech SSL, and (2) the computational
advantage and performance gain of PARP over baseline pruning methods. On the
10min Librispeech split without LM decoding, PARP discovers subnetworks from
wav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full
model. We demonstrate PARP mitigates performance degradation in cross-lingual
mask transfer, and investigate the possibility of discovering a single
subnetwork for 10 spoken languages in one run.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1">Devaraja Adiga</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1">Rishabh Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1">Amrith Krishna</a>, <a href="http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05852">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the
various linguistic peculiarities present in the language. The Sanskrit language
is lexically productive, undergoes euphonic assimilation of phones at the word
boundaries and exhibits variations in spelling conventions and in
pronunciations. In this work, we propose the first large scale study of
automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact
of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR
dataset for Sanskrit, which faithfully captures several of the linguistic
characteristics expressed by the language. We investigate the role of different
acoustic model and language model units in ASR systems for Sanskrit. We also
propose a new modelling unit, inspired by the syllable level unit selection,
that captures character sequences from one vowel in the word to the next vowel.
We also highlight the importance of choosing graphemic representations for
Sanskrit and show the impact of this choice on word error rates (WER). Finally,
we extend these insights from Sanskrit ASR for building ASR systems in two
other Indic languages, Gujarati and Telugu. For both these languages, our
experimental results show that the use of phonetic based graphemic
representations in ASR results in performance improvements as compared to ASR
systems that use native scripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Contrastive Methods for Unsupervised Learning of Visual Representations. (arXiv:2106.05967v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gansbeke_W/0/1/0/all/0/1">Wouter Van Gansbeke</a>, <a href="http://arxiv.org/find/cs/1/au:+Vandenhende_S/0/1/0/all/0/1">Simon Vandenhende</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgoulis_S/0/1/0/all/0/1">Stamatios Georgoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05967">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive self-supervised learning has outperformed supervised pretraining
on many downstream tasks like segmentation and object detection. However,
current methods are still primarily applied to curated datasets like ImageNet.
In this paper, we first study how biases in the dataset affect existing
methods. Our results show that current contrastive approaches work surprisingly
well across: (i) object- versus scene-centric, (ii) uniform versus long-tailed
and (iii) general versus domain-specific datasets. Second, given the generality
of the approach, we try to realize further gains with minor modifications. We
show that learning additional invariances -- through the use of multi-scale
cropping, stronger augmentations and nearest neighbors -- improves the
representations. Finally, we observe that MoCo learns spatially structured
representations when trained with a multi-crop strategy. The representations
can be used for semantic segment retrieval and video instance segmentation
without finetuning. Moreover, the results are on par with specialized models.
We hope this work will serve as a useful study for other researchers. The code
and models will be available at
https://github.com/wvangansbeke/Revisiting-Contrastive-SSL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Knowledge Distillation Really Work?. (arXiv:2106.05945v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stanton_S/0/1/0/all/0/1">Samuel Stanton</a>, <a href="http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1">Pavel Izmailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirichenko_P/0/1/0/all/0/1">Polina Kirichenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1">Alexander A. Alemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1">Andrew Gordon Wilson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05945">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation is a popular technique for training a small student
network to emulate a larger teacher model, such as an ensemble of networks. We
show that while knowledge distillation can improve student generalization, it
does not typically work as it is commonly understood: there often remains a
surprisingly large discrepancy between the predictive distributions of the
teacher and the student, even in cases when the student has the capacity to
perfectly match the teacher. We identify difficulties in optimization as a key
reason for why the student is unable to match the teacher. We also show how the
details of the dataset used for distillation play a role in how closely the
student matches the teacher -- and that more closely matching the teacher
paradoxically does not always lead to better student generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FetReg: Placental Vessel Segmentation and Registration in Fetoscopy Challenge Dataset. (arXiv:2106.05923v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bano_S/0/1/0/all/0/1">Sophia Bano</a>, <a href="http://arxiv.org/find/cs/1/au:+Casella_A/0/1/0/all/0/1">Alessandro Casella</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_F/0/1/0/all/0/1">Francisco Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Moccia_S/0/1/0/all/0/1">Sara Moccia</a>, <a href="http://arxiv.org/find/cs/1/au:+Attilakos_G/0/1/0/all/0/1">George Attilakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Wimalasundera_R/0/1/0/all/0/1">Ruwan Wimalasundera</a>, <a href="http://arxiv.org/find/cs/1/au:+David_A/0/1/0/all/0/1">Anna L. David</a>, <a href="http://arxiv.org/find/cs/1/au:+Paladini_D/0/1/0/all/0/1">Dario Paladini</a>, <a href="http://arxiv.org/find/cs/1/au:+Deprest_J/0/1/0/all/0/1">Jan Deprest</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattos_L/0/1/0/all/0/1">Leonardo S. Mattos</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1">Danail Stoyanov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05923">
                                    <div class="article-summary-box-inner">
                                        <span>Fetoscopy laser photocoagulation is a widely used procedure for the treatment
of Twin-to-Twin Transfusion Syndrome (TTTS), that occur in mono-chorionic
multiple pregnancies due to placental vascular anastomoses. This procedure is
particularly challenging due to limited field of view, poor manoeuvrability of
the fetoscope, poor visibility due to fluid turbidity, variability in light
source, and unusual position of the placenta. This may lead to increased
procedural time and incomplete ablation, resulting in persistent TTTS.
Computer-assisted intervention may help overcome these challenges by expanding
the fetoscopic field of view through video mosaicking and providing better
visualization of the vessel network. However, the research and development in
this domain remain limited due to unavailability of high-quality data to encode
the intra- and inter-procedure variability. Through the Fetoscopic Placental
Vessel Segmentation and Registration (FetReg) challenge, we present a
large-scale multi-centre dataset for the development of generalized and robust
semantic segmentation and video mosaicking algorithms for the fetal environment
with a focus on creating drift-free mosaics from long duration fetoscopy
videos. In this paper, we provide an overview of the FetReg dataset, challenge
tasks, evaluation metrics and baseline methods for both segmentation and
registration. Baseline methods results on the FetReg dataset shows that our
dataset poses interesting challenges, which can be modelled and competed for
through our crowd-sourcing initiative of the FetReg challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Second look at Exponential and Cosine Step Sizes: Simplicity, Adaptivity, and Performance. (arXiv:2002.05273v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xiaoyu Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhuang_Z/0/1/0/all/0/1">Zhenxun Zhuang</a>, <a href="http://arxiv.org/find/stat/1/au:+Orabona_F/0/1/0/all/0/1">Francesco Orabona</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05273">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic Gradient Descent (SGD) is a popular tool in training large-scale
machine learning models. Its performance, however, is highly variable,
depending crucially on the choice of the step sizes. Accordingly, a variety of
strategies for tuning the step sizes have been proposed, ranging from
coordinate-wise approaches (a.k.a. &#x60;&#x60;adaptive&#x27;&#x27; step sizes) to sophisticated
heuristics to change the step size in each iteration. In this paper, we study
two step size schedules whose power has been repeatedly confirmed in practice:
the exponential and the cosine step sizes. For the first time, we provide
theoretical support for them proving convergence rates for smooth non-convex
functions, with and without the Polyak-\L{}ojasiewicz (PL) condition. Moreover,
we show the surprising property that these two strategies are \emph{adaptive}
to the noise level in the stochastic gradients of PL functions. That is,
contrary to polynomial step sizes, they achieve almost optimal performance
without needing to know the noise level nor tuning their hyperparameters based
on it. Finally, we conduct a fair and comprehensive empirical evaluation of
real-world datasets with deep learning architectures. Results show that, even
if only requiring at most two hyperparameters to tune, these two strategies
best or match the performance of various finely-tuned state-of-the-art
strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EventDrop: data augmentation for event-based learning. (arXiv:2106.05836v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_F/0/1/0/all/0/1">Fuqiang Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sng_W/0/1/0/all/0/1">Weicong Sng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuke Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fangwen Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05836">
                                    <div class="article-summary-box-inner">
                                        <span>The advantages of event-sensing over conventional sensors (e.g., higher
dynamic range, lower time latency, and lower power consumption) have spurred
research into machine learning for event data. Unsurprisingly, deep learning
has emerged as a competitive methodology for learning with event sensors; in
typical setups, discrete and asynchronous events are first converted into
frame-like tensors on which standard deep networks can be applied. However,
over-fitting remains a challenge, particularly since event datasets remain
small relative to conventional datasets (e.g., ImageNet). In this paper, we
introduce EventDrop, a new method for augmenting asynchronous event data to
improve the generalization of deep models. By dropping events selected with
various strategies, we are able to increase the diversity of training data
(e.g., to simulate various levels of occlusion). From a practical perspective,
EventDrop is simple to implement and computationally low-cost. Experiments on
two event datasets (N-Caltech101 and N-Cars) demonstrate that EventDrop can
significantly improve the generalization performance across a variety of deep
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Generalization in Meta-learning via Task Augmentation. (arXiv:2007.13040v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Huaxiu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longkai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Linjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Ying Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1">Li Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenhui Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.13040">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning has proven to be a powerful paradigm for transferring the
knowledge from previous tasks to facilitate the learning of a novel task.
Current dominant algorithms train a well-generalized model initialization which
is adapted to each task via the support set. The crux lies in optimizing the
generalization capability of the initialization, which is measured by the
performance of the adapted model on the query set of each task. Unfortunately,
this generalization measure, evidenced by empirical results, pushes the
initialization to overfit the meta-training tasks, which significantly impairs
the generalization and adaptation to novel tasks. To address this issue, we
actively augment a meta-training task with &quot;more data&quot; when evaluating the
generalization. Concretely, we propose two task augmentation methods, including
MetaMix and Channel Shuffle. MetaMix linearly combines features and labels of
samples from both the support and query sets. For each class of samples,
Channel Shuffle randomly replaces a subset of their channels with the
corresponding ones from a different class. Theoretical studies show how task
augmentation improves the generalization of meta-learning. Moreover, both
MetaMix and Channel Shuffle outperform state-of-the-art results by a large
margin across many datasets and are compatible with existing meta-learning
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Ordinal Regression Based on Empirical Risk Minimization. (arXiv:1901.11351v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsuchiya_T/0/1/0/all/0/1">Taira Tsuchiya</a>, <a href="http://arxiv.org/find/cs/1/au:+Charoenphakdee_N/0/1/0/all/0/1">Nontawat Charoenphakdee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.11351">
                                    <div class="article-summary-box-inner">
                                        <span>Ordinal regression is aimed at predicting an ordinal class label. In this
paper, we consider its semi-supervised formulation, in which we have unlabeled
data along with ordinal-labeled data to train an ordinal regressor. There are
several metrics to evaluate the performance of ordinal regression, such as the
mean absolute error, mean zero-one error, and mean squared error. However, the
existing studies do not take the evaluation metric into account, have a
restriction on the model choice, and have no theoretical guarantee. To overcome
these problems, we propose a novel generic framework for semi-supervised
ordinal regression based on the empirical risk minimization principle that is
applicable to optimizing all of the metrics mentioned above. Besides, our
framework has flexible choices of models, surrogate losses, and optimization
algorithms without the common geometric assumption on unlabeled data such as
the cluster assumption or manifold assumption. We further provide an estimation
error bound to show that our risk estimator is consistent. Finally, we conduct
experiments to show the usefulness of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Transport Kernels for Sequential and Parallel Neural Architecture Search. (arXiv:2006.07593v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Vu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Tam Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1">Makoto Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1">Michael A Osborne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07593">
                                    <div class="article-summary-box-inner">
                                        <span>Neural architecture search (NAS) automates the design of deep neural
networks. One of the main challenges in searching complex and non-continuous
architectures is to compare the similarity of networks that the conventional
Euclidean metric may fail to capture. Optimal transport (OT) is resilient to
such complex structure by considering the minimal cost for transporting a
network into another. However, the OT is generally not negative definite which
may limit its ability to build the positive-definite kernels required in many
kernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a
negative definite variant of OT, we develop a novel discrepancy for neural
architectures, and demonstrate it within a Gaussian process surrogate model for
the sequential NAS settings. Furthermore, we derive a novel parallel NAS, using
quality k-determinantal point process on the GP posterior, to select diverse
and high-performing architectures from a discrete set of candidates.
Empirically, we demonstrate that our TW-based approaches outperform other
baselines in both sequential and parallel NAS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Co-occurrence of deep convolutional features for image search. (arXiv:2003.13827v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Forcen_J/0/1/0/all/0/1">J.I.Forcen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagola_M/0/1/0/all/0/1">Miguel Pagola</a>, <a href="http://arxiv.org/find/cs/1/au:+Barrenechea_E/0/1/0/all/0/1">Edurne Barrenechea</a>, <a href="http://arxiv.org/find/cs/1/au:+Bustince_H/0/1/0/all/0/1">Humberto Bustince</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13827">
                                    <div class="article-summary-box-inner">
                                        <span>Image search can be tackled using deep features from pre-trained
Convolutional Neural Networks (CNN). The feature map from the last
convolutional layer of a CNN encodes descriptive information from which a
discriminative global descriptor can be obtained. We propose a new
representation of co-occurrences from deep convolutional features to extract
additional relevant information from this last convolutional layer. Combining
this co-occurrence map with the feature map, we achieve an improved image
representation. We present two different methods to get the co-occurrence
representation, the first one based on direct aggregation of activations, and
the second one, based on a trainable co-occurrence representation. The image
descriptors derived from our methodology improve the performance in very
well-known image retrieval datasets as we prove in the experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PsiPhi-Learning: Reinforcement Learning with Demonstrations using Successor Features and Inverse Temporal Difference Learning. (arXiv:2102.12560v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Filos_A/0/1/0/all/0/1">Angelos Filos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1">Clare Lyle</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaques_N/0/1/0/all/0/1">Natasha Jaques</a>, <a href="http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1">Gregory Farquhar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12560">
                                    <div class="article-summary-box-inner">
                                        <span>We study reinforcement learning (RL) with no-reward demonstrations, a setting
in which an RL agent has access to additional data from the interaction of
other agents with the same environment. However, it has no access to the
rewards or goals of these agents, and their objectives and levels of expertise
may vary widely. These assumptions are common in multi-agent settings, such as
autonomous driving. To effectively use this data, we turn to the framework of
successor features. This allows us to disentangle shared features and dynamics
of the environment from agent-specific rewards and policies. We propose a
multi-task inverse reinforcement learning (IRL) algorithm, called \emph{inverse
temporal difference learning} (ITD), that learns shared state features,
alongside per-agent successor features and preference vectors, purely from
demonstrations without reward labels. We further show how to seamlessly
integrate ITD with learning from online environment interactions, arriving at a
novel algorithm for reinforcement learning with demonstrations, called $\Psi
\Phi$-learning (pronounced &#x60;Sci-Fi&#x27;). We provide empirical evidence for the
effectiveness of $\Psi \Phi$-learning as a method for improving RL, IRL,
imitation, and few-shot transfer, and derive worst-case bounds for its
performance in zero-shot transfer to new tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Specific Transporter Framework to Detect Fractures in Ultrasound. (arXiv:2106.05929v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tripathi_A/0/1/0/all/0/1">Arpan Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rakkunedeth_A/0/1/0/all/0/1">Abhilash Rakkunedeth</a>, <a href="http://arxiv.org/find/cs/1/au:+Panicker_M/0/1/0/all/0/1">Mahesh Raveendranatha Panicker</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jack Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Boora_N/0/1/0/all/0/1">Naveenjyote Boora</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaremko_J/0/1/0/all/0/1">Jacob Jaremko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05929">
                                    <div class="article-summary-box-inner">
                                        <span>Ultrasound examination for detecting fractures is ideally suited for
Emergency Departments (ED) as it is relatively fast, safe (from ionizing
radiation), has dynamic imaging capability and is easily portable. High
interobserver variability in manual assessment of ultrasound scans has piqued
research interest in automatic assessment techniques using Deep Learning (DL).
Most DL techniques are supervised and are trained on large numbers of labeled
data which is expensive and requires many hours of careful annotation by
experts. In this paper, we propose an unsupervised, domain specific transporter
framework to identify relevant keypoints from wrist ultrasound scans. Our
framework provides a concise geometric representation highlighting regions with
high structural variation in a 3D ultrasound (3DUS) sequence. We also
incorporate domain specific information represented by instantaneous local
phase (LP) which detects bone features from 3DUS. We validate the technique on
3DUS videos obtained from 30 subjects. Each ultrasound scan was independently
assessed by three readers to identify fractures along with the corresponding
x-ray. Saliency of keypoints detected in the image\ are compared against manual
assessment based on distance from relevant features.The transporter neural
network was able to accurately detect 180 out of 250 bone regions sampled from
wrist ultrasound videos. We expect this technique to increase the applicability
of ultrasound in fracture detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear-time inference for Gaussian Processes on one dimension. (arXiv:2003.05554v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Loper_J/0/1/0/all/0/1">Jackson Loper</a>, <a href="http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1">David Blei</a>, <a href="http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a>, <a href="http://arxiv.org/find/stat/1/au:+Paninski_L/0/1/0/all/0/1">Liam Paninski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.05554">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian Processes (GPs) provide powerful probabilistic frameworks for
interpolation, forecasting, and smoothing, but have been hampered by
computational scaling issues. Here we investigate data sampled on one dimension
(e.g., a scalar or vector time series sampled at arbitrarily-spaced intervals),
for which state-space models are popular due to their linearly-scaling
computational costs. It has long been conjectured that state-space models are
general, able to approximate any one-dimensional GP. We provide the first
general proof of this conjecture, showing that any stationary GP on one
dimension with vector-valued observations governed by a Lebesgue-integrable
continuous kernel can be approximated to any desired precision using a
specifically-chosen state-space model: the Latent Exponentially Generated (LEG)
family. This new family offers several advantages compared to the general
state-space model: it is always stable (no unbounded growth), the covariance
can be computed in closed form, and its parameter space is unconstrained
(allowing straightforward estimation via gradient descent). The theorem&#x27;s proof
also draws connections to Spectral Mixture Kernels, providing insight about
this popular family of kernels. We develop parallelized algorithms for
performing inference and learning in the LEG model, test the algorithm on real
and synthetic data, and demonstrate scaling to datasets with billions of
samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn your ABCs: Approximate Bijective Correspondence for isolating factors of variation. (arXiv:2103.03240v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1">Kieran A. Murphy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1">Varun Jampani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1">Srikumar Ramalingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Makadia_A/0/1/0/all/0/1">Ameesh Makadia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03240">
                                    <div class="article-summary-box-inner">
                                        <span>Representational learning forms the backbone of most deep learning
applications, and the value of a learned representation is intimately tied to
its information content regarding different factors of variation. Finding good
representations depends on the nature of supervision and the learning
algorithm. We propose a novel algorithm that relies on a weak form of
supervision where the data is partitioned into sets according to certain
inactive factors of variation. Our key insight is that by seeking approximate
correspondence between elements of different sets, we learn strong
representations that exclude the inactive factors of variation and isolate the
active factors which vary within all sets. We demonstrate that the method can
work in a semi-supervised scenario, and that a portion of the unsupervised data
can belong to a different domain entirely. Further control over the content of
the learned representations is possible by folding in data augmentation to
suppress nuisance factors. We outperform competing baselines on the challenging
problem of synthetic-to-real object pose transfer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploration in Approximate Hyper-State Space for Meta Reinforcement Learning. (arXiv:2010.01062v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1">Luisa Zintgraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Leo Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Igl_M/0/1/0/all/0/1">Maximilian Igl</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1">Kristian Hartikainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01062">
                                    <div class="article-summary-box-inner">
                                        <span>To rapidly learn a new task, it is often essential for agents to explore
efficiently -- especially when performance matters from the first timestep. One
way to learn such behaviour is via meta-learning. Many existing methods however
rely on dense rewards for meta-training, and can fail catastrophically if the
rewards are sparse. Without a suitable reward signal, the need for exploration
during meta-training is exacerbated. To address this, we propose HyperX, which
uses novel reward bonuses for meta-training to explore in approximate
hyper-state space (where hyper-states represent the environment state and the
agent&#x27;s task belief). We show empirically that HyperX meta-learns better
task-exploration and adapts more successfully to new tasks than existing
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigation of Uncertainty of Deep Learning-based Object Classification on Radar Spectra. (arXiv:2106.05870v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_K/0/1/0/all/0/1">Kanil Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Beluch_W/0/1/0/all/0/1">William Beluch</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambach_K/0/1/0/all/0/1">Kilian Rambach</a>, <a href="http://arxiv.org/find/cs/1/au:+Cozma_A/0/1/0/all/0/1">Adriana-Eliza Cozma</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfeiffer_M/0/1/0/all/0/1">Michael Pfeiffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05870">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning (DL) has recently attracted increasing interest to improve
object type classification for automotive radar.In addition to high accuracy,
it is crucial for decision making in autonomous vehicles to evaluate the
reliability of the predictions; however, decisions of DL networks are
non-transparent. Current DL research has investigated how uncertainties of
predictions can be quantified, and in this article, we evaluate the potential
of these methods for safe, automotive radar perception. In particular we
evaluate how uncertainty quantification can support radar perception under (1)
domain shift, (2) corruptions of input signals, and (3) in the presence of
unknown objects. We find that in agreement with phenomena observed in the
literature,deep radar classifiers are overly confident, even in their wrong
predictions. This raises concerns about the use of the confidence values for
decision making under uncertainty, as the model fails to notify when it cannot
handle an unknown situation. Accurate confidence values would allow optimal
integration of multiple information sources, e.g. via sensor fusion. We show
that by applying state-of-the-art post-hoc uncertainty calibration, the quality
of confidence measures can be significantly improved,thereby partially
resolving the over-confidence problem. Our investigation shows that further
research into training and calibrating DL networks is necessary and offers
great potential for safe automotive object classification with radar sensors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Distillation for Revenue Optimization: Interpretable Personalized Pricing. (arXiv:2007.01903v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Biggs_M/0/1/0/all/0/1">Max Biggs</a>, <a href="http://arxiv.org/find/stat/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/stat/1/au:+Ettl_M/0/1/0/all/0/1">Markus Ettl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01903">
                                    <div class="article-summary-box-inner">
                                        <span>Data-driven pricing strategies are becoming increasingly common, where
customers are offered a personalized price based on features that are
predictive of their valuation of a product. It is desirable for this pricing
policy to be simple and interpretable, so it can be verified, checked for
fairness, and easily implemented. However, efforts to incorporate machine
learning into a pricing framework often lead to complex pricing policies which
are not interpretable, resulting in slow adoption in practice. We present a
customized, prescriptive tree-based algorithm that distills knowledge from a
complex black-box machine learning algorithm, segments customers with similar
valuations and prescribes prices in such a way that maximizes revenue while
maintaining interpretability. We quantify the regret of a resulting policy and
demonstrate its efficacy in applications with both synthetic and real-world
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Polynomial Approximations for Privacy-Preserving and Verifiable ReLU Networks. (arXiv:2011.05530v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ali_R/0/1/0/all/0/1">Ramy E. Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+So_J/0/1/0/all/0/1">Jinhyun So</a>, <a href="http://arxiv.org/find/cs/1/au:+Avestimehr_A/0/1/0/all/0/1">A. Salman Avestimehr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05530">
                                    <div class="article-summary-box-inner">
                                        <span>Outsourcing neural network inference tasks to an untrusted cloud raises data
privacy and integrity concerns. To address these challenges, several
privacy-preserving and verifiable inference techniques have been proposed based
on replacing the non-polynomial activation functions such as the rectified
linear unit (ReLU) function with polynomial activation functions. Such
techniques usually require polynomials with integer coefficients or polynomials
over finite fields. Motivated by such requirements, several works proposed
replacing the ReLU activation function with the square activation function. In
this work, we empirically show that the square function is not the best
degree-$2$ polynomial that can replace the ReLU function even when restricting
the polynomials to have integer coefficients. We instead propose a degree-$2$
polynomial activation function with a first order term and empirically show
that it can lead to much better models. Our experiments on the CIFAR-$10$ and
CIFAR-$100$ datasets on various architectures show that our proposed activation
function improves the test accuracy by up to $9.4\%$ compared to the square
function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Does Rotation Prediction Tell Us about Classifier Accuracy under Varying Testing Environments?. (arXiv:2106.05961v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1">Weijian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05961">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding classifier decision under novel environments is central to the
community, and a common practice is evaluating it on labeled test sets.
However, in real-world testing, image annotations are difficult and expensive
to obtain, especially when the test environment is changing. A natural question
then arises: given a trained classifier, can we evaluate its accuracy on
varying unlabeled test sets? In this work, we train semantic classification and
rotation prediction in a multi-task way. On a series of datasets, we report an
interesting finding, i.e., the semantic classification accuracy exhibits a
strong linear relationship with the accuracy of the rotation prediction task
(Pearson&#x27;s Correlation r &gt; 0.88). This finding allows us to utilize linear
regression to estimate classifier performance from the accuracy of rotation
prediction which can be obtained on the test set through the freely generated
rotation labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flow-based sampling for fermionic lattice field theories. (arXiv:2106.05934v1 [hep-lat])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-lat/1/au:+Albergo_M/0/1/0/all/0/1">Michael S. Albergo</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1">Gurtej Kanwar</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Racaniere_S/0/1/0/all/0/1">S&#xe9;bastien Racani&#xe8;re</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Rezende_D/0/1/0/all/0/1">Danilo J. Rezende</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Urban_J/0/1/0/all/0/1">Julian M. Urban</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Boyda_D/0/1/0/all/0/1">Denis Boyda</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Cranmer_K/0/1/0/all/0/1">Kyle Cranmer</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Hackett_D/0/1/0/all/0/1">Daniel C. Hackett</a>, <a href="http://arxiv.org/find/hep-lat/1/au:+Shanahan_P/0/1/0/all/0/1">Phiala E. Shanahan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05934">
                                    <div class="article-summary-box-inner">
                                        <span>Algorithms based on normalizing flows are emerging as promising machine
learning approaches to sampling complicated probability distributions in a way
that can be made asymptotically exact. In the context of lattice field theory,
proof-of-principle studies have demonstrated the effectiveness of this approach
for scalar theories, gauge theories, and statistical systems. This work
develops approaches that enable flow-based sampling of theories with dynamical
fermions, which is necessary for the technique to be applied to lattice field
theory studies of the Standard Model of particle physics and many condensed
matter systems. As a practical demonstration, these methods are applied to the
sampling of field configurations for a two-dimensional theory of massless
staggered fermions coupled to a scalar field via a Yukawa interaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample-Efficient L0-L2 Constrained Structure Learning of Sparse Ising Models. (arXiv:2012.01744v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dedieu_A/0/1/0/all/0/1">Antoine Dedieu</a>, <a href="http://arxiv.org/find/stat/1/au:+Lazaro_Gredilla_M/0/1/0/all/0/1">Miguel L&#xe1;zaro-Gredilla</a>, <a href="http://arxiv.org/find/stat/1/au:+George_D/0/1/0/all/0/1">Dileep George</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01744">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning the underlying graph of a sparse Ising
model with $p$ nodes from $n$ i.i.d. samples. The most recent and best
performing approaches combine an empirical loss (the logistic regression loss
or the interaction screening loss) with a regularizer (an L1 penalty or an L1
constraint). This results in a convex problem that can be solved separately for
each node of the graph. In this work, we leverage the cardinality constraint L0
norm, which is known to properly induce sparsity, and further combine it with
an L2 norm to better model the non-zero coefficients. We show that our proposed
estimators achieve an improved sample complexity, both (a) theoretically, by
reaching new state-of-the-art upper bounds for recovery guarantees, and (b)
empirically, by showing sharper phase transitions between poor and full
recovery for graph topologies studied in the literature, when compared to their
L1-based state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Machine Learning Forecasts for the UEFA EURO 2020. (arXiv:2106.05799v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Groll_A/0/1/0/all/0/1">Andreas Groll</a>, <a href="http://arxiv.org/find/cs/1/au:+Hvattum_L/0/1/0/all/0/1">Lars Magnus Hvattum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ley_C/0/1/0/all/0/1">Christophe Ley</a>, <a href="http://arxiv.org/find/cs/1/au:+Popp_F/0/1/0/all/0/1">Franziska Popp</a>, <a href="http://arxiv.org/find/cs/1/au:+Schauberger_G/0/1/0/all/0/1">Gunther Schauberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Eetvelde_H/0/1/0/all/0/1">Hans Van Eetvelde</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeileis_A/0/1/0/all/0/1">Achim Zeileis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05799">
                                    <div class="article-summary-box-inner">
                                        <span>Three state-of-the-art statistical ranking methods for forecasting football
matches are combined with several other predictors in a hybrid machine learning
model. Namely an ability estimate for every team based on historic matches; an
ability estimate for every team based on bookmaker consensus; average
plus-minus player ratings based on their individual performances in their home
clubs and national teams; and further team covariates (e.g., market value, team
structure) and country-specific socio-economic factors (population, GDP). The
proposed combined approach is used for learning the number of goals scored in
the matches from the four previous UEFA EUROs 2004-2016 and then applied to
current information to forecast the upcoming UEFA EURO 2020. Based on the
resulting estimates, the tournament is simulated repeatedly and winning
probabilities are obtained for all teams. A random forest model favors the
current World Champion France with a winning probability of 14.8% before
England (13.5%) and Spain (12.3%). Additionally, we provide survival
probabilities for all teams and at all tournament stages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Attention as Intrinsic Regularization for Bimanual Multi-Object Manipulation. (arXiv:2106.05907v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1">Pingcheng Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05907">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of solving complex bimanual robot manipulation tasks
on multiple objects with sparse rewards. Such complex tasks can be decomposed
into sub-tasks that are accomplishable by different robots concurrently or
sequentially for better efficiency. While previous reinforcement learning
approaches primarily focus on modeling the compositionality of sub-tasks, two
fundamental issues are largely ignored particularly when learning cooperative
strategies for two robots: (i) domination, i.e., one robot may try to solve a
task by itself and leaves the other idle; (ii) conflict, i.e., one robot can
easily interrupt another&#x27;s workspace when executing different sub-tasks
simultaneously. To tackle these two issues, we propose a novel technique called
disentangled attention, which provides an intrinsic regularization for two
robots to focus on separate sub-tasks and objects. We evaluate our method on
four bimanual manipulation tasks. Experimental results show that our proposed
intrinsic regularization successfully avoids domination and reduces conflicts
for the policies, which leads to significantly more effective cooperative
strategies than all the baselines. Our project page with videos is at
https://mehooz.github.io/bimanual-attention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-Free Knowledge Distillation for Heterogeneous Federated Learning. (arXiv:2105.10056v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhuangdi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Junyuan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jiayu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10056">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) is a decentralized machine-learning paradigm, in
which a global server iteratively averages the model parameters of local users
without accessing their data. User heterogeneity has imposed significant
challenges to FL, which can incur drifted global models that are slow to
converge. Knowledge Distillation has recently emerged to tackle this issue, by
refining the server model using aggregated knowledge from heterogeneous users,
other than directly averaging their model parameters. This approach, however,
depends on a proxy dataset, making it impractical unless such a prerequisite is
satisfied. Moreover, the ensemble knowledge is not fully utilized to guide
local model learning, which may in turn affect the quality of the aggregated
model. Inspired by the prior art, we propose a data-free knowledge
distillation} approach to address heterogeneous FL, where the server learns a
lightweight generator to ensemble user information in a data-free manner, which
is then broadcasted to users, regulating local training using the learned
knowledge as an inductive bias. Empirical studies powered by theoretical
implications show that, our approach facilitates FL with better generalization
performance using fewer communication rounds, compared with the
state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemSegLoss: A python package of loss functions for semantic segmentation. (arXiv:2106.05844v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jadon_S/0/1/0/all/0/1">Shruti Jadon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05844">
                                    <div class="article-summary-box-inner">
                                        <span>Image Segmentation has been an active field of research as it has a wide
range of applications, ranging from automated disease detection to self-driving
cars. In recent years, various research papers proposed different loss
functions used in case of biased data, sparse segmentation, and unbalanced
dataset. In this paper, we introduce SemSegLoss, a python package consisting of
some of the well-known loss functions widely used for image segmentation. It is
developed with the intent to help researchers in the development of novel loss
functions and perform an extensive set of experiments on model architectures
for various applications. The ease-of-use and flexibility of the presented
package have allowed reducing the development time and increased evaluation
strategies of machine learning models for semantic segmentation. Furthermore,
different applications that use image segmentation can use SemSegLoss because
of the generality of its functions. This wide range of applications will lead
to the development and growth of AI across all industries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">State Entropy Maximization with Random Encoders for Efficient Exploration. (arXiv:2102.09430v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_Y/0/1/0/all/0/1">Younggyo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09430">
                                    <div class="article-summary-box-inner">
                                        <span>Recent exploration methods have proven to be a recipe for improving
sample-efficiency in deep reinforcement learning (RL). However, efficient
exploration in high-dimensional observation spaces still remains a challenge.
This paper presents Random Encoders for Efficient Exploration (RE3), an
exploration method that utilizes state entropy as an intrinsic reward. In order
to estimate state entropy in environments with high-dimensional observations,
we utilize a k-nearest neighbor entropy estimator in the low-dimensional
representation space of a convolutional encoder. In particular, we find that
the state entropy can be estimated in a stable and compute-efficient manner by
utilizing a randomly initialized encoder, which is fixed throughout training.
Our experiments show that RE3 significantly improves the sample-efficiency of
both model-free and model-based RL methods on locomotion and navigation tasks
from DeepMind Control Suite and MiniGrid benchmarks. We also show that RE3
allows learning diverse behaviors without extrinsic rewards, effectively
improving sample-efficiency in downstream tasks. Source code and videos are
available at https://sites.google.com/view/re3-rl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A concise method for feature selection via normalized frequencies. (arXiv:2106.05814v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Song Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xia He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05814">
                                    <div class="article-summary-box-inner">
                                        <span>Feature selection is an important part of building a machine learning model.
By eliminating redundant or misleading features from data, the machine learning
model can achieve better performance while reducing the demand on com-puting
resources. Metaheuristic algorithms are mostly used to implement feature
selection such as swarm intelligence algorithms and evolutionary algorithms.
However, they suffer from the disadvantage of relative complexity and slowness.
In this paper, a concise method is proposed for universal feature selection.
The proposed method uses a fusion of the filter method and the wrapper method,
rather than a combination of them. In the method, one-hoting encoding is used
to preprocess the dataset, and random forest is utilized as the classifier. The
proposed method uses normalized frequencies to assign a value to each feature,
which will be used to find the optimal feature subset. Furthermore, we propose
a novel approach to exploit the outputs of mutual information, which allows for
a better starting point for the experiments. Two real-world dataset in the
field of intrusion detection were used to evaluate the proposed method. The
evaluation results show that the proposed method outperformed several
state-of-the-art related works in terms of accuracy, precision, recall, F-score
and AUC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DMIDAS: Deep Mixed Data Sampling Regression for Long Multi-Horizon Time Series Forecasting. (arXiv:2106.05860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Challu_C/0/1/0/all/0/1">Cristian Challu</a>, <a href="http://arxiv.org/find/cs/1/au:+Olivares_K/0/1/0/all/0/1">Kin G. Olivares</a>, <a href="http://arxiv.org/find/cs/1/au:+Welter_G/0/1/0/all/0/1">Gus Welter</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1">Artur Dubrawski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05860">
                                    <div class="article-summary-box-inner">
                                        <span>Neural forecasting has shown significant improvements in the accuracy of
large-scale systems, yet predicting extremely long horizons remains a
challenging task. Two common problems are the volatility of the predictions and
their computational complexity; we addressed them by incorporating smoothness
regularization and mixed data sampling techniques to a well-performing
multi-layer perceptron based architecture (NBEATS). We validate our proposed
method, DMIDAS, on high-frequency healthcare and electricity price data with
long forecasting horizons (~1000 timestamps) where we improve the prediction
accuracy by 5% over state-of-the-art models, reducing the number of parameters
of NBEATS by nearly 70%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Backdoor Smoothing: Demystifying Backdoor Attacks on Deep Neural Networks. (arXiv:2006.06721v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1">Kathrin Grosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1">Taesung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1">Youngja Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1">Michael Backes</a>, <a href="http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1">Ian Molloy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06721">
                                    <div class="article-summary-box-inner">
                                        <span>Backdoor attacks aim to mislead machine-learning models to output an
attacker-specified class when presented a specific trigger at test time. These
attacks require poisoning the training data or compromising the learning
algorithm, e.g., by injecting poisoning samples containing the trigger into the
training set, along with the desired class label. Despite the increasing number
of studies on backdoor attacks and defenses, the underlying factors affecting
the success of backdoor attacks, along with their impact on the learning
algorithm, are not yet well understood. In this work, we aim to shed light on
this issue. In particular, we unveil that backdoor attacks work by inducing a
smoother decision function around the triggered samples -- a phenomenon which
we refer to as \textit{backdoor smoothing}. We quantify backdoor smoothing by
defining a measure that evaluates the uncertainty associated to the predictions
of a classifier around the input samples.

Our experiments show that smoothness increases when the trigger is added to
the input samples, and that the phenomenon is more pronounced for more
successful attacks.

However, our experiments also show that patterns fulfilling backdoor
smoothing can be crafted

even without poisoning the training data.

Although our measure may not be directly exploited as a defense mechanism, it
unveils an important phenomenon which may pave the way towards understanding
the limitations of current defenses that rely on a smooth decision output for
backdoors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rare event estimation using stochastic spectral embedding. (arXiv:2106.05824v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wagner_P/0/1/0/all/0/1">P.-R. Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Marelli_S/0/1/0/all/0/1">S. Marelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Papaioannou_I/0/1/0/all/0/1">I. Papaioannou</a>, <a href="http://arxiv.org/find/cs/1/au:+Straub_D/0/1/0/all/0/1">D. Straub</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudret_B/0/1/0/all/0/1">B. Sudret</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05824">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating the probability of rare failure events is an essential step in the
reliability assessment of engineering systems. Computing this failure
probability for complex non-linear systems is challenging, and has recently
spurred the development of active-learning reliability methods. These methods
approximate the limit-state function (LSF) using surrogate models trained with
a sequentially enriched set of model evaluations. A recently proposed method
called stochastic spectral embedding (SSE) aims to improve the local
approximation accuracy of global, spectral surrogate modelling techniques by
sequentially embedding local residual expansions in subdomains of the input
space. In this work we apply SSE to the LSF, giving rise to a stochastic
spectral embedding-based reliability (SSER) method. The resulting partition of
the input space decomposes the failure probability into a set of
easy-to-compute domain-wise failure probabilities. We propose a set of
modifications that tailor the algorithm to efficiently solve rare event
estimation problems. These modifications include specialized refinement domain
selection, partitioning and enrichment strategies. We showcase the algorithm
performance on four benchmark problems of various dimensionality and complexity
in the LSF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning by Watching. (arXiv:2106.05966v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jimuyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1">Eshed Ohn-Bar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05966">
                                    <div class="article-summary-box-inner">
                                        <span>When in a new situation or geographical location, human drivers have an
extraordinary ability to watch others and learn maneuvers that they themselves
may have never performed. In contrast, existing techniques for learning to
drive preclude such a possibility as they assume direct access to an
instrumented ego-vehicle with fully known observations and expert driver
actions. However, such measurements cannot be directly accessed for the non-ego
vehicles when learning by watching others. Therefore, in an application where
data is regarded as a highly valuable asset, current approaches completely
discard the vast portion of the training data that can be potentially obtained
through indirect observation of surrounding vehicles. Motivated by this key
insight, we propose the Learning by Watching (LbW) framework which enables
learning a driving policy without requiring full knowledge of neither the state
nor expert actions. To increase its data, i.e., with new perspectives and
maneuvers, LbW makes use of the demonstrations of other vehicles in a given
scene by (1) transforming the ego-vehicle&#x27;s observations to their points of
view, and (2) inferring their expert actions. Our LbW agent learns more robust
driving policies while enabling data-efficient learning, including quick
adaptation of the policy to rare and novel scenarios. In particular, LbW drives
robustly even with a fraction of available driving data required by existing
methods, achieving an average success rate of 92% on the original CARLA
benchmark with only 30 minutes of total driving data and 82% with only 10
minutes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MC-LSTM: Mass-Conserving LSTM. (arXiv:2101.05186v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hoedt_P/0/1/0/all/0/1">Pieter-Jan Hoedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kratzert_F/0/1/0/all/0/1">Frederik Kratzert</a>, <a href="http://arxiv.org/find/cs/1/au:+Klotz_D/0/1/0/all/0/1">Daniel Klotz</a>, <a href="http://arxiv.org/find/cs/1/au:+Halmich_C/0/1/0/all/0/1">Christina Halmich</a>, <a href="http://arxiv.org/find/cs/1/au:+Holzleitner_M/0/1/0/all/0/1">Markus Holzleitner</a>, <a href="http://arxiv.org/find/cs/1/au:+Nearing_G/0/1/0/all/0/1">Grey Nearing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1">Sepp Hochreiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1">G&#xfc;nter Klambauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05186">
                                    <div class="article-summary-box-inner">
                                        <span>The success of Convolutional Neural Networks (CNNs) in computer vision is
mainly driven by their strong inductive bias, which is strong enough to allow
CNNs to solve vision-related tasks with random weights, meaning without
learning. Similarly, Long Short-Term Memory (LSTM) has a strong inductive bias
towards storing information over time. However, many real-world systems are
governed by conservation laws, which lead to the redistribution of particular
quantities -- e.g. in physical and economical systems. Our novel
Mass-Conserving LSTM (MC-LSTM) adheres to these conservation laws by extending
the inductive bias of LSTM to model the redistribution of those stored
quantities. MC-LSTMs set a new state-of-the-art for neural arithmetic units at
learning arithmetic operations, such as addition tasks, which have a strong
conservation law, as the sum is constant over time. Further, MC-LSTM is applied
to traffic forecasting, modelling a pendulum, and a large benchmark dataset in
hydrology, where it sets a new state-of-the-art for predicting peak flows. In
the hydrology example, we show that MC-LSTM states correlate with real-world
processes and are therefore interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MolGrow: A Graph Normalizing Flow for Hierarchical Molecular Generation. (arXiv:2106.05856v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Kuznetsov_M/0/1/0/all/0/1">Maksim Kuznetsov</a>, <a href="http://arxiv.org/find/physics/1/au:+Polykovskiy_D/0/1/0/all/0/1">Daniil Polykovskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05856">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a hierarchical normalizing flow model for generating molecular
graphs. The model produces new molecular structures from a single-node graph by
recursively splitting every node into two. All operations are invertible and
can be used as plug-and-play modules. The hierarchical nature of the latent
codes allows for precise changes in the resulting graph: perturbations in the
top layer cause global structural changes, while perturbations in the
consequent layers change the resulting molecule marginally. The proposed model
outperforms existing generative graph models on the distribution learning task.
We also show successful experiments on global and constrained optimization of
chemical properties using latent codes of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-Optimal High Probability Complexity Bounds for Non-Smooth Stochastic Optimization with Heavy-Tailed Noise. (arXiv:2106.05958v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gorbunov_E/0/1/0/all/0/1">Eduard Gorbunov</a>, <a href="http://arxiv.org/find/math/1/au:+Danilova_M/0/1/0/all/0/1">Marina Danilova</a>, <a href="http://arxiv.org/find/math/1/au:+Shibaev_I/0/1/0/all/0/1">Innokentiy Shibaev</a>, <a href="http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1">Pavel Dvurechensky</a>, <a href="http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1">Alexander Gasnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05958">
                                    <div class="article-summary-box-inner">
                                        <span>Thanks to their practical efficiency and random nature of the data,
stochastic first-order methods are standard for training large-scale machine
learning models. Random behavior may cause a particular run of an algorithm to
result in a highly suboptimal objective value, whereas theoretical guarantees
are usually proved for the expectation of the objective value. Thus, it is
essential to theoretically guarantee that algorithms provide small objective
residual with high probability. Existing methods for non-smooth stochastic
convex optimization have complexity bounds with the dependence on the
confidence level that is either negative-power or logarithmic but under an
additional assumption of sub-Gaussian (light-tailed) noise distribution that
may not hold in practice, e.g., in several NLP tasks. In our paper, we resolve
this issue and derive the first high-probability convergence results with
logarithmic dependence on the confidence level for non-smooth convex stochastic
optimization problems with non-sub-Gaussian (heavy-tailed) noise. To derive our
results, we propose novel stepsize rules for two stochastic methods with
gradient clipping. Moreover, our analysis works for generalized smooth
objectives with H\&quot;older-continuous gradients, and for both methods, we provide
an extension for strongly convex problems. Finally, our results imply that the
first (accelerated) method we consider also has optimal iteration and oracle
complexity in all the regimes, and the second one is optimal in the non-smooth
setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group Equivariant Subsampling. (arXiv:2106.05886v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunjik Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05886">
                                    <div class="article-summary-box-inner">
                                        <span>Subsampling is used in convolutional neural networks (CNNs) in the form of
pooling or strided convolutions, to reduce the spatial dimensions of feature
maps and to allow the receptive fields to grow exponentially with depth.
However, it is known that such subsampling operations are not translation
equivariant, unlike convolutions that are translation equivariant. Here, we
first introduce translation equivariant subsampling/upsampling layers that can
be used to construct exact translation equivariant CNNs. We then generalise
these layers beyond translations to general groups, thus proposing group
equivariant subsampling/upsampling. We use these layers to construct group
equivariant autoencoders (GAEs) that allow us to learn low-dimensional
equivariant representations. We empirically verify on images that the
representations are indeed equivariant to input translations and rotations, and
thus generalise well to unseen positions and orientations. We further use GAEs
in models that learn object-centric representations on multi-object datasets,
and show improved data efficiency and decomposition compared to non-equivariant
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepVideoMVS: Multi-View Stereo on Video with Recurrent Spatio-Temporal Fusion. (arXiv:2012.02177v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duzceker_A/0/1/0/all/0/1">Arda D&#xfc;z&#xe7;eker</a>, <a href="http://arxiv.org/find/cs/1/au:+Galliani_S/0/1/0/all/0/1">Silvano Galliani</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogel_C/0/1/0/all/0/1">Christoph Vogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Speciale_P/0/1/0/all/0/1">Pablo Speciale</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusmanu_M/0/1/0/all/0/1">Mihai Dusmanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02177">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an online multi-view depth prediction approach on posed video
streams, where the scene geometry information computed in the previous time
steps is propagated to the current time step in an efficient and geometrically
plausible way. The backbone of our approach is a real-time capable, lightweight
encoder-decoder that relies on cost volumes computed from pairs of images. We
extend it by placing a ConvLSTM cell at the bottleneck layer, which compresses
an arbitrary amount of past information in its states. The novelty lies in
propagating the hidden state of the cell by accounting for the viewpoint
changes between time steps. At a given time step, we warp the previous hidden
state into the current camera plane using the previous depth prediction. Our
extension brings only a small overhead of computation time and memory
consumption, while improving the depth predictions significantly. As a result,
we outperform the existing state-of-the-art multi-view stereo methods on most
of the evaluated metrics in hundreds of indoor scenes while maintaining a
real-time performance. Code available:
https://github.com/ardaduz/deep-video-mvs</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evolving Robust Neural Architectures to Defend from Adversarial Attacks. (arXiv:1906.11667v3 [cs.NE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1">Shashank Kotyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1">Danilo Vasconcellos Vargas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.11667">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are prone to misclassify slightly modified input images.
Recently, many defences have been proposed, but none have improved the
robustness of neural networks consistently. Here, we propose to use adversarial
attacks as a function evaluation to search for neural architectures that can
resist such attacks automatically. Experiments on neural architecture search
algorithms from the literature show that although accurate, they are not able
to find robust architectures. A significant reason for this lies in their
limited search space. By creating a novel neural architecture search with
options for dense layers to connect with convolution layers and vice-versa as
well as the addition of concatenation layers in the search, we were able to
evolve an architecture that is inherently accurate on adversarial samples.
Interestingly, this inherent robustness of the evolved architecture rivals
state-of-the-art defences such as adversarial training while being trained only
on the non-adversarial samples. Moreover, the evolved architecture makes use of
some peculiar traits which might be useful for developing even more robust
ones. Thus, the results here confirm that more robust architectures exist as
well as opens up a new realm of feasibilities for the development and
exploration of neural networks.

Code available at this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Raman spectral analysis of mixtures with one-dimensional convolutional neural network. (arXiv:2106.05316v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mozaffari_M/0/1/0/all/0/1">M. Hamed Mozaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Tay_L/0/1/0/all/0/1">Li-Lin Tay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05316">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the combination of robust one-dimensional convolutional neural
networks (1-D CNNs) and Raman spectroscopy has shown great promise in rapid
identification of unknown substances with good accuracy. Using this technique,
researchers can recognize a pure compound and distinguish it from unknown
substances in a mixture. The novelty of this approach is that the trained
neural network operates automatically without any pre- or post-processing of
data. Some studies have attempted to extend this technique to the
classification of pure compounds in an unknown mixture. However, the
application of 1-D CNNs has typically been restricted to binary classifications
of pure compounds. Here we will highlight a new approach in spectral
recognition and quantification of chemical components in a multicomponent
mixture. Two 1-D CNN models, RaMixNet I and II, have been developed for this
purpose. The former is for rapid classification of components in a mixture
while the latter is for quantitative determination of those constituents. In
the proposed method, there is no limit to the number of compounds in a mixture.
A data augmentation method is also introduced by adding random baselines to the
Raman spectra. The experimental results revealed that the classification
accuracy of RaMixNet I and II is 100% for analysis of unknown test mixtures; at
the same time, the RaMixNet II model may achieve a regression accuracy of 88%
for the quantification of each component.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network Space Search for Pareto-Efficient Spaces. (arXiv:2104.11014v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1">Min-Fong Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao-Yun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Min-Hung Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yu-Syuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_H/0/1/0/all/0/1">Hsien-Kai Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yi-Min Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hung-Jen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1">Kevin Jou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11014">
                                    <div class="article-summary-box-inner">
                                        <span>Network spaces have been known as a critical factor in both handcrafted
network designs or defining search spaces for Neural Architecture Search (NAS).
However, an effective space involves tremendous prior knowledge and/or manual
effort, and additional constraints are required to discover efficiency-aware
architectures. In this paper, we define a new problem, Network Space Search
(NSS), as searching for favorable network spaces instead of a single
architecture. We propose an NSS method to directly search for efficient-aware
network spaces automatically, reducing the manual effort and immense cost in
discovering satisfactory ones. The resultant network spaces, named Elite
Spaces, are discovered from Expanded Search Space with minimal human expertise
imposed. The Pareto-efficient Elite Spaces are aligned with the Pareto front
under various complexity constraints and can be further served as NAS search
spaces, benefiting differentiable NAS approaches (e.g. In CIFAR-100, an
averagely 2.3% lower error rate and 3.7% closer to target constraint than the
baseline with around 90% fewer samples required to find satisfactory networks).
Moreover, our NSS approach is capable of searching for superior spaces in
future unexplored spaces, revealing great potential in searching for network
spaces automatically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent. (arXiv:2102.05855v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chourasia_R/0/1/0/all/0/1">Rishav Chourasia</a>, <a href="http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1">Jiayuan Ye</a>, <a href="http://arxiv.org/find/stat/1/au:+Shokri_R/0/1/0/all/0/1">Reza Shokri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05855">
                                    <div class="article-summary-box-inner">
                                        <span>What is the information leakage of an iterative learning algorithm about its
training data, when the internal state of the algorithm is \emph{not}
observable? How much is the contribution of each specific training epoch to the
final leakage? We study this problem for noisy gradient descent algorithms, and
model the \emph{dynamics} of R\&#x27;enyi differential privacy loss throughout the
training process. Our analysis traces a provably tight bound on the R\&#x27;enyi
divergence between the pair of probability distributions over parameters of
models with neighboring datasets. We prove that the privacy loss converges
exponentially fast, for smooth and strongly convex loss functions, which is a
significant improvement over composition theorems. For Lipschitz, smooth, and
strongly convex loss functions, we prove optimal utility for differential
privacy algorithms with a small gradient complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Explanations for Private Support Vector Machines. (arXiv:2102.03785v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mochaourab_R/0/1/0/all/0/1">Rami Mochaourab</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1">Sugandh Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenstein_S/0/1/0/all/0/1">Stanley Greenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Papapetrou_P/0/1/0/all/0/1">Panagiotis Papapetrou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03785">
                                    <div class="article-summary-box-inner">
                                        <span>We consider counterfactual explanations for private support vector machines
(SVM), where the privacy mechanism that publicly releases the classifier
guarantees differential privacy. While privacy preservation is essential when
dealing with sensitive data, there is a consequent degradation in the
classification accuracy due to the introduced perturbations in the classifier
weights. For such classifiers, counterfactual explanations need to be robust
against the uncertainties in the SVM weights in order to ensure, with high
confidence, that the classification of the data instance to be explained is
different than its explanation. We model the uncertainties in the SVM weights
through a random vector, and formulate the explanation problem as an
optimization problem with probabilistic constraint. Subsequently, we
characterize the problem&#x27;s deterministic equivalent and study its solution. For
linear SVMs, the problem is a convex second-order cone program. For non-linear
SVMs, the problem is non-convex. Thus, we propose a sub-optimal solution that
is based on the bisection method. The results show that, contrary to non-robust
explanations, the quality of explanations from the robust solution degrades
with increasing privacy in order to guarantee a prespecified confidence level
for correct classifications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deciphering Implicit Hate: Evaluating Automated Detection Algorithms for Multimodal Hate. (arXiv:2106.05903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Botelho_A/0/1/0/all/0/1">Austin Botelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertie Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05903">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate detection and classification of online hate is a difficult task.
Implicit hate is particularly challenging as such content tends to have unusual
syntax, polysemic words, and fewer markers of prejudice (e.g., slurs). This
problem is heightened with multimodal content, such as memes (combinations of
text and images), as they are often harder to decipher than unimodal content
(e.g., text alone). This paper evaluates the role of semantic and multimodal
context for detecting implicit and explicit hate. We show that both text- and
visual- enrichment improves model performance, with the multimodal model
(0.771) outperforming other models&#x27; F1 scores (0.544, 0.737, and 0.754). While
the unimodal-text context-aware (transformer) model was the most accurate on
the subtask of implicit hate detection, the multimodal model outperformed it
overall because of a lower propensity towards false positives. We find that all
models perform better on content with full annotator agreement and that
multimodal models are best at classifying the content where annotators
disagree. To conduct these investigations, we undertook high-quality annotation
of a sample of 5,000 multimodal entries. Tweets were annotated for primary
category, modality, and strategy. We make this corpus, along with the codebook,
code, and final model, freely available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shift Invariance Can Reduce Adversarial Robustness. (arXiv:2103.02695v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1">Songwei Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_V/0/1/0/all/0/1">Vasu Singla</a>, <a href="http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1">Ronen Basri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobs_D/0/1/0/all/0/1">David Jacobs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02695">
                                    <div class="article-summary-box-inner">
                                        <span>Shift invariance is a critical property of CNNs that improves performance on
classification. However, we show that invariance to circular shifts can also
lead to greater sensitivity to adversarial attacks. We first characterize the
margin between classes when a shift-invariant linear classifier is used. We
show that the margin can only depend on the DC component of the signals. Then,
using results about infinitely wide networks, we show that in some simple
cases, fully connected and shift-invariant neural networks produce linear
decision boundaries. Using this, we prove that shift invariance in neural
networks produces adversarial examples for the simple case of two classes, each
consisting of a single image with a black or white dot on a gray background.
This is more than a curiosity; we show empirically that with real datasets and
realistic architectures, shift invariance reduces adversarial robustness.
Finally, we describe initial experiments using synthetic data to probe the
source of this connection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Orientation Estimation Using Inertial Sensors with Performance Guarantee. (arXiv:2103.02357v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Liang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yujie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhipeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Wei Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02357">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a deep reinforcement learning (DRL) algorithm for
orientation estimation using inertial sensors combined with magnetometer. The
Lyapunov method in control theory is employed to prove the convergence of
orientation estimation errors. Based on the theoretical results, the estimator
gains and a Lyapunov function are parametrized by deep neural networks and
learned from samples. The DRL estimator is compared with three well-known
orientation estimation methods on both numerical simulations and real datasets
collected from commercially available sensors. The results show that the
proposed algorithm is superior for arbitrary estimation initialization and can
adapt to very large angular velocities for which other algorithms can be hardly
applicable. To the best of our knowledge, this is the first DRL-based
orientation estimation method with estimation error boundedness guarantee.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Normalizing Flows. (arXiv:2106.05937v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1">Mislav Balunovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruoss_A/0/1/0/all/0/1">Anian Ruoss</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05937">
                                    <div class="article-summary-box-inner">
                                        <span>Fair representation learning is an attractive approach that promises fairness
of downstream predictors by encoding sensitive data. Unfortunately, recent work
has shown that strong adversarial predictors can still exhibit unfairness by
recovering sensitive attributes from these representations. In this work, we
present Fair Normalizing Flows (FNF), a new approach offering more rigorous
fairness guarantees for learned representations. Specifically, we consider a
practical setting where we can estimate the probability density for sensitive
groups. The key idea is to model the encoder as a normalizing flow trained to
minimize the statistical distance between the latent representations of
different groups. The main advantage of FNF is that its exact likelihood
computation allows us to obtain guarantees on the maximum unfairness of any
potentially adversarial downstream predictor. We experimentally demonstrate the
effectiveness of FNF in enforcing various group fairness notions, as well as
other attractive properties such as interpretability and transfer learning, on
a variety of challenging real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Reusable Knowledge for Continual Learning via Metalearning. (arXiv:2106.05390v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hurtado_J/0/1/0/all/0/1">Julio Hurtado</a>, <a href="http://arxiv.org/find/cs/1/au:+Raymond_Saez_A/0/1/0/all/0/1">Alain Raymond-Saez</a>, <a href="http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1">Alvaro Soto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05390">
                                    <div class="article-summary-box-inner">
                                        <span>When learning tasks over time, artificial neural networks suffer from a
problem known as Catastrophic Forgetting (CF). This happens when the weights of
a network are overwritten during the training of a new task causing forgetting
of old information. To address this issue, we propose MetA Reusable Knowledge
or MARK, a new method that fosters weight reusability instead of overwriting
when learning a new task. Specifically, MARK keeps a set of shared weights
among tasks. We envision these shared weights as a common Knowledge Base (KB)
that is not only used to learn new tasks, but also enriched with new knowledge
as the model learns new tasks. Key components behind MARK are two-fold. On the
one hand, a metalearning approach provides the key mechanism to incrementally
enrich the KB with new knowledge and to foster weight reusability among tasks.
On the other hand, a set of trainable masks provides the key mechanism to
selectively choose from the KB relevant weights to solve each task. By using
MARK, we achieve state of the art results in several popular benchmarks,
surpassing the best performing methods in terms of average accuracy by over 10%
on the 20-Split-MiniImageNet dataset, while achieving almost zero forgetfulness
using 55% of the number of parameters. Furthermore, an ablation study provides
evidence that, indeed, MARK is learning reusable knowledge that is selectively
used by each task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early-stopped neural networks are consistent. (arXiv:2106.05932v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1">Ziwei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Justin D. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1">Matus Telgarsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05932">
                                    <div class="article-summary-box-inner">
                                        <span>This work studies the behavior of neural networks trained with the logistic
loss via gradient descent on binary classification data where the underlying
data distribution is general, and the (optimal) Bayes risk is not necessarily
zero. In this setting, it is shown that gradient descent with early stopping
achieves population risk arbitrarily close to optimal in terms of not just
logistic and misclassification losses, but also in terms of calibration,
meaning the sigmoid mapping of its outputs approximates the true underlying
conditional distribution arbitrarily finely. Moreover, the necessary iteration,
sample, and architectural complexities of this analysis all scale naturally
with a certain complexity measure of the true conditional model. Lastly, while
it is not shown that early stopping is necessary, it is shown that any
univariate classifier satisfying a local interpolation property is necessarily
inconsistent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data. (arXiv:2101.07597v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yao Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumatani_K/0/1/0/all/0/1">Kenichi Kumatani</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shujie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Michael Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuedong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07597">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a unified pre-training approach called UniSpeech to
learn speech representations with both unlabeled and labeled data, in which
supervised phonetic CTC learning and phonetically-aware contrastive
self-supervised learning are conducted in a multi-task learning manner. The
resultant representations can capture information more correlated with phonetic
structures and improve the generalization across languages and domains. We
evaluate the effectiveness of UniSpeech for cross-lingual representation
learning on public CommonVoice corpus. The results show that UniSpeech
outperforms self-supervised pretraining and supervised transfer learning for
speech recognition by a maximum of 13.4% and 17.8% relative phone error rate
reductions respectively (averaged over all testing languages). The
transferability of UniSpeech is also demonstrated on a domain-shift speech
recognition task, i.e., a relative word error rate reduction of 6% against the
previous approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Think Global and Act Local: Bayesian Optimisation over High-Dimensional Categorical and Mixed Search Spaces. (arXiv:2102.07188v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1">Xingchen Wan</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_V/0/1/0/all/0/1">Vu Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Ha_H/0/1/0/all/0/1">Huong Ha</a>, <a href="http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1">Binxin Ru</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_C/0/1/0/all/0/1">Cong Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Osborne_M/0/1/0/all/0/1">Michael A. Osborne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07188">
                                    <div class="article-summary-box-inner">
                                        <span>High-dimensional black-box optimisation remains an important yet notoriously
challenging problem. Despite the success of Bayesian optimisation methods on
continuous domains, domains that are categorical, or that mix continuous and
categorical variables, remain challenging. We propose a novel solution -- we
combine local optimisation with a tailored kernel design, effectively handling
high-dimensional categorical and mixed search spaces, whilst retaining sample
efficiency. We further derive convergence guarantee for the proposed approach.
Finally, we demonstrate empirically that our method outperforms the current
baselines on a variety of synthetic and real-world tasks in terms of
performance, computational costs, or both.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Probabilistic Time Series Forecasting using Augmented Recurrent Input for Dynamic Systems. (arXiv:2106.05848v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haitao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Changjun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaomo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xudong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuhua Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaofang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05848">
                                    <div class="article-summary-box-inner">
                                        <span>The demand of probabilistic time series forecasting has been recently raised
in various dynamic system scenarios, for example, system identification and
prognostic and health management of machines. To this end, we combine the
advances in both deep generative models and state space model (SSM) to come up
with a novel, data-driven deep probabilistic sequence model. Specially, we
follow the popular encoder-decoder generative structure to build the recurrent
neural networks (RNN) assisted variational sequence model on an augmented
recurrent input space, which could induce rich stochastic sequence dependency.
Besides, in order to alleviate the issue of inconsistency between training and
predicting as well as improving the mining of dynamic patterns, we (i) propose
using a hybrid output as input at next time step, which brings training and
predicting into alignment; and (ii) further devise a generalized
auto-regressive strategy that encodes all the historical dependencies at
current time step. Thereafter, we first investigate the methodological
characteristics of the proposed deep probabilistic sequence model on toy cases,
and then comprehensively demonstrate the superiority of our model against
existing deep probabilistic SSM models through extensive numerical experiments
on eight system identification benchmarks from various dynamic systems.
Finally, we apply our sequence model to a real-world centrifugal compressor
sensor data forecasting problem, and again verify its outstanding performance
by quantifying the time series predictive distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conic Blackwell Algorithm: Parameter-Free Convex-Concave Saddle-Point Solving. (arXiv:2105.13203v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grand_Clement_J/0/1/0/all/0/1">Julien Grand-Cl&#xe9;ment</a>, <a href="http://arxiv.org/find/cs/1/au:+Kroer_C/0/1/0/all/0/1">Christian Kroer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13203">
                                    <div class="article-summary-box-inner">
                                        <span>We develop new parameter and scale-free algorithms for solving convex-concave
saddle-point problems. Our results are based on a new simple regret minimizer,
the Conic Blackwell Algorithm$^+$ (CBA$^+$), which attains $O(1/\sqrt{T})$
average regret. Intuitively, our approach generalizes to other decision sets of
interest ideas from the Counterfactual Regret minimization (CFR$^+$) algorithm,
which has very strong practical performance for solving sequential games on
simplexes. We show how to implement CBA$^+$ for the simplex, $\ell_{p}$ norm
balls, and ellipsoidal confidence regions in the simplex, and we present
numerical experiments for solving matrix games and distributionally robust
optimization problems. Our empirical results show that CBA$^+$ is a simple
algorithm that outperforms state-of-the-art methods on synthetic data and real
data instances, without the need for any choice of step sizes or other
algorithmic parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GroupBERT: Enhanced Transformer Architecture with Efficient Grouped Structures. (arXiv:2106.05822v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chelombiev_I/0/1/0/all/0/1">Ivan Chelombiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Justus_D/0/1/0/all/0/1">Daniel Justus</a>, <a href="http://arxiv.org/find/cs/1/au:+Orr_D/0/1/0/all/0/1">Douglas Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dietrich_A/0/1/0/all/0/1">Anastasia Dietrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gressmann_F/0/1/0/all/0/1">Frithjof Gressmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Koliousis_A/0/1/0/all/0/1">Alexandros Koliousis</a>, <a href="http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1">Carlo Luschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05822">
                                    <div class="article-summary-box-inner">
                                        <span>Attention based language models have become a critical component in
state-of-the-art natural language processing systems. However, these models
have significant computational requirements, due to long training times, dense
operations and large parameter count. In this work we demonstrate a set of
modifications to the structure of a Transformer layer, producing a more
efficient architecture. First, we add a convolutional module to complement the
self-attention module, decoupling the learning of local and global
interactions. Secondly, we rely on grouped transformations to reduce the
computational cost of dense feed-forward layers and convolutions, while
preserving the expressivity of the model. We apply the resulting architecture
to language representation learning and demonstrate its superior performance
compared to BERT models of different scales. We further highlight its improved
efficiency, both in terms of floating-point operations (FLOPs) and
time-to-train.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the overlooked issue of defining explanation objectives for local-surrogate explainers. (arXiv:2106.05810v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poyiadzi_R/0/1/0/all/0/1">Rafael Poyiadzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Renard_X/0/1/0/all/0/1">Xavier Renard</a>, <a href="http://arxiv.org/find/cs/1/au:+Laugel_T/0/1/0/all/0/1">Thibault Laugel</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1">Raul Santos-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Detyniecki_M/0/1/0/all/0/1">Marcin Detyniecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05810">
                                    <div class="article-summary-box-inner">
                                        <span>Local surrogate approaches for explaining machine learning model predictions
have appealing properties, such as being model-agnostic and flexible in their
modelling. Several methods exist that fit this description and share this goal.
However, despite their shared overall procedure, they set out different
objectives, extract different information from the black-box, and consequently
produce diverse explanations, that are -- in general -- incomparable. In this
work we review the similarities and differences amongst multiple methods, with
a particular focus on what information they extract from the model, as this has
large impact on the output: the explanation. We discuss the implications of the
lack of agreement, and clarity, amongst the methods&#x27; objectives on the research
and practice of explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An On-Device Federated Learning Approach for Cooperative Anomaly Detection. (arXiv:2002.12301v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ito_R/0/1/0/all/0/1">Rei Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsukada_M/0/1/0/all/0/1">Mineto Tsukada</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsutani_H/0/1/0/all/0/1">Hiroki Matsutani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.12301">
                                    <div class="article-summary-box-inner">
                                        <span>Most edge AI focuses on prediction tasks on resource-limited edge devices
while the training is done at server machines. However, retraining or
customizing a model is required at edge devices as the model is becoming
outdated due to environmental changes over time. To follow such a concept
drift, a neural-network based on-device learning approach is recently proposed,
so that edge devices train incoming data at runtime to update their model. In
this case, since a training is done at distributed edge devices, the issue is
that only a limited amount of training data can be used for each edge device.
To address this issue, one approach is a cooperative learning or federated
learning, where edge devices exchange their trained results and update their
model by using those collected from the other devices. In this paper, as an
on-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme
Learning Machine) to sequentially train a model based on recent samples and
combine it with autoencoder for anomaly detection. We extend it for an
on-device federated learning so that edge devices can exchange their trained
results and update their model by using those collected from the other edge
devices. This cooperative model update is one-shot while it can be repeatedly
applied to synchronize their model. Our approach is evaluated with anomaly
detection tasks generated from a driving dataset of cars, a human activity
dataset, and MNIST dataset. The results demonstrate that the proposed on-device
federated learning can produce a merged model by integrating trained results
from multiple edge devices as accurately as traditional backpropagation based
neural networks and a traditional federated learning approach with lower
computation or communication cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classifying high-dimensional Gaussian mixtures: Where kernel methods fail and neural networks succeed. (arXiv:2102.11742v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Refinetti_M/0/1/0/all/0/1">Maria Refinetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldt_S/0/1/0/all/0/1">Sebastian Goldt</a>, <a href="http://arxiv.org/find/cs/1/au:+Krzakala_F/0/1/0/all/0/1">Florent Krzakala</a>, <a href="http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1">Lenka Zdeborov&#xe1;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11742">
                                    <div class="article-summary-box-inner">
                                        <span>A recent series of theoretical works showed that the dynamics of neural
networks with a certain initialisation are well-captured by kernel methods.
Concurrent empirical work demonstrated that kernel methods can come close to
the performance of neural networks on some image classification tasks. These
results raise the question of whether neural networks only learn successfully
if kernels also learn successfully, despite neural networks being more
expressive. Here, we show theoretically that two-layer neural networks (2LNN)
with only a few hidden neurons can beat the performance of kernel learning on a
simple Gaussian mixture classification task. We study the high-dimensional
limit where the number of samples is linearly proportional to the input
dimension, and show that while small 2LNN achieve near-optimal performance on
this task, lazy training approaches such as random features and kernel methods
do not. Our analysis is based on the derivation of a closed set of equations
that track the learning dynamics of the 2LNN and thus allow to extract the
asymptotic performance of the network as a function of signal-to-noise ratio
and other hyperparameters. We finally illustrate how over-parametrising the
neural network leads to faster convergence, but does not improve its final
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised VQ-VAE for One-Shot Music Style Transfer. (arXiv:2102.05749v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1">Ond&#x159;ej C&#xed;fka</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozerov_A/0/1/0/all/0/1">Alexey Ozerov</a>, <a href="http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1">Umut &#x15e;im&#x15f;ekli</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05749">
                                    <div class="article-summary-box-inner">
                                        <span>Neural style transfer, allowing to apply the artistic style of one image to
another, has become one of the most widely showcased computer vision
applications shortly after its introduction. In contrast, related tasks in the
music audio domain remained, until recently, largely untackled. While several
style conversion methods tailored to musical signals have been proposed, most
lack the &#x27;one-shot&#x27; capability of classical image style transfer algorithms. On
the other hand, the results of existing one-shot audio style transfer methods
on musical inputs are not as compelling. In this work, we are specifically
interested in the problem of one-shot timbre transfer. We present a novel
method for this task, based on an extension of the vector-quantized variational
autoencoder (VQ-VAE), along with a simple self-supervised learning strategy
designed to obtain disentangled representations of timbre and pitch. We
evaluate the method using a set of objective metrics and show that it is able
to outperform selected baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases. (arXiv:2103.10697v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1">St&#xe9;phane d&#x27;Ascoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1">Hugo Touvron</a>, <a href="http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1">Matthew Leavitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1">Ari Morcos</a>, <a href="http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1">Giulio Biroli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1">Levent Sagun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10697">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional architectures have proven extremely successful for vision
tasks. Their hard inductive biases enable sample-efficient learning, but come
at the cost of a potentially lower performance ceiling. Vision Transformers
(ViTs) rely on more flexible self-attention layers, and have recently
outperformed CNNs for image classification. However, they require costly
pre-training on large external datasets or distillation from pre-trained
convolutional networks. In this paper, we ask the following question: is it
possible to combine the strengths of these two architectures while avoiding
their respective limitations? To this end, we introduce gated positional
self-attention (GPSA), a form of positional self-attention which can be
equipped with a &#x60;&#x60;soft&quot; convolutional inductive bias. We initialise the GPSA
layers to mimic the locality of convolutional layers, then give each attention
head the freedom to escape locality by adjusting a gating parameter regulating
the attention paid to position versus content information. The resulting
convolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet,
while offering a much improved sample efficiency. We further investigate the
role of locality in learning by first quantifying how it is encouraged in
vanilla self-attention layers, then analysing how it is escaped in GPSA layers.
We conclude by presenting various ablations to better understand the success of
the ConViT. Our code and models are released publicly at
https://github.com/facebookresearch/convit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Arindam Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1">Chen Dun</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayer_A/0/1/0/all/0/1">Artun Bayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1">Santiago Segarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10424">
                                    <div class="article-summary-box-inner">
                                        <span>The graph convolutional network (GCN) is a go-to solution for machine
learning on graphs, but its training is notoriously difficult to scale both in
terms of graph size and the number of model parameters. Although some work has
explored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we
pioneer efficient training of large-scale GCN models (i.e., ultra-wide,
overparameterized models) with the proposal of a novel, distributed training
framework. Our proposed training methodology, called GIST, disjointly
partitions the parameters of a GCN model into several, smaller sub-GCNs that
are trained independently and in parallel. In addition to being compatible with
any GCN architecture, GIST improves model performance, scales to training on
arbitrarily large graphs, significantly decreases wall-clock training time, and
enables the training of markedly overparameterized GCN models. Remarkably, with
GIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which
exceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on
the Amazon2M dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ATOM3D: Tasks On Molecules in Three Dimensions. (arXiv:2012.04035v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Townshend_R/0/1/0/all/0/1">Raphael J.L. Townshend</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogele_M/0/1/0/all/0/1">Martin V&#xf6;gele</a>, <a href="http://arxiv.org/find/cs/1/au:+Suriana_P/0/1/0/all/0/1">Patricia Suriana</a>, <a href="http://arxiv.org/find/cs/1/au:+Derry_A/0/1/0/all/0/1">Alexander Derry</a>, <a href="http://arxiv.org/find/cs/1/au:+Powers_A/0/1/0/all/0/1">Alexander Powers</a>, <a href="http://arxiv.org/find/cs/1/au:+Laloudakis_Y/0/1/0/all/0/1">Yianni Laloudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Balachandar_S/0/1/0/all/0/1">Sidhika Balachandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_B/0/1/0/all/0/1">Bowen Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1">Brandon Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Eismann_S/0/1/0/all/0/1">Stephan Eismann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1">Risi Kondor</a>, <a href="http://arxiv.org/find/cs/1/au:+Altman_R/0/1/0/all/0/1">Russ B. Altman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dror_R/0/1/0/all/0/1">Ron O. Dror</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04035">
                                    <div class="article-summary-box-inner">
                                        <span>Computational methods that operate on three-dimensional molecular structure
have the potential to solve important questions in biology and chemistry. In
particular, deep neural networks have gained significant attention, but their
widespread adoption in the biomolecular domain has been limited by a lack of
either systematic performance benchmarks or a unified toolkit for interacting
with molecular data. To address this, we present ATOM3D, a collection of both
novel and existing benchmark datasets spanning several key classes of
biomolecules. We implement several classes of three-dimensional molecular
learning methods for each of these tasks and show that they consistently
improve performance relative to methods based on one- and two-dimensional
representations. The specific choice of architecture proves to be critical for
performance, with three-dimensional convolutional networks excelling at tasks
involving complex geometries, graph networks performing well on systems
requiring detailed positional information, and the more recently developed
equivariant networks showing significant promise. Our results indicate that
many molecular problems stand to gain from three-dimensional molecular
learning, and that there is potential for improvement on many tasks which
remain underexplored. To lower the barrier to entry and facilitate further
developments in the field, we also provide a comprehensive suite of tools for
dataset processing, model training, and evaluation in our open-source atom3d
Python package. All datasets are available for download from
https://www.atom3d.ai .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UnICORNN: A recurrent model for learning very long time dependencies. (arXiv:2103.05487v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rusch_T/0/1/0/all/0/1">T. Konstantin Rusch</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Siddhartha Mishra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05487">
                                    <div class="article-summary-box-inner">
                                        <span>The design of recurrent neural networks (RNNs) to accurately process
sequential inputs with long-time dependencies is very challenging on account of
the exploding and vanishing gradient problem. To overcome this, we propose a
novel RNN architecture which is based on a structure preserving discretization
of a Hamiltonian system of second-order ordinary differential equations that
models networks of oscillators. The resulting RNN is fast, invertible (in
time), memory efficient and we derive rigorous bounds on the hidden state
gradients to prove the mitigation of the exploding and vanishing gradient
problem. A suite of experiments are presented to demonstrate that the proposed
RNN provides state of the art performance on a variety of learning tasks with
(very) long-time dependencies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benign Overfitting of Constant-Stepsize SGD for Linear Regression. (arXiv:2103.12692v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1">Difan Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingfeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1">Quanquan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12692">
                                    <div class="article-summary-box-inner">
                                        <span>There is an increasing realization that algorithmic inductive biases are
central in preventing overfitting; empirically, we often see a benign
overfitting phenomenon in overparameterized settings for natural learning
algorithms, such as stochastic gradient descent (SGD), where little to no
explicit regularization has been employed. This work considers this issue in
arguably the most basic setting: constant-stepsize SGD (with iterate averaging)
for linear regression in the overparameterized regime. Our main result provides
a sharp excess risk bound, stated in terms of the full eigenspectrum of the
data covariance matrix, that reveals a bias-variance decomposition
characterizing when generalization is possible: (i) the variance bound is
characterized in terms of an effective dimension (specific for SGD) and (ii)
the bias bound provides a sharp geometric characterization in terms of the
location of the initial iterate (and how it aligns with the data covariance
matrix). We reflect on a number of notable differences between the algorithmic
regularization afforded by (unregularized) SGD in comparison to ordinary least
squares (minimum-norm interpolation) and ridge regression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Unfolding of Iteratively Reweighted ADMM for Wireless RF Sensing. (arXiv:2106.03686v1 [eess.SP] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thanthrige_U/0/1/0/all/0/1">Udaya S.K.P. Miriya Thanthrige</a>, <a href="http://arxiv.org/find/eess/1/au:+Jung_P/0/1/0/all/0/1">Peter Jung</a>, <a href="http://arxiv.org/find/eess/1/au:+Sezgin_A/0/1/0/all/0/1">Aydin Sezgin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03686">
                                    <div class="article-summary-box-inner">
                                        <span>We address the detection of material defects, which are inside a layered
material structure using compressive sensing based multiple-output (MIMO)
wireless radar. Here, the strong clutter due to the reflection of the layered
structure&#x27;s surface often makes the detection of the defects challenging. Thus,
sophisticated signal separation methods are required for improved defect
detection. In many scenarios, the number of defects that we are interested in
is limited and the signaling response of the layered structure can be modeled
as a low-rank structure. Therefore, we propose joint rank and sparsity
minimization for defect detection. In particular, we propose a non-convex
approach based on the iteratively reweighted nuclear and $\ell_1-$norm (a
double-reweighted approach) to obtain a higher accuracy compared to the
conventional nuclear norm and $\ell_1-$norm minimization. To this end, an
iterative algorithm is designed to estimate the low-rank and sparse
contributions. Further, we propose deep learning to learn the parameters of the
algorithm (i.e., algorithm unfolding) to improve the accuracy and the speed of
convergence of the algorithm. Our numerical results show that the proposed
approach outperforms the conventional approaches in terms of mean square errors
of the recovered low-rank and sparse components and the speed of convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Large Batch Optimizer Reality Check: Traditional, Generic Optimizers Suffice Across Batch Sizes. (arXiv:2102.06356v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nado_Z/0/1/0/all/0/1">Zachary Nado</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1">Justin M. Gilmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shallue_C/0/1/0/all/0/1">Christopher J. Shallue</a>, <a href="http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1">Rohan Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1">George E. Dahl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06356">
                                    <div class="article-summary-box-inner">
                                        <span>Recently the LARS and LAMB optimizers have been proposed for training neural
networks faster using large batch sizes. LARS and LAMB add layer-wise
normalization to the update rules of Heavy-ball momentum and Adam,
respectively, and have become popular in prominent benchmarks and deep learning
libraries. However, without fair comparisons to standard optimizers, it remains
an open question whether LARS and LAMB have any benefit over traditional,
generic algorithms. In this work we demonstrate that standard optimization
algorithms such as Nesterov momentum and Adam can match or exceed the results
of LARS and LAMB at large batch sizes. Our results establish new, stronger
baselines for future comparisons at these batch sizes and shed light on the
difficulties of comparing optimizers for neural network training more
generally.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of head impacts based on the spectral density of measurable kinematics. (arXiv:2104.09082v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhan_X/0/1/0/all/0/1">Xianghao Zhan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1">Yiheng Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_Y/0/1/0/all/0/1">Yuzhe Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cecchi_N/0/1/0/all/0/1">Nicholas J. Cecchi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Raymond_S/0/1/0/all/0/1">Samuel J. Raymond</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhou_Z/0/1/0/all/0/1">Zhou Zhou</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Alizadeh_H/0/1/0/all/0/1">Hossein Vahid Alizadeh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ruan_J/0/1/0/all/0/1">Jesse Ruan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Barbat_S/0/1/0/all/0/1">Saeed Barbat</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Tiernan_S/0/1/0/all/0/1">Stephen Tiernan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gevaert_O/0/1/0/all/0/1">Olivier Gevaert</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zeineh_M/0/1/0/all/0/1">Michael M. Zeineh</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Grant_G/0/1/0/all/0/1">Gerald A. Grant</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Camarillo_D/0/1/0/all/0/1">David B. Camarillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09082">
                                    <div class="article-summary-box-inner">
                                        <span>Traumatic brain injury can be caused by head impacts, but many brain injury
risk estimation models are less accurate across the variety of impacts that
patients may undergo. We investigated the spectral characteristics of different
head impact types with kinematics classification. Data was analyzed from 3,262
head impacts from lab reconstruction, American football, mixed martial arts,
and publicly available car crash data. A random forest classifier with spectral
densities of linear acceleration and angular velocity was built to classify
head impact types (e.g., football), reaching a median accuracy of 96% over
1,000 random partitions of training and test sets. To test the classifier on
data from different measurement devices, another 271 lab-reconstructed impacts
were obtained from 5 other instrumented mouthguards with the classifier
reaching over 96% accuracy. The most important features in the classification
included both low-frequency and high-frequency features, both linear
acceleration features and angular velocity features. Different head impact
types had different distributions of spectral densities in low-frequency and
high-frequency ranges (e.g., the spectral densities of MMA impacts were higher
in high-frequency range than in the low-frequency range). Finally, with the
classifier, type-specific, nearest-neighbor regression models were built for
95th percentile maximum principal strain, 95th percentile maximum principal
strain in corpus callosum, and cumulative strain damage (15th percentile). This
showed a generally higher R2-value than baseline models. The classifier enables
a better understanding of the impact kinematics in different sports, and it can
be applied to evaluate the quality of impact-simulation systems and on-field
data augmentation. Key words: traumatic brain injury, head impacts,
classification, impact kinematics</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Transformers with Patch Diversification. (arXiv:2104.12753v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1">Chengyue Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Meng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1">Vikas Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12753">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformer has demonstrated promising performance on challenging
computer vision tasks. However, directly training the vision transformers may
yield unstable and sub-optimal results. Recent works propose to improve the
performance of the vision transformers by modifying the transformer structures,
e.g., incorporating convolution layers. In contrast, we investigate an
orthogonal approach to stabilize the vision transformer training without
modifying the networks. We observe the instability of the training can be
attributed to the significant similarity across the extracted patch
representations. More specifically, for deep vision transformers, the
self-attention blocks tend to map different patches into similar latent
representations, yielding information loss and performance degradation. To
alleviate this problem, in this work, we introduce novel loss functions in
vision transformer training to explicitly encourage diversity across patch
representations for more discriminative feature extraction. We empirically show
that our proposed techniques stabilize the training and allow us to train wider
and deeper vision transformers. We further show the diversified features
significantly benefit the downstream tasks in transfer learning. For semantic
segmentation, we enhance the state-of-the-art (SOTA) results on Cityscapes and
ADE20k. Our code will be made publicly available soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUNRISE: A Simple Unified Framework for Ensemble Learning in Deep Reinforcement Learning. (arXiv:2007.04938v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1">Michael Laskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1">Aravind Srinivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04938">
                                    <div class="article-summary-box-inner">
                                        <span>Model-free deep reinforcement learning (RL) has been successful in a range of
challenging domains. However, there are some remaining issues, such as
stabilizing the optimization of nonlinear function approximators, preventing
error propagation due to the Bellman backup in Q-learning, and efficient
exploration. To mitigate these issues, we present SUNRISE, a simple unified
ensemble method, which is compatible with various off-policy RL algorithms.
SUNRISE integrates three key ingredients: (a) bootstrap with random
initialization which improves the stability of the learning process by training
a diverse ensemble of agents, (b) weighted Bellman backups, which prevent error
propagation in Q-learning by reweighing sample transitions based on uncertainty
estimates from the ensembles, and (c) an inference method that selects actions
using highest upper-confidence bounds for efficient exploration. Our
experiments show that SUNRISE significantly improves the performance of
existing off-policy RL algorithms, such as Soft Actor-Critic and Rainbow DQN,
for both continuous and discrete control tasks on both low-dimensional and
high-dimensional environments. Our training code is available at
https://github.com/pokaxpoka/sunrise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COUnty aggRegation mixup AuGmEntation (COURAGE) COVID-19 Prediction. (arXiv:2105.00620v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Er_S/0/1/0/all/0/1">Siawpeng Er</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shihao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00620">
                                    <div class="article-summary-box-inner">
                                        <span>The global spread of COVID-19, the disease caused by the novel coronavirus
SARS-CoV-2, has cast a significant threat to mankind. As the COVID-19 situation
continues to evolve, predicting localized disease severity is crucial for
advanced resource allocation. This paper proposes a method named COURAGE
(COUnty aggRegation mixup AuGmEntation) to generate a short-term prediction of
2-week-ahead COVID-19 related deaths for each county in the United States,
leveraging modern deep learning techniques. Specifically, our method adopts a
self-attention model from Natural Language Processing, known as the transformer
model, to capture both short-term and long-term dependencies within the time
series while enjoying computational efficiency. Our model fully utilizes
publicly available information of COVID-19 related confirmed cases, deaths,
community mobility trends and demographic information, and can produce
state-level prediction as an aggregation of the corresponding county-level
predictions. Our numerical experiments demonstrate that our model achieves the
state-of-the-art performance among the publicly available benchmark models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCC: an efficient deep reinforcement learning agent mastering the game of StarCraft II. (arXiv:2012.13169v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiangjun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Junxiao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1">Penghui Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_P/0/1/0/all/0/1">Peng Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhenkun Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weimin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pi_X/0/1/0/all/0/1">Xiongjun Pi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jujie He</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_H/0/1/0/all/0/1">Haitao Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1">Quan Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13169">
                                    <div class="article-summary-box-inner">
                                        <span>AlphaStar, the AI that reaches GrandMaster level in StarCraft II, is a
remarkable milestone demonstrating what deep reinforcement learning can achieve
in complex Real-Time Strategy (RTS) games. However, the complexities of the
game, algorithms and systems, and especially the tremendous amount of
computation needed are big obstacles for the community to conduct further
research in this direction. We propose a deep reinforcement learning agent,
StarCraft Commander (SCC). With order of magnitude less computation, it
demonstrates top human performance defeating GrandMaster players in test
matches and top professional players in a live event. Moreover, it shows strong
robustness to various human strategies and discovers novel strategies unseen
from human plays. In this paper, we will share the key insights and
optimizations on efficient imitation learning and reinforcement learning for
StarCraft II full game.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The query complexity of sampling from strongly log-concave distributions in one dimension. (arXiv:2105.14163v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chewi_S/0/1/0/all/0/1">Sinho Chewi</a>, <a href="http://arxiv.org/find/math/1/au:+Gerber_P/0/1/0/all/0/1">Patrik Gerber</a>, <a href="http://arxiv.org/find/math/1/au:+Lu_C/0/1/0/all/0/1">Chen Lu</a>, <a href="http://arxiv.org/find/math/1/au:+Gouic_T/0/1/0/all/0/1">Thibaut Le Gouic</a>, <a href="http://arxiv.org/find/math/1/au:+Rigollet_P/0/1/0/all/0/1">Philippe Rigollet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14163">
                                    <div class="article-summary-box-inner">
                                        <span>We establish the first tight lower bound of $\Omega(\log\log\kappa)$ on the
query complexity of sampling from the class of strongly log-concave and
log-smooth distributions with condition number $\kappa$ in one dimension.
Whereas existing guarantees for MCMC-based algorithms scale polynomially in
$\kappa$, we introduce a novel algorithm based on rejection sampling that
closes this doubly exponential gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Graph Augmentation to Improve Graph Contrastive Learning. (arXiv:2106.05819v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1">Susheel Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1">Cong Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1">Jennifer Neville</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05819">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning of graph neural networks (GNN) is in great need
because of the widespread label scarcity issue in real-world graph/network
data. Graph contrastive learning (GCL), by training GNNs to maximize the
correspondence between the representations of the same graph in its different
augmented forms, may yield robust and transferable GNNs even without using
labels. However, GNNs trained by traditional GCL often risk capturing redundant
graph features and thus may be brittle and provide sub-par performance in
downstream tasks. Here, we propose a novel principle, termed adversarial-GCL
(AD-GCL), which enables GNNs to avoid capturing redundant information during
the training by optimizing adversarial graph augmentation strategies used in
GCL. We pair AD-GCL with theoretical explanations and design a practical
instantiation based on trainable edge-dropping graph augmentation. We
experimentally validate AD-GCL by comparing with the state-of-the-art GCL
methods and achieve performance gains of up-to $14\%$ in unsupervised, $6\%$ in
transfer, and $3\%$ in semi-supervised learning settings overall with 18
different benchmark datasets for the tasks of molecule property regression and
classification, and social network classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Norms of CNN Layers Do Not Hurt Adversarial Robustness. (arXiv:2009.08435v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Youwei Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08435">
                                    <div class="article-summary-box-inner">
                                        <span>Since the Lipschitz properties of CNN are widely considered to be related to
adversarial robustness, we theoretically characterize the $\ell_1$ norm and
$\ell_\infty$ norm of 2D multi-channel convolutional layers and provide
efficient methods to compute the exact $\ell_1$ norm and $\ell_\infty$ norm.
Based on our theorem, we propose a novel regularization method termed norm
decay, which can effectively reduce the norms of convolutional layers and
fully-connected layers. Experiments show that norm-regularization methods,
including norm decay, weight decay, and singular value clipping, can improve
generalization of CNNs. However, they can slightly hurt adversarial robustness.
Observing this unexpected phenomenon, we compute the norms of layers in the
CNNs trained with three different adversarial training frameworks and
surprisingly find that adversarially robust CNNs have comparable or even larger
layer norms than their non-adversarially robust counterparts. Furthermore, we
prove that under a mild assumption, adversarially robust classifiers can be
achieved, and can have an arbitrarily large Lipschitz constant. For this
reason, enforcing small norms on CNN layers may be neither necessary nor
effective in achieving adversarial robustness. The code is available at
https://github.com/youweiliang/norm_robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stability and Convergence of Stochastic Gradient Clipping: Beyond Lipschitz Continuity and Smoothness. (arXiv:2102.06489v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Mai_V/0/1/0/all/0/1">Vien V. Mai</a>, <a href="http://arxiv.org/find/math/1/au:+Johansson_M/0/1/0/all/0/1">Mikael Johansson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06489">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic gradient algorithms are often unstable when applied to functions
that do not have Lipschitz-continuous and/or bounded gradients. Gradient
clipping is a simple and effective technique to stabilize the training process
for problems that are prone to the exploding gradient problem. Despite its
widespread popularity, the convergence properties of the gradient clipping
heuristic are poorly understood, especially for stochastic problems. This paper
establishes both qualitative and quantitative convergence results of the
clipped stochastic (sub)gradient method (SGD) for non-smooth convex functions
with rapidly growing subgradients. Our analyses show that clipping enhances the
stability of SGD and that the clipped SGD algorithm enjoys finite convergence
rates in many cases. We also study the convergence of a clipped method with
momentum, which includes clipped SGD as a special case, for weakly convex
problems under standard assumptions. With a novel Lyapunov analysis, we show
that the proposed method achieves the best-known rate for the considered class
of problems, demonstrating the effectiveness of clipped methods also in this
regime. Numerical results confirm our theoretical developments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empirical observations on the effects of data transformation in machine learning classification of geological domains. (arXiv:2106.05855v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leung_R/0/1/0/all/0/1">Raymond Leung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05855">
                                    <div class="article-summary-box-inner">
                                        <span>In the literature, a large body of work advocates the use of log-ratio
transformation for multivariate statistical analysis of compositional data. In
contrast, few studies have looked at how data transformation changes the
efficacy of machine learning classifiers within geoscience. This letter
presents experiment results and empirical observations to further explore this
issue. The objective is to study the effects of data transformation on geozone
classification performance when machine learning (ML) classifiers/estimators
are trained using geochemical data. The training input consists of exploration
hole assay samples obtained from a Pilbara iron-ore deposit in Western
Australia, and geozone labels assigned based on stratigraphic units, the
absence or presence and type of mineralization. The ML techniques considered
are multinomial logistic regression, Gaussian na\&quot;{i}ve Bayes, kNN, linear
support vector classifier, RBF-SVM, gradient boosting and extreme GB, random
forest (RF) and multi-layer perceptron (MLP). The transformations examined
include isometric log-ratio (ILR), center log-ratio (CLR) coupled with
principal component analysis (PCA) or independent component analysis (ICA), and
a manifold learning approach based on local linear embedding (LLE). The results
reveal that different ML classifiers exhibit varying sensitivity to these
transformations, with some clearly more advantageous or deleterious than
others. Overall, the best performing candidate is ILR which is unsurprising
considering the compositional nature of the data. The performance of pairwise
log-ratio (PWLR) transformation is better than ILR for ensemble and tree-based
learners such as boosting and RF; but worse for MLP, SVM and other classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causality in Neural Networks -- An Extended Abstract. (arXiv:2106.05842v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reddy_A/0/1/0/all/0/1">Abbavaram Gowtham Reddy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05842">
                                    <div class="article-summary-box-inner">
                                        <span>Causal reasoning is the main learning and explanation tool used by humans. AI
systems should possess causal reasoning capabilities to be deployed in the real
world with trust and reliability. Introducing the ideas of causality to machine
learning helps in providing better learning and explainable models.
Explainability, causal disentanglement are some important aspects of any
machine learning model. Causal explanations are required to believe in a
model&#x27;s decision and causal disentanglement learning is important for transfer
learning applications. We exploit the ideas of causality to be used in deep
learning models to achieve better and causally explainable models that are
useful in fairness, disentangled representation, etc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple Graph Convolutional Networks. (arXiv:2106.05809v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pasa_L/0/1/0/all/0/1">Luca Pasa</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarin_N/0/1/0/all/0/1">Nicol&#xf2; Navarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Erb_W/0/1/0/all/0/1">Wolfgang Erb</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperduti_A/0/1/0/all/0/1">Alessandro Sperduti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05809">
                                    <div class="article-summary-box-inner">
                                        <span>Many neural networks for graphs are based on the graph convolution operator,
proposed more than a decade ago. Since then, many alternative definitions have
been proposed, that tend to add complexity (and non-linearity) to the model. In
this paper, we follow the opposite direction by proposing simple graph
convolution operators, that can be implemented in single-layer graph
convolutional networks. We show that our convolution operators are more
theoretically grounded than many proposals in literature, and exhibit
state-of-the-art predictive performance on the considered benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis and Design of Thompson Sampling for Stochastic Partial Monitoring. (arXiv:2006.09668v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tsuchiya_T/0/1/0/all/0/1">Taira Tsuchiya</a>, <a href="http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1">Junya Honda</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09668">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate finite stochastic partial monitoring, which is a general model
for sequential learning with limited feedback. While Thompson sampling is one
of the most promising algorithms on a variety of online decision-making
problems, its properties for stochastic partial monitoring have not been
theoretically investigated, and the existing algorithm relies on a heuristic
approximation of the posterior distribution. To mitigate these problems, we
present a novel Thompson-sampling-based algorithm, which enables us to exactly
sample the target parameter from the posterior distribution. Besides, we prove
that the new algorithm achieves the logarithmic problem-dependent expected
pseudo-regret $\mathrm{O}(\log T)$ for a linearized variant of the problem with
local observability. This result is the first regret bound of Thompson sampling
for partial monitoring, which also becomes the first logarithmic regret bound
of Thompson sampling for linear bandits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing the Benefit of Synthetic Training Data for Various Automatic Speech Recognition Architectures. (arXiv:2104.05379v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1">Nick Rossenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1">Mohammad Zeineldeen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1">Benedikt Hilmes</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05379">
                                    <div class="article-summary-box-inner">
                                        <span>Recent publications on automatic-speech-recognition (ASR) have a strong focus
on attention encoder-decoder (AED) architectures which work well for large
datasets, but tend to overfit when applied in low resource scenarios. One
solution to tackle this issue is to generate synthetic data with a trained
text-to-speech system (TTS) if additional text is available. This was
successfully applied in many publications with AED systems. We present a novel
approach of silence correction in the data pre-processing for TTS systems which
increases the robustness when training on corpora targeted for ASR
applications. In this work we do not only show the successful application of
synthetic data for AED systems, but also test the same method on a highly
optimized state-of-the-art Hybrid ASR system and a competitive monophone based
system using connectionist-temporal-classification (CTC). We show that for the
later systems the addition of synthetic data only has a minor effect, but they
still outperform the AED systems by a large margin on LibriSpeech-100h. We
achieve a final word-error-rate of 3.3%/10.0% with a Hybrid system on the
clean/noisy test-sets, surpassing any previous state-of-the-art systems that do
not include unlabeled audio data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust MAML: Prioritization task buffer with adaptive learning process for model-agnostic meta-learning. (arXiv:2103.08233v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thanh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_T/0/1/0/all/0/1">Tung Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Trung Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Rakhimkul_S/0/1/0/all/0/1">Sanzhar Rakhimkul</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1">Chang D. Yoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08233">
                                    <div class="article-summary-box-inner">
                                        <span>Model agnostic meta-learning (MAML) is a popular state-of-the-art
meta-learning algorithm that provides good weight initialization of a model
given a variety of learning tasks. The model initialized by provided weight can
be fine-tuned to an unseen task despite only using a small amount of samples
and within a few adaptation steps. MAML is simple and versatile but requires
costly learning rate tuning and careful design of the task distribution which
affects its scalability and generalization. This paper proposes a more robust
MAML based on an adaptive learning scheme and a prioritization task buffer(PTB)
referred to as Robust MAML (RMAML) for improving scalability of training
process and alleviating the problem of distribution mismatch. RMAML uses
gradient-based hyper-parameter optimization to automatically find the optimal
learning rate and uses the PTB to gradually adjust train-ing task distribution
toward testing task distribution over the course of training. Experimental
results on meta reinforcement learning environments demonstrate a substantial
performance gain as well as being less sensitive to hyper-parameter choice and
robust to distribution mismatch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Replacement and Combination for Hybrid ASR Systems. (arXiv:2104.04298v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1">Peter Vieting</a>, <a href="http://arxiv.org/find/eess/1/au:+Luscher_C/0/1/0/all/0/1">Christoph L&#xfc;scher</a>, <a href="http://arxiv.org/find/eess/1/au:+Michel_W/0/1/0/all/0/1">Wilfried Michel</a>, <a href="http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04298">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic modeling of raw waveform and learning feature extractors as part of
the neural network classifier has been the goal of many studies in the area of
automatic speech recognition (ASR). Recently, one line of research has focused
on frameworks that can be pre-trained on audio-only data in an unsupervised
fashion and aim at improving downstream ASR tasks. In this work, we investigate
the usefulness of one of these front-end frameworks, namely wav2vec, for hybrid
ASR systems. In addition to deploying a pre-trained feature extractor, we
explore how to make use of an existing acoustic model (AM) trained on the same
task with different features as well. Another neural front-end which is only
trained together with the supervised ASR loss as well as traditional Gammatone
features are applied for comparison. Moreover, it is shown that the AM can be
retrofitted with i-vectors for speaker adaptation. Finally, the described
features are combined in order to further advance the performance. With the
final best system, we obtain a relative improvement of 4% and 6% over our
previous best model on the LibriSpeech test-clean and test-other sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Deep Supervised Anomaly Detection: Reinforcement Learning from Partially Labeled Anomaly Data. (arXiv:2009.06847v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1">Guansong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1">Anton van den Hengel</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1">Longbing Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06847">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of anomaly detection with a small set of partially
labeled anomaly examples and a large-scale unlabeled dataset. This is a common
scenario in many important applications. Existing related methods either
exclusively fit the limited anomaly examples that typically do not span the
entire set of anomalies, or proceed with unsupervised learning from the
unlabeled data. We propose here instead a deep reinforcement learning-based
approach that enables an end-to-end optimization of the detection of both
labeled and unlabeled anomalies. This approach learns the known abnormality by
automatically interacting with an anomaly-biased simulation environment, while
continuously extending the learned abnormality to novel classes of anomaly
(i.e., unknown anomalies) by actively exploring possible anomalies in the
unlabeled data. This is achieved by jointly optimizing the exploitation of the
small labeled anomaly data and the exploration of the rare unlabeled anomalies.
Extensive experiments on 48 real-world datasets show that our model
significantly outperforms five state-of-the-art competing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Align, then memorise: the dynamics of learning with feedback alignment. (arXiv:2011.12428v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Refinetti_M/0/1/0/all/0/1">Maria Refinetti</a>, <a href="http://arxiv.org/find/stat/1/au:+dAscoli_S/0/1/0/all/0/1">St&#xe9;phane d&#x27;Ascoli</a>, <a href="http://arxiv.org/find/stat/1/au:+Ohana_R/0/1/0/all/0/1">Ruben Ohana</a>, <a href="http://arxiv.org/find/stat/1/au:+Goldt_S/0/1/0/all/0/1">Sebastian Goldt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12428">
                                    <div class="article-summary-box-inner">
                                        <span>Direct Feedback Alignment (DFA) is emerging as an efficient and biologically
plausible alternative to the ubiquitous backpropagation algorithm for training
deep neural networks. Despite relying on random feedback weights for the
backward pass, DFA successfully trains state-of-the-art models such as
Transformers. On the other hand, it notoriously fails to train convolutional
networks. An understanding of the inner workings of DFA to explain these
diverging results remains elusive. Here, we propose a theory for the success of
DFA. We first show that learning in shallow networks proceeds in two steps: an
alignment phase, where the model adapts its weights to align the approximate
gradient with the true gradient of the loss function, is followed by a
memorisation phase, where the model focuses on fitting the data. This two-step
process has a degeneracy breaking effect: out of all the low-loss solutions in
the landscape, a network trained with DFA naturally converges to the solution
which maximises gradient alignment. We also identify a key quantity underlying
alignment in deep linear networks: the conditioning of the alignment matrices.
The latter enables a detailed understanding of the impact of data structure on
alignment, and suggests a simple explanation for the well-known failure of DFA
to train convolutional neural networks. Numerical experiments on MNIST and
CIFAR10 clearly demonstrate degeneracy breaking in deep non-linear networks and
show that the align-then-memorise process occurs sequentially from the bottom
layers of the network to the top.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamics-Regulated Kinematic Policy for Egocentric Pose Estimation. (arXiv:2106.05969v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhengyi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1">Ryo Hachiuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Ye Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris Kitani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05969">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method for object-aware 3D egocentric pose estimation that
tightly integrates kinematics modeling, dynamics modeling, and scene object
information. Unlike prior kinematics or dynamics-based approaches where the two
components are used disjointly, we synergize the two approaches via
dynamics-regulated training. At each timestep, a kinematic model is used to
provide a target pose using video evidence and simulation state. Then, a
prelearned dynamics model attempts to mimic the kinematic pose in a physics
simulator. By comparing the pose instructed by the kinematic model against the
pose generated by the dynamics model, we can use their misalignment to further
improve the kinematic model. By factoring in the 6DoF pose of objects (e.g.,
chairs, boxes) in the scene, we demonstrate for the first time, the ability to
estimate physically-plausible 3D human-object interactions using a single
wearable camera. We evaluate our egocentric pose estimation method in both
controlled laboratory settings and real-world scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interferometric Graph Transform for Community Labeling. (arXiv:2106.05875v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grinsztajn_N/0/1/0/all/0/1">Nathan Grinsztajn</a> (Scool), <a href="http://arxiv.org/find/cs/1/au:+Leconte_L/0/1/0/all/0/1">Louis Leconte</a> (MLIA, CMAP), <a href="http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1">Philippe Preux</a> (Scool), <a href="http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1">Edouard Oyallon</a> (MLIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05875">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new approach for learning unsupervised node representations in
community graphs. We significantly extend the Interferometric Graph Transform
(IGT) to community labeling: this non-linear operator iteratively extracts
features that take advantage of the graph topology through demodulation
operations. An unsupervised feature extraction step cascades modulus
non-linearity with linear operators that aim at building relevant invariants
for community labeling. Via a simplified model, we show that the IGT
concentrates around the E-IGT: those two representations are related through
some ergodicity properties. Experiments on community labeling tasks show that
this unsupervised representation achieves performances at the level of the
state of the art on the standard and challenging datasets Cora, Citeseer,
Pubmed and WikiCS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraged Weighted Loss for Partial Label Learning. (arXiv:2106.05731v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Hongwei Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jingyi Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hang_H/0/1/0/all/0/1">Hanyuan Hang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiabin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05731">
                                    <div class="article-summary-box-inner">
                                        <span>As an important branch of weakly supervised learning, partial label learning
deals with data where each instance is assigned with a set of candidate labels,
whereas only one of them is true. Despite many methodology studies on learning
from partial labels, there still lacks theoretical understandings of their risk
consistent properties under relatively weak assumptions, especially on the link
between theoretical results and the empirical choice of parameters. In this
paper, we propose a family of loss functions named \textit{Leveraged Weighted}
(LW) loss, which for the first time introduces the leverage parameter $\beta$
to consider the trade-off between losses on partial labels and non-partial
ones. From the theoretical side, we derive a generalized result of risk
consistency for the LW loss in learning from partial labels, based on which we
provide guidance to the choice of the leverage parameter $\beta$. In
experiments, we verify the theoretical guidance, and show the high
effectiveness of our proposed LW loss on both benchmark and real datasets
compared with other state-of-the-art partial label learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Mathematical Foundation for Robust Machine Learning based on Bias-Variance Trade-off. (arXiv:2106.05522v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_O/0/1/0/all/0/1">Ou Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Weiyao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yingjun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haixiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1">Qinghu Hou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05522">
                                    <div class="article-summary-box-inner">
                                        <span>A common assumption in machine learning is that samples are independently and
identically distributed (i.i.d). However, the contributions of different
samples are not identical in training. Some samples are difficult to learn and
some samples are noisy. The unequal contributions of samples has a considerable
effect on training performances. Studies focusing on unequal sample
contributions (e.g., easy, hard, noisy) in learning usually refer to these
contributions as robust machine learning (RML). Weighing and regularization are
two common techniques in RML. Numerous learning algorithms have been proposed
but the strategies for dealing with easy/hard/noisy samples differ or even
contradict with different learning algorithms. For example, some strategies
take the hard samples first, whereas some strategies take easy first.
Conducting a clear comparison for existing RML algorithms in dealing with
different samples is difficult due to lack of a unified theoretical framework
for RML. This study attempts to construct a mathematical foundation for RML
based on the bias-variance trade-off theory. A series of definitions and
properties are presented and proved. Several classical learning algorithms are
also explained and compared. Improvements of existing methods are obtained
based on the comparison. A unified method that combines two classical learning
strategies is proposed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Medical Segmentation Decathlon. (arXiv:2106.05735v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonelli_M/0/1/0/all/0/1">Michela Antonelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Reinke_A/0/1/0/all/0/1">Annika Reinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1">Spyridon Bakas</a>, <a href="http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1">Keyvan Farahani</a>, <a href="http://arxiv.org/find/cs/1/au:+AnnetteKopp-Schneider/0/1/0/all/0/1">AnnetteKopp-Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>, <a href="http://arxiv.org/find/cs/1/au:+Litjens_G/0/1/0/all/0/1">Geert Litjens</a>, <a href="http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1">Bjoern Menze</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1">Olaf Ronneberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1">Ronald M.Summers</a>, <a href="http://arxiv.org/find/cs/1/au:+Ginneken_B/0/1/0/all/0/1">Bram van Ginneken</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1">Michel Bilello</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilic_P/0/1/0/all/0/1">Patrick Bilic</a>, <a href="http://arxiv.org/find/cs/1/au:+Christ_P/0/1/0/all/0/1">Patrick F. Christ</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_R/0/1/0/all/0/1">Richard K. G. Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Gollub_M/0/1/0/all/0/1">Marc J. Gollub</a>, <a href="http://arxiv.org/find/cs/1/au:+Heckers_S/0/1/0/all/0/1">Stephan H. Heckers</a>, <a href="http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1">William R. Jarnagin</a>, <a href="http://arxiv.org/find/cs/1/au:+McHugo_M/0/1/0/all/0/1">Maureen K. McHugo</a>, <a href="http://arxiv.org/find/cs/1/au:+Napel_S/0/1/0/all/0/1">Sandy Napel</a>, <a href="http://arxiv.org/find/cs/1/au:+Pernicka_J/0/1/0/all/0/1">Jennifer S. Goli Pernicka</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhode_K/0/1/0/all/0/1">Kawal Rhode</a>, <a href="http://arxiv.org/find/cs/1/au:+Tobon_Gomez_C/0/1/0/all/0/1">Catalina Tobon-Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Meakin_J/0/1/0/all/0/1">James A. Meakin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiesenfarth_M/0/1/0/all/0/1">Manuel Wiesenfarth</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bae_B/0/1/0/all/0/1">Byeonguk Bae</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sihong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1">Laura Daza</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianjiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1">Baochun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yuanfeng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1">Fucang Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Namkug Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_I/0/1/0/all/0/1">Ildoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Merhof_D/0/1/0/all/0/1">Dorit Merhof</a>, <a href="http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1">Akshay Pai</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1">Beomhee Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Perslev_M/0/1/0/all/0/1">Mathias Perslev</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaiifar_R/0/1/0/all/0/1">Ramin Rezaiifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rippel_O/0/1/0/all/0/1">Oliver Rippel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarasua_I/0/1/0/all/0/1">Ignacio Sarasua</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1">Jaemin Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachinger_C/0/1/0/all/0/1">Christian Wachinger</a>, et al. (9 additional authors not shown)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05735">
                                    <div class="article-summary-box-inner">
                                        <span>International challenges have become the de facto standard for comparative
assessment of image analysis algorithms given a specific task. Segmentation is
so far the most widely investigated medical image processing task, but the
various segmentation challenges have typically been organized in isolation,
such that algorithm development was driven by the need to tackle a single
specific clinical problem. We hypothesized that a method capable of performing
well on multiple tasks will generalize well to a previously unseen task and
potentially outperform a custom-designed solution. To investigate the
hypothesis, we organized the Medical Segmentation Decathlon (MSD) - a
biomedical image analysis challenge, in which algorithms compete in a multitude
of both tasks and modalities. The underlying data set was designed to explore
the axis of difficulties typically encountered when dealing with medical
images, such as small data sets, unbalanced labels, multi-site data and small
objects. The MSD challenge confirmed that algorithms with a consistent good
performance on a set of tasks preserved their good average performance on a
different set of previously unseen tasks. Moreover, by monitoring the MSD
winner for two years, we found that this algorithm continued generalizing well
to a wide range of other clinical problems, further confirming our hypothesis.
Three main conclusions can be drawn from this study: (1) state-of-the-art image
segmentation algorithms are mature, accurate, and generalize well when
retrained on unseen tasks; (2) consistent algorithmic performance across
multiple tasks is a strong surrogate of algorithmic generalizability; (3) the
training of accurate AI segmentation models is now commoditized to non AI
experts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simplifying Deep Reinforcement Learning via Self-Supervision. (arXiv:2106.05526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1">Daochen Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_K/0/1/0/all/0/1">Kwei-Herng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaixiong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05526">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised regression to demonstrations has been demonstrated to be a stable
way to train deep policy networks. We are motivated to study how we can take
full advantage of supervised loss functions for stably training deep
reinforcement learning agents. This is a challenging task because it is unclear
how the training data could be collected to enable policy improvement. In this
work, we propose Self-Supervised Reinforcement Learning (SSRL), a simple
algorithm that optimizes policies with purely supervised losses. We demonstrate
that, without policy gradient or value estimation, an iterative procedure of
&#x60;&#x60;labeling&quot; data and supervised regression is sufficient to drive stable policy
improvement. By selecting and imitating trajectories with high episodic
rewards, SSRL is surprisingly competitive to contemporary algorithms with more
stable performance and less running time, showing the potential of solving
reinforcement learning with supervised learning techniques. The code is
available at https://github.com/daochenzha/SSRL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mode recovery in neural autoregressive sequence modeling. (arXiv:2106.05459v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kulikov_I/0/1/0/all/0/1">Ilia Kulikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1">Sean Welleck</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05459">
                                    <div class="article-summary-box-inner">
                                        <span>Despite its wide use, recent studies have revealed unexpected and undesirable
properties of neural autoregressive sequence models trained with maximum
likelihood, such as an unreasonably high affinity to short sequences after
training and to infinitely long sequences at decoding time. We propose to study
these phenomena by investigating how the modes, or local maxima, of a
distribution are maintained throughout the full learning chain of the
ground-truth, empirical, learned and decoding-induced distributions, via the
newly proposed mode recovery cost. We design a tractable testbed where we build
three types of ground-truth distributions: (1) an LSTM based structured
distribution, (2) an unstructured distribution where probability of a sequence
does not depend on its content, and (3) a product of these two which we call a
semi-structured distribution. Our study reveals both expected and unexpected
findings. First, starting with data collection, mode recovery cost strongly
relies on the ground-truth distribution and is most costly with the
semi-structured distribution. Second, after learning, mode recovery cost from
the ground-truth distribution may increase or decrease compared to data
collection, with the largest cost degradation occurring with the
semi-structured ground-truth distribution. Finally, the ability of the
decoding-induced distribution to recover modes from the learned distribution is
highly impacted by the choices made earlier in the learning chain. We conclude
that future research must consider the entire learning chain in order to fully
understand the potentials and perils and to further improve neural
autoregressive sequence models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Landmark and Structure Learning for Automatic Evaluation of Developmental Dysplasia of the Hip. (arXiv:2106.05458v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xindi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Limin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wufeng Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shengfeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuhao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shuangping Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_N/0/1/0/all/0/1">Ning Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_D/0/1/0/all/0/1">Dong Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1">Ning Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05458">
                                    <div class="article-summary-box-inner">
                                        <span>The ultrasound (US) screening of the infant hip is vital for the early
diagnosis of developmental dysplasia of the hip (DDH). The US diagnosis of DDH
refers to measuring alpha and beta angles that quantify hip joint development.
These two angles are calculated from key anatomical landmarks and structures of
the hip. However, this measurement process is not trivial for sonographers and
usually requires a thorough understanding of complex anatomical structures. In
this study, we propose a multi-task framework to learn the relationships among
landmarks and structures jointly and automatically evaluate DDH. Our multi-task
networks are equipped with three novel modules. Firstly, we adopt Mask R-CNN as
the basic framework to detect and segment key anatomical structures and add one
landmark detection branch to form a new multi-task framework. Secondly, we
propose a novel shape similarity loss to refine the incomplete anatomical
structure prediction robustly and accurately. Thirdly, we further incorporate
the landmark-structure consistent prior to ensure the consistency of the bony
rim estimated from the segmented structure and the detected landmark. In our
experiments, 1,231 US images of the infant hip from 632 patients are collected,
of which 247 images from 126 patients are tested. The average errors in alpha
and beta angles are 2.221 degrees and 2.899 degrees. About 93% and 85%
estimates of alpha and beta angles have errors less than 5 degrees,
respectively. Experimental results demonstrate that the proposed method can
accurately and robustly realize the automatic evaluation of DDH, showing great
potential for clinical application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DUET: Detection Utilizing Enhancement for Text in Scanned or Captured Documents. (arXiv:2106.05542v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1">Eun-Soo Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_H/0/1/0/all/0/1">HyeongGwan Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_K/0/1/0/all/0/1">Kyusam Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_Y/0/1/0/all/0/1">Yongkeun Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1">Soonhwan Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Min Soo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05542">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel deep neural model for text detection in document images.
For robust text detection in noisy scanned documents, the advantages of
multi-task learning are adopted by adding an auxiliary task of text
enhancement. Namely, our proposed model is designed to perform noise reduction
and text region enhancement as well as text detection. Moreover, we enrich the
training data for the model with synthesized document images that are fully
labeled for text detection and enhancement, thus overcome the insufficiency of
labeled document image data. For the effective exploitation of the synthetic
and real data, the training process is separated in two phases. The first phase
is training only synthetic data in a fully-supervised manner. Then real data
with only detection labels are added in the second phase. The enhancement task
for the real data is weakly-supervised with information from their detection
labels. Our methods are demonstrated in a real document dataset with
performances exceeding those of other text detection methods. Moreover,
ablations are conducted and the results confirm the effectiveness of the
synthetic data, auxiliary task, and weak-supervision. Whereas the existing text
detection studies mostly focus on the text in scenes, our proposed method is
optimized to the applications for the text in scanned documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Space-time Mixing Attention for Video Transformer. (arXiv:2106.05968v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bulat_A/0/1/0/all/0/1">Adrian Bulat</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Rua_J/0/1/0/all/0/1">Juan-Manuel Perez-Rua</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1">Swathikiran Sudhakaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1">Brais Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1">Georgios Tzimiropoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05968">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is on video recognition using Transformers. Very recent attempts
in this area have demonstrated promising results in terms of recognition
accuracy, yet they have been also shown to induce, in many cases, significant
computational overheads due to the additional modelling of the temporal
information. In this work, we propose a Video Transformer model the complexity
of which scales linearly with the number of frames in the video sequence and
hence induces \textit{no overhead} compared to an image-based Transformer
model. To achieve this, our model makes two approximations to the full
space-time attention used in Video Transformers: (a) It restricts time
attention to a local temporal window and capitalizes on the Transformer&#x27;s depth
to obtain full temporal coverage of the video sequence. (b) It uses efficient
space-time mixing to attend \textit{jointly} spatial and temporal locations
without inducing any additional cost on top of a spatial-only attention model.
We also show how to integrate 2 very lightweight mechanisms for global
temporal-only attention which provide additional accuracy improvements at
minimal computational cost. We demonstrate that our model produces very high
recognition accuracy on the most popular video recognition datasets while at
the same time being significantly more efficient than other Video Transformer
models. Code will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Interpretable Neural Network for Parameter Inference. (arXiv:2106.05536v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pfitzinger_J/0/1/0/all/0/1">Johann Pfitzinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05536">
                                    <div class="article-summary-box-inner">
                                        <span>Adoption of deep neural networks in fields such as economics or finance has
been constrained by the lack of interpretability of model outcomes. This paper
proposes a generative neural network architecture - the parameter encoder
neural network (PENN) - capable of estimating local posterior distributions for
the parameters of a regression model. The parameters fully explain predictions
in terms of the inputs and permit visualization, interpretation and inference
in the presence of complex heterogeneous effects and feature dependencies. The
use of Bayesian inference techniques offers an intuitive mechanism to
regularize local parameter estimates towards a stable solution, and to reduce
noise-fitting in settings of limited data availability. The proposed neural
network is particularly well-suited to applications in economics and finance,
where parameter inference plays an important role. An application to an asset
pricing problem demonstrates how the PENN can be used to explore nonlinear risk
dynamics in financial markets, and to compare empirical nonlinear effects to
behavior posited by financial theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributionally Robust Prescriptive Analytics with Wasserstein Distance. (arXiv:2106.05724v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wang_T/0/1/0/all/0/1">Tianyu Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_N/0/1/0/all/0/1">Ningyuan Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_C/0/1/0/all/0/1">Chun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05724">
                                    <div class="article-summary-box-inner">
                                        <span>In prescriptive analytics, the decision-maker observes historical samples of
$(X, Y)$, where $Y$ is the uncertain problem parameter and $X$ is the
concurrent covariate, without knowing the joint distribution. Given an
additional covariate observation $x$, the goal is to choose a decision $z$
conditional on this observation to minimize the cost $\mathbb{E}[c(z,Y)|X&#x3D;x]$.
This paper proposes a new distributionally robust approach under Wasserstein
ambiguity sets, in which the nominal distribution of $Y|X&#x3D;x$ is constructed
based on the Nadaraya-Watson kernel estimator concerning the historical data.
We show that the nominal distribution converges to the actual conditional
distribution under the Wasserstein distance. We establish the out-of-sample
guarantees and the computational tractability of the framework. Through
synthetic and empirical experiments about the newsvendor problem and portfolio
optimization, we demonstrate the strong performance and practical value of the
proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score Matching Model for Unbounded Data Score. (arXiv:2106.05527v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dongjun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seungjae Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1">Kyungwoo Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1">Wanmo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_I/0/1/0/all/0/1">Il-Chul Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05527">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advance in score-based models incorporates the stochastic differential
equation (SDE), which brings the state-of-the art performance on image
generation tasks. This paper improves such score-based models by analyzing the
model at the zero perturbation noise. In real datasets, the score function
diverges as the perturbation noise ($\sigma$) decreases to zero, and this
observation leads an argument that the score estimation fails at $\sigma&#x3D;0$
with any neural network structure. Subsequently, we introduce Unbounded Noise
Conditional Score Network (UNCSN) that resolves the score diverging problem
with an easily applicable modification to any noise conditional score-based
models. Additionally, we introduce a new type of SDE, so the exact log
likelihood can be calculated from the newly suggested SDE. On top of that, the
associated loss function mitigates the loss imbalance issue in a mini-batch,
and we present a theoretic analysis on the proposed loss to uncover the behind
mechanism of the data distribution modeling by the score-based models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Variational Approach to Clustering Survival Data. (arXiv:2106.05763v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Manduchi_L/0/1/0/all/0/1">Laura Manduchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcinkevics_R/0/1/0/all/0/1">Ri&#x10d;ards Marcinkevi&#x10d;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Massi_M/0/1/0/all/0/1">Michela C. Massi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gotta_V/0/1/0/all/0/1">Verena Gotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1">Timothy M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasella_F/0/1/0/all/0/1">Flavio Vasella</a>, <a href="http://arxiv.org/find/cs/1/au:+Neidert_M/0/1/0/all/0/1">Marian C. Neidert</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_M/0/1/0/all/0/1">Marc Pfister</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1">Julia E. Vogt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05763">
                                    <div class="article-summary-box-inner">
                                        <span>Survival analysis has gained significant attention in the medical domain and
has many far-reaching applications. Although a variety of machine learning
methods have been introduced for tackling time-to-event prediction in
unstructured data with complex dependencies, clustering of survival data
remains an under-explored problem. The latter is particularly helpful in
discovering patient subpopulations whose survival is regulated by different
generative mechanisms, a critical problem in precision medicine. To this end,
we introduce a novel probabilistic approach to cluster survival data in a
variational deep clustering setting. Our proposed method employs a deep
generative model to uncover the underlying distribution of both the explanatory
variables and the potentially censored survival times. We compare our model to
the related work on survival clustering in comprehensive experiments on a range
of synthetic, semi-synthetic, and real-world datasets. Our proposed method
performs better at identifying clusters and is competitive at predicting
survival times in terms of the concordance index and relative absolute error.
To further demonstrate the usefulness of our approach, we show that our method
identifies meaningful clusters from an observational cohort of hemodialysis
patients that are consistent with previous clinical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Option-Aware Hierarchical Imitation Learning. (arXiv:2106.05530v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jing_M/0/1/0/all/0/1">Mingxuan Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenbing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1">Fuchun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiaojian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1">Tao Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05530">
                                    <div class="article-summary-box-inner">
                                        <span>It has been a challenge to learning skills for an agent from long-horizon
unannotated demonstrations. Existing approaches like Hierarchical Imitation
Learning(HIL) are prone to compounding errors or suboptimal solutions. In this
paper, we propose Option-GAIL, a novel method to learn skills at long horizon.
The key idea of Option-GAIL is modeling the task hierarchy by options and train
the policy via generative adversarial optimization. In particular, we propose
an Expectation-Maximization(EM)-style algorithm: an E-step that samples the
options of expert conditioned on the current learned policy, and an M-step that
updates the low- and high-level policies of agent simultaneously to minimize
the newly proposed option-occupancy measurement between the expert and the
agent. We theoretically prove the convergence of the proposed algorithm.
Experiments show that Option-GAIL outperforms other counterparts consistently
across a variety of tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards an Automated Pipeline for Detecting and Classifying Malware through Machine Learning. (arXiv:2106.05625v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loi_N/0/1/0/all/0/1">Nicola Loi</a>, <a href="http://arxiv.org/find/cs/1/au:+Borile_C/0/1/0/all/0/1">Claudio Borile</a>, <a href="http://arxiv.org/find/cs/1/au:+Ucci_D/0/1/0/all/0/1">Daniele Ucci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05625">
                                    <div class="article-summary-box-inner">
                                        <span>The constant growth in the number of malware - software or code fragment
potentially harmful for computers and information networks - and the use of
sophisticated evasion and obfuscation techniques have seriously hindered
classic signature-based approaches. On the other hand, malware detection
systems based on machine learning techniques started offering a promising
alternative to standard approaches, drastically reducing analysis time and
turning out to be more robust against evasion and obfuscation techniques. In
this paper, we propose a malware taxonomic classification pipeline able to
classify Windows Portable Executable files (PEs). Given an input PE sample, it
is first classified as either malicious or benign. If malicious, the pipeline
further analyzes it in order to establish its threat type, family, and
behavior(s). We tested the proposed pipeline on the open source dataset EMBER,
containing approximately 1 million PE samples, analyzed through static
analysis. Obtained malware detection results are comparable to other academic
works in the current state of art and, in addition, we provide an in-depth
classification of malicious samples. Models used in the pipeline provides
interpretable results which can help security analysts in better understanding
decisions taken by the automated pipeline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Dimensional Structure in the Space of Language Representations is Reflected in Brain Responses. (arXiv:2106.05426v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1">Richard Antonello</a>, <a href="http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1">Javier Turek</a>, <a href="http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1">Vy Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1">Alexander Huth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05426">
                                    <div class="article-summary-box-inner">
                                        <span>How related are the representations learned by neural language models,
translation models, and language tagging tasks? We answer this question by
adapting an encoder-decoder transfer learning method from computer vision to
investigate the structure among 100 different feature spaces extracted from
hidden representations of various networks trained on language tasks. This
method reveals a low-dimensional structure where language models and
translation models smoothly interpolate between word embeddings, syntactic and
semantic tasks, and future word embeddings. We call this low-dimensional
structure a language representation embedding because it encodes the
relationships between representations needed to process language for a variety
of NLP tasks. We find that this representation embedding can predict how well
each individual feature space maps to human brain responses to natural language
stimuli recorded using fMRI. Additionally, we find that the principal dimension
of this structure can be used to create a metric which highlights the brain&#x27;s
natural language processing hierarchy. This suggests that the embedding
captures some part of the brain&#x27;s natural language representation structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Extraction for Novelty Detection in Network Traffic. (arXiv:2006.16993v2 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kpotufe_S/0/1/0/all/0/1">Samory Kpotufe</a>, <a href="http://arxiv.org/find/cs/1/au:+Feamster_N/0/1/0/all/0/1">Nick Feamster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16993">
                                    <div class="article-summary-box-inner">
                                        <span>Data representation plays a critical role in the performance of novelty
detection (or &#x60;&#x60;anomaly detection&#x27;&#x27;) methods in machine learning. The data
representation of network traffic often determines the effectiveness of these
models as much as the model itself. The wide range of novel events that network
operators need to detect (e.g., attacks, malware, new applications, changes in
traffic demands) introduces the possibility for a broad range of possible
models and data representations. In each scenario, practitioners must spend
significant effort extracting and engineering features that are most predictive
for that situation or application. While anomaly detection is well-studied in
computer networking, much existing work develops specific models that presume a
particular representation -- often IPFIX/NetFlow. Yet, other representations
may result in higher model accuracy, and the rise of programmable networks now
makes it more practical to explore a broader range of representations. To
facilitate such exploration, we develop a systematic framework, open-source
toolkit, and public Python library that makes it both possible and easy to
extract and generate features from network traffic and perform and end-to-end
evaluation of these representations across most prevalent modern novelty
detection models. We first develop and publicly release an open-source tool, an
accompanying Python library (NetML), and end-to-end pipeline for novelty
detection in network traffic. Second, we apply this tool to five different
novelty detection problems in networking, across a range of scenarios from
attack detection to novel device detection. Our findings general insights and
guidelines concerning which features appear to be more appropriate for
particular situations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning for Symbolic Hyperparameter Defaults. (arXiv:2106.05767v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gijsbers_P/0/1/0/all/0/1">Pieter Gijsbers</a>, <a href="http://arxiv.org/find/stat/1/au:+Pfisterer_F/0/1/0/all/0/1">Florian Pfisterer</a>, <a href="http://arxiv.org/find/stat/1/au:+Rijn_J/0/1/0/all/0/1">Jan N. van Rijn</a>, <a href="http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1">Bernd Bischl</a>, <a href="http://arxiv.org/find/stat/1/au:+Vanschoren_J/0/1/0/all/0/1">Joaquin Vanschoren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05767">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperparameter optimization in machine learning (ML) deals with the problem
of empirically learning an optimal algorithm configuration from data, usually
formulated as a black-box optimization problem. In this work, we propose a
zero-shot method to meta-learn symbolic default hyperparameter configurations
that are expressed in terms of the properties of the dataset. This enables a
much faster, but still data-dependent, configuration of the ML algorithm,
compared to standard hyperparameter optimization approaches. In the past,
symbolic and static default values have usually been obtained as hand-crafted
heuristics. We propose an approach of learning such symbolic configurations as
formulas of dataset properties from a large set of prior evaluations on
multiple datasets by optimizing over a grammar of expressions using an
evolutionary algorithm. We evaluate our method on surrogate empirical
performance models as well as on real data across 6 ML algorithms on more than
100 datasets and demonstrate that our method indeed finds viable symbolic
defaults.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Framework for Task-Driven Data Quality Management. (arXiv:2106.05484v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1">Yi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Ming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Ruoxi Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05484">
                                    <div class="article-summary-box-inner">
                                        <span>High-quality data is critical to train performant Machine Learning (ML)
models, highlighting the importance of Data Quality Management (DQM). Existing
DQM schemes often cannot satisfactorily improve ML performance because, by
design, they are oblivious to downstream ML tasks. Besides, they cannot handle
various data quality issues (especially those caused by adversarial attacks)
and have limited applications to only certain types of ML models. Recently,
data valuation approaches (e.g., based on the Shapley value) have been
leveraged to perform DQM; yet, empirical studies have observed that their
performance varies considerably based on the underlying data and training
process. In this paper, we propose a task-driven, multi-purpose, model-agnostic
DQM framework, DataSifter, which is optimized towards a given downstream ML
task, capable of effectively removing data points with various defects, and
applicable to diverse models. Specifically, we formulate DQM as an optimization
problem and devise a scalable algorithm to solve it. Furthermore, we propose a
theoretical framework for comparing the worst-case performance of different DQM
strategies. Remarkably, our results show that the popular strategy based on the
Shapley value may end up choosing the worst data subset in certain practical
scenarios. Our evaluation shows that DataSifter achieves and most often
significantly improves the state-of-the-art performance over a wide range of
DQM tasks, including backdoor, poison, noisy/mislabel data detection, data
summarization, and data debiasing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Nonparametric Volterra Kernels with Gaussian Processes. (arXiv:2106.05582v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ross_M/0/1/0/all/0/1">Magnus Ross</a>, <a href="http://arxiv.org/find/stat/1/au:+Smith_M/0/1/0/all/0/1">Michael T. Smith</a>, <a href="http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1">Mauricio A. &#xc1;lvarez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05582">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a method for the nonparametric Bayesian learning of
nonlinear operators, through the use of the Volterra series with kernels
represented using Gaussian processes (GPs), which we term the nonparametric
Volterra kernels model (NVKM). When the input function to the operator is
unobserved and has a GP prior, the NVKM constitutes a powerful method for both
single and multiple output regression, and can be viewed as a nonlinear and
nonparametric latent force model. When the input function is observed, the NVKM
can be used to perform Bayesian system identification. We use recent advances
in efficient sampling of explicit functions from GPs to map process
realisations through the Volterra series without resorting to numerical
integration, allowing scalability through doubly stochastic variational
inference, and avoiding the need for Gaussian approximations of the output
processes. We demonstrate the performance of the model for both multiple output
regression and system identification using standard benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Neural Tangent Kernel Perspective of GANs. (arXiv:2106.05566v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Franceschi_J/0/1/0/all/0/1">Jean-Yves Franceschi</a> (MLIA), <a href="http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1">Emmanuel de B&#xe9;zenac</a> (MLIA), <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ibrahim Ayed</a> (MLIA), <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Micka&#xeb;l Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1">Sylvain Lamprier</a> (MLIA), <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a> (MLIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05566">
                                    <div class="article-summary-box-inner">
                                        <span>Theoretical analyses for Generative Adversarial Networks (GANs) generally
assume an arbitrarily large family of discriminators and do not consider the
characteristics of the architectures used in practice. We show that this
framework of analysis is too simplistic to properly analyze GAN training. To
tackle this issue, we leverage the theory of infinite-width neural networks to
model neural discriminator training for a wide range of adversarial losses via
its Neural Tangent Kernel (NTK). Our analytical results show that GAN
trainability primarily depends on the discriminator&#x27;s architecture. We further
study the discriminator for specific architectures and losses, and highlight
properties providing a new understanding of GAN training. For example, we find
that GANs trained with the integral probability metric loss minimize the
maximum mean discrepancy with the NTK as kernel. Our conclusions demonstrate
the analysis opportunities provided by the proposed framework, which paves the
way for better and more principled GAN models. We release a generic GAN
analysis toolkit based on our framework that supports the empirical part of our
study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Self-Supervised Learning for Graphs. (arXiv:2106.05470v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Wei Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiangyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Neil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05470">
                                    <div class="article-summary-box-inner">
                                        <span>Graph self-supervised learning has gained increasing attention due to its
capacity to learn expressive node representations. Many pretext tasks, or loss
functions have been designed from distinct perspectives. However, we observe
that different pretext tasks affect downstream tasks differently cross
datasets, which suggests that searching pretext tasks is crucial for graph
self-supervised learning. Different from existing works focusing on designing
single pretext tasks, this work aims to investigate how to automatically
leverage multiple pretext tasks effectively. Nevertheless, evaluating
representations derived from multiple pretext tasks without direct access to
ground truth labels makes this problem challenging. To address this obstacle,
we make use of a key principle of many real-world graphs, i.e., homophily, or
the principle that &#x60;&#x60;like attracts like,&#x27;&#x27; as the guidance to effectively
search various self-supervised pretext tasks. We provide theoretical
understanding and empirical evidence to justify the flexibility of homophily in
this search task. Then we propose the AutoSSL framework which can automatically
search over combinations of various self-supervised tasks. By evaluating the
framework on 7 real-world datasets, our experimental results show that AutoSSL
can significantly boost the performance on downstream tasks including node
clustering and node classification compared with training under individual
tasks. Code will be released at https://github.com/ChandlerBang/AutoSSL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspace Neighbor Penetration Approach to Dynamic Programming for Model-Based Reinforcement Learning Problems with Slowly Changing Variables in A Continuous State Space. (arXiv:2106.05497v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zha_V/0/1/0/all/0/1">Vincent Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_I/0/1/0/all/0/1">Ivey Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guilbault_A/0/1/0/all/0/1">Alexandre Guilbault</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatis_J/0/1/0/all/0/1">Jaime Tatis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05497">
                                    <div class="article-summary-box-inner">
                                        <span>Slowly changing variables in a continuous state space constitute an important
category of reinforcement learning and see its application in many domains,
such as modeling a climate control system where temperature, humidity, etc.
change slowly over time. However, this subject is less addressed in recent
studies. Classical methods with certain variants, such as Dynamic Programming
with Tile Coding which discretizes the state space, fail to handle slowly
changing variables because those methods cannot capture the tiny changes in
each transition step, as it is computationally expensive or impossible to
establish an extremely granular grid system. In this paper, we introduce a
Hyperspace Neighbor Penetration (HNP) approach that solves the problem. HNP
captures in each transition step the state&#x27;s partial &quot;penetration&quot; into its
neighboring hyper-tiles in the gridded hyperspace, thus does not require the
transition to be inter-tile in order for the change to be captured. Therefore,
HNP allows for a very coarse grid system, which makes the computation feasible.
HNP assumes near linearity of the transition function in a local space, which
is commonly satisfied. In summary, HNP can be orders of magnitude more
efficient than classical method in handling slowly changing variables in
reinforcement learning. We have made an industrial implementation of NHP with a
great success.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end lung nodule detection framework with model-based feature projection block. (arXiv:2106.05741v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drokin_I/0/1/0/all/0/1">Ivan Drokin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ericheva_E/0/1/0/all/0/1">Elena Ericheva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05741">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes novel end-to-end framework for detecting suspicious
pulmonary nodules in chest CT scans. The method core idea is a new nodule
segmentation architecture with a model-based feature projection block on
three-dimensional convolutions. This block acts as a preliminary feature
extractor for a two-dimensional U-Net-like convolutional network. Using the
proposed approach along with an axial, coronal, and sagittal projection
analysis makes it possible to abandon the widely used false positives reduction
step. The proposed method achieves SOTA on LUNA2016 with 0.959 average
sensitivity, and 0.936 sensitivity if the false-positive level per scan is
0.25. The paper describes the proposed approach and represents the experimental
results on LUNA2016 as well as ablation studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Symbiosis Learning. (arXiv:2106.05455v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1">Liang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zijun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yanqiao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05455">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a framework for learning from multiple generated graph views,
named graph symbiosis learning (GraphSym). In GraphSym, graph neural networks
(GNN) developed in multiple generated graph views can adaptively exchange
parameters with each other and fuse information stored in linkage structures
and node features. Specifically, we propose a novel adaptive exchange method to
iteratively substitute redundant channels in the weight matrix of one GNN with
informative channels of another GNN in a layer-by-layer manner. GraphSym does
not rely on specific methods to generate multiple graph views and GNN
architectures. Thus, existing GNNs can be seamlessly integrated into our
framework. On 3 semi-supervised node classification datasets, GraphSym
outperforms previous single-graph and multiple-graph GNNs without knowledge
distillation, and achieves new state-of-the-art results. We also conduct a
series of experiments on 15 public benchmarks, 8 popular GNN models, and 3
graph tasks -- node classification, graph classification, and edge prediction
-- and show that GraphSym consistently achieves better performance than
existing popular GNNs by 1.9\%$\sim$3.9\% on average and their ensembles.
Extensive ablation studies and experiments on the few-shot setting also
demonstrate the effectiveness of GraphSym.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Quadrature on Riemannian Data Manifolds. (arXiv:2102.06645v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frohlich_C/0/1/0/all/0/1">Christian Fr&#xf6;hlich</a>, <a href="http://arxiv.org/find/cs/1/au:+Gessner_A/0/1/0/all/0/1">Alexandra Gessner</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1">Georgios Arvanitidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06645">
                                    <div class="article-summary-box-inner">
                                        <span>Riemannian manifolds provide a principled way to model nonlinear geometric
structure inherent in data. A Riemannian metric on said manifolds determines
geometry-aware shortest paths and provides the means to define statistical
models accordingly. However, these operations are typically computationally
demanding. To ease this computational burden, we advocate probabilistic
numerical methods for Riemannian statistics. In particular, we focus on
Bayesian quadrature (BQ) to numerically compute integrals over normal laws on
Riemannian manifolds learned from data. In this task, each function evaluation
relies on the solution of an expensive initial value problem. We show that by
leveraging both prior knowledge and an active exploration scheme, BQ
significantly reduces the number of required evaluations and thus outperforms
Monte Carlo methods on a wide range of integration problems. As a concrete
application, we highlight the merits of adopting Riemannian geometry with our
proposed framework on a nonlinear dataset from molecular dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Front Contribution instead of Back Propagation. (arXiv:2106.05569v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1">Anjana Arunkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05569">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning&#x27;s outstanding track record across several domains has stemmed
from the use of error backpropagation (BP). Several studies, however, have
shown that it is impossible to execute BP in a real brain. Also, BP still
serves as an important and unsolved bottleneck for memory usage and speed. We
propose a simple, novel algorithm, the Front-Contribution algorithm, as a
compact alternative to BP. The contributions of all weights with respect to the
final layer weights are calculated before training commences and all the
contributions are appended to weights of the final layer, i.e., the effective
final layer weights are a non-linear function of themselves. Our algorithm then
essentially collapses the network, precluding the necessity for weight updation
of all weights not in the final layer. This reduction in parameters results in
lower memory usage and higher training speed. We show that our algorithm
produces the exact same output as BP, in contrast to several recently proposed
algorithms approximating BP. Our preliminary experiments demonstrate the
efficacy of the proposed algorithm. Our work provides a foundation to
effectively utilize these presently under-explored &quot;front contributions&quot;, and
serves to inspire the next generation of training algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Brittle AI, Causal Confusion, and Bad Mental Models: Challenges and Successes in the XAI Program. (arXiv:2106.05506v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Druce_J/0/1/0/all/0/1">Jeff Druce</a>, <a href="http://arxiv.org/find/cs/1/au:+Niehaus_J/0/1/0/all/0/1">James Niehaus</a>, <a href="http://arxiv.org/find/cs/1/au:+Moody_V/0/1/0/all/0/1">Vanessa Moody</a>, <a href="http://arxiv.org/find/cs/1/au:+Jensen_D/0/1/0/all/0/1">David Jensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1">Michael L. Littman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05506">
                                    <div class="article-summary-box-inner">
                                        <span>The advances in artificial intelligence enabled by deep learning
architectures are undeniable. In several cases, deep neural network driven
models have surpassed human level performance in benchmark autonomy tasks. The
underlying policies for these agents, however, are not easily interpretable. In
fact, given their underlying deep models, it is impossible to directly
understand the mapping from observations to actions for any reasonably complex
agent. Producing this supporting technology to &quot;open the black box&quot; of these AI
systems, while not sacrificing performance, was the fundamental goal of the
DARPA XAI program. In our journey through this program, we have several &quot;big
picture&quot; takeaways: 1) Explanations need to be highly tailored to their
scenario; 2) many seemingly high performing RL agents are extremely brittle and
are not amendable to explanation; 3) causal models allow for rich explanations,
but how to present them isn&#x27;t always straightforward; and 4) human subjects
conjure fantastically wrong mental models for AIs, and these models are often
hard to break. This paper discusses the origins of these takeaways, provides
amplifying information, and suggestions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vertical Federated Learning without Revealing Intersection Membership. (arXiv:2106.05508v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiankai Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuanshun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aonan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Weihao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Junyuan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05508">
                                    <div class="article-summary-box-inner">
                                        <span>Vertical Federated Learning (vFL) allows multiple parties that own different
attributes (e.g. features and labels) of the same data entity (e.g. a person)
to jointly train a model. To prepare the training data, vFL needs to identify
the common data entities shared by all parties. It is usually achieved by
Private Set Intersection (PSI) which identifies the intersection of training
samples from all parties by using personal identifiable information (e.g.
email) as sample IDs to align data instances. As a result, PSI would make
sample IDs of the intersection visible to all parties, and therefore each party
can know that the data entities shown in the intersection also appear in the
other parties, i.e. intersection membership. However, in many real-world
privacy-sensitive organizations, e.g. banks and hospitals, revealing membership
of their data entities is prohibited. In this paper, we propose a vFL framework
based on Private Set Union (PSU) that allows each party to keep sensitive
membership information to itself. Instead of identifying the intersection of
all training samples, our PSU protocol generates the union of samples as
training instances. In addition, we propose strategies to generate synthetic
features and labels to handle samples that belong to the union but not the
intersection. Through extensive experiments on two real-world datasets, we show
our framework can protect the privacy of the intersection membership while
maintaining the model utility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ERMAS: Becoming Robust to Reward Function Sim-to-Real Gaps in Multi-Agent Simulations. (arXiv:2106.05492v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_E/0/1/0/all/0/1">Eric Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1">Alexander R. Trott</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Stephan Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05492">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-agent simulations provide a scalable environment for learning policies
that interact with rational agents. However, such policies may fail to
generalize to the real-world where agents may differ from simulated
counterparts due to unmodeled irrationality and misspecified reward functions.
We introduce Epsilon-Robust Multi-Agent Simulation (ERMAS), a robust
optimization framework for learning AI policies that are robust to such
multiagent sim-to-real gaps. While existing notions of multi-agent robustness
concern perturbations in the actions of agents, we address a novel robustness
objective concerning perturbations in the reward functions of agents. ERMAS
provides this robustness by anticipating suboptimal behaviors from other
agents, formalized as the worst-case epsilon-equilibrium. We show empirically
that ERMAS yields robust policies for repeated bimatrix games and optimal
taxation problems in economic simulations. In particular, in the two-level RL
problem posed by the AI Economist (Zheng et al., 2020) ERMAS learns tax
policies that are robust to changes in agent risk aversion, improving social
welfare by up to 15% in complex spatiotemporal simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-time integration of parametric evolution equations with physics-informed DeepONets. (arXiv:2106.05384v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1">Paris Perdikaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05384">
                                    <div class="article-summary-box-inner">
                                        <span>Ordinary and partial differential equations (ODEs/PDEs) play a paramount role
in analyzing and simulating complex dynamic processes across all corners of
science and engineering. In recent years machine learning tools are aspiring to
introduce new effective ways of simulating PDEs, however existing approaches
are not able to reliably return stable and accurate predictions across long
temporal horizons. We aim to address this challenge by introducing an effective
framework for learning infinite-dimensional operators that map random initial
conditions to associated PDE solutions within a short time interval. Such
latent operators can be parametrized by deep neural networks that are trained
in an entirely self-supervised manner without requiring any paired input-output
observations. Global long-time predictions across a range of initial conditions
can be then obtained by iteratively evaluating the trained model using each
prediction as the initial condition for the next evaluation step. This
introduces a new approach to temporal domain decomposition that is shown to be
effective in performing accurate long-time simulations for a wide range of
parametric ODE and PDE systems, from wave propagation, to reaction-diffusion
dynamics and stiff chemical kinetics, all at a fraction of the computational
cost needed by classical numerical solvers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Next-Gen Machine Learning Supported Diagnostic Systems for Spacecraft. (arXiv:2106.05659v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutherland_G/0/1/0/all/0/1">Gabriel Sutherland</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>, <a href="http://arxiv.org/find/cs/1/au:+Soboczenski_F/0/1/0/all/0/1">Frank Soboczenski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05659">
                                    <div class="article-summary-box-inner">
                                        <span>Future short or long-term space missions require a new generation of
monitoring and diagnostic systems due to communication impasses as well as
limitations in specialized crew and equipment. Machine learning supported
diagnostic systems present a viable solution for medical and technical
applications. We discuss challenges and applicability of such systems in light
of upcoming missions and outline an example use case for a next-generation
medical diagnostic system for future space operations. Additionally, we present
approach recommendations and constraints for the successful generation and use
of machine learning models aboard a spacecraft.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Robust LQR Layers. (arXiv:2106.05535v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1">Ngo Anh Vien</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05535">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a differentiable robust LQR layer for reinforcement
learning and imitation learning under model uncertainty and stochastic
dynamics. The robust LQR layer can exploit the advantages of robust optimal
control and model-free learning. It provides a new type of inductive bias for
stochasticity and uncertainty modeling in control systems. In particular, we
propose an efficient way to differentiate through a robust LQR optimization
program by rewriting it as a convex program (i.e. semi-definite program) of the
worst-case cost. Based on recent work on using convex optimization inside
neural network layers, we develop a fully differentiable layer for optimizing
this worst-case cost, i.e. we compute the derivative of a performance measure
w.r.t the model&#x27;s unknown parameters, model uncertainty and stochasticity
parameters. We demonstrate the proposed method on imitation learning and
approximate dynamic programming on stochastic and uncertain domains. The
experiment results show that the proposed method can optimize robust policies
under uncertain situations, and are able to achieve a significantly better
performance than existing methods that do not model uncertainty directly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Notion of Individually Fair Clustering: $\alpha$-Equitable $k$-Center. (arXiv:2106.05423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_D/0/1/0/all/0/1">Darshan Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John P. Dickerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Esmaeili_S/0/1/0/all/0/1">Seyed A. Esmaeili</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1">Aravind Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1">Leonidas Tsepenekas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05423">
                                    <div class="article-summary-box-inner">
                                        <span>Clustering is a fundamental problem in unsupervised machine learning, and
fair variants of it have recently received significant attention. In this work
we introduce a novel definition of fairness for clustering problems.
Specifically, in our model each point $j$ has a set of other points
$\mathcal{S}_j$ that it perceives as similar to itself, and it feels that it is
fairly treated, if the quality of service it receives in the solution is
$\alpha$-close to that of the points in $\mathcal{S}_j$. We begin our study by
answering questions regarding the structure of the problem, namely for what
values of $\alpha$ the problem is well-defined, and what the behavior of the
Price of Fairness (PoF) for it is. For the well-defined region of $\alpha$, we
provide efficient and easily implementable approximation algorithms for the
$k$-center objective, which in certain cases also enjoy bounded PoF guarantees.
We finally complement our analysis by an extensive suite of experiments that
validates the effectiveness of our theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Alternatives to the Root Mean Square for Adaptive Gradient Methods. (arXiv:2106.05449v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daley_B/0/1/0/all/0/1">Brett Daley</a>, <a href="http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1">Christopher Amato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05449">
                                    <div class="article-summary-box-inner">
                                        <span>Adam is an adaptive gradient method that has experienced widespread adoption
due to its fast and reliable training performance. Recent approaches have not
offered significant improvement over Adam, often because they do not innovate
upon one of its core features: normalization by the root mean square (RMS) of
recent gradients. However, as noted by Kingma and Ba (2015), any number of
$L^p$ normalizations are possible, with the RMS corresponding to the specific
case of $p&#x3D;2$. In our work, we theoretically and empirically characterize the
influence of different $L^p$ norms on adaptive gradient methods for the first
time. We show mathematically how the choice of $p$ influences the size of the
steps taken, while leaving other desirable properties unaffected. We evaluate
Adam with various $L^p$ norms on a suite of deep learning benchmarks, and find
that $p &gt; 2$ consistently leads to improved learning speed and final
performance. The choices of $p&#x3D;3$ or $p&#x3D;6$ also match or outperform
state-of-the-art methods in all of our experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Local Convergence of Quasi-Newton Methods Globally: Adaptive Sample Size Approach. (arXiv:2106.05445v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Jin_Q/0/1/0/all/0/1">Qiujiang Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1">Aryan Mokhtari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05445">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the application of quasi-Newton methods for solving
empirical risk minimization (ERM) problems defined over a large dataset.
Traditional deterministic and stochastic quasi-Newton methods can be executed
to solve such problems; however, it is known that their global convergence rate
may not be better than first-order methods, and their local superlinear
convergence only appears towards the end of the learning process. In this
paper, we use an adaptive sample size scheme that exploits the superlinear
convergence of quasi-Newton methods globally and throughout the entire learning
process. The main idea of the proposed adaptive sample size algorithms is to
start with a small subset of data points and solve their corresponding ERM
problem within its statistical accuracy, and then enlarge the sample size
geometrically and use the optimal solution of the problem corresponding to the
smaller set as an initial point for solving the subsequent ERM problem with
more samples. We show that if the initial sample size is sufficiently large and
we use quasi-Newton methods to solve each subproblem, the subproblems can be
solved superlinearly fast (after at most three iterations), as we guarantee
that the iterates always stay within a neighborhood that quasi-Newton methods
converge superlinearly. Numerical experiments on various datasets confirm our
theoretical results and demonstrate the computational advantages of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-VFL: A Vertical Federated Learning System for Multiple Data and Label Owners. (arXiv:2106.05468v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mugunthan_V/0/1/0/all/0/1">Vaikkunth Mugunthan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kagal_L/0/1/0/all/0/1">Lalana Kagal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05468">
                                    <div class="article-summary-box-inner">
                                        <span>Vertical Federated Learning (VFL) refers to the collaborative training of a
model on a dataset where the features of the dataset are split among multiple
data owners, while label information is owned by a single data owner. In this
paper, we propose a novel method, Multi Vertical Federated Learning
(Multi-VFL), to train VFL models when there are multiple data and label owners.
Our approach is the first to consider the setting where $D$-data owners (across
which features are distributed) and $K$-label owners (across which labels are
distributed) exist. This proposed configuration allows different entities to
train and learn optimal models without having to share their data. Our
framework makes use of split learning and adaptive federated optimizers to
solve this problem. For empirical evaluation, we run experiments on the MNIST
and FashionMNIST datasets. Our results show that using adaptive optimizers for
model aggregation fastens convergence and improves accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-domain Contrastive Learning for Unsupervised Domain Adaptation. (arXiv:2106.05528v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zuxuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_Z/0/1/0/all/0/1">Zejia Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingjing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1">Guo-Jun Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05528">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from
a fully-labeled source domain to a different unlabeled target domain. Most
existing UDA methods learn domain-invariant feature representations by
minimizing feature distances across domains. In this work, we build upon
contrastive self-supervised learning to align features so as to reduce the
domain discrepancy between training and testing sets. Exploring the same set of
categories shared by both domains, we introduce a simple yet effective
framework CDCL, for domain alignment. In particular, given an anchor image from
one domain, we minimize its distances to cross-domain samples from the same
class relative to those from different categories. Since target labels are
unavailable, we use a clustering-based approach with carefully initialized
centers to produce pseudo labels. In addition, we demonstrate that CDCL is a
general framework and can be adapted to the data-free setting, where the source
data are unavailable during training, with minimal modification. We conduct
experiments on two widely used domain adaptation benchmarks, i.e., Office-31
and VisDA-2017, and demonstrate that CDCL achieves state-of-the-art performance
on both datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Properties of Deep Residual Networks. (arXiv:2105.12245v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1">Alain-Sam Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cont_R/0/1/0/all/0/1">Rama Cont</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossier_A/0/1/0/all/0/1">Alain Rossier</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Renyuan Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12245">
                                    <div class="article-summary-box-inner">
                                        <span>Residual networks (ResNets) have displayed impressive results in pattern
recognition and, recently, have garnered considerable theoretical interest due
to a perceived link with neural ordinary differential equations (neural ODEs).
This link relies on the convergence of network weights to a smooth function as
the number of layers increases. We investigate the properties of weights
trained by stochastic gradient descent and their scaling with network depth
through detailed numerical experiments. We observe the existence of scaling
regimes markedly different from those assumed in neural ODE literature.
Depending on certain features of the network architecture, such as the
smoothness of the activation function, one may obtain an alternative ODE limit,
a stochastic differential equation or neither of these. These findings cast
doubts on the validity of the neural ODE model as an adequate asymptotic
description of deep ResNets and point to an alternative class of differential
equations as a better description of the deep network limit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Post-Hoc Explanations for Predictive Process Monitoring in Manufacturing. (arXiv:2009.10513v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mehdiyev_N/0/1/0/all/0/1">Nijat Mehdiyev</a>, <a href="http://arxiv.org/find/cs/1/au:+Fettke_P/0/1/0/all/0/1">Peter Fettke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10513">
                                    <div class="article-summary-box-inner">
                                        <span>This study proposes an innovative explainable predictive quality analytics
solution to facilitate data-driven decision-making for process planning in
manufacturing by combining process mining, machine learning, and explainable
artificial intelligence (XAI) methods. For this purpose, after integrating the
top-floor and shop-floor data obtained from various enterprise information
systems, a deep learning model was applied to predict the process outcomes.
Since this study aims to operationalize the delivered predictive insights by
embedding them into decision-making processes, it is essential to generate
relevant explanations for domain experts. To this end, two complementary local
post-hoc explanation approaches, Shapley values and Individual Conditional
Expectation (ICE) plots are adopted, which are expected to enhance the
decision-making capabilities by enabling experts to examine explanations from
different perspectives. After assessing the predictive strength of the applied
deep neural network with relevant binary classification evaluation measures, a
discussion of the generated explanations is provided.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From inexact optimization to learning via gradient concentration. (arXiv:2106.05397v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Stankewitz_B/0/1/0/all/0/1">Bernhard Stankewitz</a>, <a href="http://arxiv.org/find/stat/1/au:+Mucke_N/0/1/0/all/0/1">Nicole M&#xfc;cke</a>, <a href="http://arxiv.org/find/stat/1/au:+Rosasco_L/0/1/0/all/0/1">Lorenzo Rosasco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05397">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization was recently shown to control the inductive bias in a learning
process, a property referred to as implicit, or iterative regularization. The
estimator obtained iteratively minimizing the training error can generalise
well with no need of further penalties or constraints. In this paper, we
investigate this phenomenon in the context of linear models with smooth loss
functions. In particular, we investigate and propose a proof technique
combining ideas from inexact optimization and probability theory, specifically
gradient concentration. The proof is easy to follow and allows to obtain sharp
learning bounds. More generally, it highlights a way to develop optimization
results into learning guarantees.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clairvoyant Prefetching for Distributed Machine Learning I/O. (arXiv:2101.08734v2 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dryden_N/0/1/0/all/0/1">Nikoli Dryden</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohringer_R/0/1/0/all/0/1">Roman B&#xf6;hringer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_Nun_T/0/1/0/all/0/1">Tal Ben-Nun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1">Torsten Hoefler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08734">
                                    <div class="article-summary-box-inner">
                                        <span>I/O is emerging as a major bottleneck for machine learning training,
especially in distributed environments. Indeed, at large scale, I/O takes as
much as 85% of training time. Addressing this I/O bottleneck necessitates
careful optimization, as optimal data ingestion pipelines differ between
systems, and require a delicate balance between access to local storage,
external filesystems, and remote nodes. We introduce NoPFS, a machine learning
I/O middleware, which provides a scalable, flexible, and easy-to-use solution
to the I/O bottleneck. NoPFS uses clairvoyance: Given the seed generating the
random access pattern for training with SGD, it can exactly predict when and
where a sample will be accessed. We combine this with an analysis of access
patterns and a performance model to provide distributed caching policies that
adapt to different datasets and storage hierarchies. NoPFS reduces I/O times
and improves end-to-end training by up to 5.4x on the ImageNet-1k,
ImageNet-22k, and CosmoFlow datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Classifiers Under Infinite Imbalance. (arXiv:2106.05797v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Glasserman_P/0/1/0/all/0/1">Paul Glasserman</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1">Mike Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05797">
                                    <div class="article-summary-box-inner">
                                        <span>We study the behavior of linear discriminant functions for binary
classification in the infinite-imbalance limit, where the sample size of one
class grows without bound while the sample size of the other remains fixed. The
coefficients of the classifier minimize an expected loss specified through a
weight function. We show that for a broad class of weight functions, the
intercept diverges but the rest of the coefficient vector has a finite limit
under infinite imbalance, extending prior work on logistic regression. The
limit depends on the left tail of the weight function, for which we distinguish
three cases: bounded, asymptotically polynomial, and asymptotically
exponential. The limiting coefficient vectors reflect robustness or
conservatism properties in the sense that they optimize against certain
worst-case alternatives. In the bounded and polynomial cases, the limit is
equivalent to an implicit choice of upsampling distribution for the minority
class. We apply these ideas in a credit risk setting, with particular emphasis
on performance in the high-sensitivity and high-specificity regions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Classification with Adversarial Perturbations. (arXiv:2106.05964v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1">L. Elisa Celis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrotra_A/0/1/0/all/0/1">Anay Mehrotra</a>, <a href="http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1">Nisheeth K. Vishnoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05964">
                                    <div class="article-summary-box-inner">
                                        <span>We study fair classification in the presence of an omniscient adversary that,
given an $\eta$, is allowed to choose an arbitrary $\eta$-fraction of the
training samples and arbitrarily perturb their protected attributes. The
motivation comes from settings in which protected attributes can be incorrect
due to strategic misreporting, malicious actors, or errors in imputation; and
prior approaches that make stochastic or independence assumptions on errors may
not satisfy their guarantees in this adversarial setting. Our main contribution
is an optimization framework to learn fair classifiers in this adversarial
setting that comes with provable guarantees on accuracy and fairness. Our
framework works with multiple and non-binary protected attributes, is designed
for the large class of linear-fractional fairness metrics, and can also handle
perturbations besides protected attributes. We prove near-tightness of our
framework&#x27;s guarantees for natural hypothesis classes: no algorithm can have
significantly better accuracy and any algorithm with better fairness must have
lower accuracy. Empirically, we evaluate the classifiers produced by our
framework for statistical rate on real-world and synthetic datasets for a
family of adversaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compositional Modeling of Nonlinear Dynamical Systems with ODE-based Random Features. (arXiv:2106.05960v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+McDonald_T/0/1/0/all/0/1">Thomas M. McDonald</a>, <a href="http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1">Mauricio A. &#xc1;lvarez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05960">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling phenomena present in highly nonlinear dynamical systems
whilst also accurately quantifying uncertainty is a challenging task, which
often requires problem-specific techniques. We present a novel, domain-agnostic
approach to tackling this problem, using compositions of physics-informed
random features, derived from ordinary differential equations. The architecture
of our model leverages recent advances in approximate inference for deep
Gaussian processes, such as layer-wise weight-space approximations which allow
us to incorporate random Fourier features, and stochastic variational inference
for approximate Bayesian inference. We provide evidence that our model is
capable of capturing highly nonlinear behaviour in real-world multivariate time
series data. In addition, we find that our approach achieves comparable
performance to a number of other probabilistic models on benchmark regression
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Support Recovery of Sparse Signals from a Mixture of Linear Measurements. (arXiv:2106.05951v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gandikota_V/0/1/0/all/0/1">Venkata Gandikota</a>, <a href="http://arxiv.org/find/stat/1/au:+Mazumdar_A/0/1/0/all/0/1">Arya Mazumdar</a>, <a href="http://arxiv.org/find/stat/1/au:+Pal_S/0/1/0/all/0/1">Soumyabrata Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05951">
                                    <div class="article-summary-box-inner">
                                        <span>Recovery of support of a sparse vector from simple measurements is a widely
studied problem, considered under the frameworks of compressed sensing, 1-bit
compressed sensing, and more general single index models. We consider
generalizations of this problem: mixtures of linear regressions, and mixtures
of linear classifiers, where the goal is to recover supports of multiple sparse
vectors using only a small number of possibly noisy linear, and 1-bit
measurements respectively. The key challenge is that the measurements from
different vectors are randomly mixed. Both of these problems were also
extensively studied recently. In mixtures of linear classifiers, the
observations correspond to the side of queried hyperplane a random unknown
vector lies in, whereas in mixtures of linear regressions we observe the
projection of a random unknown vector on the queried hyperplane. The primary
step in recovering the unknown vectors from the mixture is to first identify
the support of all the individual component vectors. In this work, we study the
number of measurements sufficient for recovering the supports of all the
component vectors in a mixture in both these models. We provide algorithms that
use a number of measurements polynomial in $k, \log n$ and quasi-polynomial in
$\ell$, to recover the support of all the $\ell$ unknown vectors in the mixture
with high probability when each individual component is a $k$-sparse
$n$-dimensional vector.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal and Object Quantification Networks. (arXiv:2106.05891v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1">Jiayuan Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhezheng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1">Leslie Pack Kaelbling</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1">Tomer D. Ullman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05891">
                                    <div class="article-summary-box-inner">
                                        <span>We present Temporal and Object Quantification Networks (TOQ-Nets), a new
class of neuro-symbolic networks with a structural bias that enables them to
learn to recognize complex relational-temporal events. This is done by
including reasoning layers that implement finite-domain quantification over
objects and time. The structure allows them to generalize directly to input
instances with varying numbers of objects in temporal sequences of varying
lengths. We evaluate TOQ-Nets on input domains that require recognizing
event-types in terms of complex temporal relational patterns. We demonstrate
that TOQ-Nets can generalize from small amounts of data to scenarios containing
more objects than were present during training and to temporal warpings of
input sequences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid gene selection approach using XGBoost and multi-objective genetic algorithm for cancer classification. (arXiv:2106.05841v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xiongshi Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Min Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shaobo Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05841">
                                    <div class="article-summary-box-inner">
                                        <span>Microarray gene expression data are often accompanied by a large number of
genes and a small number of samples. However, only a few of these genes are
relevant to cancer, resulting in signigicant gene selection challenges. Hence,
we propose a two-stage gene selection approach by combining extreme gradient
boosting (XGBoost) and a multi-objective optimization genetic algorithm
(XGBoost-MOGA) for cancer classification in microarray datasets. In the first
stage, the genes are ranked use an ensemble-based feature selection using
XGBoost. This stage can effectively remove irrelevant genes and yield a group
comprising the most relevant genes related to the class. In the second stage,
XGBoost-MOGA searches for an optimal gene subset based on the most relevant
genes&#x27;s group using a multi-objective optimization genetic algorithm. We
performed comprehensive experiments to compare XGBoost-MOGA with other
state-of-the-art feature selection methods using two well-known learning
classifiers on 13 publicly available microarray expression datasets. The
experimental results show that XGBoost-MOGA yields significantly better results
than previous state-of-the-art algorithms in terms of various evaluation
criteria, such as accuracy, F-score, precision, and recall.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bagging and Boosting Based Convexly Combined Optimum Mixture Probabilistic Model. (arXiv:2106.05840v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1">Mian Arif Shams Adnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1">H. M. Miraz Mahmud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05840">
                                    <div class="article-summary-box-inner">
                                        <span>Unlike previous studies on mixture distributions, a bagging and boosting
based convexly combined mixture probabilistic model has been suggested. This
model is a result of iteratively searching for obtaining the optimum
probabilistic model that provides the maximum p value.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HASI: Hardware-Accelerated Stochastic Inference, A Defense Against Adversarial Machine Learning Attacks. (arXiv:2106.05825v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samavatian_M/0/1/0/all/0/1">Mohammad Hossein Samavatian</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1">Saikat Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Barber_K/0/1/0/all/0/1">Kristin Barber</a>, <a href="http://arxiv.org/find/cs/1/au:+Teodorescu_R/0/1/0/all/0/1">Radu Teodorescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05825">
                                    <div class="article-summary-box-inner">
                                        <span>DNNs are known to be vulnerable to so-called adversarial attacks, in which
inputs are carefully manipulated to induce misclassification. Existing defenses
are mostly software-based and come with high overheads or other limitations.
This paper presents HASI, a hardware-accelerated defense that uses a process we
call stochastic inference to detect adversarial inputs. HASI carefully injects
noise into the model at inference time and used the model&#x27;s response to
differentiate adversarial inputs from benign ones. We show an adversarial
detection rate of average 87% which exceeds the detection rate of the
state-of-the-art approaches, with a much lower overhead. We demonstrate a
software/hardware-accelerated co-design, which reduces the performance impact
of stochastic inference to 1.58X-2X relative to the unprotected baseline,
compared to 14X-20X overhead for a software-only GPU implementation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowing when we do not know: Bayesian continual learning for sensing-based analysis tasks. (arXiv:2106.05872v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Servia_Rodriguez_S/0/1/0/all/0/1">Sandra Servia-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Mascolo_C/0/1/0/all/0/1">Cecilia Mascolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1">Young D. Kwon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05872">
                                    <div class="article-summary-box-inner">
                                        <span>Despite much research targeted at enabling conventional machine learning
models to continually learn tasks and data distributions sequentially without
forgetting the knowledge acquired, little effort has been devoted to account
for more realistic situations where learning some tasks accurately might be
more critical than forgetting previous ones. In this paper we propose a
Bayesian inference based framework to continually learn a set of real-world,
sensing-based analysis tasks that can be tuned to prioritize the remembering of
previously learned tasks or the learning of new ones. Our experiments prove the
robustness and reliability of the learned models to adapt to the changing
sensing environment, and show the suitability of using uncertainty of the
predictions to assess their reliability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions. (arXiv:2106.05480v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1">Ruoqi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1">Kevin Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05480">
                                    <div class="article-summary-box-inner">
                                        <span>We give lower bounds on the performance of two of the most popular sampling
methods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and
multi-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when
applied to well-conditioned distributions. Our main result is a nearly-tight
lower bound of $\widetilde{\Omega}(\kappa d)$ on the mixing time of MALA from
an exponentially warm start, matching a line of algorithmic results up to
logarithmic factors and answering an open question of Chewi et. al. We also
show that a polynomial dependence on dimension is necessary for the relaxation
time of HMC under any number of leapfrog steps, and bound the gains achievable
by changing the step count. Our HMC analysis draws upon a novel connection
between leapfrog integration and Chebyshev polynomials, which may be of
independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Agglomerative Graph Clustering in Nearly-Linear Time. (arXiv:2106.05610v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenstat_D/0/1/0/all/0/1">David Eisenstat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacki_J/0/1/0/all/0/1">Jakub &#x141;&#x105;cki</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jessica Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05610">
                                    <div class="article-summary-box-inner">
                                        <span>We study the widely used hierarchical agglomerative clustering (HAC)
algorithm on edge-weighted graphs. We define an algorithmic framework for
hierarchical agglomerative graph clustering that provides the first efficient
$\tilde{O}(m)$ time exact algorithms for classic linkage measures, such as
complete- and WPGMA-linkage, as well as other measures. Furthermore, for
average-linkage, arguably the most popular variant of HAC, we provide an
algorithm that runs in $\tilde{O}(n\sqrt{m})$ time. For this variant, this is
the first exact algorithm that runs in subquadratic time, as long as
$m&#x3D;n^{2-\epsilon}$ for some constant $\epsilon &gt; 0$. We complement this result
with a simple $\epsilon$-close approximation algorithm for average-linkage in
our framework that runs in $\tilde{O}(m)$ time. As an application of our
algorithms, we consider clustering points in a metric space by first using
$k$-NN to generate a graph from the point set, and then running our algorithms
on the resulting weighted graph. We validate the performance of our algorithms
on publicly available datasets, and show that our approach can speed up
clustering of point datasets by a factor of 20.7--76.5x.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic-aware Binary Code Representation with BERT. (arXiv:2106.05478v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koo_H/0/1/0/all/0/1">Hyungjoon Koo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Soyeon Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Daejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taesoo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05478">
                                    <div class="article-summary-box-inner">
                                        <span>A wide range of binary analysis applications, such as bug discovery, malware
analysis and code clone detection, require recovery of contextual meanings on a
binary code. Recently, binary analysis techniques based on machine learning
have been proposed to automatically reconstruct the code representation of a
binary instead of manually crafting specifics of the analysis algorithm.
However, the existing approaches utilizing machine learning are still
specialized to solve one domain of problems, rendering recreation of models for
different types of binary analysis. In this paper, we propose DeepSemantic
utilizing BERT in producing the semantic-aware code representation of a binary
code.

To this end, we introduce well-balanced instruction normalization that holds
rich information for each of instructions yet minimizing an out-of-vocabulary
(OOV) problem. DeepSemantic has been carefully designed based on our study with
large swaths of binaries. Besides, DeepSemantic leverages the essence of the
BERT architecture into re-purposing a pre-trained generic model that is readily
available as a one-time processing, followed by quickly applying specific
downstream tasks with a fine-tuning process. We demonstrate DeepSemantic with
two downstream tasks, namely, binary similarity comparison and compiler
provenance (i.e., compiler and optimization level) prediction. Our experimental
results show that the binary similarity model outperforms two state-of-the-art
binary similarity tools, DeepBinDiff and SAFE, 49.84% and 15.83% on average,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Behaviour Discovery with Quality-Diversity Optimisation. (arXiv:2106.05648v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grillotti_L/0/1/0/all/0/1">Luca Grillotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Cully_A/0/1/0/all/0/1">Antoine Cully</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05648">
                                    <div class="article-summary-box-inner">
                                        <span>Quality-Diversity algorithms refer to a class of evolutionary algorithms
designed to find a collection of diverse and high-performing solutions to a
given problem. In robotics, such algorithms can be used for generating a
collection of controllers covering most of the possible behaviours of a robot.
To do so, these algorithms associate a behavioural descriptor to each of these
behaviours. Each behavioural descriptor is used for estimating the novelty of
one behaviour compared to the others. In most existing algorithms, the
behavioural descriptor needs to be hand-coded, thus requiring prior knowledge
about the task to solve. In this paper, we introduce: Autonomous Robots
Realising their Abilities, an algorithm that uses a dimensionality reduction
technique to automatically learn behavioural descriptors based on raw sensory
data. The performance of this algorithm is assessed on three robotic tasks in
simulation. The experimental results show that it performs similarly to
traditional hand-coded approaches without the requirement to provide any
hand-coded behavioural descriptor. In the collection of diverse and
high-performing solutions, it also manages to find behaviours that are novel
with respect to more features than its hand-coded baselines. Finally, we
introduce a variant of the algorithm which is robust to the dimensionality of
the behavioural descriptor space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audiovisual transfer learning for audio tagging and sound event detection. (arXiv:2106.05408v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Boes_W/0/1/0/all/0/1">Wim Boes</a>, <a href="http://arxiv.org/find/eess/1/au:+hamme_H/0/1/0/all/0/1">Hugo Van hamme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05408">
                                    <div class="article-summary-box-inner">
                                        <span>We study the merit of transfer learning for two sound recognition problems,
i.e., audio tagging and sound event detection. Employing feature fusion, we
adapt a baseline system utilizing only spectral acoustic inputs to also make
use of pretrained auditory and visual features, extracted from networks built
for different tasks and trained with external data. We perform experiments with
these modified models on an audiovisual multi-label data set, of which the
training partition contains a large number of unlabeled samples and a smaller
amount of clips with weak annotations, indicating the clip-level presence of 10
sound categories without specifying the temporal boundaries of the active
auditory events. For clip-based audio tagging, this transfer learning method
grants marked improvements. Addition of the visual modality on top of audio
also proves to be advantageous in this context. When it comes to generating
transcriptions of audio recordings, the benefit of pretrained features depends
on the requested temporal resolution: for coarse-grained sound event detection,
their utility remains notable. But when more fine-grained predictions are
required, performance gains are strongly reduced due to a mismatch between the
problem at hand and the goals of the models from which the pretrained vectors
were obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantized Conditional COT-GAN for Video Prediction. (arXiv:2106.05658v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Xu_T/0/1/0/all/0/1">Tianlin Xu</a>, <a href="http://arxiv.org/find/stat/1/au:+Acciaio_B/0/1/0/all/0/1">Beatrice Acciaio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05658">
                                    <div class="article-summary-box-inner">
                                        <span>Causal Optimal Transport (COT) results from imposing a temporal causality
constraint on classic optimal transport problems, which naturally generates a
new concept of distances between distributions on path spaces. The first
application of the COT theory for sequential learning was given in Xu et al.
(2020), where COT-GAN was introduced as an adversarial algorithm to train
implicit generative models optimized for producing sequential data. Relying on
Xu et al. (2020), the contribution of the present paper is twofold. First, we
develop a conditional version of COT-GAN suitable for sequence prediction. This
means that the dataset is now used in order to learn how a sequence will evolve
given the observation of its past evolution. Second, we improve on the
convergence results by working with modifications of the empirical measures via
a specific type of quantization due to Backhoff et al. (2020). The resulting
quantized conditional COT-GAN algorithm is illustrated with an application for
video prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Under-Coverage Bias in Uncertainty Estimation. (arXiv:2106.05515v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yu Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_S/0/1/0/all/0/1">Song Mei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05515">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating the data uncertainty in regression tasks is often done by learning
a quantile function or a prediction interval of the true label conditioned on
the input. It is frequently observed that quantile regression -- a vanilla
algorithm for learning quantiles with asymptotic guarantees -- tends to
\emph{under-cover} than the desired coverage level in reality. While various
fixes have been proposed, a more fundamental understanding of why this
under-coverage bias happens in the first place remains elusive.

In this paper, we present a rigorous theoretical study on the coverage of
uncertainty estimation algorithms in learning quantiles. We prove that quantile
regression suffers from an inherent under-coverage bias, in a vanilla setting
where we learn a realizable linear quantile function and there is more data
than parameters. More quantitatively, for $\alpha&gt;0.5$ and small $d/n$, the
$\alpha$-quantile learned by quantile regression roughly achieves coverage
$\alpha - (\alpha-1/2)\cdot d/n$ regardless of the noise distribution, where
$d$ is the input dimension and $n$ is the number of training data. Our theory
reveals that this under-coverage bias stems from a certain high-dimensional
parameter estimation error that is not implied by existing theories on quantile
regression. Experiments on simulated and real data verify our theory and
further illustrate the effect of various factors such as sample size and model
capacity on the under-coverage bias in more practical setups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphiT: Encoding Graph Structure in Transformers. (arXiv:2106.05667v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mialon_G/0/1/0/all/0/1">Gr&#xe9;goire Mialon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dexiong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Selosse_M/0/1/0/all/0/1">Margot Selosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Mairal_J/0/1/0/all/0/1">Julien Mairal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05667">
                                    <div class="article-summary-box-inner">
                                        <span>We show that viewing graphs as sets of node features and incorporating
structural and positional information into a transformer architecture is able
to outperform representations learned with classical graph neural networks
(GNNs). Our model, GraphiT, encodes such information by (i) leveraging relative
positional encoding strategies in self-attention scores based on positive
definite kernels on graphs, and (ii) enumerating and encoding local
sub-structures such as paths of short length. We thoroughly evaluate these two
ideas on many classification and regression tasks, demonstrating the
effectiveness of each of them independently, as well as their combination. In
addition to performing well on standard benchmarks, our model also admits
natural visualization mechanisms for interpreting graph motifs explaining the
predictions, making it a potentially strong candidate for scientific
applications where interpretation is important. Code available at
https://github.com/inria-thoth/GraphiT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Discontinuity Capturing Shallow Neural Network for Elliptic Interface Problems. (arXiv:2106.05587v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Hu_W/0/1/0/all/0/1">Wei-Fan Hu</a>, <a href="http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1">Te-Sheng Lin</a>, <a href="http://arxiv.org/find/math/1/au:+Lai_M/0/1/0/all/0/1">Ming-Chih Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05587">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a new Discontinuity Capturing Shallow Neural Network (DCSNN)
for approximating $d$-dimensional piecewise continuous functions and for
solving elliptic interface problems is developed. There are three novel
features in the present network; namely, (i) jump discontinuity is captured
sharply, (ii) it is completely shallow consisting of only one hidden layer,
(iii) it is completely mesh-free for solving partial differential equations
(PDEs). We first continuously extend the $d$-dimensional piecewise continuous
function in $(d+1)$-dimensional space by augmenting one coordinate variable to
label the pieces of discontinuous function, and then construct a shallow neural
network to express this new augmented function. Since only one hidden layer is
employed, the number of training parameters (weights and biases) scales
linearly with the dimension and the neurons used in the hidden layer. For
solving elliptic interface equations, the network is trained by minimizing the
mean squared error loss that consists of the residual of governing equation,
boundary condition, and the interface jump conditions. We perform a series of
numerical tests to compare the accuracy and efficiency of the present network.
Our DCSNN model is comparably efficient due to only moderate number of
parameters needed to be trained (a few hundreds of parameters used throughout
all numerical examples here), and the result shows better accuracy (and less
parameters) than other method using piecewise deep neural network in
literature. We also compare the results obtained by the traditional grid-based
immersed interface method (IIM) which is designed particularly for elliptic
interface problems. Again, the present results show better accuracy than the
ones obtained by IIM. We conclude by solving a six-dimensional problem to show
the capability of the present network for high-dimensional applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs. (arXiv:2106.05373v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Podobas_A/0/1/0/all/0/1">Artur Podobas</a>, <a href="http://arxiv.org/find/cs/1/au:+Svedin_M/0/1/0/all/0/1">Martin Svedin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_S/0/1/0/all/0/1">Steven W. D. Chien</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_I/0/1/0/all/0/1">Ivy B. Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravichandran_N/0/1/0/all/0/1">Naresh Balaji Ravichandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Herman_P/0/1/0/all/0/1">Pawel Herman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lansner_A/0/1/0/all/0/1">Anders Lansner</a>, <a href="http://arxiv.org/find/cs/1/au:+Markidis_S/0/1/0/all/0/1">Stefano Markidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05373">
                                    <div class="article-summary-box-inner">
                                        <span>The modern deep learning method based on backpropagation has surged in
popularity and has been used in multiple domains and application areas. At the
same time, there are other -- less-known -- machine learning algorithms with a
mature and solid theoretical foundation whose performance remains unexplored.
One such example is the brain-like Bayesian Confidence Propagation Neural
Network (BCPNN). In this paper, we introduce StreamBrain -- a framework that
allows neural networks based on BCPNN to be practically deployed in
High-Performance Computing systems. StreamBrain is a domain-specific language
(DSL), similar in concept to existing machine learning (ML) frameworks, and
supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate
that StreamBrain can train the well-known ML benchmark dataset MNIST within
seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We
also show how StreamBrain can be used to train with custom floating-point
formats and illustrate the impact of using different bfloat variations on BCPNN
using FPGAs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Industrial Control Network Cyber Security Orchestration. (arXiv:2106.05332v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mern_J/0/1/0/all/0/1">John Mern</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatch_K/0/1/0/all/0/1">Kyle Hatch</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ryan Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Brush_J/0/1/0/all/0/1">Jeff Brush</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1">Mykel J. Kochenderfer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05332">
                                    <div class="article-summary-box-inner">
                                        <span>Defending computer networks from cyber attack requires coordinating actions
across multiple nodes based on imperfect indicators of compromise while
minimizing disruptions to network operations. Advanced attacks can progress
with few observable signals over several months before execution. The resulting
sequential decision problem has large observation and action spaces and a long
time-horizon, making it difficult to solve with existing methods. In this work,
we present techniques to scale deep reinforcement learning to solve the cyber
security orchestration problem for large industrial control networks. We
propose a novel attention-based neural architecture with size complexity that
is invariant to the size of the network under protection. A pre-training
curriculum is presented to overcome early exploration difficulty. Experiments
show in that the proposed approaches greatly improve both the learning sample
complexity and converged policy performance over baseline methods in
simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Learning for Stochastic Shortest Path Model via Posterior Sampling. (arXiv:2106.05335v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jafarnia_Jahromi_M/0/1/0/all/0/1">Mehdi Jafarnia-Jahromi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1">Rahul Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haipeng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05335">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of online reinforcement learning for the Stochastic
Shortest Path (SSP) problem modeled as an unknown MDP with an absorbing state.
We propose PSRL-SSP, a simple posterior sampling-based reinforcement learning
algorithm for the SSP problem. The algorithm operates in epochs. At the
beginning of each epoch, a sample is drawn from the posterior distribution on
the unknown model dynamics, and the optimal policy with respect to the drawn
sample is followed during that epoch. An epoch completes if either the number
of visits to the goal state in the current epoch exceeds that of the previous
epoch, or the number of visits to any of the state-action pairs is doubled. We
establish a Bayesian regret bound of $O(B_\star S\sqrt{AK})$, where $B_\star$
is an upper bound on the expected cost of the optimal policy, $S$ is the size
of the state space, $A$ is the size of the action space, and $K$ is the number
of episodes. The algorithm only requires the knowledge of the prior
distribution, and has no hyper-parameters to tune. It is the first such
posterior sampling algorithm and outperforms numerically previously proposed
optimism-based algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Streaming Perception using Deep Reinforcement Learning. (arXiv:2106.05665v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1">Anurag Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1">Akshay Nambi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Aditya Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+YVS_H/0/1/0/all/0/1">Harish YVS</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1">Tanuja Ganu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05665">
                                    <div class="article-summary-box-inner">
                                        <span>Executing computer vision models on streaming visual data, or streaming
perception is an emerging problem, with applications in self-driving, embodied
agents, and augmented/virtual reality. The development of such systems is
largely governed by the accuracy and latency of the processing pipeline. While
past work has proposed numerous approximate execution frameworks, their
decision functions solely focus on optimizing latency, accuracy, or energy,
etc. This results in sub-optimum decisions, affecting the overall system
performance. We argue that the streaming perception systems should holistically
maximize the overall system performance (i.e., considering both accuracy and
latency simultaneously). To this end, we describe a new approach based on deep
reinforcement learning to learn these tradeoffs at runtime for streaming
perception. This tradeoff optimization is formulated as a novel deep contextual
bandit problem and we design a new reward function that holistically integrates
latency and accuracy into a single metric. We show that our agent can learn a
competitive policy across multiple decision dimensions, which outperforms
state-of-the-art policies on public datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection. (arXiv:2106.05410v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hojjati_H/0/1/0/all/0/1">Hadi Hojjati</a>, <a href="http://arxiv.org/find/cs/1/au:+Armanfard_N/0/1/0/all/0/1">Narges Armanfard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05410">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised anomaly detection, which aims to detect anomalies from normal
samples using a model that is solely trained on normal data, has been an active
field of research in the past decade. With recent advancements in deep
learning, particularly generative adversarial networks and autoencoders,
researchers have designed efficient deep anomaly detection methods. Existing
works commonly use neural networks such as an autoencoder to map the data into
a new representation that is easier to work with and then apply an anomaly
detection algorithm. In this paper, we propose a method, DASVDD, that jointly
learns the parameters of an autoencoder while minimizing the volume of an
enclosing hyper-sphere on its latent representation. We propose a customized
anomaly score which is a combination of autoencoder&#x27;s reconstruction error and
distance of the lower-dimensional representation of a sample from the center of
the enclosing hyper-sphere. Minimizing this anomaly score on the normal data
during training aids us in learning the underlying distribution of normal data.
Including the reconstruction error in the anomaly score ensures that DASVDD
does not suffer from the common hyper-sphere collapse issue since the proposed
DASVDD model does not converge to the trivial solution of mapping all inputs to
a constant point in the latent representation. Experimental evaluations on
several benchmark datasets from different domains show that the proposed method
outperforms most of the commonly used state-of-the-art anomaly detection
algorithms while maintaining robust and accurate performance across different
anomaly classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter and Feature Selection in Stochastic Linear Bandits. (arXiv:2106.05378v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moradipari_A/0/1/0/all/0/1">Ahmadreza Moradipari</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1">Yasin Abbasi-Yadkori</a>, <a href="http://arxiv.org/find/cs/1/au:+Alizadeh_M/0/1/0/all/0/1">Mahnoosh Alizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05378">
                                    <div class="article-summary-box-inner">
                                        <span>We study two model selection settings in stochastic linear bandits (LB). In
the first setting, the reward parameter of the LB problem is arbitrarily
selected from $M$ models represented as (possibly) overlapping balls in
$\mathbb R^d$. However, the agent only has access to misspecified models, i.e.,
estimates of the centers and radii of the balls. We refer to this setting as
parameter selection. In the second setting, which we refer to as feature
selection, the expected reward of the LB problem is in the linear span of at
least one of $M$ feature maps (models). For each setting, we develop and
analyze an algorithm that is based on a reduction from bandits to
full-information problems. This allows us to obtain regret bounds that are not
worse (up to a $\sqrt{\log M}$ factor) than the case where the true model is
known. Our parameter selection algorithm is OFUL-style and the one for feature
selection is based on the SquareCB algorithm. We also show that the regret of
our parameter selection algorithm scales logarithmically with model
misspecification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pulling back information geometry. (arXiv:2106.05367v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1">Georgios Arvanitidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Duque_M/0/1/0/all/0/1">Miguel Gonz&#xe1;lez-Duque</a>, <a href="http://arxiv.org/find/cs/1/au:+Pouplin_A/0/1/0/all/0/1">Alison Pouplin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalatzis_D/0/1/0/all/0/1">Dimitris Kalatzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05367">
                                    <div class="article-summary-box-inner">
                                        <span>Latent space geometry has shown itself to provide a rich and rigorous
framework for interacting with the latent variables of deep generative models.
The existing theory, however, relies on the decoder being a Gaussian
distribution as its simple reparametrization allows us to interpret the
generating process as a random projection of a deterministic manifold.
Consequently, this approach breaks down when applied to decoders that are not
as easily reparametrized. We here propose to use the Fisher-Rao metric
associated with the space of decoder distributions as a reference metric, which
we pull back to the latent space. We show that we can achieve meaningful latent
geometries for a wide range of decoder distributions for which the previous
theory was not applicable, opening the door to &#x60;black box&#x27; latent geometries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certified Defenses: Why Tighter Relaxations May Hurt Training. (arXiv:2102.06700v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jovanovic_N/0/1/0/all/0/1">Nikola Jovanovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Balunovic_M/0/1/0/all/0/1">Mislav Balunovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Baader_M/0/1/0/all/0/1">Maximilian Baader</a>, <a href="http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1">Martin Vechev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06700">
                                    <div class="article-summary-box-inner">
                                        <span>Certified defenses based on convex relaxations are an established technique
for training provably robust models. The key component is the choice of
relaxation, varying from simple intervals to tight polyhedra. Paradoxically,
however, training with tighter relaxations can often lead to worse certified
robustness. The poor understanding of this paradox has forced recent
state-of-the-art certified defenses to focus on designing various heuristics in
order to mitigate its effects. In contrast, in this paper we study the
underlying causes and show that tightness alone may not be the determining
factor. Concretely, we identify two key properties of relaxations that impact
training dynamics: continuity and sensitivity. Our extensive experimental
evaluation demonstrates that these two factors, observed alongside tightness,
explain the drop in certified robustness for popular relaxations. Further, we
investigate the possibility of designing and training with relaxations that are
tight, continuous and not sensitive. We believe the insights of this work can
help drive the principled discovery of new and effective certified defense
mechanisms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Public Transit for Special Events: Ridership Prediction and Train Optimization. (arXiv:2106.05359v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Santanam_T/0/1/0/all/0/1">Tejas Santanam</a>, <a href="http://arxiv.org/find/math/1/au:+Trasatti_A/0/1/0/all/0/1">Anthony Trasatti</a>, <a href="http://arxiv.org/find/math/1/au:+Hentenryck_P/0/1/0/all/0/1">Pascal Van Hentenryck</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_H/0/1/0/all/0/1">Hanyu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05359">
                                    <div class="article-summary-box-inner">
                                        <span>Many special events, including sport games and concerts, often cause surges
in demand and congestion for transit systems. Therefore, it is important for
transit providers to understand their impact on disruptions, delays, and fare
revenues. This paper proposes a suite of data-driven techniques that exploit
Automated Fare Collection (AFC) data for evaluating, anticipating, and managing
the performance of transit systems during recurring congestion peaks due to
special events. This includes an extensive analysis of ridership of the two
major stadiums in downtown Atlanta using rail data from the Metropolitan
Atlanta Rapid Transit Authority (MARTA). The paper first highlights the
ridership predictability at the aggregate level for each station on both event
and non-event days. It then presents an unsupervised machine-learning model to
cluster passengers and identify which train they are boarding. The model makes
it possible to evaluate system performance in terms of fundamental metrics such
as the passenger load per train and the wait times of riders. The paper also
presents linear regression and random forest models for predicting ridership
that are used in combination with historical throughput analysis to forecast
demand. Finally, simulations are performed that showcase the potential
improvements to wait times and demand matching by leveraging proposed
techniques to optimize train frequencies based on forecasted demand.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ZoPE: A Fast Optimizer for ReLU Networks with Low-Dimensional Inputs. (arXiv:2106.05325v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strong_C/0/1/0/all/0/1">Christopher A. Strong</a>, <a href="http://arxiv.org/find/cs/1/au:+Katz_S/0/1/0/all/0/1">Sydney M. Katz</a>, <a href="http://arxiv.org/find/cs/1/au:+Corso_A/0/1/0/all/0/1">Anthony L. Corso</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1">Mykel J. Kochenderfer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05325">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks often lack the safety and robustness guarantees needed
to be deployed in safety critical systems. Formal verification techniques can
be used to prove input-output safety properties of networks, but when
properties are difficult to specify, we rely on the solution to various
optimization problems. In this work, we present an algorithm called ZoPE that
solves optimization problems over the output of feedforward ReLU networks with
low-dimensional inputs. The algorithm eagerly splits the input space, bounding
the objective using zonotope propagation at each step, and improves
computational efficiency compared to existing mixed integer programming
approaches. We demonstrate how to formulate and solve three types of
optimization problems: (i) minimization of any convex function over the output
space, (ii) minimization of a convex function over the output of two networks
in series with an adversarial perturbation in the layer between them, and (iii)
maximization of the difference in output between two networks. Using ZoPE, we
observe a $25\times$ speedup on property 1 of the ACAS Xu neural network
verification benchmark and an $85\times$ speedup on a set of linear
optimization problems. We demonstrate the versatility of the optimizer in
analyzing networks by projecting onto the range of a generative adversarial
network and visualizing the differences between a compressed and uncompressed
network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Robust are Model Rankings: A Leaderboard Customization Approach for Equitable Evaluation. (arXiv:2106.05532v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Swaroop Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Arunkumar_A/0/1/0/all/0/1">Anjana Arunkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05532">
                                    <div class="article-summary-box-inner">
                                        <span>Models that top leaderboards often perform unsatisfactorily when deployed in
real world applications; this has necessitated rigorous and expensive
pre-deployment model testing. A hitherto unexplored facet of model performance
is: Are our leaderboards doing equitable evaluation? In this paper, we
introduce a task-agnostic method to probe leaderboards by weighting samples
based on their &#x60;difficulty&#x27; level. We find that leaderboards can be
adversarially attacked and top performing models may not always be the best
models. We subsequently propose alternate evaluation metrics. Our experiments
on 10 models show changes in model ranking and an overall reduction in
previously reported performance -- thus rectifying the overestimation of AI
systems&#x27; capabilities. Inspired by behavioral testing principles, we further
develop a prototype of a visual analytics tool that enables leaderboard
revamping through customization, based on an end user&#x27;s focus area. This helps
users analyze models&#x27; strengths and weaknesses, and guides them in the
selection of a model best suited for their application scenario. In a user
study, members of various commercial product development teams, covering 5
focus areas, find that our prototype reduces pre-deployment development and
testing effort by 41% on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-Grained System Identification of Nonlinear Neural Circuits. (arXiv:2106.05400v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bagherian_D/0/1/0/all/0/1">Dawna Bagherian</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gornet_J/0/1/0/all/0/1">James Gornet</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bernstein_J/0/1/0/all/0/1">Jeremy Bernstein</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ni_Y/0/1/0/all/0/1">Yu-Li Ni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Meister_M/0/1/0/all/0/1">Markus Meister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05400">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of sparse nonlinear model recovery of high dimensional
compositional functions. Our study is motivated by emerging opportunities in
neuroscience to recover fine-grained models of biological neural circuits using
collected measurement data. Guided by available domain knowledge in
neuroscience, we explore conditions under which one can recover the underlying
biological circuit that generated the training data. Our results suggest
insights of both theoretical and practical interests. Most notably, we find
that a sign constraint on the weights is a necessary condition for system
recovery, which we establish both theoretically with an identifiability
guarantee and empirically on simulated biological circuits. We conclude with a
case study on retinal ganglion cell circuits using data collected from mouse
retina, showcasing the practical potential of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Direct Volume Rendering: Learning Visual Feature Mappings From Exemplary Images. (arXiv:2106.05429v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weiss_J/0/1/0/all/0/1">Jakob Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05429">
                                    <div class="article-summary-box-inner">
                                        <span>Volume Rendering is an important technique for visualizing three-dimensional
scalar data grids and is commonly employed for scientific and medical image
data. Direct Volume Rendering (DVR) is a well established and efficient
rendering algorithm for volumetric data. Neural rendering uses deep neural
networks to solve inverse rendering tasks and applies techniques similar to
DVR. However, it has not been demonstrated successfully for the rendering of
scientific volume data.

In this work, we introduce Deep Direct Volume Rendering (DeepDVR), a
generalization of DVR that allows for the integration of deep neural networks
into the DVR algorithm. We conceptualize the rendering in a latent color space,
thus enabling the use of deep architectures to learn implicit mappings for
feature extraction and classification, replacing explicit feature design and
hand-crafted transfer functions. Our generalization serves to derive novel
volume rendering architectures that can be trained end-to-end directly from
examples in image space, obviating the need to manually define and fine-tune
multidimensional transfer functions while providing superior classification
strength. We further introduce a novel stepsize annealing scheme to accelerate
the training of DeepDVR models and validate its effectiveness in a set of
experiments. We validate our architectures on two example use cases: (1)
learning an optimized rendering from manually adjusted reference images for a
single volume and (2) learning advanced visualization concepts like shading and
semantic colorization that generalize to unseen volume data.

We find that deep volume rendering architectures with explicit modeling of
the DVR pipeline effectively enable end-to-end learning of scientific volume
rendering tasks from target images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Eye of the Beholder: Improved Relation Generalization for Text-based Reinforcement Learning Agents. (arXiv:2106.05387v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Murugesan_K/0/1/0/all/0/1">Keerthiram Murugesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1">Subhajit Chaudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1">Kartik Talamadupula</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05387">
                                    <div class="article-summary-box-inner">
                                        <span>Text-based games (TBGs) have become a popular proving ground for the
demonstration of learning-based agents that make decisions in quasi real-world
settings. The crux of the problem for a reinforcement learning agent in such
TBGs is identifying the objects in the world, and those objects&#x27; relations with
that world. While the recent use of text-based resources for increasing an
agent&#x27;s knowledge and improving its generalization have shown promise, we posit
in this paper that there is much yet to be learned from visual representations
of these same worlds. Specifically, we propose to retrieve images that
represent specific instances of text observations from the world and train our
agents on such images. This improves the agent&#x27;s overall understanding of the
game &#x27;scene&#x27; and objects&#x27; relationships to the world around them, and the
variety of visual representations on offer allow the agent to generate a better
generalization of a relationship. We show that incorporating such images
improves the performance of agents in various TBG settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MLP-Mixer: An all-MLP Architecture for Vision. (arXiv:2105.01601v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1">Ilya Tolstikhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1">Thomas Unterthiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Yung_J/0/1/0/all/0/1">Jessica Yung</a>, <a href="http://arxiv.org/find/cs/1/au:+Steiner_A/0/1/0/all/0/1">Andreas Steiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1">Daniel Keysers</a>, <a href="http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1">Jakob Uszkoreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1">Mario Lucic</a>, <a href="http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1">Alexey Dosovitskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01601">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) are the go-to model for computer vision.
Recently, attention-based networks, such as the Vision Transformer, have also
become popular. In this paper we show that while convolutions and attention are
both sufficient for good performance, neither of them are necessary. We present
MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).
MLP-Mixer contains two types of layers: one with MLPs applied independently to
image patches (i.e. &quot;mixing&quot; the per-location features), and one with MLPs
applied across patches (i.e. &quot;mixing&quot; spatial information). When trained on
large datasets, or with modern regularization schemes, MLP-Mixer attains
competitive scores on image classification benchmarks, with pre-training and
inference cost comparable to state-of-the-art models. We hope that these
results spark further research beyond the realms of well established CNNs and
Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing transfer learning with a model of synthetic correlated datasets. (arXiv:2106.05418v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gerace_F/0/1/0/all/0/1">Federica Gerace</a>, <a href="http://arxiv.org/find/cs/1/au:+Saglietti_L/0/1/0/all/0/1">Luca Saglietti</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannelli_S/0/1/0/all/0/1">Stefano Sarao Mannelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxe_A/0/1/0/all/0/1">Andrew Saxe</a>, <a href="http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1">Lenka Zdeborov&#xe1;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05418">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning can significantly improve the sample efficiency of neural
networks, by exploiting the relatedness between a data-scarce target task and a
data-abundant source task. Despite years of successful applications, transfer
learning practice often relies on ad-hoc solutions, while theoretical
understanding of these procedures is still limited. In the present work, we
re-think a solvable model of synthetic data as a framework for modeling
correlation between data-sets. This setup allows for an analytic
characterization of the generalization performance obtained when transferring
the learned feature map from the source to the target task. Focusing on the
problem of training two-layer networks in a binary classification setting, we
show that our model can capture a range of salient features of transfer
learning with real data. Moreover, by exploiting parametric control over the
correlation between the two data-sets, we systematically investigate under
which conditions the transfer of features is beneficial for generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distance Metric Learning through Minimization of the Free Energy. (arXiv:2106.05495v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stosic_D/0/1/0/all/0/1">Dusan Stosic</a>, <a href="http://arxiv.org/find/cs/1/au:+Stosic_D/0/1/0/all/0/1">Darko Stosic</a>, <a href="http://arxiv.org/find/cs/1/au:+Ludermir_T/0/1/0/all/0/1">Teresa B. Ludermir</a>, <a href="http://arxiv.org/find/cs/1/au:+Stosic_B/0/1/0/all/0/1">Borko Stosic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05495">
                                    <div class="article-summary-box-inner">
                                        <span>Distance metric learning has attracted a lot of interest for solving machine
learning and pattern recognition problems over the last decades. In this work
we present a simple approach based on concepts from statistical physics to
learn optimal distance metric for a given problem. We formulate the task as a
typical statistical physics problem: distances between patterns represent
constituents of a physical system and the objective function corresponds to
energy. Then we express the problem as a minimization of the free energy of a
complex system, which is equivalent to distance metric learning. Much like for
many problems in physics, we propose an approach based on Metropolis Monte
Carlo to find the best distance metric. This provides a natural way to learn
the distance metric, where the learning process can be intuitively seen as
stretching and rotating the metric space until some heuristic is satisfied. Our
proposed method can handle a wide variety of constraints including those with
spurious local minima. The approach works surprisingly well with stochastic
nearest neighbors from neighborhood component analysis (NCA). Experimental
results on artificial and real-world data sets reveal a clear superiority over
a number of state-of-the-art distance metric learning methods for nearest
neighbors classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in Drug Discovery:Applications and Techniques. (arXiv:2106.05386v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jianyuan Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Samaras_D/0/1/0/all/0/1">Dimitris Samaras</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fusheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05386">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial intelligence has transformed the practice of drug discovery in the
past decade. Various artificial intelligence techniques have been used in a
wide range of applications. In this perspective, we present major applications
of AI in drug discovery and discuss the relevant AI techniques, covering most
recent progress in AI-driven drug discovery. We expect that the perspective
will serve as a guide for researchers who are interested in working at this
intersected area of artificial intelligence and drug discovery. We also provide
a GitHub repository summarizing the surveyed papers as a learning resource,
which will be regularly updated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision. (arXiv:2102.03334v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kim_W/0/1/0/all/0/1">Wonjae Kim</a>, <a href="http://arxiv.org/find/stat/1/au:+Son_B/0/1/0/all/0/1">Bokyung Son</a>, <a href="http://arxiv.org/find/stat/1/au:+Kim_I/0/1/0/all/0/1">Ildoo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03334">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-and-Language Pre-training (VLP) has improved performance on various
joint vision-and-language downstream tasks. Current approaches to VLP heavily
rely on image feature extraction processes, most of which involve region
supervision (e.g., object detection) and the convolutional architecture (e.g.,
ResNet). Although disregarded in the literature, we find it problematic in
terms of both (1) efficiency/speed, that simply extracting input features
requires much more computation than the multimodal interaction steps; and (2)
expressive power, as it is upper bounded to the expressive power of the visual
embedder and its predefined visual vocabulary. In this paper, we present a
minimal VLP model, Vision-and-Language Transformer (ViLT), monolithic in the
sense that the processing of visual inputs is drastically simplified to just
the same convolution-free manner that we process textual inputs. We show that
ViLT is up to tens of times faster than previous VLP models, yet with
competitive or better downstream task performance. Our code and pre-trained
weights are available at https://github.com/dandelin/vilt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A step towards a reinforcement learning de novo genome assembler. (arXiv:2102.02649v2 [q-bio.GN] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Padovani_K/0/1/0/all/0/1">Kleber Padovani</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xavier_R/0/1/0/all/0/1">Roberto Xavier</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Carvalho_A/0/1/0/all/0/1">Andre Carvalho</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Reali_A/0/1/0/all/0/1">Anna Reali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chateau_A/0/1/0/all/0/1">Annie Chateau</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Alves_R/0/1/0/all/0/1">Ronnie Alves</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02649">
                                    <div class="article-summary-box-inner">
                                        <span>The use of reinforcement learning has proven to be very promising for solving
complex activities without human supervision during their learning process.
However, their successful applications are predominantly focused on fictional
and entertainment problems - such as games. Based on the above, this work aims
to shed light on the application of reinforcement learning to solve this
relevant real-world problem, the genome assembly. By expanding the only
approach found in the literature that addresses this problem, we carefully
explored the aspects of intelligent agent learning, performed by the Q-learning
algorithm, to understand its suitability to be applied in scenarios whose
characteristics are more similar to those faced by real genome projects. The
improvements proposed here include changing the previously proposed reward
system and including state space exploration optimization strategies based on
dynamic pruning and mutual collaboration with evolutionary computing. These
investigations were tried on 23 new environments with larger inputs than those
used previously. All these environments are freely available on the internet
for the evolution of this research by the scientific community. The results
suggest consistent performance progress using the proposed improvements,
however, they also demonstrate the limitations of them, especially related to
the high dimensionality of state and action spaces. We also present, later, the
paths that can be traced to tackle genome assembly efficiently in real
scenarios considering recent, successfully reinforcement learning applications
- including deep reinforcement learning - from other domains dealing with
high-dimensional inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthetic Data -- Anonymisation Groundhog Day. (arXiv:2011.07018v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stadler_T/0/1/0/all/0/1">Theresa Stadler</a>, <a href="http://arxiv.org/find/cs/1/au:+Oprisanu_B/0/1/0/all/0/1">Bristena Oprisanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Troncoso_C/0/1/0/all/0/1">Carmela Troncoso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07018">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic data has been advertised as a silver-bullet solution to
privacy-preserving data publishing that addresses the shortcomings of
traditional anonymisation techniques. The promise is that synthetic data drawn
from generative models preserves the statistical properties of the original
dataset but, at the same time, provides perfect protection against privacy
attacks. In this work, we present the first quantitative evaluation of the
privacy gain of synthetic data publishing and compare it to that of previous
anonymisation techniques.

Our evaluation of a wide range of state-of-the-art generative models
demonstrates that synthetic data either does not prevent inference attacks or
does not retain data utility. In other words, we empirically show that
synthetic data suffers from the same limitations as traditional anonymisation
techniques.

Furthermore, we find that, in contrast to traditional anonymisation, the
privacy-utility tradeoff of synthetic data publishing is hard to predict.
Because it is impossible to predict what signals a synthetic dataset will
preserve and what information will be lost, synthetic data leads to a highly
variable privacy gain and unpredictable utility loss. In summary, we find that
synthetic data is far from the holy grail of privacy-preserving data
publishing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Characterizing Residential Load Patterns by Household Demographic and Socioeconomic Factors. (arXiv:2106.05858v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhuo Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05858">
                                    <div class="article-summary-box-inner">
                                        <span>The wide adoption of smart meters makes residential load data available and
thus improves the understanding of the energy consumption behavior. Many
existing studies have focused on smart-meter data analysis, but the drivers of
energy consumption behaviors are not well understood. This paper aims to
characterize and estimate users&#x27; load patterns based on their demographic and
socioeconomic information. We adopt the symbolic aggregate approximation (SAX)
method to process the load data and use the K-Means method to extract key load
patterns. We develop a deep neural network (DNN) to analyze the relationship
between users&#x27; load patterns and their demographic and socioeconomic features.
Using real-world load data, we validate our framework and demonstrate the
connections between load patterns and household demographic and socioeconomic
features. We also take two regression models as benchmarks for comparisons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score-based Generative Modeling in Latent Space. (arXiv:2106.05931v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1">Arash Vahdat</a>, <a href="http://arxiv.org/find/stat/1/au:+Kreis_K/0/1/0/all/0/1">Karsten Kreis</a>, <a href="http://arxiv.org/find/stat/1/au:+Kautz_J/0/1/0/all/0/1">Jan Kautz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05931">
                                    <div class="article-summary-box-inner">
                                        <span>Score-based generative models (SGMs) have recently demonstrated impressive
results in terms of both sample quality and distribution coverage. However,
they are usually applied directly in data space and often require thousands of
network evaluations for sampling. Here, we propose the Latent Score-based
Generative Model (LSGM), a novel approach that trains SGMs in a latent space,
relying on the variational autoencoder framework. Moving from data to latent
space allows us to train more expressive generative models, apply SGMs to
non-continuous data, and learn smoother SGMs in a smaller space, resulting in
fewer network evaluations and faster sampling. To enable training LSGMs
end-to-end in a scalable and stable manner, we (i) introduce a new
score-matching objective suitable to the LSGM setting, (ii) propose a novel
parameterization of the score function that allows SGM to focus on the mismatch
of the target distribution with respect to a simple Normal one, and (iii)
analytically derive multiple techniques for variance reduction of the training
objective. LSGM obtains a state-of-the-art FID score of 2.10 on CIFAR-10,
outperforming all existing generative results on this dataset. On
CelebA-HQ-256, LSGM is on a par with previous SGMs in sample quality while
outperforming them in sampling time by two orders of magnitude. In modeling
binary images, LSGM achieves state-of-the-art likelihood on the binarized
OMNIGLOT dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Matrix Completion with Model-free Weighting. (arXiv:2106.05850v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jiayi Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1">Raymond K. W. Wong</a>, <a href="http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1">Xiaojun Mao</a>, <a href="http://arxiv.org/find/stat/1/au:+Chan_K/0/1/0/all/0/1">Kwun Chuen Gary Chan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05850">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel method for matrix completion under general
non-uniform missing structures. By controlling an upper bound of a novel
balancing error, we construct weights that can actively adjust for the
non-uniformity in the empirical risk without explicitly modeling the
observation probabilities, and can be computed efficiently via convex
optimization. The recovered matrix based on the proposed weighted empirical
risk enjoys appealing theoretical guarantees. In particular, the proposed
method achieves a stronger guarantee than existing work in terms of the scaling
with respect to the observation probabilities, under asymptotically
heterogeneous missing settings (where entry-wise observation probabilities can
be of different orders). These settings can be regarded as a better theoretical
model of missing patterns with highly varying probabilities. We also provide a
new minimax lower bound under a class of heterogeneous settings. Numerical
experiments are also provided to demonstrate the effectiveness of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Functional Priors and Posteriors from Data and Physics. (arXiv:2106.05863v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1">Xuhui Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Liu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1">Zhiping Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrandis_J/0/1/0/all/0/1">Jose del Aguila Ferrandis</a>, <a href="http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1">George Em Karniadakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05863">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a new Bayesian framework based on deep neural networks to be able
to extrapolate in space-time using historical data and to quantify
uncertainties arising from both noisy and gappy data in physical problems.
Specifically, the proposed approach has two stages: (1) prior learning and (2)
posterior estimation. At the first stage, we employ the physics-informed
Generative Adversarial Networks (PI-GAN) to learn a functional prior either
from a prescribed function distribution, e.g., Gaussian process, or from
historical data and physics. At the second stage, we employ the Hamiltonian
Monte Carlo (HMC) method to estimate the posterior in the latent space of
PI-GANs. In addition, we use two different approaches to encode the physics:
(1) automatic differentiation, used in the physics-informed neural networks
(PINNs) for scenarios with explicitly known partial differential equations
(PDEs), and (2) operator regression using the deep operator network (DeepONet)
for PDE-agnostic scenarios. We then test the proposed method for (1)
meta-learning for one-dimensional regression, and forward/inverse PDE problems
(combined with PINNs); (2) PDE-agnostic physical problems (combined with
DeepONet), e.g., fractional diffusion as well as saturated stochastic
(100-dimensional) flows in heterogeneous porous media; and (3) spatial-temporal
regression problems, i.e., inference of a marine riser displacement field. The
results demonstrate that the proposed approach can provide accurate predictions
as well as uncertainty quantification given very limited scattered and noisy
data, since historical data could be available to provide informative priors.
In summary, the proposed method is capable of learning flexible functional
priors, and can be extended to big data problems using stochastic HMC or
normalizing flows since the latent space is generally characterized as low
dimensional.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MLDemon: Deployment Monitoring for Machine Learning Systems. (arXiv:2104.13621v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ginart_A/0/1/0/all/0/1">Antonio Ginart</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Martin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13621">
                                    <div class="article-summary-box-inner">
                                        <span>Post-deployment monitoring of the performance of ML systems is critical for
ensuring reliability, especially as new user inputs can differ from the
training distribution. Here we propose a novel approach, MLDemon, for ML
DEployment MONitoring. MLDemon integrates both unlabeled features and a small
amount of on-demand labeled examples over time to produce a real-time estimate
of the ML model&#x27;s current performance on a given data stream. Subject to budget
constraints, MLDemon decides when to acquire additional, potentially costly,
supervised labels to verify the model. On temporal datasets with diverse
distribution drifts and models, MLDemon substantially outperforms existing
monitoring approaches. Moreover, we provide theoretical analysis to show that
MLDemon is minimax rate optimal up to logarithmic factors and is provably
robust against broad distribution drifts whereas prior approaches are not.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.05701v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuzhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1">Xi Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1">Runiu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05701">
                                    <div class="article-summary-box-inner">
                                        <span>HyperGraph Convolutional Neural Networks (HGCNNs) have demonstrated their
potential in modeling high-order relations preserved in graph structured data.
However, most existing convolution filters are localized and determined by the
pre-defined initial hypergraph topology, neglecting to explore implicit and
long-ange relations in real-world data. In this paper, we propose the first
learning-based method tailored for constructing adaptive hypergraph structure,
termed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic
plug-in-play module for improving the representational power of HGCNNs.
Specifically, HERALD adaptively optimizes the adjacency relationship between
hypernodes and hyperedges in an end-to-end manner and thus the task-aware
hypergraph is learned. Furthermore, HERALD employs the self-attention mechanism
to capture the non-local paired-nodes relation. Extensive experiments on
various popular hypergraph datasets for node classification and graph
classification tasks demonstrate that our approach obtains consistent and
considerable performance enhancement, proving its effectiveness and
generalization ability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large-scale optimal transport map estimation using projection pursuit. (arXiv:2106.05838v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Meng_C/0/1/0/all/0/1">Cheng Meng</a>, <a href="http://arxiv.org/find/stat/1/au:+Ke_Y/0/1/0/all/0/1">Yuan Ke</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1">Jingyi Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1">Mengrui Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhong_W/0/1/0/all/0/1">Wenxuan Zhong</a>, <a href="http://arxiv.org/find/stat/1/au:+Ma_P/0/1/0/all/0/1">Ping Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05838">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the estimation of large-scale optimal transport maps
(OTM), which is a well-known challenging problem owing to the curse of
dimensionality. Existing literature approximates the large-scale OTM by a
series of one-dimensional OTM problems through iterative random projection.
Such methods, however, suffer from slow or none convergence in practice due to
the nature of randomly selected projection directions. Instead, we propose an
estimation method of large-scale OTM by combining the idea of projection
pursuit regression and sufficient dimension reduction. The proposed method,
named projection pursuit Monge map (PPMM), adaptively selects the most
&#x60;&#x60;informative&#x27;&#x27; projection direction in each iteration. We theoretically show
the proposed dimension reduction method can consistently estimate the most
&#x60;&#x60;informative&#x27;&#x27; projection direction in each iteration. Furthermore, the PPMM
algorithm weakly convergences to the target large-scale OTM in a reasonable
number of steps. Empirically, PPMM is computationally easy and converges fast.
We assess its finite sample performance through the applications of Wasserstein
distance estimation and generative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Quantum State Sample Tomography with Basis-dependent Neural-networks. (arXiv:2009.07601v3 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Smith_A/0/1/0/all/0/1">Alistair W. R. Smith</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Gray_J/0/1/0/all/0/1">Johnnie Gray</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kim_M/0/1/0/all/0/1">M. S. Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07601">
                                    <div class="article-summary-box-inner">
                                        <span>We use a meta-learning neural-network approach to analyse data from a
measured quantum state. Once our neural network has been trained it can be used
to efficiently sample measurements of the state in measurement bases not
contained in the training data. These samples can be used calculate expectation
values and other useful quantities. We refer to this process as &quot;state sample
tomography&quot;. We encode the state&#x27;s measurement outcome distributions using an
efficiently parameterized generative neural network. This allows each stage in
the tomography process to be performed efficiently even for large systems. Our
scheme is demonstrated on recent IBM Quantum devices, producing a model for a
6-qubit state&#x27;s measurement outcomes with a predictive accuracy (classical
fidelity) &gt; 95% for all test cases using only 100 random measurement settings
as opposed to the 729 settings required for standard full tomography using
local measurements. This reduction in the required number of measurements
scales favourably, with training data in 200 measurement settings yielding a
predictive accuracy &gt; 92% for a 10 qubit state where 59,049 settings are
typically required for full local measurement-based quantum state tomography. A
reduction in number of measurements by a factor, in this case, of almost 600
could allow for estimations of expectation values and state fidelities in
practicable times on current quantum devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Train Your Differentiable Filter. (arXiv:2012.14313v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kloss_A/0/1/0/all/0/1">Alina Kloss</a>, <a href="http://arxiv.org/find/cs/1/au:+Martius_G/0/1/0/all/0/1">Georg Martius</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1">Jeannette Bohg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14313">
                                    <div class="article-summary-box-inner">
                                        <span>In many robotic applications, it is crucial to maintain a belief about the
state of a system, which serves as input for planning and decision making and
provides feedback during task execution. Bayesian Filtering algorithms address
this state estimation problem, but they require models of process dynamics and
sensory observations and the respective noise characteristics of these models.
Recently, multiple works have demonstrated that these models can be learned by
end-to-end training through differentiable versions of recursive filtering
algorithms. In this work, we investigate the advantages of differentiable
filters (DFs) over both unstructured learning approaches and manually-tuned
filtering algorithms, and provide practical guidance to researchers interested
in applying such differentiable filters. For this, we implement DFs with four
different underlying filtering algorithms and compare them in extensive
experiments. Specifically, we (i) evaluate different implementation choices and
training approaches, (ii) investigate how well complex models of uncertainty
can be learned in DFs, (iii) evaluate the effect of end-to-end training through
DFs and (iv) compare the DFs among each other and to unstructured LSTM models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Meta Learning Approach to Discerning Causal Graph Structure. (arXiv:2106.05859v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_J/0/1/0/all/0/1">Justin Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Damjakob_D/0/1/0/all/0/1">Dominik Damjakob</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05859">
                                    <div class="article-summary-box-inner">
                                        <span>We explore the usage of meta-learning to derive the causal direction between
variables by optimizing over a measure of distribution simplicity. We
incorporate a stochastic graph representation which includes latent variables
and allows for more generalizability and graph structure expression. Our model
is able to learn causal direction indicators for complex graph structures
despite effects of latent confounders. Further, we explore robustness of our
method with respect to violations of our distributional assumptions and data
scarcity. Our model is particularly robust to modest data scarcity, but is less
robust to distributional changes. By interpreting the model predictions as
stochastic events, we propose a simple ensemble method classifier to reduce the
outcome variability as an average of biased events. This methodology
demonstrates ability to infer the existence as well as the direction of a
causal relationship between data distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Cost Design for Model Predictive Control. (arXiv:2104.11353v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Avik Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_L/0/1/0/all/0/1">Lawrence Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1">Daniel S. Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca D. Dragan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11353">
                                    <div class="article-summary-box-inner">
                                        <span>Many robotics domains use some form of nonconvex model predictive control
(MPC) for planning, which sets a reduced time horizon, performs trajectory
optimization, and replans at every step. The actual task typically requires a
much longer horizon than is computationally tractable, and is specified via a
cost function that cumulates over that full horizon. For instance, an
autonomous car may have a cost function that makes a desired trade-off between
efficiency, safety, and obeying traffic laws. In this work, we challenge the
common assumption that the cost we optimize using MPC should be the same as the
ground truth cost for the task (plus a terminal cost). MPC solvers can suffer
from short planning horizons, local optima, incorrect dynamics models, and,
importantly, fail to account for future replanning ability. Thus, we propose
that in many tasks it could be beneficial to purposefully choose a different
cost function for MPC to optimize: one that results in the MPC rollout having
low ground truth cost, rather than the MPC planned trajectory. We formalize
this as an optimal cost design problem, and propose a zeroth-order
optimization-based approach that enables us to design optimal costs for an MPC
planning robot in continuous MDPs. We test our approach in an autonomous
driving domain where we find costs different from the ground truth that
implicitly compensate for replanning, short horizon, incorrect dynamics models,
and local minima issues. As an example, the learned cost incentivizes MPC to
delay its decision until later, implicitly accounting for the fact that it will
get more information in the future and be able to make a better decision. Code
and videos available at https://sites.google.com/berkeley.edu/ocd-mpc/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Informative Policy Representations in Multi-Agent Reinforcement Learning via Joint-Action Distributions. (arXiv:2106.05802v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yifan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haobin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zongqing Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05802">
                                    <div class="article-summary-box-inner">
                                        <span>In multi-agent reinforcement learning, the inherent non-stationarity of the
environment caused by other agents&#x27; actions posed significant difficulties for
an agent to learn a good policy independently. One way to deal with
non-stationarity is agent modeling, by which the agent takes into consideration
the influence of other agents&#x27; policies. Most existing work relies on
predicting other agents&#x27; actions or goals, or discriminating between their
policies. However, such modeling fails to capture the similarities and
differences between policies simultaneously and thus cannot provide useful
information when generalizing to unseen policies. To address this, we propose a
general method to learn representations of other agents&#x27; policies via the
joint-action distributions sampled in interactions. The similarities and
differences between policies are naturally captured by the policy distance
inferred from the joint-action distributions and deliberately reflected in the
learned representations. Agents conditioned on the policy representations can
well generalize to unseen agents. We empirically demonstrate that our method
outperforms existing work in multi-agent tasks when facing unseen agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmenting Hybrid Trajectories using Latent ODEs. (arXiv:2105.03835v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1">Ruian Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_Q/0/1/0/all/0/1">Quaid Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03835">
                                    <div class="article-summary-box-inner">
                                        <span>Smooth dynamics interrupted by discontinuities are known as hybrid systems
and arise commonly in nature. Latent ODEs allow for powerful representation of
irregularly sampled time series but are not designed to capture trajectories
arising from hybrid systems. Here, we propose the Latent Segmented ODE
(LatSegODE), which uses Latent ODEs to perform reconstruction and changepoint
detection within hybrid trajectories featuring jump discontinuities and
switching dynamical modes. Where it is possible to train a Latent ODE on the
smooth dynamical flows between discontinuities, we apply the pruned exact
linear time (PELT) algorithm to detect changepoints where latent dynamics
restart, thereby maximizing the joint probability of a piece-wise continuous
latent dynamical representation. We propose usage of the marginal likelihood as
a score function for PELT, circumventing the need for model complexity-based
penalization. The LatSegODE outperforms baselines in reconstructive and
segmentation tasks including synthetic data sets of sine waves, Lotka Volterra
dynamics, and UCI Character Trajectories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformed CNNs: recasting pre-trained convolutional layers with self-attention. (arXiv:2106.05795v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+dAscoli_S/0/1/0/all/0/1">St&#xe9;phane d&#x27;Ascoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagun_L/0/1/0/all/0/1">Levent Sagun</a>, <a href="http://arxiv.org/find/cs/1/au:+Biroli_G/0/1/0/all/0/1">Giulio Biroli</a>, <a href="http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1">Ari Morcos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05795">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformers (ViT) have recently emerged as a powerful alternative to
convolutional networks (CNNs). Although hybrid models attempt to bridge the gap
between these two architectures, the self-attention layers they rely on induce
a strong computational bottleneck, especially at large spatial resolutions. In
this work, we explore the idea of reducing the time spent training these layers
by initializing them as convolutional layers. This enables us to transition
smoothly from any pre-trained CNN to its functionally identical hybrid model,
called Transformed CNN (T-CNN). With only 50 epochs of fine-tuning, the
resulting T-CNNs demonstrate significant performance gains over the CNN (+2.2%
top-1 on ImageNet-1k for a ResNet50-RS) as well as substantially improved
robustness (+11% top-1 on ImageNet-C). We analyze the representations learnt by
the T-CNN, providing deeper insights into the fruitful interplay between
convolutions and self-attention. Finally, we experiment initializing the T-CNN
from a partially trained CNN, and find that it reaches better performance than
the corresponding hybrid model trained from scratch, while reducing training
time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Bayesian inference for multiple changepoints and risk assessment. (arXiv:2106.05834v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sorba_O/0/1/0/all/0/1">Olivier Sorba</a>, <a href="http://arxiv.org/find/cs/1/au:+Geissler_C/0/1/0/all/0/1">C Geissler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05834">
                                    <div class="article-summary-box-inner">
                                        <span>The aim of the present study is to detect abrupt trend changes in the mean of
a multidimensional sequential signal. Directly inspired by papers of Fernhead
and Liu ([4] and [5]), this work describes the signal in a hierarchical manner
: the change dates of a time segmentation process trigger the renewal of a
piece-wise constant emission law. Bayesian posterior information on the change
dates and emission parameters is obtained. These estimations can be revised
online, i.e. as new data arrive. This paper proposes explicit formulations
corresponding to various emission laws, as well as a generalization to the case
where only partially observed data are available. Practical applications
include the returns of partially observed multi-asset investment strategies,
when only scant prior knowledge of the movers of the returns is at hand,
limited to some statistical assumptions. This situation is different from the
study of trend changes in the returns of individual assets, where fundamental
exogenous information (news, earnings announcements, controversies, etc.) can
be used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dataset Condensation with Differentiable Siamese Augmentation. (arXiv:2102.08259v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1">Hakan Bilen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08259">
                                    <div class="article-summary-box-inner">
                                        <span>In many machine learning problems, large-scale datasets have become the
de-facto standard to train state-of-the-art deep networks at the price of heavy
computation load. In this paper, we focus on condensing large training sets
into significantly smaller synthetic sets which can be used to train deep
neural networks from scratch with minimum drop in performance. Inspired from
the recent training set synthesis methods, we propose Differentiable Siamese
Augmentation that enables effective use of data augmentation to synthesize more
informative synthetic images and thus achieves better performance when training
networks with augmentations. Experiments on multiple image classification
benchmarks demonstrate that the proposed method obtains substantial gains over
the state-of-the-art, 7% improvements on CIFAR10 and CIFAR100 datasets. We show
with only less than 1% data that our method achieves 99.6%, 94.9%, 88.5%, 71.5%
relative performance on MNIST, FashionMNIST, SVHN, CIFAR10 respectively. We
also explore the use of our method in continual learning and neural
architecture search, and show promising results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits. (arXiv:2106.02029v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhan_R/0/1/0/all/0/1">Ruohan Zhan</a>, <a href="http://arxiv.org/find/stat/1/au:+Hadad_V/0/1/0/all/0/1">Vitor Hadad</a>, <a href="http://arxiv.org/find/stat/1/au:+Hirshberg_D/0/1/0/all/0/1">David A. Hirshberg</a>, <a href="http://arxiv.org/find/stat/1/au:+Athey_S/0/1/0/all/0/1">Susan Athey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02029">
                                    <div class="article-summary-box-inner">
                                        <span>It has become increasingly common for data to be collected adaptively, for
example using contextual bandits. Historical data of this type can be used to
evaluate other treatment assignment policies to guide future innovation or
experiments. However, policy evaluation is challenging if the target policy
differs from the one used to collect data, and popular estimators, including
doubly robust (DR) estimators, can be plagued by bias, excessive variance, or
both. In particular, when the pattern of treatment assignment in the collected
data looks little like the pattern generated by the policy to be evaluated, the
importance weights used in DR estimators explode, leading to excessive
variance.

In this paper, we improve the DR estimator by adaptively weighting
observations to control its variance. We show that a t-statistic based on our
improved estimator is asymptotically normal under certain conditions, allowing
us to form confidence intervals and test hypotheses. Using synthetic data and
public benchmarks, we provide empirical evidence for our estimator&#x27;s improved
accuracy and inferential properties relative to existing alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-resolution Outlier Pooling for Sorghum Classification. (arXiv:2106.05748v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_C/0/1/0/all/0/1">Chao Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Dulay_J/0/1/0/all/0/1">Justin Dulay</a>, <a href="http://arxiv.org/find/cs/1/au:+Rolwes_G/0/1/0/all/0/1">Gregory Rolwes</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauli_D/0/1/0/all/0/1">Duke Pauli</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakoor_N/0/1/0/all/0/1">Nadia Shakoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1">Abby Stylianou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05748">
                                    <div class="article-summary-box-inner">
                                        <span>Automated high throughput plant phenotyping involves leveraging sensors, such
as RGB, thermal and hyperspectral cameras (among others), to make large scale
and rapid measurements of the physical properties of plants for the purpose of
better understanding the difference between crops and facilitating rapid plant
breeding programs. One of the most basic phenotyping tasks is to determine the
cultivar, or species, in a particular sensor product. This simple phenotype can
be used to detect errors in planting and to learn the most differentiating
features between cultivars. It is also a challenging visual recognition task,
as a large number of highly related crops are grown simultaneously, leading to
a classification problem with low inter-class variance. In this paper, we
introduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum
captured by a state-of-the-art gantry system, a multi-resolution network
architecture that learns both global and fine-grained features on the crops,
and a new global pooling strategy called Dynamic Outlier Pooling which
outperforms standard global pooling strategies on this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-time simulation of parameter-dependent fluid flows through deep learning-based reduced order models. (arXiv:2106.05722v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Fresca_S/0/1/0/all/0/1">Stefania Fresca</a>, <a href="http://arxiv.org/find/physics/1/au:+Manzoni_A/0/1/0/all/0/1">Andrea Manzoni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05722">
                                    <div class="article-summary-box-inner">
                                        <span>Simulating fluid flows in different virtual scenarios is of key importance in
engineering applications. However, high-fidelity, full-order models relying,
e.g., on the finite element method, are unaffordable whenever fluid flows must
be simulated in almost real-time. Reduced order models (ROMs) relying, e.g., on
proper orthogonal decomposition (POD) provide reliable approximations to
parameter-dependent fluid dynamics problems in rapid times. However, they might
require expensive hyper-reduction strategies for handling parameterized
nonlinear terms, and enriched reduced spaces (or Petrov-Galerkin projections)
if a mixed velocity-pressure formulation is considered, possibly hampering the
evaluation of reliable solutions in real-time. Dealing with fluid-structure
interactions entails even higher difficulties. The proposed deep learning
(DL)-based ROMs overcome all these limitations by learning in a non-intrusive
way both the nonlinear trial manifold and the reduced dynamics. To do so, they
rely on deep neural networks, after performing a former dimensionality
reduction through POD enhancing their training times substantially. The
resulting POD-DL-ROMs are shown to provide accurate results in almost real-time
for the flow around a cylinder benchmark, the fluid-structure interaction
between an elastic beam attached to a fixed, rigid block and a laminar
incompressible flow, and the blood flow in a cerebral aneurysm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Reinforcement Learning for Procedural Content Generation. (arXiv:2103.04847v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1">Linus Gissl&#xe9;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Eakins_A/0/1/0/all/0/1">Andy Eakins</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordillo_C/0/1/0/all/0/1">Camilo Gordillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergdahl_J/0/1/0/all/0/1">Joakim Bergdahl</a>, <a href="http://arxiv.org/find/cs/1/au:+Tollmar_K/0/1/0/all/0/1">Konrad Tollmar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04847">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new approach ARLPCG: Adversarial Reinforcement Learning for
Procedural Content Generation, which procedurally generates and tests
previously unseen environments with an auxiliary input as a control variable.
Training RL agents over novel environments is a notoriously difficult task. One
popular approach is to procedurally generate different environments to increase
the generalizability of the trained agents. ARLPCG instead deploys an
adversarial model with one PCG RL agent (called Generator) and one solving RL
agent (called Solver). The Generator receives a reward signal based on the
Solver&#x27;s performance, which encourages the environment design to be challenging
but not impossible. To further drive diversity and control of the environment
generation, we propose using auxiliary inputs for the Generator. The benefit is
two-fold: Firstly, the Solver achieves better generalization through the
Generator&#x27;s generated challenges. Secondly, the trained Generator can be used
as a creator of novel environments that, together with the Solver, can be shown
to be solvable. We create two types of 3D environments to validate our model,
representing two popular game genres: a third-person platformer and a racing
game. In these cases, we shows that ARLPCG has a significantly better solve
ratio, and that the auxiliary inputs renders the levels creation controllable
to a certain degree. For a video compilation of the results please visit
https://youtu.be/z7q2PtVsT0I.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">dFDA-VeD: A Dynamic Future Demand Aware Vehicle Dispatching System. (arXiv:2106.05737v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Guo_Y/0/1/0/all/0/1">Yang Guo</a>, <a href="http://arxiv.org/find/math/1/au:+Anwar_T/0/1/0/all/0/1">Tarique Anwar</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a>, <a href="http://arxiv.org/find/math/1/au:+Wu_J/0/1/0/all/0/1">Jia Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05737">
                                    <div class="article-summary-box-inner">
                                        <span>With the rising demand of smart mobility, ride-hailing service is getting
popular in the urban regions. These services maintain a system for serving the
incoming trip requests by dispatching available vehicles to the pickup points.
As the process should be socially and economically profitable, the task of
vehicle dispatching is highly challenging, specially due to the time-varying
travel demands and traffic conditions. Due to the uneven distribution of travel
demands, many idle vehicles could be generated during the operation in
different subareas. Most of the existing works on vehicle dispatching system,
designed static relocation centers to relocate idle vehicles. However, as
traffic conditions and demand distribution dynamically change over time, the
static solution can not fit the evolving situations. In this paper, we propose
a dynamic future demand aware vehicle dispatching system. It can dynamically
search the relocation centers considering both travel demand and traffic
conditions. We evaluate the system on real-world dataset, and compare with the
existing state-of-the-art methods in our experiments in terms of several
standard evaluation metrics and operation time. Through our experiments, we
demonstrate that the proposed system significantly improves the serving ratio
and with a very small increase in operation cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation in Bayesian neural networks and the cold posterior effect. (arXiv:2106.05586v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nabarro_S/0/1/0/all/0/1">Seth Nabarro</a>, <a href="http://arxiv.org/find/stat/1/au:+Ganev_S/0/1/0/all/0/1">Stoil Ganev</a>, <a href="http://arxiv.org/find/stat/1/au:+Garriga_Alonso_A/0/1/0/all/0/1">Adri&#xe0; Garriga-Alonso</a>, <a href="http://arxiv.org/find/stat/1/au:+Fortuin_V/0/1/0/all/0/1">Vincent Fortuin</a>, <a href="http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1">Mark van der Wilk</a>, <a href="http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1">Laurence Aitchison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05586">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation is a highly effective approach for improving performance in
deep neural networks. The standard view is that it creates an enlarged dataset
by adding synthetic data, which raises a problem when combining it with
Bayesian inference: how much data are we really conditioning on? This question
is particularly relevant to recent observations linking data augmentation to
the cold posterior effect. We investigate various principled ways of finding a
log-likelihood for augmented datasets. Our approach prescribes augmenting the
same underlying image multiple times, both at test and train-time, and
averaging either the logits or the predictive probabilities. Empirically, we
observe the best performance with averaging probabilities. While there are
interactions with the cold posterior effect, neither averaging logits or
averaging probabilities eliminates it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifiability of interaction kernels in mean-field equations of interacting particles. (arXiv:2106.05565v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lang_Q/0/1/0/all/0/1">Quanjun Lang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lu_F/0/1/0/all/0/1">Fei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05565">
                                    <div class="article-summary-box-inner">
                                        <span>We study the identifiability of the interaction kernels in mean-field
equations for intreacting particle systems. The key is to identify function
spaces on which a probabilistic loss functional has a unique minimizer. We
prove that identifiability holds on any subspace of two reproducing kernel
Hilbert spaces (RKHS), whose reproducing kernels are intrinsic to the system
and are data-adaptive. Furthermore, identifiability holds on two ambient L2
spaces if and only if the integral operators associated with the reproducing
kernels are strictly positive. Thus, the inverse problem is ill-posed in
general. We also discuss the implications of identifiability in computational
practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predictive Factors of Kinematics in Traumatic Brain Injury from Head Impacts Based on Statistical Interpretation. (arXiv:2102.05020v3 [physics.bio-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Zhan_X/0/1/0/all/0/1">Xianghao Zhan</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_Y/0/1/0/all/0/1">Yiheng Li</a>, <a href="http://arxiv.org/find/physics/1/au:+Liu_Y/0/1/0/all/0/1">Yuzhe Liu</a>, <a href="http://arxiv.org/find/physics/1/au:+Domel_A/0/1/0/all/0/1">August G. Domel</a>, <a href="http://arxiv.org/find/physics/1/au:+Alizadeh_H/0/1/0/all/0/1">Hossein Vahid Alizadeh</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhou_Z/0/1/0/all/0/1">Zhou Zhou</a>, <a href="http://arxiv.org/find/physics/1/au:+Cecchi_N/0/1/0/all/0/1">Nicholas J. Cecchi</a>, <a href="http://arxiv.org/find/physics/1/au:+Raymond_S/0/1/0/all/0/1">Samuel J. Raymond</a>, <a href="http://arxiv.org/find/physics/1/au:+Tiernan_S/0/1/0/all/0/1">Stephen Tiernan</a>, <a href="http://arxiv.org/find/physics/1/au:+Ruan_J/0/1/0/all/0/1">Jesse Ruan</a>, <a href="http://arxiv.org/find/physics/1/au:+Barbat_S/0/1/0/all/0/1">Saeed Barbat</a>, <a href="http://arxiv.org/find/physics/1/au:+Gevaert_O/0/1/0/all/0/1">Olivier Gevaert</a>, <a href="http://arxiv.org/find/physics/1/au:+Zeineh_M/0/1/0/all/0/1">Michael M. Zeineh</a>, <a href="http://arxiv.org/find/physics/1/au:+Grant_G/0/1/0/all/0/1">Gerald A. Grant</a>, <a href="http://arxiv.org/find/physics/1/au:+Camarillo_D/0/1/0/all/0/1">David B. Camarillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05020">
                                    <div class="article-summary-box-inner">
                                        <span>Brain tissue deformation resulting from head impacts is primarily caused by
rotation and can lead to traumatic brain injury. To quantify brain injury risk
based on measurements of kinematics on the head, finite element (FE) models and
various brain injury criteria based on different factors of these kinematics
have been developed, but the contribution of different kinematic factors has
not been comprehensively analyzed across different types of head impacts in a
data-driven manner. To better design brain injury criteria, the predictive
power of rotational kinematics factors, which are different in 1) the
derivative order (angular velocity, angular acceleration, angular jerk), 2) the
direction and 3) the power (e.g., square-rooted, squared, cubic) of the angular
velocity, were analyzed based on different datasets including laboratory
impacts, American football, mixed martial arts (MMA), NHTSA automobile
crashworthiness tests and NASCAR crash events. Ordinary least squares
regressions were built from kinematics factors to the 95\% maximum principal
strain (MPS95), and we compared zero-order correlation coefficients, structure
coefficients, commonality analysis, and dominance analysis. The angular
acceleration, the magnitude, and the first power factors showed the highest
predictive power for the majority of impacts including laboratory impacts,
American football impacts, with few exceptions (angular velocity for MMA and
NASCAR impacts). The predictive power of rotational kinematics in three
directions (x: posterior-to-anterior, y: left-to-right, z:
superior-to-inferior) of kinematics varied with different sports and types of
head impacts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Code Generation from Natural Language with Less Prior and More Monolingual Data. (arXiv:2101.00259v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Norouzi_S/0/1/0/all/0/1">Sajad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Keyi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yanshuai Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00259">
                                    <div class="article-summary-box-inner">
                                        <span>Training datasets for semantic parsing are typically small due to the higher
expertise required for annotation than most other NLP tasks. As a result,
models for this application usually need additional prior knowledge to be built
into the architecture or algorithm. The increased dependency on human experts
hinders automation and raises the development and maintenance costs in
practice. This work investigates whether a generic transformer-based seq2seq
model can achieve competitive performance with minimal code-generation-specific
inductive bias design. By exploiting a relatively sizeable monolingual corpus
of the target programming language, which is cheap to mine from the web, we
achieved 81.03% exact match accuracy on Django and 32.57 BLEU score on CoNaLa.
Both are SOTA to the best of our knowledge. This positive evidence highlights a
potentially easier path toward building accurate semantic parsers in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Based Proximity Matrix Factorization for Node Embedding. (arXiv:2106.05476v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xingyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1">Kun Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zengfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05476">
                                    <div class="article-summary-box-inner">
                                        <span>Node embedding learns a low-dimensional representation for each node in the
graph. Recent progress on node embedding shows that proximity matrix
factorization methods gain superb performance and scale to large graphs with
millions of nodes. Existing approaches first define a proximity matrix and then
learn the embeddings that fit the proximity by matrix factorization. Most
existing matrix factorization methods adopt the same proximity for different
tasks, while it is observed that different tasks and datasets may require
different proximity, limiting their representation power.

Motivated by this, we propose {\em Lemane}, a framework with trainable
proximity measures, which can be learned to best suit the datasets and tasks at
hand automatically. Our method is end-to-end, which incorporates differentiable
SVD in the pipeline so that the parameters can be trained via backpropagation.
However, this learning process is still expensive on large graphs. To improve
the scalability, we train proximity measures only on carefully subsampled
graphs, and then apply standard proximity matrix factorization on the original
graph using the learned proximity. Note that, computing the learned proximities
for each pair is still expensive for large graphs, and existing techniques for
computing proximities are not applicable to the learned proximities. Thus, we
present generalized push techniques to make our solution scalable to large
graphs with millions of nodes. Extensive experiments show that our proposed
solution outperforms existing solutions on both link prediction and node
classification tasks on almost all datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search of SPD Manifold Networks. (arXiv:2010.14535v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1">Rhea Sanjay Sukthanker</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiwu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Suryansh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Endsjo_E/0/1/0/all/0/1">Erik Goron Endsjo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14535">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a new neural architecture search (NAS) problem of
Symmetric Positive Definite (SPD) manifold networks, aiming to automate the
design of SPD neural architectures. To address this problem, we first introduce
a geometrically rich and diverse SPD neural architecture search space for an
efficient SPD cell design. Further, we model our new NAS problem with a
one-shot training process of a single supernet. Based on the supernet modeling,
we exploit a differentiable NAS algorithm on our relaxed continuous search
space for SPD neural architecture search. Statistical evaluation of our method
on drone, action, and emotion recognition tasks mostly provides better results
than the state-of-the-art SPD networks and traditional NAS algorithms.
Empirical results show that our algorithm excels in discovering better
performing SPD network design and provides models that are more than three
times lighter than searched by the state-of-the-art NAS algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relative Positional Encoding for Transformers with Linear Complexity. (arXiv:2105.08399v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1">Antoine Liutkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1">Ond&#x159;ej C&#xed;fka</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shih-Lun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1">Umut &#x15e;im&#x15f;ekli</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08399">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in Transformer models allow for unprecedented sequence
lengths, due to linear space and time complexity. In the meantime, relative
positional encoding (RPE) was proposed as beneficial for classical Transformers
and consists in exploiting lags instead of absolute positions for inference.
Still, RPE is not available for the recent linear-variants of the Transformer,
because it requires the explicit computation of the attention matrix, which is
precisely what is avoided by such methods. In this paper, we bridge this gap
and present Stochastic Positional Encoding as a way to generate PE that can be
used as a replacement to the classical additive (sinusoidal) PE and provably
behaves like RPE. The main theoretical contribution is to make a connection
between positional encoding and cross-covariance structures of correlated
Gaussian processes. We illustrate the performance of our approach on the
Long-Range Arena benchmark and on music generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SignalNet: A Low Resolution Sinusoid Decomposition and Estimation Network. (arXiv:2106.05490v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Dreifuerst_R/0/1/0/all/0/1">Ryan Dreifuerst</a>, <a href="http://arxiv.org/find/eess/1/au:+Heath_R/0/1/0/all/0/1">Robert W. Heath Jr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05490">
                                    <div class="article-summary-box-inner">
                                        <span>The detection and estimation of sinusoids is a fundamental signal processing
task for many applications related to sensing and communications. While
algorithms have been proposed for this setting, quantization is a critical, but
often ignored modeling effect. In wireless communications, estimation with low
resolution data converters is relevant for reduced power consumption in
wideband receivers. Similarly, low resolution sampling in imaging and spectrum
sensing allows for efficient data collection. In this work, we propose
SignalNet, a neural network architecture that detects the number of sinusoids
and estimates their parameters from quantized in-phase and quadrature samples.
We incorporate signal reconstruction internally as domain knowledge within the
network to enhance learning and surpass traditional algorithms in mean squared
error and Chamfer error. We introduce a worst-case learning threshold for
comparing the results of our network relative to the underlying data
distributions. This threshold provides insight into why neural networks tend to
outperform traditional methods and into the learned relationships between the
input and output distributions. In simulation, we find that our algorithm is
always able to surpass the threshold for three-bit data but often cannot exceed
the threshold for one-bit data. We use the learning threshold to explain, in
the one-bit case, how our estimators learn to minimize the distributional loss,
rather than learn features from the data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at Reliable OOD Detection. (arXiv:2012.05329v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ulmer_D/0/1/0/all/0/1">Dennis Ulmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Cina_G/0/1/0/all/0/1">Giovanni Cin&#xe0;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05329">
                                    <div class="article-summary-box-inner">
                                        <span>A crucial requirement for reliable deployment of deep learning models for
safety-critical applications is the ability to identify out-of-distribution
(OOD) data points, samples which differ from the training data and on which a
model might underperform. Previous work has attempted to tackle this problem
using uncertainty estimation techniques. However, there is empirical evidence
that a large family of these techniques do not detect OOD reliably in
classification tasks.

This paper gives a theoretical explanation for said experimental findings and
illustrates it on synthetic data. We prove that such techniques are not able to
reliably identify OOD samples in a classification setting, since their level of
confidence is generalized to unseen areas of the feature space. This result
stems from the interplay between the representation of ReLU networks as
piece-wise affine transformations, the saturating nature of activation
functions like softmax, and the most widely-used uncertainty metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Classifiers that Encourage Constructive Adaptation. (arXiv:2011.00355v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yatong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jialu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00355">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning systems are often used in settings where individuals adapt
their features to obtain a desired outcome. In such settings, strategic
behavior leads to a sharp loss in model performance in deployment. In this
work, we aim to address this problem by learning classifiers that encourage
decision subjects to change their features in a way that leads to improvement
in both predicted \emph{and} true outcome. We frame the dynamics of prediction
and adaptation as a two-stage game, and characterize optimal strategies for the
model designer and its decision subjects. In benchmarks on simulated and
real-world datasets, we find that classifiers trained using our method maintain
the accuracy of existing approaches while inducing higher levels of improvement
and less manipulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DNN-Based Topology Optimisation: Spatial Invariance and Neural Tangent Kernel. (arXiv:2106.05710v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dupuis_B/0/1/0/all/0/1">Benjamin Dupuis</a>, <a href="http://arxiv.org/find/stat/1/au:+Jacot_A/0/1/0/all/0/1">Arthur Jacot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05710">
                                    <div class="article-summary-box-inner">
                                        <span>We study the SIMP method with a density field generated by a fully-connected
neural network, taking the coordinates as inputs. In the large width limit, we
show that the use of DNNs leads to a filtering effect similar to traditional
filtering techniques for SIMP, with a filter described by the Neural Tangent
Kernel (NTK). This filter is however not invariant under translation, leading
to visual artifacts and non-optimal shapes. We propose two embeddings of the
input coordinates, which lead to (approximate) spatial invariance of the NTK
and of the filter. We empirically confirm our theoretical observations and
study how the filter size is affected by the architecture of the network. Our
solution can easily be applied to any other coordinates-based generation
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Fusion for Deep Learning on Transport Mode Detection: A Case Study. (arXiv:2106.05876v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreau_H/0/1/0/all/0/1">Hugues Moreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilev_A/0/1/0/all/0/1">Andr&#xe9;a Vassilev</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liming Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05876">
                                    <div class="article-summary-box-inner">
                                        <span>In Transport Mode Detection, a great diversity of methodologies exist
according to the choice made on sensors, preprocessing, model used, etc. In
this domain, the comparisons between each option are not always complete.
Experiments on a public, real-life dataset are led here to evaluate carefully
each of the choices that were made, with a specific emphasis on data fusion
methods. Our most surprising finding is that none of the methods we implemented
from the literature is better than a simple late fusion. Two important
decisions are the choice of a sensor and the choice of a representation for the
data: we found that using 2D convolutions on spectrograms with a logarithmic
axis for the frequencies was better than 1-dimensional temporal
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness for Cooperative Multi-Agent Learning with Equivariant Policies. (arXiv:2106.05727v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grupen_N/0/1/0/all/0/1">Niko A. Grupen</a>, <a href="http://arxiv.org/find/cs/1/au:+Selman_B/0/1/0/all/0/1">Bart Selman</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel D. Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05727">
                                    <div class="article-summary-box-inner">
                                        <span>We study fairness through the lens of cooperative multi-agent learning. Our
work is motivated by empirical evidence that naive maximization of team reward
yields unfair outcomes for individual team members. To address fairness in
multi-agent contexts, we introduce team fairness, a group-based fairness
measure for multi-agent learning. We then incorporate team fairness into policy
optimization -- introducing Fairness through Equivariance (Fair-E), a novel
learning strategy that achieves provably fair reward distributions. We then
introduce Fairness through Equivariance Regularization (Fair-ER) as a
soft-constraint version of Fair-E and show that Fair-ER reaches higher levels
of utility than Fair-E and fairer outcomes than policies with no equivariance.
Finally, we investigate the fairness-utility trade-off in multi-agent settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep neural network loses attention to adversarial images. (arXiv:2106.05657v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kotyan_S/0/1/0/all/0/1">Shashank Kotyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1">Danilo Vasconcellos Vargas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05657">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial algorithms have shown to be effective against neural networks for
a variety of tasks. Some adversarial algorithms perturb all the pixels in the
image minimally for the image classification task in image classification. In
contrast, some algorithms perturb few pixels strongly. However, very little
information is available regarding why these adversarial samples so diverse
from each other exist. Recently, Vargas et al. showed that the existence of
these adversarial samples might be due to conflicting saliency within the
neural network. We test this hypothesis of conflicting saliency by analysing
the Saliency Maps (SM) and Gradient-weighted Class Activation Maps (Grad-CAM)
of original and few different types of adversarial samples. We also analyse how
different adversarial samples distort the attention of the neural network
compared to original samples. We show that in the case of Pixel Attack,
perturbed pixels either calls the network attention to themselves or divert the
attention from them. Simultaneously, the Projected Gradient Descent Attack
perturbs pixels so that intermediate layers inside the neural network lose
attention for the correct class. We also show that both attacks affect the
saliency map and activation maps differently. Thus, shedding light on why some
defences successful against some attacks remain vulnerable against other
attacks. We hope that this analysis will improve understanding of the existence
and the effect of adversarial samples and enable the community to develop more
robust neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GBHT: Gradient Boosting Histogram Transform for Density Estimation. (arXiv:2106.05738v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Cui_J/0/1/0/all/0/1">Jingyi Cui</a>, <a href="http://arxiv.org/find/stat/1/au:+Hang_H/0/1/0/all/0/1">Hanyuan Hang</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05738">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a density estimation algorithm called
\textit{Gradient Boosting Histogram Transform} (GBHT), where we adopt the
\textit{Negative Log Likelihood} as the loss function to make the boosting
procedure available for the unsupervised tasks. From a learning theory
viewpoint, we first prove fast convergence rates for GBHT with the smoothness
assumption that the underlying density function lies in the space
$C^{0,\alpha}$. Then when the target density function lies in spaces
$C^{1,\alpha}$, we present an upper bound for GBHT which is smaller than the
lower bound of its corresponding base learner, in the sense of convergence
rates. To the best of our knowledge, we make the first attempt to theoretically
explain why boosting can enhance the performance of its base learners for
density estimation problems. In experiments, we not only conduct performance
comparisons with the widely used KDE, but also apply GBHT to anomaly detection
to showcase a further application of GBHT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A multi-objective perspective on jointly tuning hardware and hyperparameters. (arXiv:2106.05680v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salinas_D/0/1/0/all/0/1">David Salinas</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrone_V/0/1/0/all/0/1">Valerio Perrone</a>, <a href="http://arxiv.org/find/cs/1/au:+Cruchant_O/0/1/0/all/0/1">Olivier Cruchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1">Cedric Archambeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05680">
                                    <div class="article-summary-box-inner">
                                        <span>In addition to the best model architecture and hyperparameters, a full AutoML
solution requires selecting appropriate hardware automatically. This can be
framed as a multi-objective optimization problem: there is not a single best
hardware configuration but a set of optimal ones achieving different trade-offs
between cost and runtime. In practice, some choices may be overly costly or
take days to train. To lift this burden, we adopt a multi-objective approach
that selects and adapts the hardware configuration automatically alongside
neural architectures and their hyperparameters. Our method builds on Hyperband
and extends it in two ways. First, we replace the stopping rule used in
Hyperband by a non-dominated sorting rule to preemptively stop unpromising
configurations. Second, we leverage hyperparameter evaluations from related
tasks via transfer learning by building a probabilistic estimate of the Pareto
front that finds promising configurations more efficiently than random search.
We show in extensive NAS and HPO experiments that both ingredients bring
significant speed-ups and cost savings, with little to no impact on accuracy.
In three benchmarks where hardware is selected in addition to hyperparameters,
we obtain runtime and cost reductions of at least 5.8x and 8.8x, respectively.
Furthermore, when applying our multi-objective method to the tuning of
hyperparameters only, we obtain a 10\% improvement in runtime while maintaining
the same accuracy on two popular NAS benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness-Aware Node Representation Learning. (arXiv:2106.05391v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kose_O/0/1/0/all/0/1">&#xd6;yk&#xfc; Deniz K&#xf6;se</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yanning Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05391">
                                    <div class="article-summary-box-inner">
                                        <span>Node representation learning has demonstrated its effectiveness for various
applications on graphs. Particularly, recent developments in contrastive
learning have led to promising results in unsupervised node representation
learning for a number of tasks. Despite the success of graph contrastive
learning and consequent growing interest, fairness is largely under-explored in
the field. To this end, this study addresses fairness issues in graph
contrastive learning with fairness-aware graph augmentation designs, through
adaptive feature masking and edge deletion. In the study, different fairness
notions on graphs are introduced, which serve as guidelines for the proposed
graph augmentations. Furthermore, theoretical analysis is provided to
quantitatively prove that the proposed feature masking approach can reduce
intrinsic bias. Experimental results on real social networks are presented to
demonstrate that the proposed augmentations can enhance fairness in terms of
statistical parity and equal opportunity, while providing comparable
classification accuracy to state-of-the-art contrastive methods for node
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deception in Social Learning: A Multi-Agent Reinforcement Learning Perspective. (arXiv:2106.05402v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chelarescu_P/0/1/0/all/0/1">Paul Chelarescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05402">
                                    <div class="article-summary-box-inner">
                                        <span>Within the framework of Multi-Agent Reinforcement Learning, Social Learning
is a new class of algorithms that enables agents to reshape the reward function
of other agents with the goal of promoting cooperation and achieving higher
global rewards in mixed-motive games. However, this new modification allows
agents unprecedented access to each other&#x27;s learning process, which can
drastically increase the risk of manipulation when an agent does not realize it
is being deceived into adopting policies which are not actually in its own best
interest. This research review introduces the problem statement, defines key
concepts, critically evaluates existing evidence and addresses open problems
that should be addressed in future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervising the Transfer of Reasoning Patterns in VQA. (arXiv:2106.05597v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1">Corentin Kervadec</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1">Christian Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Antipov_G/0/1/0/all/0/1">Grigory Antipov</a>, <a href="http://arxiv.org/find/cs/1/au:+Baccouche_M/0/1/0/all/0/1">Moez Baccouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadri_M/0/1/0/all/0/1">Madiha Nadri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05597">
                                    <div class="article-summary-box-inner">
                                        <span>Methods for Visual Question Anwering (VQA) are notorious for leveraging
dataset biases rather than performing reasoning, hindering generalization. It
has been recently shown that better reasoning patterns emerge in attention
layers of a state-of-the-art VQA model when they are trained on perfect
(oracle) visual inputs. This provides evidence that deep neural networks can
learn to reason when training conditions are favorable enough. However,
transferring this learned knowledge to deployable models is a challenge, as
much of it is lost during the transfer. We propose a method for knowledge
transfer based on a regularization term in our loss function, supervising the
sequence of required reasoning operations. We provide a theoretical analysis
based on PAC-learning, showing that such program prediction can lead to
decreased sample complexity under mild hypotheses. We also demonstrate the
effectiveness of this approach experimentally on the GQA dataset and show its
complementarity to BERT-like self-supervised pre-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Central Limit Theorem, Loss Aversion and Multi-Armed Bandits. (arXiv:2106.05472v1 [math.PR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chen_Z/0/1/0/all/0/1">Zengjing Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Epstein_L/0/1/0/all/0/1">Larry G. Epstein</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_G/0/1/0/all/0/1">Guodong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05472">
                                    <div class="article-summary-box-inner">
                                        <span>This paper establishes a central limit theorem under the assumption that
conditional variances can vary in a largely unstructured history-dependent way
across experiments subject only to the restriction that they lie in a fixed
interval. Limits take a novel and tractable form, and are expressed in terms of
oscillating Brownian motion. A second contribution is application of this
result to a class of multi-armed bandit problems where the decision-maker is
loss averse.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thompson Sampling with a Mixture Prior. (arXiv:2106.05608v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1">Joey Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1">Branislav Kveton</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Manzil Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Boutilier_C/0/1/0/all/0/1">Craig Boutilier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05608">
                                    <div class="article-summary-box-inner">
                                        <span>We study Thompson sampling (TS) in online decision-making problems where the
uncertain environment is sampled from a mixture distribution. This is relevant
to multi-task settings, where a learning agent is faced with different classes
of problems. We incorporate this structure in a natural way by initializing TS
with a mixture prior -- dubbed MixTS -- and develop a novel, general technique
for analyzing the regret of TS with such priors. We apply this technique to
derive Bayes regret bounds for MixTS in both linear bandits and tabular Markov
decision processes (MDPs). Our regret bounds reflect the structure of the
problem and depend on the number of components and confidence width of each
component of the prior. Finally, we demonstrate the empirical effectiveness of
MixTS in both synthetic and real-world experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cocktail: Leveraging Ensemble Learning for Optimized Model Serving in Public Cloud. (arXiv:2106.05345v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunasekaran_J/0/1/0/all/0/1">Jashwant Raj Gunasekaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_C/0/1/0/all/0/1">Cyan Subhra Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Thinakaran_P/0/1/0/all/0/1">Prashanth Thinakaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1">Mahmut Taylan Kandemir</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_C/0/1/0/all/0/1">Chita R. Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05345">
                                    <div class="article-summary-box-inner">
                                        <span>With a growing demand for adopting ML models for a varietyof application
services, it is vital that the frameworks servingthese models are capable of
delivering highly accurate predic-tions with minimal latency along with reduced
deploymentcosts in a public cloud environment. Despite high latency,prior works
in this domain are crucially limited by the accu-racy offered by individual
models. Intuitively, model ensem-bling can address the accuracy gap by
intelligently combiningdifferent models in parallel. However, selecting the
appro-priate models dynamically at runtime to meet the desiredaccuracy with low
latency at minimal deployment cost is anontrivial problem. Towards this, we
proposeCocktail, a costeffective ensembling-based model serving
framework.Cock-tailcomprises of two key components: (i) a dynamic
modelselection framework, which reduces the number of modelsin the ensemble,
while satisfying the accuracy and latencyrequirements; (ii) an adaptive
resource management (RM)framework that employs a distributed proactive
autoscalingpolicy combined with importance sampling, to efficiently allo-cate
resources for the models. The RM framework leveragestransient virtual machine
(VM) instances to reduce the de-ployment cost in a public cloud. A prototype
implementationofCocktailon the AWS EC2 platform and exhaustive evalua-tions
using a variety of workloads demonstrate thatCocktailcan reduce deployment cost
by 1.45x, while providing 2xreduction in latency and satisfying the target
accuracy for upto 96% of the requests, when compared to
state-of-the-artmodel-serving frameworks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CaloFlow: Fast and Accurate Generation of Calorimeter Showers with Normalizing Flows. (arXiv:2106.05285v1 [physics.ins-det])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Krause_C/0/1/0/all/0/1">Claudius Krause</a>, <a href="http://arxiv.org/find/physics/1/au:+Shih_D/0/1/0/all/0/1">David Shih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05285">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce CaloFlow, a fast detector simulation framework based on
normalizing flows. For the first time, we demonstrate that normalizing flows
can reproduce many-channel calorimeter showers with extremely high fidelity,
providing a fresh alternative to computationally expensive GEANT4 simulations,
as well as other state-of-the-art fast simulation frameworks based on GANs and
VAEs. Besides the usual histograms of physical features and images of
calorimeter showers, we introduce a new metric for judging the quality of
generative modeling: the performance of a classifier trained to differentiate
real from generated images. We show that GAN-generated images can be identified
by the classifier with 100% accuracy, while images generated from CaloFlow are
able to fool the classifier much of the time. More broadly, normalizing flows
offer several advantages compared to other state-of-the-art approaches (GANs
and VAEs), including: tractable likelihoods; stable and convergent training;
and principled model selection. Normalizing flows also provide a bijective
mapping between data and the latent space, which could have other applications
beyond simulation, for example, to detector unfolding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attentional meta-learners are polythetic classifiers. (arXiv:2106.05317v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Day_B/0/1/0/all/0/1">Ben Day</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinas_R/0/1/0/all/0/1">Ramon Vi&#xf1;as</a>, <a href="http://arxiv.org/find/cs/1/au:+Simidjievski_N/0/1/0/all/0/1">Nikola Simidjievski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf2;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05317">
                                    <div class="article-summary-box-inner">
                                        <span>Polythetic classifications, based on shared patterns of features that need
neither be universal nor constant among members of a class, are common in the
natural world and greatly outnumber monothetic classifications over a set of
features. We show that threshold meta-learners require an embedding dimension
that is exponential in the number of features to emulate these functions. In
contrast, attentional classifiers are polythetic by default and able to solve
these problems with a linear embedding dimension. However, we find that in the
presence of task-irrelevant features, inherent to meta-learning problems,
attentional models are susceptible to misclassification. To address this
challenge, we further propose a self-attention feature-selection mechanism that
adaptively dilutes non-discriminative features. We demonstrate the
effectiveness of our approach in meta-learning Boolean functions, and synthetic
and real-world few-shot learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stein Latent Optimization for GANs. (arXiv:2106.05319v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1">Uiwon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Heeseung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_D/0/1/0/all/0/1">Dahuin Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Jang_H/0/1/0/all/0/1">Hyemi Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyungyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05319">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) with clustered latent spaces can
perform conditional generation in a completely unsupervised manner. However,
the salient attributes of unlabeled data in the real-world are mostly
imbalanced. Existing unsupervised conditional GANs cannot properly cluster the
attributes in their latent spaces because they assume uniform distributions of
the attributes. To address this problem, we theoretically derive Stein latent
optimization that provides reparameterizable gradient estimations of the latent
distribution parameters assuming a Gaussian mixture prior in a continuous
latent space. Structurally, we introduce an encoder network and a novel
contrastive loss to help generated data from a single mixture component to
represent a single attribute. We confirm that the proposed method, named Stein
Latent Optimization for GANs (SLOGAN), successfully learns the balanced or
imbalanced attributes and performs unsupervised tasks such as unsupervised
conditional generation, unconditional generation, and cluster assignment even
in the absence of information of the attributes (e.g. the imbalance ratio).
Moreover, we demonstrate that the attributes to be learned can be manipulated
using a small amount of probe data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tractable Density Estimation on Learned Manifolds with Conformal Embedding Flows. (arXiv:2106.05275v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ross_B/0/1/0/all/0/1">Brendan Leigh Ross</a>, <a href="http://arxiv.org/find/stat/1/au:+Cresswell_J/0/1/0/all/0/1">Jesse C. Cresswell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05275">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are generative models that provide tractable density
estimation by transforming a simple base distribution into a complex target
distribution. However, this technique cannot directly model data supported on
an unknown low-dimensional manifold, a common occurrence in real-world domains
such as image data. Recent attempts to remedy this limitation have introduced
geometric complications that defeat a central benefit of normalizing flows:
exact density estimation. We recover this benefit with Conformal Embedding
Flows, a framework for designing flows that learn manifolds with tractable
densities. We argue that composing a standard flow with a trainable conformal
embedding is the most natural way to model manifold-supported data. To this
end, we present a series of conformal building blocks and apply them in
experiments with real-world and synthetic data to demonstrate that flows can
model manifold-supported distributions without sacrificing tractable
likelihoods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Physics-Informed Deep Learning Paradigm for Traffic State Estimation and Fundamental Diagram Discovery. (arXiv:2106.03142v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_R/0/1/0/all/0/1">Rongye Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_Z/0/1/0/all/0/1">Zhaobin Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kuang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Di_X/0/1/0/all/0/1">Xuan Di</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1">Qiang Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03142">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic state estimation (TSE) bifurcates into two main categories,
model-driven and data-driven (e.g., machine learning, ML) approaches, while
each suffers from either deficient physics or small data. To mitigate these
limitations, recent studies introduced hybrid methods, such as physics-informed
deep learning (PIDL), which contains both model-driven and data-driven
components. This paper contributes an improved paradigm, called
physics-informed deep learning with a fundamental diagram learner (PIDL+FDL),
which integrates ML terms into the model-driven component to learn a functional
form of a fundamental diagram (FD), i.e., a mapping from traffic density to
flow or velocity. The proposed PIDL+FDL has the advantages of performing the
TSE learning, model parameter discovery, and FD discovery simultaneously. This
paper focuses on highway TSE with observed data from loop detectors, using
traffic density or velocity as traffic variables. We demonstrate the use of
PIDL+FDL to solve popular first-order and second-order traffic flow models and
reconstruct the FD relation as well as model parameters that are outside the FD
term. We then evaluate the PIDL+FDL-based TSE using the Next Generation
SIMulation (NGSIM) dataset. The experimental results show the superiority of
the PIDL+FDL in terms of improved estimation accuracy and data efficiency over
advanced baseline TSE methods, and additionally, the capacity to properly learn
the unknown underlying FD relation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Dimensional Bayesian Optimization with Sparse Axis-Aligned Subspaces. (arXiv:2103.00349v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eriksson_D/0/1/0/all/0/1">David Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Jankowiak_M/0/1/0/all/0/1">Martin Jankowiak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00349">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is a powerful paradigm for efficient optimization
of black-box objective functions. High-dimensional BO presents a particular
challenge, in part because the curse of dimensionality makes it difficult to
define -- as well as do inference over -- a suitable class of surrogate models.
We argue that Gaussian process surrogate models defined on sparse axis-aligned
subspaces offer an attractive compromise between flexibility and parsimony. We
demonstrate that our approach, which relies on Hamiltonian Monte Carlo for
inference, can rapidly identify sparse subspaces relevant to modeling the
unknown objective function, enabling sample-efficient high-dimensional BO. In
an extensive suite of experiments comparing to existing methods for
high-dimensional BO we demonstrate that our algorithm, Sparse Axis-Aligned
Subspace BO (SAASBO), achieves excellent performance on several synthetic and
real-world problems without the need to set problem-specific hyperparameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gi and Pal Scores: Deep Neural Network Generalization Statistics. (arXiv:2104.03469v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1">Brian Quanz</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03469">
                                    <div class="article-summary-box-inner">
                                        <span>The field of Deep Learning is rich with empirical evidence of human-like
performance on a variety of regression, classification, and control tasks.
However, despite these successes, the field lacks strong theoretical error
bounds and consistent measures of network generalization and learned
invariances. In this work, we introduce two new measures, the Gi-score and
Pal-score, that capture a deep neural network&#x27;s generalization capabilities.
Inspired by the Gini coefficient and Palma ratio, measures of income
inequality, our statistics are robust measures of a network&#x27;s invariance to
perturbations that accurately predict generalization gaps, i.e., the difference
between accuracy on training and test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Explanations via Necessity and Sufficiency: Unifying Theory and Practice. (arXiv:2103.14651v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1">David Watson</a>, <a href="http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1">Limor Gultchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Taly_A/0/1/0/all/0/1">Ankur Taly</a>, <a href="http://arxiv.org/find/cs/1/au:+Floridi_L/0/1/0/all/0/1">Luciano Floridi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14651">
                                    <div class="article-summary-box-inner">
                                        <span>Necessity and sufficiency are the building blocks of all successful
explanations. Yet despite their importance, these notions have been
conceptually underdeveloped and inconsistently applied in explainable
artificial intelligence (XAI), a fast-growing research area that is so far
lacking in firm theoretical foundations. Building on work in logic,
probability, and causality, we establish the central role of necessity and
sufficiency in XAI, unifying seemingly disparate methods in a single formal
framework. We provide a sound and complete algorithm for computing explanatory
factors with respect to a given context, and demonstrate its flexibility and
competitive performance against state of the art alternatives on various tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Space Arc Therapy Optimization. (arXiv:2106.05846v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bice_N/0/1/0/all/0/1">Noah Bice</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhreddine_M/0/1/0/all/0/1">Mohamad Fakhreddine</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruiqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kabat_C/0/1/0/all/0/1">Christopher Kabat</a>, <a href="http://arxiv.org/find/cs/1/au:+Myers_P/0/1/0/all/0/1">Pamela Myers</a>, <a href="http://arxiv.org/find/cs/1/au:+Papanikolaou_N/0/1/0/all/0/1">Niko Papanikolaou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirby_N/0/1/0/all/0/1">Neil Kirby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05846">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric modulated arc therapy planning is a challenging problem in
high-dimensional, non-convex optimization. Traditionally, heuristics such as
fluence-map-optimization-informed segment initialization use locally optimal
solutions to begin the search of the full arc therapy plan space from a
reasonable starting point. These routines facilitate arc therapy optimization
such that clinically satisfactory radiation treatment plans can be created in
about 10 minutes. However, current optimization algorithms favor solutions near
their initialization point and are slower than necessary due to plan
overparameterization. In this work, arc therapy overparameterization is
addressed by reducing the effective dimension of treatment plans with
unsupervised deep learning. An optimization engine is then built based on
low-dimensional arc representations which facilitates faster planning times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UneVEn: Universal Value Exploration for Multi-Agent Reinforcement Learning. (arXiv:2010.02974v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_T/0/1/0/all/0/1">Tarun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1">Anuj Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Bei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohmer_W/0/1/0/all/0/1">Wendelin B&#xf6;hmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02974">
                                    <div class="article-summary-box-inner">
                                        <span>VDN and QMIX are two popular value-based algorithms for cooperative MARL that
learn a centralized action value function as a monotonic mixing of per-agent
utilities. While this enables easy decentralization of the learned policy, the
restricted joint action value function can prevent them from solving tasks that
require significant coordination between agents at a given timestep. We show
that this problem can be overcome by improving the joint exploration of all
agents during training. Specifically, we propose a novel MARL approach called
Universal Value Exploration (UneVEn) that learns a set of related tasks
simultaneously with a linear decomposition of universal successor features.
With the policies of already solved related tasks, the joint exploration
process of all agents can be improved to help them achieve better coordination.
Empirical results on a set of exploration games, challenging cooperative
predator-prey tasks requiring significant coordination among agents, and
StarCraft II micromanagement benchmarks show that UneVEn can solve tasks where
other state-of-the-art MARL methods fail.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Information Plane Analyses of Neural Network Classifiers -- A Review. (arXiv:2003.09671v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1">Bernhard C. Geiger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.09671">
                                    <div class="article-summary-box-inner">
                                        <span>We review the current literature concerned with information plane analyses of
neural network classifiers. While the underlying information bottleneck theory
and the claim that information-theoretic compression is causally linked to
generalization are plausible, empirical evidence was found to be both
supporting and conflicting. We review this evidence together with a detailed
analysis of how the respective information quantities were estimated. Our
survey suggests that compression visualized in information planes is not
necessarily information-theoretic, but is rather often compatible with
geometric compression of the latent representations. This insight gives the
information plane a renewed justification.

Aside from this, we shed light on the problem of estimating mutual
information in deterministic neural networks and its consequences.
Specifically, we argue that even in feed-forward neural networks the data
processing inequality need not hold for estimates of mutual information.
Similarly, while a fitting phase, in which the mutual information between the
latent representation and the target increases, is necessary (but not
sufficient) for good classification performance, depending on the specifics of
mutual information estimation such a fitting phase need not be visible in the
information plane.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two-stage Textual Knowledge Distillation for End-to-End Spoken Language Understanding. (arXiv:2010.13105v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seongbin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1">Gyuwan Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seongjin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangmin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13105">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end approaches open a new way for more accurate and efficient spoken
language understanding (SLU) systems by alleviating the drawbacks of
traditional pipeline systems. Previous works exploit textual information for an
SLU model via pre-training with automatic speech recognition or fine-tuning
with knowledge distillation. To utilize textual information more effectively,
this work proposes a two-stage textual knowledge distillation method that
matches utterance-level representations and predicted logits of two modalities
during pre-training and fine-tuning, sequentially. We use vq-wav2vec BERT as a
speech encoder because it captures general and rich features. Furthermore, we
improve the performance, especially in a low-resource scenario, with data
augmentation methods by randomly masking spans of discrete audio tokens and
contextualized hidden representations. Consequently, we push the
state-of-the-art on the Fluent Speech Commands, achieving 99.7% test accuracy
in the full dataset setting and 99.5% in the 10% subset setting. Throughout the
ablation studies, we empirically verify that all used methods are crucial to
the final performance, providing the best practice for spoken language
understanding. Code is available at https://github.com/clovaai/textual-kd-slu.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Under-exploration in Bandits with Mean Bounds from Confounded Data. (arXiv:2002.08405v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1">Nihal Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1">Soumya Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1">Karthikeyan Shanmugam</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.08405">
                                    <div class="article-summary-box-inner">
                                        <span>We study a variant of the multi-armed bandit problem where side information
in the form of bounds on the mean of each arm is provided. We develop the novel
non-optimistic Global Under-Explore (GLUE) algorithm which uses the provided
mean bounds (across all the arms) to infer pseudo-variances for each arm, which
in turn decide the rate of exploration for the arms. We analyze the regret of
GLUE and prove regret upper bounds that are never worse than that of the
standard UCB algorithm. Furthermore, we show that GLUE improves upon regret
guarantees that exists in literature for structured bandit problems (both
theoretically and empirically). Finally, we study the practical setting of
learning adaptive interventions using prior data that has been confounded by
unrecorded variables that affect rewards. We show that mean bounds can be
inferred naturally from such logs and can thus be used to improve the learning
process. We validate our findings through semi-synthetic experiments on data
derived from real data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive machine learning for protein engineering. (arXiv:2106.05466v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Hie_B/0/1/0/all/0/1">Brian L. Hie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_K/0/1/0/all/0/1">Kevin K. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05466">
                                    <div class="article-summary-box-inner">
                                        <span>Machine-learning models that learn from data to predict how protein sequence
encodes function are emerging as a useful protein engineering tool. However,
when using these models to suggest new protein designs, one must deal with the
vast combinatorial complexity of protein sequences. Here, we review how to use
a sequence-to-function machine-learning surrogate model to select sequences for
experimental measurement. First, we discuss how to select sequences through a
single round of machine-learning optimization. Then, we discuss sequential
optimization, where the goal is to discover optimized sequences and improve the
model across multiple rounds of training, optimization, and experimental
measurement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1">Ekdeep Singh Lubana</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1">Robert P. Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1">Hidenori Tanaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05956">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by BatchNorm, there has been an explosion of normalization layers in
deep learning. Recent works have identified a multitude of beneficial
properties in BatchNorm to explain its success. However, given the pursuit of
alternative normalization techniques, these properties need to be generalized
so that any given layer&#x27;s success/failure can be accurately predicted. In this
work, we take a first step towards this goal by extending known properties of
BatchNorm in randomly initialized deep neural networks (DNNs) to nine recently
proposed normalization layers. Our primary findings follow: (i) Similar to
BatchNorm, activations-based normalization layers can avoid exploding
activations in ResNets; (ii) Use of GroupNorm ensures rank of activations is at
least $\Omega(\sqrt{\frac{\text{width}}{\text{Group Size}}})$, thus explaining
why LayerNorm witnesses slow optimization speed; (iii) Small group sizes result
in large gradient norm in earlier layers, hence justifying training instability
issues in Instance Normalization and illustrating a speed-stability tradeoff in
GroupNorm. Overall, our analysis reveals several general mechanisms that
explain the success of normalization techniques in deep learning, providing us
with a compass to systematically explore the vast design space of DNN
normalization layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Verifiable and Compositional Reinforcement Learning Systems. (arXiv:2106.05864v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neary_C/0/1/0/all/0/1">Cyrus Neary</a>, <a href="http://arxiv.org/find/cs/1/au:+Verginis_C/0/1/0/all/0/1">Christos Verginis</a>, <a href="http://arxiv.org/find/cs/1/au:+Cubuktepe_M/0/1/0/all/0/1">Murat Cubuktepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05864">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel framework for verifiable and compositional reinforcement
learning (RL) in which a collection of RL sub-systems, each of which learns to
accomplish a separate sub-task, are composed to achieve an overall task. The
framework consists of a high-level model, represented as a parametric Markov
decision process (pMDP) which is used to plan and to analyze compositions of
sub-systems, and of the collection of low-level sub-systems themselves. By
defining interfaces between the sub-systems, the framework enables automatic
decompositons of task specifications, e.g., reach a target set of states with a
probability of at least 0.95, into individual sub-task specifications, i.e.
achieve the sub-system&#x27;s exit conditions with at least some minimum
probability, given that its entry conditions are met. This in turn allows for
the independent training and testing of the sub-systems; if they each learn a
policy satisfying the appropriate sub-task specification, then their
composition is guaranteed to satisfy the overall task specification.
Conversely, if the sub-task specifications cannot all be satisfied by the
learned policies, we present a method, formulated as the problem of finding an
optimal set of parameters in the pMDP, to automatically update the sub-task
specifications to account for the observed shortcomings. The result is an
iterative procedure for defining sub-task specifications, and for training the
sub-systems to meet them. As an additional benefit, this procedure allows for
particularly challenging or important components of an overall task to be
determined automatically, and focused on, during training. Experimental results
demonstrate the presented framework&#x27;s novel capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Programming Puzzles. (arXiv:2106.05784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1">Tal Schuster</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1">Ashwin Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1">Oleksandr Polozov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1">Adam Tauman Kalai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05784">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new type of programming challenge called programming puzzles,
as an objective and comprehensive evaluation of program synthesis, and release
an open-source dataset of Python Programming Puzzles (P3). Each puzzle is
defined by a short Python program $f$, and the goal is to find an input $x$
which makes $f$ output &quot;True&quot;. The puzzles are objective in that each one is
specified entirely by the source code of its verifier $f$, so evaluating $f(x)$
is all that is needed to test a candidate solution $x$. They do not require an
answer key or input/output examples, nor do they depend on natural language
understanding. The dataset is comprehensive in that it spans problems of a
range of difficulties and domains, ranging from trivial string manipulation
problems that are immediately obvious to human programmers (but not necessarily
to AI), to classic programming puzzles (e.g., Towers of Hanoi), to
interview/competitive-programming problems (e.g., dynamic programming), to
longstanding open problems in algorithms and mathematics (e.g., factoring). The
objective nature of P3 readily supports self-supervised bootstrapping. We
develop baseline enumerative program synthesis and GPT-3 solvers that are
capable of solving easy puzzles -- even without access to any reference
solutions -- by learning from their own past solutions. Based on a small user
study, we find puzzle difficulty to correlate between human programmers and the
baseline AI solvers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Disaster Containment via Graph-Cut Problems. (arXiv:2106.05424v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Babay_A/0/1/0/all/0/1">Amy Babay</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinitz_M/0/1/0/all/0/1">Michael Dinitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sambaturu_P/0/1/0/all/0/1">Prathyush Sambaturu</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1">Aravind Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsepenekas_L/0/1/0/all/0/1">Leonidas Tsepenekas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vullikanti_A/0/1/0/all/0/1">Anil Vullikanti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05424">
                                    <div class="article-summary-box-inner">
                                        <span>Graph cut problems form a fundamental problem type in combinatorial
optimization, and are a central object of study in both theory and practice. In
addition, the study of fairness in Algorithmic Design and Machine Learning has
recently received significant attention, with many different notions proposed
and analyzed in a variety of contexts. In this paper we initiate the study of
fairness for graph cut problems by giving the first fair definitions for them,
and subsequently we demonstrate appropriate algorithmic techniques that yield a
rigorous theoretical analysis. Specifically, we incorporate two different
definitions of fairness, namely demographic and probabilistic individual
fairness, in a particular cut problem modeling disaster containment scenarios.
Our results include a variety of approximation algorithms with provable
theoretical guarantees.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero Time Waste: Recycling Predictions in Early Exit Neural Networks. (arXiv:2106.05409v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolczyk_M/0/1/0/all/0/1">Maciej Wo&#x142;czyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Wojcik_B/0/1/0/all/0/1">Bartosz W&#xf3;jcik</a>, <a href="http://arxiv.org/find/cs/1/au:+Balazy_K/0/1/0/all/0/1">Klaudia Ba&#x142;azy</a>, <a href="http://arxiv.org/find/cs/1/au:+Podolak_I/0/1/0/all/0/1">Igor Podolak</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1">Jacek Tabor</a>, <a href="http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1">Marek &#x15a;mieja</a>, <a href="http://arxiv.org/find/cs/1/au:+Trzcinski_T/0/1/0/all/0/1">Tomasz Trzci&#x144;ski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05409">
                                    <div class="article-summary-box-inner">
                                        <span>The problem of reducing processing time of large deep learning models is a
fundamental challenge in many real-world applications. Early exit methods
strive towards this goal by attaching additional Internal Classifiers (ICs) to
intermediate layers of a neural network. ICs can quickly return predictions for
easy examples and, as a result, reduce the average inference time of the whole
model. However, if a particular IC does not decide to return an answer early,
its predictions are discarded, with its computations effectively being wasted.
To solve this issue, we introduce Zero Time Waste (ZTW), a novel approach in
which each IC reuses predictions returned by its predecessors by (1) adding
direct connections between ICs and (2) combining previous outputs in an
ensemble-like manner. We conduct extensive experiments across various datasets
and architectures to demonstrate that ZTW achieves a significantly better
accuracy vs. inference time trade-off than other recently proposed early exit
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GNNAutoScale: Scalable and Expressive Graph Neural Networks via Historical Embeddings. (arXiv:2106.05609v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fey_M/0/1/0/all/0/1">Matthias Fey</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenssen_J/0/1/0/all/0/1">Jan E. Lenssen</a>, <a href="http://arxiv.org/find/cs/1/au:+Weichert_F/0/1/0/all/0/1">Frank Weichert</a>, <a href="http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1">Jure Leskovec</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05609">
                                    <div class="article-summary-box-inner">
                                        <span>We present GNNAutoScale (GAS), a framework for scaling arbitrary
message-passing GNNs to large graphs. GAS prunes entire sub-trees of the
computation graph by utilizing historical embeddings from prior training
iterations, leading to constant GPU memory consumption in respect to input node
size without dropping any data. While existing solutions weaken the expressive
power of message passing due to sub-sampling of edges or non-trainable
propagations, our approach is provably able to maintain the expressive power of
the original GNN. We achieve this by providing approximation error bounds of
historical embeddings and show how to tighten them in practice. Empirically, we
show that the practical realization of our framework, PyGAS, an easy-to-use
extension for PyTorch Geometric, is both fast and memory-efficient, learns
expressive node representations, closely resembles the performance of their
non-scaling counterparts, and reaches state-of-the-art performance on
large-scale graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Validation of Simulation-Based Testing: Bypassing Domain Shift with Label-to-Image Synthesis. (arXiv:2106.05549v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenzweig_J/0/1/0/all/0/1">Julia Rosenzweig</a>, <a href="http://arxiv.org/find/cs/1/au:+Brito_E/0/1/0/all/0/1">Eduardo Brito</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobialka_H/0/1/0/all/0/1">Hans-Ulrich Kobialka</a>, <a href="http://arxiv.org/find/cs/1/au:+Akila_M/0/1/0/all/0/1">Maram Akila</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_N/0/1/0/all/0/1">Nico M. Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schlicht_P/0/1/0/all/0/1">Peter Schlicht</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jan David Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Huger_F/0/1/0/all/0/1">Fabian H&#xfc;ger</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1">Matthias Rottmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Houben_S/0/1/0/all/0/1">Sebastian Houben</a>, <a href="http://arxiv.org/find/cs/1/au:+Wirtz_T/0/1/0/all/0/1">Tim Wirtz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05549">
                                    <div class="article-summary-box-inner">
                                        <span>Many machine learning applications can benefit from simulated data for
systematic validation - in particular if real-life data is difficult to obtain
or annotate. However, since simulations are prone to domain shift w.r.t.
real-life data, it is crucial to verify the transferability of the obtained
results. We propose a novel framework consisting of a generative label-to-image
synthesis model together with different transferability measures to inspect to
what extent we can transfer testing results of semantic segmentation models
from synthetic data to equivalent real-life data. With slight modifications,
our approach is extendable to, e.g., general multi-class classification tasks.
Grounded on the transferability analysis, our approach additionally allows for
extensive testing by incorporating controlled simulations. We validate our
approach empirically on a semantic segmentation task on driving scenes.
Transferability is tested using correlation analysis of IoU and a learned
discriminator. Although the latter can distinguish between real-life and
synthetic tests, in the former we observe surprisingly strong correlations of
0.7 for both cars and pedestrians.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics. (arXiv:2106.05739v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Domingo_Enrich_C/0/1/0/all/0/1">Carles Domingo-Enrich</a>, <a href="http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05739">
                                    <div class="article-summary-box-inner">
                                        <span>Several works in implicit and explicit generative modeling empirically
observed that feature-learning discriminators outperform fixed-kernel
discriminators in terms of the sample quality of the models. We provide
separation results between probability metrics with fixed-kernel and
feature-learning discriminators using the function classes $\mathcal{F}_2$ and
$\mathcal{F}_1$ respectively, which were developed to study overparametrized
two-layer neural networks. In particular, we construct pairs of distributions
over hyper-spheres that can not be discriminated by fixed kernel
$(\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD)
in high dimensions, but that can be discriminated by their feature learning
($\mathcal{F}_1$) counterparts. To further study the separation we provide
links between the $\mathcal{F}_1$ and $\mathcal{F}_2$ IPMs with sliced
Wasserstein distances. Our work suggests that fixed-kernel discriminators
perform worse than their feature learning counterparts because their
corresponding metrics are weaker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accurate Learning of Graph Representations with Graph Multiset Pooling. (arXiv:2102.11533v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1">Jinheon Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Minki Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11533">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks have been widely used on modeling graph data, achieving
impressive results on node classification and link prediction tasks. Yet,
obtaining an accurate representation for a graph further requires a pooling
function that maps a set of node representations into a compact form. A simple
sum or average over all node representations considers all node features
equally without consideration of their task relevance, and any structural
dependencies among them. Recently proposed hierarchical graph pooling methods,
on the other hand, may yield the same representation for two different graphs
that are distinguished by the Weisfeiler-Lehman test, as they suboptimally
preserve information from the node features. To tackle these limitations of
existing graph pooling methods, we first formulate the graph pooling problem as
a multiset encoding problem with auxiliary information about the graph
structure, and propose a Graph Multiset Transformer (GMT) which is a multi-head
attention based global pooling layer that captures the interaction between
nodes according to their structural dependencies. We show that GMT satisfies
both injectiveness and permutation invariance, such that it is at most as
powerful as the Weisfeiler-Lehman graph isomorphism test. Moreover, our methods
can be easily extended to the previous node clustering approaches for
hierarchical graph pooling. Our experimental results show that GMT
significantly outperforms state-of-the-art graph pooling methods on graph
classification benchmarks with high memory and time efficiency, and obtains
even larger performance gain on graph reconstruction and generation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphITE: Estimating Individual Effects of Graph-structured Treatments. (arXiv:2009.14061v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Harada_S/0/1/0/all/0/1">Shonosuke Harada</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14061">
                                    <div class="article-summary-box-inner">
                                        <span>Outcome estimation of treatments for target individuals is an important
foundation for decision making based on causal relations. Most existing outcome
estimation methods deal with binary or multiple-choice treatments; however, in
some applications, the number of treatments can be significantly large, while
the treatments themselves have rich information. In this study, we considered
one important instance of such cases: the outcome estimation problem of
graph-structured treatments such as drugs. Owing to the large number of
possible treatments, the counterfactual nature of observational data that
appears in conventional treatment effect estimation becomes more of a concern
for this problem. Our proposed method, GraphITE (pronounced &quot;graphite&quot;) learns
the representations of graph-structured treatments using graph neural networks
while mitigating observation biases using Hilbert-Schmidt Independence
Criterion regularization, which increases the independence of the
representations of the targets and treatments. Experiments on two real-world
datasets show that GraphITE outperforms baselines, especially in cases with a
large number of treatments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning. (arXiv:2106.05682v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">Youngtaek Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05682">
                                    <div class="article-summary-box-inner">
                                        <span>The capability of the traditional semi-supervised learning (SSL) methods is
far from real-world application since they do not consider (1) class imbalance
and (2) class distribution mismatch between labeled and unlabeled data. This
paper addresses such a relatively under-explored problem, imbalanced
semi-supervised learning, where heavily biased pseudo-labels can harm the model
performance. Interestingly, we find that the semantic pseudo-labels from a
similarity-based classifier in feature space and the traditional pseudo-labels
from the linear classifier show the complementary property. To this end, we
propose a general pseudo-labeling framework to address the bias motivated by
this observation. The key idea is to class-adaptively blend the semantic
pseudo-label to the linear one, depending on the current pseudo-label
distribution. Thereby, the increased semantic pseudo-label component suppresses
the false positives in the majority classes and vice versa. We term the novel
pseudo-labeling framework for imbalanced SSL as Distribution-Aware
Semantics-Oriented (DASO) Pseudo-label. Extensive evaluation on CIFAR10/100-LT
and STL10-LT shows that DASO consistently outperforms both recently proposed
re-balancing methods for label and pseudo-label. Moreover, we demonstrate that
typical SSL algorithms can effectively benefit from unlabeled data with DASO,
especially when (1) class imbalance and (2) class distribution mismatch exist
and even on recent real-world Semi-Aves benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Point Cloud Shape Classification with a Simple and Effective Baseline. (arXiv:2106.05304v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1">Ankit Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_H/0/1/0/all/0/1">Hei Law</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Newell_A/0/1/0/all/0/1">Alejandro Newell</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jia Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05304">
                                    <div class="article-summary-box-inner">
                                        <span>Processing point cloud data is an important component of many real-world
systems. As such, a wide variety of point-based approaches have been proposed,
reporting steady benchmark improvements over time. We study the key ingredients
of this progress and uncover two critical results. First, we find that
auxiliary factors like different evaluation schemes, data augmentation
strategies, and loss functions, which are independent of the model
architecture, make a large difference in performance. The differences are large
enough that they obscure the effect of architecture. When these factors are
controlled for, PointNet++, a relatively older network, performs competitively
with recent methods. Second, a very simple projection-based method, which we
refer to as SimpleView, performs surprisingly well. It achieves on par or
better results than sophisticated state-of-the-art methods on ModelNet40 while
being half the size of PointNet++. It also outperforms state-of-the-art methods
on ScanObjectNN, a real-world point cloud benchmark, and demonstrates better
cross-dataset generalization. Code is available at
https://github.com/princeton-vl/SimpleView.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Time Series Predictions with Dynamic Masks. (arXiv:2106.05303v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Crabbe_J/0/1/0/all/0/1">Jonathan Crabb&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05303">
                                    <div class="article-summary-box-inner">
                                        <span>How can we explain the predictions of a machine learning model? When the data
is structured as a multivariate time series, this question induces additional
difficulties such as the necessity for the explanation to embody the time
dependency and the large number of inputs. To address these challenges, we
propose dynamic masks (Dynamask). This method produces instance-wise importance
scores for each feature at each time step by fitting a perturbation mask to the
input sequence. In order to incorporate the time dependency of the data,
Dynamask studies the effects of dynamic perturbation operators. In order to
tackle the large number of inputs, we propose a scheme to make the feature
selection parsimonious (to select no more feature than necessary) and legible
(a notion that we detail by making a parallel with information theory). With
synthetic and real-world data, we demonstrate that the dynamic underpinning of
Dynamask, together with its parsimony, offer a neat improvement in the
identification of feature importance over time. The modularity of Dynamask
makes it ideal as a plug-in to increase the transparency of a wide range of
machine learning models in areas such as medicine and finance, where time
series are abundant.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiffCloth: Differentiable Cloth Simulation with Dry Frictional Contact. (arXiv:2106.05306v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yifei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1">Tao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1">Wojciech Matusik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05306">
                                    <div class="article-summary-box-inner">
                                        <span>Cloth simulation has wide applications including computer animation, garment
design, and robot-assisted dressing. In this work, we present a differentiable
cloth simulator whose additional gradient information facilitates cloth-related
applications. Our differentiable simulator extends the state-of-the-art cloth
simulator based on Projective Dynamics and with dry frictional contact governed
by the Signorini-Coulomb law. We derive gradients with contact in this forward
simulation framework and speed up the computation with Jacobi iteration
inspired by previous differentiable simulation work. To our best knowledge, we
present the first differentiable cloth simulator with the Coulomb law of
friction. We demonstrate the efficacy of our simulator in various applications,
including system identification, manipulation, inverse design, and a
real-to-sim task. Many of our applications have not been demonstrated in
previous differentiable cloth simulators. The gradient information from our
simulator enables efficient gradient-based task solvers from which we observe a
substantial speedup over standard gradient-free methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MusicBERT: Symbolic Music Understanding with Large-Scale Pre-Training. (arXiv:2106.05630v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Mingliang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_Z/0/1/0/all/0/1">Zeqian Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05630">
                                    <div class="article-summary-box-inner">
                                        <span>Symbolic music understanding, which refers to the understanding of music from
the symbolic data (e.g., MIDI format, but not audio), covers many music
applications such as genre classification, emotion classification, and music
pieces matching. While good music representations are beneficial for these
applications, the lack of training data hinders representation learning.
Inspired by the success of pre-training models in natural language processing,
in this paper, we develop MusicBERT, a large-scale pre-trained model for music
understanding. To this end, we construct a large-scale symbolic music corpus
that contains more than 1 million music songs. Since symbolic music contains
more structural (e.g., bar, position) and diverse information (e.g., tempo,
instrument, and pitch), simply adopting the pre-training techniques from NLP to
symbolic music only brings marginal gains. Therefore, we design several
mechanisms, including OctupleMIDI encoding and bar-level masking strategy, to
enhance pre-training with symbolic music data. Experiments demonstrate the
advantages of MusicBERT on four music understanding tasks, including melody
completion, accompaniment suggestion, genre classification, and style
classification. Ablation studies also verify the effectiveness of our designs
of OctupleMIDI encoding and bar-level masking strategy in MusicBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Clustering-Driven Neural Network for Intra Prediction. (arXiv:2106.05481v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Man_H/0/1/0/all/0/1">Hengyu Man</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiaopeng Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1">Ruiqin Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Debin Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05481">
                                    <div class="article-summary-box-inner">
                                        <span>As a crucial part of video compression, intra prediction utilizes local
information of images to eliminate the redundancy in spatial domain. In both
H.265/HEVC and H.266/VVC, multiple directional prediction modes are employed to
find the texture trend of each small block and then the prediction is made
based on reference samples in the selected direction. Recently, the intra
prediction schemes based on neural networks have achieved great success. In
these methods, the networks are trained and applied to intra prediction in
addition to the directional prediction modes. In this paper, we propose a novel
data clustering-driven neural network (dubbed DCDNN) for intra prediction,
which can learn deep features of the clustered data. In DCDNN, each network can
be split into two networks by adding or subtracting Gaussian random noise. Then
a data clustering-driven training is applied to train all the derived networks
recursively. In each iteration, the entire training dataset is partitioned
according to the recovery qualities of the derived networks. For the
experiment, DCDNN is implemented into HEVC reference software HM-16.9. The
experimental results demonstrate that DCDNN can reach an average of 4.2%
Bjontegaard distortion rate (BDrate) improvement (up to 7.0%) over HEVC with
all intra configuration. Compared with existing fully connected networkbased
intra prediction methods, the bitrate saving performance is further improved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Design Paradigm of Distortion Cost Function for Efficient JPEG Steganography. (arXiv:1908.01947v3 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1">Wenkang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1">Jiangqun Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xianglei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01947">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, with the introduction of JPEG phase-aware steganalysis features,
e.g., GFR, the design of JPEG steganographic distortion cost function turns to
maintain not only the statistical undetectability in DCT domain but also in
spatial domain. To tackle this issue, this paper presents a novel paradigm for
the design of JPEG steganographic distortion cost function, which calculates
the distortion cost via a generalized Distortion Cost Domain Transformation
(DCDT) function. The proposed function comprises the decompressed pixel block
embedding changes and their corresponding embedding distortion costs for unit
change, where the pixel embedding distortion costs are represented in a more
general exponential model, aiming to flexibly allocate the embedding data. In
this way, the JPEG steganography could be formulated as the optimization
problem of minimizing the overall distortion cost in its decompressed spatial
domain, which is equivalent to maximizing its statistical undetectability
against JPEG phase-aware steganalysis features. Experimental results show that
the proposed DCDT equipped with HiLL (a spatial steganographic distortion cost
function) is superior to other state-of-the-art JPEG steganographic schemes,
e.g., UERD, J-UNIWARD, and GUED in resisting the detection of JPEG phase-aware
feature-based steganalyzers GFR and SCA-GFR, and rivals BET-HiLL with one order
of magnitude lower computational complexity, along with the possibility of
being further improved by considering the mutually dependent embedding
interactions. In addition, the proposed DCDT is also verified to be effective
for different image databases and quality factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-10">2021-06-10</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations. (arXiv:2106.01978v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huai_X/0/1/0/all/0/1">Xiaoyong Huai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01978">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion Recognition in Conversations (ERC) has gained increasing attention
for developing empathetic machines. Recently, many approaches have been devoted
to perceiving conversational context by deep learning models. However, these
approaches are insufficient in understanding the context due to lacking the
ability to extract and integrate emotional clues. In this work, we propose
novel Contextual Reasoning Networks (DialogueCRN) to fully understand the
conversational context from a cognitive perspective. Inspired by the Cognitive
Theory of Emotion, we design multi-turn reasoning modules to extract and
integrate emotional clues. The reasoning module iteratively performs an
intuitive retrieving process and a conscious reasoning process, which imitates
human unique cognitive thinking. Extensive experiments on three public
benchmark datasets demonstrate the effectiveness and superiority of the
proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MICE: A Crosslinguistic Emotion Corpus in Malay, Indonesian, Chinese and English. (arXiv:2106.04831v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chin_N/0/1/0/all/0/1">Ng Bee Chin</a>, <a href="http://arxiv.org/find/cs/1/au:+Susanto_Y/0/1/0/all/0/1">Yosephine Susanto</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04831">
                                    <div class="article-summary-box-inner">
                                        <span>MICE is a corpus of emotion words in four languages which is currently
working progress. There are two sections to this study, Part I: Emotion word
corpus and Part II: Emotion word survey. In Part 1, the method of how the
emotion data is culled for each of the four languages will be described and
very preliminary data will be presented. In total, we identified 3,750 emotion
expressions in Malay, 6,657 in Indonesian, 3,347 in Mandarin Chinese and 8,683
in English. We are currently evaluating and double checking the corpus and
doing further analysis on the distribution of these emotion expressions. Part
II Emotion word survey involved an online language survey which collected
information on how speakers assigned the emotion words into basic emotion
categories, the rating for valence and intensity as well as biographical
information of all the respondents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepTileBars: Visualizing Term Distribution for Neural Information Retrieval. (arXiv:1811.00606v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.00606">
                                    <div class="article-summary-box-inner">
                                        <span>Most neural Information Retrieval (Neu-IR) models derive query-to-document
ranking scores based on term-level matching. Inspired by TileBars, a classical
term distribution visualization method, in this paper, we propose a novel
Neu-IR model that handles query-to-document matching at the subtopic and higher
levels. Our system first splits the documents into topical segments,
&quot;visualizes&quot; the matchings between the query and the segments, and then feeds
an interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final
ranking scores. DeepTileBars models the relevance signals occurring at
different granularities in a document&#x27;s topic hierarchy. It better captures the
discourse structure of a document and thus the matching patterns. Although its
design and implementation are light-weight, DeepTileBars outperforms other
state-of-the-art Neu-IR models on benchmark datasets including the Text
REtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AUGVIC: Exploiting BiText Vicinity for Low-Resource NMT. (arXiv:2106.05141v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohiuddin_T/0/1/0/all/0/1">Tasnim Mohiuddin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1">M Saiful Bari</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05141">
                                    <div class="article-summary-box-inner">
                                        <span>The success of Neural Machine Translation (NMT) largely depends on the
availability of large bitext training corpora. Due to the lack of such large
corpora in low-resource language pairs, NMT systems often exhibit poor
performance. Extra relevant monolingual data often helps, but acquiring it
could be quite expensive, especially for low-resource languages. Moreover,
domain mismatch between bitext (train/test) and monolingual data might degrade
the performance. To alleviate such issues, we propose AUGVIC, a novel data
augmentation framework for low-resource NMT which exploits the vicinal samples
of the given bitext without using any extra monolingual data explicitly. It can
diversify the in-domain bitext data with finer level control. Through extensive
experiments on four low-resource language pairs comprising data from different
domains, we have shown that our method is comparable to the traditional
back-translation that uses extra in-domain monolingual data. When we combine
the synthetic parallel data generated from AUGVIC with the ones from the extra
monolingual data, we achieve further improvements. We show that AUGVIC helps to
attenuate the discrepancies between relevant and distant-domain monolingual
data in traditional back-translation. To understand the contributions of
different components of AUGVIC, we perform an in-depth framework analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-hop Graph Convolutional Network with High-order Chebyshev Approximation for Text Reasoning. (arXiv:2106.05221v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shuoran Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qingcai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Baotian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lisai Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05221">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional network (GCN) has become popular in various natural
language processing (NLP) tasks with its superiority in long-term and
non-consecutive word interactions. However, existing single-hop graph reasoning
in GCN may miss some important non-consecutive dependencies. In this study, we
define the spectral graph convolutional network with the high-order dynamic
Chebyshev approximation (HDGCN), which augments the multi-hop graph reasoning
by fusing messages aggregated from direct and long-term dependencies into one
convolutional layer. To alleviate the over-smoothing in high-order Chebyshev
approximation, a multi-vote-based cross-attention (MVCAttn) with linear
computation complexity is also proposed. The empirical results on four
transductive and inductive NLP tasks and the ablation study verify the efficacy
of the proposed model. Our source code is available at
https://github.com/MathIsAll/HDGCN-pytorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages. (arXiv:2012.05628v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vries_W/0/1/0/all/0/1">Wietse de Vries</a>, <a href="http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1">Malvina Nissim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05628">
                                    <div class="article-summary-box-inner">
                                        <span>Large generative language models have been very successful for English, but
other languages lag behind, in part due to data and computational limitations.
We propose a method that may overcome these problems by adapting existing
pre-trained models to new languages. Specifically, we describe the adaptation
of English GPT-2 to Italian and Dutch by retraining lexical embeddings without
tuning the Transformer layers. As a result, we obtain lexical embeddings for
Italian and Dutch that are aligned with the original English lexical
embeddings. Additionally, we scale up complexity by transforming relearned
lexical embeddings of GPT-2 small to the GPT-2 medium embedding space. This
method minimises the amount of training and prevents losing information during
adaptation that was learned by GPT-2. English GPT-2 models with relearned
lexical embeddings can generate realistic sentences in Italian and Dutch.
Though on average these sentences are still identifiable as artificial by
humans, they are assessed on par with sentences generated by a GPT-2 model
fully trained from scratch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crosslingual Embeddings are Essential in UNMT for Distant Languages: An English to IndoAryan Case Study. (arXiv:2106.04995v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1">Tamali Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1">Rudra Murthy V</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Pushpak Bhattacharyya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04995">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in Unsupervised Neural Machine Translation (UNMT) have
minimized the gap between supervised and unsupervised machine translation
performance for closely related language pairs. However, the situation is very
different for distant language pairs. Lack of lexical overlap and low syntactic
similarities such as between English and Indo-Aryan languages leads to poor
translation quality in existing UNMT systems. In this paper, we show that
initializing the embedding layer of UNMT models with cross-lingual embeddings
shows significant improvements in BLEU score over existing approaches with
embeddings randomly initialized. Further, static embeddings (freezing the
embedding layer weights) lead to better gains compared to updating the
embedding layer weights during training (non-static). We experimented using
Masked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT
approaches for three distant language pairs. The proposed cross-lingual
embedding initialization yields BLEU score improvement of as much as ten times
over the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our
analysis shows the importance of cross-lingual embedding, comparisons between
approaches, and the scope of improvements in these systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text-to-SQL in the Wild: A Naturally-Occurring Dataset Based on Stack Exchange Data. (arXiv:2106.05006v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hazoom_M/0/1/0/all/0/1">Moshe Hazoom</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_V/0/1/0/all/0/1">Vibhor Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogin_B/0/1/0/all/0/1">Ben Bogin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05006">
                                    <div class="article-summary-box-inner">
                                        <span>Most available semantic parsing datasets, comprising of pairs of natural
utterances and logical forms, were collected solely for the purpose of training
and evaluation of natural language understanding systems. As a result, they do
not contain any of the richness and variety of natural-occurring utterances,
where humans ask about data they need or are curious about. In this work, we
release SEDE, a dataset with 12,023 pairs of utterances and SQL queries
collected from real usage on the Stack Exchange website. We show that these
pairs contain a variety of real-world challenges which were rarely reflected so
far in any other semantic parsing dataset, propose an evaluation metric based
on comparison of partial query clauses that is more suitable for real-world
queries, and conduct experiments with strong baselines, showing a large gap
between the performance on SEDE compared to other common datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RealTranS: End-to-End Simultaneous Speech Translation with Convolutional Weighted-Shrinking Transformer. (arXiv:2106.04833v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xingshan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liangyou Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04833">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end simultaneous speech translation (SST), which directly translates
speech in one language into text in another language in real-time, is useful in
many scenarios but has not been fully investigated. In this work, we propose
RealTranS, an end-to-end model for SST. To bridge the modality gap between
speech and text, RealTranS gradually downsamples the input speech with
interleaved convolution and unidirectional Transformer layers for acoustic
modeling, and then maps speech features into text space with a
weighted-shrinking operation and a semantic encoder. Besides, to improve the
model performance in simultaneous scenarios, we propose a blank penalty to
enhance the shrinking quality and a Wait-K-Stride-N strategy to allow local
reranking during decoding. Experiments on public and widely-used datasets show
that RealTranS with the Wait-K-Stride-N strategy outperforms prior end-to-end
models as well as cascaded models in diverse latency settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network. (arXiv:2104.11127v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pylkkonen_J/0/1/0/all/0/1">Janne Pylkk&#xf6;nen</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Ukkonen_A/0/1/0/all/0/1">Antti Ukkonen</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Kilpikoski_J/0/1/0/all/0/1">Juho Kilpikoski</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Tamminen_S/0/1/0/all/0/1">Samu Tamminen</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Heikinheimo_H/0/1/0/all/0/1">Hannes Heikinheimo</a> (1) ((1) Speechly, (2) Department of Computer Science, University of Helsinki, Finland)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11127">
                                    <div class="article-summary-box-inner">
                                        <span>Adaption of end-to-end speech recognition systems to new tasks is known to be
challenging. A number of solutions have been proposed which apply external
language models with various fusion methods, possibly with a combination of
two-pass decoding. Also TTS systems have been used to generate adaptation data
for the end-to-end models. In this paper we show that RNN-transducer models can
be effectively adapted to new domains using only small amounts of textual data.
By taking advantage of model&#x27;s inherent structure, where the prediction network
is interpreted as a language model, we can apply fast adaptation to the model.
Adapting the model avoids the need for complicated decoding time fusions and
external language models. Using appropriate regularization, the prediction
network can be adapted to new domains while still retaining good generalization
capabilities. We show with multiple ASR evaluation tasks how this method can
provide relative gains of 10-45% in target task WER. We also share insights how
RNN-transducer prediction network performs as a language model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Interaction Networks with Rethinking Mechanism for Document-level Sentiment Analysis. (arXiv:2007.08445v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xuehai Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaodan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jizhong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Songlin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08445">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level Sentiment Analysis (DSA) is more challenging due to vague
semantic links and complicate sentiment information. Recent works have been
devoted to leveraging text summarization and have achieved promising results.
However, these summarization-based methods did not take full advantage of the
summary including ignoring the inherent interactions between the summary and
document. As a result, they limited the representation to express major points
in the document, which is highly indicative of the key sentiment. In this
paper, we study how to effectively generate a discriminative representation
with explicit subject patterns and sentiment contexts for DSA. A Hierarchical
Interaction Networks (HIN) is proposed to explore bidirectional interactions
between the summary and document at multiple granularities and learn
subject-oriented document representations for sentiment classification.
Furthermore, we design a Sentiment-based Rethinking mechanism (SR) by refining
the HIN with sentiment label information to learn a more sentiment-aware
document representation. We extensively evaluate our proposed models on three
public datasets. The experimental results consistently demonstrate the
effectiveness of our proposed models and show that HIN-SR outperforms various
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intent Detection and Slot Filling for Vietnamese. (arXiv:2104.02021v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dao_M/0/1/0/all/0/1">Mai Hoang Dao</a>, <a href="http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1">Thinh Hung Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dat Quoc Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02021">
                                    <div class="article-summary-box-inner">
                                        <span>Intent detection and slot filling are important tasks in spoken and natural
language understanding. However, Vietnamese is a low-resource language in these
research topics. In this paper, we present the first public intent detection
and slot filling dataset for Vietnamese. In addition, we also propose a joint
model for intent detection and slot filling, that extends the recent
state-of-the-art JointBERT+CRF model with an intent-slot attention layer to
explicitly incorporate intent context information into slot filling via &quot;soft&quot;
intent label embedding. Experimental results on our Vietnamese dataset show
that our proposed model significantly outperforms JointBERT+CRF. We publicly
release our dataset and the implementation of our model at:
https://github.com/VinAIResearch/JointIDSF</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1">Danilo Dessi</a>, <a href="http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1">Rim Helaoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vivek Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1">Diego Reforgiato Recupero</a>, <a href="http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1">Daniele Riboni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09632">
                                    <div class="article-summary-box-inner">
                                        <span>Today, we are seeing an ever-increasing number of clinical notes that contain
clinical results, images, and textual descriptions of patient&#x27;s health state.
All these data can be analyzed and employed to cater novel services that can
help people and domain experts with their common healthcare tasks. However,
many technologies such as Deep Learning and tools like Word Embeddings have
started to be investigated only recently, and many challenges remain open when
it comes to healthcare domain applications. To address these challenges, we
propose the use of Deep Learning and Word Embeddings for identifying sixteen
morbidity types within textual descriptions of clinical records. For this
purpose, we have used a Deep Learning model based on Bidirectional Long-Short
Term Memory (LSTM) layers which can exploit state-of-the-art vector
representations of data such as Word Embeddings. We have employed pre-trained
Word Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained
on the target domain. Furthermore, we have compared the performances of the
deep learning approaches against the traditional tf-idf using Support Vector
Machine and Multilayer perceptron (our baselines). From the obtained results it
seems that the latter outperforms the combination of Deep Learning approaches
using any word embeddings. Our preliminary results indicate that there are
specific features that make the dataset biased in favour of traditional machine
learning approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DefSent: Sentence Embeddings using Definition Sentences. (arXiv:2105.04339v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsukagoshi_H/0/1/0/all/0/1">Hayato Tsukagoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasano_R/0/1/0/all/0/1">Ryohei Sasano</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1">Koichi Takeda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04339">
                                    <div class="article-summary-box-inner">
                                        <span>Sentence embedding methods using natural language inference (NLI) datasets
have been successfully applied to various tasks. However, these methods are
only available for limited languages due to relying heavily on the large NLI
datasets. In this paper, we propose DefSent, a sentence embedding method that
uses definition sentences from a word dictionary, which performs comparably on
unsupervised semantics textual similarity (STS) tasks and slightly better on
SentEval tasks than conventional methods. Since dictionaries are available for
many languages, DefSent is more broadly applicable than methods using NLI
datasets without constructing additional datasets. We demonstrate that DefSent
performs comparably on unsupervised semantics textual similarity (STS) tasks
and slightly better on SentEval tasks to the methods using large NLI datasets.
Our code is publicly available at https://github.com/hpprc/defsent .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vocabulary Learning via Optimal Transport for Machine Translation. (arXiv:2012.15671v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chun Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zaixiang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15671">
                                    <div class="article-summary-box-inner">
                                        <span>The choice of token vocabulary affects the performance of machine
translation. This paper aims to figure out what is a good vocabulary and
whether one can find the optimal vocabulary without trial training. To answer
these questions, we first provide an alternative understanding of the role of
vocabulary from the perspective of information theory. Motivated by this, we
formulate the quest of vocabularization -- finding the best token dictionary
with a proper size -- as an optimal transport (OT) problem.We We propose VOLT,
a simple and efficient solution without trial training. Empirical results show
that VOLT outperforms widely-used vocabularies in diverse scenarios, including
WMT-14 English-German and TED&#x27;s 52 translation directions. For example, VOLT
achieves 70% vocabulary size reduction and 0.5 BLEU gain on English-German
translation. Also, compared to BPE-search, VOLT reduces the search time from
384 GPU hours to 30 GPU hours on English-German translation. Codes are
available at https://github.com/Jingjing-NLP/VOLT .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Case Studies on using Natural Language Processing Techniques in Customer Relationship Management Software. (arXiv:2106.05160v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1">&#x15e;&#xfc;kr&#xfc; Ozan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05160">
                                    <div class="article-summary-box-inner">
                                        <span>How can a text corpus stored in a customer relationship management (CRM)
database be used for data mining and segmentation? In order to answer this
question we inherited the state of the art methods commonly used in natural
language processing (NLP) literature, such as word embeddings, and deep
learning literature, such as recurrent neural networks (RNN). We used the text
notes from a CRM system which are taken by customer representatives of an
internet ads consultancy agency between years 2009 and 2020. We trained word
embeddings by using the corresponding text corpus and showed that these word
embeddings can not only be used directly for data mining but also be used in
RNN architectures, which are deep learning frameworks built with long short
term memory (LSTM) units, for more comprehensive segmentation objectives. The
results prove that structured text data in a CRM can be used to mine out very
valuable information and any CRM can be equipped with useful NLP features once
the problem definitions are properly built and the solution methods are
conveniently implemented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks. (arXiv:2011.02511v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1">Julia Kreutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1">Stefan Riezler</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1">Carolin Lawrence</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02511">
                                    <div class="article-summary-box-inner">
                                        <span>Large volumes of interaction logs can be collected from NLP systems that are
deployed in the real world. How can this wealth of information be leveraged?
Using such interaction logs in an offline reinforcement learning (RL) setting
is a promising approach. However, due to the nature of NLP tasks and the
constraints of production systems, a series of challenges arise. We present a
concise overview of these challenges and discuss possible solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-stage Sequence-to-Sequence Training. (arXiv:2103.16809v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1">Berrak Sisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haizhou Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16809">
                                    <div class="article-summary-box-inner">
                                        <span>Emotional voice conversion (EVC) aims to change the emotional state of an
utterance while preserving the linguistic content and speaker identity. In this
paper, we propose a novel 2-stage training strategy for sequence-to-sequence
emotional voice conversion with a limited amount of emotional speech data. We
note that the proposed EVC framework leverages text-to-speech (TTS) as they
share a common goal that is to generate high-quality expressive voice. In stage
1, we perform style initialization with a multi-speaker TTS corpus, to
disentangle speaking style and linguistic content. In stage 2, we perform
emotion training with a limited amount of emotional speech data, to learn how
to disentangle emotional style and linguistic information from the speech. The
proposed framework can perform both spectrum and prosody conversion and
achieves significant improvement over the state-of-the-art baselines in both
objective and subjective evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transient Chaos in BERT. (arXiv:2106.03181v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Katsuma Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohara_S/0/1/0/all/0/1">Soh Ohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1">Yasuo Kuniyoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1">Kohei Nakajima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03181">
                                    <div class="article-summary-box-inner">
                                        <span>Language is an outcome of our complex and dynamic human-interactions and the
technique of natural language processing (NLP) is hence built on human
linguistic activities. Bidirectional Encoder Representations from Transformers
(BERT) has recently gained its popularity by establishing the state-of-the-art
scores in several NLP benchmarks. A Lite BERT (ALBERT) is literally
characterized as a lightweight version of BERT, in which the number of BERT
parameters is reduced by repeatedly applying the same neural network called
Transformer&#x27;s encoder layer. By pre-training the parameters with a massive
amount of natural language data, ALBERT can convert input sentences into
versatile high-dimensional vectors potentially capable of solving multiple NLP
tasks. In that sense, ALBERT can be regarded as a well-designed
high-dimensional dynamical system whose operator is the Transformer&#x27;s encoder,
and essential structures of human language are thus expected to be encapsulated
in its dynamics. In this study, we investigated the embedded properties of
ALBERT to reveal how NLP tasks are effectively solved by exploiting its
dynamics. We thereby aimed to explore the nature of human language from the
dynamical expressions of the NLP model. Our short-term analysis clarified that
the pre-trained model stably yields trajectories with higher dimensionality,
which would enhance the expressive capacity required for NLP tasks. Also, our
long-term analysis revealed that ALBERT intrinsically shows transient chaos, a
typical nonlinear phenomenon showing chaotic dynamics only in its transient,
and the pre-trained ALBERT model tends to produce the chaotic trajectory for a
significantly longer time period compared to a randomly-initialized one. Our
results imply that local chaoticity would contribute to improving NLP
performance, uncovering a novel aspect in the role of chaotic dynamics in human
language behaviors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Quality Diversification for Task-Oriented Dialogue Systems. (arXiv:2106.00891v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_H/0/1/0/all/0/1">Hrishikesh Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00891">
                                    <div class="article-summary-box-inner">
                                        <span>Many task-oriented dialogue systems use deep reinforcement learning (DRL) to
learn policies that respond to the user appropriately and complete the tasks
successfully. Training DRL agents with diverse dialogue trajectories prepare
them well for rare user requests and unseen situations. One effective
diversification method is to let the agent interact with a diverse set of
learned user models. However, trajectories created by these artificial user
models may contain generation errors, which can quickly propagate into the
agent&#x27;s policy. It is thus important to control the quality of the
diversification and resist the noise. In this paper, we propose a novel
dialogue diversification method for task-oriented dialogue systems trained in
simulators. Our method, Intermittent Short Extension Ensemble (I-SEE),
constrains the intensity to interact with an ensemble of diverse user models
and effectively controls the quality of the diversification. Evaluations on the
Multiwoz dataset show that I-SEE successfully boosts the performance of several
state-of-the-art DRL dialogue agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Streaming End-to-End Framework For Spoken Language Understanding. (arXiv:2105.10042v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1">Nihal Potdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1">Anderson R. Avila</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1">Chao Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yiran Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10042">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end spoken language understanding (SLU) has recently attracted
increasing interest. Compared to the conventional tandem-based approach that
combines speech recognition and language understanding as separate modules, the
new approach extracts users&#x27; intentions directly from the speech signals,
resulting in joint optimization and low latency. Such an approach, however, is
typically designed to process one intention at a time, which leads users to
take multiple rounds to fulfill their requirements while interacting with a
dialogue system. In this paper, we propose a streaming end-to-end framework
that can process multiple intentions in an online and incremental way. The
backbone of our framework is a unidirectional RNN trained with the
connectionist temporal classification (CTC) criterion. By this design, an
intention can be identified when sufficient evidence has been accumulated, and
multiple intentions can be identified sequentially. We evaluate our solution on
the Fluent Speech Commands (FSC) dataset and the intent detection accuracy is
about 97 % on all multi-intent settings. This result is comparable to the
performance of the state-of-the-art non-streaming models, but is achieved in an
online and incremental way. We also employ our model to a keyword spotting task
using the Google Speech Commands dataset and the results are also highly
promising.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes. (arXiv:2012.14210v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1">Nils Reimers</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14210">
                                    <div class="article-summary-box-inner">
                                        <span>Information Retrieval using dense low-dimensional representations recently
became popular and showed out-performance to traditional sparse-representations
like BM25. However, no previous work investigated how dense representations
perform with large index sizes. We show theoretically and empirically that the
performance for dense representations decreases quicker than sparse
representations for increasing index sizes. In extreme cases, this can even
lead to a tipping point where at a certain index size sparse representations
outperform dense representations. We show that this behavior is tightly
connected to the number of dimensions of the representations: The lower the
dimension, the higher the chance for false positives, i.e. returning irrelevant
documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open Domain Question Answering over Tables via Dense Retrieval. (arXiv:2103.12011v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1">Jonathan Herzig</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1">Thomas M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Krichene_S/0/1/0/all/0/1">Syrine Krichene</a>, <a href="http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1">Julian Martin Eisenschlos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12011">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in open-domain QA have led to strong models based on dense
retrieval, but only focused on retrieving textual passages. In this work, we
tackle open-domain QA over tables for the first time, and show that retrieval
can be improved by a retriever designed to handle tabular context. We present
an effective pre-training procedure for our retriever and improve retrieval
quality with mined hard negatives. As relevant datasets are missing, we extract
a subset of Natural Questions (Kwiatkowski et al., 2019) into a Table QA
dataset. We find that our retriever improves retrieval results from 72.0 to
81.1 recall@10 and end-to-end QA results from 33.8 to 37.7 exact match, over a
BERT based retriever.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition. (arXiv:2106.05111v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karita_S/0/1/0/all/0/1">Shigeki Karita</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubo_Y/0/1/0/all/0/1">Yotaro Kubo</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacchiani_M/0/1/0/all/0/1">Michiel Adriaan Unico Bacchiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_L/0/1/0/all/0/1">Llion Jones</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05111">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end (E2E) modeling is advantageous for automatic speech recognition
(ASR) especially for Japanese since word-based tokenization of Japanese is not
trivial, and E2E modeling is able to model character sequences directly. This
paper focuses on the latest E2E modeling techniques, and investigates their
performances on character-based Japanese ASR by conducting comparative
experiments. The results are analyzed and discussed in order to understand the
relative advantages of long short-term memory (LSTM), and Conformer models in
combination with connectionist temporal classification, transducer, and
attention-based loss functions. Furthermore, the paper investigates on
effectivity of the recent training techniques such as data augmentation
(SpecAugment), variational noise injection, and exponential moving average. The
best configuration found in the paper achieved the state-of-the-art character
error rates of 4.1%, 3.2%, and 3.5% for Corpus of Spontaneous Japanese (CSJ)
eval1, eval2, and eval3 tasks, respectively. The system is also shown to be
computationally efficient thanks to the efficiency of Conformer transducers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Complex Knowledge Graph Embeddings. (arXiv:2008.03130v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1">Caglar Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1">Axel-Cyrille Ngonga Ngomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03130">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of learning continuous vector
representations of knowledge graphs for predicting missing links. We present a
new approach called ConEx, which infers missing links by leveraging the
composition of a 2D convolution with a Hermitian inner product of
complex-valued embedding vectors. We evaluate ConEx against state-of-the-art
approaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our
experimental results show that ConEx achieves a performance superior to that of
state-of-the-art approaches such as RotatE, QuatE and TuckER on the link
prediction task on all datasets while requiring at least 8 times fewer
parameters. We ensure the reproducibility of our results by providing an
open-source implementation which includes the training, evaluation scripts
along with pre-trained models at https://github.com/conex-kge/ConEx.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coreference Reasoning in Machine Reading Comprehension. (arXiv:2012.15573v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Mingzhu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosavi_N/0/1/0/all/0/1">Nafise Sadat Moosavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1">Dan Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15573">
                                    <div class="article-summary-box-inner">
                                        <span>Coreference resolution is essential for natural language understanding and
has been long studied in NLP. In recent years, as the format of Question
Answering (QA) became a standard for machine reading comprehension (MRC), there
have been data collection efforts, e.g., Dasigi et al. (2019), that attempt to
evaluate the ability of MRC models to reason about coreference. However, as we
show, coreference reasoning in MRC is a greater challenge than earlier thought;
MRC datasets do not reflect the natural distribution and, consequently, the
challenges of coreference reasoning. Specifically, success on these datasets
does not reflect a model&#x27;s proficiency in coreference reasoning. We propose a
methodology for creating MRC datasets that better reflect the challenges of
coreference reasoning and use it to create a sample evaluation set. The results
on our dataset show that state-of-the-art models still struggle with these
phenomena. Furthermore, we develop an effective way to use naturally occurring
coreference phenomena from existing coreference resolution datasets when
training MRC models. This allows us to show an improvement in the coreference
reasoning abilities of state-of-the-art models. The code and the resulting
dataset are available at https://github.com/UKPLab/coref-reasoning-in-qa.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Licheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yen-Chun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1">Rohit Pillai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luowei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Eric Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1">Tamara Lee Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04632">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing video-and-language (VidL) research focuses on a single dataset,
or multiple datasets of a single task. In reality, a truly useful VidL system
is expected to be easily generalizable to diverse tasks, domains, and datasets.
To facilitate the evaluation of such systems, we introduce Video-And-Language
Understanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets
over 3 popular tasks: (i) text-to-video retrieval; (ii) video question
answering; and (iii) video captioning. VALUE benchmark aims to cover a broad
range of video genres, video lengths, data volumes, and task difficulty levels.
Rather than focusing on single-channel videos with visual information only,
VALUE promotes models that leverage information from both video frames and
their associated subtitles, as well as models that share knowledge across
multiple tasks. We evaluate various baseline methods with and without
large-scale VidL pre-training, and systematically investigate the impact of
video input channels, fusion methods, and different video representations. We
also study the transferability between tasks, and conduct multi-task learning
under different settings. The significant gap between our best model and human
performance calls for future study for advanced VidL models. VALUE is available
at https://value-leaderboard.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Attention Belief Networks. (arXiv:2106.05251v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shujian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xinjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05251">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based neural networks have achieved state-of-the-art results on a
wide range of tasks. Most such models use deterministic attention while
stochastic attention is less explored due to the optimization difficulties or
complicated model design. This paper introduces Bayesian attention belief
networks, which construct a decoder network by modeling unnormalized attention
weights with a hierarchy of gamma distributions, and an encoder network by
stacking Weibull distributions with a deterministic-upward-stochastic-downward
structure to approximate the posterior. The resulting auto-encoding networks
can be optimized in a differentiable way with a variational lower bound. It is
simple to convert any models with deterministic attention, including pretrained
ones, to the proposed Bayesian attention belief networks. On a variety of
language understanding tasks, we show that our method outperforms deterministic
attention and state-of-the-art stochastic attention in accuracy, uncertainty
estimation, generalization across domains, and robustness to adversarial
attacks. We further demonstrate the general applicability of our method on
neural machine translation and visual question answering, showing great
potential of incorporating our method into various attention-related tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Would a Teacher Do? Predicting Future Talk Moves. (arXiv:2106.05249v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesh_A/0/1/0/all/0/1">Ananya Ganesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1">Martha Palmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1">Katharina Kann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05249">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in natural language processing (NLP) have the ability to
transform how classroom learning takes place. Combined with the increasing
integration of technology in today&#x27;s classrooms, NLP systems leveraging
question answering and dialog processing techniques can serve as private tutors
or participants in classroom discussions to increase student engagement and
learning. To progress towards this goal, we use the classroom discourse
framework of academically productive talk (APT) to learn strategies that make
for the best learning experience. In this paper, we introduce a new task,
called future talk move prediction (FTMP): it consists of predicting the next
talk move -- an utterance strategy from APT -- given a conversation history
with its corresponding talk moves. We further introduce a neural network model
for this task, which outperforms multiple baselines by a large margin. Finally,
we compare our model&#x27;s performance on FTMP to human performance and show
several similarities between the two.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Class-Transductive Intent Representations for Zero-shot Intent Detection. (arXiv:2012.01721v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1">Qingyi Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuanxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1">Peng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiangnan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01721">
                                    <div class="article-summary-box-inner">
                                        <span>Zero-shot intent detection (ZSID) aims to deal with the continuously emerging
intents without annotated training data. However, existing ZSID systems suffer
from two limitations: 1) They are not good at modeling the relationship between
seen and unseen intents. 2) They cannot effectively recognize unseen intents
under the generalized intent detection (GZSID) setting. A critical problem
behind these limitations is that the representations of unseen intents cannot
be learned in the training stage. To address this problem, we propose a novel
framework that utilizes unseen class labels to learn Class-Transductive Intent
Representations (CTIR). Specifically, we allow the model to predict unseen
intents during training, with the corresponding label names serving as input
utterances. On this basis, we introduce a multi-task learning objective, which
encourages the model to learn the distinctions among intents, and a similarity
scorer, which estimates the connections among intents more accurately. CTIR is
easy to implement and can be integrated with existing methods. Experiments on
two real-world datasets show that CTIR brings considerable improvement to the
baseline systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding. (arXiv:2106.04939v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikzad_Khasmakhi_N/0/1/0/all/0/1">Narjes Nikzad-Khasmakhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1">Mohammad-Reza Feizi-Derakhshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1">Meysam Asgari-Chenaghlu</a>, <a href="http://arxiv.org/find/cs/1/au:+Balafar_M/0/1/0/all/0/1">Mohammad-Ali Balafar</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_A/0/1/0/all/0/1">Ali-Reza Feizi-Derakhshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahkar_Farshi_T/0/1/0/all/0/1">Taymaz Rahkar-Farshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1">Majid Ramezani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jahanbakhsh_Nagadeh_Z/0/1/0/all/0/1">Zoleikha Jahanbakhsh-Nagadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafarani_Moattar_E/0/1/0/all/0/1">Elnaz Zafarani-Moattar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1">Mehrdad Ranjbar-Khadivi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04939">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Keyword extraction is a popular research topic in the field of
natural language processing. Keywords are terms that describe the most relevant
information in a document. The main problem that researchers are facing is how
to efficiently and accurately extract the core keywords from a document.
However, previous keyword extraction approaches have utilized the text and
graph features, there is the lack of models that can properly learn and combine
these features in a best way.

Methods: In this paper, we develop a multimodal Key-phrase extraction
approach, namely Phraseformer, using transformer and graph embedding
techniques. In Phraseformer, each keyword candidate is presented by a vector
which is the concatenation of the text and structure learning representations.
Phraseformer takes the advantages of recent researches such as BERT and ExEm to
preserve both representations. Also, the Phraseformer treats the key-phrase
extraction task as a sequence labeling problem solved using classification
task.

Results: We analyze the performance of Phraseformer on three datasets
including Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we
investigate the performance of different classifiers on Phraseformer method
over Inspec dataset. Experimental results demonstrate the effectiveness of
Phraseformer method over the three datasets used. Additionally, the Random
Forest classifier gain the highest F1-score among all classifiers.

Conclusions: Due to the fact that the combination of BERT and ExEm is more
meaningful and can better represent the semantic of words. Hence, Phraseformer
significantly outperforms single-modality methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Which transformer architecture fits my data? A vocabulary bottleneck in self-attention. (arXiv:2105.03928v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1">Noam Wies</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1">Yoav Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Jannai_D/0/1/0/all/0/1">Daniel Jannai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1">Amnon Shashua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03928">
                                    <div class="article-summary-box-inner">
                                        <span>After their successful debut in natural language processing, Transformer
architectures are now becoming the de-facto standard in many domains. An
obstacle for their deployment over new modalities is the architectural
configuration: the optimal depth-to-width ratio has been shown to dramatically
vary across data types (e.g., $10$x larger over images than over language). We
theoretically predict the existence of an embedding rank bottleneck that limits
the contribution of self-attention width to the Transformer expressivity. We
thus directly tie the input vocabulary size and rank to the optimal
depth-to-width ratio, since a small vocabulary size or rank dictates an added
advantage of depth over width. We empirically demonstrate the existence of this
bottleneck and its implications on the depth-to-width interplay of Transformer
architectures, linking the architecture variability across domains to the often
glossed-over usage of different vocabulary sizes or embedding ranks in
different domains. As an additional benefit, our rank bottlenecking framework
allows us to identify size redundancies of $25\%-50\%$ in leading NLP models
such as ALBERT and T5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Sequence Labeling for Transformer-based Sentence Classifiers. (arXiv:2103.14465v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bujel_K/0/1/0/all/0/1">Kamil Bujel</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1">Helen Yannakoudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rei_M/0/1/0/all/0/1">Marek Rei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14465">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate how sentence-level transformers can be modified into effective
sequence labelers at the token level without any direct supervision. Existing
approaches to zero-shot sequence labeling do not perform well when applied on
transformer-based architectures. As transformers contain multiple layers of
multi-head self-attention, information in the sentence gets distributed between
many tokens, negatively affecting zero-shot token-level performance. We find
that a soft attention module which explicitly encourages sharpness of attention
weights can significantly outperform existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-Efficient Transfer Learning with Diff Pruning. (arXiv:2012.07463v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1">Demi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1">Alexander M. Rush</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yoon Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07463">
                                    <div class="article-summary-box-inner">
                                        <span>While task-specific finetuning of pretrained networks has led to significant
empirical advances in NLP, the large size of networks makes finetuning
difficult to deploy in multi-task, memory-constrained settings. We propose diff
pruning as a simple approach to enable parameter-efficient transfer learning
within the pretrain-finetune framework. This approach views finetuning as
learning a task-specific diff vector that is applied on top of the pretrained
parameter vector, which remains fixed and is shared across different tasks. The
diff vector is adaptively pruned during training with a differentiable
approximation to the L0-norm penalty to encourage sparsity. Diff pruning
becomes parameter-efficient as the number of tasks increases, as it requires
storing only the nonzero positions and weights of the diff vector for each
task, while the cost of storing the shared pretrained model remains constant.
It further does not require access to all tasks during training, which makes it
attractive in settings where tasks arrive in stream or the set of tasks is
unknown. We find that models finetuned with diff pruning can match the
performance of fully finetuned baselines on the GLUE benchmark while only
modifying 0.5% of the pretrained model&#x27;s parameters per task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multilingual Representation for Natural Language Understanding with Enhanced Cross-Lingual Supervision. (arXiv:2106.05166v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yinpeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liangyou Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05166">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, pre-training multilingual language models has shown great potential
in learning multilingual representation, a crucial topic of natural language
processing. Prior works generally use a single mixed attention (MA) module,
following TLM (Conneau and Lample, 2019), for attending to intra-lingual and
cross-lingual contexts equivalently and simultaneously. In this paper, we
propose a network named decomposed attention (DA) as a replacement of MA. The
DA consists of an intra-lingual attention (IA) and a cross-lingual attention
(CA), which model intralingual and cross-lingual supervisions respectively. In
addition, we introduce a language-adaptive re-weighting strategy during
training to further boost the model&#x27;s performance. Experiments on various
cross-lingual natural language understanding (NLU) tasks show that the proposed
architecture and learning strategy significantly improve the model&#x27;s
cross-lingual transferability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syn-QG: Syntactic and Shallow Semantic Rules for Question Generation. (arXiv:2004.08694v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1">Kaustubh D. Dhole</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.08694">
                                    <div class="article-summary-box-inner">
                                        <span>Question Generation (QG) is fundamentally a simple syntactic transformation;
however, many aspects of semantics influence what questions are good to form.
We implement this observation by developing Syn-QG, a set of transparent
syntactic rules leveraging universal dependencies, shallow semantic parsing,
lexical resources, and custom rules which transform declarative sentences into
question-answer pairs. We utilize PropBank argument descriptions and VerbNet
state predicates to incorporate shallow semantic content, which helps generate
questions of a descriptive nature and produce inferential and semantically
richer questions than existing systems. In order to improve syntactic fluency
and eliminate grammatically incorrect questions, we employ back-translation
over the output of these syntactic rules. A set of crowd-sourced evaluations
shows that our system can generate a larger number of highly grammatical and
relevant questions than previous QG systems and that back-translation
drastically improves grammaticality at a slight cost of generating irrelevant
questions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Supervised Domain Adaptation by Augmenting Pre-trained Models with Random Units. (arXiv:2106.04935v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meftah_S/0/1/0/all/0/1">Sara Meftah</a>, <a href="http://arxiv.org/find/cs/1/au:+Semmar_N/0/1/0/all/0/1">Nasredine Semmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamaazousti_Y/0/1/0/all/0/1">Youssef Tamaazousti</a>, <a href="http://arxiv.org/find/cs/1/au:+Essafi_H/0/1/0/all/0/1">Hassane Essafi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadat_F/0/1/0/all/0/1">Fatiha Sadat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04935">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language
Processing (NLP), thanks to its high performance on many tasks, especially in
low-resourced scenarios. Notably, TL is widely used for neural domain
adaptation to transfer valuable knowledge from high-resource to low-resource
domains. In the standard fine-tuning scheme of TL, a model is initially
pre-trained on a source domain and subsequently fine-tuned on a target domain
and, therefore, source and target domains are trained using the same
architecture. In this paper, we show through interpretation methods that such
scheme, despite its efficiency, is suffering from a main limitation. Indeed,
although capable of adapting to new domains, pre-trained neurons struggle with
learning certain patterns that are specific to the target domain. Moreover, we
shed light on the hidden negative transfer occurring despite the high
relatedness between source and target domains, which may mitigate the final
gain brought by transfer learning. To address these problems, we propose to
augment the pre-trained model with normalised, weighted and randomly
initialised units that foster a better adaptation while maintaining the
valuable source knowledge. We show that our approach exhibits significant
improvements to the standard fine-tuning scheme for neural domain adaptation
from the news domain to the social media domain on four NLP tasks:
part-of-speech tagging, chunking, named entity recognition and morphosyntactic
tagging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Memorization of Conspiracy Theories in Text Generation. (arXiv:2101.00379v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Levy_S/0/1/0/all/0/1">Sharon Levy</a>, <a href="http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1">Michael Saxon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00379">
                                    <div class="article-summary-box-inner">
                                        <span>The adoption of natural language generation (NLG) models can leave
individuals vulnerable to the generation of harmful information memorized by
the models, such as conspiracy theories. While previous studies examine
conspiracy theories in the context of social media, they have not evaluated
their presence in the new space of generative language models. In this work, we
investigate the capability of language models to generate conspiracy theory
text. Specifically, we aim to answer: can we test pretrained generative
language models for the memorization and elicitation of conspiracy theories
without access to the model&#x27;s training data? We highlight the difficulties of
this task and discuss it in the context of memorization, generalization, and
hallucination. Utilizing a new dataset consisting of conspiracy theory topics
and machine-generated conspiracy theories helps us discover that many
conspiracy theories are deeply rooted in the pretrained language models. Our
experiments demonstrate a relationship between model parameters such as size
and temperature and their propensity to generate conspiracy theory text. These
results indicate the need for a more thorough review of NLG applications before
release and an in-depth discussion of the drawbacks of memorization in
generative language models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xiao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09501">
                                    <div class="article-summary-box-inner">
                                        <span>Existing multilingual machine translation approaches mainly focus on
English-centric directions, while the non-English directions still lag behind.
In this work, we aim to build a many-to-many translation system with an
emphasis on the quality of non-English language directions. Our intuition is
based on the hypothesis that a universal cross-language representation leads to
better multilingual translation performance. To this end, we propose mRASP2, a
training method to obtain a single unified multilingual translation model.
mRASP2 is empowered by two techniques: a) a contrastive learning scheme to
close the gap among representations of different languages, and b) data
augmentation on both multiple parallel and monolingual data to further align
token representations. For English-centric directions, mRASP2 outperforms
existing best unified model and achieves competitive or even better performance
than the pre-trained and fine-tuned model mBART on tens of WMT&#x27;s translation
directions. For non-English directions, mRASP2 achieves an improvement of
average 10+ BLEU compared with the multilingual Transformer baseline. Code,
data and trained models are available at https://github.com/PANXiao1994/mRASP2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Lack of Robust Interpretability of Neural Text Classifiers. (arXiv:2106.04631v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1">Muhammad Bilal Zafar</a>, <a href="http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1">Michele Donini</a>, <a href="http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1">Dylan Slack</a>, <a href="http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1">C&#xe9;dric Archambeau</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Sanjiv Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1">Krishnaram Kenthapadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04631">
                                    <div class="article-summary-box-inner">
                                        <span>With the ever-increasing complexity of neural language models, practitioners
have turned to methods for understanding the predictions of these models. One
of the most well-adopted approaches for model interpretability is feature-based
interpretability, i.e., ranking the features in terms of their impact on model
predictions. Several prior studies have focused on assessing the fidelity of
feature-based interpretability methods, i.e., measuring the impact of dropping
the top-ranked features on the model output. However, relatively little work
has been conducted on quantifying the robustness of interpretations. In this
work, we assess the robustness of interpretations of neural text classifiers,
specifically, those based on pretrained Transformer encoders, using two
randomization tests. The first compares the interpretations of two models that
are identical except for their initializations. The second measures whether the
interpretations differ between a model with trained parameters and a model with
random parameters. Both tests show surprising deviations from expected
behavior, raising questions about the extent of insights that practitioners may
draw from interpretations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Extractive Search. (arXiv:2106.04612v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1">Shauli Ravfogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Taub_Tabib_H/0/1/0/all/0/1">Hillel Taub-Tabib</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04612">
                                    <div class="article-summary-box-inner">
                                        <span>Domain experts often need to extract structured information from large
corpora. We advocate for a search paradigm called &#x60;&#x60;extractive search&#x27;&#x27;, in
which a search query is enriched with capture-slots, to allow for such rapid
extraction. Such an extractive search system can be built around syntactic
structures, resulting in high-precision, low-recall results. We show how the
recall can be improved using neural retrieval and alignment. The goals of this
paper are to concisely introduce the extractive-search paradigm; and to
demonstrate a prototype neural retrieval system for extractive search and its
benefits and potential. Our prototype is available at
\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is
available at \url{https://vimeo.com/559586687}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech to Standard German Text Corpus. (arXiv:2010.02810v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pluss_M/0/1/0/all/0/1">Michel Pl&#xfc;ss</a>, <a href="http://arxiv.org/find/cs/1/au:+Neukom_L/0/1/0/all/0/1">Lukas Neukom</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1">Christian Scheller</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1">Manfred Vogel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02810">
                                    <div class="article-summary-box-inner">
                                        <span>We present the Swiss Parliaments Corpus (SPC), an automatically aligned Swiss
German speech to Standard German text corpus. This first version of the corpus
is based on publicly available data of the Bernese cantonal parliament and
consists of 293 hours of data. It was created using a novel forced sentence
alignment procedure and an alignment quality estimator, which can be used to
trade off corpus size and quality. We trained Automatic Speech Recognition
(ASR) models as baselines on different subsets of the data and achieved a Word
Error Rate (WER) of 0.278 and a BLEU score of 0.586 on the SPC test set. The
corpus is freely available for download.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding. (arXiv:2106.04970v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1">Tao Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Houfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04970">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the
online inference efficiency of the Transformer for instantaneous Grammatical
Error Correction (GEC). SAD optimizes the online inference efficiency for GEC
by two innovations: 1) it aggressively decodes as many tokens as possible in
parallel instead of always decoding only one token in each step to improve
computational parallelism; 2) it uses a shallow decoder instead of the
conventional Transformer architecture with balanced encoder-decoder depth to
reduce the computational cost during inference. Experiments in both English and
Chinese GEC benchmarks show that aggressive decoding could yield the same
predictions as greedy decoding but with a significant speedup for online
inference. Its combination with the shallow decoder could offer an even higher
online inference speedup over the powerful Transformer baseline without quality
loss. Not only does our approach allow a single model to achieve the
state-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14
and 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference
speedup over the Transformer-big model, but also it is easily adapted to other
languages. Our code is available at
https://github.com/AutoTemp/Shallow-Aggressive-Decoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation. (arXiv:2106.05093v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1">Cunxiao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05093">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new training objective named order-agnostic cross entropy (OaXE)
for fully non-autoregressive translation (NAT) models. OaXE improves the
standard cross-entropy loss to ameliorate the effect of word reordering, which
is a common source of the critical multimodality problem in NAT. Concretely,
OaXE removes the penalty for word order errors, and computes the cross entropy
loss based on the best possible alignment between model predictions and target
tokens. Since the log loss is very sensitive to invalid references, we leverage
cross entropy initialization and loss truncation to ensure the model focuses on
a good part of the search space. Extensive experiments on major WMT benchmarks
show that OaXE substantially improves translation performance, setting new
state of the art for fully NAT models. Further analyses show that OaXE
alleviates the multimodality problem by reducing token repetitions and
increasing prediction confidence. Our code, data, and trained models are
available at https://github.com/tencent-ailab/ICML21_OAXE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System. (arXiv:2106.04835v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zichuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04835">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on
dialog systems and found that improvement on individual components (e.g., NLU,
policy) in prior work may not necessarily bring benefit to pipeline systems in
system-wise evaluation. To improve the system-wise performance, in this paper,
we propose new joint system-wise optimization techniques for the pipeline
dialog system. First, we propose a new data augmentation approach which
automates the labeling process for NLU training. Second, we propose a novel
stochastic policy parameterization with Poisson distribution that enables
better exploration and offers a principled way to compute policy gradient.
Third, we propose a reward bonus to help policy explore successful dialogs. Our
approaches outperform the competitive pipeline systems from Takanobu et al.
(2020) by big margins of 12% success rate in automatic system-wise evaluation
and of 16% success rate in human evaluation on the standard multi-domain
benchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art
end-to-end trained model from DSTC9.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auto-tagging of Short Conversational Sentences using Natural Language Processing Methods. (arXiv:2106.04959v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1">D. Emre Ta&#x15f;ar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04959">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we aim to find a method to auto-tag sentences specific to a
domain. Our training data comprises short conversational sentences extracted
from chat conversations between company&#x27;s customer representatives and web site
visitors. We manually tagged approximately 14 thousand visitor inputs into ten
basic categories, which will later be used in a transformer-based language
model with attention mechanisms for the ultimate goal of developing a chatbot
application that can produce meaningful dialogue. We considered three different
state-of-the-art models and reported their auto-tagging capabilities. We
achieved the best performance with the bidirectional encoder representation
from transformers (BERT) model. Implementation of the models used in these
experiments can be cloned from our GitHub repository and tested for similar
auto-tagging problems without much effort.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making Better Use of Bilingual Information for Cross-Lingual AMR Parsing. (arXiv:2106.04814v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yitao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhe Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1">Xiaojun Wan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04814">
                                    <div class="article-summary-box-inner">
                                        <span>Abstract Meaning Representation (AMR) is a rooted, labeled, acyclic graph
representing the semantics of natural language. As previous works show,
although AMR is designed for English at first, it can also represent semantics
in other languages. However, they find that concepts in their predicted AMR
graphs are less specific. We argue that the misprediction of concepts is due to
the high relevance between English tokens and AMR concepts. In this work, we
introduce bilingual input, namely the translated texts as well as non-English
texts, in order to enable the model to predict more accurate concepts. Besides,
we also introduce an auxiliary task, requiring the decoder to predict the
English sequences at the same time. The auxiliary task can help the decoder
understand what exactly the corresponding English tokens are. Our proposed
cross-lingual AMR parser surpasses previous state-of-the-art parser by 10.6
points on Smatch F1 score. The ablation study also demonstrates the efficacy of
our proposed modules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing Multilingual Language Models for Discourse. (arXiv:2106.04832v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kurfali_M/0/1/0/all/0/1">Murathan Kurfal&#x131;</a>, <a href="http://arxiv.org/find/cs/1/au:+Ostling_R/0/1/0/all/0/1">Robert &#xd6;stling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04832">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained multilingual language models have become an important building
block in multilingual natural language processing. In the present paper, we
investigate a range of such models to find out how well they transfer
discourse-level knowledge across languages. This is done with a systematic
evaluation on a broader set of discourse-level tasks than has been previously
been assembled. We find that the XLM-RoBERTa family of models consistently show
the best performance, by simultaneously being good monolingual models and
degrading relatively little in a zero-shot setting. Our results also indicate
that model distillation may hurt the ability of cross-lingual transfer of
sentence representations, while language dissimilarity at most has a modest
effect. We hope that our test suite, covering 5 tasks with a total of 22
languages in 10 distinct families, will serve as a useful evaluation platform
for multilingual performance at and beyond the sentence level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Psycholinguistic Tripartite Graph Network for Personality Detection. (arXiv:2106.04963v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Feifan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_H/0/1/0/all/0/1">Haolan Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04963">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the recent work on personality detection from online posts adopts
multifarious deep neural networks to represent the posts and builds predictive
models in a data-driven manner, without the exploitation of psycholinguistic
knowledge that may unveil the connections between one&#x27;s language usage and his
psychological traits. In this paper, we propose a psycholinguistic
knowledge-based tripartite graph network, TrigNet, which consists of a
tripartite graph network and a BERT-based graph initializer. The graph network
injects structural psycholinguistic knowledge from LIWC, a computerized
instrument for psycholinguistic analysis, by constructing a heterogeneous
tripartite graph. The graph initializer is employed to provide initial
embeddings for the graph nodes. To reduce the computational cost in graph
learning, we further propose a novel flow graph attention network (GAT) that
only transmits messages between neighboring parties in the tripartite graph.
Benefiting from the tripartite graph, TrigNet can aggregate post information
from a psychological perspective, which is a novel way of exploiting domain
knowledge. Extensive experiments on two datasets show that TrigNet outperforms
the existing state-of-art model by 3.47 and 2.10 points in average F1.
Moreover, the flow GAT reduces the FLOPS and Memory measures by 38% and 32%,
respectively, in comparison to the original GAT in our setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DGA-Net Dynamic Gaussian Attention Network for Sentence Semantic Matching. (arXiv:2106.04905v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1">Guangyi Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04905">
                                    <div class="article-summary-box-inner">
                                        <span>Sentence semantic matching requires an agent to determine the semantic
relation between two sentences, where much recent progress has been made by the
advancement of representation learning techniques and inspiration of human
behaviors. Among all these methods, attention mechanism plays an essential role
by selecting important parts effectively. However, current attention methods
either focus on all the important parts in a static way or only select one
important part at one attention step dynamically, which leaves a large space
for further improvement. To this end, in this paper, we design a novel Dynamic
Gaussian Attention Network (DGA-Net) to combine the advantages of current
static and dynamic attention methods. More specifically, we first leverage
pre-trained language model to encode the input sentences and construct semantic
representations from a global perspective. Then, we develop a Dynamic Gaussian
Attention (DGA) to dynamically capture the important parts and corresponding
local contexts from a detailed perspective. Finally, we combine the global
information and detailed local information together to decide the semantic
relation of sentences comprehensively and precisely. Extensive experiments on
two popular sentence semantic matching tasks demonstrate that our proposed
DGA-Net is effective in improving the ability of attention mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Automatic Speech Recognition: A Review. (arXiv:2106.04897v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aldarmaki_H/0/1/0/all/0/1">Hanan Aldarmaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullah_A/0/1/0/all/0/1">Asad Ullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaki_N/0/1/0/all/0/1">Nazar Zaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04897">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic Speech Recognition (ASR) systems can be trained to achieve
remarkable performance given large amounts of manually transcribed speech, but
large labeled data sets can be difficult or expensive to acquire for all
languages of interest. In this paper, we review the research literature to
identify models and ideas that could lead to fully unsupervised ASR, including
unsupervised segmentation of the speech signal, unsupervised mapping from
speech segments to text, and semi-supervised models with nominal amounts of
labeled examples. The objective of the study is to identify the limitations of
what can be learned from speech data alone and to understand the minimum
requirements for speech recognition. Identifying these limitations would help
optimize the resources and efforts in ASR development for low-resource
languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentence Embeddings using Supervised Contrastive Learning. (arXiv:2106.04791v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1">Danqi Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04791">
                                    <div class="article-summary-box-inner">
                                        <span>Sentence embeddings encode sentences in fixed dense vectors and have played
an important role in various NLP tasks and systems. Methods for building
sentence embeddings include unsupervised learning such as Quick-Thoughts and
supervised learning such as InferSent. With the success of pretrained NLP
models, recent research shows that fine-tuning pretrained BERT on SNLI and
Multi-NLI data creates state-of-the-art sentence embeddings, outperforming
previous sentence embeddings methods on various evaluation benchmarks. In this
paper, we propose a new method to build sentence embeddings by doing supervised
contrastive learning. Specifically our method fine-tunes pretrained BERT on
SNLI data, incorporating both supervised crossentropy loss and supervised
contrastive loss. Compared with baseline where fine-tuning is only done with
supervised cross-entropy loss similar to current state-of-the-art method SBERT,
our supervised contrastive method improves 2.8% in average on Semantic Textual
Similarity (STS) benchmarks and 1.05% in average on various sentence transfer
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Sexism Detection with Multilingual Transformer Models. (arXiv:2106.04908v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mina_S/0/1/0/all/0/1">Sch&#xfc;tz Mina</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaqueline_B/0/1/0/all/0/1">Boeck Jaqueline</a>, <a href="http://arxiv.org/find/cs/1/au:+Daria_L/0/1/0/all/0/1">Liakhovets Daria</a>, <a href="http://arxiv.org/find/cs/1/au:+Djordje_S/0/1/0/all/0/1">Slijep&#x10d;evi&#x107; Djordje</a>, <a href="http://arxiv.org/find/cs/1/au:+Armin_K/0/1/0/all/0/1">Kirchknopf Armin</a>, <a href="http://arxiv.org/find/cs/1/au:+Manuel_H/0/1/0/all/0/1">Hecht Manuel</a>, <a href="http://arxiv.org/find/cs/1/au:+Johannes_B/0/1/0/all/0/1">Bogensperger Johannes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sven_S/0/1/0/all/0/1">Schlarb Sven</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexander_S/0/1/0/all/0/1">Schindler Alexander</a>, <a href="http://arxiv.org/find/cs/1/au:+Matthias_Z/0/1/0/all/0/1">Zeppelzauer Matthias</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04908">
                                    <div class="article-summary-box-inner">
                                        <span>Sexism has become an increasingly major problem on social networks during the
last years. The first shared task on sEXism Identification in Social neTworks
(EXIST) at IberLEF 2021 is an international competition in the field of Natural
Language Processing (NLP) with the aim to automatically identify sexism in
social media content by applying machine learning methods. Thereby sexism
detection is formulated as a coarse (binary) classification problem and a
fine-grained classification task that distinguishes multiple types of sexist
content (e.g., dominance, stereotyping, and objectification). This paper
presents the contribution of the AIT_FHSTP team at the EXIST2021 benchmark for
both tasks. To solve the tasks we applied two multilingual transformer models,
one based on multilingual BERT and one based on XLM-R. Our approach uses two
different strategies to adapt the transformers to the detection of sexist
content: first, unsupervised pre-training with additional data and second,
supervised fine-tuning with additional and augmented data. For both tasks our
best model is XLM-R with unsupervised pre-training on the EXIST data and
additional datasets and fine-tuning on the provided dataset. The best run for
the binary classification (task 1) achieves a macro F1-score of 0.7752 and
scores 5th rank in the benchmark; for the multiclass classification (task 2)
our best submission scores 6th rank with a macro F1-score of 0.5589.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Models for Code Generation under Compilability Constraints. (arXiv:2106.04985v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1">Tomasz Korbak</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsahar_H/0/1/0/all/0/1">Hady Elsahar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1">Marc Dymetman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1">Germ&#xe1;n Kruszewski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04985">
                                    <div class="article-summary-box-inner">
                                        <span>Neural language models can be successfully trained on source code, leading to
applications such as code completion. However, their versatile autoregressive
self-supervision objective overlooks important global sequence-level features
that are present in the data such as syntactic correctness or compilability. In
this work, we pose the problem of learning to generate compilable code as
constraint satisfaction. We define an Energy-Based Model (EBM) representing a
pre-trained generative model with an imposed constraint of generating only
compilable sequences. We then use the KL-Adaptive Distributional Policy
Gradient algorithm (Khalifa et al., 2021) to train a generative model
approximating the EBM. We conduct experiments showing that our proposed
approach is able to improve compilability rates without sacrificing diversity
and complexity of the generated samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniKeyphrase: A Unified Extraction and Generation Framework for Keyphrase Prediction. (arXiv:2106.04847v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huanqin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_D/0/1/0/all/0/1">Dan Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Feng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04847">
                                    <div class="article-summary-box-inner">
                                        <span>Keyphrase Prediction (KP) task aims at predicting several keyphrases that can
summarize the main idea of the given document. Mainstream KP methods can be
categorized into purely generative approaches and integrated models with
extraction and generation. However, these methods either ignore the diversity
among keyphrases or only weakly capture the relation across tasks implicitly.
In this paper, we propose UniKeyphrase, a novel end-to-end learning framework
that jointly learns to extract and generate keyphrases. In UniKeyphrase,
stacked relation layer and bag-of-words constraint are proposed to fully
exploit the latent semantic relation between extraction and generation in the
view of model structure and training process, respectively. Experiments on KP
benchmarks demonstrate that our joint approach outperforms mainstream methods
by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Catchphrase: Automatic Detection of Cultural References. (arXiv:2106.04830v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sweed_N/0/1/0/all/0/1">Nir Sweed</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahaf_D/0/1/0/all/0/1">Dafna Shahaf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04830">
                                    <div class="article-summary-box-inner">
                                        <span>A snowclone is a customizable phrasal template that can be realized in
multiple, instantly recognized variants. For example, &#x60;&#x60;* is the new *&quot; (Orange
is the new black, 40 is the new 30). Snowclones are extensively used in social
media. In this paper, we study snowclones originating from pop-culture quotes;
our goal is to automatically detect cultural references in text. We introduce a
new, publicly available data set of pop-culture quotes and their corresponding
snowclone usages and train models on them. We publish code for Catchphrase, an
internet browser plugin to automatically detect and mark references in
real-time, and examine its performance via a user study. Aside from assisting
people to better comprehend cultural references, we hope that detecting
snowclones can complement work on paraphrasing and help to tackle long-standing
questions in social science about the dynamics of information propagation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fragmented and Valuable: Following Sentiment Changes in Food Tweets. (arXiv:2106.04903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Maija K&#x101;le</a>, <a href="http://arxiv.org/find/cs/1/au:+Rikters_M/0/1/0/all/0/1">Mat&#x12b;ss Rikters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04903">
                                    <div class="article-summary-box-inner">
                                        <span>We analysed sentiment and frequencies related to smell, taste and temperature
expressed by food tweets in the Latvian language. To get a better understanding
of the role of smell, taste and temperature in the mental map of food
associations, we looked at such categories as &#x27;tasty&#x27; and &#x27;healthy&#x27;, which
turned out to be mutually exclusive. By analysing the occurrence frequency of
words associated with these categories, we discovered that food discourse
overall was permeated by &#x60;tasty&#x27; while the category of &#x27;healthy&#x27; was relatively
small. Finally, we used the analysis of temporal dynamics to see if we can
trace seasonality or other temporal aspects in smell, taste and temperature as
reflected in food tweets. Understanding the composition of social media content
with relation to smell, taste and temperature in food tweets allows us to
develop our work further - on food culture/seasonality and its relation to
temperature, on our limited capacity to express smell-related sentiments, and
the lack of the paradigm of taste in discussing food healthiness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Human Evaluation for Style Transfer. (arXiv:2106.04747v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Briakou_E/0/1/0/all/0/1">Eleftheria Briakou</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Sweta Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Ke Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tetreault_J/0/1/0/all/0/1">Joel Tetreault</a>, <a href="http://arxiv.org/find/cs/1/au:+Carpuat_M/0/1/0/all/0/1">Marine Carpuat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04747">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews and summarizes human evaluation practices described in 97
style transfer papers with respect to three main evaluation aspects: style
transfer, meaning preservation, and fluency. In principle, evaluations by human
raters should be the most reliable. However, in style transfer papers, we find
that protocols for human evaluations are often underspecified and not
standardized, which hampers the reproducibility of research in this field and
progress toward better human and automatic evaluation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Sample Based Explanation Methods for NLP:Efficiency, Faithfulness, and Semantic Evaluation. (arXiv:2106.04753v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yada Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_G/0/1/0/all/0/1">Guangnan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1">Xiaodong Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04753">
                                    <div class="article-summary-box-inner">
                                        <span>In the recent advances of natural language processing, the scale of the
state-of-the-art models and datasets is usually extensive, which challenges the
application of sample-based explanation methods in many aspects, such as
explanation interpretability, efficiency, and faithfulness. In this work, for
the first time, we can improve the interpretability of explanations by allowing
arbitrary text sequences as the explanation unit. On top of this, we implement
a hessian-free method with a model faithfulness guarantee. Finally, to compare
our method with the others, we propose a semantic-based evaluation metric that
can better align with humans&#x27; judgment of explanations than the widely adopted
diagnostic or re-training measures. The empirical results on multiple real data
sets demonstrate the proposed method&#x27;s superior performance to popular
explanation techniques such as Influence Function or TracIn on semantic
evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Expansion using Back Translation and Paraphrasing for Hate Speech Detection. (arXiv:2106.04681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beddiar_D/0/1/0/all/0/1">Djamila Romaissa Beddiar</a>, <a href="http://arxiv.org/find/cs/1/au:+Jahan_M/0/1/0/all/0/1">Md Saroar Jahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Oussalah_M/0/1/0/all/0/1">Mourad Oussalah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04681">
                                    <div class="article-summary-box-inner">
                                        <span>With proliferation of user generated contents in social media platforms,
establishing mechanisms to automatically identify toxic and abusive content
becomes a prime concern for regulators, researchers, and society. Keeping the
balance between freedom of speech and respecting each other dignity is a major
concern of social media platform regulators. Although, automatic detection of
offensive content using deep learning approaches seems to provide encouraging
results, training deep learning-based models requires large amounts of
high-quality labeled data, which is often missing. In this regard, we present
in this paper a new deep learning-based method that fuses a Back Translation
method, and a Paraphrasing technique for data augmentation. Our pipeline
investigates different word-embedding-based architectures for classification of
hate speech. The back translation technique relies on an encoder-decoder
architecture pre-trained on a large corpus and mostly used for machine
translation. In addition, paraphrasing exploits the transformer model and the
mixture of experts to generate diverse paraphrases. Finally, LSTM, and CNN are
compared to seek enhanced classification results. We evaluate our proposal on
five publicly available datasets; namely, AskFm corpus, Formspring dataset,
Warner and Waseem dataset, Olid, and Wikipedia toxic comments dataset. The
performance of the proposal together with comparison to some related
state-of-art results demonstrate the effectiveness and soundness of our
proposal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DravidianMultiModality: A Dataset for Multi-modal Sentiment Analysis in Tamil and Malayalam. (arXiv:2106.04853v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+K_J/0/1/0/all/0/1">Jishnu Parameswaran P.K</a>, <a href="http://arxiv.org/find/cs/1/au:+B_P/0/1/0/all/0/1">Premjith B</a>, <a href="http://arxiv.org/find/cs/1/au:+Soman_K/0/1/0/all/0/1">K.P Soman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponnusamy_R/0/1/0/all/0/1">Rahul Ponnusamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumaresan_P/0/1/0/all/0/1">Prasanna Kumar Kumaresan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thamburaj_K/0/1/0/all/0/1">Kingston Pal Thamburaj</a>, <a href="http://arxiv.org/find/cs/1/au:+McCrae_J/0/1/0/all/0/1">John P. McCrae</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04853">
                                    <div class="article-summary-box-inner">
                                        <span>Human communication is inherently multimodal and asynchronous. Analyzing
human emotions and sentiment is an emerging field of artificial intelligence.
We are witnessing an increasing amount of multimodal content in local languages
on social media about products and other topics. However, there are not many
multimodal resources available for under-resourced Dravidian languages. Our
study aims to create a multimodal sentiment analysis dataset for the
under-resourced Tamil and Malayalam languages. First, we downloaded product or
movies review videos from YouTube for Tamil and Malayalam. Next, we created
captions for the videos with the help of annotators. Then we labelled the
videos for sentiment, and verified the inter-annotator agreement using Fleiss&#x27;s
Kappa. This is the first multimodal sentiment analysis dataset for Tamil and
Malayalam by volunteer annotators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FastSeq: Make Sequence Generation Faster. (arXiv:2106.04718v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1">Fei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiusheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1">Nikhil Bhendawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1">Ting Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yeyun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_D/0/1/0/all/0/1">Desheng Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_B/0/1/0/all/0/1">Bingyu Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruifei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04718">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based models have made tremendous impacts in natural language
generation. However the inference speed is a bottleneck due to large model size
and intensive computing involved in auto-regressive decoding process. We
develop FastSeq framework to accelerate sequence generation without accuracy
loss. The proposed optimization techniques include an attention cache
optimization, an efficient algorithm for detecting repeated n-grams, and an
asynchronous generation pipeline with parallel I/O. These optimizations are
general enough to be applicable to Transformer-based models (e.g., T5, GPT2,
and UniLM). Our benchmark results on a set of widely used and diverse models
demonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use
with a simple one-line code change. The source code is available at
https://github.com/microsoft/fastseq.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1">Ashkan Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1">Kiran Garimella</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1">Devin Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04726">
                                    <div class="article-summary-box-inner">
                                        <span>WhatsApp is a popular chat application used by over 2 billion users
worldwide. However, due to end-to-end encryption, there is currently no easy
way to fact-check content on WhatsApp at scale. In this paper, we analyze the
usefulness of a crowd-sourced system on WhatsApp through which users can submit
&quot;tips&quot; containing messages they want fact-checked. We compare the tips sent to
a WhatsApp tipline run during the 2019 Indian national elections with the
messages circulating in large, public groups on WhatsApp and other social media
platforms during the same period. We find that tiplines are a very useful lens
into WhatsApp conversations: a significant fraction of messages and images sent
to the tipline match with the content being shared on public WhatsApp groups
and other social media. Our analysis also shows that tiplines cover the most
popular content well, and a majority of such content is often shared to the
tipline before appearing in large, public WhatsApp groups. Overall, the
analysis suggests tiplines can be an effective source for discovering content
to fact-check.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1">Nasser Zalmout</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Luna Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04630">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding product attributes plays an important role in improving online
shopping experience for customers and serves as an integral part for
constructing a product knowledge graph. Most existing methods focus on
attribute extraction from text description or utilize visual information from
product images such as shape and color. Compared to the inputs considered in
prior works, a product image in fact contains more information, represented by
a rich mixture of words and visual clues with a layout carefully designed to
impress customers. This work proposes a more inclusive framework that fully
utilizes these different modalities for attribute extraction. Inspired by
recent works in visual question answering, we use a transformer based sequence
to sequence model to fuse representations of product text, Optical Character
Recognition (OCR) tokens and visual objects detected in the product image. The
framework is further extended with the capability to extract attribute value
across multiple product categories with a single model, by training the decoder
to predict both product category and attribute value and conditioning its
output on product category. The model provides a unified attribute extraction
solution desirable at an e-commerce platform that offers numerous product
categories with a diverse body of product attributes. We evaluated the model on
two product attributes, one with many possible values and one with a small set
of possible values, over 14 product categories and found the model could
achieve 15% gain on the Recall and 10% gain on the F1 score compared to
existing methods using text-only features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Success of Domain Adaptation in Text Similarity. (arXiv:2106.04641v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pogrebnyakov_N/0/1/0/all/0/1">Nicolai Pogrebnyakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaghaghian_S/0/1/0/all/0/1">Shohreh Shaghaghian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04641">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning methods, and in particular domain adaptation, help exploit
labeled data in one domain to improve the performance of a certain task in
another domain. However, it is still not clear what factors affect the success
of domain adaptation. This paper models adaptation success and selection of the
most suitable source domains among several candidates in text similarity. We
use descriptive domain information and cross-domain similarity metrics as
predictive features. While mostly positive, the results also point to some
domains where adaptation success was difficult to predict.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compacter: Efficient Low-Rank Hypercomplex Adapter Layers. (arXiv:2106.04647v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1">Rabeeh Karimi Mahabadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1">James Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04647">
                                    <div class="article-summary-box-inner">
                                        <span>Adapting large-scale pretrained language models to downstream tasks via
fine-tuning is the standard method for achieving state-of-the-art performance
on NLP benchmarks. However, fine-tuning all weights of models with millions or
billions of parameters is sample-inefficient, unstable in low-resource
settings, and wasteful as it requires storing a separate copy of the model for
each task. Recent work has developed parameter-efficient fine-tuning methods,
but these approaches either still require a relatively large number of
parameters or underperform standard fine-tuning. In this work, we propose
Compacter, a method for fine-tuning large-scale language models with a better
trade-off between task performance and the number of trainable parameters than
prior work. Compacter accomplishes this by building on top of ideas from
adapters, low-rank optimization, and parameterized hypercomplex multiplication
layers.

Specifically, Compacter inserts task-specific weight matrices into a
pretrained model&#x27;s weights, which are computed efficiently as a sum of
Kronecker products between shared &#x60;&#x60;slow&#x27;&#x27; weights and &#x60;&#x60;fast&#x27;&#x27; rank-one
matrices defined per Compacter layer. By only training 0.047% of a pretrained
model&#x27;s parameters, Compacter performs on par with standard fine-tuning on GLUE
and outperforms fine-tuning in low-resource settings. Our code is publicly
available in https://github.com/rabeehk/compacter/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential End-to-End Intent and Slot Label Classification and Localization. (arXiv:2106.04660v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yiran Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Potdar_N/0/1/0/all/0/1">Nihal Potdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Avila_A/0/1/0/all/0/1">Anderson R. Avila</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04660">
                                    <div class="article-summary-box-inner">
                                        <span>Human-computer interaction (HCI) is significantly impacted by delayed
responses from a spoken dialogue system. Hence, end-to-end (e2e) spoken
language understanding (SLU) solutions have recently been proposed to decrease
latency. Such approaches allow for the extraction of semantic information
directly from the speech signal, thus bypassing the need for a transcript from
an automatic speech recognition (ASR) system. In this paper, we propose a
compact e2e SLU architecture for streaming scenarios, where chunks of the
speech signal are processed continuously to predict intent and slot values. Our
model is based on a 3D convolutional neural network (3D-CNN) and a
unidirectional long short-term memory (LSTM). We compare the performance of two
alignment-free losses: the connectionist temporal classification (CTC) method
and its adapted version, namely connectionist temporal localization (CTL). The
latter performs not only the classification but also localization of sequential
audio events. The proposed solution is evaluated on the Fluent Speech Command
dataset and results show our model ability to process incoming speech signal,
reaching accuracy as high as 98.97 % for CTC and 98.78 % for CTL on
single-label classification, and as high as 95.69 % for CTC and 95.28 % for CTL
on two-label prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comprehension Based Question Answering using Bloom&#x27;s Taxonomy. (arXiv:2106.04653v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sahu_P/0/1/0/all/0/1">Pritish Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cogswell_M/0/1/0/all/0/1">Michael Cogswell</a>, <a href="http://arxiv.org/find/cs/1/au:+Rutherford_Quach_S/0/1/0/all/0/1">Sara Rutherford-Quach</a>, <a href="http://arxiv.org/find/cs/1/au:+Divakaran_A/0/1/0/all/0/1">Ajay Divakaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04653">
                                    <div class="article-summary-box-inner">
                                        <span>Current pre-trained language models have lots of knowledge, but a more
limited ability to use that knowledge. Bloom&#x27;s Taxonomy helps educators teach
children how to use knowledge by categorizing comprehension skills, so we use
it to analyze and improve the comprehension skills of large pre-trained
language models. Our experiments focus on zero-shot question answering, using
the taxonomy to provide proximal context that helps the model answer questions
by being relevant to those questions. We show targeting context in this manner
improves performance across 4 popular common sense question answer datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1">Boris N. Oreshkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1">Florent Bocquelet</a>, <a href="http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1">F&#xe9;lix G. Harvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1">Bay Raitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1">Dominic Laflamme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01981">
                                    <div class="article-summary-box-inner">
                                        <span>Our work focuses on the development of a learnable neural representation of
human pose for advanced AI assisted animation tooling. Specifically, we tackle
the problem of constructing a full static human pose based on sparse and
variable user inputs (e.g. locations and/or orientations of a subset of body
joints). To solve this problem, we propose a novel neural architecture that
combines residual connections with prototype encoding of a partially specified
pose to create a new complete pose from the learned latent space. We show that
our architecture outperforms a baseline based on Transformer, both in terms of
accuracy and computational efficiency. Additionally, we develop a user
interface to integrate our neural model in Unity, a real-time 3D development
platform. Furthermore, we introduce two new datasets representing the static
human pose modeling problem, based on high-quality human motion capture data,
which will be released publicly along with model code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison for Anti-noise Robustness of Deep Learning Classification Methods on a Tiny Object Image Dataset: from Convolutional Neural Network to Visual Transformer and Performer. (arXiv:2106.01927v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Ao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hechen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1">Shuojia Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1">Marcin Grzegorzek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01927">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification has achieved unprecedented advance with the the rapid
development of deep learning. However, the classification of tiny object images
is still not well investigated. In this paper, we first briefly review the
development of Convolutional Neural Network and Visual Transformer in deep
learning, and introduce the sources and development of conventional noises and
adversarial attacks. Then we use various models of Convolutional Neural Network
and Visual Transformer to conduct a series of experiments on the image dataset
of tiny objects (sperms and impurities), and compare various evaluation metrics
in the experimental results to obtain a model with stable performance. Finally,
we discuss the problems in the classification of tiny objects and make a
prospect for the classification of tiny objects in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1">Yash Sharma</a>, <a href="http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1">Luigi Gresele</a>, <a href="http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>, <a href="http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1">Michel Besserve</a>, <a href="http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04619">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised representation learning has shown remarkable success in a
number of domains. A common practice is to perform data augmentation via
hand-crafted transformations intended to leave the semantics of the data
invariant. We seek to understand the empirical success of this approach from a
theoretical perspective. We formulate the augmentation process as a latent
variable model by postulating a partition of the latent representation into a
content component, which is assumed invariant to augmentation, and a style
component, which is allowed to change. Unlike prior work on disentanglement and
independent component analysis, we allow for both nontrivial statistical and
causal dependencies in the latent space. We study the identifiability of the
latent representation based on pairs of views of the observations and prove
sufficient conditions that allow us to identify the invariant content partition
up to an invertible mapping in both generative and discriminative settings. We
find numerical simulations with dependent latent variables are consistent with
our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,
visually complex images with rich causal dependencies, which we use to study
the effect of data augmentations performed in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1">Nasser Zalmout</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Luna Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04630">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding product attributes plays an important role in improving online
shopping experience for customers and serves as an integral part for
constructing a product knowledge graph. Most existing methods focus on
attribute extraction from text description or utilize visual information from
product images such as shape and color. Compared to the inputs considered in
prior works, a product image in fact contains more information, represented by
a rich mixture of words and visual clues with a layout carefully designed to
impress customers. This work proposes a more inclusive framework that fully
utilizes these different modalities for attribute extraction. Inspired by
recent works in visual question answering, we use a transformer based sequence
to sequence model to fuse representations of product text, Optical Character
Recognition (OCR) tokens and visual objects detected in the product image. The
framework is further extended with the capability to extract attribute value
across multiple product categories with a single model, by training the decoder
to predict both product category and attribute value and conditioning its
output on product category. The model provides a unified attribute extraction
solution desirable at an e-commerce platform that offers numerous product
categories with a diverse body of product attributes. We evaluated the model on
two product attributes, one with many possible values and one with a small set
of possible values, over 14 product categories and found the model could
achieve 15% gain on the Recall and 10% gain on the F1 score compared to
existing methods using text-only features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation. (arXiv:2106.04632v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Licheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yen-Chun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillai_R/0/1/0/all/0/1">Rohit Pillai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luowei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Eric Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">William Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1">Tamara Lee Berg</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04632">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing video-and-language (VidL) research focuses on a single dataset,
or multiple datasets of a single task. In reality, a truly useful VidL system
is expected to be easily generalizable to diverse tasks, domains, and datasets.
To facilitate the evaluation of such systems, we introduce Video-And-Language
Understanding Evaluation (VALUE) benchmark, an assemblage of 11 VidL datasets
over 3 popular tasks: (i) text-to-video retrieval; (ii) video question
answering; and (iii) video captioning. VALUE benchmark aims to cover a broad
range of video genres, video lengths, data volumes, and task difficulty levels.
Rather than focusing on single-channel videos with visual information only,
VALUE promotes models that leverage information from both video frames and
their associated subtitles, as well as models that share knowledge across
multiple tasks. We evaluate various baseline methods with and without
large-scale VidL pre-training, and systematically investigate the impact of
video input channels, fusion methods, and different video representations. We
also study the transferability between tasks, and conduct multi-task learning
under different settings. The significant gap between our best model and human
performance calls for future study for advanced VidL models. VALUE is available
at https://value-leaderboard.github.io/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Space-Time Attention All You Need for Video Understanding?. (arXiv:2102.05095v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1">Gedas Bertasius</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1">Lorenzo Torresani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05095">
                                    <div class="article-summary-box-inner">
                                        <span>We present a convolution-free approach to video classification built
exclusively on self-attention over space and time. Our method, named
&quot;TimeSformer,&quot; adapts the standard Transformer architecture to video by
enabling spatiotemporal feature learning directly from a sequence of
frame-level patches. Our experimental study compares different self-attention
schemes and suggests that &quot;divided attention,&quot; where temporal attention and
spatial attention are separately applied within each block, leads to the best
video classification accuracy among the design choices considered. Despite the
radically new design, TimeSformer achieves state-of-the-art results on several
action recognition benchmarks, including the best reported accuracy on
Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks,
our model is faster to train, it can achieve dramatically higher test
efficiency (at a small drop in accuracy), and it can also be applied to much
longer video clips (over one minute long). Code and models are available at:
https://github.com/facebookresearch/TimeSformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Neural Network Subspaces. (arXiv:2102.10472v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1">Mitchell Wortsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Horton_M/0/1/0/all/0/1">Maxwell Horton</a>, <a href="http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1">Carlos Guestrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1">Mohammad Rastegari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10472">
                                    <div class="article-summary-box-inner">
                                        <span>Recent observations have advanced our understanding of the neural network
optimization landscape, revealing the existence of (1) paths of high accuracy
containing diverse solutions and (2) wider minima offering improved
performance. Previous methods observing diverse paths require multiple training
runs. In contrast we aim to leverage both property (1) and (2) with a single
method and in a single training run. With a similar computational cost as
training one model, we learn lines, curves, and simplexes of high-accuracy
neural networks. These neural network subspaces contain diverse solutions that
can be ensembled, approaching the ensemble performance of independently trained
networks without the training cost. Moreover, using the subspace midpoint
boosts accuracy, calibration, and robustness to label noise, outperforming
Stochastic Weight Averaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhance Convolutional Neural Networks with Noise Incentive Block. (arXiv:2012.12109v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1">Menghan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1">Tien-Tsin Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12109">
                                    <div class="article-summary-box-inner">
                                        <span>As a generic modeling tool, Convolutional Neural Networks (CNNs) have been
widely employed in image generation and translation tasks. However, when fed
with a flat input, current CNN models may fail to generate vivid results due to
the spatially shared convolution kernels. We call it the flatness degradation
of CNNs. Unfortunately, such degradation is the greatest obstacles to generate
a spatially-variant output from a flat input, which has been barely discussed
in the previous literature. To tackle this problem, we propose a model agnostic
solution, i.e. Noise Incentive Block (NIB), which serves as a generic plug-in
for any CNN generation model. The key idea is to break the flat input condition
while keeping the intactness of the original information. Specifically, the NIB
perturbs the input data symmetrically with a noise map and reassembles them in
the feature domain as driven by the objective function. Extensive experiments
show that existing CNN models equipped with NIB survive from the flatness
degradation and are able to generate visually better results with richer
details in some specific image generation tasks given flat inputs, e.g.
semantic image synthesis, data-hidden image generation, and deep neural
dithering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervision of Feature Transformation for Further Improving Supervised Learning. (arXiv:2106.04922v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zilin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuhang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaomin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04922">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning, which benefits from automatically constructing
labels through pre-designed pretext task, has recently been applied for
strengthen supervised learning. Since previous self-supervised pretext tasks
are based on input, they may incur huge additional training overhead. In this
paper we find that features in CNNs can be also used for self-supervision. Thus
we creatively design the \emph{feature-based pretext task} which requires only
a small amount of additional training overhead. In our task we discard
different particular regions of features, and then train the model to
distinguish these different features. In order to fully apply our feature-based
pretext task in supervised learning, we also propose a novel learning framework
containing multi-classifiers for further improvement. Original labels will be
expanded to joint labels via self-supervision of feature transformations. With
more semantic information provided by our self-supervised tasks, this approach
can train CNNs more effectively. Extensive experiments on various supervised
learning tasks demonstrate the accuracy improvement and wide applicability of
our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I Don&#x27;t Need $\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Willetts_M/0/1/0/all/0/1">Matthew Willetts</a>, <a href="http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1">Brooks Paige</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05238">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we introduce a new approach for identifiable non-linear ICA
models. Recently there has been a renaissance in identifiability results in
deep generative models, not least for non-linear ICA. These prior works,
however, have assumed access to a sufficiently-informative auxiliary set of
observations, denoted $\mathbf{u}$. We show here how identifiability can be
obtained in the absence of this side-information, rendering possible
fully-unsupervised identifiable non-linear ICA. While previous theoretical
results have established the impossibility of identifiable non-linear ICA in
the presence of infinitely-flexible universal function approximators, here we
rely on the intrinsically-finite modelling capacity of any particular chosen
parameterisation of a deep generative model. In particular, we focus on
generative models which perform clustering in their latent space -- a model
structure which matches previous identifiable models, but with the learnt
clustering providing a synthetic form of auxiliary information. We evaluate our
proposals using VAEs, on synthetic and image datasets, and find that the
learned clusterings function effectively: deep generative models with latent
clusterings are empirically identifiable, to the same degree as models which
rely on side information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GaitGraph: Graph Convolutional Network for Skeleton-Based Gait Recognition. (arXiv:2101.11228v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teepe_T/0/1/0/all/0/1">Torben Teepe</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Ali Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilg_J/0/1/0/all/0/1">Johannes Gilg</a>, <a href="http://arxiv.org/find/cs/1/au:+Herzog_F/0/1/0/all/0/1">Fabian Herzog</a>, <a href="http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1">Stefan H&#xf6;rmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1">Gerhard Rigoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11228">
                                    <div class="article-summary-box-inner">
                                        <span>Gait recognition is a promising video-based biometric for identifying
individual walking patterns from a long distance. At present, most gait
recognition methods use silhouette images to represent a person in each frame.
However, silhouette images can lose fine-grained spatial information, and most
papers do not regard how to obtain these silhouettes in complex scenes.
Furthermore, silhouette images contain not only gait features but also other
visual clues that can be recognized. Hence these approaches can not be
considered as strict gait recognition.

We leverage recent advances in human pose estimation to estimate robust
skeleton poses directly from RGB images to bring back model-based gait
recognition with a cleaner representation of gait. Thus, we propose GaitGraph
that combines skeleton poses with Graph Convolutional Network (GCN) to obtain a
modern model-based approach for gait recognition. The main advantages are a
cleaner, more elegant extraction of the gait features and the ability to
incorporate powerful spatio-temporal modeling using GCN. Experiments on the
popular CASIA-B gait dataset show that our method archives state-of-the-art
performance in model-based gait recognition.

The code and models are publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit field learning for unsupervised anomaly detection in medical images. (arXiv:2106.05214v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Marimont_S/0/1/0/all/0/1">Sergio Naval Marimont</a>, <a href="http://arxiv.org/find/eess/1/au:+Tarroni_G/0/1/0/all/0/1">Giacomo Tarroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05214">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel unsupervised out-of-distribution detection method for
medical images based on implicit fields image representations. In our approach,
an auto-decoder feed-forward neural network learns the distribution of healthy
images in the form of a mapping between spatial coordinates and probabilities
over a proxy for tissue types. At inference time, the learnt distribution is
used to retrieve, from a given test image, a restoration, i.e. an image
maximally consistent with the input one but belonging to the healthy
distribution. Anomalies are localized using the voxel-wise probability
predicted by our model for the restored image. We tested our approach in the
task of unsupervised localization of gliomas on brain MR images and compared it
to several other VAE-based anomaly detection methods. Results show that the
proposed technique substantially outperforms them (average DICE 0.640 vs 0.518
for the best performing VAE-based alternative) while also requiring
considerably less computing time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1">Wang Yifan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1">Lukas Rahmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1">Olga Sorkine-Hornung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05187">
                                    <div class="article-summary-box-inner">
                                        <span>We present implicit displacement fields, a novel representation for detailed
3D geometry. Inspired by a classic surface deformation technique, displacement
mapping, our method represents a complex surface as a smooth base surface plus
a displacement along the base&#x27;s normal directions, resulting in a
frequency-based shape decomposition, where the high frequency signal is
constrained geometrically by the low frequency signal. Importantly, this
disentanglement is unsupervised thanks to a tailored architectural design that
has an innate frequency hierarchy by construction. We explore implicit
displacement field surface reconstruction and detail transfer and demonstrate
superior representational power, training stability and generalizability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PCNet: A Structure Similarity Enhancement Method for Multispectral and Multimodal Image Registration. (arXiv:2106.05124v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Si-Yuan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Hui-Liang Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Lun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shu-Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunguang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05124">
                                    <div class="article-summary-box-inner">
                                        <span>Multispectral and multimodal image processing is important in the community
of computer vision and computational photography. As the acquired multispectral
and multimodal data are generally misaligned due to the alternation or movement
of the image device, the image registration procedure is necessary. The
registration of multispectral or multimodal image is challenging due to the
non-linear intensity and gradient variation. To cope with this challenge, we
propose the phase congruency network (PCNet), which is able to enhance the
structure similarity and alleviate the non-linear intensity and gradient
variation. The images can then be aligned using the similarity enhanced
features produced by the network. PCNet is constructed under the guidance of
the phase congruency prior. The network contains three trainable layers
accompany with the modified learnable Gabor kernels according to the phase
congruency theory. Thanks to the prior knowledge, PCNet is extremely
light-weight and can be trained on quite a small amount of multispectral data.
PCNet can be viewed to be fully convolutional and hence can take input of
arbitrary sizes. Once trained, PCNet is applicable on a variety of
multispectral and multimodal data such as RGB/NIR and flash/no-flash images
without additional further tuning. Experimental results validate that PCNet
outperforms current state-of-the-art registration algorithms, including the
deep-learning based ones that have the number of parameters hundreds times
compared to PCNet. Thanks to the similarity enhancement training, PCNet
outperforms the original phase congruency algorithm with two-thirds less
feature channels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cervical Cytology Classification Using PCA &amp; GWO Enhanced Deep Features Selection. (arXiv:2106.04919v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Basak_H/0/1/0/all/0/1">Hritam Basak</a>, <a href="http://arxiv.org/find/cs/1/au:+Kundu_R/0/1/0/all/0/1">Rohit Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Sukanta Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_N/0/1/0/all/0/1">Nibaran Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04919">
                                    <div class="article-summary-box-inner">
                                        <span>Cervical cancer is one of the most deadly and common diseases among women
worldwide. It is completely curable if diagnosed in an early stage, but the
tedious and costly detection procedure makes it unviable to conduct
population-wise screening. Thus, to augment the effort of the clinicians, in
this paper, we propose a fully automated framework that utilizes Deep Learning
and feature selection using evolutionary optimization for cytology image
classification. The proposed framework extracts Deep feature from several
Convolution Neural Network models and uses a two-step feature reduction
approach to ensure reduction in computation cost and faster convergence. The
features extracted from the CNN models form a large feature space whose
dimensionality is reduced using Principal Component Analysis while preserving
99% of the variance. A non-redundant, optimal feature subset is selected from
this feature space using an evolutionary optimization algorithm, the Grey Wolf
Optimizer, thus improving the classification performance. Finally, the selected
feature subset is used to train an SVM classifier for generating the final
predictions. The proposed framework is evaluated on three publicly available
benchmark datasets: Mendeley Liquid Based Cytology (4-class) dataset, Herlev
Pap Smear (7-class) dataset, and the SIPaKMeD Pap Smear (5-class) dataset
achieving classification accuracies of 99.47%, 98.32% and 97.87% respectively,
thus justifying the reliability of the approach. The relevant codes for the
proposed approach can be found in:
https://github.com/DVLP-CMATERJU/Two-Step-Feature-Enhancement</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework. (arXiv:2106.04966v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McCay_K/0/1/0/all/0/1">Kevin D. McCay</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1">Edmond S. L. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakkos_D/0/1/0/all/0/1">Dimitrios Sakkos</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1">Wai Lok Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcroft_C/0/1/0/all/0/1">Claire Marcroft</a>, <a href="http://arxiv.org/find/cs/1/au:+Dulson_P/0/1/0/all/0/1">Patricia Dulson</a>, <a href="http://arxiv.org/find/cs/1/au:+Embleton_N/0/1/0/all/0/1">Nicholas D. Embleton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04966">
                                    <div class="article-summary-box-inner">
                                        <span>Providing early diagnosis of cerebral palsy (CP) is key to enhancing the
developmental outcomes for those affected. Diagnostic tools such as the General
Movements Assessment (GMA), have produced promising results in early diagnosis,
however these manual methods can be laborious.

In this paper, we propose a new framework for the automated classification of
infant body movements, based upon the GMA, which unlike previous methods, also
incorporates a visualization framework to aid with interpretability. Our
proposed framework segments extracted features to detect the presence of
Fidgety Movements (FMs) associated with the GMA spatiotemporally. These
features are then used to identify the body-parts with the greatest
contribution towards a classification decision and highlight the related
body-part segment providing visual feedback to the user.

We quantitatively compare the proposed framework&#x27;s classification performance
with several other methods from the literature and qualitatively evaluate the
visualization&#x27;s veracity. Our experimental results show that the proposed
method performs more robustly than comparable techniques in this setting whilst
simultaneously providing relevant visual interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLCC: Contrastive Learning for Color Constancy. (arXiv:2106.04989v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_Y/0/1/0/all/0/1">Yi-Chen Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chia-Che Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_H/0/1/0/all/0/1">Hsuan-Chao Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Hao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chia-Ping Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yu-Lin Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jou_K/0/1/0/all/0/1">Kevin Jou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04989">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present CLCC, a novel contrastive learning framework for
color constancy. Contrastive learning has been applied for learning
high-quality visual representations for image classification. One key aspect to
yield useful representations for image classification is to design illuminant
invariant augmentations. However, the illuminant invariant assumption conflicts
with the nature of the color constancy task, which aims to estimate the
illuminant given a raw image. Therefore, we construct effective contrastive
pairs for learning better illuminant-dependent features via a novel raw-domain
color augmentation. On the NUS-8 dataset, our method provides $17.5\%$ relative
improvements over a strong baseline, reaching state-of-the-art performance
without increasing model complexity. Furthermore, our method achieves
competitive performance on the Gehler dataset with $3\times$ fewer parameters
compared to top-ranking deep learning methods. More importantly, we show that
our model is more robust to different scenes under close proximity of
illuminants, significantly reducing $28.7\%$ worst-case error in data-sparse
regions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey. (arXiv:2012.04830v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoqing Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1">Yan Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fang_J/0/1/0/all/0/1">Jiansheng Fang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Higashita_R/0/1/0/all/0/1">Risa Higashita</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1">Jiang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04830">
                                    <div class="article-summary-box-inner">
                                        <span>Cataract is one of the leading causes of reversible visual impairment and
blindness globally. Over the years, researchers have achieved significant
progress in developing state-of-the-art artificial intelligence techniques for
automatic cataract classification and grading, helping clinicians prevent and
treat cataract in time. This paper provides a comprehensive survey of recent
advances in machine learning for cataract classification and grading based on
ophthalmic images. We summarize existing literature from two research
directions: conventional machine learning techniques and deep learning
techniques. This paper also provides insights into existing works of both
merits and limitations. In addition, we discuss several challenges of automatic
cataract classification and grading based on machine learning techniques and
present possible solutions to these challenges for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaussian Mixture Estimation from Weighted Samples. (arXiv:2106.05109v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Frisch_D/0/1/0/all/0/1">Daniel Frisch</a>, <a href="http://arxiv.org/find/stat/1/au:+Hanebeck_U/0/1/0/all/0/1">Uwe D. Hanebeck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05109">
                                    <div class="article-summary-box-inner">
                                        <span>We consider estimating the parameters of a Gaussian mixture density with a
given number of components best representing a given set of weighted samples.
We adopt a density interpretation of the samples by viewing them as a discrete
Dirac mixture density over a continuous domain with weighted components. Hence,
Gaussian mixture fitting is viewed as density re-approximation. In order to
speed up computation, an expectation-maximization method is proposed that
properly considers not only the sample locations, but also the corresponding
weights. It is shown that methods from literature do not treat the weights
correctly, resulting in wrong estimates. This is demonstrated with simple
counterexamples. The proposed method works in any number of dimensions with the
same computational load as standard Gaussian mixture estimators for unweighted
samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeRF in detail: Learning to sample for view synthesis. (arXiv:2106.05264v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1">Relja Arandjelovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05264">
                                    <div class="article-summary-box-inner">
                                        <span>Neural radiance fields (NeRF) methods have demonstrated impressive novel view
synthesis performance. The core approach is to render individual rays by
querying a neural network at points sampled along the ray to obtain the density
and colour of the sampled points, and integrating this information using the
rendering equation. Since dense sampling is computationally prohibitive, a
common solution is to perform coarse-to-fine sampling.

In this work we address a clear limitation of the vanilla coarse-to-fine
approach -- that it is based on a heuristic and not trained end-to-end for the
task at hand. We introduce a differentiable module that learns to propose
samples and their importance for the fine network, and consider and compare
multiple alternatives for its neural architecture. Training the proposal module
from scratch can be unstable due to lack of supervision, so an effective
pre-training strategy is also put forward. The approach, named &#x60;NeRF in detail&#x27;
(NeRF-ID), achieves superior view synthesis quality over NeRF and the
state-of-the-art on the synthetic Blender benchmark and on par or better
performance on the real LLFF-NeRF scenes. Furthermore, by leveraging the
predicted sample importance, a 25% saving in computation can be achieved
without significantly sacrificing the rendering quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densely connected multidilated convolutional networks for dense prediction tasks. (arXiv:2011.11844v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1">Naoya Takahashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1">Yuki Mitsufuji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11844">
                                    <div class="article-summary-box-inner">
                                        <span>Tasks that involve high-resolution dense prediction require a modeling of
both local and global patterns in a large input field. Although the local and
global structures often depend on each other and their simultaneous modeling is
important, many convolutional neural network (CNN)-based approaches interchange
representations in different resolutions only a few times. In this paper, we
claim the importance of a dense simultaneous modeling of multiresolution
representation and propose a novel CNN architecture called densely connected
multidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution
that has different dilation factors in a single layer to model different
resolutions simultaneously. By combining the multidilated convolution with the
DenseNet architecture, D3Net incorporates multiresolution learning with an
exponentially growing receptive field in almost all layers, while avoiding the
aliasing problem that occurs when we naively incorporate the dilated
convolution in DenseNet. Experiments on the image semantic segmentation task
using Cityscapes and the audio source separation task using MUSDB18 show that
the proposed method has superior performance over state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Class Relations: Absolute-relative Supervised and Unsupervised Few-shot Learning. (arXiv:2001.03919v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongguang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1">Piotr Koniusz</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1">Songlei Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongdong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03919">
                                    <div class="article-summary-box-inner">
                                        <span>The majority of existing few-shot learning methods describe image relations
with binary labels. However, such binary relations are insufficient to teach
the network complicated real-world relations, due to the lack of decision
smoothness. Furthermore, current few-shot learning models capture only the
similarity via relation labels, but they are not exposed to class concepts
associated with objects, which is likely detrimental to the classification
performance due to underutilization of the available class labels. To
paraphrase, children learn the concept of tiger from a few of actual examples
as well as from comparisons of tiger to other animals. Thus, we hypothesize
that in fact both similarity and class concept learning must be occurring
simultaneously. With these observations at hand, we study the fundamental
problem of simplistic class modeling in current few-shot learning methods. We
rethink the relations between class concepts, and propose a novel
Absolute-relative Learning paradigm to fully take advantage of label
information to refine the image representations and correct the relation
understanding in both supervised and unsupervised scenarios. Our proposed
paradigm improves the performance of several the state-of-the-art models on
publicly available datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Discover Multi-Class Attentional Regions for Multi-Label Image Recognition. (arXiv:2007.01755v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1">Bin-Bin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hong-Yu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01755">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-label image recognition is a practical and challenging task compared to
single-label image classification. However, previous works may be suboptimal
because of a great number of object proposals or complex attentional region
generation modules. In this paper, we propose a simple but efficient two-stream
framework to recognize multi-category objects from global image to local
regions, similar to how human beings perceive objects. To bridge the gap
between global and local streams, we propose a multi-class attentional region
module which aims to make the number of attentional regions as small as
possible and keep the diversity of these regions as high as possible. Our
method can efficiently and effectively recognize multi-class objects with an
affordable computation cost and a parameter-free region localization module.
Over three benchmarks on multi-label image classification, we create new
state-of-the-art results with a single model only using image semantics without
label dependency. In addition, the effectiveness of the proposed method is
extensively demonstrated under different factors such as global pooling
strategy, input size and network architecture. Code has been made available
at~\url{https://github.com/gaobb/MCAR}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Training Stronger Video Vision Transformers for EPIC-KITCHENS-100 Action Recognition. (arXiv:2106.05058v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qing_Z/0/1/0/all/0/1">Zhiwu Qing</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yutong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shiwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jianwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1">Zhurong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1">Mingqian Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1">Nong Sang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1">Marcelo H. Ang Jr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05058">
                                    <div class="article-summary-box-inner">
                                        <span>With the recent surge in the research of vision transformers, they have
demonstrated remarkable potential for various challenging computer vision
applications, such as image recognition, point cloud classification as well as
video understanding. In this paper, we present empirical results for training a
stronger video vision transformer on the EPIC-KITCHENS-100 Action Recognition
dataset. Specifically, we explore training techniques for video vision
transformers, such as augmentations, resolutions as well as initialization,
etc. With our training recipe, a single ViViT model achieves the performance of
47.4\% on the validation set of EPIC-KITCHENS-100 dataset, outperforming what
is reported in the original paper by 3.4%. We found that video transformers are
especially good at predicting the noun in the verb-noun action prediction task.
This makes the overall action prediction accuracy of video transformers notably
higher than convolutional ones. Surprisingly, even the best video transformers
underperform the convolutional networks on the verb prediction. Therefore, we
combine the video vision transformers and some of the convolutional video
networks and present our solution to the EPIC-KITCHENS-100 Action Recognition
competition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affordance Transfer Learning for Human-Object Interaction Detection. (arXiv:2104.02867v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zhi Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Baosheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xiaojiang Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02867">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning the human-object interactions (HOI) is essential for deeper scene
understanding, while object affordances (or functionalities) are of great
importance for human to discover unseen HOIs with novel objects. Inspired by
this, we introduce an affordance transfer learning approach to jointly detect
HOIs with novel objects and recognize affordances. Specifically, HOI
representations can be decoupled into a combination of affordance and object
representations, making it possible to compose novel interactions by combining
affordance representations and novel object representations from additional
images, i.e. transferring the affordance to novel objects. With the proposed
affordance transfer learning, the model is also capable of inferring the
affordances of novel objects from known affordance representations. The
proposed method can thus be used to 1) improve the performance of HOI
detection, especially for the HOIs with unseen objects; and 2) infer the
affordances of novel objects. Experimental results on two datasets, HICO-DET
and HOI-COCO (from V-COCO), demonstrate significant improvements over recent
state-of-the-art methods for HOI detection and object affordance detection.
Code is available at https://github.com/zhihou7/HOI-CL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking Representation Learning for Natural World Image Collections. (arXiv:2103.16483v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Horn_G/0/1/0/all/0/1">Grant Van Horn</a>, <a href="http://arxiv.org/find/cs/1/au:+Cole_E/0/1/0/all/0/1">Elijah Cole</a>, <a href="http://arxiv.org/find/cs/1/au:+Beery_S/0/1/0/all/0/1">Sara Beery</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilber_K/0/1/0/all/0/1">Kimberly Wilber</a>, <a href="http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1">Serge Belongie</a>, <a href="http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1">Oisin Mac Aodha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16483">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress in self-supervised learning has resulted in models that are
capable of extracting rich representations from image collections without
requiring any explicit label supervision. However, to date the vast majority of
these approaches have restricted themselves to training on standard benchmark
datasets such as ImageNet. We argue that fine-grained visual categorization
problems, such as plant and animal species classification, provide an
informative testbed for self-supervised learning. In order to facilitate
progress in this area we present two new natural world visual classification
datasets, iNat2021 and NeWT. The former consists of 2.7M images from 10k
different species uploaded by users of the citizen science application
iNaturalist. We designed the latter, NeWT, in collaboration with domain experts
with the aim of benchmarking the performance of representation learning
algorithms on a suite of challenging natural world binary classification tasks
that go beyond standard species classification. These two new datasets allow us
to explore questions related to large-scale representation and transfer
learning in the context of fine-grained categories. We provide a comprehensive
analysis of feature extractors trained with and without supervision on ImageNet
and iNat2021, shedding light on the strengths and weaknesses of different
learned features across a diverse set of tasks. We find that features produced
by standard supervised methods still outperform those produced by
self-supervised approaches such as SimCLR. However, improved self-supervised
learning methods are constantly being released and the iNat2021 and NeWT
datasets are a valuable resource for tracking their progress.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous Learning and Adaptation with Membrane Potential and Activation Threshold Homeostasis. (arXiv:2104.10851v3 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hadjiivanov_A/0/1/0/all/0/1">Alexander Hadjiivanov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10851">
                                    <div class="article-summary-box-inner">
                                        <span>Most classical (non-spiking) neural network models disregard internal neuron
dynamics and treat neurons as simple input integrators. However, biological
neurons have an internal state governed by complex dynamics that plays a
crucial role in learning, adaptation and the overall network activity and
behaviour. This paper presents the Membrane Potential and Activation Threshold
Homeostasis (MPATH) neuron model, which combines several biologically inspired
mechanisms to efficiently simulate internal neuron dynamics with a single
parameter analogous to the membrane time constant in biological neurons. The
model allows neurons to maintain a form of dynamic equilibrium by automatically
regulating their activity when presented with fluctuating input. One
consequence of the MPATH model is that it imbues neurons with a sense of time
without recurrent connections, paving the way for modelling processes that
depend on temporal aspects of neuron activity. Experiments demonstrate the
model&#x27;s ability to adapt to and continually learn from its input.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1">Sebastian Cygert</a>, <a href="http://arxiv.org/find/cs/1/au:+Czyzewski_A/0/1/0/all/0/1">Andrzej Czy&#x17c;ewski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05509">
                                    <div class="article-summary-box-inner">
                                        <span>Model compression techniques allow to significantly reduce the computational
cost associated with data processing by deep neural networks with only a minor
decrease in average accuracy. Simultaneously, reducing the model size may have
a large effect on noisy cases or objects belonging to less frequent classes. It
is a crucial problem from the perspective of the models&#x27; safety, especially for
object detection in the autonomous driving setting, which is considered in this
work. It was shown in the paper that the sensitivity of compressed models to
different distortion types is nuanced, and some of the corruptions are heavily
impacted by the compression methods (i.e., additive noise), while others (blur
effect) are only slightly affected. A common way to improve the robustness of
models is to use data augmentation, which was confirmed to positively affect
models&#x27; robustness, also for highly compressed models. It was further shown
that while data imbalance methods brought only a slight increase in accuracy
for the baseline model (without compression), the impact was more striking at
higher compression rates for the structured pruning. Finally, methods for
handling data imbalance brought a significant improvement of the pruned models&#x27;
worst-detected class accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Triplet Loss: Uncertainty Quantification in Image Retrieval. (arXiv:2011.12663v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Warburg_F/0/1/0/all/0/1">Frederik Warburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Jorgensen_M/0/1/0/all/0/1">Martin J&#xf8;rgensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Civera_J/0/1/0/all/0/1">Javier Civera</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12663">
                                    <div class="article-summary-box-inner">
                                        <span>Uncertainty quantification in image retrieval is crucial for downstream
decisions, yet it remains a challenging and largely unexplored problem. Current
methods for estimating uncertainties are poorly calibrated, computationally
expensive, or based on heuristics. We present a new method that views image
embeddings as stochastic features rather than deterministic features. Our two
main contributions are (1) a likelihood that matches the triplet constraint and
that evaluates the probability of an anchor being closer to a positive than a
negative; and (2) a prior over the feature space that justifies the
conventional l2 normalization. To ensure computational efficiency, we derive a
variational approximation of the posterior, called the Bayesian triplet loss,
that produces state-of-the-art uncertainty estimates and matches the predictive
performance of current state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular 3D Object Detection with Decoupled Structured Polygon Estimation and Height-Guided Depth Estimation. (arXiv:2002.01619v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yingjie Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Buyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_Z/0/1/0/all/0/1">Zeyu Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xingyu Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.01619">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular 3D object detection task aims to predict the 3D bounding boxes of
objects based on monocular RGB images. Since the location recovery in 3D space
is quite difficult on account of absence of depth information, this paper
proposes a novel unified framework which decomposes the detection problem into
a structured polygon prediction task and a depth recovery task. Different from
the widely studied 2D bounding boxes, the proposed novel structured polygon in
the 2D image consists of several projected surfaces of the target object.
Compared to the widely-used 3D bounding box proposals, it is shown to be a
better representation for 3D detection. In order to inversely project the
predicted 2D structured polygon to a cuboid in the 3D physical world, the
following depth recovery task uses the object height prior to complete the
inverse projection transformation with the given camera projection matrix.
Moreover, a fine-grained 3D box refinement scheme is proposed to further
rectify the 3D detection results. Experiments are conducted on the challenging
KITTI benchmark, in which our method achieves state-of-the-art detection
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Facet Clustering Variational Autoencoders. (arXiv:2106.05241v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1">Fabian Falck</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1">Haoting Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1">Matthew Willetts</a>, <a href="http://arxiv.org/find/stat/1/au:+Nicholson_G/0/1/0/all/0/1">George Nicholson</a>, <a href="http://arxiv.org/find/stat/1/au:+Yau_C/0/1/0/all/0/1">Christopher Yau</a>, <a href="http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1">Christopher C Holmes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05241">
                                    <div class="article-summary-box-inner">
                                        <span>Work in deep clustering focuses on finding a single partition of data.
However, high-dimensional data, such as images, typically feature multiple
interesting characteristics one could cluster over. For example, images of
objects against a background could be clustered over the shape of the object
and separately by the colour of the background. In this paper, we introduce
Multi-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of
variational autoencoders with a hierarchy of latent variables, each with a
Mixture-of-Gaussians prior, that learns multiple clusterings simultaneously,
and is trained fully unsupervised and end-to-end. MFCVAE uses a
progressively-trained ladder architecture which leads to highly stable
performance. We provide novel theoretical results for optimising the ELBO
analytically with respect to the categorical variational posterior
distribution, and corrects earlier influential theoretical work. On image
benchmarks, we demonstrate that our approach separates out and clusters over
different aspects of the data in a disentangled manner. We also show other
advantages of our model: the compositionality of its latent space and that it
provides controlled generation of samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1">Divyam Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12135">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial learning has emerged as one of the successful techniques to
circumvent the susceptibility of existing methods against adversarial
perturbations. However, the majority of existing defense methods are tailored
to defend against a single category of adversarial perturbation (e.g.
$\ell_\infty$-attack). In safety-critical applications, this makes these
methods extraneous as the attacker can adopt diverse adversaries to deceive the
system. Moreover, training on multiple perturbations simultaneously
significantly increases the computational overhead during training. To address
these challenges, we propose a novel meta-learning framework that explicitly
learns to generate noise to improve the model&#x27;s robustness against multiple
types of attacks. Its key component is Meta Noise Generator (MNG) that outputs
optimal noise to stochastically perturb a given sample, such that it helps
lower the error on diverse adversarial perturbations. By utilizing samples
generated by MNG, we train a model by enforcing the label consistency across
multiple perturbations. We validate the robustness of models trained by our
scheme on various datasets and against a wide variety of perturbations,
demonstrating that it significantly outperforms the baselines across multiple
perturbations with a marginal computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">We Can Always Catch You: Detecting Adversarial Patched Objects WITH or WITHOUT Signature. (arXiv:2106.05261v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1">Bin Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianjun Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05261">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the object detection based on deep learning has proven to be
vulnerable to adversarial patch attacks. The attackers holding a specially
crafted patch can hide themselves from the state-of-the-art person detectors,
e.g., YOLO, even in the physical world. This kind of attack can bring serious
security threats, such as escaping from surveillance cameras. In this paper, we
deeply explore the detection problems about the adversarial patch attacks to
the object detection. First, we identify a leverageable signature of existing
adversarial patches from the point of the visualization explanation. A fast
signature-based defense method is proposed and demonstrated to be effective.
Second, we design an improved patch generation algorithm to reveal the risk
that the signature-based way may be bypassed by the techniques emerging in the
future. The newly generated adversarial patches can successfully evade the
proposed signature-based defense. Finally, we present a novel
signature-independent detection method based on the internal content semantics
consistency rather than any attack-specific prior knowledge. The fundamental
intuition is that the adversarial object can appear locally but disappear
globally in an input image. The experiments demonstrate that the
signature-independent method can effectively detect the existing and improved
attacks. It has also proven to be a general method by detecting unforeseen and
even other types of attacks without any attack-specific prior knowledge. The
two proposed detection methods can be adopted in different scenarios, and we
believe that combining them can offer a comprehensive protection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CARPe Posterum: A Convolutional Approach for Real-time Pedestrian Path Prediction. (arXiv:2005.12469v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mendieta_M/0/1/0/all/0/1">Mat&#xed;as Mendieta</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabkhi_H/0/1/0/all/0/1">Hamed Tabkhi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.12469">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian path prediction is an essential topic in computer vision and video
understanding. Having insight into the movement of pedestrians is crucial for
ensuring safe operation in a variety of applications including autonomous
vehicles, social robots, and environmental monitoring. Current works in this
area utilize complex generative or recurrent methods to capture many possible
futures. However, despite the inherent real-time nature of predicting future
paths, little work has been done to explore accurate and computationally
efficient approaches for this task. To this end, we propose a convolutional
approach for real-time pedestrian path prediction, CARPe. It utilizes a
variation of Graph Isomorphism Networks in combination with an agile
convolutional neural network design to form a fast and accurate path prediction
approach. Notable results in both inference speed and prediction accuracy are
achieved, improving FPS considerably in comparison to current state-of-the-art
methods while delivering competitive accuracy on well-known path prediction
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is it Enough to Optimize CNN Architectures on ImageNet?. (arXiv:2103.09108v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1">Lukas Tuggener</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a>, <a href="http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1">Thilo Stadelmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09108">
                                    <div class="article-summary-box-inner">
                                        <span>An implicit but pervasive hypothesis of modern computer vision research is
that convolutional neural network (CNN) architectures that perform better on
ImageNet will also perform better on other vision datasets. We challenge this
hypothesis through an extensive empirical study for which we train 500 sampled
CNN architectures on ImageNet as well as 8 other image classification datasets
from a wide array of application domains. The relationship between architecture
and performance varies wildly, depending on the datasets. For some of them, the
performance correlation with ImageNet is even negative. Clearly, it is not
enough to optimize architectures solely for ImageNet when aiming for progress
that is relevant for all applications. Therefore, we identify two
dataset-specific performance indicators: the cumulative width across layers as
well as the total depth of the network. Lastly, we show that the range of
dataset variability covered by ImageNet can be significantly extended by adding
ImageNet subsets restricted to few classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Adversarial Attacks on Neural Networks with Better Optimizer. (arXiv:2012.00567v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Heng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hengwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_R/0/1/0/all/0/1">Ruiyu Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00567">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks have outperformed humans in image recognition
tasks, but they remain vulnerable to attacks from adversarial examples. Since
these data are crafted by adding imperceptible noise to normal images, their
existence poses potential security threats to deep learning systems.
Sophisticated adversarial examples with strong attack performance can also be
used as a tool to evaluate the robustness of a model. However, the success rate
of adversarial attacks can be further improved in black-box environments.
Therefore, this study combines a modified Adam gradient descent algorithm with
the iterative gradient-based attack method. The proposed Adam Iterative Fast
Gradient Method is then used to improve the transferability of adversarial
examples. Extensive experiments on ImageNet showed that the proposed method
offers a higher attack success rate than existing iterative methods. By
extending our method, we achieved a state-of-the-art attack success rate of
95.0% on defense models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised 3D Hand-Object Poses Estimation with Interactions in Time. (arXiv:2106.05266v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shaowei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hanwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiarui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sifei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05266">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating 3D hand and object pose from a single image is an extremely
challenging problem: hands and objects are often self-occluded during
interactions, and the 3D annotations are scarce as even humans cannot directly
label the ground-truths from a single image perfectly. To tackle these
challenges, we propose a unified framework for estimating the 3D hand and
object poses with semi-supervised learning. We build a joint learning framework
where we perform explicit contextual reasoning between hand and object
representations by a Transformer. Going beyond limited 3D annotations in a
single image, we leverage the spatial-temporal consistency in large-scale
hand-object videos as a constraint for generating pseudo labels in
semi-supervised learning. Our method not only improves hand pose estimation in
challenging real-world dataset, but also substantially improve the object pose
which has fewer ground-truths per instance. By training with large-scale
diverse videos, our model also generalizes better across multiple out-of-domain
datasets. Project page and code: https://stevenlsw.github.io/Semi-Hand-Object</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Models as a Data Source for Multiview Representation Learning. (arXiv:2106.05258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jahanian_A/0/1/0/all/0/1">Ali Jahanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Puig_X/0/1/0/all/0/1">Xavier Puig</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonglong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05258">
                                    <div class="article-summary-box-inner">
                                        <span>Generative models are now capable of producing highly realistic images that
look nearly indistinguishable from the data on which they are trained. This
raises the question: if we have good enough generative models, do we still need
datasets? We investigate this question in the setting of learning
general-purpose visual representations from a black-box generative model rather
than directly from data. Given an off-the-shelf image generator without any
access to its training data, we train representations from the samples output
by this generator. We compare several representation learning methods that can
be applied to this setting, using the latent space of the generator to generate
multiple &quot;views&quot; of the same semantic content. We show that for contrastive
methods, this multiview data can naturally be used to identify positive pairs
(nearby in latent space) and negative pairs (far apart in latent space). We
find that the resulting representations rival those learned directly from real
data, but that good performance requires care in the sampling strategy applied
and the training method. Generative models can be viewed as a compressed and
organized copy of a dataset, and we envision a future where more and more
&quot;model zoos&quot; proliferate while datasets become increasingly unwieldy, missing,
or private. This paper suggests several techniques for dealing with visual
representation learning in such a future. Code is released on our project page:
https://ali-design.github.io/GenRep/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Evaluation of Multimodal Models under Realistic Gray Box Assumption. (arXiv:2011.12902v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evtimov_I/0/1/0/all/0/1">Ivan Evtimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Howes_R/0/1/0/all/0/1">Russel Howes</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolhansky_B/0/1/0/all/0/1">Brian Dolhansky</a>, <a href="http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1">Hamed Firooz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1">Cristian Canton Ferrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12902">
                                    <div class="article-summary-box-inner">
                                        <span>This work examines the vulnerability of multimodal (image + text) models to
adversarial threats similar to those discussed in previous literature on
unimodal (image- or text-only) models. We introduce realistic assumptions of
partial model knowledge and access, and discuss how these assumptions differ
from the standard &quot;black-box&quot;/&quot;white-box&quot; dichotomy common in current
literature on adversarial attacks. Working under various levels of these
&quot;gray-box&quot; assumptions, we develop new attack methodologies unique to
multimodal classification and evaluate them on the Hateful Memes Challenge
classification task. We find that attacking multiple modalities yields stronger
attacks than unimodal attacks alone (inducing errors in up to 73% of cases),
and that the unimodal image attacks on multimodal classifiers we explored were
stronger than character-based text augmentation attacks (inducing errors on
average in 45% and 30% of cases, respectively).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Point of Gaze Estimator for Low-Resolution Imaging Systems Using Extracted Ocular Features Based Neural Architecture. (arXiv:2106.05106v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1">Atul Sahay</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_I/0/1/0/all/0/1">Imon Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Arya_K/0/1/0/all/0/1">Kavi Arya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05106">
                                    <div class="article-summary-box-inner">
                                        <span>A user&#x27;s eyes provide means for Human Computer Interaction (HCI) research as
an important modal. The time to time scientific explorations of the eye has
already seen an upsurge of the benefits in HCI applications from gaze
estimation to the measure of attentiveness of a user looking at a screen for a
given time period. The eye tracking system as an assisting, interactive tool
can be incorporated by physically disabled individuals, fitted best for those
who have eyes as only a limited set of communication. The threefold objective
of this paper is - 1. To introduce a neural network based architecture to
predict users&#x27; gaze at 9 positions displayed in the 11.31{\deg} visual range on
the screen, through a low resolution based system such as a webcam in real time
by learning various aspects of eyes as an ocular feature set. 2.A collection of
coarsely supervised feature set obtained in real time which is also validated
through the user case study presented in the paper for 21 individuals ( 17 men
and 4 women ) from whom a 35k set of instances was derived with an accuracy
score of 82.36% and f1_score of 82.2% and 3.A detailed study over applicability
and underlying challenges of such systems. The experimental results verify the
feasibility and validity of the proposed eye gaze tracking model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation. (arXiv:1804.06679v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1">Rana Ali Amjad</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kairen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1">Bernhard C. Geiger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1804.06679">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we investigate the use of three information-theoretic
quantities -- entropy, mutual information with the class variable, and a class
selectivity measure based on Kullback-Leibler divergence -- to understand and
study the behavior of already trained fully-connected feed-forward neural
networks. We analyze the connection between these information-theoretic
quantities and classification performance on the test set by cumulatively
ablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our
results parallel those recently published by Morcos et al., indicating that
class selectivity is not a good indicator for classification performance.
However, looking at individual layers separately, both mutual information and
class selectivity are positively correlated with classification performance, at
least for networks with ReLU activation functions. We provide explanations for
this phenomenon and conclude that it is ill-advised to compare the proposed
information-theoretic quantities across layers. Furthermore, we show that
cumulative ablation of neurons with ascending or descending
information-theoretic quantities can be used to formulate hypotheses regarding
the joint behavior of multiple neurons, such as redundancy and synergy, with
comparably low computational cost. We also draw connections to the information
bottleneck theory for neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effect of large-scale pre-training on full and few-shot transfer learning for natural and medical images. (arXiv:2106.00116v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1">Mehdi Cherti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1">Jenia Jitsev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00116">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning aims to exploit pre-trained models for more efficient
follow-up training on wide range of downstream tasks and datasets, enabling
successful training also on small data. Recent line of work posits strong
benefits for model generalization and transfer when model size, data size, and
compute budget are increased for the pre-training. It remains however still
largely unclear whether the observed transfer improvement due to increase in
scale also holds when source and target data distributions are far apart from
each other. In this work we conduct large-scale pre-training on large source
datasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and
compare full and few-shot transfer using different target datasets from both
natural and medical imaging domains. Our observations provide evidence that
while pre-training and transfer on closely related datasets do show clear
benefit of increasing model and data size during pre-training, such benefits
are not clearly visible when source and target datasets are further apart.
These observations hold across both full and few-shot transfer and indicate
that scaling laws pointing to improvement of generalization and transfer with
increasing model and data size are incomplete and should be revised by taking
into account the type and proximity of the source and target data, to correctly
predict the effect of model and data scale during pre-training on transfer.
Remarkably, in full shot transfer to a large X-Ray chest imaging target
(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms
best models pre-trained on large X-Ray chest imaging data. This indicates
possibility to obtain high quality models for domain-specific transfer even
without access to large domain-specific data, by pre-training instead on
comparably very large, generic source data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Investigating Learned Representations. (arXiv:1905.13308v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1">Jesse A. Livezey</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_A/0/1/0/all/0/1">Ahyeon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1">Jacob Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1">Kristofer E. Bouchard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13308">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchy and compositionality are common latent properties in many natural
and scientific datasets. Determining when a deep network&#x27;s hidden activations
represent hierarchy and compositionality is important both for understanding
deep representation learning and for applying deep networks in domains where
interpretability is crucial. However, current benchmark machine learning
datasets either have little hierarchical or compositional structure, or the
structure is not known. This gap impedes precise analysis of a network&#x27;s
representations and thus hinders development of new methods that can learn such
properties. To address this gap, we developed a new benchmark dataset with
known hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)
is comprised of 35 fonts from the Korean writing system (Hangul), each with
11,172 blocks (syllables) composed from the product of initial consonant,
medial vowel, and final consonant glyphs. All blocks can be grouped into a few
geometric types which induces a hierarchy across blocks. In addition, each
block is composed of individual glyphs with rotations, translations, scalings,
and naturalistic style variation across fonts. We find that both shallow and
deep unsupervised methods only show modest evidence of hierarchy and
compositionality in their representations of the HFD compared to supervised
deep networks. Supervised deep network representations contain structure
related to the geometrical hierarchy of the characters, but the compositional
structure of the data is not evident. Thus, HFD enables the identification of
shortcomings in existing methods, a critical first step toward developing new
machine learning algorithms to extract hierarchical and compositional structure
in the context of naturalistic variability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation. (arXiv:2106.05210v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Ho Kei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Yu-Wing Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chi-Keung Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05210">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a simple yet effective approach to modeling space-time
correspondences in the context of video object segmentation. Unlike most
existing approaches, we establish correspondences directly between frames
without re-encoding the mask features for every object, leading to a highly
efficient and robust framework. With the correspondences, every node in the
current query frame is inferred by aggregating features from the past in an
associative fashion. We cast the aggregation process as a voting problem and
find that the existing inner-product affinity leads to poor use of memory with
a small (fixed) subset of memory nodes dominating the votes, regardless of the
query. In light of this phenomenon, we propose using the negative squared
Euclidean distance instead to compute the affinities. We validated that every
memory node now has a chance to contribute, and experimentally showed that such
diversified voting is beneficial to both memory efficiency and inference
accuracy. The synergy of correspondence networks and diversified voting works
exceedingly well, achieves new state-of-the-art results on both DAVIS and
YouTubeVOS datasets while running significantly faster at 20+ FPS for multiple
objects without bells and whistles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">All Tokens Matter: Token Labeling for Training Better Vision Transformers. (arXiv:2104.10858v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zihang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1">Qibin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Li Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Daquan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yujun Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiaojie Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Anran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10858">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present token labeling -- a new training objective for
training high-performance vision transformers (ViTs). Different from the
standard training objective of ViTs that computes the classification loss on an
additional trainable class token, our proposed one takes advantage of all the
image patch tokens to compute the training loss in a dense manner.
Specifically, token labeling reformulates the image classification problem into
multiple token-level recognition problems and assigns each patch token with an
individual location-specific supervision generated by a machine annotator.
Experiments show that token labeling can clearly and consistently improve the
performance of various ViT models across a wide spectrum. For a vision
transformer with 26M learnable parameters serving as an example, with token
labeling, the model can achieve 84.4% Top-1 accuracy on ImageNet. The result
can be further increased to 86.4% by slightly scaling the model size up to
150M, delivering the minimal-sized model among previous models (250M+) reaching
86%. We also show that token labeling can clearly improve the generalization
capability of the pre-trained models on downstream tasks with dense prediction,
such as semantic segmentation. Our code and all the training details will be
made publicly available at https://github.com/zihangJiang/TokenLabeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More than meets the eye: Self-supervised depth reconstruction from brain activity. (arXiv:2106.05113v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gaziv_G/0/1/0/all/0/1">Guy Gaziv</a>, <a href="http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1">Michal Irani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05113">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, significant advancements were made in reconstruction
of observed natural images from fMRI brain recordings using deep-learning
tools. Here, for the first time, we show that dense 3D depth maps of observed
2D natural images can also be recovered directly from fMRI brain recordings. We
use an off-the-shelf method to estimate the unknown depth maps of natural
images. This is applied to both: (i) the small number of images presented to
subjects in an fMRI scanner (images for which we have fMRI recordings -
referred to as &quot;paired&quot; data), and (ii) a very large number of natural images
with no fMRI recordings (&quot;unpaired data&quot;). The estimated depth maps are then
used as an auxiliary reconstruction criterion to train for depth reconstruction
directly from fMRI. We propose two main approaches: Depth-only recovery and
joint image-depth RGBD recovery. Because the number of available &quot;paired&quot;
training data (images with fMRI) is small, we enrich the training data via
self-supervised cycle-consistent training on many &quot;unpaired&quot; data (natural
images &amp; depth maps without fMRI). This is achieved using our newly defined and
trained Depth-based Perceptual Similarity metric as a reconstruction criterion.
We show that predicting the depth map directly from fMRI outperforms its
indirect sequential recovery from the reconstructed images. We further show
that activations from early cortical visual areas dominate our depth
reconstruction results, and propose means to characterize fMRI voxels by their
degree of depth-information tuning. This work adds an important layer of
decoded information, extending the current envelope of visual brain decoding
capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Application of Deep Learning in Generating Desired Design Options: Experiments Using Synthetic Training Dataset. (arXiv:2001.05849v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shaghaghian_Z/0/1/0/all/0/1">Zohreh Shaghaghian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_W/0/1/0/all/0/1">Wei Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.05849">
                                    <div class="article-summary-box-inner">
                                        <span>Most design methods contain a forward framework, asking for primary
specifications of a building to generate an output or assess its performance.
However, architects urge for specific objectives though uncertain of the proper
design parameters. Deep Learning (DL) algorithms provide an intelligent
workflow in which the system can learn from sequential training experiments.
This study applies a method using DL algorithms towards generating demanded
design options. In this study, an object recognition problem is investigated to
initially predict the label of unseen sample images based on training dataset
consisting of different types of synthetic 2D shapes; later, a generative DL
algorithm is applied to be trained and generate new shapes for given labels. In
the next step, the algorithm is trained to generate a window/wall pattern for
desired light/shadow performance based on the spatial daylight autonomy (sDA)
metrics. The experiments show promising results both in predicting unseen
sample shapes and generating new design options.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Modal Contrastive Learning for Text-to-Image Generation. (arXiv:2101.04702v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1">Jing Yu Koh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldridge_J/0/1/0/all/0/1">Jason Baldridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinfei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04702">
                                    <div class="article-summary-box-inner">
                                        <span>The output of text-to-image synthesis systems should be coherent, clear,
photo-realistic scenes with high semantic fidelity to their conditioned text
descriptions. Our Cross-Modal Contrastive Generative Adversarial Network
(XMC-GAN) addresses this challenge by maximizing the mutual information between
image and text. It does this via multiple contrastive losses which capture
inter-modality and intra-modality correspondences. XMC-GAN uses an attentional
self-modulation generator, which enforces strong text-image correspondence, and
a contrastive discriminator, which acts as a critic as well as a feature
encoder for contrastive learning. The quality of XMC-GAN&#x27;s output is a major
step up from previous models, as we show on three challenging datasets. On
MS-COCO, not only does XMC-GAN improve state-of-the-art FID from 24.70 to 9.33,
but--more importantly--people prefer XMC-GAN by 77.3 for image quality and 74.1
for image-text alignment, compared to three other recent models. XMC-GAN also
generalizes to the challenging Localized Narratives dataset (which has longer,
more detailed descriptions), improving state-of-the-art FID from 48.70 to
14.12. Lastly, we train and evaluate XMC-GAN on the challenging Open Images
data, establishing a strong benchmark FID score of 26.91.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Salient Object Ranking with Position-Preserved Attention. (arXiv:2106.05047v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1">Hao Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daoxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiawei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofei He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05047">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation can detect where the objects are in an image, but hard
to understand the relationship between them. We pay attention to a typical
relationship, relative saliency. A closely related task, salient object
detection, predicts a binary map highlighting a visually salient region while
hard to distinguish multiple objects. Directly combining two tasks by
post-processing also leads to poor performance. There is a lack of research on
relative saliency at present, limiting the practical applications such as
content-aware image cropping, video summary, and image labeling.

In this paper, we study the Salient Object Ranking (SOR) task, which manages
to assign a ranking order of each detected object according to its visual
saliency. We propose the first end-to-end framework of the SOR task and solve
it in a multi-task learning fashion. The framework handles instance
segmentation and salient object ranking simultaneously. In this framework, the
SOR branch is independent and flexible to cooperate with different detection
methods, so that easy to use as a plugin. We also introduce a
Position-Preserved Attention (PPA) module tailored for the SOR branch. It
consists of the position embedding stage and feature interaction stage.
Considering the importance of position in saliency comparison, we preserve
absolute coordinates of objects in ROI pooling operation and then fuse
positional information with semantic features in the first stage. In the
feature interaction stage, we apply the attention mechanism to obtain
proposals&#x27; contextualized representations to predict their relative ranking
orders. Extensive experiments have been conducted on the ASR dataset. Without
bells and whistles, our proposed method outperforms the former state-of-the-art
method significantly. The code will be released publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer in Convolutional Neural Networks. (arXiv:2106.03180v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1">Guolei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yu Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Le Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chhatkuli_A/0/1/0/all/0/1">Ajad Chhatkuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03180">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the low-efficiency flaw of vision transformer caused by the high
computational/space complexity in Multi-Head Self-Attention (MHSA). To this
end, we propose the Hierarchical MHSA (H-MHSA), whose representation is
computed in a hierarchical manner. Specifically, our H-MHSA first learns
feature relationships within small grids by viewing image patches as tokens.
Then, small grids are merged into larger ones, within which feature
relationship is learned by viewing each small grid at the preceding step as a
token. This process is iterated to gradually reduce the number of tokens. The
H-MHSA module is readily pluggable into any CNN architectures and amenable to
training via backpropagation. We call this new backbone TransCNN, and it
essentially inherits the advantages of both transformer and CNN. Experiments
demonstrate that TransCNN achieves state-of-the-art accuracy for image
recognition. Code and pretrained models are available at
https://github.com/yun-liu/TransCNN. This technical report will keep updating
by adding more experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XIRL: Cross-embodiment Inverse Reinforcement Learning. (arXiv:2106.03911v1 [cs.RO] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zakka_K/0/1/0/all/0/1">Kevin Zakka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Andy Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1">Pete Florence</a>, <a href="http://arxiv.org/find/cs/1/au:+Tompson_J/0/1/0/all/0/1">Jonathan Tompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1">Jeannette Bohg</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1">Debidatta Dwibedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03911">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the visual cross-embodiment imitation setting, in which agents
learn policies from videos of other agents (such as humans) demonstrating the
same task, but with stark differences in their embodiments -- shape, actions,
end-effector dynamics, etc. In this work, we demonstrate that it is possible to
automatically discover and learn vision-based reward functions from
cross-embodiment demonstration videos that are robust to these differences.
Specifically, we present a self-supervised method for Cross-embodiment Inverse
Reinforcement Learning (XIRL) that leverages temporal cycle-consistency
constraints to learn deep visual embeddings that capture task progression from
offline videos of demonstrations across multiple expert agents, each performing
the same task differently due to embodiment differences. Prior to our work,
producing rewards from self-supervised embeddings has typically required
alignment with a reference trajectory, which may be difficult to acquire. We
show empirically that if the embeddings are aware of task-progress, simply
taking the negative distance between the current state and goal state in the
learned embedding space is useful as a reward for training policies with
reinforcement learning. We find our learned reward function not only works for
embodiments seen during training, but also generalizes to entirely new
embodiments. We also find that XIRL policies are more sample efficient than
baselines, and in some cases exceed the sample efficiency of the same agent
trained with ground truth sparse rewards.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Deb_D/0/1/0/all/0/1">Diptodip Deb</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiao_Z/0/1/0/all/0/1">Zhenfei Jiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1">Alex B. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ahrens_M/0/1/0/all/0/1">Misha B. Ahrens</a>, <a href="http://arxiv.org/find/eess/1/au:+Podgorski_K/0/1/0/all/0/1">Kaspar Podgorski</a>, <a href="http://arxiv.org/find/eess/1/au:+Turaga_S/0/1/0/all/0/1">Srinivas C. Turaga</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10611">
                                    <div class="article-summary-box-inner">
                                        <span>3D snapshot microscopy enables fast volumetric imaging by capturing a 3D
volume in a single 2D camera image, and has found a variety of biological
applications such as whole brain imaging of fast neural activity in larval
zebrafish. The optimal microscope design for this optical 3D-to-2D encoding is
both sample- and task-dependent, with no general solution known. Highly
programmable optical elements create new possibilities for sample-specific
computational optimization of microscope parameters, e.g. tuning the collection
of light for a given sample structure. We perform such optimization with deep
learning, using a differentiable wave-optics simulation of light propagation
through a programmable microscope and a neural network to reconstruct volumes
from the microscope image. We introduce a class of global kernel Fourier
convolutional neural networks which can efficiently decode information from
multiple depths in the volume, globally encoded across a 3D snapshot image. We
show that our proposed networks succeed in large field of view volume
reconstruction and microscope parameter optimization where traditional networks
fail. We also show that our networks outperform the state-of-the-art learned
reconstruction algorithms for lensless computational photography.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Agile wide-field imaging with selective high resolution. (arXiv:2106.05082v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1">Lintao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_L/0/1/0/all/0/1">Liheng Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tiexin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05082">
                                    <div class="article-summary-box-inner">
                                        <span>Wide-field and high-resolution (HR) imaging is essential for various
applications such as aviation reconnaissance, topographic mapping and safety
monitoring. The existing techniques require a large-scale detector array to
capture HR images of the whole field, resulting in high complexity and heavy
cost. In this work, we report an agile wide-field imaging framework with
selective high resolution that requires only two detectors. It builds on the
statistical sparsity prior of natural scenes that the important targets locate
only at small regions of interests (ROI), instead of the whole field. Under
this assumption, we use a short-focal camera to image wide field with a certain
low resolution, and use a long-focal camera to acquire the HR images of ROI. To
automatically locate ROI in the wide field in real time, we propose an
efficient deep-learning based multiscale registration method that is robust and
blind to the large setting differences (focal, white balance, etc) between the
two cameras. Using the registered location, the long-focal camera mounted on a
gimbal enables real-time tracking of the ROI for continuous HR imaging. We
demonstrated the novel imaging framework by building a proof-of-concept setup
with only 1181 gram weight, and assembled it on an unmanned aerial vehicle for
air-to-ground monitoring. Experiments show that the setup maintains
120$^{\circ}$ wide field-of-view (FOV) with selective 0.45$mrad$ instantaneous
FOV.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Modality Vehicle Anomaly Detection via Bilateral Trajectory Tracing. (arXiv:2106.05003v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Guanchen Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuchen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1">Wenwei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kangmin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tianyi Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanping Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenzhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05003">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic anomaly detection has played a crucial role in Intelligent
Transportation System (ITS). The main challenges of this task lie in the highly
diversified anomaly scenes and variational lighting conditions. Although much
work has managed to identify the anomaly in homogenous weather and scene, few
resolved to cope with complex ones. In this paper, we proposed a dual-modality
modularized methodology for the robust detection of abnormal vehicles. We
introduced an integrated anomaly detection framework comprising the following
modules: background modeling, vehicle tracking with detection, mask
construction, Region of Interest (ROI) backtracking, and dual-modality tracing.
Concretely, we employed background modeling to filter the motion information
and left the static information for later vehicle detection. For the vehicle
detection and tracking module, we adopted YOLOv5 and multi-scale tracking to
localize the anomalies. Besides, we utilized the frame difference and tracking
results to identify the road and obtain the mask. In addition, we introduced
multiple similarity estimation metrics to refine the anomaly period via
backtracking. Finally, we proposed a dual-modality bilateral tracing module to
refine the time further. The experiments conducted on the Track 4 testset of
the NVIDIA 2021 AI City Challenge yielded a result of 0.9302 F1-Score and
3.4039 root mean square error (RMSE), indicating the effectiveness of our
framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Feature Enhancement: Applying Internal Pretext Task to Supervised Learning. (arXiv:2106.04921v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuhang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zilin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaomin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04921">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional self-supervised learning requires CNNs using external pretext
tasks (i.e., image- or video-based tasks) to encode high-level semantic visual
representations. In this paper, we show that feature transformations within
CNNs can also be regarded as supervisory signals to construct the
self-supervised task, called \emph{internal pretext task}. And such a task can
be applied for the enhancement of supervised learning. Specifically, we first
transform the internal feature maps by discarding different channels, and then
define an additional internal pretext task to identify the discarded channels.
CNNs are trained to predict the joint labels generated by the combination of
self-supervised labels and original labels. By doing so, we let CNNs know which
channels are missing while classifying in the hope to mine richer feature
information. Extensive experiments show that our approach is effective on
various models and datasets. And it&#x27;s worth noting that we only incur
negligible computational overhead. Furthermore, our approach can also be
compatible with other methods to get better results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A machine learning pipeline for aiding school identification from child trafficking images. (arXiv:2106.05215v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Sumit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sederholm_T/0/1/0/all/0/1">Tina Sederholm</a>, <a href="http://arxiv.org/find/cs/1/au:+Roman_A/0/1/0/all/0/1">Anthony C. Roman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankar_R/0/1/0/all/0/1">Ria Sankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Caltagirone_S/0/1/0/all/0/1">Sherrie Caltagirone</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1">Juan Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05215">
                                    <div class="article-summary-box-inner">
                                        <span>Child trafficking in a serious problem around the world. Every year there are
more than 4 million victims of child trafficking around the world, many of them
for the purposes of child sexual exploitation. In collaboration with UK Police
and a non-profit focused on child abuse prevention, Global Emancipation
Network, we developed a proof-of-concept machine learning pipeline to aid the
identification of children from intercepted images. In this work, we focus on
images that contain children wearing school uniforms to identify the school of
origin. In the absence of a machine learning pipeline, this hugely time
consuming and labor intensive task is manually conducted by law enforcement
personnel. Thus, by automating aspects of the school identification process, we
hope to significantly impact the speed of this portion of child identification.
Our proposed pipeline consists of two machine learning models: i) to identify
whether an image of a child contains a school uniform in it, and ii)
identification of attributes of different school uniform items (such as
color/texture of shirts, sweaters, blazers etc.). We describe the data
collection, labeling, model development and validation process, along with
strategies for efficient searching of schools using the model predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real Time Egocentric Object Segmentation: THU-READ Labeling and Benchmarking Results. (arXiv:2106.04957v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Sosa_E/0/1/0/all/0/1">E. Gonzalez-Sosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Robledo_G/0/1/0/all/0/1">G. Robledo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Morin_D/0/1/0/all/0/1">D. Gonzalez-Morin</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Garcia_P/0/1/0/all/0/1">P. Perez-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Villegas_A/0/1/0/all/0/1">A. Villegas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04957">
                                    <div class="article-summary-box-inner">
                                        <span>Egocentric segmentation has attracted recent interest in the computer vision
community due to their potential in Mixed Reality (MR) applications. While most
previous works have been focused on segmenting egocentric human body parts
(mainly hands), little attention has been given to egocentric objects. Due to
the lack of datasets of pixel-wise annotations of egocentric objects, in this
paper we contribute with a semantic-wise labeling of a subset of 2124 images
from the RGB-D THU-READ Dataset. We also report benchmarking results using
Thundernet, a real-time semantic segmentation network, that could allow future
integration with end-to-end MR applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A multi-stage GAN for multi-organ chest X-ray image generation and segmentation. (arXiv:2106.05132v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ciano_G/0/1/0/all/0/1">Giorgio Ciano</a>, <a href="http://arxiv.org/find/eess/1/au:+Andreini_P/0/1/0/all/0/1">Paolo Andreini</a>, <a href="http://arxiv.org/find/eess/1/au:+Mazzierli_T/0/1/0/all/0/1">Tommaso Mazzierli</a>, <a href="http://arxiv.org/find/eess/1/au:+Bianchini_M/0/1/0/all/0/1">Monica Bianchini</a>, <a href="http://arxiv.org/find/eess/1/au:+Scarselli_F/0/1/0/all/0/1">Franco Scarselli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05132">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-organ segmentation of X-ray images is of fundamental importance for
computer aided diagnosis systems. However, the most advanced semantic
segmentation methods rely on deep learning and require a huge amount of labeled
images, which are rarely available due to both the high cost of human resources
and the time required for labeling. In this paper, we present a novel
multi-stage generation algorithm based on Generative Adversarial Networks
(GANs) that can produce synthetic images along with their semantic labels and
can be used for data augmentation. The main feature of the method is that,
unlike other approaches, generation occurs in several stages, which simplifies
the procedure and allows it to be used on very small datasets. The method has
been evaluated on the segmentation of chest radiographic images, showing
promising results. The multistage approach achieves state-of-the-art and, when
very few images are used to train the GANs, outperforms the corresponding
single-stage approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ST++: Make Self-training Work Better for Semi-supervised Semantic Segmentation. (arXiv:2106.05095v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lihe Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_W/0/1/0/all/0/1">Wei Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lei Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yinghuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05095">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate if we could make the self-training -- a simple
but popular framework -- work better for semi-supervised segmentation. Since
the core issue in semi-supervised setting lies in effective and efficient
utilization of unlabeled data, we notice that increasing the diversity and
hardness of unlabeled data is crucial to performance improvement. Being aware
of this fact, we propose to adopt the most plain self-training scheme coupled
with appropriate strong data augmentations on unlabeled data (namely ST) for
this task, which surprisingly outperforms previous methods under various
settings without any bells and whistles. Moreover, to alleviate the negative
impact of the wrongly pseudo labeled images, we further propose an advanced
self-training framework (namely ST++), that performs selective re-training via
selecting and prioritizing the more reliable unlabeled images. As a result, the
proposed ST++ boosts the performance of semi-supervised model significantly and
surpasses existing methods by a large margin on the Pascal VOC 2012 and
Cityscapes benchmark. Overall, we hope this straightforward and simple
framework will serve as a strong baseline or competitor for future works. Code
is available at https://github.com/LiheYoung/ST-PlusPlus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling. (arXiv:2106.05233v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1">Benjamin Walter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05233">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification is considered, and a hierarchical max-pooling model with
additional local pooling is introduced. Here the additional local pooling
enables the hierachical model to combine parts of the image which have a
variable relative distance towards each other. Various convolutional neural
network image classifiers are introduced and compared in view of their rate of
convergence. The finite sample size performance of the estimates is analyzed by
applying them to simulated and real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Rank Words: Optimizing Ranking Metrics for Word Spotting. (arXiv:2106.05144v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1">Adri&#xe0; Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1">Lluis Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1">Oriol Ramos-Terrades</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05144">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore and evaluate the use of ranking-based objective
functions for learning simultaneously a word string and a word image encoder.
We consider retrieval frameworks in which the user expects a retrieval list
ranked according to a defined relevance score. In the context of a word
spotting problem, the relevance score has been set according to the string edit
distance from the query string. We experimentally demonstrate the competitive
performance of the proposed model on query-by-string word spotting for both,
handwritten and real scene word images. We also provide the results for
query-by-example word spotting, although it is not the main focus of this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Image Classifiers in Object Detectors. (arXiv:2106.05209v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shuxuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1">Jose M. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1">Mathieu Salzmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05209">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation constitutes a simple yet effective way to improve the
performance of a compact student network by exploiting the knowledge of a more
powerful teacher. Nevertheless, the knowledge distillation literature remains
limited to the scenario where the student and the teacher tackle the same task.
Here, we investigate the problem of transferring knowledge not only across
architectures but also across tasks. To this end, we study the case of object
detection and, instead of following the standard detector-to-detector
distillation approach, introduce a classifier-to-detector knowledge transfer
framework. In particular, we propose strategies to exploit the classification
teacher to improve both the detector&#x27;s recognition accuracy and localization
performance. Our experiments on several detectors with different backbones
demonstrate the effectiveness of our approach, allowing us to outperform the
state-of-the-art detector-to-detector distillation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Defending against Adversarial Examples via Attack-Invariant Features. (arXiv:2106.05036v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Dawei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1">Nannan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chunlei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinbo Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05036">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are vulnerable to adversarial noise. Their
adversarial robustness can be improved by exploiting adversarial examples.
However, given the continuously evolving attacks, models trained on seen types
of adversarial examples generally cannot generalize well to unseen types of
adversarial examples. To solve this problem, in this paper, we propose to
remove adversarial noise by learning generalizable invariant features across
attacks which maintain semantic classification information. Specifically, we
introduce an adversarial feature learning mechanism to disentangle invariant
features from adversarial noise. A normalization term has been proposed in the
encoded space of the attack-invariant features to address the bias issue
between the seen and unseen types of attacks. Empirical evaluations demonstrate
that our method could provide better protection in comparison to previous
state-of-the-art approaches, especially against unseen types of attacks and
adaptive attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised lane detection with Deep Hough Transform. (arXiv:2106.05094v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yancong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pintea_S/0/1/0/all/0/1">Silvia-Laura Pintea</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05094">
                                    <div class="article-summary-box-inner">
                                        <span>Current work on lane detection relies on large manually annotated datasets.
We reduce the dependency on annotations by leveraging massive cheaply available
unlabelled data. We propose a novel loss function exploiting geometric
knowledge of lanes in Hough space, where a lane can be identified as a local
maximum. By splitting lanes into separate channels, we can localize each lane
via simple global max-pooling. The location of the maximum encodes the layout
of a lane, while the intensity indicates the the probability of a lane being
present. Maximizing the log-probability of the maximal bins helps neural
networks find lanes without labels. On the CULane and TuSimple datasets, we
show that the proposed Hough Transform loss improves performance significantly
by learning from large amounts of unlabelled images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic CT Segmentation from Bounding Box Annotations using Convolutional Neural Networks. (arXiv:2105.14314v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuanpeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hui_Q/0/1/0/all/0/1">Qinglei Hui</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhiyi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1">Shaolin Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1">Dexing Kong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14314">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate segmentation for medical images is important for clinical diagnosis.
Existing automatic segmentation methods are mainly based on fully supervised
learning and have an extremely high demand for precise annotations, which are
very costly and time-consuming to obtain. To address this problem, we proposed
an automatic CT segmentation method based on weakly supervised learning, by
which one could train an accurate segmentation model only with weak annotations
in the form of bounding boxes. The proposed method is composed of two steps: 1)
generating pseudo masks with bounding box annotations by k-means clustering,
and 2) iteratively training a 3D U-Net convolutional neural network as a
segmentation model. Some data pre-processing methods are used to improve
performance. The method was validated on four datasets containing three types
of organs with a total of 627 CT volumes. For liver, spleen and kidney
segmentation, it achieved an accuracy of 95.19%, 92.11%, and 91.45%,
respectively. Experimental results demonstrate that our method is accurate,
efficient, and suitable for clinical use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethink Transfer Learning in Medical Image Classification. (arXiv:2106.05152v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1">Le Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1">Hengyue Liang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Taihui Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Ju Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05152">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning (TL) with deep convolutional neural networks (DCNNs) has
proved successful in medical image classification (MIC). However, the current
practice is puzzling, as MIC typically relies only on low- and/or mid-level
features that are learned in the bottom layers of DCNNs. Following this
intuition, we question the current strategies of TL in MIC. In this paper, we
perform careful experimental comparisons between shallow and deep networks for
classification on two chest x-ray datasets, using different TL strategies. We
find that deep models are not always favorable, and finetuning truncated deep
models almost always yields the best performance, especially in data-poor
regimes.

Project webpage:
https://github.com/sun-umn/Transfer-Learning-in-Medical-Imaging

Keywords: Transfer learning, Medical image classification, Feature hierarchy,
Medical imaging, Evaluation metrics, Imbalanced data</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An ordinal CNN approach for the assessment of neurological damage in Parkinson&#x27;s disease patients. (arXiv:2106.05230v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbero_Gomez_J/0/1/0/all/0/1">Javier Barbero-G&#xf3;mez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1">Pedro-Antonio Guti&#xe9;rrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_V/0/1/0/all/0/1">V&#xed;ctor-Manuel Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallejo_Casas_J/0/1/0/all/0/1">Juan-Antonio Vallejo-Casas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hervas_Martinez_C/0/1/0/all/0/1">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05230">
                                    <div class="article-summary-box-inner">
                                        <span>3D image scans are an assessment tool for neurological damage in Parkinson&#x27;s
disease (PD) patients. This diagnosis process can be automatized to help
medical staff through Decision Support Systems (DSSs), and Convolutional Neural
Networks (CNNs) are good candidates, because they are effective when applied to
spatial data. This paper proposes a 3D CNN ordinal model for assessing the
level or neurological damage in PD patients. Given that CNNs need large
datasets to achieve acceptable performance, a data augmentation method is
adapted to work with spatial data. We consider the Ordinal Graph-based
Oversampling via Shortest Paths (OGO-SP) method, which applies a gamma
probability distribution for inter-class data generation. A modification of
OGO-SP is proposed, the OGO-SP-$\beta$ algorithm, which applies the beta
distribution for generating synthetic samples in the inter-class region, a
better suited distribution when compared to gamma. The evaluation of the
different methods is based on a novel 3D image dataset provided by the Hospital
Universitario &#x27;Reina Sof\&#x27;ia&#x27; (C\&#x27;ordoba, Spain). We show how the ordinal
methodology improves the performance with respect to the nominal one, and how
OGO-SP-$\beta$ yields better performance than OGO-SP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Royer_A/0/1/0/all/0/1">Am&#xe9;lie Royer</a>, <a href="http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1">Larisa Markeeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1">Rohan Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05237">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing discrepancy in computer vision between large-scale models
that achieve state-of-the-art performance and models that are affordable in
practical applications. In this paper we address this issue and significantly
bridge the gap between these two types of models. Throughout our empirical
investigation we do not aim to necessarily propose a new method, but strive to
identify a robust and effective recipe for making state-of-the-art large scale
models affordable in practice. We demonstrate that, when performed correctly,
knowledge distillation can be a powerful tool for reducing the size of large
models without compromising their performance. In particular, we uncover that
there are certain implicit design choices, which may drastically affect the
effectiveness of distillation. Our key contribution is the explicit
identification of these design choices, which were not previously articulated
in the literature. We back up our findings by a comprehensive empirical study,
demonstrate compelling results on a wide range of vision datasets and, in
particular, obtain a state-of-the-art ResNet-50 model for ImageNet, which
achieves 82.8\% top-1 accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Salient Positions based Attention Network for Image Classification. (arXiv:2106.04996v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1">Sheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kaiyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhe Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04996">
                                    <div class="article-summary-box-inner">
                                        <span>The self-attention mechanism has attracted wide publicity for its most
important advantage of modeling long dependency, and its variations in computer
vision tasks, the non-local block tries to model the global dependency of the
input feature maps. Gathering global contextual information will inevitably
need a tremendous amount of memory and computing resources, which has been
extensively studied in the past several years. However, there is a further
problem with the self-attention scheme: is all information gathered from the
global scope helpful for the contextual modelling? To our knowledge, few
studies have focused on the problem. Aimed at both questions this paper
proposes the salient positions-based attention scheme SPANet, which is inspired
by some interesting observations on the attention maps and affinity matrices
generated in self-attention scheme. We believe these observations are
beneficial for better understanding of the self-attention. SPANet uses the
salient positions selection algorithm to select only a limited amount of
salient points to attend in the attention map computing. This approach will not
only spare a lot of memory and computing resources, but also try to distill the
positive information from the transformation of the input feature maps. In the
implementation, considering the feature maps with channel high dimensions,
which are completely different from the general visual image, we take the
squared power of the feature maps along the channel dimension as the saliency
metric of the positions. In general, different from the non-local block method,
SPANet models the contextual information using only the selected positions
instead of all, along the channel dimension instead of space dimension. Our
source code is available at https://github.com/likyoo/SPANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding inductive biases in natural images:invariance stems from variations in data. (arXiv:2106.05121v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bouchacourt_D/0/1/0/all/0/1">Diane Bouchacourt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ibrahim_M/0/1/0/all/0/1">Mark Ibrahim</a>, <a href="http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1">Ari S. Morcos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05121">
                                    <div class="article-summary-box-inner">
                                        <span>To perform well on unseen and potentially out-of-distribution samples, it is
desirable for machine learning models to have a predictable response with
respect to transformations affecting the factors of variation of the input.
Invariance is commonly achieved through hand-engineered data augmentation, but
do standard data augmentations address transformations that explain variations
in real data? While prior work has focused on synthetic data, we attempt here
to characterize the factors of variation in a real dataset, ImageNet, and study
the invariance of both standard residual networks and the recently proposed
vision transformer with respect to changes in these factors. We show standard
augmentation relies on a precise combination of translation and scale, with
translation recapturing most of the performance improvement -- despite the
(approximate) translation invariance built in to convolutional architectures,
such as residual networks. In fact, we found that scale and translation
invariance was similar across residual networks and vision transformer models
despite their markedly different inductive biases. We show the training data
itself is the main source of invariance, and that data augmentation only
further increases the learned invariances. Interestingly, the invariances
brought from the training process align with the ImageNet factors of variation
we found. Finally, we find that the main factors of variation in ImageNet
mostly relate to appearance and are specific to each class.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. (arXiv:2106.05001v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Mi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dapeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05001">
                                    <div class="article-summary-box-inner">
                                        <span>A central challenge in training classification models in the real-world
federated system is learning with non-IID data. To cope with this, most of the
existing works involve enforcing regularization in local optimization or
improving the model aggregation scheme at the server. Other works also share
public datasets or synthesized samples to supplement the training of
under-represented classes or introduce a certain level of personalization.
Though effective, they lack a deep understanding of how the data heterogeneity
affects each layer of a deep classification model. In this paper, we bridge
this gap by performing an experimental analysis of the representations learned
by different layers. Our observations are surprising: (1) there exists a
greater bias in the classifier than other layers, and (2) the classification
performance can be significantly improved by post-calibrating the classifier
after federated training. Motivated by the above findings, we propose a novel
and simple algorithm called Classifier Calibration with Virtual Representations
(CCVR), which adjusts the classifier using virtual representations sampled from
an approximated gaussian mixture model. Experimental results demonstrate that
CCVR achieves state-of-the-art performance on popular federated learning
benchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple
yet effective method can shed some light on the future research of federated
learning with non-IID data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1">David Berthelot</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1">Rebecca Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1">Kihyuk Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1">Alex Kurakin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04732">
                                    <div class="article-summary-box-inner">
                                        <span>We extend semi-supervised learning to the problem of domain adaptation to
learn significantly higher-accuracy models that train on one data distribution
and test on a different one. With the goal of generality, we introduce
AdaMatch, a method that unifies the tasks of unsupervised domain adaptation
(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation
(SSDA). In an extensive experimental study, we compare its behavior with
respective state-of-the-art techniques from SSL, SSDA, and UDA on vision
classification tasks. We find AdaMatch either matches or significantly exceeds
the state-of-the-art in each case using the same hyper-parameters regardless of
the dataset or task. For example, AdaMatch nearly doubles the accuracy compared
to that of the prior state-of-the-art on the UDA task for DomainNet and even
exceeds the accuracy of the prior state-of-the-art obtained with pre-training
by 6.4% when AdaMatch is trained completely from scratch. Furthermore, by
providing AdaMatch with just one labeled example per class from the target
domain (i.e., the SSDA setting), we increase the target accuracy by an
additional 6.1%, and with 5 labeled examples, by 13.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tracking by Joint Local and Global Search: A Target-aware Attention based Approach. (arXiv:2106.04840v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Bin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaowei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonghong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04840">
                                    <div class="article-summary-box-inner">
                                        <span>Tracking-by-detection is a very popular framework for single object tracking
which attempts to search the target object within a local search window for
each frame. Although such local search mechanism works well on simple videos,
however, it makes the trackers sensitive to extremely challenging scenarios,
such as heavy occlusion and fast motion. In this paper, we propose a novel and
general target-aware attention mechanism (termed TANet) and integrate it with
tracking-by-detection framework to conduct joint local and global search for
robust tracking. Specifically, we extract the features of target object patch
and continuous video frames, then we concatenate and feed them into a decoder
network to generate target-aware global attention maps. More importantly, we
resort to adversarial training for better attention prediction. The appearance
and motion discriminator networks are designed to ensure its consistency in
spatial and temporal views. In the tracking procedure, we integrate the
target-aware attention with multiple trackers by exploring candidate search
regions for robust tracking. Extensive experiments on both short-term and
long-term tracking benchmark datasets all validated the effectiveness of our
algorithm. The project page of this paper can be found at
\url{https://sites.google.com/view/globalattentiontracking/home/extend}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continuous-discrete multiple target tracking with out-of-sequence measurements. (arXiv:2106.04898v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Garcia_Fernandez_A/0/1/0/all/0/1">&#xc1;ngel F. Garc&#xed;a-Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/eess/1/au:+Yi_W/0/1/0/all/0/1">Wei Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04898">
                                    <div class="article-summary-box-inner">
                                        <span>This paper derives the optimal Bayesian processing of an out-of-sequence
(OOS) set of measurements in continuous-time for multiple target tracking. We
consider a multi-target system modelled in continuous time that is discretised
at the time steps when we receive the measurements, which are distributed
according to the standard point target model. All information about this system
at the sampled time steps is provided by the posterior density on the set of
all trajectories. This density can be computed via the continuous-discrete
trajectory Poisson multi-Bernoulli mixture (TPMBM) filter. When we receive an
OOS measurement, the optimal Bayesian processing performs a retrodiction step
that adds trajectory information at the OOS measurement time stamp followed by
an update step. After the OOS measurement update, the posterior remains in
TPMBM form. We also provide a computationally lighter alternative based on a
trajectory Poisson multi-Bernoulli filter. The effectiveness of the two
approaches to handle OOS measurements is evaluated via simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">It Takes Two to Tango: Mixup for Deep Metric Learning. (arXiv:2106.04990v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1">Shashanka Venkataramanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Psomas_B/0/1/0/all/0/1">Bill Psomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1">Yannis Avrithis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1">Ewa Kijak</a>, <a href="http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1">Laurent Amsaleg</a>, <a href="http://arxiv.org/find/cs/1/au:+Karantzalos_K/0/1/0/all/0/1">Konstantinos Karantzalos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04990">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning involves learning a discriminative representation such that
embeddings of similar classes are encouraged to be close, while embeddings of
dissimilar classes are pushed far apart. State-of-the-art methods focus mostly
on sophisticated loss functions or mining strategies. On the one hand, metric
learning losses consider two or more examples at a time. On the other hand,
modern data augmentation methods for classification consider two or more
examples at a time. The combination of the two ideas is under-studied.

In this work, we aim to bridge this gap and improve representations using
mixup, which is a powerful data augmentation approach interpolating two or more
examples and corresponding target labels at a time. This task is challenging
because, unlike classification, the loss functions used in metric learning are
not additive over examples, so the idea of interpolating target labels is not
straightforward. To the best of our knowledge, we are the first to investigate
mixing examples and target labels for deep metric learning. We develop a
generalized formulation that encompasses existing metric learning loss
functions and modify it to accommodate for mixup, introducing Metric Mix, or
Metrix. We show that mixing inputs, intermediate representations or embeddings
along with target labels significantly improves representations and outperforms
state-of-the-art metric learning methods on four benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Learned Symmetries in Group Equivariant Convolutions. (arXiv:2106.04914v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lengyel_A/0/1/0/all/0/1">Attila Lengyel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan C. van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04914">
                                    <div class="article-summary-box-inner">
                                        <span>Group Equivariant Convolutions (GConvs) enable convolutional neural networks
to be equivariant to various transformation groups, but at an additional
parameter and compute cost. We investigate the filter parameters learned by
GConvs and find certain conditions under which they become highly redundant. We
show that GConvs can be efficiently decomposed into depthwise separable
convolutions while preserving equivariance properties and demonstrate improved
performance and data efficiency on two datasets. All code is publicly available
at github.com/Attila94/SepGrouPy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHARP: Shape-Aware Reconstruction of People In Loose Clothing. (arXiv:2106.04778v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jinka_S/0/1/0/all/0/1">Sai Sagar Jinka</a>, <a href="http://arxiv.org/find/cs/1/au:+Chacko_R/0/1/0/all/0/1">Rohan Chacko</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1">Astitva Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Avinash Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1">P.J. Narayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04778">
                                    <div class="article-summary-box-inner">
                                        <span>3D human body reconstruction from monocular images is an interesting and
ill-posed problem in computer vision with wider applications in multiple
domains. In this paper, we propose SHARP, a novel end-to-end trainable network
that accurately recovers the detailed geometry and appearance of 3D people in
loose clothing from a monocular image. We propose a sparse and efficient fusion
of a parametric body prior with a non-parametric peeled depth map
representation of clothed models. The parametric body prior constraints our
model in two ways: first, the network retains geometrically consistent body
parts that are not occluded by clothing, and second, it provides a body shape
context that improves prediction of the peeled depth maps. This enables SHARP
to recover fine-grained 3D geometrical details with just L1 losses on the 2D
maps, given an input image. We evaluate SHARP on publicly available Cloth3D and
THuman datasets and report superior performance to state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Dual-Stream Neural Network for Sequential Whole-Body PET Segmentation. (arXiv:2106.04961v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liang_K/0/1/0/all/0/1">Kai-Chieh Liang</a>, <a href="http://arxiv.org/find/eess/1/au:+Bi_L/0/1/0/all/0/1">Lei Bi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Ashnil Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Fulham_M/0/1/0/all/0/1">Michael Fulham</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1">Jinman Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04961">
                                    <div class="article-summary-box-inner">
                                        <span>Sequential whole-body 18F-Fluorodeoxyglucose (FDG) positron emission
tomography (PET) scans are regarded as the imaging modality of choice for the
assessment of treatment response in the lymphomas because they detect treatment
response when there may not be changes on anatomical imaging. Any computerized
analysis of lymphomas in whole-body PET requires automatic segmentation of the
studies so that sites of disease can be quantitatively monitored over time.
State-of-the-art PET image segmentation methods are based on convolutional
neural networks (CNNs) given their ability to leverage annotated datasets to
derive high-level features about the disease process. Such methods, however,
focus on PET images from a single time-point and discard information from other
scans or are targeted towards specific organs and cannot cater for the multiple
structures in whole-body PET images. In this study, we propose a
spatio-temporal &#x27;dual-stream&#x27; neural network (ST-DSNN) to segment sequential
whole-body PET scans. Our ST-DSNN learns and accumulates image features from
the PET images done over time. The accumulated image features are used to
enhance the organs / structures that are consistent over time to allow easier
identification of sites of active lymphoma. Our results show that our method
outperforms the state-of-the-art PET image segmentation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zihang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingxing Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04803">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have attracted increasing interests in computer vision, but they
still fall behind state-of-the-art convolutional networks. In this work, we
show that while Transformers tend to have larger model capacity, their
generalization can be worse than convolutional networks due to the lack of the
right inductive bias. To effectively combine the strengths from both
architectures, we present CoAtNets(pronounced &quot;coat&quot; nets), a family of hybrid
models built from two key insights:(1) depthwise Convolution and self-Attention
can be naturally unified via simple relative attention; (2) vertically stacking
convolution layers and attention layers in a principled way is surprisingly
effective in improving generalization, capacity and efficiency. Experiments
show that our CoAtNets achieve state-of-the-art performance under different
resource constraints across various datasets. For example, CoAtNet achieves
86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT
data, outperforming prior arts of both convolutional networks and Transformers.
Notably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet
achieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images
from JFT while using 23x less data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1">Ashkan Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1">Kiran Garimella</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1">Devin Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04726">
                                    <div class="article-summary-box-inner">
                                        <span>WhatsApp is a popular chat application used by over 2 billion users
worldwide. However, due to end-to-end encryption, there is currently no easy
way to fact-check content on WhatsApp at scale. In this paper, we analyze the
usefulness of a crowd-sourced system on WhatsApp through which users can submit
&quot;tips&quot; containing messages they want fact-checked. We compare the tips sent to
a WhatsApp tipline run during the 2019 Indian national elections with the
messages circulating in large, public groups on WhatsApp and other social media
platforms during the same period. We find that tiplines are a very useful lens
into WhatsApp conversations: a significant fraction of messages and images sent
to the tipline match with the content being shared on public WhatsApp groups
and other social media. Our analysis also shows that tiplines cover the most
popular content well, and a majority of such content is often shared to the
tipline before appearing in large, public WhatsApp groups. Overall, the
analysis suggests tiplines can be an effective source for discovering content
to fact-check.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densely connected normalizing flows. (arXiv:2106.04627v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1">Matej Grci&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1">Ivan Grubi&#x161;i&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1">Sini&#x161;a &#x160;egvi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04627">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are bijective mappings between inputs and latent
representations with a fully factorized distribution. They are very attractive
due to exact likelihood evaluation and efficient sampling. However, their
effective capacity is often insufficient since the bijectivity constraint
limits the model width. We address this issue by incrementally padding
intermediate representations with noise. We precondition the noise in
accordance with previous invertible units, which we describe as cross-unit
coupling. Our invertible glow-like modules express intra-unit affine coupling
as a fusion of a densely connected block and Nystr\&quot;om self-attention. We refer
to our architecture as DenseFlow since both cross-unit and intra-unit couplings
rely on dense connectivity. Experiments show significant improvements due to
the proposed contributions, and reveal state-of-the-art density estimation
among all generative models under moderate computing budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Tiny Network for Recognition-Oriented Face Image Quality Assessment. (arXiv:2106.04852v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Baoyun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Min Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Heng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhaoning Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04852">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition has made significant progress in recent years due to deep
convolutional neural networks (CNN). In many face recognition (FR) scenarios,
face images are acquired from a sequence with huge intra-variations. These
intra-variations, which are mainly affected by the low-quality face images,
cause instability of recognition performance. Previous works have focused on
ad-hoc methods to select frames from a video or use face image quality
assessment (FIQA) methods, which consider only a particular or combination of
several distortions.

In this work, we present an efficient non-reference image quality assessment
for FR that directly links image quality assessment (IQA) and FR. More
specifically, we propose a new measurement to evaluate image quality without
any reference. Based on the proposed quality measurement, we propose a deep
Tiny Face Quality network (tinyFQnet) to learn a quality prediction function
from data.

We evaluate the proposed method for different powerful FR models on two
classical video-based (or template-based) benchmark: IJB-B and YTF. Extensive
experiments show that, although the tinyFQnet is much smaller than the others,
the proposed method outperforms state-of-the-art quality assessment methods in
terms of effectiveness and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Computational Ghost Imaging using Unpaired Deep Learning and a Constrained Generative Adversarial Network. (arXiv:2106.04822v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Alishahi_F/0/1/0/all/0/1">Fatemeh Alishahi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mohajerin_Ariaei_A/0/1/0/all/0/1">Amirhossein Mohajerin-Ariaei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04822">
                                    <div class="article-summary-box-inner">
                                        <span>The unpaired training can be the only option available for fast deep
learning-based ghost imaging, where obtaining a high signal-to-noise ratio
(SNR) image copy of each low SNR ghost image could be practically
time-consuming and challenging. This paper explores the capabilities of deep
learning to leverage computational ghost imaging when there is a lack of paired
training images. The deep learning approach proposed here enables fast ghost
imaging through reconstruction of high SNR images from faint and hastily shot
ghost images using a constrained Wasserstein generative adversarial network. In
the proposed approach, the objective function is regularized to enforce the
generation of faithful and relevant high SNR images to the ghost copies. This
regularization measures the distance between reconstructed images and the faint
ghost images in a low-noise manifold generated by a shadow network. The
performance of the constrained network is shown to be particularly important
for ghost images with low SNR. The proposed pipeline is able to reconstruct
high-quality images from the ghost images with SNR values not necessarily equal
to the SNR of the training set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Check It Again: Progressive Visual Question Answering via Visual Entailment. (arXiv:2106.04605v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1">Qingyi Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Mingyu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1">Peng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04605">
                                    <div class="article-summary-box-inner">
                                        <span>While sophisticated Visual Question Answering models have achieved remarkable
success, they tend to answer questions only according to superficial
correlations between question and answer. Several recent approaches have been
developed to address this language priors problem. However, most of them
predict the correct answer according to one best output without checking the
authenticity of answers. Besides, they only explore the interaction between
image and question, ignoring the semantics of candidate answers. In this paper,
we propose a select-and-rerank (SAR) progressive framework based on Visual
Entailment. Specifically, we first select the candidate answers relevant to the
question or the image, then we rerank the candidate answers by a visual
entailment task, which verifies whether the image semantically entails the
synthetic statement of the question and each candidate answer. Experimental
results show the effectiveness of our proposed framework, which establishes a
new state-of-the-art accuracy on VQA-CP v2 with a 7.55% improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ex uno plures: Splitting One Model into an Ensemble of Subnetworks. (arXiv:2106.04767v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhilu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1">Vianne R. Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1">Mert R. Sabuncu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04767">
                                    <div class="article-summary-box-inner">
                                        <span>Monte Carlo (MC) dropout is a simple and efficient ensembling method that can
improve the accuracy and confidence calibration of high-capacity deep neural
network models. However, MC dropout is not as effective as more
compute-intensive methods such as deep ensembles. This performance gap can be
attributed to the relatively poor quality of individual models in the MC
dropout ensemble and their lack of diversity. These issues can in turn be
traced back to the coupled training and substantial parameter sharing of the
dropout models. Motivated by this perspective, we propose a strategy to compute
an ensemble of subnetworks, each corresponding to a non-overlapping dropout
mask computed via a pruning strategy and trained independently. We show that
the proposed subnetwork ensembling method can perform as well as standard deep
ensembles in both accuracy and uncertainty estimates, yet with a computational
efficiency similar to MC dropout. Lastly, using several computer vision
datasets like CIFAR10/100, CUB200, and Tiny-Imagenet, we experimentally
demonstrate that subnetwork ensembling also consistently outperforms recently
proposed approaches that efficiently ensemble neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point Cloud Upsampling via Disentangled Refinement. (arXiv:2106.04779v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruihui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xianzhi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng-Ann Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chi-Wing Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04779">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds produced by 3D scanning are often sparse, non-uniform, and
noisy. Recent upsampling approaches aim to generate a dense point set, while
achieving both distribution uniformity and proximity-to-surface, and possibly
amending small holes, all in a single network. After revisiting the task, we
propose to disentangle the task based on its multi-objective nature and
formulate two cascaded sub-networks, a dense generator and a spatial refiner.
The dense generator infers a coarse but dense output that roughly describes the
underlying surface, while the spatial refiner further fine-tunes the coarse
output by adjusting the location of each point. Specifically, we design a pair
of local and global refinement units in the spatial refiner to evolve a coarse
feature map. Also, in the spatial refiner, we regress a per-point offset vector
to further adjust the coarse outputs in fine-scale. Extensive qualitative and
quantitative results on both synthetic and real-scanned datasets demonstrate
the superiority of our method over the state-of-the-arts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncovering Closed-form Governing Equations of Nonlinear Dynamics from Videos. (arXiv:2106.04776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luan_L/0/1/0/all/0/1">Lele Luan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04776">
                                    <div class="article-summary-box-inner">
                                        <span>Distilling analytical models from data has the potential to advance our
understanding and prediction of nonlinear dynamics. Although discovery of
governing equations based on observed system states (e.g., trajectory time
series) has revealed success in a wide range of nonlinear dynamics, uncovering
the closed-form equations directly from raw videos still remains an open
challenge. To this end, we introduce a novel end-to-end unsupervised deep
learning framework to uncover the mathematical structure of equations that
governs the dynamics of moving objects in videos. Such an architecture consists
of (1) an encoder-decoder network that learns low-dimensional spatial/pixel
coordinates of the moving object, (2) a learnable Spatial-Physical
Transformation component that creates mapping between the extracted
spatial/pixel coordinates and the latent physical states of dynamics, and (3) a
numerical integrator-based sparse regression module that uncovers the
parsimonious closed-form governing equations of learned physical states and,
meanwhile, serves as a constraint to the autoencoder. The efficacy of the
proposed method is demonstrated by uncovering the governing equations of a
variety of nonlinear dynamical systems depicted by moving objects in videos.
The resulting computational framework enables discovery of parsimonious
interpretable model in a flexible and accessible sensing environment where only
videos are available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Neural Architecture Search via Proxy Data. (arXiv:2106.04784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1">Byunggook Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1">Jisoo Mok</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1">Hyeokjun Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04784">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the increasing interest in neural architecture search (NAS), the
significant computational cost of NAS is a hindrance to researchers. Hence, we
propose to reduce the cost of NAS using proxy data, i.e., a representative
subset of the target data, without sacrificing search performance. Even though
data selection has been used across various fields, our evaluation of existing
selection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that
they are not always appropriate for NAS and a new selection method is
necessary. By analyzing proxy data constructed using various selection methods
through data entropy, we propose a novel proxy data selection method tailored
for NAS. To empirically demonstrate the effectiveness, we conduct thorough
experiments across diverse datasets, search spaces, and NAS algorithms.
Consequently, NAS algorithms with the proposed selection discover architectures
that are competitive with those obtained using the entire dataset. It
significantly reduces the search cost: executing DARTS with the proposed
selection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a
single GPU. Additionally, when the architecture searched on ImageNet using the
proposed selection is inversely transferred to CIFAR-10, a state-of-the-art
test error of 2.4\% is yielded. Our code is available at
https://github.com/nabk89/NAS-with-Proxy-data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices. (arXiv:2106.04723v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1">Stylianos I. Venieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1">Ioannis Panopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1">Iakovos S. Venieris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04723">
                                    <div class="article-summary-box-inner">
                                        <span>Radical progress in the field of deep learning (DL) has led to unprecedented
accuracy in diverse inference tasks. As such, deploying DL models across mobile
platforms is vital to enable the development and broad availability of the
next-generation intelligent apps. Nevertheless, the wide and optimised
deployment of DL models is currently hindered by the vast system heterogeneity
of mobile devices, the varying computational cost of different DL models and
the variability of performance needs across DL applications. This paper
proposes OODIn, a framework for the optimised deployment of DL apps across
heterogeneous mobile devices. OODIn comprises a novel DL-specific software
architecture together with an analytical framework for modelling DL
applications that: (1) counteract the variability in device resources and DL
models by means of a highly parametrised multi-layer design; and (2) perform a
principled optimisation of both model- and system-level parameters through a
multi-objective formulation, designed for DL inference apps, in order to adapt
the deployment to the user-specified performance requirements and device
capabilities. Quantitative evaluation shows that the proposed framework
consistently outperforms status-quo designs across heterogeneous devices and
delivers up to 4.3x and 3.5x performance gain over highly optimised platform-
and model-aware designs respectively, while effectively adapting execution to
dynamic changes in resource availability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TED-net: Convolution-free T2T Vision Transformer-based Encoder-decoder Dilation network for Low-dose CT Denoising. (arXiv:2106.04650v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1">Dayang Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_Z/0/1/0/all/0/1">Zhan Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_H/0/1/0/all/0/1">Hengyong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04650">
                                    <div class="article-summary-box-inner">
                                        <span>Low dose computed tomography is a mainstream for clinical applications.
How-ever, compared to normal dose CT, in the low dose CT (LDCT) images, there
are stronger noise and more artifacts which are obstacles for practical
applications. In the last few years, convolution-based end-to-end deep learning
methods have been widely used for LDCT image denoising. Recently, transformer
has shown superior performance over convolution with more feature interactions.
Yet its ap-plications in LDCT denoising have not been fully cultivated. Here,
we propose a convolution-free T2T vision transformer-based Encoder-decoder
Dilation net-work (TED-net) to enrich the family of LDCT denoising algorithms.
The model is free of convolution blocks and consists of a symmetric
encoder-decoder block with sole transformer. Our model is evaluated on the
AAPM-Mayo clinic LDCT Grand Challenge dataset, and results show outperformance
over the state-of-the-art denoising methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes. (arXiv:2012.14210v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1">Nils Reimers</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14210">
                                    <div class="article-summary-box-inner">
                                        <span>Information Retrieval using dense low-dimensional representations recently
became popular and showed out-performance to traditional sparse-representations
like BM25. However, no previous work investigated how dense representations
perform with large index sizes. We show theoretically and empirically that the
performance for dense representations decreases quicker than sparse
representations for increasing index sizes. In extreme cases, this can even
lead to a tipping point where at a certain index size sparse representations
outperform dense representations. We show that this behavior is tightly
connected to the number of dimensions of the representations: The lower the
dimension, the higher the chance for false positives, i.e. returning irrelevant
documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qitian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hengrui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiaofeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04833">
                                    <div class="article-summary-box-inner">
                                        <span>Recommendation models can effectively estimate underlying user interests and
predict one&#x27;s future behaviors by factorizing an observed user-item rating
matrix into products of two sets of latent factors. However, the user-specific
embedding factors can only be learned in a transductive way, making it
difficult to handle new users on-the-fly. In this paper, we propose an
inductive collaborative filtering framework that contains two representation
models. The first model follows conventional matrix factorization which
factorizes a group of key users&#x27; rating matrix to obtain meta latents. The
second model resorts to attention-based structure learning that estimates
hidden relations from query to key users and learns to leverage meta latents to
inductively compute embeddings for query users via neural message passing. Our
model enables inductive representation learning for users and meanwhile
guarantees equivalent representation capacity as matrix factorization.
Experiments demonstrate that our model achieves promising results for
recommendation on few-shot users with limited training ratings and new unseen
users which are commonly encountered in open-world recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Balancing Reinforcement Learning Training Experiences in Interactive Information Retrieval. (arXiv:2006.03185v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Limin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03185">
                                    <div class="article-summary-box-inner">
                                        <span>Interactive Information Retrieval (IIR) and Reinforcement Learning (RL) share
many commonalities, including an agent who learns while interacts, a long-term
and complex goal, and an algorithm that explores and adapts. To successfully
apply RL methods to IIR, one challenge is to obtain sufficient relevance labels
to train the RL agents, which are infamously known as sample inefficient.
However, in a text corpus annotated for a given query, it is not the relevant
documents but the irrelevant documents that predominate. This would cause very
unbalanced training experiences for the agent and prevent it from learning any
policy that is effective. Our paper addresses this issue by using domain
randomization to synthesize more relevant documents for the training. Our
experimental results on the Text REtrieval Conference (TREC) Dynamic Domain
(DD) 2017 Track show that the proposed method is able to boost an RL agent&#x27;s
learning effectiveness by 22\% in dealing with unseen situations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepTileBars: Visualizing Term Distribution for Neural Information Retrieval. (arXiv:1811.00606v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.00606">
                                    <div class="article-summary-box-inner">
                                        <span>Most neural Information Retrieval (Neu-IR) models derive query-to-document
ranking scores based on term-level matching. Inspired by TileBars, a classical
term distribution visualization method, in this paper, we propose a novel
Neu-IR model that handles query-to-document matching at the subtopic and higher
levels. Our system first splits the documents into topical segments,
&quot;visualizes&quot; the matchings between the query and the segments, and then feeds
an interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final
ranking scores. DeepTileBars models the relevance signals occurring at
different granularities in a document&#x27;s topic hierarchy. It better captures the
discourse structure of a document and thus the matching patterns. Although its
design and implementation are light-weight, DeepTileBars outperforms other
state-of-the-art Neu-IR models on benchmark datasets including the Text
REtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Context Enhanced Graph Neural Networks for Session-based Recommendation. (arXiv:2106.05081v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1">Gao Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiao-Li Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xian-Ling Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_M/0/1/0/all/0/1">Minghui Qiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05081">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based recommendation (SBR) is a challenging task, which aims at
recommending items based on anonymous behavior sequences. Almost all the
existing solutions for SBR model user preference only based on the current
session without exploiting the other sessions, which may contain both relevant
and irrelevant item-transitions to the current session. This paper proposes a
novel approach, called Global Context Enhanced Graph Neural Networks (GCE-GNN)
to exploit item transitions over all sessions in a more subtle manner for
better inferring the user preference of the current session. Specifically,
GCE-GNN learns two levels of item embeddings from session graph and global
graph, respectively: (i) Session graph, which is to learn the session-level
item embedding by modeling pairwise item-transitions within the current
session; and (ii) Global graph, which is to learn the global-level item
embedding by modeling pairwise item-transitions over all sessions. In GCE-GNN,
we propose a novel global-level item representation learning layer, which
employs a session-aware attention mechanism to recursively incorporate the
neighbors&#x27; embeddings of each node on the global graph. We also design a
session-level item representation learning layer, which employs a GNN on the
session graph to learn session-level item embeddings within the current
session. Moreover, GCE-GNN aggregates the learnt item representations in the
two levels with a soft attention mechanism. Experiments on three benchmark
datasets demonstrate that GCE-GNN outperforms the state-of-the-art methods
consistently.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoFT: Automatic Fine-Tune for Parameters Transfer Learning in Click-Through Rate Prediction. (arXiv:2106.04873v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiangli Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1">Rong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Ruiming Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhirong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiuqiang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04873">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems are often asked to serve multiple recommendation
scenarios or domains. Fine-tuning a pre-trained CTR model from source domains
and adapting it to a target domain allows knowledge transferring. However,
optimizing all the parameters of the pre-trained network may result in
over-fitting if the target dataset is small and the number of parameters is
large. This leads us to think of directly reusing parameters in the pre-trained
model which represent more general features learned from multiple domains.
However, the design of freezing or fine-tuning layers of parameters requires
much manual effort since the decision highly depends on the pre-trained model
and target instances. In this work, we propose an end-to-end transfer learning
framework, called Automatic Fine-Tuning (AutoFT), for CTR prediction. AutoFT
consists of a field-wise transfer policy and a layer-wise transfer policy. The
field-wise transfer policy decides how the pre-trained embedding
representations are frozen or fine-tuned based on the given instance from the
target domain. The layer-wise transfer policy decides how the high?order
feature representations are transferred layer by layer. Extensive experiments
on two public benchmark datasets and one private industrial dataset demonstrate
that AutoFT can significantly improve the performance of CTR prediction
compared with state-of-the-art transferring approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Corpus-Level End-to-End Exploration for Interactive Systems. (arXiv:1912.00753v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00753">
                                    <div class="article-summary-box-inner">
                                        <span>A core interest in building Artificial Intelligence (AI) agents is to let
them interact with and assist humans. One example is Dynamic Search (DS), which
models the process that a human works with a search engine agent to accomplish
a complex and goal-oriented task. Early DS agents using Reinforcement Learning
(RL) have only achieved limited success for (1) their lack of direct control
over which documents to return and (2) the difficulty to recover from wrong
search trajectories. In this paper, we present a novel corpus-level end-to-end
exploration (CE3) method to address these issues. In our method, an entire text
corpus is compressed into a global low-dimensional representation, which
enables the agent to gain access to the full state and action spaces, including
the under-explored areas. We also propose a new form of retrieval function,
whose linear approximation allows end-to-end manipulation of documents.
Experiments on the Text REtrieval Conference (TREC) Dynamic Domain (DD) Track
show that CE3 outperforms the state-of-the-art DS systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Server Private Linear Transformation: The Individual Privacy Case. (arXiv:2106.05222v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1">Anoosheh Heidarzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1">Nahid Esmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1">Alex Sprintson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05222">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers the single-server Private Linear Transformation (PLT)
problem with individual privacy guarantees. In this problem, there is a user
that wishes to obtain $L$ independent linear combinations of a $D$-subset of
messages belonging to a dataset of $K$ messages stored on a single server. The
goal is to minimize the download cost while keeping the identity of each
message required for the computation individually private. The individual
privacy requirement ensures that the identity of each individual message
required for the computation is kept private. This is in contrast to the
stricter notion of joint privacy that protects the entire set of identities of
all messages used for the computation, including the correlations between these
identities. The notion of individual privacy captures a broad set of practical
applications. For example, such notion is relevant when the dataset contains
information about individuals, each of them requires privacy guarantees for
their data access patterns. We focus on the setting in which the required
linear transformation is associated with a maximum distance separable (MDS)
matrix. In particular, we require that the matrix of coefficients pertaining to
the required linear combinations is the generator matrix of an MDS code. We
establish lower and upper bounds on the capacity of PLT with individual
privacy, where the capacity is defined as the supremum of all achievable
download rates. We show that our bounds are tight under certain conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIGRAC: Digraph Clustering with Flow Imbalance. (arXiv:2106.05194v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1">Yixuan He</a>, <a href="http://arxiv.org/find/stat/1/au:+Reinert_G/0/1/0/all/0/1">Gesine Reinert</a>, <a href="http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05194">
                                    <div class="article-summary-box-inner">
                                        <span>Node clustering is a powerful tool in the analysis of networks. Here, we
introduce a graph neural network framework with a novel scalable Directed Mixed
Path Aggregation(DIMPA) scheme to obtain node embeddings for directed networks
in a self-supervised manner, including a novel probabilistic imbalance loss.
The method is end-to-end in combining embedding generation and clustering
without an intermediate step. In contrast to standard approaches in the
literature, in this paper, directionality is not treated as a nuisance, but
rather contains the main signal. In particular, we leverage the recently
introduced cut flow imbalance measure, which is tightly related to
directionality; cut flow imbalance is optimized without resorting to spectral
methods or cluster labels. Experimental results on synthetic data, in the form
of directed stochastic block models and real-world data at different scales,
demonstrate that our method attains state-of-the-art results on directed
clustering, for a wide range of noise and sparsity levels, as well as graph
structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Helping results assessment by adding explainable elements to the deep relevance matching model. (arXiv:2106.05147v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chios_I/0/1/0/all/0/1">Ioannis Chios</a>, <a href="http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1">Suzan Verberne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05147">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we address the explainability of web search engines. We propose
two explainable elements on the search engine result page: a visualization of
query term weights and a visualization of passage relevance. The idea is that
search engines that indicate to the user why results are retrieved are valued
higher by users and gain user trust. We deduce the query term weights from the
term gating network in the Deep Relevance Matching Model (DRMM) and visualize
them as a doughnut chart. In addition, we train a passage-level ranker with
DRMM that selects the most relevant passage from each document and shows it as
snippet on the result page. Next to the snippet we show a document thumbnail
with this passage highlighted. We evaluate the proposed interface in an online
user study, asking users to judge the explainability and assessability of the
interface. We found that users judge our proposed interface significantly more
explainable and easier to assess than a regular search engine result page.
However, they are not significantly better in selecting the relevant documents
from the top-5. This indicates that the explainability of the search engine
result page leads to a better user experience. Thus, we conclude that the
proposed explainable elements are promising as visualization for search engine
users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sirius: A Mutual Information Tool for Exploratory Visualization of Mixed Data. (arXiv:2106.05260v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Adams_J/0/1/0/all/0/1">Jane L. Adams</a>, <a href="http://arxiv.org/find/stat/1/au:+Deluca_T/0/1/0/all/0/1">Todd F. Deluca</a>, <a href="http://arxiv.org/find/stat/1/au:+Danforth_C/0/1/0/all/0/1">Christopher M. Danforth</a>, <a href="http://arxiv.org/find/stat/1/au:+Dodds_P/0/1/0/all/0/1">Peter S. Dodds</a>, <a href="http://arxiv.org/find/stat/1/au:+Zheng_Y/0/1/0/all/0/1">Yuhang Zheng</a>, <a href="http://arxiv.org/find/stat/1/au:+Anastasakis_K/0/1/0/all/0/1">Konstantinos Anastasakis</a>, <a href="http://arxiv.org/find/stat/1/au:+Choi_B/0/1/0/all/0/1">Boyoon Choi</a>, <a href="http://arxiv.org/find/stat/1/au:+Min_A/0/1/0/all/0/1">Allison Min</a>, <a href="http://arxiv.org/find/stat/1/au:+Bessey_M/0/1/0/all/0/1">Michael M. Bessey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05260">
                                    <div class="article-summary-box-inner">
                                        <span>Data scientists across disciplines are increasingly in need of exploratory
analysis tools for data sets with a high volume of features. We expand upon
graph mining approaches for exploratory analysis of high-dimensional data to
introduce Sirius, a visualization package for researchers to explore feature
relationships among mixed data types using mutual information and network
backbone sparsification. Visualizations of feature relationships aid data
scientists in finding meaningful dependence among features, which can engender
further analysis for feature selection, feature extraction, projection,
identification of proxy variables, or insight into temporal variation at the
macro scale. Graph mining approaches for feature analysis exist, such as
association networks of binary features, or correlation networks of
quantitative features, but mixed data types present a unique challenge for
developing comprehensive feature networks for exploratory analysis. Using an
information theoretic approach, Sirius supports heterogeneous data sets
consisting of binary, continuous quantitative, and discrete categorical data
types, and provides a user interface exploring feature pairs with high mutual
information scores. We leverage a backbone sparsification approach from network
theory as a dimensionality reduction technique, which probabilistically trims
edges according to the local network context. Sirius is an open source Python
package and Django web application for exploratory visualization, which can be
deployed in data analysis pipelines. The Sirius codebase and exemplary data
sets can be found at: https://github.com/compstorylab/sirius</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Rank Words: Optimizing Ranking Metrics for Word Spotting. (arXiv:2106.05144v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1">Adri&#xe0; Molina</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_L/0/1/0/all/0/1">Lluis Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_Terrades_O/0/1/0/all/0/1">Oriol Ramos-Terrades</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05144">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we explore and evaluate the use of ranking-based objective
functions for learning simultaneously a word string and a word image encoder.
We consider retrieval frameworks in which the user expects a retrieval list
ranked according to a defined relevance score. In the context of a word
spotting problem, the relevance score has been set according to the string edit
distance from the query string. We experimentally demonstrate the competitive
performance of the proposed model on query-by-string word spotting for both,
handwritten and real scene word images. We also provide the results for
query-by-example word spotting, although it is not the main focus of this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Server Private Linear Transformation: The Joint Privacy Case. (arXiv:2106.05220v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1">Anoosheh Heidarzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1">Nahid Esmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1">Alex Sprintson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05220">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the problem of Private Linear Transformation (PLT)
which generalizes the problems of private information retrieval and private
linear computation. The PLT problem includes one or more remote server(s)
storing (identical copies of) $K$ messages and a user who wants to compute $L$
independent linear combinations of a $D$-subset of messages. The objective of
the user is to perform the computation by downloading minimum possible amount
of information from the server(s), while protecting the identities of the $D$
messages required for the computation. In this work, we focus on the
single-server setting of the PLT problem when the identities of the $D$
messages required for the computation must be protected jointly. We consider
two different models, depending on whether the coefficient matrix of the
required $L$ linear combinations generates a Maximum Distance Separable (MDS)
code. We prove that the capacity for both models is given by $L/(K-D+L)$, where
the capacity is defined as the supremum of all achievable download rates. Our
converse proofs are based on linear-algebraic and information-theoretic
arguments that establish connections between PLT schemes and linear codes. We
also present an achievability scheme for each of the models being considered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Extractive Search. (arXiv:2106.04612v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1">Shauli Ravfogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Taub_Tabib_H/0/1/0/all/0/1">Hillel Taub-Tabib</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04612">
                                    <div class="article-summary-box-inner">
                                        <span>Domain experts often need to extract structured information from large
corpora. We advocate for a search paradigm called &#x60;&#x60;extractive search&#x27;&#x27;, in
which a search query is enriched with capture-slots, to allow for such rapid
extraction. Such an extractive search system can be built around syntactic
structures, resulting in high-precision, low-recall results. We show how the
recall can be improved using neural retrieval and alignment. The goals of this
paper are to concisely introduce the extractive-search paradigm; and to
demonstrate a prototype neural retrieval system for extractive search and its
benefits and potential. Our prototype is available at
\url{https://spike.neural-sim.apps.allenai.org/} and a video demonstration is
available at \url{https://vimeo.com/559586687}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Proper initialization is crucial to the optimization and the generalization
of neural networks. However, most existing neural recommendation systems
initialize the user and item embeddings randomly. In this work, we propose a
new initialization scheme for user and item embeddings called Laplacian
Eigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).
LEPORID endows the embeddings with information regarding multi-scale
neighborhood structures on the data manifold and performs adaptive
regularization to compensate for high embedding variance on the tail of the
data distribution. Exploiting matrix sparsity, LEPORID embeddings can be
computed efficiently. We evaluate LEPORID in a wide range of neural
recommendation models. In contrast to the recent surprising finding that the
simple K-nearest-neighbor (KNN) method often outperforms neural recommendation
systems, we show that existing neural systems initialized with LEPORID often
perform on par or better than KNN. To maximize the effects of the
initialization, we propose the Dual-Loss Residual Recommendation (DLR2)
network, which, when initialized with LEPORID, substantially outperforms both
traditional and state-of-the-art neural recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1">Boris N. Oreshkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1">Florent Bocquelet</a>, <a href="http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1">F&#xe9;lix G. Harvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1">Bay Raitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1">Dominic Laflamme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01981">
                                    <div class="article-summary-box-inner">
                                        <span>Our work focuses on the development of a learnable neural representation of
human pose for advanced AI assisted animation tooling. Specifically, we tackle
the problem of constructing a full static human pose based on sparse and
variable user inputs (e.g. locations and/or orientations of a subset of body
joints). To solve this problem, we propose a novel neural architecture that
combines residual connections with prototype encoding of a partially specified
pose to create a new complete pose from the learned latent space. We show that
our architecture outperforms a baseline based on Transformer, both in terms of
accuracy and computational efficiency. Additionally, we develop a user
interface to integrate our neural model in Unity, a real-time 3D development
platform. Furthermore, we introduce two new datasets representing the static
human pose modeling problem, based on high-quality human motion capture data,
which will be released publicly along with model code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network insensitivity to parameter noise via adversarial regularization. (arXiv:2106.05009v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bucher_J/0/1/0/all/0/1">Julian B&#xfc;cher</a>, <a href="http://arxiv.org/find/cs/1/au:+Faber_F/0/1/0/all/0/1">Fynn Faber</a>, <a href="http://arxiv.org/find/cs/1/au:+Muir_D/0/1/0/all/0/1">Dylan R. Muir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05009">
                                    <div class="article-summary-box-inner">
                                        <span>Neuromorphic neural network processors, in the form of compute-in-memory
crossbar arrays of memristors, or in the form of subthreshold analog and
mixed-signal ASICs, promise enormous advantages in compute density and energy
efficiency for NN-based ML tasks. However, these technologies are prone to
computational non-idealities, due to process variation and intrinsic device
physics. This degrades the task performance of networks deployed to the
processor, by introducing parameter noise into the deployed model. While it is
possible to calibrate each device, or train networks individually for each
processor, these approaches are expensive and impractical for commercial
deployment. Alternative methods are therefore needed to train networks that are
inherently robust against parameter variation, as a consequence of network
architecture and parameters. We present a new adversarial network optimisation
algorithm that attacks network parameters during training, and promotes robust
performance during inference in the face of parameter variation. Our approach
introduces a regularization term penalising the susceptibility of a network to
weight perturbation. We compare against previous approaches for producing
parameter insensitivity such as dropout, weight smoothing and introducing
parameter noise during training. We show that our approach produces models that
are more robust to targeted parameter variation, and equally robust to random
parameter variation. Our approach finds minima in flatter locations in the
weight-loss landscape compared with other approaches, highlighting that the
networks found by our technique are less sensitive to parameter perturbation.
Our work provides an approach to deploy neural network architectures to
inference devices that suffer from computational non-idealities, with minimal
loss of performance. ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Ensemble Search for Uncertainty Estimation and Dataset Shift. (arXiv:2006.08573v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaidi_S/0/1/0/all/0/1">Sheheryar Zaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1">Arber Zela</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsken_T/0/1/0/all/0/1">Thomas Elsken</a>, <a href="http://arxiv.org/find/cs/1/au:+Holmes_C/0/1/0/all/0/1">Chris Holmes</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08573">
                                    <div class="article-summary-box-inner">
                                        <span>Ensembles of neural networks achieve superior performance compared to
stand-alone networks in terms of accuracy, uncertainty calibration and
robustness to dataset shift. \emph{Deep ensembles}, a state-of-the-art method
for uncertainty estimation, only ensemble random initializations of a
\emph{fixed} architecture. Instead, we propose two methods for automatically
constructing ensembles with \emph{varying} architectures, which implicitly
trade-off individual architectures&#x27; strengths against the ensemble&#x27;s diversity
and exploit architectural variation as a source of diversity. On a variety of
classification tasks and modern architecture search spaces, we show that the
resulting ensembles outperform deep ensembles not only in terms of accuracy but
also uncertainty calibration and robustness to dataset shift. Our further
analysis and ablation studies provide evidence of higher ensemble diversity due
to architectural variation, resulting in ensembles that can outperform deep
ensembles, even when having weaker average base learners.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PEBBLE: Feedback-Efficient Interactive Reinforcement Learning via Relabeling Experience and Unsupervised Pre-training. (arXiv:2106.05091v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Laura Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05091">
                                    <div class="article-summary-box-inner">
                                        <span>Conveying complex objectives to reinforcement learning (RL) agents can often
be difficult, involving meticulous design of reward functions that are
sufficiently informative yet easy enough to provide. Human-in-the-loop RL
methods allow practitioners to instead interactively teach agents through
tailored feedback; however, such approaches have been challenging to scale
since human feedback is very expensive. In this work, we aim to make this
process more sample- and feedback-efficient. We present an off-policy,
interactive RL algorithm that capitalizes on the strengths of both feedback and
off-policy learning. Specifically, we learn a reward model by actively querying
a teacher&#x27;s preferences between two clips of behavior and use it to train an
agent. To enable off-policy learning, we relabel all the agent&#x27;s past
experience when its reward model changes. We additionally show that
pre-training our agents with unsupervised exploration substantially increases
the mileage of its queries. We demonstrate that our approach is capable of
learning tasks of higher complexity than previously considered by
human-in-the-loop methods, including a variety of locomotion and robotic
manipulation skills. We also show that our method is able to utilize real-time
human feedback to effectively prevent reward exploitation and learn new
behaviors that are difficult to specify with standard reward functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Survival Machines: Fully Parametric Survival Regression and Representation Learning for Censored Data with Competing Risks. (arXiv:2003.01176v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1">Chirag Nagpal</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinyu Rachel Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1">Artur Dubrawski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.01176">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a new approach to estimating relative risks in time-to-event
prediction problems with censored data in a fully parametric manner. Our
approach does not require making strong assumptions of constant proportional
hazard of the underlying survival distribution, as required by the
Cox-proportional hazard model. By jointly learning deep nonlinear
representations of the input covariates, we demonstrate the benefits of our
approach when used to estimate survival risks through extensive experimentation
on multiple real world datasets with different levels of censoring. We further
demonstrate advantages of our model in the competing risks scenario. To the
best of our knowledge, this is the first work involving fully parametric
estimation of survival times with competing risks in the presence of censoring.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polynomial magic! Hermite polynomials for private data generation. (arXiv:2106.05042v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Mijung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinaroz_M/0/1/0/all/0/1">Margarita Vinaroz</a>, <a href="http://arxiv.org/find/cs/1/au:+Charusaie_M/0/1/0/all/0/1">Mohammad-Amin Charusaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Harder_F/0/1/0/all/0/1">Frederik Harder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05042">
                                    <div class="article-summary-box-inner">
                                        <span>Kernel mean embedding is a useful tool to compare probability measures.
Despite its usefulness, kernel mean embedding considers infinite-dimensional
features, which are challenging to handle in the context of differentially
private data generation. A recent work proposes to approximate the kernel mean
embedding of data distribution using finite-dimensional random features, where
the sensitivity of the features becomes analytically tractable. More
importantly, this approach significantly reduces the privacy cost, compared to
other known privatization methods (e.g., DP-SGD), as the approximate kernel
mean embedding of the data distribution is privatized only once and can then be
repeatedly used during training of a generator without incurring any further
privacy cost. However, the required number of random features is excessively
high, often ten thousand to a hundred thousand, which worsens the sensitivity
of the approximate kernel mean embedding. To improve the sensitivity, we
propose to replace random features with Hermite polynomial features. Unlike the
random features, the Hermite polynomial features are ordered, where the
features at the low orders contain more information on the distribution than
those at the high orders. Hence, a relatively low order of Hermite polynomial
features can more accurately approximate the mean embedding of the data
distribution compared to a significantly higher number of random features. As a
result, using the Hermite polynomial features, we significantly improve the
privacy-accuracy trade-off, reflected in the high quality and diversity of the
generated data, when tested on several heterogeneous tabular datasets, as well
as several image benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instantaneous Grammatical Error Correction with Shallow Aggressive Decoding. (arXiv:2106.04970v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1">Tao Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Houfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04970">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Shallow Aggressive Decoding (SAD) to improve the
online inference efficiency of the Transformer for instantaneous Grammatical
Error Correction (GEC). SAD optimizes the online inference efficiency for GEC
by two innovations: 1) it aggressively decodes as many tokens as possible in
parallel instead of always decoding only one token in each step to improve
computational parallelism; 2) it uses a shallow decoder instead of the
conventional Transformer architecture with balanced encoder-decoder depth to
reduce the computational cost during inference. Experiments in both English and
Chinese GEC benchmarks show that aggressive decoding could yield the same
predictions as greedy decoding but with a significant speedup for online
inference. Its combination with the shallow decoder could offer an even higher
online inference speedup over the powerful Transformer baseline without quality
loss. Not only does our approach allow a single model to achieve the
state-of-the-art results in English GEC benchmarks: 66.4 F0.5 in the CoNLL-14
and 72.9 F0.5 in the BEA-19 test set with an almost 10x online inference
speedup over the Transformer-big model, but also it is easily adapted to other
languages. Our code is available at
https://github.com/AutoTemp/Shallow-Aggressive-Decoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Black-box density function estimation using recursive partitioning. (arXiv:2010.13632v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bodin_E/0/1/0/all/0/1">Erik Bodin</a>, <a href="http://arxiv.org/find/stat/1/au:+Dai_Z/0/1/0/all/0/1">Zhenwen Dai</a>, <a href="http://arxiv.org/find/stat/1/au:+Campbell_N/0/1/0/all/0/1">Neill D. F. Campbell</a>, <a href="http://arxiv.org/find/stat/1/au:+Ek_C/0/1/0/all/0/1">Carl Henrik Ek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13632">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach to Bayesian inference and general Bayesian
computation that is defined through a sequential decision loop. Our method
defines a recursive partitioning of the sample space. It neither relies on
gradients nor requires any problem-specific tuning, and is asymptotically exact
for any density function with a bounded domain. The output is an approximation
to the whole density function including the normalisation constant, via
partitions organised in efficient data structures. Such approximations may be
used for evidence estimation or fast posterior sampling, but also as building
blocks to treat a larger class of estimation problems. The algorithm shows
competitive performance to recent state-of-the-art methods on synthetic and
real-world problems including parameter inference for gravitational-wave
physics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The dilemma of quantum neural networks. (arXiv:2106.04975v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Qian_Y/0/1/0/all/0/1">Yang Qian</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1">Xinbiao Wang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Du_Y/0/1/0/all/0/1">Yuxuan Du</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1">Xingyao Wu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04975">
                                    <div class="article-summary-box-inner">
                                        <span>The core of quantum machine learning is to devise quantum models with good
trainability and low generalization error bound than their classical
counterparts to ensure better reliability and interpretability. Recent studies
confirmed that quantum neural networks (QNNs) have the ability to achieve this
goal on specific datasets. With this regard, it is of great importance to
understand whether these advantages are still preserved on real-world tasks.
Through systematic numerical experiments, we empirically observe that current
QNNs fail to provide any benefit over classical learning models. Concretely,
our results deliver two key messages. First, QNNs suffer from the severely
limited effective model capacity, which incurs poor generalization on
real-world datasets. Second, the trainability of QNNs is insensitive to
regularization techniques, which sharply contrasts with the classical scenario.
These empirical results force us to rethink the role of current QNNs and to
design novel protocols for solving real-world problems with quantum advantages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncovering Closed-form Governing Equations of Nonlinear Dynamics from Videos. (arXiv:2106.04776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luan_L/0/1/0/all/0/1">Lele Luan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04776">
                                    <div class="article-summary-box-inner">
                                        <span>Distilling analytical models from data has the potential to advance our
understanding and prediction of nonlinear dynamics. Although discovery of
governing equations based on observed system states (e.g., trajectory time
series) has revealed success in a wide range of nonlinear dynamics, uncovering
the closed-form equations directly from raw videos still remains an open
challenge. To this end, we introduce a novel end-to-end unsupervised deep
learning framework to uncover the mathematical structure of equations that
governs the dynamics of moving objects in videos. Such an architecture consists
of (1) an encoder-decoder network that learns low-dimensional spatial/pixel
coordinates of the moving object, (2) a learnable Spatial-Physical
Transformation component that creates mapping between the extracted
spatial/pixel coordinates and the latent physical states of dynamics, and (3) a
numerical integrator-based sparse regression module that uncovers the
parsimonious closed-form governing equations of learned physical states and,
meanwhile, serves as a constraint to the autoencoder. The efficacy of the
proposed method is demonstrated by uncovering the governing equations of a
variety of nonlinear dynamical systems depicted by moving objects in videos.
The resulting computational framework enables discovery of parsimonious
interpretable model in a flexible and accessible sensing environment where only
videos are available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiple Kernel Representation Learning on Networks. (arXiv:2106.05057v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Celikkanat_A/0/1/0/all/0/1">Abdulkadir Celikkanat</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yanning Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1">Fragkiskos D. Malliaros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05057">
                                    <div class="article-summary-box-inner">
                                        <span>Learning representations of nodes in a low dimensional space is a crucial
task with numerous interesting applications in network analysis, including link
prediction, node classification, and visualization. Two popular approaches for
this problem are matrix factorization and random walk-based models. In this
paper, we aim to bring together the best of both worlds, towards learning node
representations. In particular, we propose a weighted matrix factorization
model that encodes random walk-based information about nodes of the network.
The benefit of this novel formulation is that it enables us to utilize kernel
functions without realizing the exact proximity matrix so that it enhances the
expressiveness of existing matrix decomposition methods with kernels and
alleviates their computational complexities. We extend the approach with a
multiple kernel learning formulation that provides the flexibility of learning
the kernel as the linear combination of a dictionary of kernels in data-driven
fashion. We perform an empirical evaluation on real-world networks, showing
that the proposed model outperforms baseline node embedding algorithms in
downstream machine learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Framework for Clustered Federated Learning. (arXiv:2006.04088v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1">Avishek Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Chung_J/0/1/0/all/0/1">Jichan Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Yin_D/0/1/0/all/0/1">Dong Yin</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1">Kannan Ramchandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04088">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of federated learning (FL) where users are distributed
and partitioned into clusters. This setup captures settings where different
groups of users have their own objectives (learning tasks) but by aggregating
their data with others in the same cluster (same learning task), they can
leverage the strength in numbers in order to perform more efficient federated
learning. For this new framework of clustered federated learning, we propose
the Iterative Federated Clustering Algorithm (IFCA), which alternately
estimates the cluster identities of the users and optimizes model parameters
for the user clusters via gradient descent. We analyze the convergence rate of
this algorithm first in a linear model with squared loss and then for generic
strongly convex and smooth loss functions. We show that in both settings, with
good initialization, IFCA is guaranteed to converge, and discuss the optimality
of the statistical error rate. In particular, for the linear model with two
clusters, we can guarantee that our algorithm converges as long as the
initialization is slightly better than random. When the clustering structure is
ambiguous, we propose to train the models by combining IFCA with the weight
sharing technique in multi-task learning. In the experiments, we show that our
algorithm can succeed even if we relax the requirements on initialization with
random initialization and multiple restarts. We also present experimental
results showing that our algorithm is efficient in non-convex problems such as
neural networks. We demonstrate the benefits of IFCA over the baselines on
several clustered FL benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interaction-Grounded Learning. (arXiv:2106.04887v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tengyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1">John Langford</a>, <a href="http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1">Paul Mineiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1">Ida Momennejad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04887">
                                    <div class="article-summary-box-inner">
                                        <span>Consider a prosthetic arm, learning to adapt to its user&#x27;s control signals.
We propose Interaction-Grounded Learning for this novel setting, in which a
learner&#x27;s goal is to interact with the environment with no grounding or
explicit reward to optimize its policies. Such a problem evades common RL
solutions which require an explicit reward. The learning agent observes a
multidimensional context vector, takes an action, and then observes a
multidimensional feedback vector. This multidimensional feedback vector has no
explicit reward information. In order to succeed, the algorithm must learn how
to evaluate the feedback vector to discover a latent reward signal, with which
it can ground its policies without supervision. We show that in an
Interaction-Grounded Learning setting, with certain natural assumptions, a
learner can discover the latent reward and ground its policy for successful
interaction. We provide theoretical guarantees and a proof-of-concept empirical
evaluation to demonstrate the effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable AI for medical imaging: Explaining pneumothorax diagnoses with Bayesian Teaching. (arXiv:2106.04684v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Folke_T/0/1/0/all/0/1">Tomas Folke</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Scott Cheng-Hsin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_S/0/1/0/all/0/1">Sean Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafto_P/0/1/0/all/0/1">Patrick Shafto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04684">
                                    <div class="article-summary-box-inner">
                                        <span>Limited expert time is a key bottleneck in medical imaging. Due to advances
in image classification, AI can now serve as decision-support for medical
experts, with the potential for great gains in radiologist productivity and, by
extension, public health. However, these gains are contingent on building and
maintaining experts&#x27; trust in the AI agents. Explainable AI may build such
trust by helping medical experts to understand the AI decision processes behind
diagnostic judgements. Here we introduce and evaluate explanations based on
Bayesian Teaching, a formal account of explanation rooted in the cognitive
science of human learning. We find that medical experts exposed to explanations
generated by Bayesian Teaching successfully predict the AI&#x27;s diagnostic
decisions and are more likely to certify the AI for cases when the AI is
correct than when it is wrong, indicating appropriate trust. These results show
that Explainable AI can be used to support human-AI collaboration in medical
imaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint System-Wise Optimization for Pipeline Goal-Oriented Dialog System. (arXiv:2106.04835v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zichuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04835">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work (Takanobu et al., 2020) proposed the system-wise evaluation on
dialog systems and found that improvement on individual components (e.g., NLU,
policy) in prior work may not necessarily bring benefit to pipeline systems in
system-wise evaluation. To improve the system-wise performance, in this paper,
we propose new joint system-wise optimization techniques for the pipeline
dialog system. First, we propose a new data augmentation approach which
automates the labeling process for NLU training. Second, we propose a novel
stochastic policy parameterization with Poisson distribution that enables
better exploration and offers a principled way to compute policy gradient.
Third, we propose a reward bonus to help policy explore successful dialogs. Our
approaches outperform the competitive pipeline systems from Takanobu et al.
(2020) by big margins of 12% success rate in automatic system-wise evaluation
and of 16% success rate in human evaluation on the standard multi-domain
benchmark dataset MultiWOZ 2.1, and also outperform the recent state-of-the-art
end-to-end trained model from DSTC9.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms. (arXiv:2106.04881v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Camuto_A/0/1/0/all/0/1">Alexander Camuto</a>, <a href="http://arxiv.org/find/stat/1/au:+Deligiannidis_G/0/1/0/all/0/1">George Deligiannidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1">Murat A. Erdogdu</a>, <a href="http://arxiv.org/find/stat/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href="http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1">Umut &#x15e;im&#x15f;ekli</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_L/0/1/0/all/0/1">Lingjiong Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04881">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding generalization in deep learning has been one of the major
challenges in statistical learning theory over the last decade. While recent
work has illustrated that the dataset and the training algorithm must be taken
into account in order to obtain meaningful generalization bounds, it is still
theoretically not clear which properties of the data and the algorithm
determine the generalization performance. In this study, we approach this
problem from a dynamical systems theory perspective and represent stochastic
optimization algorithms as random iterated function systems (IFS). Well studied
in the dynamical systems literature, under mild assumptions, such IFSs can be
shown to be ergodic with an invariant measure that is often supported on sets
with a fractal structure. As our main contribution, we prove that the
generalization error of a stochastic optimization algorithm can be bounded
based on the &#x60;complexity&#x27; of the fractal structure that underlies its invariant
measure. Leveraging results from dynamical systems theory, we show that the
generalization error can be explicitly linked to the choice of the algorithm
(e.g., stochastic gradient descent -- SGD), algorithm hyperparameters (e.g.,
step-size, batch-size), and the geometry of the problem (e.g., Hessian of the
loss). We further specialize our results to specific problems (e.g.,
linear/logistic regression, one hidden-layered neural networks) and algorithms
(e.g., SGD and preconditioned variants), and obtain analytical estimates for
our bound.For modern neural networks, we develop an efficient algorithm to
compute the developed bound and support our theory with various experiments on
neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scale Free Adversarial Multi Armed Bandits. (arXiv:2106.04700v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Putta_S/0/1/0/all/0/1">Sudeep Raja Putta</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Shipra Agrawal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04700">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the Scale-Free Adversarial Multi Armed Bandit(MAB) problem, where
the player only knows the number of arms $n$ and not the scale or magnitude of
the losses. It sees bandit feedback about the loss vectors $l_1,\dots, l_T \in
\mathbb{R}^n$. The goal is to bound its regret as a function of $n$ and
$l_1,\dots, l_T$. We design a Follow The Regularized Leader(FTRL) algorithm,
which comes with the first scale-free regret guarantee for MAB. It uses the log
barrier regularizer, the importance weighted estimator, an adaptive learning
rate, and an adaptive exploration parameter. In the analysis, we introduce a
simple, unifying technique for obtaining regret inequalities for FTRL and
Online Mirror Descent(OMD) on the probability simplex using Potential Functions
and Mixed Bregmans. We also develop a new technique for obtaining local-norm
lower bounds for Bregman Divergences, which are crucial in bandit regret
bounds. These tools could be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Bi-Level Framework for Learning to Solve Combinatorial Optimization on Graphs. (arXiv:2106.04927v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runzhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_Z/0/1/0/all/0/1">Zhigang Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiayi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1">Feng Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04927">
                                    <div class="article-summary-box-inner">
                                        <span>Combinatorial Optimization (CO) has been a long-standing challenging research
topic featured by its NP-hard nature. Traditionally such problems are
approximately solved with heuristic algorithms which are usually fast but may
sacrifice the solution quality. Currently, machine learning for combinatorial
optimization (MLCO) has become a trending research topic, but most existing
MLCO methods treat CO as a single-level optimization by directly learning the
end-to-end solutions, which are hard to scale up and mostly limited by the
capacity of ML models given the high complexity of CO. In this paper, we
propose a hybrid approach to combine the best of the two worlds, in which a
bi-level framework is developed with an upper-level learning method to optimize
the graph (e.g. add, delete or modify edges in a graph), fused with a
lower-level heuristic algorithm solving on the optimized graph. Such a bi-level
approach simplifies the learning on the original hard CO and can effectively
mitigate the demand for model capacity. The experiments and results on several
popular CO problems like Directed Acyclic Graph scheduling, Graph Edit Distance
and Hamiltonian Cycle Problem show its effectiveness over manually designed
heuristics and single-level learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Supervised Domain Adaptation by Augmenting Pre-trained Models with Random Units. (arXiv:2106.04935v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meftah_S/0/1/0/all/0/1">Sara Meftah</a>, <a href="http://arxiv.org/find/cs/1/au:+Semmar_N/0/1/0/all/0/1">Nasredine Semmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamaazousti_Y/0/1/0/all/0/1">Youssef Tamaazousti</a>, <a href="http://arxiv.org/find/cs/1/au:+Essafi_H/0/1/0/all/0/1">Hassane Essafi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadat_F/0/1/0/all/0/1">Fatiha Sadat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04935">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Transfer Learning (TL) is becoming ubiquitous in Natural Language
Processing (NLP), thanks to its high performance on many tasks, especially in
low-resourced scenarios. Notably, TL is widely used for neural domain
adaptation to transfer valuable knowledge from high-resource to low-resource
domains. In the standard fine-tuning scheme of TL, a model is initially
pre-trained on a source domain and subsequently fine-tuned on a target domain
and, therefore, source and target domains are trained using the same
architecture. In this paper, we show through interpretation methods that such
scheme, despite its efficiency, is suffering from a main limitation. Indeed,
although capable of adapting to new domains, pre-trained neurons struggle with
learning certain patterns that are specific to the target domain. Moreover, we
shed light on the hidden negative transfer occurring despite the high
relatedness between source and target domains, which may mitigate the final
gain brought by transfer learning. To address these problems, we propose to
augment the pre-trained model with normalised, weighted and randomly
initialised units that foster a better adaptation while maintaining the
valuable source knowledge. We show that our approach exhibits significant
improvements to the standard fine-tuning scheme for neural domain adaptation
from the news domain to the social media domain on four NLP tasks:
part-of-speech tagging, chunking, named entity recognition and morphosyntactic
tagging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Models for Code Generation under Compilability Constraints. (arXiv:2106.04985v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1">Tomasz Korbak</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsahar_H/0/1/0/all/0/1">Hady Elsahar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1">Marc Dymetman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1">Germ&#xe1;n Kruszewski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04985">
                                    <div class="article-summary-box-inner">
                                        <span>Neural language models can be successfully trained on source code, leading to
applications such as code completion. However, their versatile autoregressive
self-supervision objective overlooks important global sequence-level features
that are present in the data such as syntactic correctness or compilability. In
this work, we pose the problem of learning to generate compilable code as
constraint satisfaction. We define an Energy-Based Model (EBM) representing a
pre-trained generative model with an imposed constraint of generating only
compilable sequences. We then use the KL-Adaptive Distributional Policy
Gradient algorithm (Khalifa et al., 2021) to train a generative model
approximating the EBM. We conduct experiments showing that our proposed
approach is able to improve compilability rates without sacrificing diversity
and complexity of the generated samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Influence-Augmented Online Planning for Complex Environments. (arXiv:2010.11038v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jinke He</a>, <a href="http://arxiv.org/find/cs/1/au:+Suau_M/0/1/0/all/0/1">Miguel Suau</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1">Frans A. Oliehoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11038">
                                    <div class="article-summary-box-inner">
                                        <span>How can we plan efficiently in real time to control an agent in a complex
environment that may involve many other agents? While existing sample-based
planners have enjoyed empirical success in large POMDPs, their performance
heavily relies on a fast simulator. However, real-world scenarios are complex
in nature and their simulators are often computationally demanding, which
severely limits the performance of online planners. In this work, we propose
influence-augmented online planning, a principled method to transform a
factored simulator of the entire environment into a local simulator that
samples only the state variables that are most relevant to the observation and
reward of the planning agent and captures the incoming influence from the rest
of the environment using machine learning methods. Our main experimental
results show that planning on this less accurate but much faster local
simulator with POMCP leads to higher real-time planning performance than
planning on the simulator that models the entire environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Handcrafted Backdoors in Deep Neural Networks. (arXiv:2106.04690v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1">Sanghyun Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1">Alexey Kurakin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04690">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs), while accurate, are expensive to train. Many
practitioners, therefore, outsource the training process to third parties or
use pre-trained DNNs. This practice makes DNNs vulnerable to $backdoor$
$attacks$: the third party who trains the model may act maliciously to inject
hidden behaviors into the otherwise accurate model. Until now, the mechanism to
inject backdoors has been limited to $poisoning$.

We argue that such a supply-chain attacker has more attack techniques
available. To study this hypothesis, we introduce a handcrafted attack that
directly manipulates the parameters of a pre-trained model to inject backdoors.
Our handcrafted attacker has more degrees of freedom in manipulating model
parameters than poisoning. This makes it difficult for a defender to identify
or remove the manipulations with straightforward methods, such as statistical
analysis, adding random noises to model parameters, or clipping their values
within a certain range. Further, our attacker can combine the handcrafting
process with additional techniques, $e.g.$, jointly optimizing a trigger
pattern, to inject backdoors into complex networks effectively$-$the
meet-in-the-middle attack.

In evaluations, our handcrafted backdoors remain effective across four
datasets and four network architectures with a success rate above 96%. Our
backdoored models are resilient to both parameter-level backdoor removal
techniques and can evade existing defenses by slightly changing the backdoor
attack configurations. Moreover, we demonstrate the feasibility of suppressing
unwanted behaviors otherwise caused by poisoning. Our results suggest that
further research is needed for understanding the complete space of supply-chain
backdoor attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Loss function based second-order Jensen inequality and its application to particle variational inference. (arXiv:2106.05010v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Futami_F/0/1/0/all/0/1">Futoshi Futami</a>, <a href="http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1">Naonori Ueda</a>, <a href="http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05010">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian model averaging, obtained as the expectation of a likelihood
function by a posterior distribution, has been widely used for prediction,
evaluation of uncertainty, and model selection. Various approaches have been
developed to efficiently capture the information in the posterior distribution;
one such approach is the optimization of a set of models simultaneously with
interaction to ensure the diversity of the individual models in the same way as
ensemble learning. A representative approach is particle variational inference
(PVI), which uses an ensemble of models as an empirical approximation for the
posterior distribution. PVI iteratively updates each model with a repulsion
force to ensure the diversity of the optimized models. However, despite its
promising performance, a theoretical understanding of this repulsion and its
association with the generalization ability remains unclear. In this paper, we
tackle this problem in light of PAC-Bayesian analysis. First, we provide a new
second-order Jensen inequality, which has the repulsion term based on the loss
function. Thanks to the repulsion term, it is tighter than the standard Jensen
inequality. Then, we derive a novel generalization error bound and show that it
can be reduced by enhancing the diversity of models. Finally, we derive a new
PVI that optimizes the generalization error bound directly. Numerical
experiments demonstrate that the performance of the proposed PVI compares
favorably with existing methods in the experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Softmax Confidence and Uncertainty. (arXiv:2106.04972v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1">Tim Pearce</a>, <a href="http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1">Alexandra Brintrup</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04972">
                                    <div class="article-summary-box-inner">
                                        <span>It is often remarked that neural networks fail to increase their uncertainty
when predicting on data far from the training distribution. Yet naively using
softmax confidence as a proxy for uncertainty achieves modest success in tasks
exclusively testing for this, e.g., out-of-distribution (OOD) detection. This
paper investigates this contradiction, identifying two implicit biases that do
encourage softmax confidence to correlate with epistemic uncertainty: 1)
Approximately optimal decision boundary structure, and 2) Filtering effects of
deep networks. It describes why low-dimensional intuitions about softmax
confidence are misleading. Diagnostic experiments quantify reasons softmax
confidence can fail, finding that extrapolations are less to blame than overlap
between training and OOD data in final-layer representations.
Pre-trained/fine-tuned networks reduce this overlap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Inverse Reinforcement Learning. (arXiv:2106.05068v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1">Firas Jarboui</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05068">
                                    <div class="article-summary-box-inner">
                                        <span>The objective of offline RL is to learn optimal policies when a fixed
exploratory demonstrations data-set is available and sampling additional
observations is impossible (typically if this operation is either costly or
rises ethical questions). In order to solve this problem, off the shelf
approaches require a properly defined cost function (or its evaluation on the
provided data-set), which are seldom available in practice. To circumvent this
issue, a reasonable alternative is to query an expert for few optimal
demonstrations in addition to the exploratory data-set. The objective is then
to learn an optimal policy w.r.t. the expert&#x27;s latent cost function. Current
solutions either solve a behaviour cloning problem (which does not leverage the
exploratory data) or a reinforced imitation learning problem (using a fixed
cost function that discriminates available exploratory trajectories from expert
ones). Inspired by the success of IRL techniques in achieving state of the art
imitation performances in online settings, we exploit GAN based data
augmentation procedures to construct the first offline IRL algorithm. The
obtained policies outperformed the aforementioned solutions on multiple OpenAI
gym environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No Fear of Heterogeneity: Classifier Calibration for Federated Learning with Non-IID Data. (arXiv:2106.05001v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1">Mi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dapeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yifan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jiashi Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05001">
                                    <div class="article-summary-box-inner">
                                        <span>A central challenge in training classification models in the real-world
federated system is learning with non-IID data. To cope with this, most of the
existing works involve enforcing regularization in local optimization or
improving the model aggregation scheme at the server. Other works also share
public datasets or synthesized samples to supplement the training of
under-represented classes or introduce a certain level of personalization.
Though effective, they lack a deep understanding of how the data heterogeneity
affects each layer of a deep classification model. In this paper, we bridge
this gap by performing an experimental analysis of the representations learned
by different layers. Our observations are surprising: (1) there exists a
greater bias in the classifier than other layers, and (2) the classification
performance can be significantly improved by post-calibrating the classifier
after federated training. Motivated by the above findings, we propose a novel
and simple algorithm called Classifier Calibration with Virtual Representations
(CCVR), which adjusts the classifier using virtual representations sampled from
an approximated gaussian mixture model. Experimental results demonstrate that
CCVR achieves state-of-the-art performance on popular federated learning
benchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple
yet effective method can shed some light on the future research of federated
learning with non-IID data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initialization Matters: Regularizing Manifold-informed Initialization for Neural Recommendation Systems. (arXiv:2106.04993v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Boyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04993">
                                    <div class="article-summary-box-inner">
                                        <span>Proper initialization is crucial to the optimization and the generalization
of neural networks. However, most existing neural recommendation systems
initialize the user and item embeddings randomly. In this work, we propose a
new initialization scheme for user and item embeddings called Laplacian
Eigenmaps with Popularity-based Regularization for Isolated Data (LEPORID).
LEPORID endows the embeddings with information regarding multi-scale
neighborhood structures on the data manifold and performs adaptive
regularization to compensate for high embedding variance on the tail of the
data distribution. Exploiting matrix sparsity, LEPORID embeddings can be
computed efficiently. We evaluate LEPORID in a wide range of neural
recommendation models. In contrast to the recent surprising finding that the
simple K-nearest-neighbor (KNN) method often outperforms neural recommendation
systems, we show that existing neural systems initialized with LEPORID often
perform on par or better than KNN. To maximize the effects of the
initialization, we propose the Dual-Loss Residual Recommendation (DLR2)
network, which, when initialized with LEPORID, substantially outperforms both
traditional and state-of-the-art neural recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">It Takes Two to Tango: Mixup for Deep Metric Learning. (arXiv:2106.04990v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venkataramanan_S/0/1/0/all/0/1">Shashanka Venkataramanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Psomas_B/0/1/0/all/0/1">Bill Psomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Avrithis_Y/0/1/0/all/0/1">Yannis Avrithis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kijak_E/0/1/0/all/0/1">Ewa Kijak</a>, <a href="http://arxiv.org/find/cs/1/au:+Amsaleg_L/0/1/0/all/0/1">Laurent Amsaleg</a>, <a href="http://arxiv.org/find/cs/1/au:+Karantzalos_K/0/1/0/all/0/1">Konstantinos Karantzalos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04990">
                                    <div class="article-summary-box-inner">
                                        <span>Metric learning involves learning a discriminative representation such that
embeddings of similar classes are encouraged to be close, while embeddings of
dissimilar classes are pushed far apart. State-of-the-art methods focus mostly
on sophisticated loss functions or mining strategies. On the one hand, metric
learning losses consider two or more examples at a time. On the other hand,
modern data augmentation methods for classification consider two or more
examples at a time. The combination of the two ideas is under-studied.

In this work, we aim to bridge this gap and improve representations using
mixup, which is a powerful data augmentation approach interpolating two or more
examples and corresponding target labels at a time. This task is challenging
because, unlike classification, the loss functions used in metric learning are
not additive over examples, so the idea of interpolating target labels is not
straightforward. To the best of our knowledge, we are the first to investigate
mixing examples and target labels for deep metric learning. We develop a
generalized formulation that encompasses existing metric learning loss
functions and modify it to accommodate for mixup, introducing Metric Mix, or
Metrix. We show that mixing inputs, intermediate representations or embeddings
along with target labels significantly improves representations and outperforms
state-of-the-art metric learning methods on four benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhance Convolutional Neural Networks with Noise Incentive Block. (arXiv:2012.12109v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1">Menghan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_T/0/1/0/all/0/1">Tien-Tsin Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12109">
                                    <div class="article-summary-box-inner">
                                        <span>As a generic modeling tool, Convolutional Neural Networks (CNNs) have been
widely employed in image generation and translation tasks. However, when fed
with a flat input, current CNN models may fail to generate vivid results due to
the spatially shared convolution kernels. We call it the flatness degradation
of CNNs. Unfortunately, such degradation is the greatest obstacles to generate
a spatially-variant output from a flat input, which has been barely discussed
in the previous literature. To tackle this problem, we propose a model agnostic
solution, i.e. Noise Incentive Block (NIB), which serves as a generic plug-in
for any CNN generation model. The key idea is to break the flat input condition
while keeping the intactness of the original information. Specifically, the NIB
perturbs the input data symmetrically with a noise map and reassembles them in
the feature domain as driven by the objective function. Extensive experiments
show that existing CNN models equipped with NIB survive from the flatness
degradation and are able to generate visually better results with richer
details in some specific image generation tasks given flat inputs, e.g.
semantic image synthesis, data-hidden image generation, and deep neural
dithering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions. (arXiv:2106.05022v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laskaridis_S/0/1/0/all/0/1">Stefanos Laskaridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouris_A/0/1/0/all/0/1">Alexandros Kouris</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas D. Lane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05022">
                                    <div class="article-summary-box-inner">
                                        <span>DNNs are becoming less and less over-parametrised due to recent advances in
efficient model design, through careful hand-crafted or NAS-based methods.
Relying on the fact that not all inputs require the same amount of computation
to yield a confident prediction, adaptive inference is gaining attention as a
prominent approach for pushing the limits of efficient deployment.
Particularly, early-exit networks comprise an emerging direction for tailoring
the computation depth of each input sample at runtime, offering complementary
performance gains to other efficiency optimisations. In this paper, we
decompose the design methodology of early-exit networks to its key components
and survey the recent advances in each one of them. We also position
early-exiting against other efficient inference solutions and provide our
insights on the current challenges and most promising future directions for
research in the field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Bellman Operators. (arXiv:2106.05012v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fellows_M/0/1/0/all/0/1">Matthew Fellows</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartikainen_K/0/1/0/all/0/1">Kristian Hartikainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1">Shimon Whiteson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05012">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a novel perspective on Bayesian reinforcement learning (RL);
whereas existing approaches infer a posterior over the transition distribution
or Q-function, we characterise the uncertainty in the Bellman operator. Our
Bayesian Bellman operator (BBO) framework is motivated by the insight that when
bootstrapping is introduced, model-free approaches actually infer a posterior
over Bellman operators, not value functions. In this paper, we use BBO to
provide a rigorous theoretical analysis of model-free Bayesian RL to better
understand its relationshipto established frequentist RL methodologies. We
prove that Bayesian solutions are consistent with frequentist RL solutions,
even when approximate inference isused, and derive conditions for which
convergence properties hold. Empirically, we demonstrate that algorithms
derived from the BBO framework have sophisticated deep exploration properties
that enable them to solve continuous control tasks at which state-of-the-art
regularised actor-critic algorithms fail catastrophically</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Cataract Classification and Grading on Ophthalmic Imaging Modalities: A Survey. (arXiv:2012.04830v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoqing Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1">Yan Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Fang_J/0/1/0/all/0/1">Jiansheng Fang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Higashita_R/0/1/0/all/0/1">Risa Higashita</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1">Jiang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04830">
                                    <div class="article-summary-box-inner">
                                        <span>Cataract is one of the leading causes of reversible visual impairment and
blindness globally. Over the years, researchers have achieved significant
progress in developing state-of-the-art artificial intelligence techniques for
automatic cataract classification and grading, helping clinicians prevent and
treat cataract in time. This paper provides a comprehensive survey of recent
advances in machine learning for cataract classification and grading based on
ophthalmic images. We summarize existing literature from two research
directions: conventional machine learning techniques and deep learning
techniques. This paper also provides insights into existing works of both
merits and limitations. In addition, we discuss several challenges of automatic
cataract classification and grading based on machine learning techniques and
present possible solutions to these challenges for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeRF in detail: Learning to sample for view synthesis. (arXiv:2106.05264v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1">Relja Arandjelovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Zisserman_A/0/1/0/all/0/1">Andrew Zisserman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05264">
                                    <div class="article-summary-box-inner">
                                        <span>Neural radiance fields (NeRF) methods have demonstrated impressive novel view
synthesis performance. The core approach is to render individual rays by
querying a neural network at points sampled along the ray to obtain the density
and colour of the sampled points, and integrating this information using the
rendering equation. Since dense sampling is computationally prohibitive, a
common solution is to perform coarse-to-fine sampling.

In this work we address a clear limitation of the vanilla coarse-to-fine
approach -- that it is based on a heuristic and not trained end-to-end for the
task at hand. We introduce a differentiable module that learns to propose
samples and their importance for the fine network, and consider and compare
multiple alternatives for its neural architecture. Training the proposal module
from scratch can be unstable due to lack of supervision, so an effective
pre-training strategy is also put forward. The approach, named &#x60;NeRF in detail&#x27;
(NeRF-ID), achieves superior view synthesis quality over NeRF and the
state-of-the-art on the synthetic Blender benchmark and on par or better
performance on the real LLFF-NeRF scenes. Furthermore, by leveraging the
predicted sample importance, a 25% saving in computation can be achieved
without significantly sacrificing the rendering quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiFair: Training Fair Models with Bilevel Optimization. (arXiv:2106.04757v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozdayi_M/0/1/0/all/0/1">Mustafa Safa Ozdayi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kantarcioglu_M/0/1/0/all/0/1">Murat Kantarcioglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1">Rishabh Iyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04757">
                                    <div class="article-summary-box-inner">
                                        <span>Prior studies have shown that, training machine learning models via empirical
loss minimization to maximize a utility metric (e.g., accuracy), might yield
models that make discriminatory predictions. To alleviate this issue, we
develop a new training algorithm, named BiFair, which jointly minimizes for a
utility, and a fairness loss of interest. Crucially, we do so without directly
modifying the training objective, e.g., by adding regularization terms. Rather,
we learn a set of weights on the training dataset, such that, training on the
weighted dataset ensures both good utility, and fairness. The dataset weights
are learned in concurrence to the model training, which is done by solving a
bilevel optimization problem using a held-out validation dataset. Overall, this
approach yields models with better fairness-utility trade-offs. Particularly,
we compare our algorithm with three other state-of-the-art fair training
algorithms over three real-world datasets, and demonstrate that, BiFair
consistently performs better, i.e., we reach to better values of a given
fairness metric under same, or higher accuracy. Further, our algorithm is
scalable. It is applicable both to simple models, such as logistic regression,
as well as more complex models, such as deep neural networks, as evidenced by
our experimental analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Harmless Overparametrization in Two-layer Neural Networks. (arXiv:2106.04795v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huiyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04795">
                                    <div class="article-summary-box-inner">
                                        <span>Overparametrized neural networks, where the number of active parameters is
larger than the sample size, prove remarkably effective in modern deep learning
practice. From the classical perspective, however, much fewer parameters are
sufficient for optimal estimation and prediction, whereas overparametrization
can be harmful even in the presence of explicit regularization. To reconcile
this conflict, we present a generalization theory for overparametrized ReLU
networks by incorporating an explicit regularizer based on the scaled variation
norm. Interestingly, this regularizer is equivalent to the ridge from the angle
of gradient-based optimization, but is similar to the group lasso in terms of
controlling model complexity. By exploiting this ridge-lasso duality, we show
that overparametrization is generally harmless to two-layer ReLU networks. In
particular, the overparametrized estimators are minimax optimal up to a
logarithmic factor. By contrast, we show that overparametrized random feature
models suffer from the curse of dimensionality and thus are suboptimal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication-efficient SGD: From Local SGD to One-Shot Averaging. (arXiv:2106.04759v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Spiridonoff_A/0/1/0/all/0/1">Artin Spiridonoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Olshevsky_A/0/1/0/all/0/1">Alex Olshevsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1">Ioannis Ch. Paschalidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04759">
                                    <div class="article-summary-box-inner">
                                        <span>We consider speeding up stochastic gradient descent (SGD) by parallelizing it
across multiple workers. We assume the same data set is shared among $N$
workers, who can take SGD steps and coordinate with a central server. While it
is possible to obtain a linear reduction in the variance by averaging all the
stochastic gradients at every step, this requires a lot of communication
between the workers and the server, which can dramatically reduce the gains
from parallelism. The Local SGD method, proposed and analyzed in the earlier
literature, suggests machines should make many local steps between such
communications. While the initial analysis of Local SGD showed it needs $\Omega
( \sqrt{T} )$ communications for $T$ local gradient steps in order for the
error to scale proportionately to $1/(NT)$, this has been successively improved
in a string of papers, with the state-of-the-art requiring $\Omega \left( N
\left( \mbox{ polynomial in log } (T) \right) \right)$ communications. In this
paper, we suggest a Local SGD scheme that communicates less overall by
communicating less frequently as the number of iterations grows. Our analysis
shows that this can achieve an error that scales as $1/(NT)$ with a number of
communications that is completely independent of $T$. In particular, we show
that $\Omega(N)$ communications are sufficient. Empirical evidence suggests
this bound is close to tight as we further show that $\sqrt{N}$ or $N^{3/4}$
communications fail to achieve linear speed-up in simulations. Moreover, we
show that under mild assumptions, the main of which is twice differentiability
on any neighborhood of the optimal solution, one-shot averaging which only uses
a single round of communication can also achieve the optimal convergence rate
asymptotically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Up Graph Neural Networks Via Graph Coarsening. (arXiv:2106.05150v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zengfeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengzhong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1">Chong Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Min Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05150">
                                    <div class="article-summary-box-inner">
                                        <span>Scalability of graph neural networks remains one of the major challenges in
graph machine learning. Since the representation of a node is computed by
recursively aggregating and transforming representation vectors of its
neighboring nodes from previous layers, the receptive fields grow
exponentially, which makes standard stochastic optimization techniques
ineffective. Various approaches have been proposed to alleviate this issue,
e.g., sampling-based methods and techniques based on pre-computation of graph
filters.

In this paper, we take a different approach and propose to use graph
coarsening for scalable training of GNNs, which is generic, extremely simple
and has sublinear memory and time costs during training. We present extensive
theoretical analysis on the effect of using coarsening operations and provides
useful guidance on the choice of coarsening methods. Interestingly, our
theoretical analysis shows that coarsening can also be considered as a type of
regularization and may improve the generalization. Finally, empirical results
on real world datasets show that, simply applying off-the-shelf coarsening
methods, we can reduce the number of nodes by up to a factor of ten without
causing a noticeable downgrade in classification accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformers for Modeling Physical Systems. (arXiv:2010.03957v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geneva_N/0/1/0/all/0/1">Nicholas Geneva</a>, <a href="http://arxiv.org/find/cs/1/au:+Zabaras_N/0/1/0/all/0/1">Nicholas Zabaras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03957">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers are widely used in natural language processing due to their
ability to model longer-term dependencies in text. Although these models
achieve state-of-the-art performance for many language related tasks, their
applicability outside of the natural language processing field has been
minimal. In this work, we propose the use of transformer models for the
prediction of dynamical systems representative of physical phenomena. The use
of Koopman based embeddings provide a unique and powerful method for projecting
any dynamical system into a vector representation which can then be predicted
by a transformer model. The proposed model is able to accurately predict
various dynamical systems and outperform classical methods that are commonly
used in the scientific machine learning literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Curiosity: RL Agents Discovering Self-supervised Experiments for Causal Representation Learning. (arXiv:2010.03110v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sontakke_S/0/1/0/all/0/1">Sumedh A. Sontakke</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1">Arash Mehrjou</a>, <a href="http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1">Laurent Itti</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03110">
                                    <div class="article-summary-box-inner">
                                        <span>Animals exhibit an innate ability to learn regularities of the world through
interaction. By performing experiments in their environment, they are able to
discern the causal factors of variation and infer how they affect the world&#x27;s
dynamics. Inspired by this, we attempt to equip reinforcement learning agents
with the ability to perform experiments that facilitate a categorization of the
rolled-out trajectories, and to subsequently infer the causal factors of the
environment in a hierarchical manner. We introduce {\em causal curiosity}, a
novel intrinsic reward, and show that it allows our agents to learn optimal
sequences of actions and discover causal factors in the dynamics of the
environment. The learned behavior allows the agents to infer a binary quantized
representation for the ground-truth causal factors in every environment.
Additionally, we find that these experimental behaviors are semantically
meaningful (e.g., our agents learn to lift blocks to categorize them by
weight), and are learnt in a self-supervised manner with approximately 2.5
times less data than conventional supervised planners. We show that these
behaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or
other downstream tasks). Finally, we show that the knowledge of causal factor
representations aids zero-shot learning for more complex tasks. Visit
https://sites.google.com/usc.edu/causal-curiosity/home for website.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Investigating Learned Representations. (arXiv:1905.13308v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1">Jesse A. Livezey</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_A/0/1/0/all/0/1">Ahyeon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1">Jacob Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1">Kristofer E. Bouchard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13308">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchy and compositionality are common latent properties in many natural
and scientific datasets. Determining when a deep network&#x27;s hidden activations
represent hierarchy and compositionality is important both for understanding
deep representation learning and for applying deep networks in domains where
interpretability is crucial. However, current benchmark machine learning
datasets either have little hierarchical or compositional structure, or the
structure is not known. This gap impedes precise analysis of a network&#x27;s
representations and thus hinders development of new methods that can learn such
properties. To address this gap, we developed a new benchmark dataset with
known hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)
is comprised of 35 fonts from the Korean writing system (Hangul), each with
11,172 blocks (syllables) composed from the product of initial consonant,
medial vowel, and final consonant glyphs. All blocks can be grouped into a few
geometric types which induces a hierarchy across blocks. In addition, each
block is composed of individual glyphs with rotations, translations, scalings,
and naturalistic style variation across fonts. We find that both shallow and
deep unsupervised methods only show modest evidence of hierarchy and
compositionality in their representations of the HFD compared to supervised
deep networks. Supervised deep network representations contain structure
related to the geometrical hierarchy of the characters, but the compositional
structure of the data is not evident. Thus, HFD enables the identification of
shortcomings in existing methods, a critical first step toward developing new
machine learning algorithms to extract hierarchical and compositional structure
in the context of naturalistic variability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL. (arXiv:2106.05087v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yanchao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Ruijie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yongyuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05087">
                                    <div class="article-summary-box-inner">
                                        <span>Evaluating the worst-case performance of a reinforcement learning (RL) agent
under the strongest/optimal adversarial perturbations on state observations
(within some constraints) is crucial for understanding the robustness of RL
agents. However, finding the optimal adversary is challenging, in terms of both
whether we can find the optimal attack and how efficiently we can find it.
Existing works on adversarial RL either use heuristics-based methods that may
not find the strongest adversary, or directly train an RL-based adversary by
treating the agent as a part of the environment, which can find the optimal
adversary but may become intractable in a large state space. In this paper, we
propose a novel attacking algorithm which has an RL-based &quot;director&quot; searching
for the optimal policy perturbation, and an &quot;actor&quot; crafting state
perturbations following the directions from the director (i.e. the actor
executes targeted attacks). Our proposed algorithm, PA-AD, is theoretically
optimal against an RL agent and significantly improves the efficiency compared
with prior RL-based works in environments with large or pixel state spaces.
Empirical results show that our proposed PA-AD universally outperforms
state-of-the-art attacking methods in a wide range of environments. Our method
can be easily applied to any RL algorithms to evaluate and improve their
robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Path Integration of Grid Cells: Group Representation and Isotropic Scaling. (arXiv:2006.10259v5 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Gao_R/0/1/0/all/0/1">Ruiqi Gao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xie_J/0/1/0/all/0/1">Jianwen Xie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wei_X/0/1/0/all/0/1">Xue-Xin Wei</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_S/0/1/0/all/0/1">Song-Chun Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wu_Y/0/1/0/all/0/1">Ying Nian Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10259">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding how grid cells perform path integration calculations remains a
fundamental problem. In this paper, we conduct theoretical analysis of a
general representation model of path integration by grid cells, where the 2D
self-position is encoded as a higher dimensional vector, and the 2D self-motion
is represented by a general transformation of the vector. We identify two
conditions on the transformation. One is a group representation condition that
is necessary for path integration. The other is an isotropic scaling condition
that ensures locally conformal embedding, so that the error in the vector
representation translates proportionally to the error in the 2D self-position.
Then we investigate the simplest transformation, i.e., the linear
transformation, uncover its explicit algebraic and geometric structure as
matrix Lie group of rotation, and establish the connection between the
isotropic scaling condition and hexagon grid patterns of grid cells under the
linear transformation. Finally, with our optimization-based approach, we manage
to learn hexagon grid patterns that share similar properties of the grid cells
in the rodent brain. The learned model is capable of accurate long distance
path integration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Neural Networks and Individual Neuron Importance via Information-Ordered Cumulative Ablation. (arXiv:1804.06679v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amjad_R/0/1/0/all/0/1">Rana Ali Amjad</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kairen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_B/0/1/0/all/0/1">Bernhard C. Geiger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1804.06679">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we investigate the use of three information-theoretic
quantities -- entropy, mutual information with the class variable, and a class
selectivity measure based on Kullback-Leibler divergence -- to understand and
study the behavior of already trained fully-connected feed-forward neural
networks. We analyze the connection between these information-theoretic
quantities and classification performance on the test set by cumulatively
ablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our
results parallel those recently published by Morcos et al., indicating that
class selectivity is not a good indicator for classification performance.
However, looking at individual layers separately, both mutual information and
class selectivity are positively correlated with classification performance, at
least for networks with ReLU activation functions. We provide explanations for
this phenomenon and conclude that it is ill-advised to compare the proposed
information-theoretic quantities across layers. Furthermore, we show that
cumulative ablation of neurons with ascending or descending
information-theoretic quantities can be used to formulate hypotheses regarding
the joint behavior of multiple neurons, such as redundancy and synergy, with
comparably low computational cost. We also draw connections to the information
bottleneck theory for neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSTDP: A More Biologically Plausible Learning. (arXiv:1912.00009v2 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shiyuan Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00009">
                                    <div class="article-summary-box-inner">
                                        <span>Spike-timing dependent plasticity (STDP) which observed in the brain has
proven to be important in biological learning. On the other hand, artificial
neural networks use a different way to learn, such as Back-Propagation or
Contrastive Hebbian Learning. In this work, we propose a new framework called
mstdp that learn almost the same way biological learning use, it only uses STDP
rules for supervised and unsupervised learning and don&#x27; t need a global loss or
other supervise information. The framework works like an auto-encoder by making
each input neuron also an output neuron. It can make predictions or generate
patterns in one model without additional configuration. We also brought a new
iterative inference method using momentum to make the framework more efficient,
which can be used in training and testing phases. Finally, we verified our
framework on MNIST dataset for classification and generation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacking Adversarial Attacks as A Defense. (arXiv:2106.04938v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Boxi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Heng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Li Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jindong Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shuai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhifeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1">Deng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04938">
                                    <div class="article-summary-box-inner">
                                        <span>It is well known that adversarial attacks can fool deep neural networks with
imperceptible perturbations. Although adversarial training significantly
improves model robustness, failure cases of defense still broadly exist. In
this work, we find that the adversarial attacks can also be vulnerable to small
perturbations. Namely, on adversarially-trained models, perturbing adversarial
examples with a small random noise may invalidate their misled predictions.
After carefully examining state-of-the-art attacks of various kinds, we find
that all these attacks have this deficiency to different extents. Enlightened
by this finding, we propose to counter attacks by crafting more effective
defensive perturbations. Our defensive perturbations leverage the advantage
that adversarial training endows the ground-truth class with smaller local
Lipschitzness. By simultaneously attacking all the classes, the misled
predictions with larger Lipschitzness can be flipped into correct ones. We
verify our defensive perturbation with both empirical experiments and
theoretical analyses on a linear model. On CIFAR10, it boosts the
state-of-the-art model from 66.16% to 72.66% against the four attacks of
AutoAttack, including 71.76% to 83.30% against the Square attack. On ImageNet,
the top-1 robust accuracy of FastAT is improved from 33.18% to 38.54% under the
100-step PGD attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Complex Knowledge Graph Embeddings. (arXiv:2008.03130v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demir_C/0/1/0/all/0/1">Caglar Demir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1">Axel-Cyrille Ngonga Ngomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03130">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of learning continuous vector
representations of knowledge graphs for predicting missing links. We present a
new approach called ConEx, which infers missing links by leveraging the
composition of a 2D convolution with a Hermitian inner product of
complex-valued embedding vectors. We evaluate ConEx against state-of-the-art
approaches on the WN18RR, FB15K-237, KINSHIP and UMLS benchmark datasets. Our
experimental results show that ConEx achieves a performance superior to that of
state-of-the-art approaches such as RotatE, QuatE and TuckER on the link
prediction task on all datasets while requiring at least 8 times fewer
parameters. We ensure the reproducibility of our results by providing an
open-source implementation which includes the training, evaluation scripts
along with pre-trained models at https://github.com/conex-kge/ConEx.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Neural Network Subspaces. (arXiv:2102.10472v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1">Mitchell Wortsman</a>, <a href="http://arxiv.org/find/cs/1/au:+Horton_M/0/1/0/all/0/1">Maxwell Horton</a>, <a href="http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1">Carlos Guestrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1">Mohammad Rastegari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10472">
                                    <div class="article-summary-box-inner">
                                        <span>Recent observations have advanced our understanding of the neural network
optimization landscape, revealing the existence of (1) paths of high accuracy
containing diverse solutions and (2) wider minima offering improved
performance. Previous methods observing diverse paths require multiple training
runs. In contrast we aim to leverage both property (1) and (2) with a single
method and in a single training run. With a similar computational cost as
training one model, we learn lines, curves, and simplexes of high-accuracy
neural networks. These neural network subspaces contain diverse solutions that
can be ensembled, approaching the ensemble performance of independently trained
networks without the training cost. Moreover, using the subspace midpoint
boosts accuracy, calibration, and robustness to label noise, outperforming
Stochastic Weight Averaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Phraseformer: Multimodal Key-phrase Extraction using Transformer and Graph Embedding. (arXiv:2106.04939v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikzad_Khasmakhi_N/0/1/0/all/0/1">Narjes Nikzad-Khasmakhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1">Mohammad-Reza Feizi-Derakhshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1">Meysam Asgari-Chenaghlu</a>, <a href="http://arxiv.org/find/cs/1/au:+Balafar_M/0/1/0/all/0/1">Mohammad-Ali Balafar</a>, <a href="http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_A/0/1/0/all/0/1">Ali-Reza Feizi-Derakhshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahkar_Farshi_T/0/1/0/all/0/1">Taymaz Rahkar-Farshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1">Majid Ramezani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jahanbakhsh_Nagadeh_Z/0/1/0/all/0/1">Zoleikha Jahanbakhsh-Nagadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafarani_Moattar_E/0/1/0/all/0/1">Elnaz Zafarani-Moattar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1">Mehrdad Ranjbar-Khadivi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04939">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Keyword extraction is a popular research topic in the field of
natural language processing. Keywords are terms that describe the most relevant
information in a document. The main problem that researchers are facing is how
to efficiently and accurately extract the core keywords from a document.
However, previous keyword extraction approaches have utilized the text and
graph features, there is the lack of models that can properly learn and combine
these features in a best way.

Methods: In this paper, we develop a multimodal Key-phrase extraction
approach, namely Phraseformer, using transformer and graph embedding
techniques. In Phraseformer, each keyword candidate is presented by a vector
which is the concatenation of the text and structure learning representations.
Phraseformer takes the advantages of recent researches such as BERT and ExEm to
preserve both representations. Also, the Phraseformer treats the key-phrase
extraction task as a sequence labeling problem solved using classification
task.

Results: We analyze the performance of Phraseformer on three datasets
including Inspec, SemEval2010 and SemEval 2017 by F1-score. Also, we
investigate the performance of different classifiers on Phraseformer method
over Inspec dataset. Experimental results demonstrate the effectiveness of
Phraseformer method over the three datasets used. Additionally, the Random
Forest classifier gain the highest F1-score among all classifiers.

Conclusions: Due to the fact that the combination of BERT and ExEm is more
meaningful and can better represent the semantic of words. Hence, Phraseformer
significantly outperforms single-modality methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Independent mechanism analysis, a new concept?. (arXiv:2106.05200v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1">Luigi Gresele</a>, <a href="http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/stat/1/au:+Stimper_V/0/1/0/all/0/1">Vincent Stimper</a>, <a href="http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1">Michel Besserve</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05200">
                                    <div class="article-summary-box-inner">
                                        <span>Independent component analysis provides a principled framework for
unsupervised representation learning, with solid theory on the identifiability
of the latent code that generated the data, given only observations of mixtures
thereof. Unfortunately, when the mixing is nonlinear, the model is provably
nonidentifiable, since statistical independence alone does not sufficiently
constrain the problem. Identifiability can be recovered in settings where
additional, typically observed variables are included in the generative
process. We investigate an alternative path and consider instead including
assumptions reflecting the principle of independent causal mechanisms exploited
in the field of causality. Specifically, our approach is motivated by thinking
of each source as independently influencing the mixing process. This gives rise
to a framework which we term independent mechanism analysis. We provide
theoretical and empirical evidence that our approach circumvents a number of
nonidentifiability issues arising in nonlinear blind source separation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiffPD: Differentiable Projective Dynamics. (arXiv:2101.05917v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1">Tao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1">Pingchuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wah_S/0/1/0/all/0/1">Sebastien Wah</a>, <a href="http://arxiv.org/find/cs/1/au:+Spielberg_A/0/1/0/all/0/1">Andrew Spielberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>, <a href="http://arxiv.org/find/cs/1/au:+Matusik_W/0/1/0/all/0/1">Wojciech Matusik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05917">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel, fast differentiable simulator for soft-body learning and
control applications. Existing differentiable soft-body simulators can be
classified into two categories based on their time integration methods:
Simulators using explicit time-stepping scheme require tiny time steps to avoid
numerical instabilities in gradient computation, and simulators using implicit
time integration typically compute gradients by employing the adjoint method
and solving the expensive linearized dynamics. Inspired by Projective Dynamics
(PD), we present Differentiable Projective Dynamics (DiffPD), an efficient
differentiable soft-body simulator based on PD with implicit time integration.
The key idea in DiffPD is to speed up backpropagation by exploiting the
prefactorized Cholesky decomposition in forward PD simulation. In terms of
contact handling, DiffPD supports two types of contacts: a penalty-based model
describing contact and friction forces and a complementarity-based model
enforcing non-penetration conditions and static friction. We evaluate the
performance of DiffPD and observe it is 4-19 times faster compared to the
standard Newton&#x27;s method in various applications including system
identification, inverse design problems, trajectory optimization, and
closed-loop control. We also apply DiffPD in a real-to-sim example with contact
and collisions and show its capability of reconstructing a digital twin of
real-world scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crosslingual Embeddings are Essential in UNMT for Distant Languages: An English to IndoAryan Case Study. (arXiv:2106.04995v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banerjee_T/0/1/0/all/0/1">Tamali Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1">Rudra Murthy V</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1">Pushpak Bhattacharyya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04995">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in Unsupervised Neural Machine Translation (UNMT) have
minimized the gap between supervised and unsupervised machine translation
performance for closely related language pairs. However, the situation is very
different for distant language pairs. Lack of lexical overlap and low syntactic
similarities such as between English and Indo-Aryan languages leads to poor
translation quality in existing UNMT systems. In this paper, we show that
initializing the embedding layer of UNMT models with cross-lingual embeddings
shows significant improvements in BLEU score over existing approaches with
embeddings randomly initialized. Further, static embeddings (freezing the
embedding layer weights) lead to better gains compared to updating the
embedding layer weights during training (non-static). We experimented using
Masked Sequence to Sequence (MASS) and Denoising Autoencoder (DAE) UNMT
approaches for three distant language pairs. The proposed cross-lingual
embedding initialization yields BLEU score improvement of as much as ten times
over the baseline for English-Hindi, English-Bengali, and English-Gujarati. Our
analysis shows the importance of cross-lingual embedding, comparisons between
approaches, and the scope of improvements in these systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unifying Behavioral and Response Diversity for Open-ended Learning in Zero-sum Games. (arXiv:2106.04958v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiangyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">Hangtian Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Ying Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaodong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yujing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04958">
                                    <div class="article-summary-box-inner">
                                        <span>Measuring and promoting policy diversity is critical for solving games with
strong non-transitive dynamics where strategic cycles exist, and there is no
consistent winner (e.g., Rock-Paper-Scissors). With that in mind, maintaining a
pool of diverse policies via open-ended learning is an attractive solution,
which can generate auto-curricula to avoid being exploited. However, in
conventional open-ended learning algorithms, there are no widely accepted
definitions for diversity, making it hard to construct and evaluate the diverse
policies. In this work, we summarize previous concepts of diversity and work
towards offering a unified measure of diversity in multi-agent open-ended
learning to include all elements in Markov games, based on both Behavioral
Diversity (BD) and Response Diversity (RD). At the trajectory distribution
level, we re-define BD in the state-action space as the discrepancies of
occupancy measures. For the reward dynamics, we propose RD to characterize
diversity through the responses of policies when encountering different
opponents. We also show that many current diversity measures fall in one of the
categories of BD or RD but not both. With this unified diversity measure, we
design the corresponding diversity-promoting objective and population
effectivity when seeking the best responses in open-ended learning. We validate
our methods in both relatively simple games like matrix game, non-transitive
mixture model, and the complex \textit{Google Research Football} environment.
The population found by our methods reveals the lowest exploitability, highest
population effectivity in matrix game and non-transitive mixture model, as well
as the largest goal difference when interacting with opponents of various
levels in \textit{Google Research Football}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Realizing GANs via a Tunable Loss Function. (arXiv:2106.05232v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kurri_G/0/1/0/all/0/1">Gowtham R. Kurri</a>, <a href="http://arxiv.org/find/cs/1/au:+Sypherd_T/0/1/0/all/0/1">Tyler Sypherd</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankar_L/0/1/0/all/0/1">Lalitha Sankar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05232">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a tunable GAN, called $\alpha$-GAN, parameterized by $\alpha \in
(0,\infty]$, which interpolates between various $f$-GANs and Integral
Probability Metric based GANs (under constrained discriminator set). We
construct $\alpha$-GAN using a supervised loss function, namely, $\alpha$-loss,
which is a tunable loss function capturing several canonical losses. We show
that $\alpha$-GAN is intimately related to the Arimoto divergence, which was
first proposed by \&quot;{O}sterriecher (1996), and later studied by Liese and Vajda
(2006). We posit that the holistic understanding that $\alpha$-GAN introduces
will have practical benefits of addressing both the issues of vanishing
gradients and mode collapse.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Online Learning. (arXiv:2106.04982v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1">Tommaso R. Cesari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vecchia_R/0/1/0/all/0/1">Riccardo Della Vecchia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04982">
                                    <div class="article-summary-box-inner">
                                        <span>In this preliminary (and unpolished) version of the paper, we study an
asynchronous online learning setting with a network of agents. At each time
step, some of the agents are activated, requested to make a prediction, and pay
the corresponding loss. Some feedback is then revealed to these agents and is
later propagated through the network. We consider the case of full, bandit, and
semi-bandit feedback. In particular, we construct a reduction to delayed
single-agent learning that applies to both the full and the bandit feedback
case and allows to obtain regret guarantees for both settings. We complement
these results with a near-matching lower bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling massive highly-multivariate nonstationary spatial data with the basis graphical lasso. (arXiv:2101.02404v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Krock_M/0/1/0/all/0/1">Mitchell Krock</a>, <a href="http://arxiv.org/find/stat/1/au:+Kleiber_W/0/1/0/all/0/1">William Kleiber</a>, <a href="http://arxiv.org/find/stat/1/au:+Hammerling_D/0/1/0/all/0/1">Dorit Hammerling</a>, <a href="http://arxiv.org/find/stat/1/au:+Becker_S/0/1/0/all/0/1">Stephen Becker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02404">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new modeling framework for highly-multivariate spatial processes
that synthesizes ideas from recent multiscale and spectral approaches with
graphical models. The basis graphical lasso writes a univariate Gaussian
process as a linear combination of basis functions weighted with entries of a
Gaussian graphical vector whose graph is estimated from optimizing an $\ell_1$
penalized likelihood. This paper extends the setting to a multivariate Gaussian
process where the basis functions are weighted with Gaussian graphical vectors.
We motivate a model where the basis functions represent different levels of
resolution and the graphical vectors for each level are assumed to be
independent. Using an orthogonal basis grants linear complexity and memory
usage in the number of spatial locations, the number of basis functions, and
the number of realizations. An additional fusion penalty encourages a
parsimonious conditional independence structure in the multilevel graphical
model. We illustrate our method on a large climate ensemble from the National
Center for Atmospheric Research&#x27;s Community Atmosphere Model that involves 40
spatial processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks. (arXiv:2011.02511v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1">Julia Kreutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1">Stefan Riezler</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawrence_C/0/1/0/all/0/1">Carolin Lawrence</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02511">
                                    <div class="article-summary-box-inner">
                                        <span>Large volumes of interaction logs can be collected from NLP systems that are
deployed in the real world. How can this wealth of information be leveraged?
Using such interaction logs in an offline reinforcement learning (RL) setting
is a promising approach. However, due to the nature of NLP tasks and the
constraints of production systems, a series of challenges arise. We present a
concise overview of these challenges and discuss possible solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Server Private Linear Transformation: The Individual Privacy Case. (arXiv:2106.05222v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1">Anoosheh Heidarzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1">Nahid Esmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1">Alex Sprintson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05222">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers the single-server Private Linear Transformation (PLT)
problem with individual privacy guarantees. In this problem, there is a user
that wishes to obtain $L$ independent linear combinations of a $D$-subset of
messages belonging to a dataset of $K$ messages stored on a single server. The
goal is to minimize the download cost while keeping the identity of each
message required for the computation individually private. The individual
privacy requirement ensures that the identity of each individual message
required for the computation is kept private. This is in contrast to the
stricter notion of joint privacy that protects the entire set of identities of
all messages used for the computation, including the correlations between these
identities. The notion of individual privacy captures a broad set of practical
applications. For example, such notion is relevant when the dataset contains
information about individuals, each of them requires privacy guarantees for
their data access patterns. We focus on the setting in which the required
linear transformation is associated with a maximum distance separable (MDS)
matrix. In particular, we require that the matrix of coefficients pertaining to
the required linear combinations is the generator matrix of an MDS code. We
establish lower and upper bounds on the capacity of PLT with individual
privacy, where the capacity is defined as the supremum of all achievable
download rates. We show that our bounds are tight under certain conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Canonical Transform for Strengthening the Local $L^p$-Type Universal Approximation Property. (arXiv:2006.14378v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kratsios_A/0/1/0/all/0/1">Anastasis Kratsios</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamanlooy_B/0/1/0/all/0/1">Behnoosh Zamanlooy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14378">
                                    <div class="article-summary-box-inner">
                                        <span>Most $L^p$-type universal approximation theorems guarantee that a given
machine learning model class $\mathscr{F}\subseteq
C(\mathbb{R}^d,\mathbb{R}^D)$ is dense in
$L^p_{\mu}(\mathbb{R}^d,\mathbb{R}^D)$ for any suitable finite Borel measure
$\mu$ on $\mathbb{R}^d$. Unfortunately, this means that the model&#x27;s
approximation quality can rapidly degenerate outside some compact subset of
$\mathbb{R}^d$, as any such measure is largely concentrated on some bounded
subset of $\mathbb{R}^d$. This paper proposes a generic solution to this
approximation theoretic problem by introducing a canonical transformation which
&quot;upgrades $\mathscr{F}$&#x27;s approximation property&quot; in the following sense. The
transformed model class, denoted by $\mathscr{F}\text{-tope}$, is shown to be
dense in $L^p_{\mu,\text{strict}}(\mathbb{R}^d,\mathbb{R}^D)$ which is a
topological space whose elements are locally $p$-integrable functions and whose
topology is much finer than usual norm topology on
$L^p_{\mu}(\mathbb{R}^d,\mathbb{R}^D)$; here $\mu$ is any suitable
$\sigma$-finite Borel measure $\mu$ on $\mathbb{R}^d$. Next, we show that if
$\mathscr{F}$ is any family of analytic functions then there is always a strict
&quot;gap&quot; between $\mathscr{F}\text{-tope}$&#x27;s expressibility and that of
$\mathscr{F}$, since we find that $\mathscr{F}$ can never dense in
$L^p_{\mu,\text{strict}}(\mathbb{R}^d,\mathbb{R}^D)$. In the general case,
where $\mathscr{F}$ may contain non-analytic functions, we provide an abstract
form of these results guaranteeing that there always exists some function space
in which $\mathscr{F}\text{-tope}$ is dense but $\mathscr{F}$ is not, while,
the converse is never possible. Applications to feedforward networks,
convolutional neural networks, and polynomial bases are explored.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit field learning for unsupervised anomaly detection in medical images. (arXiv:2106.05214v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Marimont_S/0/1/0/all/0/1">Sergio Naval Marimont</a>, <a href="http://arxiv.org/find/eess/1/au:+Tarroni_G/0/1/0/all/0/1">Giacomo Tarroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05214">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel unsupervised out-of-distribution detection method for
medical images based on implicit fields image representations. In our approach,
an auto-decoder feed-forward neural network learns the distribution of healthy
images in the form of a mapping between spatial coordinates and probabilities
over a proxy for tissue types. At inference time, the learnt distribution is
used to retrieve, from a given test image, a restoration, i.e. an image
maximally consistent with the input one but belonging to the healthy
distribution. Anomalies are localized using the voxel-wise probability
predicted by our model for the restored image. We tested our approach in the
task of unsupervised localization of gliomas on brain MR images and compared it
to several other VAE-based anomaly detection methods. Results show that the
proposed technique substantially outperforms them (average DICE 0.640 vs 0.518
for the best performing VAE-based alternative) while also requiring
considerably less computing time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Subset Selection for Efficient Training and Inference of Neural Networks. (arXiv:2006.14222v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Andreis_B/0/1/0/all/0/1">Bruno Andreis</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">A. Tuan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seanie Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Juho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14222">
                                    <div class="article-summary-box-inner">
                                        <span>Current machine learning algorithms are designed to work with huge volumes of
high dimensional data such as images. However, these algorithms are being
increasingly deployed to resource constrained systems such as mobile devices
and embedded systems. Even in cases where large computing infrastructure is
available, the size of each data instance, as well as datasets, can be a
bottleneck in data transfer across communication channels. Also, there is a
huge incentive both in energy and monetary terms in reducing both the
computational and memory requirements of these algorithms. For nonparametric
models that require to leverage the stored training data at inference time, the
increased cost in memory and computation could be even more problematic. In
this work, we aim to reduce the volume of data these algorithms must process
through an end-to-end two-stage neural subset selection model. We first
efficiently obtain a subset of candidate elements by sampling a mask from a
conditionally independent Bernoulli distribution, and then autoregressivley
construct a subset consisting of the most task relevant elements via sampling
the elements from a conditional Categorical distribution. We validate our
method on set reconstruction and classification tasks with feature selection as
well as the selection of representative samples from a given dataset, on which
our method outperforms relevant baselines. We also show in our experiments that
our method enhances scalability of nonparametric models such as Neural
Processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diversity Actor-Critic: Sample-Aware Entropy Regularization for Sample-Efficient Exploration. (arXiv:2006.01419v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Seungyul Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1">Youngchul Sung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.01419">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, sample-aware policy entropy regularization is proposed to
enhance the conventional policy entropy regularization for better exploration.
Exploiting the sample distribution obtainable from the replay buffer, the
proposed sample-aware entropy regularization maximizes the entropy of the
weighted sum of the policy action distribution and the sample action
distribution from the replay buffer for sample-efficient exploration. A
practical algorithm named diversity actor-critic (DAC) is developed by applying
policy iteration to the objective function with the proposed sample-aware
entropy regularization. Numerical results show that DAC significantly
outperforms existing recent algorithms for reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Class-Transductive Intent Representations for Zero-shot Intent Detection. (arXiv:2012.01721v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1">Qingyi Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuanxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_P/0/1/0/all/0/1">Peng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiangnan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01721">
                                    <div class="article-summary-box-inner">
                                        <span>Zero-shot intent detection (ZSID) aims to deal with the continuously emerging
intents without annotated training data. However, existing ZSID systems suffer
from two limitations: 1) They are not good at modeling the relationship between
seen and unseen intents. 2) They cannot effectively recognize unseen intents
under the generalized intent detection (GZSID) setting. A critical problem
behind these limitations is that the representations of unseen intents cannot
be learned in the training stage. To address this problem, we propose a novel
framework that utilizes unseen class labels to learn Class-Transductive Intent
Representations (CTIR). Specifically, we allow the model to predict unseen
intents during training, with the corresponding label names serving as input
utterances. On this basis, we introduce a multi-task learning objective, which
encourages the model to learn the distinctions among intents, and a similarity
scorer, which estimates the connections among intents more accurately. CTIR is
easy to implement and can be integrated with existing methods. Experiments on
two real-world datasets show that CTIR brings considerable improvement to the
baseline systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Facet Clustering Variational Autoencoders. (arXiv:2106.05241v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Falck_F/0/1/0/all/0/1">Fabian Falck</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1">Haoting Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Willetts_M/0/1/0/all/0/1">Matthew Willetts</a>, <a href="http://arxiv.org/find/stat/1/au:+Nicholson_G/0/1/0/all/0/1">George Nicholson</a>, <a href="http://arxiv.org/find/stat/1/au:+Yau_C/0/1/0/all/0/1">Christopher Yau</a>, <a href="http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1">Christopher C Holmes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05241">
                                    <div class="article-summary-box-inner">
                                        <span>Work in deep clustering focuses on finding a single partition of data.
However, high-dimensional data, such as images, typically feature multiple
interesting characteristics one could cluster over. For example, images of
objects against a background could be clustered over the shape of the object
and separately by the colour of the background. In this paper, we introduce
Multi-Facet Clustering Variational Autoencoders (MFCVAE), a novel class of
variational autoencoders with a hierarchy of latent variables, each with a
Mixture-of-Gaussians prior, that learns multiple clusterings simultaneously,
and is trained fully unsupervised and end-to-end. MFCVAE uses a
progressively-trained ladder architecture which leads to highly stable
performance. We provide novel theoretical results for optimising the ELBO
analytically with respect to the categorical variational posterior
distribution, and corrects earlier influential theoretical work. On image
benchmarks, we demonstrate that our approach separates out and clusters over
different aspects of the data in a disentangled manner. We also show other
advantages of our model: the compositionality of its latent space and that it
provides controlled generation of samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural UpFlow: A Scene Flow Learning Approach to Increase the Apparent Resolution of Particle-Based Liquids. (arXiv:2106.05143v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Bruno Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Poulin_P/0/1/0/all/0/1">Pierre Poulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Paquette_E/0/1/0/all/0/1">Eric Paquette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05143">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel up-resing technique for generating high-resolution liquids
based on scene flow estimation using deep neural networks. Our approach infers
and synthesizes small- and large-scale details solely from a low-resolution
particle-based liquid simulation. The proposed network leverages neighborhood
contributions to encode inherent liquid properties throughout convolutions. We
also propose a particle-based approach to interpolate between liquids generated
from varying simulation discretizations using a state-of-the-art bidirectional
optical flow solver method for fluids in addition to a novel key-event
topological alignment constraint. In conjunction with the neighborhood
contributions, our loss formulation allows the inference model throughout
epochs to reward important differences in regard to significant gaps in
simulation discretizations. Even when applied in an untested simulation setup,
our approach is able to generate plausible high-resolution details. Using this
interpolation approach and the predicted displacements, our approach combines
the input liquid properties with the predicted motion to infer semi-Lagrangian
advection. We furthermore showcase how the proposed interpolation approach can
facilitate generating large simulation datasets with a subset of initial
condition parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An ordinal CNN approach for the assessment of neurological damage in Parkinson&#x27;s disease patients. (arXiv:2106.05230v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbero_Gomez_J/0/1/0/all/0/1">Javier Barbero-G&#xf3;mez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1">Pedro-Antonio Guti&#xe9;rrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_V/0/1/0/all/0/1">V&#xed;ctor-Manuel Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallejo_Casas_J/0/1/0/all/0/1">Juan-Antonio Vallejo-Casas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hervas_Martinez_C/0/1/0/all/0/1">C&#xe9;sar Herv&#xe1;s-Mart&#xed;nez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05230">
                                    <div class="article-summary-box-inner">
                                        <span>3D image scans are an assessment tool for neurological damage in Parkinson&#x27;s
disease (PD) patients. This diagnosis process can be automatized to help
medical staff through Decision Support Systems (DSSs), and Convolutional Neural
Networks (CNNs) are good candidates, because they are effective when applied to
spatial data. This paper proposes a 3D CNN ordinal model for assessing the
level or neurological damage in PD patients. Given that CNNs need large
datasets to achieve acceptable performance, a data augmentation method is
adapted to work with spatial data. We consider the Ordinal Graph-based
Oversampling via Shortest Paths (OGO-SP) method, which applies a gamma
probability distribution for inter-class data generation. A modification of
OGO-SP is proposed, the OGO-SP-$\beta$ algorithm, which applies the beta
distribution for generating synthetic samples in the inter-class region, a
better suited distribution when compared to gamma. The evaluation of the
different methods is based on a novel 3D image dataset provided by the Hospital
Universitario &#x27;Reina Sof\&#x27;ia&#x27; (C\&#x27;ordoba, Spain). We show how the ordinal
methodology improves the performance with respect to the nominal one, and how
OGO-SP-$\beta$ yields better performance than OGO-SP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry-Consistent Neural Shape Representation with Implicit Displacement Fields. (arXiv:2106.05187v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yifan_W/0/1/0/all/0/1">Wang Yifan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmann_L/0/1/0/all/0/1">Lukas Rahmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorkine_Hornung_O/0/1/0/all/0/1">Olga Sorkine-Hornung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05187">
                                    <div class="article-summary-box-inner">
                                        <span>We present implicit displacement fields, a novel representation for detailed
3D geometry. Inspired by a classic surface deformation technique, displacement
mapping, our method represents a complex surface as a smooth base surface plus
a displacement along the base&#x27;s normal directions, resulting in a
frequency-based shape decomposition, where the high frequency signal is
constrained geometrically by the low frequency signal. Importantly, this
disentanglement is unsupervised thanks to a tailored architectural design that
has an innate frequency hierarchy by construction. We explore implicit
displacement field surface reconstruction and detail transfer and demonstrate
superior representational power, training stability and generalizability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Attention Belief Networks. (arXiv:2106.05251v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shujian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xinjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05251">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based neural networks have achieved state-of-the-art results on a
wide range of tasks. Most such models use deterministic attention while
stochastic attention is less explored due to the optimization difficulties or
complicated model design. This paper introduces Bayesian attention belief
networks, which construct a decoder network by modeling unnormalized attention
weights with a hierarchy of gamma distributions, and an encoder network by
stacking Weibull distributions with a deterministic-upward-stochastic-downward
structure to approximate the posterior. The resulting auto-encoding networks
can be optimized in a differentiable way with a variational lower bound. It is
simple to convert any models with deterministic attention, including pretrained
ones, to the proposed Bayesian attention belief networks. On a variety of
language understanding tasks, we show that our method outperforms deterministic
attention and state-of-the-art stochastic attention in accuracy, uncertainty
estimation, generalization across domains, and robustness to adversarial
attacks. We further demonstrate the general applicability of our method on
neural machine translation and visual question answering, showing great
potential of incorporating our method into various attention-related tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixture weights optimisation for Alpha-Divergence Variational Inference. (arXiv:2106.05114v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Daudel_K/0/1/0/all/0/1">Kam&#xe9;lia Daudel</a>, <a href="http://arxiv.org/find/math/1/au:+Douc_R/0/1/0/all/0/1">Randal Douc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05114">
                                    <div class="article-summary-box-inner">
                                        <span>This paper focuses on $\alpha$-divergence minimisation methods for
Variational Inference. More precisely, we are interested in algorithms
optimising the mixture weights of any given mixture model, without any
information on the underlying distribution of its mixture components
parameters. The Power Descent, defined for all $\alpha \neq 1$, is one such
algorithm and we establish in our work the full proof of its convergence
towards the optimal mixture weights when $\alpha &lt;1$. Since the
$\alpha$-divergence recovers the widely-used forward Kullback-Leibler when
$\alpha \to 1$, we then extend the Power Descent to the case $\alpha &#x3D; 1$ and
show that we obtain an Entropic Mirror Descent. This leads us to investigate
the link between Power Descent and Entropic Mirror Descent: first-order
approximations allow us to introduce the Renyi Descent, a novel algorithm for
which we prove an $O(1/N)$ convergence rate. Lastly, we compare numerically the
behavior of the unbiased Power Descent and of the biased Renyi Descent and we
discuss the potential advantages of one algorithm over the other.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning normal form autoencoders for data-driven discovery of universal,parameter-dependent governing equations. (arXiv:2106.05102v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalia_M/0/1/0/all/0/1">Manu Kalia</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunton_S/0/1/0/all/0/1">Steven L. Brunton</a>, <a href="http://arxiv.org/find/cs/1/au:+Meijer_H/0/1/0/all/0/1">Hil G.E. Meijer</a>, <a href="http://arxiv.org/find/cs/1/au:+Brune_C/0/1/0/all/0/1">Christoph Brune</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1">J. Nathan Kutz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05102">
                                    <div class="article-summary-box-inner">
                                        <span>Complex systems manifest a small number of instabilities and bifurcations
that are canonical in nature, resulting in universal pattern forming
characteristics as a function of some parametric dependence. Such parametric
instabilities are mathematically characterized by their universal un-foldings,
or normal form dynamics, whereby a parsimonious model can be used to represent
the dynamics. Although center manifold theory guarantees the existence of such
low-dimensional normal forms, finding them has remained a long standing
challenge. In this work, we introduce deep learning autoencoders to discover
coordinate transformations that capture the underlying parametric dependence of
a dynamical system in terms of its canonical normal form, allowing for a simple
representation of the parametric dependence and bifurcation structure. The
autoencoder constrains the latent variable to adhere to a given normal form,
thus allowing it to learn the appropriate coordinate transformation. We
demonstrate the method on a number of example problems, showing that it can
capture a diverse set of normal forms associated with Hopf, pitchfork,
transcritical and/or saddle node bifurcations. This method shows how normal
forms can be leveraged as canonical and universal building blocks in deep
learning approaches for model discovery and reduced-order modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Lipschitz Constant of Self-Attention. (arXiv:2006.04710v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1">Hyunjik Kim</a>, <a href="http://arxiv.org/find/stat/1/au:+Papamakarios_G/0/1/0/all/0/1">George Papamakarios</a>, <a href="http://arxiv.org/find/stat/1/au:+Mnih_A/0/1/0/all/0/1">Andriy Mnih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04710">
                                    <div class="article-summary-box-inner">
                                        <span>Lipschitz constants of neural networks have been explored in various contexts
in deep learning, such as provable adversarial robustness, estimating
Wasserstein distance, stabilising training of GANs, and formulating invertible
neural networks. Such works have focused on bounding the Lipschitz constant of
fully connected or convolutional networks, composed of linear maps and
pointwise non-linearities. In this paper, we investigate the Lipschitz constant
of self-attention, a non-linear neural network module widely used in sequence
modelling. We prove that the standard dot-product self-attention is not
Lipschitz for unbounded input domain, and propose an alternative L2
self-attention that is Lipschitz. We derive an upper bound on the Lipschitz
constant of L2 self-attention and provide empirical evidence for its asymptotic
tightness. To demonstrate the practical relevance of our theoretical work, we
formulate invertible self-attention and use it in a Transformer-based
architecture for a character-level language modelling task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Lyapunov-Based Methodology for Constrained Optimization with Bandit Feedback. (arXiv:2106.05165v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1">Semih Cayci</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yilin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Eryilmaz_A/0/1/0/all/0/1">Atilla Eryilmaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05165">
                                    <div class="article-summary-box-inner">
                                        <span>In a wide variety of applications including online advertising, contractual
hiring, and wireless scheduling, the controller is constrained by a stringent
budget constraint on the available resources, which are consumed in a random
amount by each action, and a stochastic feasibility constraint that may impose
important operational limitations on decision-making. In this work, we consider
a general model to address such problems, where each action returns a random
reward, cost, and penalty from an unknown joint distribution, and the
decision-maker aims to maximize the total reward under a budget constraint $B$
on the total cost and a stochastic constraint on the time-average penalty. We
propose a novel low-complexity algorithm based on Lyapunov optimization
methodology, named ${\tt LyOn}$, and prove that it achieves $O(\sqrt{B\log B})$
regret and $O(\log B/B)$ constraint-violation. The low computational cost and
sharp performance bounds of ${\tt LyOn}$ suggest that Lyapunov-based algorithm
design methodology can be effective in solving constrained bandit optimization
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilling Image Classifiers in Object Detectors. (arXiv:2106.05209v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shuxuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1">Jose M. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1">Mathieu Salzmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05209">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation constitutes a simple yet effective way to improve the
performance of a compact student network by exploiting the knowledge of a more
powerful teacher. Nevertheless, the knowledge distillation literature remains
limited to the scenario where the student and the teacher tackle the same task.
Here, we investigate the problem of transferring knowledge not only across
architectures but also across tasks. To this end, we study the case of object
detection and, instead of following the standard detector-to-detector
distillation approach, introduce a classifier-to-detector knowledge transfer
framework. In particular, we propose strategies to exploit the classification
teacher to improve both the detector&#x27;s recognition accuracy and localization
performance. Our experiments on several detectors with different backbones
demonstrate the effectiveness of our approach, allowing us to outperform the
state-of-the-art detector-to-detector distillation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling. (arXiv:2106.05233v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Walter_B/0/1/0/all/0/1">Benjamin Walter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05233">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification is considered, and a hierarchical max-pooling model with
additional local pooling is introduced. Here the additional local pooling
enables the hierachical model to combine parts of the image which have a
variable relative distance towards each other. Various convolutional neural
network image classifiers are introduced and compared in view of their rate of
convergence. The finite sample size performance of the estimates is analyzed by
applying them to simulated and real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Massively Parallel and Asynchronous Tsetlin Machine Architecture Supporting Almost Constant-Time Scaling. (arXiv:2009.04861v4 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abeyrathna_K/0/1/0/all/0/1">K. Darshana Abeyrathna</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1">Bimal Bhattarai</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1">Morten Goodwin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorji_S/0/1/0/all/0/1">Saeed Gorji</a>, <a href="http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1">Ole-Christoffer Granmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Lei Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1">Rupsa Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_R/0/1/0/all/0/1">Rohan K. Yadav</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04861">
                                    <div class="article-summary-box-inner">
                                        <span>Using logical clauses to represent patterns, Tsetlin Machines (TMs) have
recently obtained competitive performance in terms of accuracy, memory
footprint, energy, and learning speed on several benchmarks. Each TM clause
votes for or against a particular class, with classification resolved using a
majority vote. While the evaluation of clauses is fast, being based on binary
operators, the voting makes it necessary to synchronize the clause evaluation,
impeding parallelization. In this paper, we propose a novel scheme for
desynchronizing the evaluation of clauses, eliminating the voting bottleneck.
In brief, every clause runs in its own thread for massive native parallelism.
For each training example, we keep track of the class votes obtained from the
clauses in local voting tallies. The local voting tallies allow us to detach
the processing of each clause from the rest of the clauses, supporting
decentralized learning. This means that the TM most of the time will operate on
outdated voting tallies. We evaluated the proposed parallelization across
diverse learning tasks and it turns out that our decentralized TM learning
algorithm copes well with working on outdated data, resulting in no significant
loss in learning accuracy. Furthermore, we show that the proposed approach
provides up to 50 times faster learning. Finally, learning time is almost
constant for reasonable clause amounts (employing from 20 to 7,000 clauses on a
Tesla V100 GPU). For sufficiently large clause numbers, computation time
increases approximately proportionally. Our parallel and asynchronous
architecture thus allows processing of massive datasets and operating with more
clauses for higher accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Bag is to Prune. (arXiv:2008.07063v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Coulombe_P/0/1/0/all/0/1">Philippe Goulet Coulombe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.07063">
                                    <div class="article-summary-box-inner">
                                        <span>It is notoriously difficult to build a bad Random Forest (RF). Concurrently,
RF blatantly overfits in-sample without any apparent consequence out-of-sample.
Standard arguments, like the classic bias-variance trade-off or double descent,
cannot rationalize this paradox. I propose a new explanation: bootstrap
aggregation and model perturbation as implemented by RF automatically prune a
latent &quot;true&quot; tree. More generally, randomized ensembles of greedily optimized
learners implicitly perform optimal early stopping out-of-sample. So there is
no need to tune the stopping point. By construction, novel variants of Boosting
and MARS are also eligible for automatic tuning. I empirically demonstrate the
property, with simulated and real data, by reporting that these new completely
overfitting ensembles perform similarly to their tuned counterparts -- or
better.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Swiss Parliaments Corpus, an Automatically Aligned Swiss German Speech to Standard German Text Corpus. (arXiv:2010.02810v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pluss_M/0/1/0/all/0/1">Michel Pl&#xfc;ss</a>, <a href="http://arxiv.org/find/cs/1/au:+Neukom_L/0/1/0/all/0/1">Lukas Neukom</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheller_C/0/1/0/all/0/1">Christian Scheller</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1">Manfred Vogel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02810">
                                    <div class="article-summary-box-inner">
                                        <span>We present the Swiss Parliaments Corpus (SPC), an automatically aligned Swiss
German speech to Standard German text corpus. This first version of the corpus
is based on publicly available data of the Bernese cantonal parliament and
consists of 293 hours of data. It was created using a novel forced sentence
alignment procedure and an alignment quality estimator, which can be used to
trade off corpus size and quality. We trained Automatic Speech Recognition
(ASR) models as baselines on different subsets of the data and achieved a Word
Error Rate (WER) of 0.278 and a BLEU score of 0.586 on the SPC test set. The
corpus is freely available for download.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning. (arXiv:2006.10412v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1">Arrasy Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hopner_N/0/1/0/all/0/1">Niklas H&#xf6;pner</a>, <a href="http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1">Filippos Christianos</a>, <a href="http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1">Stefano V. Albrecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.10412">
                                    <div class="article-summary-box-inner">
                                        <span>Ad hoc teamwork is the challenging problem of designing an autonomous agent
which can adapt quickly to collaborate with teammates without prior
coordination mechanisms, including joint training. Prior work in this area has
focused on closed teams in which the number of agents is fixed. In this work,
we consider open teams by allowing agents with different fixed policies to
enter and leave the environment without prior notification. Our solution builds
on graph neural networks to learn agent models and joint-action value models
under varying team compositions. We contribute a novel action-value computation
that integrates the agent model and joint-action value model to produce
action-value estimates. We empirically demonstrate that our approach
successfully models the effects other agents have on the learner, leading to
policies that robustly adapt to dynamic team compositions and significantly
outperform several alternative methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order-Agnostic Cross Entropy for Non-Autoregressive Machine Translation. (arXiv:2106.05093v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1">Cunxiao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05093">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new training objective named order-agnostic cross entropy (OaXE)
for fully non-autoregressive translation (NAT) models. OaXE improves the
standard cross-entropy loss to ameliorate the effect of word reordering, which
is a common source of the critical multimodality problem in NAT. Concretely,
OaXE removes the penalty for word order errors, and computes the cross entropy
loss based on the best possible alignment between model predictions and target
tokens. Since the log loss is very sensitive to invalid references, we leverage
cross entropy initialization and loss truncation to ensure the model focuses on
a good part of the search space. Extensive experiments on major WMT benchmarks
show that OaXE substantially improves translation performance, setting new
state of the art for fully NAT models. Further analyses show that OaXE
alleviates the multimodality problem by reducing token repetitions and
increasing prediction confidence. Our code, data, and trained models are
available at https://github.com/tencent-ailab/ICML21_OAXE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback. (arXiv:2106.05203v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1">Peter Richt&#xe1;rik</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokolov_I/0/1/0/all/0/1">Igor Sokolov</a>, <a href="http://arxiv.org/find/cs/1/au:+Fatkhullin_I/0/1/0/all/0/1">Ilyas Fatkhullin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05203">
                                    <div class="article-summary-box-inner">
                                        <span>Error feedback (EF), also known as error compensation, is an immensely
popular convergence stabilization mechanism in the context of distributed
training of supervised machine learning models enhanced by the use of
contractive communication compression mechanisms, such as Top-$k$. First
proposed by Seide et al (2014) as a heuristic, EF resisted any theoretical
understanding until recently [Stich et al., 2018, Alistarh et al., 2018].
However, all existing analyses either i) apply to the single node setting only,
ii) rely on very strong and often unreasonable assumptions, such global
boundedness of the gradients, or iterate-dependent assumptions that cannot be
checked a-priori and may not hold in practice, or iii) circumvent these issues
via the introduction of additional unbiased compressors, which increase the
communication cost. In this work we fix all these deficiencies by proposing and
analyzing a new EF mechanism, which we call EF21, which consistently and
substantially outperforms EF in practice. Our theoretical analysis relies on
standard assumptions only, works in the distributed heterogeneous data setting,
and leads to better and more meaningful rates. In particular, we prove that
EF21 enjoys a fast $O(1/T)$ convergence rate for smooth nonconvex problems,
beating the previous bound of $O(1/T^{2/3})$, which was shown a bounded
gradients assumption. We further improve this to a fast linear rate for PL
functions, which is the first linear convergence result for an EF-type method
not relying on unbiased compressors. Since EF has a large number of
applications where it reigns supreme, we believe that our 2021 variant, EF21,
can a large impact on the practice of communication efficient distributed
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concave Utility Reinforcement Learning: the Mean-field Game viewpoint. (arXiv:2106.03787v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>, <a href="http://arxiv.org/find/cs/1/au:+Perolat_J/0/1/0/all/0/1">Julien P&#xe9;rolat</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauriere_M/0/1/0/all/0/1">Mathieu Lauri&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Elie_R/0/1/0/all/0/1">Romuald Elie</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrin_S/0/1/0/all/0/1">Sarah Perrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1">Olivier Bachem</a>, <a href="http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1">R&#xe9;mi Munos</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1">Olivier Pietquin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03787">
                                    <div class="article-summary-box-inner">
                                        <span>Concave Utility Reinforcement Learning (CURL) extends RL from linear to
concave utilities in the occupancy measure induced by the agent&#x27;s policy. This
encompasses not only RL but also imitation learning and exploration, among
others. Yet, this more general paradigm invalidates the classical Bellman
equations, and calls for new algorithms. Mean-field Games (MFGs) are a
continuous approximation of many-agent RL. They consider the limit case of a
continuous distribution of identical agents, anonymous with symmetric
interests, and reduce the problem to the study of a single representative agent
in interaction with the full population. Our core contribution consists in
showing that CURL is a subclass of MFGs. We think this important to bridge
together both communities. It also allows to shed light on aspects of both
fields: we show the equivalence between concavity in CURL and monotonicity in
the associated MFG, between optimality conditions in CURL and Nash equilibrium
in MFG, or that Fictitious Play (FP) for this class of MFGs is simply
Frank-Wolfe, bringing the first convergence rate for discrete-time FP for MFGs.
We also experimentally demonstrate that, using algorithms recently introduced
for solving MFGs, we can address the CURL problem more efficiently.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighborhood Contrastive Learning Applied to Online Patient Monitoring. (arXiv:2106.05142v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeche_H/0/1/0/all/0/1">Hugo Y&#xe8;che</a>, <a href="http://arxiv.org/find/cs/1/au:+Dresdner_G/0/1/0/all/0/1">Gideon Dresdner</a>, <a href="http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>, <a href="http://arxiv.org/find/cs/1/au:+Huser_M/0/1/0/all/0/1">Matthias H&#xfc;ser</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1">Gunnar R&#xe4;tsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05142">
                                    <div class="article-summary-box-inner">
                                        <span>Intensive care units (ICU) are increasingly looking towards machine learning
for methods to provide online monitoring of critically ill patients. In machine
learning, online monitoring is often formulated as a supervised learning
problem. Recently, contrastive learning approaches have demonstrated promising
improvements over competitive supervised benchmarks. These methods rely on
well-understood data augmentation techniques developed for image data which do
not apply to online monitoring. In this work, we overcome this limitation by
supplementing time-series data augmentation techniques with a novel contrastive
learning objective which we call neighborhood contrastive learning (NCL). Our
objective explicitly groups together contiguous time segments from each patient
while maintaining state-specific information. Our experiments demonstrate a
marked improvement over existing work applying contrastive methods to medical
time-series.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densely connected multidilated convolutional networks for dense prediction tasks. (arXiv:2011.11844v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takahashi_N/0/1/0/all/0/1">Naoya Takahashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1">Yuki Mitsufuji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11844">
                                    <div class="article-summary-box-inner">
                                        <span>Tasks that involve high-resolution dense prediction require a modeling of
both local and global patterns in a large input field. Although the local and
global structures often depend on each other and their simultaneous modeling is
important, many convolutional neural network (CNN)-based approaches interchange
representations in different resolutions only a few times. In this paper, we
claim the importance of a dense simultaneous modeling of multiresolution
representation and propose a novel CNN architecture called densely connected
multidilated DenseNet (D3Net). D3Net involves a novel multidilated convolution
that has different dilation factors in a single layer to model different
resolutions simultaneously. By combining the multidilated convolution with the
DenseNet architecture, D3Net incorporates multiresolution learning with an
exponentially growing receptive field in almost all layers, while avoiding the
aliasing problem that occurs when we naively incorporate the dilated
convolution in DenseNet. Experiments on the image semantic segmentation task
using Cityscapes and the audio source separation task using MUSDB18 show that
the proposed method has superior performance over state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hottung_A/0/1/0/all/0/1">Andr&#xe9; Hottung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1">Yeong-Dae Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Tierney_K/0/1/0/all/0/1">Kevin Tierney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05126">
                                    <div class="article-summary-box-inner">
                                        <span>Recently numerous machine learning based methods for combinatorial
optimization problems have been proposed that learn to construct solutions in a
sequential decision process via reinforcement learning. While these methods can
be easily combined with search strategies like sampling and beam search, it is
not straightforward to integrate them into a high-level search procedure
offering strong search guidance. Bello et al. (2016) propose active search,
which adjusts the weights of a (trained) model with respect to a single
instance at test time using reinforcement learning. While active search is
simple to implement, it is not competitive with state-of-the-art methods
because adjusting all model weights for each test instance is very time and
memory intensive. Instead of updating all model weights, we propose and
evaluate three efficient active search strategies that only update a subset of
parameters during the search. The proposed methods offer a simple way to
significantly improve the search performance of a given model and outperform
state-of-the-art machine learning based methods on combinatorial problems, even
surpassing the well-known heuristic solver LKH3 on the capacitated vehicle
routing problem. Finally, we show that (efficient) active search enables
learned models to effectively solve instances that are much larger than those
seen during training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MLPF: Efficient machine-learned particle-flow reconstruction using graph neural networks. (arXiv:2101.08578v3 [physics.data-an] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Pata_J/0/1/0/all/0/1">Joosep Pata</a>, <a href="http://arxiv.org/find/physics/1/au:+Duarte_J/0/1/0/all/0/1">Javier Duarte</a>, <a href="http://arxiv.org/find/physics/1/au:+Vlimant_J/0/1/0/all/0/1">Jean-Roch Vlimant</a>, <a href="http://arxiv.org/find/physics/1/au:+Pierini_M/0/1/0/all/0/1">Maurizio Pierini</a>, <a href="http://arxiv.org/find/physics/1/au:+Spiropulu_M/0/1/0/all/0/1">Maria Spiropulu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08578">
                                    <div class="article-summary-box-inner">
                                        <span>In general-purpose particle detectors, the particle-flow algorithm may be
used to reconstruct a comprehensive particle-level view of the event by
combining information from the calorimeters and the trackers, significantly
improving the detector resolution for jets and the missing transverse momentum.
In view of the planned high-luminosity upgrade of the CERN Large Hadron
Collider (LHC), it is necessary to revisit existing reconstruction algorithms
and ensure that both the physics and computational performance are sufficient
in an environment with many simultaneous proton-proton interactions (pileup).
Machine learning may offer a prospect for computationally efficient event
reconstruction that is well-suited to heterogeneous computing platforms, while
significantly improving the reconstruction quality over rule-based algorithms
for granular detectors. We introduce MLPF, a novel, end-to-end trainable,
machine-learned particle-flow algorithm based on parallelizable,
computationally efficient, and scalable graph neural networks optimized using a
multi-task objective on simulated events. We report the physics and
computational performance of the MLPF algorithm on a Monte Carlo dataset of top
quark-antiquark pairs produced in proton-proton collisions in conditions
similar to those expected for the high-luminosity LHC. The MLPF algorithm
improves the physics response with respect to a rule-based benchmark algorithm
and demonstrates computationally scalable particle-flow reconstruction in a
high-pileup environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SMG: A Shuffling Gradient-Based Method with Momentum. (arXiv:2011.11884v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Tran_T/0/1/0/all/0/1">Trang H. Tran</a>, <a href="http://arxiv.org/find/math/1/au:+Nguyen_L/0/1/0/all/0/1">Lam M. Nguyen</a>, <a href="http://arxiv.org/find/math/1/au:+Tran_Dinh_Q/0/1/0/all/0/1">Quoc Tran-Dinh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11884">
                                    <div class="article-summary-box-inner">
                                        <span>We combine two advanced ideas widely used in optimization for machine
learning: shuffling strategy and momentum technique to develop a novel
shuffling gradient-based method with momentum, coined Shuffling Momentum
Gradient (SMG), for non-convex finite-sum optimization problems. While our
method is inspired by momentum techniques, its update is fundamentally
different from existing momentum-based methods. We establish state-of-the-art
convergence rates of SMG for any shuffling strategy using either constant or
diminishing learning rate under standard assumptions (i.e.$L$-smoothness and
bounded variance). When the shuffling strategy is fixed, we develop another new
algorithm that is similar to existing momentum methods, and prove the same
convergence rates for this algorithm under the $L$-smoothness and bounded
gradient assumptions. We demonstrate our algorithms via numerical simulations
on standard datasets and compare them with existing shuffling methods. Our
tests have shown encouraging performance of the new algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Algorithms for Finding Densely Connected Clusters. (arXiv:2106.05245v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Macgregor_P/0/1/0/all/0/1">Peter Macgregor</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">He Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05245">
                                    <div class="article-summary-box-inner">
                                        <span>Local graph clustering is an important algorithmic technique for analysing
massive graphs, and has been widely applied in many research fields of data
science. While the objective of most (local) graph clustering algorithms is to
find a vertex set of low conductance, there has been a sequence of recent
studies that highlight the importance of the inter-connection between clusters
when analysing real-world datasets. Following this line of research, in this
work we study local algorithms for finding a pair of vertex sets defined with
respect to their inter-connection and their relationship with the rest of the
graph. The key to our analysis is a new reduction technique that relates the
structure of multiple sets to a single vertex set in the reduced graph. Among
many potential applications, we show that our algorithms successfully recover
densely connected clusters in the Interstate Disputes Dataset and the US
Migration Dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretrained Encoders are All You Need. (arXiv:2106.05139v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mina Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivatsa_P/0/1/0/all/0/1">P Srivatsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Rane_A/0/1/0/all/0/1">Advait Rane</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenniappa_S/0/1/0/all/0/1">Shriram Chenniappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Anand_R/0/1/0/all/0/1">Rishabh Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1">Sherjil Ozair</a>, <a href="http://arxiv.org/find/cs/1/au:+Maes_P/0/1/0/all/0/1">Pattie Maes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05139">
                                    <div class="article-summary-box-inner">
                                        <span>Data-efficiency and generalization are key challenges in deep learning and
deep reinforcement learning as many models are trained on large-scale,
domain-specific, and expensive-to-label datasets. Self-supervised models
trained on large-scale uncurated datasets have shown successful transfer to
diverse settings. We investigate using pretrained image representations and
spatio-temporal attention for state representation learning in Atari. We also
explore fine-tuning pretrained representations with self-supervised techniques,
i.e., contrastive predictive coding, spatio-temporal contrastive learning, and
augmentations. Our results show that pretrained representations are at par with
state-of-the-art self-supervised methods trained on domain-specific data.
Pretrained representations, thus, yield data and compute-efficient state
representations. https://github.com/PAL-ML/PEARL_v1</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge distillation: A good teacher is patient and consistent. (arXiv:2106.05237v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Royer_A/0/1/0/all/0/1">Am&#xe9;lie Royer</a>, <a href="http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1">Larisa Markeeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1">Rohan Anil</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05237">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing discrepancy in computer vision between large-scale models
that achieve state-of-the-art performance and models that are affordable in
practical applications. In this paper we address this issue and significantly
bridge the gap between these two types of models. Throughout our empirical
investigation we do not aim to necessarily propose a new method, but strive to
identify a robust and effective recipe for making state-of-the-art large scale
models affordable in practice. We demonstrate that, when performed correctly,
knowledge distillation can be a powerful tool for reducing the size of large
models without compromising their performance. In particular, we uncover that
there are certain implicit design choices, which may drastically affect the
effectiveness of distillation. Our key contribution is the explicit
identification of these design choices, which were not previously articulated
in the literature. We back up our findings by a comprehensive empirical study,
demonstrate compelling results on a wide range of vision datasets and, in
particular, obtain a state-of-the-art ResNet-50 model for ImageNet, which
achieves 82.8\% top-1 accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethink Transfer Learning in Medical Image Classification. (arXiv:2106.05152v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1">Le Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Liang_H/0/1/0/all/0/1">Hengyue Liang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Taihui Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Ju Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05152">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning (TL) with deep convolutional neural networks (DCNNs) has
proved successful in medical image classification (MIC). However, the current
practice is puzzling, as MIC typically relies only on low- and/or mid-level
features that are learned in the bottom layers of DCNNs. Following this
intuition, we question the current strategies of TL in MIC. In this paper, we
perform careful experimental comparisons between shallow and deep networks for
classification on two chest x-ray datasets, using different TL strategies. We
find that deep models are not always favorable, and finetuning truncated deep
models almost always yields the best performance, especially in data-poor
regimes.

Project webpage:
https://github.com/sun-umn/Transfer-Learning-in-Medical-Imaging

Keywords: Transfer learning, Medical image classification, Feature hierarchy,
Medical imaging, Evaluation metrics, Imbalanced data</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-armed Bandit Requiring Monotone Arm Sequences. (arXiv:2106.03790v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Ningyuan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03790">
                                    <div class="article-summary-box-inner">
                                        <span>In many online learning or multi-armed bandit problems, the taken actions or
pulled arms are ordinal and required to be monotone over time. Examples include
dynamic pricing, in which the firms use markup pricing policies to please early
adopters and deter strategic waiting, and clinical trials, in which the dose
allocation usually follows the dose escalation principle to prevent dose
limiting toxicities. We consider the continuum-armed bandit problem when the
arm sequence is required to be monotone. We show that when the unknown
objective function is Lipschitz continuous, the regret is $O(T)$. When in
addition the objective function is unimodal or quasiconcave, the regret is
$\tilde O(T^{3/4})$ under the proposed algorithm, which is also shown to be the
optimal rate. This deviates from the optimal rate $\tilde O(T^{2/3})$ in the
continuous-armed bandit literature and demonstrates the cost to the learning
efficiency brought by the monotonicity requirement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Framelets Enhance Graph Neural Networks. (arXiv:2102.06986v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xuebin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bingxin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Guang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Lio</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Ming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1">Guido Montufar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06986">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new approach for assembling graph neural networks based
on framelet transforms. The latter provides a multi-scale representation for
graph-structured data. We decompose an input graph into low-pass and high-pass
frequencies coefficients for network training, which then defines a
framelet-based graph convolution. The framelet decomposition naturally induces
a graph pooling strategy by aggregating the graph feature into low-pass and
high-pass spectra, which considers both the feature values and geometry of the
graph data and conserves the total information. The graph neural networks with
the proposed framelet convolution and pooling achieve state-of-the-art
performance in many node and graph prediction tasks. Moreover, we propose
shrinkage as a new activation for the framelet convolution, which thresholds
high-frequency information at different scales. Compared to ReLU, shrinkage
activation improves model performance on denoising and signal compression:
noises in both node and structure can be significantly reduced by accurately
cutting off the high-pass coefficients from framelet decomposition, and the
signal can be compressed to less than half its original size with
well-preserved prediction performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Transformers Really Perform Bad for Graph Representation?. (arXiv:2106.05234v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1">Chengxuan Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shengjie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuxin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_G/0/1/0/all/0/1">Guolin Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Di He</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yanming Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05234">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer architecture has become a dominant choice in many domains,
such as natural language processing and computer vision. Yet, it has not
achieved competitive performance on popular leaderboards of graph-level
prediction compared to mainstream GNN variants. Therefore, it remains a mystery
how Transformers could perform well for graph representation learning. In this
paper, we solve this mystery by presenting Graphormer, which is built upon the
standard Transformer architecture, and could attain excellent results on a
broad range of graph representation learning tasks, especially on the recent
OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the
graph is the necessity of effectively encoding the structural information of a
graph into the model. To this end, we propose several simple yet effective
structural encoding methods to help Graphormer better model graph-structured
data. Besides, we mathematically characterize the expressive power of
Graphormer and exhibit that with our ways of encoding the structural
information of graphs, many popular GNN variants could be covered as the
special cases of Graphormer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Clustering based Fair Outlier Detection. (arXiv:2106.05127v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hanyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peizhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongfu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05127">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we focus on the fairness issues regarding unsupervised outlier
detection. Traditional algorithms, without a specific design for algorithmic
fairness, could implicitly encode and propagate statistical bias in data and
raise societal concerns. To correct such unfairness and deliver a fair set of
potential outlier candidates, we propose Deep Clustering based Fair Outlier
Detection (DCFOD) that learns a good representation for utility maximization
while enforcing the learnable representation to be subgroup-invariant on the
sensitive attribute. Considering the coupled and reciprocal nature between
clustering and outlier detection, we leverage deep clustering to discover the
intrinsic cluster structure and out-of-structure instances. Meanwhile, an
adversarial training erases the sensitive pattern for instances for fairness
adaptation. Technically, we propose an instance-level weighted representation
learning strategy to enhance the joint deep clustering and outlier detection,
where the dynamic weight module re-emphasizes contributions of likely-inliers
while mitigating the negative impact from outliers. Demonstrated by experiments
on eight datasets comparing to 17 outlier detection algorithms, our DCFOD
method consistently achieves superior performance on both the outlier detection
validity and two types of fairness notions in outlier detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Generate Noise for Multi-Attack Robustness. (arXiv:2006.12135v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1">Divyam Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12135">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial learning has emerged as one of the successful techniques to
circumvent the susceptibility of existing methods against adversarial
perturbations. However, the majority of existing defense methods are tailored
to defend against a single category of adversarial perturbation (e.g.
$\ell_\infty$-attack). In safety-critical applications, this makes these
methods extraneous as the attacker can adopt diverse adversaries to deceive the
system. Moreover, training on multiple perturbations simultaneously
significantly increases the computational overhead during training. To address
these challenges, we propose a novel meta-learning framework that explicitly
learns to generate noise to improve the model&#x27;s robustness against multiple
types of attacks. Its key component is Meta Noise Generator (MNG) that outputs
optimal noise to stochastically perturb a given sample, such that it helps
lower the error on diverse adversarial perturbations. By utilizing samples
generated by MNG, we train a model by enforcing the label consistency across
multiple perturbations. We validate the robustness of models trained by our
scheme on various datasets and against a wide variety of perturbations,
demonstrating that it significantly outperforms the baselines across multiple
perturbations with a marginal computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-domain Speech Recognition with Unsupervised Character-level Distribution Matching. (arXiv:2104.07491v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1">Wenxin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shinozaki_T/0/1/0/all/0/1">Takahiro Shinozaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07491">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end automatic speech recognition (ASR) can achieve promising
performance with large-scale training data. However, it is known that domain
mismatch between training and testing data often leads to a degradation of
recognition accuracy. In this work, we focus on the unsupervised domain
adaptation for ASR and propose CMatch, a Character-level distribution matching
method to perform fine-grained adaptation between each character in two
domains. First, to obtain labels for the features belonging to each character,
we achieve frame-level label assignment using the Connectionist Temporal
Classification (CTC) pseudo labels. Then, we match the character-level
distributions using Maximum Mean Discrepancy. We train our algorithm using the
self-training technique. Experiments on the Libri-Adapt dataset show that our
proposed approach achieves 14.39% and 16.50% relative Word Error Rate (WER)
reduction on both cross-device and cross-environment ASR. We also
comprehensively analyze the different strategies for frame-level label
assignment and Transformer adaptations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Diagnosing GAN: Diagnosing Underrepresented Samples in Generative Adversarial Networks. (arXiv:2102.12033v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinhee Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Haeri Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Youngkyu Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hye Won Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12033">
                                    <div class="article-summary-box-inner">
                                        <span>Despite remarkable performance in producing realistic samples, Generative
Adversarial Networks (GANs) often produce low-quality samples near low-density
regions of the data manifold, especially for samples with minor features. Many
techniques have been developed to improve the quality of generated samples,
either by post-processing generated samples or by pre-processing the empirical
data distribution, but at the cost of reduced diversity. To promote diversity
in sample generation without degrading the overall quality, we propose a simple
yet effective method to diagnose and emphasize underrepresented samples during
training of a GAN. The main idea is to use the statistics of the discrepancy
between the data distribution and the model distribution at each data instance.
Based on the observation that the underrepresented samples have a high average
discrepancy or high variability in discrepancy, we propose a method to
emphasize those samples during training of a GAN. Our experimental results
demonstrate that the proposed method improves GAN performance on various
datasets, and it is especially effective in improving the quality and diversity
of generated samples with minor features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crowdsourced Labeling for Worker-Task Specialization Model. (arXiv:2004.00101v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Doyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1">Hye Won Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.00101">
                                    <div class="article-summary-box-inner">
                                        <span>We consider crowdsourced labeling under a $d$-type worker-task specialization
model, where each worker and task is associated with one particular type among
a finite set of types and a worker provides a more reliable answer to tasks of
the matched type than to tasks of unmatched types. We design an inference
algorithm that recovers binary task labels (up to any given recovery accuracy)
by using worker clustering, worker skill estimation and weighted majority
voting. The designed inference algorithm does not require any information about
worker/task types, and achieves any targeted recovery accuracy with the best
known performance (minimum number of queries per task).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XBNet : An Extremely Boosted Neural Network. (arXiv:2106.05239v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarkar_T/0/1/0/all/0/1">Tushar Sarkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05239">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have proved to be very robust at processing unstructured data
like images, text, videos, and audio. However, it has been observed that their
performance is not up to the mark in tabular data; hence tree-based models are
preferred in such scenarios. A popular model for tabular data is boosted trees,
a highly efficacious and extensively used machine learning method, and it also
provides good interpretability compared to neural networks. In this paper, we
describe a novel architecture XBNet, which tries to combine tree-based models
with that of neural networks to create a robust architecture trained by using a
novel optimization technique, Boosted Gradient Descent for Tabular Data which
increases its interpretability and performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MACE: A Flexible Framework for Membership Privacy Estimation in Generative Models. (arXiv:2009.05683v3 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yixi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tople_S/0/1/0/all/0/1">Shruti Tople</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Sumit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferres_J/0/1/0/all/0/1">Juan Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05683">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we formally study the membership privacy risk of generative
models and propose a membership privacy estimation framework. We formulate the
membership privacy risk as a statistical divergence between training samples
and hold-out samples, and propose sample-based methods to estimate this
divergence. Unlike previous works, our proposed metric and estimators make
realistic and flexible assumptions. First, we offer a generalizable metric as
an alternative to accuracy for imbalanced datasets. Second, our estimators are
capable of estimating the membership privacy risk given any scalar or vector
valued attributes from the learned model, while prior work require access to
specific attributes. This allows our framework to provide data-driven
certificates for trained generative models in terms of membership privacy risk.
Finally, we show a connection to differential privacy, which allows our
proposed estimators to be used to understand the privacy budget &#x27;epsilon&#x27;
needed for differentially private generative models. We demonstrate the utility
of our framework through experimental demonstrations on different generative
models using various model attributes yielding some new insights about
membership leakage and vulnerabilities of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TF-IDF vs Word Embeddings for Morbidity Identification in Clinical Notes: An Initial Study. (arXiv:2105.09632v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dessi_D/0/1/0/all/0/1">Danilo Dessi</a>, <a href="http://arxiv.org/find/cs/1/au:+Helaoui_R/0/1/0/all/0/1">Rim Helaoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vivek Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1">Diego Reforgiato Recupero</a>, <a href="http://arxiv.org/find/cs/1/au:+Riboni_D/0/1/0/all/0/1">Daniele Riboni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09632">
                                    <div class="article-summary-box-inner">
                                        <span>Today, we are seeing an ever-increasing number of clinical notes that contain
clinical results, images, and textual descriptions of patient&#x27;s health state.
All these data can be analyzed and employed to cater novel services that can
help people and domain experts with their common healthcare tasks. However,
many technologies such as Deep Learning and tools like Word Embeddings have
started to be investigated only recently, and many challenges remain open when
it comes to healthcare domain applications. To address these challenges, we
propose the use of Deep Learning and Word Embeddings for identifying sixteen
morbidity types within textual descriptions of clinical records. For this
purpose, we have used a Deep Learning model based on Bidirectional Long-Short
Term Memory (LSTM) layers which can exploit state-of-the-art vector
representations of data such as Word Embeddings. We have employed pre-trained
Word Embeddings namely GloVe and Word2Vec, and our own Word Embeddings trained
on the target domain. Furthermore, we have compared the performances of the
deep learning approaches against the traditional tf-idf using Support Vector
Machine and Multilayer perceptron (our baselines). From the obtained results it
seems that the latter outperforms the combination of Deep Learning approaches
using any word embeddings. Our preliminary results indicate that there are
specific features that make the dataset biased in favour of traditional machine
learning approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-Driven Robust Optimization using Unsupervised Deep Learning. (arXiv:2011.09769v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Goerigk_M/0/1/0/all/0/1">Marc Goerigk</a>, <a href="http://arxiv.org/find/math/1/au:+Kurtz_J/0/1/0/all/0/1">Jannis Kurtz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09769">
                                    <div class="article-summary-box-inner">
                                        <span>Robust optimization has been established as a leading methodology to approach
decision problems under uncertainty. To derive a robust optimization model, a
central ingredient is to identify a suitable model for uncertainty, which is
called the uncertainty set, containing all scenarios against which we wish to
protect. An ongoing challenge in the recent literature is to derive uncertainty
sets from given historical data.

In this paper we use an unsupervised deep learning method to construct
non-convex uncertainty sets from data, which have a more complex structure than
the typically considered sets. We prove that most of the classical uncertainty
classes are special cases of our derived sets and that optimizing over it is
strongly NP-hard. Nevertheless we show that the trained neural networks can be
integrated into a robust optimization model by formulating the adversarial
problem as a convex quadratic mixed-integer program. This allows us to derive
robust solutions through an iterative scenario generation process. We prove
that our class of uncertainty sets contains In extensive computational
experiments, we compare this approach to a similar approach, which derives
uncertainty sets by kernel-based support vector clustering. We find that
uncertainty sets derived by the unsupervised deep learning method can give a
better description of data, leading to robust solutions that often outperform
the comparison method both with respect to objective value and feasibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multistep Electric Vehicle Charging Station Occupancy Prediction using Mixed LSTM Neural Networks. (arXiv:2106.04986v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tai-Yu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Faye_S/0/1/0/all/0/1">S&#xe9;bastien Faye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04986">
                                    <div class="article-summary-box-inner">
                                        <span>Public charging station occupancy prediction plays key importance in
developing a smart charging strategy to reduce electric vehicle (EV) operator
and user inconvenience. However, existing studies are mainly based on
conventional econometric or time series methodologies with limited accuracy. We
propose a new mixed long short-term memory neural network incorporating both
historical charging state sequences and time-related features for multistep
discrete charging occupancy state prediction. Unlike the existing LSTM
networks, the proposed model separates different types of features and handles
them differently with mixed neural network architecture. The model is compared
to a number of state-of-the-art machine learning and deep learning approaches
based on the EV charging data obtained from the open data portal of the city of
Dundee, UK. The results show that the proposed method produces very accurate
predictions (99.99% and 81.87% for 1 step (10 minutes) and 6 step (1 hour)
ahead, respectively, and outperforms the benchmark approaches significantly
(+22.4% for one-step-ahead prediction and +6.2% for 6 steps ahead). A
sensitivity analysis is conducted to evaluate the impact of the model
parameters on prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Parametric Stochastic Sequential Assignment With Random Arrival Times. (arXiv:2106.04944v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dervovic_D/0/1/0/all/0/1">Danial Dervovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassanzadeh_P/0/1/0/all/0/1">Parisa Hassanzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Assefa_S/0/1/0/all/0/1">Samuel Assefa</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_P/0/1/0/all/0/1">Prashant Reddy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04944">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a problem wherein jobs arrive at random times and assume random
values. Upon each job arrival, the decision-maker must decide immediately
whether or not to accept the job and gain the value on offer as a reward, with
the constraint that they may only accept at most $n$ jobs over some reference
time period. The decision-maker only has access to $M$ independent realisations
of the job arrival process. We propose an algorithm, Non-Parametric Sequential
Allocation (NPSA), for solving this problem. Moreover, we prove that the
expected reward returned by the NPSA algorithm converges in probability to
optimality as $M$ grows large. We demonstrate the effectiveness of the
algorithm empirically on synthetic data and on public fraud-detection datasets,
from where the motivation for this work is derived.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-Efficient Transfer Learning with Diff Pruning. (arXiv:2012.07463v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1">Demi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1">Alexander M. Rush</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yoon Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07463">
                                    <div class="article-summary-box-inner">
                                        <span>While task-specific finetuning of pretrained networks has led to significant
empirical advances in NLP, the large size of networks makes finetuning
difficult to deploy in multi-task, memory-constrained settings. We propose diff
pruning as a simple approach to enable parameter-efficient transfer learning
within the pretrain-finetune framework. This approach views finetuning as
learning a task-specific diff vector that is applied on top of the pretrained
parameter vector, which remains fixed and is shared across different tasks. The
diff vector is adaptively pruned during training with a differentiable
approximation to the L0-norm penalty to encourage sparsity. Diff pruning
becomes parameter-efficient as the number of tasks increases, as it requires
storing only the nonzero positions and weights of the diff vector for each
task, while the cost of storing the shared pretrained model remains constant.
It further does not require access to all tasks during training, which makes it
attractive in settings where tasks arrive in stream or the set of tasks is
unknown. We find that models finetuned with diff pruning can match the
performance of fully finetuned baselines on the GLUE benchmark while only
modifying 0.5% of the pretrained model&#x27;s parameters per task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transient Chaos in BERT. (arXiv:2106.03181v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Katsuma Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohara_S/0/1/0/all/0/1">Soh Ohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1">Yasuo Kuniyoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_K/0/1/0/all/0/1">Kohei Nakajima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03181">
                                    <div class="article-summary-box-inner">
                                        <span>Language is an outcome of our complex and dynamic human-interactions and the
technique of natural language processing (NLP) is hence built on human
linguistic activities. Bidirectional Encoder Representations from Transformers
(BERT) has recently gained its popularity by establishing the state-of-the-art
scores in several NLP benchmarks. A Lite BERT (ALBERT) is literally
characterized as a lightweight version of BERT, in which the number of BERT
parameters is reduced by repeatedly applying the same neural network called
Transformer&#x27;s encoder layer. By pre-training the parameters with a massive
amount of natural language data, ALBERT can convert input sentences into
versatile high-dimensional vectors potentially capable of solving multiple NLP
tasks. In that sense, ALBERT can be regarded as a well-designed
high-dimensional dynamical system whose operator is the Transformer&#x27;s encoder,
and essential structures of human language are thus expected to be encapsulated
in its dynamics. In this study, we investigated the embedded properties of
ALBERT to reveal how NLP tasks are effectively solved by exploiting its
dynamics. We thereby aimed to explore the nature of human language from the
dynamical expressions of the NLP model. Our short-term analysis clarified that
the pre-trained model stably yields trajectories with higher dimensionality,
which would enhance the expressive capacity required for NLP tasks. Also, our
long-term analysis revealed that ALBERT intrinsically shows transient chaos, a
typical nonlinear phenomenon showing chaotic dynamics only in its transient,
and the pre-trained ALBERT model tends to produce the chaotic trajectory for a
significantly longer time period compared to a randomly-initialized one. Our
results imply that local chaoticity would contribute to improving NLP
performance, uncovering a novel aspect in the role of chaotic dynamics in human
language behaviors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Node Federated Graph Neural Network for Spatio-Temporal Data Modeling. (arXiv:2106.05223v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1">Chuizheng Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambhatla_S/0/1/0/all/0/1">Sirisha Rambhatla</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05223">
                                    <div class="article-summary-box-inner">
                                        <span>Vast amount of data generated from networks of sensors, wearables, and the
Internet of Things (IoT) devices underscores the need for advanced modeling
techniques that leverage the spatio-temporal structure of decentralized data
due to the need for edge computation and licensing (data access) issues. While
federated learning (FL) has emerged as a framework for model training without
requiring direct data sharing and exchange, effectively modeling the complex
spatio-temporal dependencies to improve forecasting capabilities still remains
an open problem. On the other hand, state-of-the-art spatio-temporal
forecasting models assume unfettered access to the data, neglecting constraints
on data sharing. To bridge this gap, we propose a federated spatio-temporal
model -- Cross-Node Federated Graph Neural Network (CNFGNN) -- which explicitly
encodes the underlying graph structure using graph neural network (GNN)-based
architecture under the constraint of cross-node federated learning, which
requires that data in a network of nodes is generated locally on each node and
remains decentralized. CNFGNN operates by disentangling the temporal dynamics
modeling on devices and spatial dynamics on the server, utilizing alternating
optimization to reduce the communication cost, facilitating computations on the
edge devices. Experiments on the traffic flow forecasting task show that CNFGNN
achieves the best forecasting performance in both transductive and inductive
learning settings with no extra computation cost on edge devices, while
incurring modest communication cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Paced Context Evaluation for Contextual Reinforcement Learning. (arXiv:2106.05110v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eimer_T/0/1/0/all/0/1">Theresa Eimer</a>, <a href="http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1">Andr&#xe9; Biedenkapp</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1">Marius Lindauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05110">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) has made a lot of advances for solving a single
problem in a given environment; but learning policies that generalize to unseen
variations of a problem remains challenging. To improve sample efficiency for
learning on such instances of a problem domain, we present Self-Paced Context
Evaluation (SPaCE). Based on self-paced learning, \spc automatically generates
\task curricula online with little computational overhead. To this end, SPaCE
leverages information contained in state values during training to accelerate
and improve training performance as well as generalization capabilities to new
instances from the same problem domain. Nevertheless, SPaCE is independent of
the problem domain at hand and can be applied on top of any RL agent with
state-value function approximation. We demonstrate SPaCE&#x27;s ability to speed up
learning of different value-based RL agents on two environments, showing better
generalization capabilities and up to 10x faster learning compared to naive
approaches such as round robin or SPDRL, as the closest state-of-the-art
approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EMA2S: An End-to-End Multimodal Articulatory-to-Speech System. (arXiv:2102.03786v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yu-Wen Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Hung_K/0/1/0/all/0/1">Kuo-Hsuan Hung</a>, <a href="http://arxiv.org/find/eess/1/au:+Chuang_S/0/1/0/all/0/1">Shang-Yi Chuang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sherman_J/0/1/0/all/0/1">Jonathan Sherman</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1">Wen-Chin Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_X/0/1/0/all/0/1">Xugang Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1">Yu Tsao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03786">
                                    <div class="article-summary-box-inner">
                                        <span>Synthesized speech from articulatory movements can have real-world use for
patients with vocal cord disorders, situations requiring silent speech, or in
high-noise environments. In this work, we present EMA2S, an end-to-end
multimodal articulatory-to-speech system that directly converts articulatory
movements to speech signals. We use a neural-network-based vocoder combined
with multimodal joint-training, incorporating spectrogram, mel-spectrogram, and
deep features. The experimental results confirm that the multimodal approach of
EMA2S outperforms the baseline system in terms of both objective evaluation and
subjective evaluation metrics. Moreover, results demonstrate that joint
mel-spectrogram and deep feature loss training can effectively improve system
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tight Bounds on the Smallest Eigenvalue of the Neural Tangent Kernel for Deep ReLU Networks. (arXiv:2012.11654v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nguyen_Q/0/1/0/all/0/1">Quynh Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Mondelli_M/0/1/0/all/0/1">Marco Mondelli</a>, <a href="http://arxiv.org/find/stat/1/au:+Montufar_G/0/1/0/all/0/1">Guido Montufar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11654">
                                    <div class="article-summary-box-inner">
                                        <span>A recent line of work has analyzed the theoretical properties of deep neural
networks via the Neural Tangent Kernel (NTK). In particular, the smallest
eigenvalue of the NTK has been related to the memorization capacity, the global
convergence of gradient descent algorithms and the generalization of deep nets.
However, existing results either provide bounds in the two-layer setting or
assume that the spectrum of the NTK matrices is bounded away from 0 for
multi-layer networks. In this paper, we provide tight bounds on the smallest
eigenvalue of NTK matrices for deep ReLU nets, both in the limiting case of
infinite widths and for finite widths. In the finite-width setting, the network
architectures we consider are fairly general: we require the existence of a
wide layer with roughly order of $N$ neurons, $N$ being the number of data
samples; and the scaling of the remaining layer widths is arbitrary (up to
logarithmic factors). To obtain our results, we analyze various quantities of
independent interest: we give lower bounds on the smallest singular value of
hidden feature matrices, and upper bounds on the Lipschitz constant of
input-output feature maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A general approach for Explanations in terms of Middle Level Features. (arXiv:2106.05037v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Apicella_A/0/1/0/all/0/1">Andrea Apicella</a>, <a href="http://arxiv.org/find/cs/1/au:+Isgro_F/0/1/0/all/0/1">Francesco Isgr&#xf2;</a>, <a href="http://arxiv.org/find/cs/1/au:+Prevete_R/0/1/0/all/0/1">Roberto Prevete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05037">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, it is growing interest to make Machine Learning (ML) systems more
understandable and trusting to general users. Thus, generating explanations for
ML system behaviours that are understandable to human beings is a central
scientific and technological issue addressed by the rapidly growing research
area of eXplainable Artificial Intelligence (XAI). Recently, it is becoming
more and more evident that new directions to create better explanations should
take into account what a good explanation is to a human user, and consequently,
develop XAI solutions able to provide user-centred explanations. This paper
suggests taking advantage of developing an XAI general approach that allows
producing explanations for an ML system behaviour in terms of different and
user-selected input features, i.e., explanations composed of input properties
that the human user can select according to his background knowledge and goals.
To this end, we propose an XAI general approach which is able: 1) to construct
explanations in terms of input features that represent more salient and
understandable input properties for a user, which we call here Middle-Level
input Features (MLFs), 2) to be applied to different types of MLFs. We
experimentally tested our approach on two different datasets and using three
different types of MLFs. The results seem encouraging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Avoiding Traps in Nonconvex Problems. (arXiv:2106.05206v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Deyo_S/0/1/0/all/0/1">Sean Deyo</a>, <a href="http://arxiv.org/find/math/1/au:+Elser_V/0/1/0/all/0/1">Veit Elser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05206">
                                    <div class="article-summary-box-inner">
                                        <span>Iterative projection methods may become trapped at non-solutions when the
constraint sets are nonconvex. Two kinds of parameters are available to help
avoid this behavior and this study gives examples of both. The first kind of
parameter, called a hyperparameter, includes any kind of parameter that appears
in the definition of the iteration rule itself. The second kind comprises
metric parameters in the definition of the constraint sets, a feature that
arises when the problem to be solved has two or more kinds of variables.
Through examples we show the importance of properly tuning both kinds of
parameters and offer heuristic interpretations of the observed behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self Normalizing Flows. (arXiv:2011.07248v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_T/0/1/0/all/0/1">T. Anderson Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jorn W.T. Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaini_P/0/1/0/all/0/1">Priyank Jaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1">Emiel Hoogeboom</a>, <a href="http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1">Patrick Forr&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07248">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient gradient computation of the Jacobian determinant term is a core
problem in many machine learning settings, and especially so in the normalizing
flow framework. Most proposed flow models therefore either restrict to a
function class with easy evaluation of the Jacobian determinant, or an
efficient estimator thereof. However, these restrictions limit the performance
of such density models, frequently requiring significant depth to reach desired
performance levels. In this work, we propose Self Normalizing Flows, a flexible
framework for training normalizing flows by replacing expensive terms in the
gradient by learned approximate inverses at each layer. This reduces the
computational complexity of each layer&#x27;s exact update from $\mathcal{O}(D^3)$
to $\mathcal{O}(D^2)$, allowing for the training of flow architectures which
were otherwise computationally infeasible, while also providing efficient
sampling. We show experimentally that such models are remarkably stable and
optimize to similar data likelihood values as their exact gradient
counterparts, while training more quickly and surpassing the performance of
functionally constrained counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Point of Gaze Estimator for Low-Resolution Imaging Systems Using Extracted Ocular Features Based Neural Architecture. (arXiv:2106.05106v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sahay_A/0/1/0/all/0/1">Atul Sahay</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_I/0/1/0/all/0/1">Imon Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Arya_K/0/1/0/all/0/1">Kavi Arya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05106">
                                    <div class="article-summary-box-inner">
                                        <span>A user&#x27;s eyes provide means for Human Computer Interaction (HCI) research as
an important modal. The time to time scientific explorations of the eye has
already seen an upsurge of the benefits in HCI applications from gaze
estimation to the measure of attentiveness of a user looking at a screen for a
given time period. The eye tracking system as an assisting, interactive tool
can be incorporated by physically disabled individuals, fitted best for those
who have eyes as only a limited set of communication. The threefold objective
of this paper is - 1. To introduce a neural network based architecture to
predict users&#x27; gaze at 9 positions displayed in the 11.31{\deg} visual range on
the screen, through a low resolution based system such as a webcam in real time
by learning various aspects of eyes as an ocular feature set. 2.A collection of
coarsely supervised feature set obtained in real time which is also validated
through the user case study presented in the paper for 21 individuals ( 17 men
and 4 women ) from whom a 35k set of instances was derived with an accuracy
score of 82.36% and f1_score of 82.2% and 3.A detailed study over applicability
and underlying challenges of such systems. The experimental results verify the
feasibility and validity of the proposed eye gaze tracking model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-Server Private Linear Transformation: The Joint Privacy Case. (arXiv:2106.05220v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heidarzadeh_A/0/1/0/all/0/1">Anoosheh Heidarzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Esmati_N/0/1/0/all/0/1">Nahid Esmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprintson_A/0/1/0/all/0/1">Alex Sprintson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05220">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the problem of Private Linear Transformation (PLT)
which generalizes the problems of private information retrieval and private
linear computation. The PLT problem includes one or more remote server(s)
storing (identical copies of) $K$ messages and a user who wants to compute $L$
independent linear combinations of a $D$-subset of messages. The objective of
the user is to perform the computation by downloading minimum possible amount
of information from the server(s), while protecting the identities of the $D$
messages required for the computation. In this work, we focus on the
single-server setting of the PLT problem when the identities of the $D$
messages required for the computation must be protected jointly. We consider
two different models, depending on whether the coefficient matrix of the
required $L$ linear combinations generates a Maximum Distance Separable (MDS)
code. We prove that the capacity for both models is given by $L/(K-D+L)$, where
the capacity is defined as the supremum of all achievable download rates. Our
converse proofs are based on linear-algebraic and information-theoretic
arguments that establish connections between PLT schemes and linear codes. We
also present an achievability scheme for each of the models being considered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More than meets the eye: Self-supervised depth reconstruction from brain activity. (arXiv:2106.05113v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gaziv_G/0/1/0/all/0/1">Guy Gaziv</a>, <a href="http://arxiv.org/find/cs/1/au:+Irani_M/0/1/0/all/0/1">Michal Irani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05113">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, significant advancements were made in reconstruction
of observed natural images from fMRI brain recordings using deep-learning
tools. Here, for the first time, we show that dense 3D depth maps of observed
2D natural images can also be recovered directly from fMRI brain recordings. We
use an off-the-shelf method to estimate the unknown depth maps of natural
images. This is applied to both: (i) the small number of images presented to
subjects in an fMRI scanner (images for which we have fMRI recordings -
referred to as &quot;paired&quot; data), and (ii) a very large number of natural images
with no fMRI recordings (&quot;unpaired data&quot;). The estimated depth maps are then
used as an auxiliary reconstruction criterion to train for depth reconstruction
directly from fMRI. We propose two main approaches: Depth-only recovery and
joint image-depth RGBD recovery. Because the number of available &quot;paired&quot;
training data (images with fMRI) is small, we enrich the training data via
self-supervised cycle-consistent training on many &quot;unpaired&quot; data (natural
images &amp; depth maps without fMRI). This is achieved using our newly defined and
trained Depth-based Perceptual Similarity metric as a reconstruction criterion.
We show that predicting the depth map directly from fMRI outperforms its
indirect sequential recovery from the reconstructed images. We further show
that activations from early cortical visual areas dominate our depth
reconstruction results, and propose means to characterize fMRI voxels by their
degree of depth-information tuning. This work adds an important layer of
decoded information, extending the current envelope of visual brain decoding
capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Significance tests of feature relevance for a blackbox learner. (arXiv:2103.04985v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dai_B/0/1/0/all/0/1">Ben Dai</a>, <a href="http://arxiv.org/find/stat/1/au:+Shen_X/0/1/0/all/0/1">Xiaotong Shen</a>, <a href="http://arxiv.org/find/stat/1/au:+Pan_W/0/1/0/all/0/1">Wei Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04985">
                                    <div class="article-summary-box-inner">
                                        <span>An exciting recent development is the uptake of deep learning in many
scientific fields, where the objective is seeking novel scientific insights and
discoveries. To interpret a learning outcome, researchers perform hypothesis
testing for explainable features to advance scientific domain knowledge. In
such a situation, testing for a blackbox learner poses a severe challenge
because of intractable models, unknown limiting distributions of parameter
estimates, and high computational constraints. In this article, we derive two
consistent tests for the feature relevance of a blackbox learner. The first one
evaluates a loss difference with perturbation on an inference sample, which is
independent of an estimation sample used for parameter estimation in model
fitting. The second further splits the inference sample into two but does not
require data perturbation. Also, we develop their combined versions by
aggregating the order statistics of the $p$-values based on repeated sample
splitting. To estimate the splitting ratio and the perturbation size, we
develop adaptive splitting schemes for suitably controlling the Type \rom{1}
error subject to computational constraints. By deflating the
\textit{bias-sd-ratio}, we establish asymptotic null distributions of the test
statistics and their consistency in terms of statistical power. Our theoretical
power analysis and simulations indicate that the one-split test is more
powerful than the two-split test, though the latter is easier to apply for
large datasets. Moreover, the combined tests are more stable while compensating
for a power loss by repeated sample splitting. Numerically, we demonstrate the
utility of the proposed tests on two benchmark examples. Accompanying this
paper is our Python library {\tt dnn-inference}
https://dnn-inference.readthedocs.io/en/latest/ that implements the proposed
tests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recovering AES Keys with a Deep Cold Boot Attack. (arXiv:2106.04876v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimerman_I/0/1/0/all/0/1">Itamar Zimerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1">Eliya Nachmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04876">
                                    <div class="article-summary-box-inner">
                                        <span>Cold boot attacks inspect the corrupted random access memory soon after the
power has been shut down. While most of the bits have been corrupted, many
bits, at random locations, have not. Since the keys in many encryption schemes
are being expanded in memory into longer keys with fixed redundancies, the keys
can often be restored. In this work, we combine a novel cryptographic variant
of a deep error correcting code technique with a modified SAT solver scheme to
apply the attack on AES keys. Even though AES consists of Rijndael S-box
elements, that are specifically designed to be resistant to linear and
differential cryptanalysis, our method provides a novel formalization of the
AES key scheduling as a computational graph, which is implemented by a neural
message passing network. Our results show that our methods outperform the state
of the art attack methods by a very large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias-Robust Bayesian Optimization via Dueling Bandits. (arXiv:2105.11802v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kirschner_J/0/1/0/all/0/1">Johannes Kirschner</a>, <a href="http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11802">
                                    <div class="article-summary-box-inner">
                                        <span>We consider Bayesian optimization in settings where observations can be
adversarially biased, for example by an uncontrolled hidden confounder. Our
first contribution is a reduction of the confounded setting to the dueling
bandit model. Then we propose a novel approach for dueling bandits based on
information-directed sampling (IDS). Thereby, we obtain the first efficient
kernelized algorithm for dueling bandits that comes with cumulative regret
guarantees. Our analysis further generalizes a previously proposed
semi-parametric linear bandit model to non-linear reward functions, and
uncovers interesting links to doubly-robust estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Graph Learning with Hyperbolic Embedding for Temporal Health Event Prediction. (arXiv:2106.04751v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1">Chandan K. Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ning_Y/0/1/0/all/0/1">Yue Ning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04751">
                                    <div class="article-summary-box-inner">
                                        <span>Electronic Health Records (EHR) have been heavily used in modern healthcare
systems for recording patients&#x27; admission information to hospitals. Many
data-driven approaches employ temporal features in EHR for predicting specific
diseases, readmission times, or diagnoses of patients. However, most existing
predictive models cannot fully utilize EHR data, due to an inherent lack of
labels in supervised training for some temporal events. Moreover, it is hard
for existing works to simultaneously provide generic and personalized
interpretability. To address these challenges, we first propose a hyperbolic
embedding method with information flow to pre-train medical code
representations in a hierarchical structure. We incorporate these pre-trained
representations into a graph neural network to detect disease complications,
and design a multi-level attention method to compute the contributions of
particular diseases and admissions, thus enhancing personalized
interpretability. We present a new hierarchy-enhanced historical prediction
proxy task in our self-supervised learning framework to fully utilize EHR data
and exploit medical domain knowledge. We conduct a comprehensive set of
experiments and case studies on widely used publicly available EHR datasets to
verify the effectiveness of our model. The results demonstrate our model&#x27;s
strengths in both predictive tasks and interpretable abilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Which transformer architecture fits my data? A vocabulary bottleneck in self-attention. (arXiv:2105.03928v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wies_N/0/1/0/all/0/1">Noam Wies</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1">Yoav Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Jannai_D/0/1/0/all/0/1">Daniel Jannai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1">Amnon Shashua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03928">
                                    <div class="article-summary-box-inner">
                                        <span>After their successful debut in natural language processing, Transformer
architectures are now becoming the de-facto standard in many domains. An
obstacle for their deployment over new modalities is the architectural
configuration: the optimal depth-to-width ratio has been shown to dramatically
vary across data types (e.g., $10$x larger over images than over language). We
theoretically predict the existence of an embedding rank bottleneck that limits
the contribution of self-attention width to the Transformer expressivity. We
thus directly tie the input vocabulary size and rank to the optimal
depth-to-width ratio, since a small vocabulary size or rank dictates an added
advantage of depth over width. We empirically demonstrate the existence of this
bottleneck and its implications on the depth-to-width interplay of Transformer
architectures, linking the architecture variability across domains to the often
glossed-over usage of different vocabulary sizes or embedding ranks in
different domains. As an additional benefit, our rank bottlenecking framework
allows us to identify size redundancies of $25\%-50\%$ in leading NLP models
such as ALBERT and T5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Music Generation using Three-layered LSTM. (arXiv:2105.09046v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ingale_V/0/1/0/all/0/1">Vaishali Ingale</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_A/0/1/0/all/0/1">Anush Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Adlakha_D/0/1/0/all/0/1">Divit Adlakha</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1">Krishan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Mohit Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09046">
                                    <div class="article-summary-box-inner">
                                        <span>This paper explores the idea of utilising Long Short-Term Memory neural
networks (LSTMNN) for the generation of musical sequences in ABC notation. The
proposed approach takes ABC notations from the Nottingham dataset and encodes
it to be fed as input for the neural networks. The primary objective is to
input the neural networks with an arbitrary note, let the network process and
augment a sequence based on the note until a good piece of music is produced.
Multiple calibrations have been done to amend the parameters of the network for
optimal generation. The output is assessed on the basis of rhythm, harmony, and
grammar accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonlinear Invariant Risk Minimization: A Causal Approach. (arXiv:2102.12353v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chaochao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuhuai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1">Jo&#x15b;e Miguel Hern&#xe1;ndez-Lobato</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12353">
                                    <div class="article-summary-box-inner">
                                        <span>Due to spurious correlations, machine learning systems often fail to
generalize to environments whose distributions differ from the ones used at
training time. Prior work addressing this, either explicitly or implicitly,
attempted to find a data representation that has an invariant relationship with
the target. This is done by leveraging a diverse set of training environments
to reduce the effect of spurious features and build an invariant predictor.
However, these methods have generalization guarantees only when both data
representation and classifiers come from a linear model class. We propose
invariant Causal Representation Learning (iCaRL), an approach that enables
out-of-distribution (OOD) generalization in the nonlinear setting (i.e.,
nonlinear representations and nonlinear classifiers). It builds upon a
practical and general assumption: the prior over the data representation (i.e.,
a set of latent variables encoding the data) given the target and the
environment belongs to general exponential family distributions. Based on this,
we show that it is possible to identify the data representation up to simple
transformations. We also prove that all direct causes of the target can be
fully discovered, which further enables us to obtain generalization guarantees
in the nonlinear setting. Extensive experiments on both synthetic and
real-world datasets show that our approach outperforms a variety of baseline
methods. Finally, in the discussion, we further explore the aforementioned
assumption and propose a more general hypothesis, called the Agnostic
Hypothesis: there exist a set of hidden causal factors affecting both inputs
and outcomes. The Agnostic Hypothesis can provide a unifying view of machine
learning. More importantly, it can inspire a new direction to explore a general
theory for identifying hidden causal factors, which is key to enabling the OOD
generalization guarantees.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Periodic-GP: Learning Periodic World with Gaussian Process Bandits. (arXiv:2105.14422v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hengrui Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cen_Z/0/1/0/all/0/1">Zhihao Cen</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_L/0/1/0/all/0/1">Ling Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Rui Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14422">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the sequential decision optimization on the periodic environment,
that occurs in a wide variety of real-world applications when the data involves
seasonality, such as the daily demand of drivers in ride-sharing and dynamic
traffic patterns in transportation. In this work, we focus on learning the
stochastic periodic world by leveraging this seasonal law. To deal with the
general action space, we use the bandit based on Gaussian process (GP) as the
base model due to its flexibility and generality, and propose the Periodic-GP
method with a temporal periodic kernel based on the upper confidence bound.
Theoretically, we provide a new regret bound of the proposed method, by
explicitly characterizing the periodic kernel in the periodic stationary model.
Empirically, the proposed algorithm significantly outperforms the existing
methods in both synthetic data experiments and a real data application on
Madrid traffic pollution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-based Optimization Methods for Model-Agnostic Meta-Learning. (arXiv:2106.04911v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bokun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhuoning Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1">Yiming Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04911">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, model-agnostic meta-learning (MAML) has garnered tremendous
attention. However, stochastic optimization of MAML is still immature. Existing
algorithms for MAML are based on the &#x60;&#x60;episode&quot; idea by sampling a number of
tasks and a number of data points for each sampled task at each iteration for
updating the meta-model. However, they either do not necessarily guarantee
convergence with a constant mini-batch size or require processing a larger
number of tasks at every iteration, which is not viable for continual learning
or cross-device federated learning where only a small number of tasks are
available per-iteration or per-round. This paper addresses these issues by (i)
proposing efficient memory-based stochastic algorithms for MAML with a
diminishing convergence error, which only requires sampling a constant number
of tasks and a constant number of examples per-task per-iteration; (ii)
proposing communication-efficient distributed memory-based MAML algorithms for
personalized federated learning in both the cross-device (w/ client sampling)
and the cross-silo (w/o client sampling) settings. The key novelty of the
proposed algorithms is to maintain an individual personalized model (aka
memory) for each task besides the meta-model and only update them for the
sampled tasks by a momentum method that incorporates historical updates at each
iteration. The theoretical results significantly improve the optimization
theory for MAML and the empirical results also corroborate the theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effect of large-scale pre-training on full and few-shot transfer learning for natural and medical images. (arXiv:2106.00116v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1">Mehdi Cherti</a>, <a href="http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1">Jenia Jitsev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00116">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning aims to exploit pre-trained models for more efficient
follow-up training on wide range of downstream tasks and datasets, enabling
successful training also on small data. Recent line of work posits strong
benefits for model generalization and transfer when model size, data size, and
compute budget are increased for the pre-training. It remains however still
largely unclear whether the observed transfer improvement due to increase in
scale also holds when source and target data distributions are far apart from
each other. In this work we conduct large-scale pre-training on large source
datasets of either natural (ImageNet-21k/1k) or medical chest X-Ray images and
compare full and few-shot transfer using different target datasets from both
natural and medical imaging domains. Our observations provide evidence that
while pre-training and transfer on closely related datasets do show clear
benefit of increasing model and data size during pre-training, such benefits
are not clearly visible when source and target datasets are further apart.
These observations hold across both full and few-shot transfer and indicate
that scaling laws pointing to improvement of generalization and transfer with
increasing model and data size are incomplete and should be revised by taking
into account the type and proximity of the source and target data, to correctly
predict the effect of model and data scale during pre-training on transfer.
Remarkably, in full shot transfer to a large X-Ray chest imaging target
(PadChest), the largest model pre-trained on ImageNet-21k slightly outperforms
best models pre-trained on large X-Ray chest imaging data. This indicates
possibility to obtain high quality models for domain-specific transfer even
without access to large domain-specific data, by pre-training instead on
comparably very large, generic source data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TempoRL: Learning When to Act. (arXiv:2106.05262v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biedenkapp_A/0/1/0/all/0/1">Andr&#xe9; Biedenkapp</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_R/0/1/0/all/0/1">Raghu Rajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1">Marius Lindauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05262">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning is a powerful approach to learn behaviour through
interactions with an environment. However, behaviours are usually learned in a
purely reactive fashion, where an appropriate action is selected based on an
observation. In this form, it is challenging to learn when it is necessary to
execute new decisions. This makes learning inefficient, especially in
environments that need various degrees of fine and coarse control. To address
this, we propose a proactive setting in which the agent not only selects an
action in a state but also for how long to commit to that action. Our TempoRL
approach introduces skip connections between states and learns a skip-policy
for repeating the same action along these skips. We demonstrate the
effectiveness of TempoRL on a variety of traditional and deep RL environments,
showing that our approach is capable of learning successful policies up to an
order of magnitude faster than vanilla Q-learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Transformers Are Secretly Fast Weight Programmers. (arXiv:2102.11174v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schlag_I/0/1/0/all/0/1">Imanol Schlag</a>, <a href="http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1">Kazuki Irie</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11174">
                                    <div class="article-summary-box-inner">
                                        <span>We show the formal equivalence of linearised self-attention mechanisms and
fast weight controllers from the early &#x27;90s, where a &#x60;&#x60;slow&quot; neural net learns
by gradient descent to program the &#x60;&#x60;fast weights&quot; of another net through
sequences of elementary programming instructions which are additive outer
products of self-invented activation patterns (today called keys and values).
Such Fast Weight Programmers (FWPs) learn to manipulate the contents of a
finite memory and dynamically interact with it. We infer a memory capacity
limitation of recent linearised softmax attention variants, and replace the
purely additive outer products by a delta rule-like programming instruction,
such that the FWP can more easily learn to correct the current mapping from
keys to values. The FWP also learns to compute dynamically changing learning
rates. We also propose a new kernel function to linearise attention which
balances simplicity and effectiveness. We conduct experiments on synthetic
retrieval problems as well as standard machine translation and language
modelling tasks which demonstrate the benefits of our methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GP-ConvCNP: Better Generalization for Convolutional Conditional Neural Processes on Time Series Data. (arXiv:2106.04967v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Petersen_J/0/1/0/all/0/1">Jens Petersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohler_G/0/1/0/all/0/1">Gregor K&#xf6;hler</a>, <a href="http://arxiv.org/find/cs/1/au:+Zimmerer_D/0/1/0/all/0/1">David Zimmerer</a>, <a href="http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/cs/1/au:+Jager_P/0/1/0/all/0/1">Paul F. J&#xe4;ger</a>, <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1">Klaus H. Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04967">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Processes (NPs) are a family of conditional generative models that are
able to model a distribution over functions, in a way that allows them to
perform predictions at test time conditioned on a number of context points. A
recent addition to this family, Convolutional Conditional Neural Processes
(ConvCNP), have shown remarkable improvement in performance over prior art, but
we find that they sometimes struggle to generalize when applied to time series
data. In particular, they are not robust to distribution shifts and fail to
extrapolate observed patterns into the future. By incorporating a Gaussian
Process into the model, we are able to remedy this and at the same time improve
performance within distribution. As an added benefit, the Gaussian Process
reintroduces the possibility to sample from the model, a key feature of other
members in the NP family.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning for Many-to-many Multilingual Neural Machine Translation. (arXiv:2105.09501v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xiao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09501">
                                    <div class="article-summary-box-inner">
                                        <span>Existing multilingual machine translation approaches mainly focus on
English-centric directions, while the non-English directions still lag behind.
In this work, we aim to build a many-to-many translation system with an
emphasis on the quality of non-English language directions. Our intuition is
based on the hypothesis that a universal cross-language representation leads to
better multilingual translation performance. To this end, we propose mRASP2, a
training method to obtain a single unified multilingual translation model.
mRASP2 is empowered by two techniques: a) a contrastive learning scheme to
close the gap among representations of different languages, and b) data
augmentation on both multiple parallel and monolingual data to further align
token representations. For English-centric directions, mRASP2 outperforms
existing best unified model and achieves competitive or even better performance
than the pre-trained and fine-tuned model mBART on tens of WMT&#x27;s translation
directions. For non-English directions, mRASP2 achieves an improvement of
average 10+ BLEU compared with the multilingual Transformer baseline. Code,
data and trained models are available at https://github.com/PANXiao1994/mRASP2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Binary Neural Network Operation from 233 K to 398 K via Gate Stack and Bias Optimization of Ferroelectric FinFET Synapses. (arXiv:2103.03111v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+De_S/0/1/0/all/0/1">Sourav De</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hoang-Hiep Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_B/0/1/0/all/0/1">Bo-Han Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Baig_M/0/1/0/all/0/1">Md. Aftab Baig</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_P/0/1/0/all/0/1">Po-Jung Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chung Jun Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yao-Jen Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">Darsen D. Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03111">
                                    <div class="article-summary-box-inner">
                                        <span>A synergistic approach for optimizing devices, circuits, and neural network
architectures was used to abate junction-temperature-change-induced performance
degradation of a Fe-FinFET-based artificial neural network. We demonstrated
that the digital nature of the binarized neural network, with the &quot;0&quot; state
programmed deep in the subthreshold and the &quot;1&quot; state in strong inversion, is
crucial for robust DNN inference. The performance of a purely software-based
binary neural network (BNN), with 96.1% accuracy for Modified National
Institute of Standards and Technology (MNIST) handwritten digit recognition,
was used as a baseline. The Fe-FinFET-based BNN (including device-to-device
variation at 300 K) achieved 95.7% inference accuracy on the MNIST dataset.
Although substantial inference accuracy degradation with temperature change was
observed in a nonbinary neural network, the BNN with optimized Fe-FinFETs as
synaptic devices had excellent resistance to temperature change effects and
maintained a minimum inference accuracy of 95.2% within a temperature range of
-233K to 398K after gate stack and bias optimization. However, reprogramming to
adjust device conductance was necessary for temperatures higher than 398K.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autobahn: Automorphism-based Graph Neural Nets. (arXiv:2103.01710v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thiede_E/0/1/0/all/0/1">Erik Henning Thiede</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wenda Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1">Risi Kondor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01710">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Automorphism-based graph neural networks (Autobahn), a new
family of graph neural networks. In an Autobahn, we decompose the graph into a
collection of subgraphs and apply local convolutions that are equivariant to
each subgraph&#x27;s automorphism group. Specific choices of local neighborhoods and
subgraphs recover existing architectures such as message passing neural
networks. Our formalism also encompasses novel architectures: as an example, we
introduce a graph neural network that decomposes the graph into paths and
cycles. The resulting convolutions reflect the natural way that parts of the
graph can transform, preserving the intuitive meaning of convolution without
sacrificing global permutation equivariance. We validate our approach by
applying Autobahn to molecular graphs, where it achieves state-of-the-art
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Annealing for Automated Feature Selection in Stress Detection. (arXiv:2106.05134v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Nath_R/0/1/0/all/0/1">Rajdeep Kumar Nath</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Thapliyal_H/0/1/0/all/0/1">Himanshu Thapliyal</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Humble_T/0/1/0/all/0/1">Travis S. Humble</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05134">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel methodology for automated feature subset selection from a
pool of physiological signals using Quantum Annealing (QA). As a case study, we
will investigate the effectiveness of QA-based feature selection techniques in
selecting the optimal feature subset for stress detection. Features are
extracted from four signal sources: foot EDA, hand EDA, ECG, and respiration.
The proposed method embeds the feature variables extracted from the
physiological signals in a binary quadratic model. The bias of the feature
variable is calculated using the Pearson correlation coefficient between the
feature variable and the target variable. The weight of the edge connecting the
two feature variables is calculated using the Pearson correlation coefficient
between two feature variables in the binary quadratic model. Subsequently,
D-Wave&#x27;s clique sampler is used to sample cliques from the binary quadratic
model. The underlying solution is then re-sampled to obtain multiple good
solutions and the clique with the lowest energy is returned as the optimal
solution. The proposed method is compared with commonly used feature selection
techniques for stress detection. Results indicate that QA-based feature subset
selection performed equally as that of classical techniques. However, under
data uncertainty conditions such as limited training data, the performance of
quantum annealing for selecting optimum features remained unaffected, whereas a
significant decrease in performance is observed with classical feature
selection techniques. Preliminary results show the promise of quantum annealing
in optimizing the training phase of a machine learning classifier, especially
under data uncertainty conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and More Powerful Selective Inference for Sparse High-order Interaction Model. (arXiv:2106.04929v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Das_D/0/1/0/all/0/1">Diptesh Das</a>, <a href="http://arxiv.org/find/stat/1/au:+Duy_V/0/1/0/all/0/1">Vo Nguyen Le Duy</a>, <a href="http://arxiv.org/find/stat/1/au:+Hanada_H/0/1/0/all/0/1">Hiroyuki Hanada</a>, <a href="http://arxiv.org/find/stat/1/au:+Tsuda_K/0/1/0/all/0/1">Koji Tsuda</a>, <a href="http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1">Ichiro Takeuchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04929">
                                    <div class="article-summary-box-inner">
                                        <span>Automated high-stake decision-making such as medical diagnosis requires
models with high interpretability and reliability. As one of the interpretable
and reliable models with good prediction ability, we consider Sparse High-order
Interaction Model (SHIM) in this study. However, finding statistically
significant high-order interactions is challenging due to the intrinsic high
dimensionality of the combinatorial effects. Another problem in data-driven
modeling is the effect of &quot;cherry-picking&quot; a.k.a. selection bias. Our main
contribution is to extend the recently developed parametric programming
approach for selective inference to high-order interaction models. Exhaustive
search over the cherry tree (all possible interactions) can be daunting and
impractical even for a small-sized problem. We introduced an efficient pruning
strategy and demonstrated the computational efficiency and statistical power of
the proposed method using both synthetic and real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is it Enough to Optimize CNN Architectures on ImageNet?. (arXiv:2103.09108v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1">Lukas Tuggener</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1">J&#xfc;rgen Schmidhuber</a>, <a href="http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1">Thilo Stadelmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09108">
                                    <div class="article-summary-box-inner">
                                        <span>An implicit but pervasive hypothesis of modern computer vision research is
that convolutional neural network (CNN) architectures that perform better on
ImageNet will also perform better on other vision datasets. We challenge this
hypothesis through an extensive empirical study for which we train 500 sampled
CNN architectures on ImageNet as well as 8 other image classification datasets
from a wide array of application domains. The relationship between architecture
and performance varies wildly, depending on the datasets. For some of them, the
performance correlation with ImageNet is even negative. Clearly, it is not
enough to optimize architectures solely for ImageNet when aiming for progress
that is relevant for all applications. Therefore, we identify two
dataset-specific performance indicators: the cumulative width across layers as
well as the total depth of the network. Lastly, we show that the range of
dataset variability covered by ImageNet can be significantly extended by adding
ImageNet subsets restricted to few classes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedDR -- Randomized Douglas-Rachford Splitting Algorithms for Nonconvex Federated Composite Optimization. (arXiv:2103.03452v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tran_Dinh_Q/0/1/0/all/0/1">Quoc Tran-Dinh</a>, <a href="http://arxiv.org/find/stat/1/au:+Pham_N/0/1/0/all/0/1">Nhan H. Pham</a>, <a href="http://arxiv.org/find/stat/1/au:+Phan_D/0/1/0/all/0/1">Dzung T. Phan</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_L/0/1/0/all/0/1">Lam M. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03452">
                                    <div class="article-summary-box-inner">
                                        <span>We develop two new algorithms, called, FedDR and asyncFedDR, for solving a
fundamental nonconvex composite optimization problem in federated learning. Our
algorithms rely on a novel combination between a nonconvex Douglas-Rachford
splitting method, randomized block-coordinate strategies, and asynchronous
implementation. They can also handle convex regularizers. Unlike recent methods
in the literature, e.g., FedSplit and FedPD, our algorithms update only a
subset of users at each communication round, and possibly in an asynchronous
manner, making them more practical. These new algorithms also achieve
communication efficiency and more importantly can handle statistical and system
heterogeneity, which are the two main challenges in federated learning. Our
convergence analysis shows that the new algorithms match the communication
complexity lower bound up to a constant factor under standard assumptions. Our
numerical experiments illustrate the advantages of our methods compared to
existing ones on several datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Reliable Process Event Streams and Time Series Data based on Neural Networks. (arXiv:2103.05462v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Herbert_T/0/1/0/all/0/1">Tobias Herbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangler_J/0/1/0/all/0/1">Juergen Mangler</a>, <a href="http://arxiv.org/find/cs/1/au:+Rinderle_Ma_S/0/1/0/all/0/1">Stefanie Rinderle-Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05462">
                                    <div class="article-summary-box-inner">
                                        <span>Domains such as manufacturing and medicine crave for continuous monitoring
and analysis of their processes, especially in combination with time series as
produced by sensors. Time series data can be exploited to, for example, explain
and predict concept drifts during runtime. Generally, a certain data volume is
required in order to produce meaningful analysis results. However, reliable
data sets are often missing, for example, if event streams and times series
data are collected separately, in case of a new process, or if it is too
expensive to obtain a sufficient data volume. Additional challenges arise with
preparing time series data from multiple event sources, variations in data
collection frequency, and concept drift. This paper proposes the GENLOG
approach to generate reliable event and time series data that follows the
distribution of the underlying input data set. GENLOG employs data resampling
and enables the user to select different parts of the log data to orchestrate
the training of a recurrent neural network for stream generation. The generated
data is sampled back to its original sample rate and is embedded into the
originating log data file. Overall, GENLOG can boost small data sets and
consequently the application of online process mining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Objective Robustness in Deep Reinforcement Learning. (arXiv:2105.14111v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koch_J/0/1/0/all/0/1">Jack Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Langosco_L/0/1/0/all/0/1">Lauro Langosco</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfau_J/0/1/0/all/0/1">Jacob Pfau</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_J/0/1/0/all/0/1">James Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharkey_L/0/1/0/all/0/1">Lee Sharkey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14111">
                                    <div class="article-summary-box-inner">
                                        <span>We study objective robustness failures, a type of out-of-distribution
robustness failure in reinforcement learning (RL). Objective robustness
failures occur when an RL agent retains its capabilities out-of-distribution
yet pursues the wrong objective. This kind of failure presents different risks
than the robustness problems usually considered in the literature, since it
involves agents that leverage their capabilities to pursue the wrong objective
rather than simply failing to do anything useful. We provide the first explicit
empirical demonstrations of objective robustness failures and present a partial
characterization of its causes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPINN: Sparse, Physics-based, and Interpretable Neural Networks for PDEs. (arXiv:2102.13037v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramabathiran_A/0/1/0/all/0/1">Amuthan A. Ramabathiran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1">Prabhu Ramachandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13037">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a class of Sparse, Physics-based, and Interpretable Neural
Networks (SPINN) for solving ordinary and partial differential equations
(PDEs). By reinterpreting a traditional meshless representation of solutions of
PDEs we develop a class of sparse neural network architectures that are
interpretable. The SPINN model we propose here serves as a seamless bridge
between two extreme modeling tools for PDEs, namely dense neural network based
methods like Physics Informed Neural Networks (PINNs) and traditional mesh-free
numerical methods, thereby providing a novel means to develop a new class of
hybrid algorithms that build on the best of both these viewpoints. A unique
feature of the SPINN model that distinguishes it from other neural network
based approximations proposed earlier is that it is (i) interpretable, and (ii)
sparse in the sense that it has much fewer connections than typical dense
neural networks used for PDEs. Further, the SPINN algorithm implicitly encodes
mesh adaptivity and is able to handle discontinuities in the solutions. In
addition, we demonstrate that Fourier series representations can also be
expressed as a special class of SPINN and propose generalized neural network
analogues of Fourier representations. We illustrate the utility of the proposed
method with a variety of examples involving ordinary differential equations,
elliptic, parabolic, hyperbolic and nonlinear partial differential equations,
and an example in fluid dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fully differentiable model discovery. (arXiv:2106.04886v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Both_G/0/1/0/all/0/1">Gert-Jan Both</a>, <a href="http://arxiv.org/find/stat/1/au:+Kusters_R/0/1/0/all/0/1">Remy Kusters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04886">
                                    <div class="article-summary-box-inner">
                                        <span>Model discovery aims at autonomously discovering differential equations
underlying a dataset. Approaches based on Physics Informed Neural Networks
(PINNs) have shown great promise, but a fully-differentiable model which
explicitly learns the equation has remained elusive. In this paper we propose
such an approach by combining neural network based surrogates with Sparse
Bayesian Learning (SBL). We start by reinterpreting PINNs as multitask models,
applying multitask learning using uncertainty, and show that this leads to a
natural framework for including Bayesian regression techniques. We then
construct a robust model discovery algorithm by using SBL, which we showcase on
various datasets. Concurrently, the multitask approach allows the use of
probabilistic approximators, and we show a proof of concept using normalizing
flows to directly learn a density model from single particle data. Our work
expands PINNs to various types of neural network architectures, and connects
neural network-based surrogates to the rich field of Bayesian parameter
inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WGAN with an Infinitely Wide Generator Has No Spurious Stationary Points. (arXiv:2102.07541v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1">Albert No</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_T/0/1/0/all/0/1">TaeHo Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1">Sehyun Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryu_E/0/1/0/all/0/1">Ernest K. Ryu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07541">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GAN) are a widely used class of deep
generative models, but their minimax training dynamics are not understood very
well. In this work, we show that GANs with a 2-layer infinite-width generator
and a 2-layer finite-width discriminator trained with stochastic gradient
ascent-descent have no spurious stationary points. We then show that when the
width of the generator is finite but wide, there are no spurious stationary
points within a ball whose radius becomes arbitrarily large (to cover the
entire parameter space) as the width goes to infinity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does the Adam Optimizer Exacerbate Catastrophic Forgetting?. (arXiv:2102.07686v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1">Dylan R. Ashley</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1">Sina Ghiassian</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1">Richard S. Sutton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07686">
                                    <div class="article-summary-box-inner">
                                        <span>Catastrophic forgetting remains a severe hindrance to the broad application
of artificial neural networks (ANNs), however, it continues to be a poorly
understood phenomenon. Despite the extensive amount of work on catastrophic
forgetting, we argue that it is still unclear how exactly the phenomenon should
be quantified, and, moreover, to what degree all of the choices we make when
designing learning systems affect the amount of catastrophic forgetting. We use
various testbeds from the reinforcement learning and supervised learning
literature to (1) provide evidence that the choice of which modern
gradient-based optimization algorithm is used to train an ANN has a significant
impact on the amount of catastrophic forgetting and show that-surprisingly-in
many instances classical algorithms such as vanilla SGD experience less
catastrophic forgetting than the more modern algorithms such as Adam. We
empirically compare four different existing metrics for quantifying
catastrophic forgetting and (2) show that the degree to which the learning
systems experience catastrophic forgetting is sufficiently sensitive to the
metric used that a change from one principled metric to another is enough to
change the conclusions of a study dramatically. Our results suggest that a much
more rigorous experimental methodology is required when looking at catastrophic
forgetting. Based on our results, we recommend inter-task forgetting in
supervised learning must be measured with both retention and relearning metrics
concurrently, and intra-task forgetting in reinforcement learning must-at the
very least-be measured with pairwise interference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse Algorithms for Markovian Gaussian Processes. (arXiv:2103.10710v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wilkinson_W/0/1/0/all/0/1">William J. Wilkinson</a>, <a href="http://arxiv.org/find/stat/1/au:+Solin_A/0/1/0/all/0/1">Arno Solin</a>, <a href="http://arxiv.org/find/stat/1/au:+Adam_V/0/1/0/all/0/1">Vincent Adam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10710">
                                    <div class="article-summary-box-inner">
                                        <span>Approximate Bayesian inference methods that scale to very large datasets are
crucial in leveraging probabilistic models for real-world time series. Sparse
Markovian Gaussian processes combine the use of inducing variables with
efficient Kalman filter-like recursions, resulting in algorithms whose
computational and memory requirements scale linearly in the number of inducing
points, whilst also enabling parallel parameter updates and stochastic
optimisation. Under this paradigm, we derive a general site-based approach to
approximate inference, whereby we approximate the non-Gaussian likelihood with
local Gaussian terms, called sites. Our approach results in a suite of novel
sparse extensions to algorithms from both the machine learning and signal
processing literature, including variational inference, expectation
propagation, and the classical nonlinear Kalman smoothers. The derived methods
are suited to large time series, and we also demonstrate their applicability to
spatio-temporal data, where the model has separate inducing points in both time
and space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Domain Invariant Representations by Joint Wasserstein Distance Minimization. (arXiv:2106.04923v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Andeol_L/0/1/0/all/0/1">L&#xe9;o And&#xe9;ol</a>, <a href="http://arxiv.org/find/stat/1/au:+Kawakami_Y/0/1/0/all/0/1">Yusei Kawakami</a>, <a href="http://arxiv.org/find/stat/1/au:+Wada_Y/0/1/0/all/0/1">Yuichiro Wada</a>, <a href="http://arxiv.org/find/stat/1/au:+Kanamori_T/0/1/0/all/0/1">Takafumi Kanamori</a>, <a href="http://arxiv.org/find/stat/1/au:+Muller_K/0/1/0/all/0/1">Klaus-Robert M&#xfc;ller</a>, <a href="http://arxiv.org/find/stat/1/au:+Montavon_G/0/1/0/all/0/1">Gr&#xe9;goire Montavon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04923">
                                    <div class="article-summary-box-inner">
                                        <span>Domain shifts in the training data are common in practical applications of
machine learning, they occur for instance when the data is coming from
different sources. Ideally, a ML model should work well independently of these
shifts, for example, by learning a domain-invariant representation. Moreover,
privacy concerns regarding the source also require a domain-invariant
representation. In this work, we provide theoretical results that link domain
invariant representations -- measured by the Wasserstein distance on the joint
distributions -- to a practical semi-supervised learning objective based on a
cross-entropy classifier and a novel domain critic. Quantitative experiments
demonstrate that the proposed approach is indeed able to practically learn such
an invariant representation (between two domains), and the latter also supports
models with higher predictive accuracy on both domains, comparing favorably to
existing techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal Least Squares Based Fast Feature Selection for Linear Classification. (arXiv:2101.08539v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sikai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_Z/0/1/0/all/0/1">Zi-Qiang Lang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08539">
                                    <div class="article-summary-box-inner">
                                        <span>An Orthogonal Least Squares (OLS) based feature selection method is proposed
for both binomial and multinomial classification. The novel Squared Orthogonal
Correlation Coefficient (SOCC) is defined based on Error Reduction Ratio (ERR)
in OLS and used as the feature ranking criterion. The equivalence between the
canonical correlation coefficient, Fisher&#x27;s criterion, and the sum of the SOCCs
is revealed, which unveils the statistical implication of ERR in OLS for the
first time. It is also shown that the OLS based feature selection method has
speed advantages when applied for greedy search. The proposed method is
comprehensively compared with the mutual information based feature selection
methods in 2 synthetic and 7 real world datasets. The results show that the
proposed method is always in the top 5 among the 10 candidate methods. Besides,
the proposed method can be directly applied to continuous features without
discretisation, which is another significant advantage over mutual information
based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonlinear Hawkes Processes in Time-Varying System. (arXiv:2106.04844v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1">Quyu Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1">Cheng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04844">
                                    <div class="article-summary-box-inner">
                                        <span>Hawkes processes are a class of point processes that have the ability to
model the self- and mutual-exciting phenomena. Although the classic Hawkes
processes cover a wide range of applications, their expressive ability is
limited due to three key hypotheses: parametric, linear and homogeneous. Recent
work has attempted to address these limitations separately. This work aims to
overcome all three assumptions simultaneously by proposing the flexible
state-switching Hawkes processes: a flexible, nonlinear and nonhomogeneous
variant where a state process is incorporated to interact with the point
processes. The proposed model empowers Hawkes processes to be applied to
time-varying systems. For inference, we utilize the latent variable
augmentation technique to design two efficient Bayesian inference algorithms:
Gibbs sampler and mean-field variational inference, with analytical iterative
updates to estimate the posterior. In experiments, our model achieves superior
performance compared to the state-of-the-art competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Stable High-order Tuner for General Convex Functions. (arXiv:2011.09996v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreu_J/0/1/0/all/0/1">Jos&#xe9; M. Moreu</a>, <a href="http://arxiv.org/find/cs/1/au:+Annaswamy_A/0/1/0/all/0/1">Anuradha M. Annaswamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09996">
                                    <div class="article-summary-box-inner">
                                        <span>Iterative gradient-based algorithms have been increasingly applied for the
training of a broad variety of machine learning models including large
neural-nets. In particular, momentum-based methods, with accelerated learning
guarantees, have received a lot of attention due to their provable guarantees
of fast learning in certain classes of problems and multiple algorithms have
been derived. However, properties for these methods hold only for constant
regressors. When time-varying regressors occur, which is commonplace in dynamic
systems, many of these momentum-based methods cannot guarantee stability.
Recently, a new High-order Tuner (HT) was developed for linear regression
problems and shown to have 1) stability and asymptotic convergence for
time-varying regressors and 2) non-asymptotic accelerated learning guarantees
for constant regressors. In this paper, we extend and discuss the results of
this same HT for general convex loss functions. Through the exploitation of
convexity and smoothness definitions, we establish similar stability and
asymptotic convergence guarantees. Finally, we provide numerical simulations
supporting the satisfactory behavior of the HT algorithm as well as an
accelerated learning property.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Explainable Abnormal Infant Movements Identification: A Body-part Based Prediction and Visualisation Framework. (arXiv:2106.04966v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McCay_K/0/1/0/all/0/1">Kevin D. McCay</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1">Edmond S. L. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakkos_D/0/1/0/all/0/1">Dimitrios Sakkos</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_W/0/1/0/all/0/1">Wai Lok Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcroft_C/0/1/0/all/0/1">Claire Marcroft</a>, <a href="http://arxiv.org/find/cs/1/au:+Dulson_P/0/1/0/all/0/1">Patricia Dulson</a>, <a href="http://arxiv.org/find/cs/1/au:+Embleton_N/0/1/0/all/0/1">Nicholas D. Embleton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04966">
                                    <div class="article-summary-box-inner">
                                        <span>Providing early diagnosis of cerebral palsy (CP) is key to enhancing the
developmental outcomes for those affected. Diagnostic tools such as the General
Movements Assessment (GMA), have produced promising results in early diagnosis,
however these manual methods can be laborious.

In this paper, we propose a new framework for the automated classification of
infant body movements, based upon the GMA, which unlike previous methods, also
incorporates a visualization framework to aid with interpretability. Our
proposed framework segments extracted features to detect the presence of
Fidgety Movements (FMs) associated with the GMA spatiotemporally. These
features are then used to identify the body-parts with the greatest
contribution towards a classification decision and highlight the related
body-part segment providing visual feedback to the user.

We quantitatively compare the proposed framework&#x27;s classification performance
with several other methods from the literature and qualitatively evaluate the
visualization&#x27;s veracity. Our experimental results show that the proposed
method performs more robustly than comparable techniques in this setting whilst
simultaneously providing relevant visual interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densely connected normalizing flows. (arXiv:2106.04627v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grcic_M/0/1/0/all/0/1">Matej Grci&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Grubisic_I/0/1/0/all/0/1">Ivan Grubi&#x161;i&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Segvic_S/0/1/0/all/0/1">Sini&#x161;a &#x160;egvi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04627">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are bijective mappings between inputs and latent
representations with a fully factorized distribution. They are very attractive
due to exact likelihood evaluation and efficient sampling. However, their
effective capacity is often insufficient since the bijectivity constraint
limits the model width. We address this issue by incrementally padding
intermediate representations with noise. We precondition the noise in
accordance with previous invertible units, which we describe as cross-unit
coupling. Our invertible glow-like modules express intra-unit affine coupling
as a fusion of a densely connected block and Nystr\&quot;om self-attention. We refer
to our architecture as DenseFlow since both cross-unit and intra-unit couplings
rely on dense connectivity. Experiments show significant improvements due to
the proposed contributions, and reveal state-of-the-art density estimation
among all generative models under moderate computing budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Tracking Control via Strongly Adaptive Online Learning with Memory. (arXiv:2102.01623v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1">Ashok Cutkosky</a>, <a href="http://arxiv.org/find/cs/1/au:+Paschalidis_I/0/1/0/all/0/1">Ioannis Ch. Paschalidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01623">
                                    <div class="article-summary-box-inner">
                                        <span>We consider tracking adversarial targets in a delayed time-varying linear
system with adversarial disturbances and loss functions, which significantly
generalizes earlier work. To this end, we develop three techniques that each
could be of independent interest. First, we propose a black-box reduction from
adversarial tracking control to strongly adaptive online learning with memory.
Any solution to the latter translates to a tracking controller that pursues the
best action on any time interval. Second, for the resulting online learning
problem we develop a novel approach that further adapts to the observed
gradients. Third, we propose a new algorithm for unconstrained online linear
optimization: for all (unknown) $T\in\mathbb{N}_+$, the cumulative loss and
movement on the time horizon $[1:T]$ is upper-bounded by a user-specified
constant. Combining these individual techniques, we propose a tracking
controller with a sensible performance guarantee even when the adversarial
target has a large range of movement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust normalizing flows using Bernstein-type polynomials. (arXiv:2102.03509v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1">Sameera Ramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_K/0/1/0/all/0/1">Kasun Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1">Nick Barnes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03509">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling real-world distributions can often be challenging due to sample data
that are subjected to perturbations, e.g., instrumentation errors, or added
random noise. Since flow models are typically nonlinear algorithms, they
amplify these initial errors, leading to poor generalizations. This paper
proposes a framework to construct Normalizing Flows (NF), which demonstrates
higher robustness against such initial errors. To this end, we utilize
Bernstein-type polynomials inspired by the optimal stability of the Bernstein
basis. Further, compared to the existing NF frameworks, our method provides
compelling advantages like theoretical upper bounds for the approximation
error, higher interpretability, suitability for compactly supported densities,
and the ability to employ higher degree polynomials without training
instability. We conduct a thorough theoretical analysis and empirically
demonstrate the efficacy of the proposed technique using experiments on both
real-world and synthetic datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning. (arXiv:2106.04895v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tengyang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yu Bai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04895">
                                    <div class="article-summary-box-inner">
                                        <span>Recent theoretical work studies sample-efficient reinforcement learning (RL)
extensively in two settings: learning interactively in the environment (online
RL), or learning from an offline dataset (offline RL). However, existing
algorithms and theories for learning near-optimal policies in these two
settings are rather different and disconnected. Towards bridging this gap, this
paper initiates the theoretical study of policy finetuning, that is, online RL
where the learner has additional access to a &quot;reference policy&quot; $\mu$ close to
the optimal policy $\pi_\star$ in a certain sense. We consider the policy
finetuning problem in episodic Markov Decision Processes (MDPs) with $S$
states, $A$ actions, and horizon length $H$. We first design a sharp offline
reduction algorithm -- which simply executes $\mu$ and runs offline policy
optimization on the collected dataset -- that finds an $\varepsilon$
near-optimal policy within $\widetilde{O}(H^3SC^\star/\varepsilon^2)$ episodes,
where $C^\star$ is the single-policy concentrability coefficient between $\mu$
and $\pi_\star$. This offline result is the first that matches the sample
complexity lower bound in this setting, and resolves a recent open question in
offline RL. We then establish an $\Omega(H^3S\min\{C^\star, A\}/\varepsilon^2)$
sample complexity lower bound for any policy finetuning algorithm, including
those that can adaptively explore the environment. This implies that -- perhaps
surprisingly -- the optimal policy finetuning algorithm is either offline
reduction or a purely online RL algorithm that does not use $\mu$. Finally, we
design a new hybrid offline/online algorithm for policy finetuning that
achieves better sample complexity than both vanilla offline reduction and
purely online RL algorithms, in a relaxed setting where $\mu$ only satisfies
concentrability partially up to a certain time step.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretraining Representations for Data-Efficient Reinforcement Learning. (arXiv:2106.04799v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzer_M/0/1/0/all/0/1">Max Schwarzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajkumar_N/0/1/0/all/0/1">Nitarshan Rajkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Noukhovitch_M/0/1/0/all/0/1">Michael Noukhovitch</a>, <a href="http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1">Ankesh Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Charlin_L/0/1/0/all/0/1">Laurent Charlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hjelm_D/0/1/0/all/0/1">Devon Hjelm</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1">Philip Bachman</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04799">
                                    <div class="article-summary-box-inner">
                                        <span>Data efficiency is a key challenge for deep reinforcement learning. We
address this problem by using unlabeled data to pretrain an encoder which is
then finetuned on a small amount of task-specific data. To encourage learning
representations which capture diverse aspects of the underlying MDP, we employ
a combination of latent dynamics modelling and unsupervised goal-conditioned
RL. When limited to 100k steps of interaction on Atari games (equivalent to two
hours of human experience), our approach significantly surpasses prior work
combining offline representation pretraining with task-specific finetuning, and
compares favourably with other pretraining methods that require orders of
magnitude more data. Our approach shows particular promise when combined with
larger models as well as more diverse, task-aligned observational data --
approaching human-level performance and data-efficiency on Atari in our best
setting. We provide code associated with this work at
https://github.com/mila-iqia/SGI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Lack of Robust Interpretability of Neural Text Classifiers. (arXiv:2106.04631v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1">Muhammad Bilal Zafar</a>, <a href="http://arxiv.org/find/cs/1/au:+Donini_M/0/1/0/all/0/1">Michele Donini</a>, <a href="http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1">Dylan Slack</a>, <a href="http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1">C&#xe9;dric Archambeau</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Sanjiv Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1">Krishnaram Kenthapadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04631">
                                    <div class="article-summary-box-inner">
                                        <span>With the ever-increasing complexity of neural language models, practitioners
have turned to methods for understanding the predictions of these models. One
of the most well-adopted approaches for model interpretability is feature-based
interpretability, i.e., ranking the features in terms of their impact on model
predictions. Several prior studies have focused on assessing the fidelity of
feature-based interpretability methods, i.e., measuring the impact of dropping
the top-ranked features on the model output. However, relatively little work
has been conducted on quantifying the robustness of interpretations. In this
work, we assess the robustness of interpretations of neural text classifiers,
specifically, those based on pretrained Transformer encoders, using two
randomization tests. The first compares the interpretations of two models that
are identical except for their initializations. The second measures whether the
interpretations differ between a model with trained parameters and a model with
random parameters. Both tests show surprising deviations from expected
behavior, raising questions about the extent of insights that practitioners may
draw from interpretations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reliable Adversarial Distillation with Unreliable Teachers. (arXiv:2106.04928v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jianing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiangchao Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jianliang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04928">
                                    <div class="article-summary-box-inner">
                                        <span>In ordinary distillation, student networks are trained with soft labels (SLs)
given by pretrained teacher networks, and students are expected to improve upon
teachers since SLs are stronger supervision than the original hard labels.
However, when considering adversarial robustness, teachers may become
unreliable and adversarial distillation may not work: teachers are pretrained
on their own adversarial data, and it is too demanding to require that teachers
are also good at every adversarial data queried by students. Therefore, in this
paper, we propose reliable introspective adversarial distillation (IAD) where
students partially instead of fully trust their teachers. Specifically, IAD
distinguishes between three cases given a query of a natural data (ND) and the
corresponding adversarial data (AD): (a) if a teacher is good at AD, its SL is
fully trusted; (b) if a teacher is good at ND but not AD, its SL is partially
trusted and the student also takes its own SL into account; (c) otherwise, the
student only relies on its own SL. Experiments demonstrate the effectiveness of
IAD for improving upon teachers in terms of adversarial robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models. (arXiv:2106.00120v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Daniel T. Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00120">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic deep learning is deep learning that accounts for uncertainty,
both model uncertainty and data uncertainty. It is based on the use of
probabilistic models and deep neural networks. We distinguish two approaches to
probabilistic deep learning: probabilistic neural networks and deep
probabilistic models. The former employs deep neural networks that utilize
probabilistic layers which can represent and process uncertainty; the latter
uses probabilistic models that incorporate deep neural network components which
capture complex non-linear stochastic relationships between the random
variables. We discuss some major examples of each approach including Bayesian
neural networks and mixture density networks (for probabilistic neural
networks), and variational autoencoders, deep Gaussian processes and deep mixed
effects models (for deep probabilistic models). TensorFlow Probability is a
library for probabilistic modeling and inference which can be used for both
approaches of probabilistic deep learning. We include its code examples for
illustration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Improved Retrosynthetic Planning. (arXiv:2106.04880v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Junsu Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Sungsoo Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hankook Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04880">
                                    <div class="article-summary-box-inner">
                                        <span>Retrosynthetic planning is a fundamental problem in chemistry for finding a
pathway of reactions to synthesize a target molecule. Recently, search
algorithms have shown promising results for solving this problem by using deep
neural networks (DNNs) to expand their candidate solutions, i.e., adding new
reactions to reaction pathways. However, the existing works on this line are
suboptimal; the retrosynthetic planning problem requires the reaction pathways
to be (a) represented by real-world reactions and (b) executable using
&quot;building block&quot; molecules, yet the DNNs expand reaction pathways without fully
incorporating such requirements. Motivated by this, we propose an end-to-end
framework for directly training the DNNs towards generating reaction pathways
with the desirable properties. Our main idea is based on a self-improving
procedure that trains the model to imitate successful trajectories found by
itself. We also propose a novel reaction augmentation scheme based on a forward
reaction model. Our experiments demonstrate that our scheme significantly
improves the success rate of solving the retrosynthetic problem from 86.84% to
96.32% while maintaining the performance of DNN for predicting valid reactions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Deep Industrial Transfer Learning for Anomaly Detection on Time Series Data. (arXiv:2106.04920v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maschler_B/0/1/0/all/0/1">Benjamin Maschler</a>, <a href="http://arxiv.org/find/cs/1/au:+Knodel_T/0/1/0/all/0/1">Tim Knodel</a>, <a href="http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1">Michael Weyrich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04920">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning promises performant anomaly detection on time-variant datasets,
but greatly suffers from low availability of suitable training datasets and
frequently changing tasks. Deep transfer learning offers mitigation by letting
algorithms built upon previous knowledge from different tasks or locations. In
this article, a modular deep learning algorithm for anomaly detection on time
series datasets is presented that allows for an easy integration of such
transfer learning capabilities. It is thoroughly tested on a dataset from a
discrete manufacturing process in order to prove its fundamental adequacy
towards deep industrial transfer learning - the transfer of knowledge in
industrial applications&#x27; special environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simulating Continuum Mechanics with Multi-Scale Graph Neural Networks. (arXiv:2106.04900v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lino_M/0/1/0/all/0/1">Mario Lino</a>, <a href="http://arxiv.org/find/cs/1/au:+Cantwell_C/0/1/0/all/0/1">Chris Cantwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharath_A/0/1/0/all/0/1">Anil A. Bharath</a>, <a href="http://arxiv.org/find/cs/1/au:+Fotiadis_S/0/1/0/all/0/1">Stathi Fotiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04900">
                                    <div class="article-summary-box-inner">
                                        <span>Continuum mechanics simulators, numerically solving one or more partial
differential equations, are essential tools in many areas of science and
engineering, but their performance often limits application in practice. Recent
modern machine learning approaches have demonstrated their ability to
accelerate spatio-temporal predictions, although, with only moderate accuracy
in comparison. Here we introduce MultiScaleGNN, a novel multi-scale graph
neural network model for learning to infer unsteady continuum mechanics.
MultiScaleGNN represents the physical domain as an unstructured set of nodes,
and it constructs one or more graphs, each of them encoding different scales of
spatial resolution. Successive learnt message passing between these graphs
improves the ability of GNNs to capture and forecast the system state in
problems encompassing a range of length scales. Using graph representations,
MultiScaleGNN can impose periodic boundary conditions as an inductive bias on
the edges in the graphs, and achieve independence to the nodes&#x27; positions. We
demonstrate this method on advection problems and incompressible fluid
dynamics. Our results show that the proposed model can generalise from uniform
advection fields to high-gradient fields on complex domains at test time and
infer long-term Navier-Stokes solutions within a range of Reynolds numbers.
Simulations obtained with MultiScaleGNN are between two and four orders of
magnitude faster than the ones on which it was trained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expectation Programming. (arXiv:2106.04953v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reichelt_T/0/1/0/all/0/1">Tim Reichelt</a>, <a href="http://arxiv.org/find/cs/1/au:+Golinski_A/0/1/0/all/0/1">Adam Goli&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ong_L/0/1/0/all/0/1">Luke Ong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04953">
                                    <div class="article-summary-box-inner">
                                        <span>Building on ideas from probabilistic programming, we introduce the concept of
an expectation programming framework (EPF) that automates the calculation of
expectations. Analogous to a probabilistic program, an expectation program is
comprised of a mix of probabilistic constructs and deterministic calculations
that define a conditional distribution over its variables. However, the focus
of the inference engine in an EPF is to directly estimate the resulting
expectation of the program return values, rather than approximate the
conditional distribution itself. This distinction allows us to achieve
substantial performance improvements over the standard probabilistic
programming pipeline by tailoring the inference to the precise expectation we
care about. We realize a particular instantiation of our EPF concept by
extending the probabilistic programming language Turing to allow so-called
target-aware inference to be run automatically, and show that this leads to
significant empirical gains compared to conventional posterior-based inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1">David Berthelot</a>, <a href="http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1">Rebecca Roelofs</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1">Kihyuk Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1">Nicholas Carlini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1">Alex Kurakin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04732">
                                    <div class="article-summary-box-inner">
                                        <span>We extend semi-supervised learning to the problem of domain adaptation to
learn significantly higher-accuracy models that train on one data distribution
and test on a different one. With the goal of generality, we introduce
AdaMatch, a method that unifies the tasks of unsupervised domain adaptation
(UDA), semi-supervised learning (SSL), and semi-supervised domain adaptation
(SSDA). In an extensive experimental study, we compare its behavior with
respective state-of-the-art techniques from SSL, SSDA, and UDA on vision
classification tasks. We find AdaMatch either matches or significantly exceeds
the state-of-the-art in each case using the same hyper-parameters regardless of
the dataset or task. For example, AdaMatch nearly doubles the accuracy compared
to that of the prior state-of-the-art on the UDA task for DomainNet and even
exceeds the accuracy of the prior state-of-the-art obtained with pre-training
by 6.4% when AdaMatch is trained completely from scratch. Furthermore, by
providing AdaMatch with just one labeled example per class from the target
domain (i.e., the SSDA setting), we increase the target accuracy by an
additional 6.1%, and with 5 labeled examples, by 13.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Margin-Based Cluster Recovery with Oracle Queries. (arXiv:2106.04913v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bressan_M/0/1/0/all/0/1">Marco Bressan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1">Nicol&#xf2; Cesa-Bianchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_S/0/1/0/all/0/1">Silvio Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1">Andrea Paudice</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04913">
                                    <div class="article-summary-box-inner">
                                        <span>We study an active cluster recovery problem where, given a set of $n$ points
and an oracle answering queries like &quot;are these two points in the same
cluster?&quot;, the task is to recover exactly all clusters using as few queries as
possible. We begin by introducing a simple but general notion of margin between
clusters that captures, as special cases, the margins used in previous work,
the classic SVM margin, and standard notions of stability for center-based
clusterings. Then, under our margin assumptions we design algorithms that, in a
variety of settings, recover all clusters exactly using only $O(\log n)$
queries. For the Euclidean case, $\mathbb{R}^m$, we give an algorithm that
recovers arbitrary convex clusters, in polynomial time, and with a number of
queries that is lower than the best existing algorithm by $\Theta(m^m)$
factors. For general pseudometric spaces, where clusters might not be convex or
might not have any notion of shape, we give an algorithm that achieves the
$O(\log n)$ query bound, and is provably near-optimal as a function of the
packing number of the space. Finally, for clusterings realized by binary
concept classes, we give a combinatorial characterization of recoverability
with $O(\log n)$ queries, and we show that, for many concept classes in
Euclidean spaces, this characterization is equivalent to our margin condition.
Our results show a deep connection between cluster margins and active cluster
recoverability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regret and Cumulative Constraint Violation Analysis for Online Convex Optimization with Long Term Constraints. (arXiv:2106.05135v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xinlei Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiuxian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lihua Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_T/0/1/0/all/0/1">Tianyou Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansson_K/0/1/0/all/0/1">Karl H. Johansson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05135">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers online convex optimization with long term constraints,
where constraints can be violated in intermediate rounds, but need to be
satisfied in the long run. The cumulative constraint violation is used as the
metric to measure constraint violations, which excludes the situation that
strictly feasible constraints can compensate the effects of violated
constraints. A novel algorithm is first proposed and it achieves an
$\mathcal{O}(T^{\max\{c,1-c\}})$ bound for static regret and an
$\mathcal{O}(T^{(1-c)/2})$ bound for cumulative constraint violation, where
$c\in(0,1)$ is a user-defined trade-off parameter, and thus has improved
performance compared with existing results. Both static regret and cumulative
constraint violation bounds are reduced to $\mathcal{O}(\log(T))$ when the loss
functions are strongly convex, which also improves existing results. %In order
to bound the regret with respect to any comparator sequence, In order to
achieve the optimal regret with respect to any comparator sequence, another
algorithm is then proposed and it achieves the optimal
$\mathcal{O}(\sqrt{T(1+P_T)})$ regret and an $\mathcal{O}(\sqrt{T})$ cumulative
constraint violation, where $P_T$ is the path-length of the comparator
sequence. Finally, numerical simulations are provided to illustrate the
effectiveness of the theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Success of Domain Adaptation in Text Similarity. (arXiv:2106.04641v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pogrebnyakov_N/0/1/0/all/0/1">Nicolai Pogrebnyakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaghaghian_S/0/1/0/all/0/1">Shohreh Shaghaghian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04641">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning methods, and in particular domain adaptation, help exploit
labeled data in one domain to improve the performance of a certain task in
another domain. However, it is still not clear what factors affect the success
of domain adaptation. This paper models adaptation success and selection of the
most suitable source domains among several candidates in text similarity. We
use descriptive domain information and cross-domain similarity metrics as
predictive features. While mostly positive, the results also point to some
domains where adaptation success was difficult to predict.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EMFlow: Data Imputation in Latent Space via EM and Deep Flow Models. (arXiv:2106.04804v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1">Qi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Sujit K. Ghosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04804">
                                    <div class="article-summary-box-inner">
                                        <span>High dimensional incomplete data can be found in a wide range of systems. Due
to the fact that most of the data mining techniques and machine learning
algorithms require complete observations, data imputation is vital for
down-stream analysis. In this work, we introduce an imputation approach, called
EMFlow, that performs imputation in an latent space via an online version of
Expectation-Maximization (EM) algorithm and connects the latent space and the
data space via the normalizing flow (NF). The inference of EMFlow is iterative,
involving updating the parameters of online EM and NF alternatively. Extensive
experimental results on multivariate and image datasets show that the proposed
EMFlow has superior performance to competing methods in terms of both
imputation quality and convergence speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symmetric Spaces for Graph Embeddings: A Finsler-Riemannian Approach. (arXiv:2106.04941v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lopez_F/0/1/0/all/0/1">Federico L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pozzetti_B/0/1/0/all/0/1">Beatrice Pozzetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Trettel_S/0/1/0/all/0/1">Steve Trettel</a>, <a href="http://arxiv.org/find/cs/1/au:+Strube_M/0/1/0/all/0/1">Michael Strube</a>, <a href="http://arxiv.org/find/cs/1/au:+Wienhard_A/0/1/0/all/0/1">Anna Wienhard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04941">
                                    <div class="article-summary-box-inner">
                                        <span>Learning faithful graph representations as sets of vertex embeddings has
become a fundamental intermediary step in a wide range of machine learning
applications. We propose the systematic use of symmetric spaces in
representation learning, a class encompassing many of the previously used
embedding targets. This enables us to introduce a new method, the use of
Finsler metrics integrated in a Riemannian optimization scheme, that better
adapts to dissimilar structures in the graph. We develop a tool to analyze the
embeddings and infer structural properties of the data sets. For
implementation, we choose Siegel spaces, a versatile family of symmetric
spaces. Our approach outperforms competitive baselines for graph reconstruction
tasks on various synthetic and real-world datasets. We further demonstrate its
applicability on two downstream tasks, recommender systems and node
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Phase Retrieval using Single-Instance Deep Generative Prior. (arXiv:2106.04812v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tayal_K/0/1/0/all/0/1">Kshitij Tayal</a>, <a href="http://arxiv.org/find/cs/1/au:+Manekar_R/0/1/0/all/0/1">Raunak Manekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zhong Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">David Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vipin Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_F/0/1/0/all/0/1">Felix Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Ju Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04812">
                                    <div class="article-summary-box-inner">
                                        <span>Several deep learning methods for phase retrieval exist, but most of them
fail on realistic data without precise support information. We propose a novel
method based on single-instance deep generative prior that works well on
complex-valued crystal data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Pseudo-Backdoors for Mixed Integer Programs. (arXiv:2106.05080v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1">Aaron Ferber</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jialin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1">Bistra Dilkina</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05080">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a machine learning approach for quickly solving Mixed Integer
Programs (MIP) by learning to prioritize a set of decision variables, which we
call pseudo-backdoors, for branching that results in faster solution times.
Learning-based approaches have seen success in the area of solving
combinatorial optimization problems by being able to flexibly leverage common
structures in a given distribution of problems. Our approach takes inspiration
from the concept of strong backdoors, which corresponds to a small set of
variables such that only branching on these variables yields an optimal
integral solution and a proof of optimality. Our notion of pseudo-backdoors
corresponds to a small set of variables such that only branching on them leads
to faster solve time (which can be solver dependent). A key advantage of
pseudo-backdoors over strong backdoors is that they are much amenable to
data-driven identification or prediction. Our proposed method learns to
estimate the solver performance of a proposed pseudo-backdoor, using a labeled
dataset collected on a set of training MIP instances. This model can then be
used to identify high-quality pseudo-backdoors on new MIP instances from the
same distribution. We evaluate our method on the generalized independent set
problems and find that our approach can efficiently identify high-quality
pseudo-backdoors. In addition, we compare our learned approach against Gurobi,
a state-of-the-art MIP solver, demonstrating that our method can be used to
improve solver performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Labeled Data Generation with Inexact Supervision. (arXiv:2106.04716v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1">Enyan Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1">Kai Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yiwei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suhang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04716">
                                    <div class="article-summary-box-inner">
                                        <span>The recent advanced deep learning techniques have shown the promising results
in various domains such as computer vision and natural language processing. The
success of deep neural networks in supervised learning heavily relies on a
large amount of labeled data. However, obtaining labeled data with target
labels is often challenging due to various reasons such as cost of labeling and
privacy issues, which challenges existing deep models. In spite of that, it is
relatively easy to obtain data with \textit{inexact supervision}, i.e., having
labels/tags related to the target task. For example, social media platforms are
overwhelmed with billions of posts and images with self-customized tags, which
are not the exact labels for target classification tasks but are usually
related to the target labels. It is promising to leverage these tags (inexact
supervision) and their relations with target classes to generate labeled data
to facilitate the downstream classification tasks. However, the work on this is
rather limited. Therefore, we study a novel problem of labeled data generation
with inexact supervision. We propose a novel generative framework named as
ADDES which can synthesize high-quality labeled data for target classification
tasks by learning from data with inexact supervision and the relations between
inexact supervision and target classes. Experimental results on image and text
datasets demonstrate the effectiveness of the proposed ADDES for generating
realistic labeled data from inexact supervision to facilitate the target
classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness in Compressed Neural Networks for Object Detection. (arXiv:2102.05509v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cygert_S/0/1/0/all/0/1">Sebastian Cygert</a>, <a href="http://arxiv.org/find/cs/1/au:+Czyzewski_A/0/1/0/all/0/1">Andrzej Czy&#x17c;ewski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05509">
                                    <div class="article-summary-box-inner">
                                        <span>Model compression techniques allow to significantly reduce the computational
cost associated with data processing by deep neural networks with only a minor
decrease in average accuracy. Simultaneously, reducing the model size may have
a large effect on noisy cases or objects belonging to less frequent classes. It
is a crucial problem from the perspective of the models&#x27; safety, especially for
object detection in the autonomous driving setting, which is considered in this
work. It was shown in the paper that the sensitivity of compressed models to
different distortion types is nuanced, and some of the corruptions are heavily
impacted by the compression methods (i.e., additive noise), while others (blur
effect) are only slightly affected. A common way to improve the robustness of
models is to use data augmentation, which was confirmed to positively affect
models&#x27; robustness, also for highly compressed models. It was further shown
that while data imbalance methods brought only a slight increase in accuracy
for the baseline model (without compression), the impact was more striking at
higher compression rates for the structured pruning. Finally, methods for
handling data imbalance brought a significant improvement of the pruned models&#x27;
worst-detected class accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tracking by Joint Local and Global Search: A Target-aware Attention based Approach. (arXiv:2106.04840v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Bin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yaowei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonghong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04840">
                                    <div class="article-summary-box-inner">
                                        <span>Tracking-by-detection is a very popular framework for single object tracking
which attempts to search the target object within a local search window for
each frame. Although such local search mechanism works well on simple videos,
however, it makes the trackers sensitive to extremely challenging scenarios,
such as heavy occlusion and fast motion. In this paper, we propose a novel and
general target-aware attention mechanism (termed TANet) and integrate it with
tracking-by-detection framework to conduct joint local and global search for
robust tracking. Specifically, we extract the features of target object patch
and continuous video frames, then we concatenate and feed them into a decoder
network to generate target-aware global attention maps. More importantly, we
resort to adversarial training for better attention prediction. The appearance
and motion discriminator networks are designed to ensure its consistency in
spatial and temporal views. In the tracking procedure, we integrate the
target-aware attention with multiple trackers by exploring candidate search
regions for robust tracking. Extensive experiments on both short-term and
long-term tracking benchmark datasets all validated the effectiveness of our
algorithm. The project page of this paper can be found at
\url{https://sites.google.com/view/globalattentiontracking/home/extend}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intermittent Speech Recovery. (arXiv:2106.05229v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yu-Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_T/0/1/0/all/0/1">Tsun-An Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_K/0/1/0/all/0/1">Kuo-Hsuan Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cheng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Garudadri_H/0/1/0/all/0/1">Harinath Garudadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1">Yu Tsao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_T/0/1/0/all/0/1">Tei-Wei Kuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05229">
                                    <div class="article-summary-box-inner">
                                        <span>A large number of Internet of Things (IoT) devices today are powered by
batteries, which are often expensive to maintain and may cause serious
environmental pollution. To avoid these problems, researchers have begun to
consider the use of energy systems based on energy-harvesting units for such
devices. However, the power harvested from an ambient source is fundamentally
small and unstable, resulting in frequent power failures during the operation
of IoT applications involving, for example, intermittent speech signals and the
streaming of videos. This paper presents a deep-learning-based speech recovery
system that reconstructs intermittent speech signals from self-powered IoT
devices. Our intermittent speech recovery system (ISR) consists of three
stages: interpolation, recovery, and combination. The experimental results show
that our recovery system increases speech quality by up to 707.1%, while
increasing speech intelligibility by up to 92.1%. Most importantly, our ISR
system also enhances the WER scores by up to 65.6%. To the best of our
knowledge, this study is one of the first to reconstruct intermittent speech
signals from self-powered-sensing IoT devices. These promising results suggest
that even though self powered microphone devices function with weak energy
sources, our ISR system can still maintain the performance of most
speech-signal-based applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIGRAC: Digraph Clustering with Flow Imbalance. (arXiv:2106.05194v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+He_Y/0/1/0/all/0/1">Yixuan He</a>, <a href="http://arxiv.org/find/stat/1/au:+Reinert_G/0/1/0/all/0/1">Gesine Reinert</a>, <a href="http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05194">
                                    <div class="article-summary-box-inner">
                                        <span>Node clustering is a powerful tool in the analysis of networks. Here, we
introduce a graph neural network framework with a novel scalable Directed Mixed
Path Aggregation(DIMPA) scheme to obtain node embeddings for directed networks
in a self-supervised manner, including a novel probabilistic imbalance loss.
The method is end-to-end in combining embedding generation and clustering
without an intermediate step. In contrast to standard approaches in the
literature, in this paper, directionality is not treated as a nuisance, but
rather contains the main signal. In particular, we leverage the recently
introduced cut flow imbalance measure, which is tightly related to
directionality; cut flow imbalance is optimized without resorting to spectral
methods or cluster labels. Experimental results on synthetic data, in the form
of directed stochastic block models and real-world data at different scales,
demonstrate that our method attains state-of-the-art results on directed
clustering, for a wide range of noise and sparsity levels, as well as graph
structures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DPER: Efficient Parameter Estimation for Randomly Missing Data. (arXiv:2106.05190v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1">Thu Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_Duy_K/0/1/0/all/0/1">Khoi Minh Nguyen-Duy</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_D/0/1/0/all/0/1">Duy Ho Minh Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wade_B/0/1/0/all/0/1">Bruce Alan Wade</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05190">
                                    <div class="article-summary-box-inner">
                                        <span>The missing data problem has been broadly studied in the last few decades and
has various applications in different areas such as statistics or
bioinformatics. Even though many methods have been developed to tackle this
challenge, most of those are imputation techniques that require multiple
iterations through the data before yielding convergence. In addition, such
approaches may introduce extra biases and noises to the estimated parameters.
In this work, we propose novel algorithms to find the maximum likelihood
estimates (MLEs) for a one-class/multiple-class randomly missing data set under
some mild assumptions. As the computation is direct without any imputation, our
algorithms do not require multiple iterations through the data, thus promising
to be less time-consuming than other methods while maintaining superior
estimation performance. We validate these claims by empirical results on
various data sets of different sizes and release all codes in a GitHub
repository to contribute to the research community related to this problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I Don&#x27;t Need $\mathbf{u}$: Identifiable Non-Linear ICA Without Side Information. (arXiv:2106.05238v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Willetts_M/0/1/0/all/0/1">Matthew Willetts</a>, <a href="http://arxiv.org/find/cs/1/au:+Paige_B/0/1/0/all/0/1">Brooks Paige</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05238">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we introduce a new approach for identifiable non-linear ICA
models. Recently there has been a renaissance in identifiability results in
deep generative models, not least for non-linear ICA. These prior works,
however, have assumed access to a sufficiently-informative auxiliary set of
observations, denoted $\mathbf{u}$. We show here how identifiability can be
obtained in the absence of this side-information, rendering possible
fully-unsupervised identifiable non-linear ICA. While previous theoretical
results have established the impossibility of identifiable non-linear ICA in
the presence of infinitely-flexible universal function approximators, here we
rely on the intrinsically-finite modelling capacity of any particular chosen
parameterisation of a deep generative model. In particular, we focus on
generative models which perform clustering in their latent space -- a model
structure which matches previous identifiable models, but with the learnt
clustering providing a synthetic form of auxiliary information. We evaluate our
proposals using VAEs, on synthetic and image datasets, and find that the
learned clusterings function effectively: deep generative models with latent
clusterings are empirically identifiable, to the same degree as models which
rely on side information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Regularization in Tensor Factorization. (arXiv:2102.09972v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Razin_N/0/1/0/all/0/1">Noam Razin</a>, <a href="http://arxiv.org/find/cs/1/au:+Maman_A/0/1/0/all/0/1">Asaf Maman</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1">Nadav Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09972">
                                    <div class="article-summary-box-inner">
                                        <span>Recent efforts to unravel the mystery of implicit regularization in deep
learning have led to a theoretical focus on matrix factorization -- matrix
completion via linear neural network. As a step further towards practical deep
learning, we provide the first theoretical analysis of implicit regularization
in tensor factorization -- tensor completion via certain type of non-linear
neural network. We circumvent the notorious difficulty of tensor problems by
adopting a dynamical systems perspective, and characterizing the evolution
induced by gradient descent. The characterization suggests a form of greedy low
tensor rank search, which we rigorously prove under certain conditions, and
empirically demonstrate under others. Motivated by tensor rank capturing the
implicit regularization of a non-linear neural network, we empirically explore
it as a measure of complexity, and find that it captures the essence of
datasets on which neural networks generalize. This leads us to believe that
tensor rank may pave way to explaining both implicit regularization in deep
learning, and the properties of real-world data translating this implicit
regularization to generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What causes the test error? Going beyond bias-variance via ANOVA. (arXiv:2010.05170v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lin_L/0/1/0/all/0/1">Licong Lin</a>, <a href="http://arxiv.org/find/stat/1/au:+Dobriban_E/0/1/0/all/0/1">Edgar Dobriban</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05170">
                                    <div class="article-summary-box-inner">
                                        <span>Modern machine learning methods are often overparametrized, allowing
adaptation to the data at a fine level. This can seem puzzling; in the worst
case, such models do not need to generalize. This puzzle inspired a great
amount of work, arguing when overparametrization reduces test error, in a
phenomenon called &quot;double descent&quot;. Recent work aimed to understand in greater
depth why overparametrization is helpful for generalization. This leads to
discovering the unimodality of variance as a function of the level of
parametrization, and to decomposing the variance into that arising from label
noise, initialization, and randomness in the training data to understand the
sources of the error.

In this work we develop a deeper understanding of this area. Specifically, we
propose using the analysis of variance (ANOVA) to decompose the variance in the
test error in a symmetric way, for studying the generalization performance of
certain two-layer linear and non-linear networks. The advantage of the analysis
of variance is that it reveals the effects of initialization, label noise, and
training data more clearly than prior approaches. Moreover, we also study the
monotonicity and unimodality of the variance components. While prior work
studied the unimodality of the overall variance, we study the properties of
each term in variance decomposition.

One key insight is that in typical settings, the interaction between training
samples and initialization can dominate the variance; surprisingly being larger
than their marginal effect. Also, we characterize &quot;phase transitions&quot; where the
variance changes from unimodal to monotone. On a technical level, we leverage
advanced deterministic equivalent techniques for Haar random matrices, that --
to our knowledge -- have not yet been used in the area. We also verify our
results in numerical simulations and on empirical data examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-layered Network Exploration via Random Walks: From Offline Optimization to Online Learning. (arXiv:2106.05065v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xutong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1">Jinhang Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaowei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lui_J/0/1/0/all/0/1">John C.S. Lui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05065">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-layered network exploration (MuLaNE) problem is an important problem
abstracted from many applications. In MuLaNE, there are multiple network layers
where each node has an importance weight and each layer is explored by a random
walk. The MuLaNE task is to allocate total random walk budget $B$ into each
network layer so that the total weights of the unique nodes visited by random
walks are maximized. We systematically study this problem from offline
optimization to online learning. For the offline optimization setting where the
network structure and node weights are known, we provide greedy based
constant-ratio approximation algorithms for overlapping networks, and greedy or
dynamic-programming based optimal solutions for non-overlapping networks. For
the online learning setting, neither the network structure nor the node weights
are known initially. We adapt the combinatorial multi-armed bandit framework
and design algorithms to learn random walk related parameters and node weights
while optimizing the budget allocation in multiple rounds, and prove that they
achieve logarithmic regret bounds. Finally, we conduct experiments on a
real-world social network dataset to validate our theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qitian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hengrui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiaofeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04833">
                                    <div class="article-summary-box-inner">
                                        <span>Recommendation models can effectively estimate underlying user interests and
predict one&#x27;s future behaviors by factorizing an observed user-item rating
matrix into products of two sets of latent factors. However, the user-specific
embedding factors can only be learned in a transductive way, making it
difficult to handle new users on-the-fly. In this paper, we propose an
inductive collaborative filtering framework that contains two representation
models. The first model follows conventional matrix factorization which
factorizes a group of key users&#x27; rating matrix to obtain meta latents. The
second model resorts to attention-based structure learning that estimates
hidden relations from query to key users and learns to leverage meta latents to
inductively compute embeddings for query users via neural message passing. Our
model enables inductive representation learning for users and meanwhile
guarantees equivalent representation capacity as matrix factorization.
Experiments demonstrate that our model achieves promising results for
recommendation on few-shot users with limited training ratings and new unseen
users which are commonly encountered in open-world recommender systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maximum Probability Theorem: A Framework for Probabilistic Learning. (arXiv:1910.09417v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marvasti_A/0/1/0/all/0/1">Amir Emad Marvasti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marvasti_E/0/1/0/all/0/1">Ehsan Emad Marvasti</a>, <a href="http://arxiv.org/find/cs/1/au:+Foroosh_H/0/1/0/all/0/1">Hassan Foroosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.09417">
                                    <div class="article-summary-box-inner">
                                        <span>We present a theoretical framework of probabilistic learning derived by
Maximum Probability (MP) Theorem shown in the current paper. In this
probabilistic framework, a model is defined as an event in the probability
space, and a model or the associated event - either the true underlying model
or the parameterized model - have a quantified probability measure. This
quantification of a model&#x27;s probability measure is derived by the MP Theorem,
in which we have shown that an event&#x27;s probability measure has an upper-bound
given its conditional distribution on an arbitrary random variable. Through
this alternative framework, the notion of model parameters is encompassed in
the definition of the model or the associated event. Therefore, this framework
deviates from the conventional approach of assuming a prior on the model
parameters. Instead, the regularizing effects of assuming prior over parameters
is seen through maximizing probabilities of models or according to information
theory, minimizing the information content of a model. The probability of a
model in our framework is invariant to reparameterization and is solely
dependent on the model&#x27;s likelihood function. Also, rather than maximizing the
posterior in a conventional Bayesian setting, the objective function in our
alternative framework is defined as the probability of set operations (e.g.
intersection) on the event of the true underlying model and the event of the
model at hand. Our theoretical framework, as a derivation of MP theorem, adds
clarity to probabilistic learning through solidifying the definition of
probabilistic models, quantifying their probabilities, and providing a visual
understanding of objective functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Adaptive Doubly Robust Estimator for Policy Evaluation in Adaptive Experiments and a Paradox Concerning Logging Policy. (arXiv:2010.03792v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kato_M/0/1/0/all/0/1">Masahiro Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasui_S/0/1/0/all/0/1">Shota Yasui</a>, <a href="http://arxiv.org/find/cs/1/au:+McAlinn_K/0/1/0/all/0/1">Kenichiro McAlinn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03792">
                                    <div class="article-summary-box-inner">
                                        <span>The doubly robust (DR) estimator, which consists of two nuisance parameters,
the conditional mean outcome and the logging policy (the probability of
choosing an action), is crucial in causal inference. This paper proposes a DR
estimator for dependent samples obtained from adaptive experiments. To obtain
an asymptotically normal semiparametric estimator from dependent samples with
non-Donsker nuisance estimators, we propose adaptive-fitting as a variant of
sample-splitting. We also report an empirical paradox that our proposed DR
estimator tends to show better performances compared to other estimators
utilizing the true logging policy. While a similar phenomenon is known for
estimators with i.i.d. samples, traditional explanations based on asymptotic
efficiency cannot elucidate our case with dependent samples. We confirm this
hypothesis through simulation studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quickest change detection with unknown parameters: Constant complexity and near optimality. (arXiv:2106.05061v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jarboui_F/0/1/0/all/0/1">Firas Jarboui</a>, <a href="http://arxiv.org/find/cs/1/au:+Perchet_V/0/1/0/all/0/1">Viannet Perchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05061">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the quickest change detection problem where both the parameters
of pre- and post- change distributions are unknown, which prevents the use of
classical simple hypothesis testing. Without additional assumptions, optimal
solutions are not tractable as they rely on some minimax and robust variant of
the objective. As a consequence, change points might be detected too late for
practical applications (in economics, health care or maintenance for instance).
Available constant complexity techniques typically solve a relaxed version of
the problem, deeply relying on very specific probability distributions and/or
some very precise additional knowledge. We consider a totally different
approach that leverages the theoretical asymptotic properties of optimal
solutions to derive a new scalable approximate algorithm with near optimal
performance that runs~in~$\mathcal{O}(1)$, adapted to even more complex
Markovian settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dimensionwise Separable 2-D Graph Convolution for Unsupervised and Semi-Supervised Learning on Graphs. (arXiv:1909.12038v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qimai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaotong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Han Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1">Quanyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiao-Ming Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.12038">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional neural networks (GCN) have been the model of choice for
graph representation learning, which is mainly due to the effective design of
graph convolution that computes the representation of a node by aggregating
those of its neighbors. However, existing GCN variants commonly use 1-D graph
convolution that solely operates on the object link graph without exploring
informative relational information among object attributes. This significantly
limits their modeling capability and may lead to inferior performance on noisy
and sparse real-world networks. In this paper, we explore 2-D graph convolution
to jointly model object links and attribute relations for graph representation
learning. Specifically, we propose a computationally efficient dimensionwise
separable 2-D graph convolution (DSGC) for filtering node features.
Theoretically, we show that DSGC can reduce intra-class variance of node
features on both the object dimension and the attribute dimension to learn more
effective representations. Empirically, we demonstrate that by modeling
attribute relations, DSGC achieves significant performance gain over
state-of-the-art methods for node classification and clustering on a variety of
real-world networks. The source code for reproducing the experimental results
is available at https://github.com/liqimai/DSGC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Source Identification on Networks with Statistical Confidence. (arXiv:2106.04800v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dawkins_Q/0/1/0/all/0/1">Quinlan Dawkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haifeng Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04800">
                                    <div class="article-summary-box-inner">
                                        <span>Diffusion source identification on networks is a problem of fundamental
importance in a broad class of applications, including rumor controlling and
virus identification. Though this problem has received significant recent
attention, most studies have focused only on very restrictive settings and lack
theoretical guarantees for more realistic networks. We introduce a statistical
framework for the study of diffusion source identification and develop a
confidence set inference approach inspired by hypothesis testing. Our method
efficiently produces a small subset of nodes, which provably covers the source
node with any pre-specified confidence level without restrictive assumptions on
network structures. Moreover, we propose multiple Monte Carlo strategies for
the inference procedure based on network topology and the probabilistic
properties that significantly improve the scalability. To our knowledge, this
is the first diffusion source identification method with a practically useful
theoretical guarantee on general networks. We demonstrate our approach via
extensive synthetic experiments on well-known random network models and a
mobility network between cities concerning the COVID-19 spreading.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Optimization over Hybrid Spaces. (arXiv:2106.04682v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deshwal_A/0/1/0/all/0/1">Aryan Deshwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Belakaria_S/0/1/0/all/0/1">Syrine Belakaria</a>, <a href="http://arxiv.org/find/cs/1/au:+Doppa_J/0/1/0/all/0/1">Janardhan Rao Doppa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04682">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of optimizing hybrid structures (mixture of discrete
and continuous input variables) via expensive black-box function evaluations.
This problem arises in many real-world applications. For example, in materials
design optimization via lab experiments, discrete and continuous variables
correspond to the presence/absence of primitive elements and their relative
concentrations respectively. The key challenge is to accurately model the
complex interactions between discrete and continuous variables. In this paper,
we propose a novel approach referred as Hybrid Bayesian Optimization (HyBO) by
utilizing diffusion kernels, which are naturally defined over continuous and
discrete variables. We develop a principled approach for constructing diffusion
kernels over hybrid spaces by utilizing the additive kernel formulation, which
allows additive interactions of all orders in a tractable manner. We
theoretically analyze the modeling strength of additive hybrid kernels and
prove that it has the universal approximation property. Our experiments on
synthetic and six diverse real-world benchmarks show that HyBO significantly
outperforms the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FastSeq: Make Sequence Generation Faster. (arXiv:2106.04718v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1">Fei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiusheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhendawade_N/0/1/0/all/0/1">Nikhil Bhendawade</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_T/0/1/0/all/0/1">Ting Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1">Yeyun Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1">Nan Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_D/0/1/0/all/0/1">Desheng Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_B/0/1/0/all/0/1">Bingyu Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruifei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04718">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based models have made tremendous impacts in natural language
generation. However the inference speed is a bottleneck due to large model size
and intensive computing involved in auto-regressive decoding process. We
develop FastSeq framework to accelerate sequence generation without accuracy
loss. The proposed optimization techniques include an attention cache
optimization, an efficient algorithm for detecting repeated n-grams, and an
asynchronous generation pipeline with parallel I/O. These optimizations are
general enough to be applicable to Transformer-based models (e.g., T5, GPT2,
and UniLM). Our benchmark results on a set of widely used and diverse models
demonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use
with a simple one-line code change. The source code is available at
https://github.com/microsoft/fastseq.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On a class of data-driven combinatorial optimization problems under uncertainty: a distributionally robust approach. (arXiv:2105.14139v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Ketkov_S/0/1/0/all/0/1">Sergey S. Ketkov</a>, <a href="http://arxiv.org/find/math/1/au:+Shilov_A/0/1/0/all/0/1">Andrei S. Shilov</a>, <a href="http://arxiv.org/find/math/1/au:+Prokopyev_O/0/1/0/all/0/1">Oleg A. Prokopyev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14139">
                                    <div class="article-summary-box-inner">
                                        <span>In this study we analyze linear combinatorial optimization problems where the
cost vector is not known a priori, but is only observable through a finite data
set. In contrast to the related studies, we presume that the number of
observations with respect to particular components of the cost vector may vary.
The goal is to find a procedure that transforms the data set into an estimate
of the expected value of the objective function (which is referred to as a
prediction rule) and a procedure that retrieves a candidate decision (which is
referred to as a prescription rule). We aim at finding the least conservative
prediction and prescription rules, which satisfy some specified asymptotic
guarantees. We demonstrate that the resulting vector optimization problems
admit a weakly optimal solution, which can be obtained by solving a particular
distributionally robust optimization problem. Specifically, the decision-maker
may optimize the worst-case expected loss across all probability distributions
with given component-wise relative entropy distances from the empirical
marginal distributions. Finally, we perform numerical experiments to analyze
the out-of-sample performance of the proposed solution approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incentivizing Efficient Equilibria in Traffic Networks with Mixed Autonomy. (arXiv:2106.04678v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biyik_E/0/1/0/all/0/1">Erdem B&#x131;y&#x131;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazar_D/0/1/0/all/0/1">Daniel A. Lazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedarsani_R/0/1/0/all/0/1">Ramtin Pedarsani</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1">Dorsa Sadigh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04678">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic congestion has large economic and social costs. The introduction of
autonomous vehicles can potentially reduce this congestion by increasing road
capacity via vehicle platooning and by creating an avenue for influencing
people&#x27;s choice of routes. We consider a network of parallel roads with two
modes of transportation: (i) human drivers, who will choose the quickest route
available to them, and (ii) a ride hailing service, which provides an array of
autonomous vehicle route options, each with different prices, to users. We
formalize a model of vehicle flow in mixed autonomy and a model of how
autonomous service users make choices between routes with different prices and
latencies. Developing an algorithm to learn the preferences of the users, we
formulate a planning optimization that chooses prices to maximize a social
objective. We demonstrate the benefit of the proposed scheme by comparing the
results to theoretical benchmarks which we show can be efficiently calculated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ex uno plures: Splitting One Model into an Ensemble of Subnetworks. (arXiv:2106.04767v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhilu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_V/0/1/0/all/0/1">Vianne R. Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1">Mert R. Sabuncu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04767">
                                    <div class="article-summary-box-inner">
                                        <span>Monte Carlo (MC) dropout is a simple and efficient ensembling method that can
improve the accuracy and confidence calibration of high-capacity deep neural
network models. However, MC dropout is not as effective as more
compute-intensive methods such as deep ensembles. This performance gap can be
attributed to the relatively poor quality of individual models in the MC
dropout ensemble and their lack of diversity. These issues can in turn be
traced back to the coupled training and substantial parameter sharing of the
dropout models. Motivated by this perspective, we propose a strategy to compute
an ensemble of subnetworks, each corresponding to a non-overlapping dropout
mask computed via a pruning strategy and trained independently. We show that
the proposed subnetwork ensembling method can perform as well as standard deep
ensembles in both accuracy and uncertainty estimates, yet with a computational
efficiency similar to MC dropout. Lastly, using several computer vision
datasets like CIFAR10/100, CUB200, and Tiny-Imagenet, we experimentally
demonstrate that subnetwork ensembling also consistently outperforms recently
proposed approaches that efficiently ensemble neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlling False Discovery Rates under Cross-Sectional Correlations. (arXiv:2102.07826v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Komiyama_J/0/1/0/all/0/1">Junpei Komiyama</a>, <a href="http://arxiv.org/find/stat/1/au:+Abe_M/0/1/0/all/0/1">Masaya Abe</a>, <a href="http://arxiv.org/find/stat/1/au:+Nakagawa_K/0/1/0/all/0/1">Kei Nakagawa</a>, <a href="http://arxiv.org/find/stat/1/au:+McAlinn_K/0/1/0/all/0/1">Kenichiro McAlinn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07826">
                                    <div class="article-summary-box-inner">
                                        <span>We consider controlling the false discovery rate for testing many time series
with an unknown cross-sectional correlation structure. Given a large number of
hypotheses, false and missing discoveries can plague an analysis. While many
procedures have been proposed to control false discovery, most of them either
assume independent hypotheses or lack statistical power. A problem of
particular interest is in financial asset pricing, where the goal is to
determine which &#x60;&#x60;factors&quot; lead to excess returns out of a large number of
potential factors. Our contribution is two-fold. First, we show the consistency
of Fama and French&#x27;s prominent method under multiple testing. Second, we
propose a novel method for false discovery control using double bootstrapping.
We achieve superior statistical power to existing methods and prove that the
false discovery rate is controlled. Simulations and a real data application
illustrate the efficacy of our method over existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Feature Collapse and Deep Kernel Learning for Single Forward Pass Uncertainty. (arXiv:2102.11409v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1">Joost van Amersfoort</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Lewis Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1">Andrew Jesson</a>, <a href="http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1">Oscar Key</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11409">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes are often considered a gold standard in uncertainty
estimation with low dimensional data, but they have difficulty scaling to high
dimensional inputs. Deep Kernel Learning (DKL) was introduced as a solution to
this problem: a deep feature extractor is used to transform the inputs over
which a Gaussian process&#x27; kernel is defined. However, DKL has been shown to
provide unreliable uncertainty estimates in practice. We study why, and show
that for certain feature extractors, &quot;far-away&quot; data points are mapped to the
same features as those of training-set points. With this insight we propose to
constrain DKL&#x27;s feature extractor to approximately preserve distances through a
bi-Lipschitz constraint, resulting in a feature space favorable to DKL. We
obtain a model, DUE, which demonstrates uncertainty quality outperforming
previous DKL and single forward pass uncertainty methods, while maintaining the
speed and accuracy of softmax neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Marginalizable Density Models. (arXiv:2106.04741v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gilboa_D/0/1/0/all/0/1">Dar Gilboa</a>, <a href="http://arxiv.org/find/stat/1/au:+Pakman_A/0/1/0/all/0/1">Ari Pakman</a>, <a href="http://arxiv.org/find/stat/1/au:+Vatter_T/0/1/0/all/0/1">Thibault Vatter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04741">
                                    <div class="article-summary-box-inner">
                                        <span>Probability density models based on deep networks have achieved remarkable
success in modeling complex high-dimensional datasets. However, unlike kernel
density estimators, modern neural models do not yield marginals or conditionals
in closed form, as these quantities require the evaluation of seldom tractable
integrals. In this work, we present the Marginalizable Density Model
Approximator (MDMA), a novel deep network architecture which provides closed
form expressions for the probabilities, marginals and conditionals of any
subset of the variables. The MDMA learns deep scalar representations for each
individual variable and combines them via learned hierarchical tensor
decompositions into a tractable yet expressive CDF, from which marginals and
conditional densities are easily obtained. We illustrate the advantage of exact
marginalizability in several tasks that are out of reach of previous deep
network-based density estimation models, such as estimating mutual information
between arbitrary subsets of variables, inferring causality by testing for
conditional independence, and inference with missing data without the need for
data imputation, outperforming state-of-the-art models on these tasks. The
model also allows for parallelized sampling with only a logarithmic dependence
of the time complexity on the number of variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Deb_D/0/1/0/all/0/1">Diptodip Deb</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiao_Z/0/1/0/all/0/1">Zhenfei Jiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_A/0/1/0/all/0/1">Alex B. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ahrens_M/0/1/0/all/0/1">Misha B. Ahrens</a>, <a href="http://arxiv.org/find/eess/1/au:+Podgorski_K/0/1/0/all/0/1">Kaspar Podgorski</a>, <a href="http://arxiv.org/find/eess/1/au:+Turaga_S/0/1/0/all/0/1">Srinivas C. Turaga</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10611">
                                    <div class="article-summary-box-inner">
                                        <span>3D snapshot microscopy enables fast volumetric imaging by capturing a 3D
volume in a single 2D camera image, and has found a variety of biological
applications such as whole brain imaging of fast neural activity in larval
zebrafish. The optimal microscope design for this optical 3D-to-2D encoding is
both sample- and task-dependent, with no general solution known. Highly
programmable optical elements create new possibilities for sample-specific
computational optimization of microscope parameters, e.g. tuning the collection
of light for a given sample structure. We perform such optimization with deep
learning, using a differentiable wave-optics simulation of light propagation
through a programmable microscope and a neural network to reconstruct volumes
from the microscope image. We introduce a class of global kernel Fourier
convolutional neural networks which can efficiently decode information from
multiple depths in the volume, globally encoded across a 3D snapshot image. We
show that our proposed networks succeed in large field of view volume
reconstruction and microscope parameter optimization where traditional networks
fail. We also show that our networks outperform the state-of-the-art learned
reconstruction algorithms for lensless computational photography.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. (arXiv:2106.03760v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hazimeh_H/0/1/0/all/0/1">Hussein Hazimeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhe Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhery_A/0/1/0/all/0/1">Aakanksha Chowdhery</a>, <a href="http://arxiv.org/find/cs/1/au:+Sathiamoorthy_M/0/1/0/all/0/1">Maheswaran Sathiamoorthy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yihua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazumder_R/0/1/0/all/0/1">Rahul Mazumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1">Lichan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1">Ed H. Chi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03760">
                                    <div class="article-summary-box-inner">
                                        <span>The Mixture-of-experts (MoE) architecture is showing promising results in
multi-task learning (MTL) and in scaling high-capacity neural networks.
State-of-the-art MoE models use a trainable sparse gate to select a subset of
the experts for each input example. While conceptually appealing, existing
sparse gates, such as Top-k, are not smooth. The lack of smoothness can lead to
convergence and statistical performance issues when training with
gradient-based methods. In this paper, we develop DSelect-k: the first,
continuously differentiable and sparse gate for MoE, based on a novel binary
encoding formulation. Our gate can be trained using first-order methods, such
as stochastic gradient descent, and offers explicit control over the number of
experts to select. We demonstrate the effectiveness of DSelect-k in the context
of MTL, on both synthetic and real datasets with up to 128 tasks. Our
experiments indicate that MoE models based on DSelect-k can achieve
statistically significant improvements in predictive and expert selection
performance. Notably, on a real-world large-scale recommender system, DSelect-k
achieves over 22% average improvement in predictive performance compared to the
Top-k gate. We provide an open-source TensorFlow implementation of our gate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic task modelling for meta-learning. (arXiv:2106.04802v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Cuong C. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Do_T/0/1/0/all/0/1">Thanh-Toan Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04802">
                                    <div class="article-summary-box-inner">
                                        <span>We propose probabilistic task modelling -- a generative probabilistic model
for collections of tasks used in meta-learning. The proposed model combines
variational auto-encoding and latent Dirichlet allocation to model each task as
a mixture of Gaussian distribution in an embedding space. Such modelling
provides an explicit representation of a task through its task-theme mixture.
We present an efficient approximation inference technique based on variational
inference method for empirical Bayes parameter estimation. We perform empirical
evaluations to validate the task uncertainty and task distance produced by the
proposed method through correlation diagrams of the prediction accuracy on
testing tasks. We also carry out experiments of task selection in meta-learning
to demonstrate how the task relatedness inferred from the proposed model help
to facilitate meta-learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ghosts in Neural Networks: Existence, Structure and Role of Infinite-Dimensional Null Space. (arXiv:2106.04770v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1">Sho Sonoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_I/0/1/0/all/0/1">Isao Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikeda_M/0/1/0/all/0/1">Masahiro Ikeda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04770">
                                    <div class="article-summary-box-inner">
                                        <span>Overparametrization has been remarkably successful for deep learning studies.
This study investigates an overlooked but important aspect of overparametrized
neural networks, that is, the null components in the parameters of neural
networks, or the ghosts. Since deep learning is not explicitly regularized,
typical deep learning solutions contain null components. In this paper, we
present a structure theorem of the null space for a general class of neural
networks. Specifically, we show that any null element can be uniquely written
by the linear combination of ridgelet transforms. In general, it is quite
difficult to fully characterize the null space of an arbitrarily given
operator. Therefore, the structure theorem is a great advantage for
understanding a complicated landscape of neural network parameters. As
applications, we discuss the roles of ghosts on the generalization performance
of deep learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Operationalizing Complex Causes:A Pragmatic View of Mediation. (arXiv:2106.05074v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1">Limor Gultchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Watson_D/0/1/0/all/0/1">David S. Watson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ricardo Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05074">
                                    <div class="article-summary-box-inner">
                                        <span>We examine the problem of causal response estimation for complex objects
(e.g., text, images, genomics). In this setting, classical \emph{atomic}
interventions are often not available (e.g., changes to characters, pixels, DNA
base-pairs). Instead, we only have access to indirect or \emph{crude}
interventions (e.g., enrolling in a writing program, modifying a scene,
applying a gene therapy). In this work, we formalize this problem and provide
an initial solution. Given a collection of candidate mediators, we propose (a)
a two-step method for predicting the causal responses of crude interventions;
and (b) a testing procedure to identify mediators of crude interventions. We
demonstrate, on a range of simulated and real-world-inspired examples, that our
approach allows us to efficiently estimate the effect of crude interventions
with limited data from new treatment regimes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Optimization in Games via Control Theory: Connecting Regret, Passivity and Poincar\&#x27;e Recurrence. (arXiv:2106.04748v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheung_Y/0/1/0/all/0/1">Yun Kuen Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1">Georgios Piliouras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04748">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel control-theoretic understanding of online optimization and
learning in games, via the notion of passivity. Passivity is a fundamental
concept in control theory, which abstracts energy conservation and dissipation
in physical systems. It has become a standard tool in analysis of general
feedback systems, to which game dynamics belong. Our starting point is to show
that all continuous-time Follow-the-Regularized-Leader (FTRL) dynamics, which
includes the well-known Replicator Dynamic, are lossless, i.e. it is passive
with no energy dissipation. Interestingly, we prove that passivity implies
bounded regret, connecting two fundamental primitives of control theory and
online optimization.

The observation of energy conservation in FTRL inspires us to present a
family of lossless learning dynamics, each of which has an underlying energy
function with a simple gradient structure. This family is closed under convex
combination; as an immediate corollary, any convex combination of FTRL dynamics
is lossless and thus has bounded regret. This allows us to extend the framework
of Fox and Shamma (Games, 2013) to prove not just global asymptotic stability
results for game dynamics, but Poincar\&#x27;e recurrence results as well.
Intuitively, when a lossless game (e.g. graphical constant-sum game) is coupled
with lossless learning dynamic, their interconnection is also lossless, which
results in a pendulum-like energy-preserving recurrent behavior, generalizing
the results of Piliouras and Shamma (SODA, 2014) and Mertikopoulos,
Papadimitriou and Piliouras (SODA, 2018).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sentence Embeddings using Supervised Contrastive Learning. (arXiv:2106.04791v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liao_D/0/1/0/all/0/1">Danqi Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04791">
                                    <div class="article-summary-box-inner">
                                        <span>Sentence embeddings encode sentences in fixed dense vectors and have played
an important role in various NLP tasks and systems. Methods for building
sentence embeddings include unsupervised learning such as Quick-Thoughts and
supervised learning such as InferSent. With the success of pretrained NLP
models, recent research shows that fine-tuning pretrained BERT on SNLI and
Multi-NLI data creates state-of-the-art sentence embeddings, outperforming
previous sentence embeddings methods on various evaluation benchmarks. In this
paper, we propose a new method to build sentence embeddings by doing supervised
contrastive learning. Specifically our method fine-tunes pretrained BERT on
SNLI data, incorporating both supervised crossentropy loss and supervised
contrastive loss. Compared with baseline where fine-tuning is only done with
supervised cross-entropy loss similar to current state-of-the-art method SBERT,
our supervised contrastive method improves 2.8% in average on Semantic Textual
Similarity (STS) benchmarks and 1.05% in average on various sentence transfer
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TeachMyAgent: a Benchmark for Automatic Curriculum Learning in Deep RL. (arXiv:2103.09815v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Romac_C/0/1/0/all/0/1">Cl&#xe9;ment Romac</a>, <a href="http://arxiv.org/find/cs/1/au:+Portelas_R/0/1/0/all/0/1">R&#xe9;my Portelas</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09815">
                                    <div class="article-summary-box-inner">
                                        <span>Training autonomous agents able to generalize to multiple tasks is a key
target of Deep Reinforcement Learning (DRL) research. In parallel to improving
DRL algorithms themselves, Automatic Curriculum Learning (ACL) study how
teacher algorithms can train DRL agents more efficiently by adapting task
selection to their evolving abilities. While multiple standard benchmarks exist
to compare DRL agents, there is currently no such thing for ACL algorithms.
Thus, comparing existing approaches is difficult, as too many experimental
parameters differ from paper to paper. In this work, we identify several key
challenges faced by ACL algorithms. Based on these, we present TeachMyAgent
(TA), a benchmark of current ACL algorithms leveraging procedural task
generation. It includes 1) challenge-specific unit-tests using variants of a
procedural Box2D bipedal walker environment, and 2) a new procedural Parkour
environment combining most ACL challenges, making it ideal for global
performance assessment. We then use TeachMyAgent to conduct a comparative study
of representative existing approaches, showcasing the competitiveness of some
ACL algorithms that do not use expert knowledge. We also show that the Parkour
environment remains an open problem. We open-source our environments, all
studied ACL algorithms (collected from open-source code or re-implemented), and
DRL students in a Python package available at
https://github.com/flowersteam/TeachMyAgent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contextual Recommendations and Low-Regret Cutting-Plane Algorithms. (arXiv:2106.04819v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gollapudi_S/0/1/0/all/0/1">Sreenivas Gollapudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Guruganesh_G/0/1/0/all/0/1">Guru Guruganesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kollias_K/0/1/0/all/0/1">Kostas Kollias</a>, <a href="http://arxiv.org/find/cs/1/au:+Manurangsi_P/0/1/0/all/0/1">Pasin Manurangsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1">Renato Paes Leme</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1">Jon Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04819">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the following variant of contextual linear bandits motivated by
routing applications in navigational engines and recommendation systems. We
wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are
presented with a subset $\mathcal{X}_t \subseteq \mathbb{R}^d$ of possible
actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain
utility $\langle x_t, w^* \rangle$ but only learn the identity of the best
action $\arg\max_{x \in \mathcal{X}_t} \langle x, w^* \rangle$. We design
algorithms for this problem which achieve regret $O(d\log T)$ and $\exp(O(d
\log d))$. To accomplish this, we design novel cutting-plane algorithms with
low &quot;regret&quot; -- the total distance between the true point $w^*$ and the
hyperplanes the separation oracle returns. We also consider the variant where
we are allowed to provide a list of several recommendations. In this variant,
we give an algorithm with $O(d^2 \log d)$ regret and list size
$\mathrm{poly}(d)$. Finally, we construct nearly tight algorithms for a weaker
variant of this problem where the learner only learns the identity of an action
that is better than the recommendation. Our results rely on new algorithmic
techniques in convex geometry (including a variant of Steiner&#x27;s formula for the
centroid of a convex set) which may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vector Quantized Models for Planning. (arXiv:2106.04615v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1">Sherjil Ozair</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yazhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Razavi_A/0/1/0/all/0/1">Ali Razavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Antonoglou_I/0/1/0/all/0/1">Ioannis Antonoglou</a>, <a href="http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1">A&#xe4;ron van den Oord</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1">Oriol Vinyals</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04615">
                                    <div class="article-summary-box-inner">
                                        <span>Recent developments in the field of model-based RL have proven successful in
a range of environments, especially ones where planning is essential. However,
such successes have been limited to deterministic fully-observed environments.
We present a new approach that handles stochastic and partially-observable
environments. Our key insight is to use discrete autoencoders to capture the
multiple possible effects of an action in a stochastic environment. We use a
stochastic variant of \emph{Monte Carlo tree search} to plan over both the
agent&#x27;s actions and the discrete latent variables representing the
environment&#x27;s response. Our approach significantly outperforms an offline
version of MuZero on a stochastic interpretation of chess where the opponent is
considered part of the environment. We also show that our approach scales to
\emph{DeepMind Lab}, a first-person 3D environment with large visual
observations and partial observability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Boosting for Linear Mixed Models. (arXiv:2106.04862v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_B/0/1/0/all/0/1">Boyao Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Griesbach_C/0/1/0/all/0/1">Colin Griesbach</a>, <a href="http://arxiv.org/find/stat/1/au:+Kim_C/0/1/0/all/0/1">Cora Kim</a>, <a href="http://arxiv.org/find/stat/1/au:+Muller_Voggel_N/0/1/0/all/0/1">Nadia M&#xfc;ller-Voggel</a>, <a href="http://arxiv.org/find/stat/1/au:+Bergherr_E/0/1/0/all/0/1">Elisabeth Bergherr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04862">
                                    <div class="article-summary-box-inner">
                                        <span>Boosting methods are widely used in statistical learning to deal with
high-dimensional data due to their variable selection feature. However, those
methods lack straightforward ways to construct estimators for the precision of
the parameters such as variance or confidence interval, which can be achieved
by conventional statistical methods like Bayesian inference. In this paper, we
propose a new inference method &quot;BayesBoost&quot; that combines boosting and Bayesian
for linear mixed models to make the uncertainty estimation for the random
effects possible on the one hand. On the other hand, the new method overcomes
the shortcomings of Bayesian inference in giving precise and unambiguous
guidelines for the selection of covariates by benefiting from boosting
techniques. The implementation of Bayesian inference leads to the randomness of
model selection criteria like the conditional AIC (cAIC), so we also propose a
cAIC-based model selection criteria that focus on the stabilized regions
instead of the global minimum. The effectiveness of the new approach can be
observed via simulation and in a data example from the field of neurophysiology
focussing on the mechanisms in the brain while listening to unpleasant sounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rate-Distortion Theoretic Model Compression: Successive Refinement for Pruning. (arXiv:2102.08329v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isik_B/0/1/0/all/0/1">Berivan Isik</a>, <a href="http://arxiv.org/find/cs/1/au:+No_A/0/1/0/all/0/1">Albert No</a>, <a href="http://arxiv.org/find/cs/1/au:+Weissman_T/0/1/0/all/0/1">Tsachy Weissman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08329">
                                    <div class="article-summary-box-inner">
                                        <span>We study the neural network (NN) compression problem, viewing the tension
between the compression ratio and NN performance through the lens of
rate-distortion theory. We choose a distortion metric that reflects the effect
of NN compression on the model output and then derive the tradeoff between rate
(compression ratio) and distortion. In addition to characterizing theoretical
limits of NN compression, this formulation shows that \emph{pruning},
implicitly or explicitly, must be a part of a good compression algorithm. This
observation bridges a gap between parts of the literature pertaining to NN and
data compression, respectively, providing insight into the empirical success of
pruning for NN compression. Finally, we propose a novel pruning strategy
derived from our information-theoretic formulation and show that it outperforms
the relevant baselines on CIFAR-10 and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards the Memorization Effect of Neural Networks in Adversarial Training. (arXiv:2106.04794v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Han Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wentao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenbiao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhongqin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zitao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1">Anil Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04794">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies suggest that &#x60;&#x60;memorization&#x27;&#x27; is one important factor for
overparameterized deep neural networks (DNNs) to achieve optimal performance.
Specifically, the perfectly fitted DNNs can memorize the labels of many
atypical samples, generalize their memorization to correctly classify test
atypical samples and enjoy better test performance. While, DNNs which are
optimized via adversarial training algorithms can also achieve perfect training
performance by memorizing the labels of atypical samples, as well as the
adversarially perturbed atypical samples. However, adversarially trained models
always suffer from poor generalization, with both relatively low clean accuracy
and robustness on the test set. In this work, we study the effect of
memorization in adversarial trained DNNs and disclose two important findings:
(a) Memorizing atypical samples is only effective to improve DNN&#x27;s accuracy on
clean atypical samples, but hardly improve their adversarial robustness and (b)
Memorizing certain atypical samples will even hurt the DNN&#x27;s performance on
typical samples. Based on these two findings, we propose Benign Adversarial
Training (BAT) which can facilitate adversarial training to avoid fitting
&#x60;&#x60;harmful&#x27;&#x27; atypical samples and fit as more &#x60;&#x60;benign&#x27;&#x27; atypical samples as
possible. In our experiments, we validate the effectiveness of BAT, and show it
can achieve better clean accuracy vs. robustness trade-off than baseline
methods, in benchmark datasets such as CIFAR100 and Tiny~ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Evolution of Neuron Communities in a Deep Learning Architecture. (arXiv:2106.04693v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mostafa_S/0/1/0/all/0/1">Sakib Mostafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1">Debajyoti Mondal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04693">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning techniques are increasingly being adopted for classification
tasks over the past decade, yet explaining how deep learning architectures can
achieve state-of-the-art performance is still an elusive goal. While all the
training information is embedded deeply in a trained model, we still do not
understand much about its performance by only analyzing the model. This paper
examines the neuron activation patterns of deep learning-based classification
models and explores whether the models&#x27; performances can be explained through
neurons&#x27; activation behavior. We propose two approaches: one that models
neurons&#x27; activation behavior as a graph and examines whether the neurons form
meaningful communities, and the other examines the predictability of neurons&#x27;
behavior using entropy. Our comprehensive experimental study reveals that both
the community quality (modularity) and entropy are closely related to the deep
learning models&#x27; performances, thus paves a novel way of explaining deep
learning models directly from the neurons&#x27; activation pattern.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedding Physics to Learn Spatiotemporal Dynamics from Sparse Data. (arXiv:2106.04781v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_C/0/1/0/all/0/1">Chengping Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04781">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling nonlinear spatiotemporal dynamical systems has primarily relied on
partial differential equations (PDEs) that are typically derived from first
principles. However, the explicit formulation of PDEs for many underexplored
processes, such as climate systems, biochemical reaction and epidemiology,
remains uncertain or partially unknown, where very sparse measurement data is
yet available. To tackle this challenge, we propose a novel deep learning
architecture that forcibly embedded known physics knowledge in a
residual-recurrent $\Pi$-block network, to facilitate the learning of the
spatiotemporal dynamics in a data-driven manner. The coercive embedding
mechanism of physics, fundamentally different from physics-informed neural
networks based on loss penalty, ensures the network to rigorously obey given
physics. Numerical experiments demonstrate that the resulting learning paradigm
that embeds physics possesses remarkable accuracy, robustness, interpretability
and generalizability for learning spatiotemporal dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Machine Learning Safety: A Survey and Primer. (arXiv:2106.04823v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohseni_S/0/1/0/all/0/1">Sina Mohseni</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haotao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadawa_J/0/1/0/all/0/1">Jay Yadawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04823">
                                    <div class="article-summary-box-inner">
                                        <span>The open-world deployment of Machine Learning (ML) algorithms in
safety-critical applications such as autonomous vehicles needs to address a
variety of ML vulnerabilities such as interpretability, verifiability, and
performance limitations. Research explores different approaches to improve ML
dependability by proposing new models and training techniques to reduce
generalization error, achieve domain adaptation, and detect outlier examples
and adversarial attacks. In this paper, we review and organize practical ML
techniques that can improve the safety and dependability of ML algorithms and
therefore ML-based software. Our organization maps state-of-the-art ML
techniques to safety strategies in order to enhance the dependability of the ML
algorithm from different aspects, and discuss research gaps as well as
promising solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Job Dispatching Policies for Queueing Systems with Unknown Service Rates. (arXiv:2106.04707v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Choudhury_T/0/1/0/all/0/1">Tuhinangshu Choudhury</a>, <a href="http://arxiv.org/find/eess/1/au:+Joshi_G/0/1/0/all/0/1">Gauri Joshi</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Weina Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04707">
                                    <div class="article-summary-box-inner">
                                        <span>In multi-server queueing systems where there is no central queue holding all
incoming jobs, job dispatching policies are used to assign incoming jobs to the
queue at one of the servers. Classic job dispatching policies such as
join-the-shortest-queue and shortest expected delay assume that the service
rates and queue lengths of the servers are known to the dispatcher. In this
work, we tackle the problem of job dispatching without the knowledge of service
rates and queue lengths, where the dispatcher can only obtain noisy estimates
of the service rates by observing job departures. This problem presents a novel
exploration-exploitation trade-off between sending jobs to all the servers to
estimate their service rates, and exploiting the currently known fastest
servers to minimize the expected queueing delay. We propose a bandit-based
exploration policy that learns the service rates from observed job departures.
Unlike the standard multi-armed bandit problem where only one out of a finite
set of actions is optimal, here the optimal policy requires identifying the
optimal fraction of incoming jobs to be sent to each server. We present a
regret analysis and simulations to demonstrate the effectiveness of the
proposed bandit-based exploration policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Submodular + Concave. (arXiv:2106.04769v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Mitra_S/0/1/0/all/0/1">Siddharth Mitra</a>, <a href="http://arxiv.org/find/math/1/au:+Feldman_M/0/1/0/all/0/1">Moran Feldman</a>, <a href="http://arxiv.org/find/math/1/au:+Karbasi_A/0/1/0/all/0/1">Amin Karbasi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04769">
                                    <div class="article-summary-box-inner">
                                        <span>It has been well established that first order optimization methods can
converge to the maximal objective value of concave functions and provide
constant factor approximation guarantees for (non-convex/non-concave)
continuous submodular functions. In this work, we initiate the study of the
maximization of functions of the form $F(x) &#x3D; G(x) +C(x)$ over a solvable
convex body $P$, where $G$ is a smooth DR-submodular function and $C$ is a
smooth concave function. This class of functions is a strict extension of both
concave and continuous DR-submodular functions for which no theoretical
guarantee is known. We provide a suite of Frank-Wolfe style algorithms, which,
depending on the nature of the objective function (i.e., if $G$ and $C$ are
monotone or not, and non-negative or not) and on the nature of the set $P$
(i.e., whether it is downward closed or not), provide $1-1/e$, $1/e$, or $1/2$
approximation guarantees. We then use our algorithms to get a framework to
smoothly interpolate between choosing a diverse set of elements from a given
ground set (corresponding to the mode of a determinantal point process) and
choosing a clustered set of elements (corresponding to the maxima of a suitable
concave function). Additionally, we apply our algorithms to various functions
in the above class (DR-submodular + concave) in both constrained and
unconstrained settings, and show that our algorithms consistently outperform
natural baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drones for Medical Delivery Considering Different Demands Classes: A Markov Decision Process Approach for Managing Health Centers Dispatching Medical Products. (arXiv:2106.04729v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Asadi_A/0/1/0/all/0/1">Amin Asadi</a>, <a href="http://arxiv.org/find/math/1/au:+Pinkley_S/0/1/0/all/0/1">Sarah Nurre Pinkley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04729">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of optimizing the distribution operations of a hub
using drones to deliver medical supplies to different geographic regions.
Drones are an innovative method with many benefits including low-contact
delivery thereby reducing the spread of pandemic and vaccine-preventable
diseases. While we focus on medical supply delivery for this work, it is
applicable to drone delivery for many other applications, including food,
postal items, and e-commerce delivery. In this paper, our goal is to address
drone delivery challenges by optimizing the distribution operations at a drone
hub that dispatch drones to different geographic locations generating
stochastic demands for medical supplies. By considering different geographic
locations, we consider different classes of demand that require different
flight ranges, which is directly related to the amount of charge held in a
drone battery. We classify the stochastic demands based on their distance from
the drone hub, use a Markov decision process to model the problem, and perform
computational tests using realistic data representing a prominent drone
delivery company. We solve the problem using a reinforcement learning method
and show its high performance compared with the exact solution found using
dynamic programming. Finally, we analyze the results and provide insights for
managing the drone hub operations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Instance-Wise Classification in Correlated Feature Spaces. (arXiv:2106.04668v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liyanage_Y/0/1/0/all/0/1">Yasitha Warahena Liyanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Zois_D/0/1/0/all/0/1">Daphney-Stavroula Zois</a>, <a href="http://arxiv.org/find/cs/1/au:+Chelmis_C/0/1/0/all/0/1">Charalampos Chelmis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04668">
                                    <div class="article-summary-box-inner">
                                        <span>In a typical supervised machine learning setting, the predictions on all test
instances are based on a common subset of features discovered during model
training. However, using a different subset of features that is most
informative for each test instance individually may not only improve prediction
accuracy, but also the overall interpretability of the model. At the same time,
feature selection methods for classification have been known to be the most
effective when many features are irrelevant and/or uncorrelated. In fact,
feature selection ignoring correlations between features can lead to poor
classification performance. In this work, a Bayesian network is utilized to
model feature dependencies. Using the dependency network, a new method is
proposed that sequentially selects the best feature to evaluate for each test
instance individually, and stops the selection process to make a prediction
once it determines that no further improvement can be achieved with respect to
classification accuracy. The optimum number of features to acquire and the
optimum classification strategy are derived for each test instance. The
theoretical properties of the optimum solution are analyzed, and a new
algorithm is proposed that takes advantage of these properties to implement a
robust and scalable solution for high dimensional settings. The effectiveness,
generalizability, and scalability of the proposed method is illustrated on a
variety of real-world datasets from diverse application domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Neural Network to Quantify Uncertainty of Wind Power Estimation. (arXiv:2106.04656v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karami_F/0/1/0/all/0/1">Farzad Karami</a>, <a href="http://arxiv.org/find/cs/1/au:+Kehtarnavaz_N/0/1/0/all/0/1">Nasser Kehtarnavaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Rotea_M/0/1/0/all/0/1">Mario Rotea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04656">
                                    <div class="article-summary-box-inner">
                                        <span>Each year a growing number of wind farms are being added to power grids to
generate electricity. The power curve of a wind turbine, which exhibits the
relationship between generated power and wind speed, plays a major role in
assessing the performance of a wind farm. Neural networks have been used for
power curve estimation. However, they do not produce a confidence measure for
their output, unless computationally prohibitive Bayesian methods are used. In
this paper, a probabilistic neural network with Monte Carlo dropout is
considered to quantify the model (epistemic) uncertainty of the power curve
estimation. This approach offers a minimal increase in computational complexity
over deterministic approaches. Furthermore, by incorporating a probabilistic
loss function, the noise or aleatoric uncertainty in the data is estimated. The
developed network captures both model and noise uncertainty which is found to
be useful tools in assessing performance. Also, the developed network is
compared with existing ones across a public domain dataset showing superior
performance in terms of prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning subtree pattern importance for Weisfeiler-Lehmanbased graph kernels. (arXiv:2106.04739v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dai Hai Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Canh Hao Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mamitsuka_H/0/1/0/all/0/1">Hiroshi Mamitsuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04739">
                                    <div class="article-summary-box-inner">
                                        <span>Graph is an usual representation of relational data, which are ubiquitous in
manydomains such as molecules, biological and social networks. A popular
approach to learningwith graph structured data is to make use of graph kernels,
which measure the similaritybetween graphs and are plugged into a kernel
machine such as a support vector machine.Weisfeiler-Lehman (WL) based graph
kernels, which employ WL labeling scheme to extract subtree patterns and
perform node embedding, are demonstrated to achieve great performance while
being efficiently computable. However, one of the main drawbacks of ageneral
kernel is the decoupling of kernel construction and learning process. For
moleculargraphs, usual kernels such as WL subtree, based on substructures of
the molecules, consider all available substructures having the same importance,
which might not be suitable inpractice. In this paper, we propose a method to
learn the weights of subtree patterns in the framework of WWL kernels, the
state of the art method for graph classification task [14]. To overcome the
computational issue on large scale data sets, we present an efficient learning
algorithm and also derive a generalization gap bound to show its convergence.
Finally, through experiments on synthetic and real-world data sets, we
demonstrate the effectiveness of our proposed method for learning the weights
of subtree patterns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Streaming Belief Propagation for Community Detection. (arXiv:2106.04805v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1">Yuchen Wu</a>, <a href="http://arxiv.org/find/stat/1/au:+Bateni_M/0/1/0/all/0/1">MohammadHossein Bateni</a>, <a href="http://arxiv.org/find/stat/1/au:+Linhares_A/0/1/0/all/0/1">Andre Linhares</a>, <a href="http://arxiv.org/find/stat/1/au:+Almeida_F/0/1/0/all/0/1">Filipe Miguel Goncalves de Almeida</a>, <a href="http://arxiv.org/find/stat/1/au:+Montanari_A/0/1/0/all/0/1">Andrea Montanari</a>, <a href="http://arxiv.org/find/stat/1/au:+Norouzi_Fard_A/0/1/0/all/0/1">Ashkan Norouzi-Fard</a>, <a href="http://arxiv.org/find/stat/1/au:+Tardos_J/0/1/0/all/0/1">Jakab Tardos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04805">
                                    <div class="article-summary-box-inner">
                                        <span>The community detection problem requires to cluster the nodes of a network
into a small number of well-connected &quot;communities&quot;. There has been substantial
recent progress in characterizing the fundamental statistical limits of
community detection under simple stochastic block models. However, in
real-world applications, the network structure is typically dynamic, with nodes
that join over time. In this setting, we would like a detection algorithm to
perform only a limited number of updates at each node arrival. While standard
voting approaches satisfy this constraint, it is unclear whether they exploit
the network information optimally. We introduce a simple model for networks
growing over time which we refer to as streaming stochastic block model
(StSBM). Within this model, we prove that voting algorithms have fundamental
limitations. We also develop a streaming belief-propagation (StreamBP)
approach, for which we prove optimality in certain regimes. We validate our
theoretical findings on synthetic and real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">General Rough Modeling of Cluster Analysis. (arXiv:2106.04683v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mani_A/0/1/0/all/0/1">A. Mani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04683">
                                    <div class="article-summary-box-inner">
                                        <span>In this research, a general theoretical framework for clustering is proposed
over specific partial algebraic systems by the present author. Her theory helps
in isolating minimal assumptions necessary for different concepts of clustering
information in any form to be realized in a situation (and therefore in a
semantics). \emph{It is well-known that of the limited number of proofs in the
theory of hard and soft clustering that are known to exist, most involve
statistical assumptions}. Many methods seem to work because they seem to work
in specific empirical practice. A new general rough method of analyzing
clusterings is invented, and this opens the subject to clearer conceptions and
contamination-free theoretical proofs. Numeric ideas of validation are also
proposed to be replaced by those based on general rough approximation. The
essence of the approach is explained in brief and supported by an example.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Deep Neural Network Generalization with Perturbation Response Curves. (arXiv:2106.04765v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/cs/1/au:+Quanz_B/0/1/0/all/0/1">Brian Quanz</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04765">
                                    <div class="article-summary-box-inner">
                                        <span>The field of Deep Learning is rich with empirical evidence of human-like
performance on a variety of prediction tasks. However, despite these successes,
the recent Predicting Generalization in Deep Learning (PGDL) NeurIPS 2020
competition suggests that there is a need for more robust and efficient
measures of network generalization. In this work, we propose a new framework
for evaluating the generalization capabilities of trained networks. We use
perturbation response (PR) curves that capture the accuracy change of a given
network as a function of varying levels of training sample perturbation. From
these PR curves, we derive novel statistics that capture generalization
capability. Specifically, we introduce two new measures for accurately
predicting generalization gaps: the Gi-score and Pal-score, that are inspired
by the Gini coefficient and Palma ratio (measures of income inequality), that
accurately predict generalization gaps. Using our framework applied to intra
and inter class sample mixup, we attain better predictive scores than the
current state-of-the-art measures on a majority of tasks in the PGDL
competition. In addition, we show that our framework and the proposed
statistics can be used to capture to what extent a trained network is invariant
to a given parametric input transformation, such as rotation or translation.
Therefore, these generalization gap prediction statistics also provide a useful
means for selecting the optimal network architectures and hyperparameters that
are invariant to a certain perturbation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering using Nearest-Neighbor Chain. (arXiv:2106.04727v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shangdi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiqiu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhulipala_L/0/1/0/all/0/1">Laxman Dhulipala</a>, <a href="http://arxiv.org/find/cs/1/au:+Shun_J/0/1/0/all/0/1">Julian Shun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04727">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the hierarchical clustering problem, where the goal is to
produce a dendrogram that represents clusters at varying scales of a data set.
We propose the ParChain framework for designing parallel hierarchical
agglomerative clustering (HAC) algorithms, and using the framework we obtain
novel parallel algorithms for the complete linkage, average linkage, and Ward&#x27;s
linkage criteria. Compared to most previous parallel HAC algorithms, which
require quadratic memory, our new algorithms require only linear memory, and
are scalable to large data sets. ParChain is based on our parallelization of
the nearest-neighbor chain algorithm, and enables multiple clusters to be
merged on every round. We introduce two key optimizations that are critical for
efficiency: a range query optimization that reduces the number of distance
computations required when finding nearest neighbors of clusters, and a caching
optimization that stores a subset of previously computed distances, which are
likely to be reused.

Experimentally, we show that our highly-optimized implementations using 48
cores with two-way hyper-threading achieve 5.8--110.1x speedup over
state-of-the-art parallel HAC algorithms and achieve 13.75--54.23x
self-relative speedup. Compared to state-of-the-art algorithms, our algorithms
require up to 237.3x less space. Our algorithms are able to scale to data set
sizes with tens of millions of points, which existing algorithms are not able
to handle.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoAtNet: Marrying Convolution and Attention for All Data Sizes. (arXiv:2106.04803v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zihang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingxing Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04803">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have attracted increasing interests in computer vision, but they
still fall behind state-of-the-art convolutional networks. In this work, we
show that while Transformers tend to have larger model capacity, their
generalization can be worse than convolutional networks due to the lack of the
right inductive bias. To effectively combine the strengths from both
architectures, we present CoAtNets(pronounced &quot;coat&quot; nets), a family of hybrid
models built from two key insights:(1) depthwise Convolution and self-Attention
can be naturally unified via simple relative attention; (2) vertically stacking
convolution layers and attention layers in a principled way is surprisingly
effective in improving generalization, capacity and efficiency. Experiments
show that our CoAtNets achieve state-of-the-art performance under different
resource constraints across various datasets. For example, CoAtNet achieves
86.0% ImageNet top-1 accuracy without extra data, and 89.77% with extra JFT
data, outperforming prior arts of both convolutional networks and Transformers.
Notably, when pre-trained with 13M images fromImageNet-21K, our CoAtNet
achieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images
from JFT while using 23x less data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChaCha for Online AutoML. (arXiv:2106.04815v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1">John Langford</a>, <a href="http://arxiv.org/find/cs/1/au:+Mineiro_P/0/1/0/all/0/1">Paul Mineiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_M/0/1/0/all/0/1">Marco Rossi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04815">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the ChaCha (Champion-Challengers) algorithm for making an online
choice of hyperparameters in online learning settings. ChaCha handles the
process of determining a champion and scheduling a set of &#x60;live&#x27; challengers
over time based on sample complexity bounds. It is guaranteed to have sublinear
regret after the optimal configuration is added into consideration by an
application-dependent oracle based on the champions. Empirically, we show that
ChaCha provides good performance across a wide array of datasets when
optimizing over featurization and hyperparameter decisions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAM: Understanding Product Images in Cross Product Category Attribute Extraction. (arXiv:2106.04630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jie Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1">Nasser Zalmout</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Luna Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04630">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding product attributes plays an important role in improving online
shopping experience for customers and serves as an integral part for
constructing a product knowledge graph. Most existing methods focus on
attribute extraction from text description or utilize visual information from
product images such as shape and color. Compared to the inputs considered in
prior works, a product image in fact contains more information, represented by
a rich mixture of words and visual clues with a layout carefully designed to
impress customers. This work proposes a more inclusive framework that fully
utilizes these different modalities for attribute extraction. Inspired by
recent works in visual question answering, we use a transformer based sequence
to sequence model to fuse representations of product text, Optical Character
Recognition (OCR) tokens and visual objects detected in the product image. The
framework is further extended with the capability to extract attribute value
across multiple product categories with a single model, by training the decoder
to predict both product category and attribute value and conditioning its
output on product category. The model provides a unified attribute extraction
solution desirable at an e-commerce platform that offers numerous product
categories with a diverse body of product attributes. We evaluated the model on
two product attributes, one with many possible values and one with a small set
of possible values, over 14 product categories and found the model could
achieve 15% gain on the Recall and 10% gain on the F1 score compared to
existing methods using text-only features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Neural Architecture Search via Proxy Data. (arXiv:2106.04784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Na_B/0/1/0/all/0/1">Byunggook Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Mok_J/0/1/0/all/0/1">Jisoo Mok</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_H/0/1/0/all/0/1">Hyeokjun Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04784">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the increasing interest in neural architecture search (NAS), the
significant computational cost of NAS is a hindrance to researchers. Hence, we
propose to reduce the cost of NAS using proxy data, i.e., a representative
subset of the target data, without sacrificing search performance. Even though
data selection has been used across various fields, our evaluation of existing
selection methods for NAS algorithms offered by NAS-Bench-1shot1 reveals that
they are not always appropriate for NAS and a new selection method is
necessary. By analyzing proxy data constructed using various selection methods
through data entropy, we propose a novel proxy data selection method tailored
for NAS. To empirically demonstrate the effectiveness, we conduct thorough
experiments across diverse datasets, search spaces, and NAS algorithms.
Consequently, NAS algorithms with the proposed selection discover architectures
that are competitive with those obtained using the entire dataset. It
significantly reduces the search cost: executing DARTS with the proposed
selection requires only 40 minutes on CIFAR-10 and 7.5 hours on ImageNet with a
single GPU. Additionally, when the architecture searched on ImageNet using the
proposed selection is inversely transferred to CIFAR-10, a state-of-the-art
test error of 2.4\% is yielded. Our code is available at
https://github.com/nabk89/NAS-with-Proxy-data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boolean Matrix Factorization via Nonnegative Auxiliary Optimization. (arXiv:2106.04708v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Truong_D/0/1/0/all/0/1">Duc P. Truong</a>, <a href="http://arxiv.org/find/cs/1/au:+Skau_E/0/1/0/all/0/1">Erik Skau</a>, <a href="http://arxiv.org/find/cs/1/au:+Desantis_D/0/1/0/all/0/1">Derek Desantis</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1">Boian Alexandrov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04708">
                                    <div class="article-summary-box-inner">
                                        <span>A novel approach to Boolean matrix factorization (BMF) is presented. Instead
of solving the BMF problem directly, this approach solves a nonnegative
optimization problem with the constraint over an auxiliary matrix whose Boolean
structure is identical to the initial Boolean data. Then the solution of the
nonnegative auxiliary optimization problem is thresholded to provide a solution
for the BMF problem. We provide the proofs for the equivalencies of the two
solution spaces under the existence of an exact solution. Moreover, the
nonincreasing property of the algorithm is also proven. Experiments on
synthetic and real datasets are conducted to show the effectiveness and
complexity of the algorithm compared to other current methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NRGNN: Learning a Label Noise-Resistant Graph Neural Network on Sparsely and Noisily Labeled Graphs. (arXiv:2106.04714v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_E/0/1/0/all/0/1">Enyan Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_C/0/1/0/all/0/1">Charu Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Suhang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04714">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have achieved promising results for
semi-supervised learning tasks on graphs such as node classification. Despite
the great success of GNNs, many real-world graphs are often sparsely and
noisily labeled, which could significantly degrade the performance of GNNs, as
the noisy information could propagate to unlabeled nodes via graph structure.
Thus, it is important to develop a label noise-resistant GNN for
semi-supervised node classification. Though extensive studies have been
conducted to learn neural networks with noisy labels, they mostly focus on
independent and identically distributed data and assume a large number of noisy
labels are available, which are not directly applicable for GNNs. Thus, we
investigate a novel problem of learning a robust GNN with noisy and limited
labels. To alleviate the negative effects of label noise, we propose to link
the unlabeled nodes with labeled nodes of high feature similarity to bring more
clean label information. Furthermore, accurate pseudo labels could be obtained
by this strategy to provide more supervision and further reduce the effects of
label noise. Our theoretical and empirical analysis verify the effectiveness of
these two strategies under mild conditions. Extensive experiments on real-world
datasets demonstrate the effectiveness of the proposed method in learning a
robust GNN with noisy and limited labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. (arXiv:2106.04619v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/stat/1/au:+Sharma_Y/0/1/0/all/0/1">Yash Sharma</a>, <a href="http://arxiv.org/find/stat/1/au:+Gresele_L/0/1/0/all/0/1">Luigi Gresele</a>, <a href="http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>, <a href="http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/stat/1/au:+Besserve_M/0/1/0/all/0/1">Michel Besserve</a>, <a href="http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1">Francesco Locatello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04619">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised representation learning has shown remarkable success in a
number of domains. A common practice is to perform data augmentation via
hand-crafted transformations intended to leave the semantics of the data
invariant. We seek to understand the empirical success of this approach from a
theoretical perspective. We formulate the augmentation process as a latent
variable model by postulating a partition of the latent representation into a
content component, which is assumed invariant to augmentation, and a style
component, which is allowed to change. Unlike prior work on disentanglement and
independent component analysis, we allow for both nontrivial statistical and
causal dependencies in the latent space. We study the identifiability of the
latent representation based on pairs of views of the observations and prove
sufficient conditions that allow us to identify the invariant content partition
up to an invertible mapping in both generative and discriminative settings. We
find numerical simulations with dependent latent variables are consistent with
our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional,
visually complex images with rich causal dependencies, which we use to study
the effect of data augmentations performed in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm. (arXiv:2106.04763v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1">MohammadJavad Azizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1">Branislav Kveton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04763">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of best-arm identification (BAI) in contextual bandits
in the fixed-budget setting. We propose a general successive elimination
algorithm that proceeds in stages and eliminates a fixed fraction of suboptimal
arms in each stage. This design takes advantage of the strengths of static and
adaptive allocations. We analyze the algorithm in linear models and obtain a
better error bound than prior work. We also apply it to generalized linear
models (GLMs) and bound its error. This is the first BAI algorithm for GLMs in
the fixed-budget setting. Our extensive numerical experiments show that our
algorithm outperforms the state of art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Curriculum Design for Teaching via Demonstrations: Theory and Applications. (arXiv:2106.04696v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yengera_G/0/1/0/all/0/1">Gaurav Yengera</a>, <a href="http://arxiv.org/find/cs/1/au:+Devidze_R/0/1/0/all/0/1">Rati Devidze</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamalaruban_P/0/1/0/all/0/1">Parameswaran Kamalaruban</a>, <a href="http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1">Adish Singla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04696">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of teaching via demonstrations in sequential
decision-making settings. In particular, we study how to design a personalized
curriculum over demonstrations to speed up the learner&#x27;s convergence. We
provide a unified curriculum strategy for two popular learner models: Maximum
Causal Entropy Inverse Reinforcement Learning (MaxEnt-IRL) and Cross-Entropy
Behavioral Cloning (CrossEnt-BC). Our unified strategy induces a ranking over
demonstrations based on a notion of difficulty scores computed w.r.t. the
teacher&#x27;s optimal policy and the learner&#x27;s current policy. Compared to the
state of the art, our strategy doesn&#x27;t require access to the learner&#x27;s internal
dynamics and still enjoys similar convergence guarantees under mild technical
conditions. Furthermore, we adapt our curriculum strategy to teach a learner
using domain knowledge in the form of task-specific difficulty scores when the
teacher&#x27;s optimal policy is unknown. Experiments on a car driving simulator
environment and shortest path problems in a grid-world environment demonstrate
the effectiveness of our proposed curriculum strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Price Against a Moving Target. (arXiv:2106.04689v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leme_R/0/1/0/all/0/1">Renato Paes Leme</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivan_B/0/1/0/all/0/1">Balasubramanian Sivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1">Yifeng Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Worah_P/0/1/0/all/0/1">Pratik Worah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04689">
                                    <div class="article-summary-box-inner">
                                        <span>In the Learning to Price setting, a seller posts prices over time with the
goal of maximizing revenue while learning the buyer&#x27;s valuation. This problem
is very well understood when values are stationary (fixed or iid). Here we
study the problem where the buyer&#x27;s value is a moving target, i.e., they change
over time either by a stochastic process or adversarially with bounded
variation. In either case, we provide matching upper and lower bounds on the
optimal revenue loss. Since the target is moving, any information learned soon
becomes out-dated, which forces the algorithms to keep switching between
exploring and exploiting phases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices. (arXiv:2106.04723v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1">Stylianos I. Venieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Panopoulos_I/0/1/0/all/0/1">Ioannis Panopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Venieris_I/0/1/0/all/0/1">Iakovos S. Venieris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04723">
                                    <div class="article-summary-box-inner">
                                        <span>Radical progress in the field of deep learning (DL) has led to unprecedented
accuracy in diverse inference tasks. As such, deploying DL models across mobile
platforms is vital to enable the development and broad availability of the
next-generation intelligent apps. Nevertheless, the wide and optimised
deployment of DL models is currently hindered by the vast system heterogeneity
of mobile devices, the varying computational cost of different DL models and
the variability of performance needs across DL applications. This paper
proposes OODIn, a framework for the optimised deployment of DL apps across
heterogeneous mobile devices. OODIn comprises a novel DL-specific software
architecture together with an analytical framework for modelling DL
applications that: (1) counteract the variability in device resources and DL
models by means of a highly parametrised multi-layer design; and (2) perform a
principled optimisation of both model- and system-level parameters through a
multi-objective formulation, designed for DL inference apps, in order to adapt
the deployment to the user-specified performance requirements and device
capabilities. Quantitative evaluation shows that the proposed framework
consistently outperforms status-quo designs across heterogeneous devices and
delivers up to 4.3x and 3.5x performance gain over highly optimised platform-
and model-aware designs respectively, while effectively adapting execution to
dynamic changes in resource availability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Faster Algorithms for Bilevel Optimization. (arXiv:2106.04692v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Junjie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1">Kaiyi Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingbin Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04692">
                                    <div class="article-summary-box-inner">
                                        <span>Bilevel optimization has been widely applied in many important machine
learning applications such as hyperparameter optimization and meta-learning.
Recently, several momentum-based algorithms have been proposed to solve bilevel
optimization problems faster. However, those momentum-based algorithms do not
achieve provably better computational complexity than
$\mathcal{O}(\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we
propose two new algorithms for bilevel optimization, where the first algorithm
adopts momentum-based recursive iterations, and the second algorithm adopts
recursive gradient estimations in nested loops to decrease the variance. We
show that both algorithms achieve the complexity of
$\mathcal{O}(\epsilon^{-1.5})$, which outperforms all existing algorithms by
the order of magnitude. Our experiments validate our theoretical results and
demonstrate the superior empirical performance of our algorithms in
hyperparameter applications. Our codes for MRBO, VRBO and other benchmarks are
available $\text{online}^1$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adaptive Swarm System (SASS). (arXiv:2106.04679v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04679">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed artificial intelligence (DAI) studies artificial intelligence
entities working together to reason, plan, solve problems, organize behaviors
and strategies, make collective decisions and learn. This Ph.D. research
proposes a principled Multi-Agent Systems (MAS) cooperation framework,
Self-Adaptive Swarm System (SASS), to bridge the fourth level automation gap
between perception, communication, planning, execution, decision-making, and
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning. (arXiv:2106.04590v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liew_S/0/1/0/all/0/1">Seng Pei Liew</a>, <a href="http://arxiv.org/find/cs/1/au:+Takahashi_T/0/1/0/all/0/1">Tsubasa Takahashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueno_M/0/1/0/all/0/1">Michihiko Ueno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04590">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new framework of synthesizing data using deep generative models
in a differentially private manner. Within our framework, sensitive data are
sanitized with rigorous privacy guarantees in a one-shot fashion, such that
training deep generative models is possible without re-using the original data.
Hence, no extra privacy costs or model constraints are incurred, in contrast to
popular approaches such as Differentially Private Stochastic Gradient Descent
(DP-SGD), which, among other issues, causes degradation in privacy guarantees
as the training iteration increases. We demonstrate a realization of our
framework by making use of the characteristic function and an adversarial
re-weighting objective, which are of independent interest as well. Our proposal
has theoretical guarantees of performance, and empirical evaluations on
multiple datasets show that our approach outperforms other methods at
reasonable levels of privacy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpeechBrain: A General-Purpose Speech Toolkit. (arXiv:2106.04624v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ravanelli_M/0/1/0/all/0/1">Mirco Ravanelli</a>, <a href="http://arxiv.org/find/eess/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/eess/1/au:+Plantinga_P/0/1/0/all/0/1">Peter Plantinga</a>, <a href="http://arxiv.org/find/eess/1/au:+Rouhe_A/0/1/0/all/0/1">Aku Rouhe</a>, <a href="http://arxiv.org/find/eess/1/au:+Cornell_S/0/1/0/all/0/1">Samuele Cornell</a>, <a href="http://arxiv.org/find/eess/1/au:+Lugosch_L/0/1/0/all/0/1">Loren Lugosch</a>, <a href="http://arxiv.org/find/eess/1/au:+Subakan_C/0/1/0/all/0/1">Cem Subakan</a>, <a href="http://arxiv.org/find/eess/1/au:+Dawalatabad_N/0/1/0/all/0/1">Nauman Dawalatabad</a>, <a href="http://arxiv.org/find/eess/1/au:+Heba_A/0/1/0/all/0/1">Abdelwahab Heba</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhong_J/0/1/0/all/0/1">Jianyuan Zhong</a>, <a href="http://arxiv.org/find/eess/1/au:+Chou_J/0/1/0/all/0/1">Ju-Chieh Chou</a>, <a href="http://arxiv.org/find/eess/1/au:+Yeh_S/0/1/0/all/0/1">Sung-Lin Yeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_S/0/1/0/all/0/1">Szu-Wei Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Liao_C/0/1/0/all/0/1">Chien-Feng Liao</a>, <a href="http://arxiv.org/find/eess/1/au:+Rastorgueva_E/0/1/0/all/0/1">Elena Rastorgueva</a>, <a href="http://arxiv.org/find/eess/1/au:+Grondin_F/0/1/0/all/0/1">Fran&#xe7;ois Grondin</a>, <a href="http://arxiv.org/find/eess/1/au:+Aris_W/0/1/0/all/0/1">William Aris</a>, <a href="http://arxiv.org/find/eess/1/au:+Na_H/0/1/0/all/0/1">Hwidong Na</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Mori_R/0/1/0/all/0/1">Renato De Mori</a>, <a href="http://arxiv.org/find/eess/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04624">
                                    <div class="article-summary-box-inner">
                                        <span>SpeechBrain is an open-source and all-in-one speech toolkit. It is designed
to facilitate the research and development of neural speech processing
technologies by being simple, flexible, user-friendly, and well-documented.
This paper describes the core architecture designed to support several tasks of
common interest, allowing users to naturally conceive, compare and share novel
speech processing pipelines. SpeechBrain achieves competitive or
state-of-the-art performance in a wide range of speech benchmarks. It also
provides training recipes, pretrained models, and inference scripts for popular
speech datasets, as well as tutorials which allow anyone with basic Python
proficiency to familiarize themselves with speech technologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EXPObench: Benchmarking Surrogate-based Optimisation Algorithms on Expensive Black-box Functions. (arXiv:2106.04618v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bliek_L/0/1/0/all/0/1">Laurens Bliek</a>, <a href="http://arxiv.org/find/cs/1/au:+Guijt_A/0/1/0/all/0/1">Arthur Guijt</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlsson_R/0/1/0/all/0/1">Rickard Karlsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1">Sicco Verwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Weerdt_M/0/1/0/all/0/1">Mathijs de Weerdt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04618">
                                    <div class="article-summary-box-inner">
                                        <span>Surrogate algorithms such as Bayesian optimisation are especially designed
for black-box optimisation problems with expensive objectives, such as
hyperparameter tuning or simulation-based optimisation. In the literature,
these algorithms are usually evaluated with synthetic benchmarks which are well
established but have no expensive objective, and only on one or two real-life
applications which vary wildly between papers. There is a clear lack of
standardisation when it comes to benchmarking surrogate algorithms on
real-life, expensive, black-box objective functions. This makes it very
difficult to draw conclusions on the effect of algorithmic contributions. A new
benchmark library, EXPObench, provides first steps towards such a
standardisation. The library is used to provide an extensive comparison of six
different surrogate algorithms on four expensive optimisation problems from
different real-life applications. This has led to new insights regarding the
relative importance of exploration, the evaluation time of the objective, and
the used model. A further contribution is that we make the algorithms and
benchmark problem instances publicly available, contributing to more uniform
analysis of surrogate algorithms. Most importantly, we include the performance
of the six algorithms on all evaluated problem instances. This results in a
unique new dataset that lowers the bar for researching new methods as the
number of expensive evaluations required for comparison is significantly
reduced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Launchpad: A Programming Model for Distributed Machine Learning Research. (arXiv:2106.04516v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Fan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Barth_Maron_G/0/1/0/all/0/1">Gabriel Barth-Maron</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanczyk_P/0/1/0/all/0/1">Piotr Sta&#x144;czyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1">Matthew Hoffman</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kroiss_M/0/1/0/all/0/1">Manuel Kroiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Pope_A/0/1/0/all/0/1">Aedan Pope</a>, <a href="http://arxiv.org/find/cs/1/au:+Rrustemi_A/0/1/0/all/0/1">Alban Rrustemi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04516">
                                    <div class="article-summary-box-inner">
                                        <span>A major driver behind the success of modern machine learning algorithms has
been their ability to process ever-larger amounts of data. As a result, the use
of distributed systems in both research and production has become increasingly
prevalent as a means to scale to this growing data. At the same time, however,
distributing the learning process can drastically complicate the implementation
of even simple algorithms. This is especially problematic as many machine
learning practitioners are not well-versed in the design of distributed
systems, let alone those that have complicated communication topologies. In
this work we introduce Launchpad, a programming model that simplifies the
process of defining and launching distributed systems that is specifically
tailored towards a machine learning audience. We describe our framework, its
design philosophy and implementation, and give a number of examples of common
learning algorithms whose designs are greatly simplified by this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Generalization for Document Authentication against Practical Recapturing Attacks. (arXiv:2101.01404v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Changsheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuzheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_F/0/1/0/all/0/1">Fengbo Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01404">
                                    <div class="article-summary-box-inner">
                                        <span>Recapturing attack can be employed as a simple but effective anti-forensic
tool for digital document images. Inspired by the document inspection process
that compares a questioned document against a reference sample, we proposed a
document recapture detection scheme by employing Siamese network to compare and
extract distinct features in a recapture document image. The proposed algorithm
takes advantages of both metric learning and image forensic techniques. Instead
of adopting Euclidean distance-based loss function, we integrate the forensic
similarity function with a triplet loss and a normalized softmax loss. After
training with the proposed triplet selection strategy, the resulting feature
embedding clusters the genuine samples near the reference while pushes the
recaptured samples apart. In the experiment, we consider practical domain
generalization problems, such as the variations in printing/imaging devices,
substrates, recapturing channels, and document types. To evaluate the
robustness of different approaches, we benchmark some popular off-the-shelf
machine learning-based approaches, a state-of-the-art document image detection
scheme, and the proposed schemes with different network backbones under various
experimental protocols. Experimental results show that the proposed schemes
with different network backbones have consistently outperformed the
state-of-the-art approaches under different experimental settings.
Specifically, under the most challenging scenario in our experiment, i.e.,
evaluation across different types of documents that produced by different
devices, we have achieved less than 5.00% APCER (Attack Presentation
Classification Error Rate) and 5.56% BPCER (Bona Fide Presentation
Classification Error Rate) by the proposed network with ResNeXt101 backbone at
5% BPCER decision threshold.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-09">2021-06-09</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic Bias Metrics Do Not Correlate with Application Bias. (arXiv:2012.15859v5 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goldfarb_Tarrant_S/0/1/0/all/0/1">Seraphina Goldfarb-Tarrant</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchant_R/0/1/0/all/0/1">Rebecca Marchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_R/0/1/0/all/0/1">Ricardo Mu&#xf1;oz Sanchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandya_M/0/1/0/all/0/1">Mugdha Pandya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1">Adam Lopez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15859">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Processing (NLP) systems learn harmful societal biases that
cause them to amplify inequality as they are deployed in more and more
situations. To guide efforts at debiasing these systems, the NLP community
relies on a variety of metrics that quantify bias in models. Some of these
metrics are intrinsic, measuring bias in word embedding spaces, and some are
extrinsic, measuring bias in downstream tasks that the word embeddings enable.
Do these intrinsic and extrinsic metrics correlate with each other? We compare
intrinsic and extrinsic metrics across hundreds of trained models covering
different tasks and experimental conditions. Our results show no reliable
correlation between these metrics that holds in all scenarios across tasks and
languages. We urge researchers working on debiasing to focus on extrinsic
measures of bias, and to make using these measures more feasible via creation
of new challenge sets and annotated test data. To aid this effort, we release
code, a new intrinsic metric, and an annotated test set focused on gender bias
in hate speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ARBERT &amp; MARBERT: Deep Bidirectional Transformers for Arabic. (arXiv:2101.01785v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1">AbdelRahim Elmadany</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1">El Moatez Billah Nagoudi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01785">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models (LMs) are currently integral to many natural
language processing systems. Although multilingual LMs were also introduced to
serve many languages, these have limitations such as being costly at inference
time and the size and diversity of non-English data involved in their
pre-training. We remedy these issues for a collection of diverse Arabic
varieties by introducing two powerful deep bidirectional transformer-based
models, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a
new benchmark for multi-dialectal Arabic language understanding evaluation.
ARLUE is built using 42 datasets targeting six different task clusters,
allowing us to offer a series of standardized experiments under rich
conditions. When fine-tuned on ARLUE, our models collectively achieve new
state-of-the-art results across the majority of tasks (37 out of 48
classification tasks, on the 42 datasets). Our best model acquires the highest
ARLUE score (77.40) across all six task clusters, outperforming all other
models including XLM-R Large (~ 3.4 x larger size). Our models are publicly
available at https://github.com/UBC-NLP/marbert and ARLUE will be released
through the same repository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Sparse Attention more Interpretable?. (arXiv:2106.01087v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1">Clara Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazov_S/0/1/0/all/0/1">Stefan Lazov</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01087">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse attention has been claimed to increase model interpretability under
the assumption that it highlights influential inputs. Yet the attention
distribution is typically over representations internal to the model rather
than the inputs themselves, suggesting this assumption may not have merit. We
build on the recent work exploring the interpretability of attention; we design
a set of experiments to help us understand how sparsity affects our ability to
use attention as an explainability tool. On three text classification tasks, we
verify that only a weak relationship between inputs and co-indexed intermediate
representations exists -- under sparse attention and otherwise. Further, we do
not find any plausible mappings from sparse attention distributions to a sparse
set of influential inputs through other avenues. Rather, we observe in this
setting that inducing sparsity may make it less plausible that attention can be
used as a tool for understanding model behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Contextualized Word Embeddings. (arXiv:2010.12684v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hofmann_V/0/1/0/all/0/1">Valentin Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pierrehumbert_J/0/1/0/all/0/1">Janet B. Pierrehumbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12684">
                                    <div class="article-summary-box-inner">
                                        <span>Static word embeddings that represent words by a single vector cannot capture
the variability of word meaning in different linguistic and extralinguistic
contexts. Building on prior work on contextualized and dynamic word embeddings,
we introduce dynamic contextualized word embeddings that represent words as a
function of both linguistic and extralinguistic context. Based on a pretrained
language model (PLM), dynamic contextualized word embeddings model time and
social space jointly, which makes them attractive for a range of NLP tasks
involving semantic variability. We highlight potential application scenarios by
means of qualitative and quantitative analyses on four English datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Schema2QA: High-Quality and Low-Cost Q&amp;A Agents for the Structured Web. (arXiv:2001.05609v6 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Silei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Campagna_G/0/1/0/all/0/1">Giovanni Campagna</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1">Monica S. Lam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.05609">
                                    <div class="article-summary-box-inner">
                                        <span>Building a question-answering agent currently requires large annotated
datasets, which are prohibitively expensive. This paper proposes Schema2QA, an
open-source toolkit that can generate a Q&amp;A system from a database schema
augmented with a few annotations for each field. The key concept is to cover
the space of possible compound queries on the database with a large number of
in-domain questions synthesized with the help of a corpus of generic query
templates. The synthesized data and a small paraphrase set are used to train a
novel neural network based on the BERT pretrained model. We use Schema2QA to
generate Q&amp;A systems for five Schema.org domains, restaurants, people, movies,
books and music, and obtain an overall accuracy between 64% and 75% on
crowdsourced questions for these domains. Once annotations and paraphrases are
obtained for a Schema.org schema, no additional manual effort is needed to
create a Q&amp;A agent for any website that uses the same schema. Furthermore, we
demonstrate that learning can be transferred from the restaurant to the hotel
domain, obtaining a 64% accuracy on crowdsourced questions with no manual
effort. Schema2QA achieves an accuracy of 60% on popular restaurant questions
that can be answered using Schema.org. Its performance is comparable to Google
Assistant, 7% lower than Siri, and 15% higher than Alexa. It outperforms all
these assistants by at least 18% on more complex, long-tail questions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAiRE in DialDoc21: Data Augmentation for Information-Seeking Dialogue System. (arXiv:2106.03530v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1">Etsuko Ishii</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1">Genta Indra Winata</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhaojiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1">Andrea Madotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zihan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1">Pascale Fung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03530">
                                    <div class="article-summary-box-inner">
                                        <span>Information-seeking dialogue systems, including knowledge identification and
response generation, aim to respond to users with fluent, coherent, and
informative responses based on users&#x27; needs, which. To tackle this challenge,
we utilize data augmentation methods and several training techniques with the
pre-trained language models to learn a general pattern of the task and thus
achieve promising performance. In DialDoc21 competition, our system achieved
74.95 F1 score and 60.74 Exact Match score in subtask 1, and 37.72 SacreBLEU
score in subtask 2. Empirical analysis is provided to explain the effectiveness
of our approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PANDORA Talks: Personality and Demographics on Reddit. (arXiv:2004.04460v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gjurkovic_M/0/1/0/all/0/1">Matej Gjurkovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Karan_M/0/1/0/all/0/1">Mladen Karan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vukojevic_I/0/1/0/all/0/1">Iva Vukojevi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Bosnjak_M/0/1/0/all/0/1">Mihaela Bo&#x161;njak</a>, <a href="http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1">Jan &#x160;najder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04460">
                                    <div class="article-summary-box-inner">
                                        <span>Personality and demographics are important variables in social sciences,
while in NLP they can aid in interpretability and removal of societal biases.
However, datasets with both personality and demographic labels are scarce. To
address this, we present PANDORA, the first large-scale dataset of Reddit
comments labeled with three personality models (including the well-established
Big 5 model) and demographics (age, gender, and location) for more than 10k
users. We showcase the usefulness of this dataset on three experiments, where
we leverage the more readily available data from other personality models to
predict the Big 5 traits, analyze gender classification biases arising from
psycho-demographic variables, and carry out a confirmatory and exploratory
analysis based on psychological theories. Finally, we present benchmark
prediction models for all personality and demographic variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Recombine and Resample Data for Compositional Generalization. (arXiv:2010.03706v6 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1">Ekin Aky&#xfc;rek</a>, <a href="http://arxiv.org/find/cs/1/au:+Akyurek_A/0/1/0/all/0/1">Afra Feyza Aky&#xfc;rek</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03706">
                                    <div class="article-summary-box-inner">
                                        <span>Flexible neural sequence models outperform grammar- and automaton-based
counterparts on a variety of tasks. However, neural models perform poorly in
settings requiring compositional generalization beyond the training data --
particularly to rare or unseen subsequences. Past work has found symbolic
scaffolding (e.g. grammars or automata) essential in these settings. We
describe R&amp;R, a learned data augmentation scheme that enables a large category
of compositional generalizations without appeal to latent symbolic structure.
R&amp;R has two components: recombination of original training examples via a
prototype-based generative model and resampling of generated examples to
encourage extrapolation. Training an ordinary neural sequence model on a
dataset augmented with recombined and resampled examples significantly improves
generalization in two language processing problems -- instruction following
(SCAN) and morphological analysis (SIGMORPHON 2018) -- where R&amp;R enables
learning of new constructions and tenses from as few as eight initial examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting the Unknown from Long Math Problems. (arXiv:2103.12048v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nakashole_N/0/1/0/all/0/1">Ndapa Nakashole</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12048">
                                    <div class="article-summary-box-inner">
                                        <span>In problem solving, understanding the problem that one seeks to solve is an
essential initial step. In this paper, we propose computational methods for
facilitating problem understanding through the task of recognizing the unknown
in specifications of long Math problems. We focus on the topic of Probability.
Our experimental results show that learning models yield strong results on the
task, a promising first step towards human interpretable, modular approaches to
understanding long Math problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating label suggestions for opinion mining in German Covid-19 social media. (arXiv:2105.12980v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beck_T/0/1/0/all/0/1">Tilman Beck</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Ji-Ung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Viehmann_C/0/1/0/all/0/1">Christina Viehmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Maurer_M/0/1/0/all/0/1">Marcus Maurer</a>, <a href="http://arxiv.org/find/cs/1/au:+Quiring_O/0/1/0/all/0/1">Oliver Quiring</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12980">
                                    <div class="article-summary-box-inner">
                                        <span>This work investigates the use of interactively updated label suggestions to
improve upon the efficiency of gathering annotations on the task of opinion
mining in German Covid-19 social media data. We develop guidelines to conduct a
controlled annotation study with social science students and find that
suggestions from a model trained on a small, expert-annotated dataset already
lead to a substantial improvement - in terms of inter-annotator agreement(+.14
Fleiss&#x27; $\kappa$) and annotation quality - compared to students that do not
receive any label suggestions. We further find that label suggestions from
interactively trained models do not lead to an improvement over suggestions
from a static model. Nonetheless, our analysis of suggestion bias shows that
annotators remain capable of reflecting upon the suggested label in general.
Finally, we confirm the quality of the annotated data in transfer learning
experiments between different annotator groups. To facilitate further research
in opinion mining on social media data, we release our collected data
consisting of 200 expert and 2,785 student annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Reordering for Modeling Latent Alignments in Sequence Transduction. (arXiv:2106.03257v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bailin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1">Mirella Lapata</a>, <a href="http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1">Ivan Titov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03257">
                                    <div class="article-summary-box-inner">
                                        <span>Despite success in many domains, neural models struggle in settings where
train and test examples are drawn from different distributions. In particular,
in contrast to humans, conventional sequence-to-sequence (seq2seq) models fail
to generalize systematically, i.e., interpret sentences representing novel
combinations of concepts (e.g., text segments) seen in training. Traditional
grammar formalisms excel in such settings by implicitly encoding alignments
between input and output segments, but are hard to scale and maintain. Instead
of engineering a grammar, we directly model segment-to-segment alignments as
discrete structured latent variables within a neural seq2seq model. To
efficiently explore the large space of alignments, we introduce a reorder-first
align-later framework whose central component is a neural reordering module
producing {\it separable} permutations. We present an efficient dynamic
programming algorithm performing exact marginal inference of separable
permutations, and, thus, enabling end-to-end differentiable training of our
model. The resulting seq2seq model exhibits better systematic generalization
than standard models on synthetic problems and NLP tasks (i.e., semantic
parsing and machine translation).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Translate, then Parse! A strong baseline for Cross-Lingual AMR Parsing. (arXiv:2106.04565v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uhrig_S/0/1/0/all/0/1">Sarah Uhrig</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Y/0/1/0/all/0/1">Yoalli Rezepka Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Opitz_J/0/1/0/all/0/1">Juri Opitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04565">
                                    <div class="article-summary-box-inner">
                                        <span>In cross-lingual Abstract Meaning Representation (AMR) parsing, researchers
develop models that project sentences from various languages onto their AMRs to
capture their essential semantic structures: given a sentence in any language,
we aim to capture its core semantic content through concepts connected by
manifold types of semantic relations. Methods typically leverage large silver
training data to learn a single model that is able to project non-English
sentences to AMRs. However, we find that a simple baseline tends to be
over-looked: translating the sentences to English and projecting their AMR with
a monolingual AMR parser (translate+parse,T+P). In this paper, we revisit this
simple two-step base-line, and enhance it with a strong NMT system and a strong
AMR parser. Our experiments show that T+P outperforms a recent state-of-the-art
system across all tested languages: German, Italian, Spanish and Mandarin with
+14.6, +12.6, +14.3 and +16.0 Smatch points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta Learning for Knowledge Distillation. (arXiv:2106.04570v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Canwen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04570">
                                    <div class="article-summary-box-inner">
                                        <span>We present Meta Learning for Knowledge Distillation (MetaDistil), a simple
yet effective alternative to traditional knowledge distillation (KD) methods
where the teacher model is fixed during training. We show the teacher network
can learn to better transfer knowledge to the student network (i.e., learning
to teach) with the feedback from the performance of the distilled student
network in a meta learning framework. Moreover, we introduce a pilot update
mechanism to improve the alignment between the inner-learner and meta-learner
in meta learning algorithms that focus on an improved inner-learner.
Experiments on various benchmarks show that MetaDistil can yield significant
improvements compared with traditional KD algorithms and is less sensitive to
the choice of different student capacity and hyperparameters, facilitating the
use of KD on different tasks and models. The code is available at
https://github.com/JetRunner/MetaDistil</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blow the Dog Whistle: A Chinese Dataset for Cant Understanding with Common Sense and World Knowledge. (arXiv:2104.02704v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Canwen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1">Tao Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Ke Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02704">
                                    <div class="article-summary-box-inner">
                                        <span>Cant is important for understanding advertising, comedies and dog-whistle
politics. However, computational research on cant is hindered by a lack of
available datasets. In this paper, we propose a large and diverse Chinese
dataset for creating and understanding cant from a computational linguistics
perspective. We formulate a task for cant understanding and provide both
quantitative and qualitative analysis for tested word embedding similarity and
pretrained language models. Experiments suggest that such a task requires deep
language understanding, common sense, and world knowledge and thus can be a
good testbed for pretrained language models and help models perform better on
other tasks. The code is available at https://github.com/JetRunner/dogwhistle.
The data and leaderboard are available at
https://competitions.codalab.org/competitions/30451.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViTA: Visual-Linguistic Translation by Aligning Object Tags. (arXiv:2106.00250v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1">Kshitij Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gautam_D/0/1/0/all/0/1">Devansh Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1">Radhika Mamidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00250">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal Machine Translation (MMT) enriches the source text with visual
information for translation. It has gained popularity in recent years, and
several pipelines have been proposed in the same direction. Yet, the task lacks
quality datasets to illustrate the contribution of visual modality in the
translation systems. In this paper, we propose our system under the team name
Volta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We
also participate in the textual-only subtask of the same language pair for
which we use mBART, a pretrained multilingual sequence-to-sequence model. For
multimodal translation, we propose to enhance the textual input by bringing the
visual information to a textual domain by extracting object tags from the
image. We also explore the robustness of our system by systematically degrading
the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test
set and challenge set of the multimodal task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Transformers with Gradient Boosted Decision Trees for NLI Fine-Tuning. (arXiv:2105.03791v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Minixhofer_B/0/1/0/all/0/1">Benjamin Minixhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gritta_M/0/1/0/all/0/1">Milan Gritta</a>, <a href="http://arxiv.org/find/cs/1/au:+Iacobacci_I/0/1/0/all/0/1">Ignacio Iacobacci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03791">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning has become the dominant paradigm for many natural language
processing tasks. In addition to models being pretrained on large datasets,
they can be further trained on intermediate (supervised) tasks that are similar
to the target task. For small Natural Language Inference (NLI) datasets,
language modelling is typically followed by pretraining on a large (labelled)
NLI dataset before fine-tuning with each NLI subtask. In this work, we explore
Gradient Boosted Decision Trees (GBDTs) as an alternative to the commonly used
Multi-Layer Perceptron (MLP) classification head. GBDTs have desirable
properties such as good performance on dense, numerical features and are
effective where the ratio of the number of samples w.r.t the number of features
is low. We then introduce FreeGBDT, a method of fitting a GBDT head on the
features computed during fine-tuning to increase performance without additional
computation by the neural network. We demonstrate the effectiveness of our
method on several NLI datasets using a strong baseline model (RoBERTa-large
with MNLI pretraining). The FreeGBDT shows a consistent improvement over the
MLP classification head.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bh\&#x3D;a$\unicode{x1E63}$\&#x3D;acitra: Visualising the dialect geography of South Asia. (arXiv:2105.14082v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1">Aryaman Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Farris_A/0/1/0/all/0/1">Adam Farris</a>, <a href="http://arxiv.org/find/cs/1/au:+R_G/0/1/0/all/0/1">Gopalakrishnan R</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1">Samopriya Basu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14082">
                                    <div class="article-summary-box-inner">
                                        <span>We present Bh\&#x3D;a$\unicode{x1E63}$\&#x3D;acitra, a dialect mapping system for South
Asia built on a database of linguistic studies of languages of the region
annotated for topic and location data. We analyse language coverage and look
towards applications to typology by visualising example datasets. The
application is not only meant to be useful for feature mapping, but also serves
as a new kind of interactive bibliography for linguists of South Asian
languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruocheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1">Jiayuan Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1">Samuel J. Gershman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15814">
                                    <div class="article-summary-box-inner">
                                        <span>We present Language-mediated, Object-centric Representation Learning (LORL),
a paradigm for learning disentangled, object-centric scene representations from
vision and language. LORL builds upon recent advances in unsupervised object
discovery and segmentation, notably MONet and Slot Attention. While these
algorithms learn an object-centric representation just by reconstructing the
input image, LORL enables them to further learn to associate the learned
representations to concepts, i.e., words for object categories, properties, and
spatial relationships, from language input. These object-centric concepts
derived from language facilitate the learning of object-centric
representations. LORL can be integrated with various unsupervised object
discovery algorithms that are language-agnostic. Experiments show that the
integration of LORL consistently improves the performance of unsupervised
object discovery methods on two datasets via the help of language. We also show
that concepts learned by LORL, in conjunction with object discovery methods,
aid downstream tasks such as referring expression comprehension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bangla Natural Language Processing: A Comprehensive Review of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sen_O/0/1/0/all/0/1">Ovishake Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1">Mohtasim Fuad</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">MD. Nazrul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabbi_J/0/1/0/all/0/1">Jakaria Rabbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">MD. Kamrul Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Baz_M/0/1/0/all/0/1">Mohammed Baz</a>, <a href="http://arxiv.org/find/cs/1/au:+Masud_M/0/1/0/all/0/1">Mehedi Masud</a>, <a href="http://arxiv.org/find/cs/1/au:+Awal_M/0/1/0/all/0/1">Md. Abdul Awal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fime_A/0/1/0/all/0/1">Awal Ahmed Fime</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1">Md. Tahmid Hasan Fuad</a>, <a href="http://arxiv.org/find/cs/1/au:+Sikder_D/0/1/0/all/0/1">Delowar Sikder</a>, <a href="http://arxiv.org/find/cs/1/au:+Iftee_M/0/1/0/all/0/1">MD. Akil Raihan Iftee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14875">
                                    <div class="article-summary-box-inner">
                                        <span>The Bangla language is the seventh most spoken language, with 265 million
native and non-native speakers worldwide. However, English is the predominant
language for online resources and technical knowledge, journals, and
documentation. Consequently, many Bangla-speaking people, who have limited
command of English, face hurdles to utilize English resources. To bridge the
gap between limited support and increasing demand, researchers conducted many
experiments and developed valuable tools and techniques to create and process
Bangla language materials. Many efforts are also ongoing to make it easy to use
the Bangla language in the online and technical domains. There are some review
papers to understand the past, previous, and future Bangla Natural Language
Processing (BNLP) trends. The studies are mainly concentrated on the specific
domains of BNLP, such as sentiment analysis, speech recognition, optical
character recognition, and text summarization. There is an apparent scarcity of
resources that contain a comprehensive study of the recent BNLP tools and
methods. Therefore, in this paper, we present a thorough review of 71 BNLP
research papers and categorize them into 11 categories, namely Information
Extraction, Machine Translation, Named Entity Recognition, Parsing, Parts of
Speech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake
Detection, Text Summarization, Word Sense Disambiguation, and Speech Processing
and Recognition. We study articles published between 1999 to 2021, and 50% of
the papers were published after 2015. We discuss Classical, Machine Learning
and Deep Learning approaches with different datasets while addressing the
limitations and current and future trends of the BNLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I-BERT: Integer-only BERT Quantization. (arXiv:2101.01321v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sehoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1">Amir Gholami</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhewei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01321">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer based models, like BERT and RoBERTa, have achieved
state-of-the-art results in many Natural Language Processing tasks. However,
their memory footprint, inference latency, and power consumption are
prohibitive efficient inference at the edge, and even at the data center. While
quantization can be a viable solution for this, previous work on quantizing
Transformer based models use floating-point arithmetic during inference, which
cannot efficiently utilize integer-only logical units such as the recent Turing
Tensor Cores, or traditional integer-only ARM processors. In this work, we
propose I-BERT, a novel quantization scheme for Transformer based models that
quantizes the entire inference with integer-only arithmetic. Based on
lightweight integer-only approximation methods for nonlinear operations, e.g.,
GELU, Softmax, and Layer Normalization, I-BERT performs an end-to-end
integer-only BERT inference without any floating point calculation. We evaluate
our approach on GLUE downstream tasks using RoBERTa-Base/Large. We show that
for both cases, I-BERT achieves similar (and slightly higher) accuracy as
compared to the full-precision baseline. Furthermore, our preliminary
implementation of I-BERT shows a speedup of 2.4-4.0x for INT8 inference on a T4
GPU system as compared to FP32 inference. The framework has been developed in
PyTorch and has been open-sourced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lexical Semantic Recognition. (arXiv:2004.15008v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Nelson F. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1">Daniel Hershcovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Kranzlein_M/0/1/0/all/0/1">Michael Kranzlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1">Nathan Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.15008">
                                    <div class="article-summary-box-inner">
                                        <span>In lexical semantics, full-sentence segmentation and segment labeling of
various phenomena are generally treated separately, despite their
interdependence. We hypothesize that a unified lexical semantic recognition
task is an effective way to encapsulate previously disparate styles of
annotation, including multiword expression identification / classification and
supersense tagging. Using the STREUSLE corpus, we train a neural CRF sequence
tagger and evaluate its performance along various axes of annotation. As the
label set generalizes that of previous tasks (PARSEME, DiMSUM), we additionally
evaluate how well the model generalizes to those test sets, finding that it
approaches or surpasses existing models despite training only on STREUSLE. Our
work also establishes baseline models and evaluation metrics for integrated and
accurate modeling of lexical semantics, facilitating future work in this area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Itihasa: A large-scale corpus for Sanskrit to English translation. (arXiv:2106.03269v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1">Rahul Aralikatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Lhoneux_M/0/1/0/all/0/1">Miryam de Lhoneux</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1">Anoop Kunchukuttan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1">Anders S&#xf8;gaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03269">
                                    <div class="article-summary-box-inner">
                                        <span>This work introduces Itihasa, a large-scale translation dataset containing
93,000 pairs of Sanskrit shlokas and their English translations. The shlokas
are extracted from two Indian epics viz., The Ramayana and The Mahabharata. We
first describe the motivation behind the curation of such a dataset and follow
up with empirical analysis to bring out its nuances. We then benchmark the
performance of standard translation models on this corpus and show that even
state-of-the-art transformer architectures perform poorly, emphasizing the
complexity of the dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization. (arXiv:2105.12002v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1">Simiao Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minshuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haoming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12002">
                                    <div class="article-summary-box-inner">
                                        <span>The Lottery Ticket Hypothesis suggests that an over-parametrized network
consists of &#x60;&#x60;lottery tickets&#x27;&#x27;, and training a certain collection of them
(i.e., a subnetwork) can match the performance of the full model. In this
paper, we study such a collection of tickets, which is referred to as &#x60;&#x60;winning
tickets&#x27;&#x27;, in extremely over-parametrized models, e.g., pre-trained language
models. We observe that at certain compression ratios, the generalization
performance of the winning tickets can not only match but also exceed that of
the full model. In particular, we observe a phase transition phenomenon: As the
compression ratio increases, generalization performance of the winning tickets
first improves then deteriorates after a certain threshold. We refer to the
tickets on the threshold as &#x60;&#x60;super tickets&#x27;&#x27;. We further show that the phase
transition is task and model dependent -- as the model size becomes larger and
the training data set becomes smaller, the transition becomes more pronounced.
Our experiments on the GLUE benchmark show that the super tickets improve
single task fine-tuning by $0.9$ points on BERT-base and $1.0$ points on
BERT-large, in terms of task-average score. We also demonstrate that adaptively
sharing the super tickets across tasks benefits multi-task learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Position Bias Mitigation: A Knowledge-Aware Graph Model for Emotion Cause Extraction. (arXiv:2106.03518v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hanqi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1">Lin Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1">Gabriele Pergola</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yulan He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03518">
                                    <div class="article-summary-box-inner">
                                        <span>The Emotion Cause Extraction (ECE)} task aims to identify clauses which
contain emotion-evoking information for a particular emotion expressed in text.
We observe that a widely-used ECE dataset exhibits a bias that the majority of
annotated cause clauses are either directly before their associated emotion
clauses or are the emotion clauses themselves. Existing models for ECE tend to
explore such relative position information and suffer from the dataset bias. To
investigate the degree of reliance of existing ECE models on clause relative
positions, we propose a novel strategy to generate adversarial examples in
which the relative position information is no longer the indicative feature of
cause clauses. We test the performance of existing models on such adversarial
examples and observe a significant performance drop. To address the dataset
bias, we propose a novel graph-based method to explicitly model the emotion
triggering paths by leveraging the commonsense knowledge to enhance the
semantic dependencies between a candidate clause and an emotion clause.
Experimental results show that our proposed approach performs on par with the
existing state-of-the-art methods on the original ECE dataset, and is more
robust against adversarial attacks compared to existing models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Temperature Matters in Abstractive Summarization Distillation. (arXiv:2106.03441v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengqiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xingxing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1">Hangbo Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Furu Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03441">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress of abstractive text summarization largely relies on large
pre-trained sequence-to-sequence Transformer models, which are computationally
expensive. This paper aims to distill these large models into smaller ones for
faster inference and minimal performance loss. Pseudo-labeling based methods
are popular in sequence-to-sequence model distillation. In this paper, we find
simply manipulating attention temperatures in Transformers can make pseudo
labels easier to learn for student models. Our experiments on three
summarization datasets show our proposed method consistently improves over
vanilla pseudo-labeling based methods. We also find that both the pseudo labels
and summaries produced by our students are shorter and more abstractive. We
will make our code and models publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation. (arXiv:2009.07526v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1">Yuan Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yujing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yue Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07526">
                                    <div class="article-summary-box-inner">
                                        <span>Scene graphs are semantic abstraction of images that encourage visual
understanding and reasoning. However, the performance of Scene Graph Generation
(SGG) is unsatisfactory when faced with biased data in real-world scenarios.
Conventional debiasing research mainly studies from the view of balancing data
distribution or learning unbiased models and representations, ignoring the
correlations among the biased classes. In this work, we analyze this problem
from a novel cognition perspective: automatically building a hierarchical
cognitive structure from the biased predictions and navigating that hierarchy
to locate the relationships, making the tail relationships receive more
attention in a coarse-to-fine mode. To this end, we propose a novel debiasing
Cognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive
structure CogTree to organize the relationships based on the prediction of a
biased SGG model. The CogTree distinguishes remarkably different relationships
at first and then focuses on a small portion of easily confused ones. Then, we
propose a debiasing loss specially for this cognitive structure, which supports
coarse-to-fine distinction for the correct relationships. The loss is
model-agnostic and consistently boosting the performance of several
state-of-the-art models. The code is available at:
https://github.com/CYVincent/Scene-Graph-Transformer-CogTree.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantics of the Unwritten: The Effect of End of Paragraph and Sequence Tokens on Text Generation with GPT2. (arXiv:2004.02251v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">He Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1">Peng Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jimmy Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1">Luchen Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_K/0/1/0/all/0/1">Kun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Ming Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.02251">
                                    <div class="article-summary-box-inner">
                                        <span>The semantics of a text is manifested not only by what is read, but also by
what is not read. In this article, we will study how the implicit &quot;not read&quot;
information such as end-of-paragraph (\eop) and end-of-sequence (\eos) affect
the quality of text generation. Specifically, we find that the pre-trained
language model GPT2 can generate better continuations by learning to generate
the \eop in the fine-tuning stage. Experimental results on English story
generation show that \eop can lead to higher BLEU score and lower \eos
perplexity. We also conduct experiments on a self-collected Chinese essay
dataset with Chinese-GPT2, a character level LM without \eop or \eos during
pre-training. Experimental results show that the Chinese GPT2 can generate
better essay endings with \eop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks. (arXiv:2004.07601v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shaoxiong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07601">
                                    <div class="article-summary-box-inner">
                                        <span>Mental health is a critical issue in modern society, and mental disorders
could sometimes turn to suicidal ideation without effective treatment. Early
detection of mental disorders and suicidal ideation from social content
provides a potential way for effective social intervention. However,
classifying suicidal ideation and other mental disorders is challenging as they
share similar patterns in language usage and sentimental polarity. This paper
enhances text representation with lexicon-based sentiment scores and latent
topics and proposes using relation networks to detect suicidal ideation and
mental disorders with related risk indicators. The relation module is further
equipped with the attention mechanism to prioritize more critical relational
features. Through experiments on three real-world datasets, our model
outperforms most of its counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoQA: From Databases To QA Semantic Parsers With Only Synthetic Training Data. (arXiv:2010.04806v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Silei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Semnani_S/0/1/0/all/0/1">Sina J. Semnani</a>, <a href="http://arxiv.org/find/cs/1/au:+Campagna_G/0/1/0/all/0/1">Giovanni Campagna</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1">Monica S. Lam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04806">
                                    <div class="article-summary-box-inner">
                                        <span>We propose AutoQA, a methodology and toolkit to generate semantic parsers
that answer questions on databases, with no manual effort. Given a database
schema and its data, AutoQA automatically generates a large set of high-quality
questions for training that covers different database operations. It uses
automatic paraphrasing combined with template-based parsing to find alternative
expressions of an attribute in different parts of speech. It also uses a novel
filtered auto-paraphraser to generate correct paraphrases of entire sentences.
We apply AutoQA to the Schema2QA dataset and obtain an average logical form
accuracy of 62.9% when tested on natural questions, which is only 6.4% lower
than a model trained with expert natural language annotations and paraphrase
data collected from crowdworkers. To demonstrate the generality of AutoQA, we
also apply it to the Overnight dataset. AutoQA achieves 69.8% answer accuracy,
16.4% higher than the state-of-the-art zero-shot models and only 5.2% lower
than the same model trained with human data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Transformers. (arXiv:2106.04554v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiangyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04554">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved great success in many artificial intelligence
fields, such as natural language processing, computer vision, and audio
processing. Therefore, it is natural to attract lots of interest from academic
and industry researchers. Up to the present, a great variety of Transformer
variants (a.k.a. X-formers) have been proposed, however, a systematic and
comprehensive literature review on these Transformer variants is still missing.
In this survey, we provide a comprehensive review of various X-formers. We
first briefly introduce the vanilla Transformer and then propose a new taxonomy
of X-formers. Next, we introduce the various X-formers from three perspectives:
architectural modification, pre-training, and applications. Finally, we outline
some potential directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EarlyBERT: Efficient BERT Training via Early-bird Lottery Tickets. (arXiv:2101.00063v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuohang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00063">
                                    <div class="article-summary-box-inner">
                                        <span>Heavily overparameterized language models such as BERT, XLNet and T5 have
achieved impressive success in many NLP tasks. However, their high model
complexity requires enormous computation resources and extremely long training
time for both pre-training and fine-tuning. Many works have studied model
compression on large NLP models, but only focusing on reducing inference time
while still requiring an expensive training process. Other works use extremely
large batch sizes to shorten the pre-training time, at the expense of higher
computational resource demands. In this paper, inspired by the Early-Bird
Lottery Tickets recently studied for computer vision tasks, we propose
EarlyBERT, a general computationally-efficient training algorithm applicable to
both pre-training and fine-tuning of large-scale language models. By slimming
the self-attention and fully-connected sub-layers inside a transformer, we are
the first to identify structured winning tickets in the early stage of BERT
training. We apply those tickets towards efficient BERT training, and conduct
comprehensive pre-training and fine-tuning experiments on GLUE and SQuAD
downstream tasks. Our results show that EarlyBERT achieves comparable
performance to standard BERT, with 35~45% less training time. Code is available
at https://github.com/VITA-Group/EarlyBERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TIMEDIAL: Temporal Commonsense Reasoning in Dialog. (arXiv:2106.04571v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1">Lianhui Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aditya Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1">Shyam Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Luheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Faruqui_M/0/1/0/all/0/1">Manaal Faruqui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04571">
                                    <div class="article-summary-box-inner">
                                        <span>Everyday conversations require understanding everyday events, which in turn,
requires understanding temporal commonsense concepts interwoven with those
events. Despite recent progress with massive pre-trained language models (LMs)
such as T5 and GPT-3, their capability of temporal reasoning in dialogs remains
largely under-explored. In this paper, we present the first study to
investigate pre-trained LMs for their temporal reasoning capabilities in
dialogs by introducing a new task and a crowd-sourced English challenge set,
TIMEDIAL. We formulate TIME-DIAL as a multiple-choice cloze task with over 1.1K
carefully curated dialogs. Empirical results demonstrate that even the best
performing models struggle on this task compared to humans, with 23 absolute
points of gap in accuracy. Furthermore, our analysis reveals that the models
fail to reason about dialog context correctly; instead, they rely on shallow
cues based on existing temporal patterns in context, motivating future research
for modeling temporal concepts in text and robust contextual reasoning about
them. The dataset is publicly available at:
https://github.com/google-research-datasets/timedial.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Doing Natural Language Processing in A Natural Way: An NLP toolkit based on object-oriented knowledge base and multi-level grammar base. (arXiv:2105.05227v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yu Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05227">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce an NLP toolkit based on object-oriented knowledge base and
multi-level grammar base. This toolkit focuses on semantic parsing, it also has
abilities to discover new knowledge and grammar automatically, new discovered
knowledge and grammar will be identified by human, and will be used to update
the knowledge base and grammar base. This process can be iterated many times to
improve the toolkit continuously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stabilizing Label Assignment for Speech Separation by Self-supervised Pre-training. (arXiv:2010.15366v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Sung-Feng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_S/0/1/0/all/0/1">Shun-Po Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Da-Rong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yi-Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Gene-Ping Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15366">
                                    <div class="article-summary-box-inner">
                                        <span>Speech separation has been well developed, with the very successful
permutation invariant training (PIT) approach, although the frequent label
assignment switching happening during PIT training remains to be a problem when
better convergence speed and achievable performance are desired. In this paper,
we propose to perform self-supervised pre-training to stabilize the label
assignment in training the speech separation model. Experiments over several
types of self-supervised approaches, several typical speech separation models
and two different datasets showed that very good improvements are achievable if
a proper self-supervised approach is chosen.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using a New Nonlinear Gradient Method for Solving Large Scale Convex Optimization Problems with an Application on Arabic Medical Text. (arXiv:2106.04383v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Hammoud_J/0/1/0/all/0/1">Jaafar Hammoud</a>, <a href="http://arxiv.org/find/math/1/au:+Eisab_A/0/1/0/all/0/1">Ali Eisab</a>, <a href="http://arxiv.org/find/math/1/au:+Dobrenkoa_N/0/1/0/all/0/1">Natalia Dobrenkoa</a>, <a href="http://arxiv.org/find/math/1/au:+Gusarovaa_N/0/1/0/all/0/1">Natalia Gusarovaa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04383">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient methods have applications in multiple fields, including signal
processing, image processing, and dynamic systems. In this paper, we present a
nonlinear gradient method for solving convex supra-quadratic functions by
developing the search direction, that done by hybridizing between the two
conjugate coefficients HRM [2] and NHS [1]. The numerical results proved the
effectiveness of the presented method by applying it to solve standard problems
and reaching the exact solution if the objective function is quadratic convex.
Also presented in this article, an application to the problem of named entities
in the Arabic medical language, as it proved the stability of the proposed
method and its efficiency in terms of execution time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reading StackOverflow Encourages Cheating: Adding Question Text Improves Extractive Code Generation. (arXiv:2106.04447v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Orlanski_G/0/1/0/all/0/1">Gabriel Orlanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Gittens_A/0/1/0/all/0/1">Alex Gittens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04447">
                                    <div class="article-summary-box-inner">
                                        <span>Answering a programming question using only its title is difficult as salient
contextual information is omitted. Based on this observation, we present a
corpus of over 40,000 StackOverflow question texts to be used in conjunction
with their corresponding intents from the CoNaLa dataset (Yin et al., 2018).
Using both the intent and question body, we use BART to establish a baseline
BLEU score of 34.35 for this new task. We find further improvements of $2.8\%$
by combining the mined CoNaLa data with the labeled data to achieve a 35.32
BLEU score. We evaluate prior state-of-the-art CoNaLa models with this
additional data and find that our proposed method of using the body and mined
data beats the BLEU score of the prior state-of-the-art by $71.96\%$. Finally,
we perform ablations to demonstrate that BART is an unsupervised multimodal
learner and examine its extractive behavior. The code and data can be found
https://github.com/gabeorlanski/stackoverflow-encourages-cheating.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are Pretrained Transformers Robust in Intent Classification? A Missing Ingredient in Evaluation of Out-of-Scope Intent Detection. (arXiv:2106.04564v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian-Guo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1">Kazuma Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1">Yao Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Ye Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04564">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained Transformer-based models were reported to be robust in intent
classification. In this work, we first point out the importance of in-domain
out-of-scope detection in few-shot intent recognition tasks and then illustrate
the vulnerability of pretrained Transformer-based models against samples that
are in-domain but out-of-scope (ID-OOS). We empirically show that pretrained
models do not perform well on both ID-OOS examples and general out-of-scope
examples, especially on fine-grained few-shot intent detection tasks. To figure
out how the models mistakenly classify ID-OOS intents as in-scope intents, we
further conduct analysis on confidence scores and the overlapping keywords and
provide several prospective directions for future work. We release the relevant
resources to facilitate future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Subhabrata Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed Hassan Awadallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04563">
                                    <div class="article-summary-box-inner">
                                        <span>While deep and large pre-trained models are the state-of-the-art for various
natural language processing tasks, their huge size poses significant challenges
for practical uses in resource constrained settings. Recent works in knowledge
distillation propose task-agnostic as well as task-specific methods to compress
these models, with task-specific ones often yielding higher compression rate.
In this work, we develop a new task-agnostic distillation framework
XtremeDistilTransformers that leverages the advantage of task-specific methods
for learning a small universal model that can be applied to arbitrary tasks and
languages. To this end, we study the transferability of several source tasks,
augmentation resources and model architecture for distillation. We evaluate our
model performance on multiple tasks, including the General Language
Understanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and
a massive multi-lingual NER dataset with 41 languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Lifelong Learning of End-to-end ASR. (arXiv:2104.01616v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Heng-Jui Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1">Lin-shan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01616">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) technologies today are primarily optimized
for given datasets; thus, any changes in the application environment (e.g.,
acoustic conditions or topic domains) may inevitably degrade the performance.
We can collect new data describing the new environment and fine-tune the
system, but this naturally leads to higher error rates for the earlier
datasets, referred to as catastrophic forgetting. The concept of lifelong
learning (LLL) aiming to enable a machine to sequentially learn new tasks from
new datasets describing the changing real world without forgetting the
previously learned knowledge is thus brought to attention. This paper reports,
to our knowledge, the first effort to extensively consider and analyze the use
of various approaches of LLL in end-to-end (E2E) ASR, including proposing novel
methods in saving data for past domains to mitigate the catastrophic forgetting
problem. An overall relative reduction of 28.7% in WER was achieved compared to
the fine-tuning baseline when sequentially learning on three very different
benchmark corpora. This can be the first step toward the highly desired ASR
technologies capable of synchronizing with the continuously changing real
world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Turing: an Accurate and Interpretable Multi-Hypothesis Cross-Domain Natural Language Database Interface. (arXiv:2106.04559v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_W/0/1/0/all/0/1">Wenjie Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahidi_H/0/1/0/all/0/1">Hamidreza Shahidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadar_A/0/1/0/all/0/1">&#xc1;kos K&#xe1;d&#xe1;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1">Keyi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ateeq_J/0/1/0/all/0/1">Jawad Ateeq</a>, <a href="http://arxiv.org/find/cs/1/au:+Barot_H/0/1/0/all/0/1">Harsh Barot</a>, <a href="http://arxiv.org/find/cs/1/au:+Alon_M/0/1/0/all/0/1">Meidan Alon</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yanshuai Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04559">
                                    <div class="article-summary-box-inner">
                                        <span>A natural language database interface (NLDB) can democratize data-driven
insights for non-technical users. However, existing Text-to-SQL semantic
parsers cannot achieve high enough accuracy in the cross-database setting to
allow good usability in practice. This work presents Turing, a NLDB system
toward bridging this gap. The cross-domain semantic parser of Turing with our
novel value prediction method achieves $75.1\%$ execution accuracy, and
$78.3\%$ top-5 beam execution accuracy on the Spider validation set. To benefit
from the higher beam accuracy, we design an interactive system where the SQL
hypotheses in the beam are explained step-by-step in natural language, with
their differences highlighted. The user can then compare and judge the
hypotheses to select which one reflects their intention if any. The English
explanations of SQL queries in Turing are produced by our high-precision
natural language generation system based on synchronous grammars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Obtaining Better Static Word Embeddings Using Contextual Embedding Models. (arXiv:2106.04302v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1">Prakhar Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04302">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of contextual word embeddings -- representations of words which
incorporate semantic and syntactic information from their context -- has led to
tremendous improvements on a wide variety of NLP tasks. However, recent
contextual models have prohibitively high computational cost in many use-cases
and are often hard to interpret. In this work, we demonstrate that our proposed
distillation method, which is a simple extension of CBOW-based training, allows
to significantly improve computational efficiency of NLP applications, while
outperforming the quality of existing static embeddings trained from scratch as
well as those distilled from previously proposed methods. As a side-effect, our
approach also allows a fair comparison of both contextual and static embeddings
via standard lexical evaluation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLTR: An End-to-End, Transformer-Based System for Cell Level TableRetrieval and Table Question Answering. (arXiv:2106.04441v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Feifei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Canim_M/0/1/0/all/0/1">Mustafa Canim</a>, <a href="http://arxiv.org/find/cs/1/au:+Glass_M/0/1/0/all/0/1">Michael Glass</a>, <a href="http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1">Alfio Gliozzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_P/0/1/0/all/0/1">Peter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04441">
                                    <div class="article-summary-box-inner">
                                        <span>We present the first end-to-end, transformer-based table question answering
(QA) system that takes natural language questions and massive table corpus as
inputs to retrieve the most relevant tables and locate the correct table cells
to answer the question. Our system, CLTR, extends the current state-of-the-art
QA over tables model to build an end-to-end table QA architecture. This system
has successfully tackled many real-world table QA problems with a simple,
unified pipeline. Our proposed system can also generate a heatmap of candidate
columns and rows over complex tables and allow users to quickly identify the
correct cells to answer questions. In addition, we introduce two new
open-domain benchmarks, E2E_WTQ and E2E_GNQ, consisting of 2,005 natural
language questions over 76,242 tables. The benchmarks are designed to validate
CLTR as well as accommodate future table retrieval and end-to-end table QA
research and experiments. Our experiments demonstrate that our system is the
current state-of-the-art model on the table retrieval task and produces
promising results for end-to-end table QA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1">Daniel Rosenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1">Itai Gat</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04484">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms have shown promising results in visual question
answering (VQA) tasks, but a more careful look reveals that they often do not
understand the rich signal they are being fed with. To understand and better
measure the generalization capabilities of VQA systems, we look at their
robustness to counterfactually augmented data. Our proposed augmentations are
designed to make a focused intervention on a specific property of the question
such that the answer changes. Using these augmentations, we propose a new
robustness measure, Robustness to Augmented Data (RAD), which measures the
consistency of model predictions between original and augmented examples.
Through extensive experimentation, we show that RAD, unlike classical accuracy
measures, can quantify when state-of-the-art systems are not robust to
counterfactuals. We find substantial failure cases which reveal that current
VQA systems are still brittle. Finally, we connect between robustness and
generalization, demonstrating the predictive power of RAD for performance on
unseen augmentations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks. (arXiv:2106.04489v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahabadi_R/0/1/0/all/0/1">Rabeeh Karimi Mahabadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1">Mostafa Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1">James Henderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04489">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art parameter-efficient fine-tuning methods rely on introducing
adapter modules between the layers of a pretrained language model. However,
such modules are trained separately for each task and thus do not enable
sharing information across tasks. In this paper, we show that we can learn
adapter parameters for all layers and tasks by generating them using shared
hypernetworks, which condition on task, adapter position, and layer id in a
transformer model. This parameter-efficient multi-task learning framework
allows us to achieve the best of both worlds by sharing knowledge across tasks
via hypernetworks while enabling the model to adapt to each individual task
through task-specific adapters. Experiments on the well-known GLUE benchmark
show improved performance in multi-task learning while adding only 0.29%
parameters per task. We additionally demonstrate substantial performance
improvements in few-shot domain generalization across a variety of tasks. Our
code is publicly available in https://github.com/rabeehk/hyperformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Training for Machine Reading Comprehension with Virtual Embeddings. (arXiv:2106.04437v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziqing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yiming Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1">Chenglei Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1">Wanxiang Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shijin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1">Guoping Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04437">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training (AT) as a regularization method has proved its
effectiveness on various tasks. Though there are successful applications of AT
on some NLP tasks, the distinguishing characteristics of NLP tasks have not
been exploited. In this paper, we aim to apply AT on machine reading
comprehension (MRC) tasks. Furthermore, we adapt AT for MRC tasks by proposing
a novel adversarial training method called PQAT that perturbs the embedding
matrix instead of word vectors. To differentiate the roles of passages and
questions, PQAT uses additional virtual P/Q-embedding matrices to gather the
global perturbations of words from passages and questions separately. We test
the method on a wide range of MRC tasks, including span-based extractive RC and
multiple-choice RC. The results show that adversarial training is effective
universally, and PQAT further improves the performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Question Generation for Adaptive Education. (arXiv:2106.04262v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1">Megha Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04262">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent and adaptive online education systems aim to make high-quality
education available for a diverse range of students. However, existing systems
usually depend on a pool of hand-made questions, limiting how fine-grained and
open-ended they can be in adapting to individual students. We explore targeted
question generation as a controllable sequence generation task. We first show
how to fine-tune pre-trained language models for deep knowledge tracing
(LM-KT). This model accurately predicts the probability of a student answering
a question correctly, and generalizes to questions not seen in training. We
then use LM-KT to specify the objective and data for training a model to
generate questions conditioned on the student and target difficulty. Our
results show we succeed at generating novel, well-calibrated language
translation questions for second language learners from a real online education
platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SynthRef: Generation of Synthetic Referring Expressions for Object Segmentation. (arXiv:2106.04403v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazakos_I/0/1/0/all/0/1">Ioannis Kazakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventura_C/0/1/0/all/0/1">Carles Ventura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellver_M/0/1/0/all/0/1">Miriam Bellver</a>, <a href="http://arxiv.org/find/cs/1/au:+Silberer_C/0/1/0/all/0/1">Carina Silberer</a>, <a href="http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1">Xavier Giro-i-Nieto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04403">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep learning have brought significant progress in visual
grounding tasks such as language-guided video object segmentation. However,
collecting large datasets for these tasks is expensive in terms of annotation
time, which represents a bottleneck. To this end, we propose a novel method,
namely SynthRef, for generating synthetic referring expressions for target
objects in an image (or video frame), and we also present and disseminate the
first large-scale dataset with synthetic referring expressions for video object
segmentation. Our experiments demonstrate that by training with our synthetic
referring expressions one can improve the ability of a model to generalize
across different datasets, without any additional annotation cost. Moreover,
our formulation allows its application to any object detection or segmentation
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning compositional structures for semantic graph parsing. (arXiv:2106.04398v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Groschwitz_J/0/1/0/all/0/1">Jonas Groschwitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Fowlie_M/0/1/0/all/0/1">Meaghan Fowlie</a>, <a href="http://arxiv.org/find/cs/1/au:+Koller_A/0/1/0/all/0/1">Alexander Koller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04398">
                                    <div class="article-summary-box-inner">
                                        <span>AM dependency parsing is a method for neural semantic graph parsing that
exploits the principle of compositionality. While AM dependency parsers have
been shown to be fast and accurate across several graphbanks, they require
explicit annotations of the compositional tree structures for training. In the
past, these were obtained using complex graphbank-specific heuristics written
by experts. Here we show how they can instead be trained directly on the graphs
with a neural latent-variable model, drastically reducing the amount and
complexity of manual heuristics. We demonstrate that our model picks up on
several linguistic phenomena on its own and achieves comparable accuracy to
supervised training, greatly facilitating the use of AM dependency parsing for
new sembanks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hash Layers For Large Sparse Models. (arXiv:2106.04426v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1">Sainbayar Sukhbaatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1">Arthur Szlam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04426">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the training of sparse layers that use different parameters
for different inputs based on hashing in large Transformer models.
Specifically, we modify the feedforward layer to hash to different sets of
weights depending on the current token, over all tokens in the sequence. We
show that this procedure either outperforms or is competitive with
learning-to-route mixture-of-expert methods such as Switch Transformers and
BASE Layers, while requiring no routing parameters or extra terms in the
objective function such as a load balancing loss, and no sophisticated
assignment algorithm. We study the performance of different hashing techniques,
hash sizes and input features, and show that balanced and random hashes focused
on the most local features work best, compared to either learning clusters or
using longer-range context. We show our approach works well both on large
language modeling and dialogue tasks, and on downstream fine-tuning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cyberbullying Detection Using Deep Neural Network from Social Media Comments in Bangla Language. (arXiv:2106.04506v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1">Md Faisal Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_Z/0/1/0/all/0/1">Zalish Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Biash_Z/0/1/0/all/0/1">Zarin Tasnim Biash</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryen_A/0/1/0/all/0/1">Ahmed Ann Noor Ryen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_A/0/1/0/all/0/1">Arman Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashraf_F/0/1/0/all/0/1">Faisal Bin Ashraf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04506">
                                    <div class="article-summary-box-inner">
                                        <span>Cyberbullying or Online harassment detection on social media for various
major languages is currently being given a good amount of focus by researchers
worldwide. Being the seventh most speaking language in the world and increasing
usage of online platform among the Bengali speaking people urge to find
effective detection technique to handle the online harassment. In this paper,
we have proposed binary and multiclass classification model using hybrid neural
network for bully expression detection in Bengali language. We have used 44,001
users comments from popular public Facebook pages, which fall into five classes
- Non-bully, Sexual, Threat, Troll and Religious. We have examined the
performance of our proposed models from different perspective. Our binary
classification model gives 87.91% accuracy, whereas introducing ensemble
technique after neural network for multiclass classification, we got 85%
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Generative Framework for Aspect-Based Sentiment Analysis. (arXiv:2106.04300v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Junqi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+ji_T/0/1/0/all/0/1">Tuo ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04300">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect-based Sentiment Analysis (ABSA) aims to identify the aspect terms,
their corresponding sentiment polarities, and the opinion terms. There exist
seven subtasks in ABSA. Most studies only focus on the subsets of these
subtasks, which leads to various complicated ABSA models while hard to solve
these subtasks in a unified framework. In this paper, we redefine every subtask
target as a sequence mixed by pointer indexes and sentiment class indexes,
which converts all ABSA subtasks into a unified generative formulation. Based
on the unified formulation, we exploit the pre-training sequence-to-sequence
model BART to solve all ABSA subtasks in an end-to-end framework. Extensive
experiments on four ABSA datasets for seven subtasks demonstrate that our
framework achieves substantial performance gain and provides a real unified
end-to-end solution for the whole ABSA subtasks, which could benefit multiple
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Semantic Parser to Parse Them All: Sequence to Sequence Multi-Task Learning on Semantic Parsing Datasets. (arXiv:2106.04476v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damonte_M/0/1/0/all/0/1">Marco Damonte</a>, <a href="http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1">Emilio Monti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04476">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic parsers map natural language utterances to meaning representations.
The lack of a single standard for meaning representations led to the creation
of a plethora of semantic parsing datasets. To unify different datasets and
train a single model for them, we investigate the use of Multi-Task Learning
(MTL) architectures. We experiment with five datasets (Geoquery, NLMaps, TOP,
Overnight, AMR). We find that an MTL architecture that shares the entire
network across datasets yields competitive or better parsing accuracies than
the single-task baselines, while reducing the total number of parameters by
68%. We further provide evidence that MTL has also better compositional
generalization than single-task models. We also present a comparison of task
sampling methods and propose a competitive alternative to widespread
proportional sampling strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable agent communication from scratch(with a generic visual processor emerging on the side). (arXiv:2106.04258v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1">Roberto Dess&#xec;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1">Marco Baroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04258">
                                    <div class="article-summary-box-inner">
                                        <span>As deep networks begin to be deployed as autonomous agents, the issue of how
they can communicate with each other becomes important. Here, we train two deep
nets from scratch to perform realistic referent identification through
unsupervised emergent communication. We show that the largely interpretable
emergent protocol allows the nets to successfully communicate even about object
types they did not see at training time. The visual representations induced as
a by-product of our training regime, moreover, show comparable quality, when
re-used as generic visual features, to a recent self-supervised learning model.
Our results provide concrete evidence of the viability of (interpretable)
emergent deep net communication in a more realistic scenario than previously
considered, as well as establishing an intriguing link between this field and
self-supervised visual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Staircase Attention for Recurrent Processing of Sequences. (arXiv:2106.04279v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ju_D/0/1/0/all/0/1">Da Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1">Sainbayar Sukhbaatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04279">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanisms have become a standard tool for sequence modeling tasks,
in particular by stacking self-attention layers over the entire input sequence
as in the Transformer architecture. In this work we introduce a novel attention
procedure called staircase attention that, unlike self-attention, operates
across the sequence (in time) recurrently processing the input by adding
another step of processing. A step in the staircase comprises of backward
tokens (encoding the sequence so far seen) and forward tokens (ingesting a new
part of the sequence), or an extreme Ladder version with a forward step of zero
that simply repeats the Transformer on each step of the ladder, sharing the
weights. We thus describe a family of such models that can trade off
performance and compute, by either increasing the amount of recurrence through
time, the amount of sequential processing via recurrence in depth, or both.
Staircase attention is shown to be able to solve tasks that involve tracking
that conventional Transformers cannot, due to this recurrence. Further, it is
shown to provide improved modeling power for the same size model (number of
parameters) compared to self-attentive Transformers on large language modeling
and dialogue tasks, yielding significant perplexity gains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperbolic Temporal Knowledge Graph Embeddings with Relational and Time Curvatures. (arXiv:2106.04311v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Montella_S/0/1/0/all/0/1">Sebastien Montella</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_Barahona_L/0/1/0/all/0/1">Lina Rojas-Barahona</a>, <a href="http://arxiv.org/find/cs/1/au:+Heinecke_J/0/1/0/all/0/1">Johannes Heinecke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04311">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graph (KG) completion has been excessively studied with a massive
number of models proposed for the Link Prediction (LP) task. The main
limitation of such models is their insensitivity to time. Indeed, the temporal
aspect of stored facts is often ignored. To this end, more and more works
consider time as a parameter to complete KGs. In this paper, we first
demonstrate that, by simply increasing the number of negative samples, the
recent AttH model can achieve competitive or even better performance than the
state-of-the-art on Temporal KGs (TKGs), albeit its nontemporality. We further
propose Hercules, a time-aware extension of AttH model, which defines the
curvature of a Riemannian manifold as the product of both relation and time.
Our experiments show that both Hercules and AttH achieve competitive or new
state-of-the-art performances on ICEWS04 and ICEWS05-15 datasets. Therefore,
one should raise awareness when learning TKGs representations to identify
whether time truly boosts performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Realistic Evaluation Principles for Cross-document Coreference Resolution. (arXiv:2106.04192v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1">Arie Cattan</a>, <a href="http://arxiv.org/find/cs/1/au:+Eirew_A/0/1/0/all/0/1">Alon Eirew</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1">Gabriel Stanovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1">Mandar Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1">Ido Dagan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04192">
                                    <div class="article-summary-box-inner">
                                        <span>We point out that common evaluation practices for cross-document coreference
resolution have been unrealistically permissive in their assumed settings,
yielding inflated results. We propose addressing this issue via two evaluation
methodology principles. First, as in other tasks, models should be evaluated on
predicted mentions rather than on gold mentions. Doing this raises a subtle
issue regarding singleton coreference clusters, which we address by decoupling
the evaluation of mention detection from that of coreference linking. Second,
we argue that models should not exploit the synthetic topic structure of the
standard ECB+ dataset, forcing models to confront the lexical ambiguity
challenge, as intended by the dataset creators. We demonstrate empirically the
drastic impact of our more realistic evaluation principles on a competitive
model, yielding a score which is 33 F1 lower compared to evaluating by prior
lenient practices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Word Segmentation from Discrete Speech Units in Low-Resource Settings. (arXiv:2106.04298v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boito_M/0/1/0/all/0/1">Marcely Zanon Boito</a>, <a href="http://arxiv.org/find/cs/1/au:+Yusuf_B/0/1/0/all/0/1">Bolaji Yusuf</a>, <a href="http://arxiv.org/find/cs/1/au:+Ondel_L/0/1/0/all/0/1">Lucas Ondel</a>, <a href="http://arxiv.org/find/cs/1/au:+Villavicencio_A/0/1/0/all/0/1">Aline Villavicencio</a>, <a href="http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1">Laurent Besacier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04298">
                                    <div class="article-summary-box-inner">
                                        <span>When documenting oral-languages, Unsupervised Word Segmentation (UWS) from
speech is a useful, yet challenging, task. It can be performed from phonetic
transcriptions, or in the absence of these, from the output of unsupervised
speech discretization models. These discretization models are trained using raw
speech only, producing discrete speech units which can be applied for
downstream (text-based) tasks. In this paper we compare five of these models:
three Bayesian and two neural approaches, with regards to the exploitability of
the produced units for UWS. Two UWS models are experimented with and we report
results for Finnish, Hungarian, Mboshi, Romanian and Russian in a low-resource
setting (using only 5k sentences). Our results suggest that neural models for
speech discretization are difficult to exploit in our setting, and that it
might be necessary to adapt them to limit sequence length. We obtain our best
UWS results by using the SHMM and H-SHMM Bayesian models, which produce high
quality, yet compressed, discrete representations of the input speech signal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lexicon Learning for Few-Shot Neural Sequence Modeling. (arXiv:2106.03993v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1">Ekin Aky&#xfc;rek</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03993">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence-to-sequence transduction is the core problem in language processing
applications as diverse as semantic parsing, machine translation, and
instruction following. The neural network models that provide the dominant
solution to these problems are brittle, especially in low-resource settings:
they fail to generalize correctly or systematically from small datasets. Past
work has shown that many failures of systematic generalization arise from
neural models&#x27; inability to disentangle lexical phenomena from syntactic ones.
To address this, we augment neural decoders with a lexical translation
mechanism that generalizes existing copy mechanisms to incorporate learned,
decontextualized, token-level translation rules. We describe how to initialize
this mechanism using a variety of lexicon learning algorithms, and show that it
improves systematic generalization on a diverse set of sequence modeling tasks
drawn from cognitive science, formal semantics, and machine translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Falta de Pan, Buenas Son Tortas: The Efficacy of Predicted UPOS Tags for Low Resource UD Parsing. (arXiv:2106.04222v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1">Mark Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehouck_M/0/1/0/all/0/1">Mathieu Dehouck</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_C/0/1/0/all/0/1">Carlos G&#xf3;mez Rodr&#xed;guez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04222">
                                    <div class="article-summary-box-inner">
                                        <span>We evaluate the efficacy of predicted UPOS tags as input features for
dependency parsers in lower resource settings to evaluate how treebank size
affects the impact tagging accuracy has on parsing performance. We do this for
real low resource universal dependency treebanks, artificially low resource
data with varying treebank sizes, and for very small treebanks with varying
amounts of augmented data. We find that predicted UPOS tags are somewhat
helpful for low resource treebanks, especially when fewer fully-annotated trees
are available. We also find that this positive impact diminishes as the amount
of data increases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disfl-QA: A Benchmark Dataset for Understanding Disfluencies in Question Answering. (arXiv:2106.04016v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aditya Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiacheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Upadhyay_S/0/1/0/all/0/1">Shyam Upadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Diyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Faruqui_M/0/1/0/all/0/1">Manaal Faruqui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04016">
                                    <div class="article-summary-box-inner">
                                        <span>Disfluencies is an under-studied topic in NLP, even though it is ubiquitous
in human conversation. This is largely due to the lack of datasets containing
disfluencies. In this paper, we present a new challenge question answering
dataset, Disfl-QA, a derivative of SQuAD, where humans introduce contextual
disfluencies in previously fluent questions. Disfl-QA contains a variety of
challenging disfluencies that require a more comprehensive understanding of the
text than what was necessary in prior datasets. Experiments show that the
performance of existing state-of-the-art question answering models degrades
significantly when tested on Disfl-QA in a zero-shot setting.We show data
augmentation methods partially recover the loss in performance and also
demonstrate the efficacy of using gold data for fine-tuning. We argue that we
need large-scale disfluency datasets in order for NLP models to be robust to
them. The dataset is publicly available at:
https://github.com/google-research-datasets/disfl-qa.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable and Low-Resource Entity Matching via Decoupling Feature Learning from Decision Making. (arXiv:2106.04174v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zijun Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengjiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1">Tiansi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xin Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jifan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1">Lei Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juanzi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zelin Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04174">
                                    <div class="article-summary-box-inner">
                                        <span>Entity Matching (EM) aims at recognizing entity records that denote the same
real-world object. Neural EM models learn vector representation of entity
descriptions and match entities end-to-end. Though robust, these methods
require many resources for training, and lack of interpretability. In this
paper, we propose a novel EM framework that consists of Heterogeneous
Information Fusion (HIF) and Key Attribute Tree (KAT) Induction to decouple
feature representation from matching decision. Using self-supervised learning
and mask mechanism in pre-trained language modeling, HIF learns the embeddings
of noisy attribute values by inter-attribute attention with unlabeled data.
Using a set of comparison features and a limited amount of annotated data, KAT
Induction learns an efficient decision tree that can be interpreted by
generating entity matching rules whose structure is advocated by domain
experts. Experiments on 6 public datasets and 3 industrial datasets show that
our method is highly efficient and outperforms SOTA EM models in most cases.
Our codes and datasets can be obtained from https://github.com/THU-KEG/HIF-KAT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Modest Pareto Optimisation Analysis of Dependency Parsers in 2021. (arXiv:2106.04216v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1">Mar Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_C/0/1/0/all/0/1">Carlos G&#xf3;mez Rodr&#xed;guez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04216">
                                    <div class="article-summary-box-inner">
                                        <span>We evaluate three leading dependency parser systems from different paradigms
on a small yet diverse subset of languages in terms of their
accuracy-efficiency Pareto front. As we are interested in efficiency, we
evaluate core parsers without pretrained language models (as these are
typically huge networks and would constitute most of the compute time) or other
augmentations that can be transversally applied to any of them. Biaffine
parsing emerges as a well-balanced default choice, with sequence-labelling
parsing being preferable if inference speed (but not training energy cost) is
the priority.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Transfer Learning in Multilingual Pre-trained Language Models through Chinese Natural Language Inference. (arXiv:2106.03983v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hai Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">He Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1">Zuoyu Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yina Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanting Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Yixin Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Richardson_K/0/1/0/all/0/1">Kyle Richardson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03983">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual transformers (XLM, mT5) have been shown to have remarkable
transfer skills in zero-shot settings. Most transfer studies, however, rely on
automatically translated resources (XNLI, XQuAD), making it hard to discern the
particular linguistic knowledge that is being transferred, and the role of
expert annotated monolingual datasets when developing task-specific models. We
investigate the cross-lingual transfer abilities of XLM-R for Chinese and
English natural language inference (NLI), with a focus on the recent
large-scale Chinese dataset OCNLI. To better understand linguistic transfer, we
created 4 categories of challenge and adversarial tasks (totaling 17 new
datasets) for Chinese that build on several well-known resources for English
(e.g., HANS, NLI stress-tests). We find that cross-lingual models trained on
English NLI do transfer well across our Chinese tasks (e.g., in 3/4 of our
challenge categories, they perform as well/better than the best monolingual
models, even on 3/5 uniquely Chinese linguistic phenomena such as idioms, pro
drop). These results, however, come with important caveats: cross-lingual
models often perform best when trained on a mixture of English and high-quality
monolingual NLI data (OCNLI), and are often hindered by automatically
translated resources (XNLI-zh). For many phenomena, all models continue to
struggle, highlighting the need for our new diagnostics to help benchmark
Chinese and cross-lingual models. All new datasets/code are released at
https://github.com/huhailinguist/ChineseNLIProbing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised and Supervised Joint Training for Resource-rich Machine Translation. (arXiv:2106.04060v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Macherey_W/0/1/0/all/0/1">Wolfgang Macherey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04060">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised pre-training of text representations has been successfully
applied to low-resource Neural Machine Translation (NMT). However, it usually
fails to achieve notable gains on resource-rich NMT. In this paper, we propose
a joint training approach, $F_2$-XEnDec, to combine self-supervised and
supervised learning to optimize NMT models. To exploit complementary
self-supervised signals for supervised learning, NMT models are trained on
examples that are interbred from monolingual and parallel sentences through a
new process called crossover encoder-decoder. Experiments on two resource-rich
translation benchmarks, WMT&#x27;14 English-German and WMT&#x27;14 English-French,
demonstrate that our approach achieves substantial improvements over several
strong baseline methods and obtains a new state of the art of 46.19 BLEU on
English-French when incorporating back translation. Results also show that our
approach is capable of improving model robustness to input perturbations such
as code-switching noise which frequently appears on social media.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Insight from NLP Analysis: COVID-19 Vaccines Sentiments on Social Media. (arXiv:2106.04081v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Na_T/0/1/0/all/0/1">Tao Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wanyu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongjiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04081">
                                    <div class="article-summary-box-inner">
                                        <span>Social media is an appropriate source for analyzing public attitudes towards
the COVID-19 vaccine and various brands. Nevertheless, there are few relevant
studies. In the research, we collected tweet posts by the UK and US residents
from the Twitter API during the pandemic and designed experiments to answer
three main questions concerning vaccination. To get the dominant sentiment of
the civics, we performed sentiment analysis by VADER and proposed a new method
that can count the individual&#x27;s influence. This allows us to go a step further
in sentiment analysis and explain some of the fluctuations in the data
changing. The results indicated that celebrities could lead the opinion shift
on social media in vaccination progress. Moreover, at the peak, nearly 40\% of
the population in both countries have a negative attitude towards COVID-19
vaccines. Besides, we investigated how people&#x27;s opinions toward different
vaccine brands are. We found that the Pfizer vaccine enjoys the most popular
among people. By applying the sentiment analysis tool, we discovered most
people hold positive views toward the COVID-19 vaccine manufactured by most
brands. In the end, we carried out topic modelling by using the LDA model. We
found residents in the two countries are willing to share their views and
feelings concerning the vaccine. Several death cases have occurred after
vaccination. Due to these negative events, US residents are more worried about
the side effects and safety of the vaccine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning to Compositionally Generalize. (arXiv:2106.04252v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conklin_H/0/1/0/all/0/1">Henry Conklin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bailin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kenny Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1">Ivan Titov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04252">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language is compositional; the meaning of a sentence is a function of
the meaning of its parts. This property allows humans to create and interpret
novel sentences, generalizing robustly outside their prior experience. Neural
networks have been shown to struggle with this kind of generalization, in
particular performing poorly on tasks designed to assess compositional
generalization (i.e. where training and testing distributions differ in ways
that would be trivial for a compositional strategy to resolve). Their poor
performance on these tasks may in part be due to the nature of supervised
learning which assumes training and testing data to be drawn from the same
distribution. We implement a meta-learning augmented version of supervised
learning whose objective directly optimizes for out-of-distribution
generalization. We construct pairs of tasks for meta-learning by sub-sampling
existing training data. Each pair of tasks is constructed to contain relevant
examples, as determined by a similarity metric, in an effort to inhibit models
from memorizing their input. Experimental results on the COGS and SCAN datasets
show that our similarity-driven meta-learning can improve generalization
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring and Improving BERT&#x27;s Mathematical Abilities by Predicting the Order of Reasoning. (arXiv:2106.03921v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1">Piotr Pi&#x119;kos</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1">Henryk Michalewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1">Mateusz Malinowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03921">
                                    <div class="article-summary-box-inner">
                                        <span>Imagine you are in a supermarket. You have two bananas in your basket and
want to buy four apples. How many fruits do you have in total? This seemingly
straightforward question can be challenging for data-driven language models,
even if trained at scale. However, we would expect such generic language models
to possess some mathematical abilities in addition to typical linguistic
competence. Towards this goal, we investigate if a commonly used language
model, BERT, possesses such mathematical abilities and, if so, to what degree.
For that, we fine-tune BERT on a popular dataset for word math problems,
AQuA-RAT, and conduct several tests to understand learned representations
better. Since we teach models trained on natural language to do formal
mathematics, we hypothesize that such models would benefit from training on
semi-formal steps that explain how math results are derived. To better
accommodate such training, we also propose new pretext tasks for learning
mathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or
NROP). With this new model, we achieve significantly better outcomes than
data-driven baselines and even on-par with more tailored models. We also show
how to reduce positional bias in such models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study. (arXiv:2106.03958v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khemchandani_Y/0/1/0/all/0/1">Yash Khemchandani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehtani_S/0/1/0/all/0/1">Sarvesh Mehtani</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_V/0/1/0/all/0/1">Vaidehi Patil</a>, <a href="http://arxiv.org/find/cs/1/au:+Awasthi_A/0/1/0/all/0/1">Abhijeet Awasthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1">Partha Talukdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1">Sunita Sarawagi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03958">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research in multilingual language models (LM) has demonstrated their
ability to effectively handle multiple languages in a single model. This holds
promise for low web-resource languages (LRL) as multilingual models can enable
transfer of supervision from high resource languages to LRLs. However,
incorporating a new language in an LM still remains a challenge, particularly
for languages with limited corpora and in unseen scripts. In this paper we
argue that relatedness among languages in a language family may be exploited to
overcome some of the corpora limitations of LRLs, and propose RelateLM. We
focus on Indian languages, and exploit relatedness along two dimensions: (1)
script (since many Indic scripts originated from the Brahmic script), and (2)
sentence structure. RelateLM uses transliteration to convert the unseen script
of limited LRL text into the script of a Related Prominent Language (RPL)
(Hindi in our case). While exploiting similar sentence structures, RelateLM
utilizes readily available bilingual dictionaries to pseudo translate RPL text
into LRL corpora. Experiments on multiple real-world benchmark datasets provide
validation to our hypothesis that using a related language as pivot, along with
transliteration and pseudo translation based data augmentation, can be an
effective way to adapt LMs for LRLs, rather than direct training or pivoting
through English.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ultra-Fine Entity Typing with Weak Supervision from a Masked Language Model. (arXiv:2106.04098v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hongliang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haixun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04098">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there is an effort to extend fine-grained entity typing by using a
richer and ultra-fine set of types, and labeling noun phrases including
pronouns and nominal nouns instead of just named entity mentions. A key
challenge for this ultra-fine entity typing task is that human annotated data
are extremely scarce, and the annotation ability of existing distant or weak
supervision approaches is very limited. To remedy this problem, in this paper,
we propose to obtain training data for ultra-fine entity typing by using a BERT
Masked Language Model (MLM). Given a mention in a sentence, our approach
constructs an input for the BERT MLM so that it predicts context dependent
hypernyms of the mention, which can be used as type labels. Experimental
results demonstrate that, with the help of these automatically generated
labels, the performance of an ultra-fine entity typing model can be improved
substantially. We also show that our approach can be applied to improve
traditional fine-grained entity typing after performing simple type mapping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RewardsOfSum: Exploring Reinforcement Learning Rewards for Summarisation. (arXiv:2106.04080v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parnell_J/0/1/0/all/0/1">Jacob Parnell</a>, <a href="http://arxiv.org/find/cs/1/au:+Unanue_I/0/1/0/all/0/1">Inigo Jauregi Unanue</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccardi_M/0/1/0/all/0/1">Massimo Piccardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04080">
                                    <div class="article-summary-box-inner">
                                        <span>To date, most abstractive summarisation models have relied on variants of the
negative log-likelihood (NLL) as their training objective. In some cases,
reinforcement learning has been added to train the models with an objective
that is closer to their evaluation measures (e.g. ROUGE). However, the reward
function to be used within the reinforcement learning approach can play a key
role for performance and is still partially unexplored. For this reason, in
this paper, we propose two reward functions for the task of abstractive
summarisation: the first function, referred to as RwB-Hinge, dynamically
selects the samples for the gradient update. The second function, nicknamed
RISK, leverages a small pool of strong candidates to inform the reward. In the
experiments, we probe the proposed approach by fine-tuning an NLL pre trained
model over nine summarisation datasets of diverse size and nature. The
experimental results show a consistent improvement over the negative
log-likelihood baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIGTYP 2021 Shared Task: Robust Spoken Language Identification. (arXiv:2106.03895v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Salesky_E/0/1/0/all/0/1">Elizabeth Salesky</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdullah_B/0/1/0/all/0/1">Badr M. Abdullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mielke_S/0/1/0/all/0/1">Sabrina J. Mielke</a>, <a href="http://arxiv.org/find/cs/1/au:+Klyachko_E/0/1/0/all/0/1">Elena Klyachko</a>, <a href="http://arxiv.org/find/cs/1/au:+Serikov_O/0/1/0/all/0/1">Oleg Serikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1">Ritesh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>, <a href="http://arxiv.org/find/cs/1/au:+Vylomova_E/0/1/0/all/0/1">Ekaterina Vylomova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03895">
                                    <div class="article-summary-box-inner">
                                        <span>While language identification is a fundamental speech and language processing
task, for many languages and language families it remains a challenging task.
For many low-resource and endangered languages this is in part due to resource
availability: where larger datasets exist, they may be single-speaker or have
different domains than desired application scenarios, demanding a need for
domain and speaker-invariant language identification systems. This year&#x27;s
shared task on robust spoken language identification sought to investigate just
this scenario: systems were to be trained on largely single-speaker speech from
one domain, but evaluated on data in other domains recorded from speakers under
different recording circumstances, mimicking realistic low-resource scenarios.
We see that domain and speaker mismatch proves very challenging for current
methods which can perform above 95% accuracy in-domain, which domain adaptation
can address to some degree, but that these conditions merit further
investigation to make spoken language identification accessible in many
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Swords: A Benchmark for Lexical Substitution with Improved Data Coverage and Quality. (arXiv:2106.04102v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Mina Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1">Chris Donahue</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyabor_A/0/1/0/all/0/1">Alexander Iyabor</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1">Robin Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04102">
                                    <div class="article-summary-box-inner">
                                        <span>We release a new benchmark for lexical substitution, the task of finding
appropriate substitutes for a target word in a context. To assist humans with
writing, lexical substitution systems can suggest words that humans cannot
easily think of. However, existing benchmarks depend on human recall as the
only source of data, and therefore lack coverage of the substitutes that would
be most helpful to humans. Furthermore, annotators often provide substitutes of
low quality, which are not actually appropriate in the given context. We
collect higher-coverage and higher-quality data by framing lexical substitution
as a classification problem, guided by the intuition that it is easier for
humans to judge the appropriateness of candidate substitutes than conjure them
from memory. To this end, we use a context-free thesaurus to produce candidates
and rely on human judgement to determine contextual appropriateness. Compared
to the previous largest benchmark, our Swords benchmark has 4.1x more
substitutes per target word for the same level of quality, and its substitutes
are 1.5x more appropriate (based on human judgement) for the same number of
substitutes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cheap and Good? Simple and Effective Data Augmentation for Low Resource Machine Reading. (arXiv:2106.04134v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Van_H/0/1/0/all/0/1">Hoang Van</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1">Vikas Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1">Mihai Surdeanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04134">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a simple and effective strategy for data augmentation for
low-resource machine reading comprehension (MRC). Our approach first pretrains
the answer extraction components of a MRC system on the augmented data that
contains approximate context of the correct answers, before training it on the
exact answer spans. The approximate context helps the QA method components in
narrowing the location of the answers. We demonstrate that our simple strategy
substantially improves both document retrieval and answer extraction
performance by providing larger context of the answers and additional training
data. In particular, our method significantly improves the performance of BERT
based retriever (15.12\%), and answer extractor (4.33\% F1) on TechQA, a
complex, low-resource MRC task. Further, our data augmentation strategy yields
significant improvements of up to 3.9\% exact match (EM) and 2.7\% F1 for
answer extraction on PolicyQA, another practical but moderate sized QA dataset
that also contains long answer spans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring Conversational Uptake: A Case Study on Student-Teacher Interactions. (arXiv:2106.03873v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Demszky_D/0/1/0/all/0/1">Dorottya Demszky</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mancenido_Z/0/1/0/all/0/1">Zid Mancenido</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1">Julie Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_H/0/1/0/all/0/1">Heather Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1">Dan Jurafsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1">Tatsunori Hashimoto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03873">
                                    <div class="article-summary-box-inner">
                                        <span>In conversation, uptake happens when a speaker builds on the contribution of
their interlocutor by, for example, acknowledging, repeating or reformulating
what they have said. In education, teachers&#x27; uptake of student contributions
has been linked to higher student achievement. Yet measuring and improving
teachers&#x27; uptake at scale is challenging, as existing methods require expensive
annotation by experts. We propose a framework for computationally measuring
uptake, by (1) releasing a dataset of student-teacher exchanges extracted from
US math classroom transcripts annotated for uptake by experts; (2) formalizing
uptake as pointwise Jensen-Shannon Divergence (pJSD), estimated via next
utterance classification; (3) conducting a linguistically-motivated comparison
of different unsupervised measures and (4) correlating these measures with
educational outcomes. We find that although repetition captures a significant
part of uptake, pJSD outperforms repetition-based baselines, as it is capable
of identifying a wider range of uptake phenomena like question answering and
reformulation. We apply our uptake measure to three different educational
datasets with outcome indicators. Unlike baseline measures, pJSD correlates
significantly with instruction quality in all three, providing evidence for its
generalizability and for its potential to serve as an automated professional
development tool for teachers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expressivity of Emergent Language is a Trade-off between Contextual Complexity and Unpredictability. (arXiv:2106.03982v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shangmin Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathewson_K/0/1/0/all/0/1">Kory Mathewson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirby_S/0/1/0/all/0/1">Simon Kirby</a>, <a href="http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1">Stefano V. Albrecht</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kenny Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03982">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers are now using deep learning models to explore the emergence of
language in various language games, where simulated agents interact and develop
an emergent language to solve a task. Although it is quite intuitive that
different types of language games posing different communicative challenges
might require emergent languages which encode different levels of information,
there is no existing work exploring the expressivity of the emergent languages.
In this work, we propose a definition of partial order between expressivity
based on the generalisation performance across different language games. We
also validate the hypothesis that expressivity of emergent languages is a
trade-off between the complexity and unpredictability of the context those
languages are used in. Our second novel contribution is introducing contrastive
loss into the implementation of referential games. We show that using our
contrastive loss alleviates the collapse of message types seen using standard
referential loss functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Abstractive Unsupervised Summarization of Online News Discussions. (arXiv:2106.03953v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palma_I/0/1/0/all/0/1">Ignacio Tampe Palma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendoza_M/0/1/0/all/0/1">Marcelo Mendoza</a>, <a href="http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1">Evangelos Milios</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03953">
                                    <div class="article-summary-box-inner">
                                        <span>Summarization has usually relied on gold standard summaries to train
extractive or abstractive models. Social media brings a hurdle to summarization
techniques since it requires addressing a multi-document multi-author approach.
We address this challenging task by introducing a novel method that generates
abstractive summaries of online news discussions. Our method extends a
BERT-based architecture, including an attention encoding that fed comments&#x27;
likes during the training stage. To train our model, we define a task which
consists of reconstructing high impact comments based on popularity (likes).
Accordingly, our model learns to summarize online discussions based on their
most relevant comments. Our novel approach provides a summary that represents
the most relevant aspects of a news item that users comment on, incorporating
the social context as a source of information to summarize texts in online
social networks. Our model is evaluated using ROUGE scores between the
generated summary and each comment on the thread. Our model, including the
social attention encoding, significantly outperforms both extractive and
abstractive summarization methods based on such evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Different Types of Subtle Toxicity in Unhealthy Online Conversations. (arXiv:2106.03952v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gilda_S/0/1/0/all/0/1">Shlok Gilda</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_M/0/1/0/all/0/1">Mirela Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Giovanini_L/0/1/0/all/0/1">Luiz Giovanini</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1">Daniela Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03952">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the use of machine learning models for the
classification of unhealthy online conversations containing one or more forms
of subtler abuse, such as hostility, sarcasm, and generalization. We leveraged
a public dataset of 44K online comments containing healthy and unhealthy
comments labeled with seven forms of subtle toxicity. We were able to
distinguish between these comments with a top micro F1-score, macro F1-score,
and ROC-AUC of 88.76%, 67.98%, and 0.71, respectively. Hostile comments were
easier to detect than other types of unhealthy comments. We also conducted a
sentiment analysis which revealed that most types of unhealthy comments were
associated with a slight negative sentiment, with hostile comments being the
most negative ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Hypothetical Events for Abductive Inference. (arXiv:2106.03973v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1">Debjit Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03973">
                                    <div class="article-summary-box-inner">
                                        <span>Abductive reasoning starts from some observations and aims at finding the
most plausible explanation for these observations. To perform abduction, humans
often make use of temporal and causal inferences, and knowledge about how some
hypothetical situation can result in different outcomes. This work offers the
first study of how such knowledge impacts the Abductive NLI task -- which
consists in choosing the more likely explanation for given observations. We
train a specialized language model LMI that is tasked to generate what could
happen next from a hypothetical scenario that evolves from a given event. We
then propose a multi-task model MTL to solve the Abductive NLI task, which
predicts a plausible explanation by a) considering different possible events
emerging from candidate hypotheses -- events generated by LMI -- and b)
selecting the one that is most similar to the observed outcome. We show that
our MTL model improves over prior vanilla pre-trained LMs fine-tuned on
Abductive NLI. Our manual evaluation and analysis suggest that learning about
possible next events from different hypothetical scenarios supports abductive
inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11601">
                                    <div class="article-summary-box-inner">
                                        <span>Personalization of natural language generation plays a vital role in a large
spectrum of tasks, such as explainable recommendation, review summarization and
dialog systems. In these tasks, user and item IDs are important identifiers for
personalization. Transformer, which is demonstrated with strong language
modeling capability, however, is not personalized and fails to make use of the
user and item IDs since the ID tokens are not even in the same semantic space
as the words. To address this problem, we present a PErsonalized Transformer
for Explainable Recommendation (PETER), on which we design a simple and
effective learning objective that utilizes the IDs to predict the words in the
target explanation, so as to endow the IDs with linguistic meanings and to
achieve personalized Transformer. Besides generating explanations, PETER can
also make recommendations, which makes it a unified model for the whole
recommendation-explanation pipeline. Extensive experiments show that our small
unpretrained model outperforms fine-tuned BERT on the generation task, in terms
of both effectiveness and efficiency, which highlights the importance and the
nice utility of our design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Active Surface Models. (arXiv:2011.08826v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1">Udaranga Wickramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1">Graham Knott</a>, <a href="http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1">Pascal Fua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08826">
                                    <div class="article-summary-box-inner">
                                        <span>Active Surface Models have a long history of being useful to model complex 3D
surfaces but only Active Contours have been used in conjunction with deep
networks, and then only to produce the data term as well as meta-parameter maps
controlling them. In this paper, we advocate a much tighter integration. We
introduce layers that implement them that can be integrated seamlessly into
Graph Convolutional Networks to enforce sophisticated smoothness priors at an
acceptable computational cost. We will show that the resulting Deep Active
Surface Models outperform equivalent architectures that use traditional
regularization loss terms to impose smoothness priors for 3D surface
reconstruction from 2D images and for 3D volume segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GasHis-Transformer: A Multi-scale Visual Transformer Approach for Gastric Histopathology Image Classification. (arXiv:2104.14528v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changhao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yudong Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1">Yueyang Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1">Marcin Grzegorzek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14528">
                                    <div class="article-summary-box-inner">
                                        <span>Existing deep learning methods for diagnosis of gastric cancer commonly use
convolutional neural network. Recently, the Visual Transformer has attracted
great attention because of its performance and efficiency, but its applications
are mostly in the field of computer vision. In this paper, a multi-scale visual
transformer model, referred to as GasHis-Transformer, is proposed for Gastric
Histopathological Image Classification (GHIC), which enables the automatic
classification of microscopic gastric images into abnormal and normal cases.
The GasHis-Transformer model consists of two key modules: A global information
module and a local information module to extract histopathological features
effectively. In our experiments, a public hematoxylin and eosin (H&amp;E) stained
gastric histopathological dataset with 280 abnormal and normal images are
divided into training, validation and test sets by a ratio of 1 : 1 : 2. The
GasHis-Transformer model is applied to estimate precision, recall, F1-score and
accuracy on the test set of gastric histopathological dataset as 98.0%, 100.0%,
96.0% and 98.0%, respectively. Furthermore, a critical study is conducted to
evaluate the robustness of GasHis-Transformer, where ten different noises
including four adversarial attack and six conventional image noises are added.
In addition, a clinically meaningful study is executed to test the
gastrointestinal cancer identification performance of GasHis-Transformer with
620 abnormal images and achieves 96.8% accuracy. Finally, a comparative study
is performed to test the generalizability with both H&amp;E and immunohistochemical
stained images on a lymphoma image dataset and a breast cancer dataset,
producing comparable F1-scores (85.6% and 82.8%) and accuracies (83.9% and
89.4%), respectively. In conclusion, GasHisTransformer demonstrates high
classification performance and shows its significant potential in the GHIC
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing All From a Few: Nodes Selection Using Graph Pooling for Graph Clustering. (arXiv:2105.05320v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Dongxia Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhiqian Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05320">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been considerable research interest in graph clustering
aimed at data partition using the graph information. However, one limitation of
the most of graph-based methods is that they assume the graph structure to
operate is fixed and reliable. And there are inevitably some edges in the graph
that are not conducive to graph clustering, which we call spurious edges. This
paper is the first attempt to employ graph pooling technique for node
clustering and we propose a novel dual graph embedding network (DGEN), which is
designed as a two-step graph encoder connected by a graph pooling layer to
learn the graph embedding. In our model, it is assumed that if a node and its
nearest neighboring node are close to the same clustering center, this node is
an informative node and this edge can be considered as a cluster-friendly edge.
Based on this assumption, the neighbor cluster pooling (NCPool) is devised to
select the most informative subset of nodes and the corresponding edges based
on the distance of nodes and their nearest neighbors to the cluster centers.
This can effectively alleviate the impact of the spurious edges on the
clustering. Finally, to obtain the clustering assignment of all nodes, a
classifier is trained using the clustering results of the selected nodes.
Experiments on five benchmark graph datasets demonstrate the superiority of the
proposed method over state-of-the-art algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StyTr^2: Unbiased Image Style Transfer with Transformers. (arXiv:2105.14576v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yingying Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1">Fan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xingjia Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Weiming Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chongyang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Changsheng Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14576">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of image style transfer is to render an image with artistic features
guided by a style reference while maintaining the original content. Due to the
locality and spatial invariance in CNNs, it is difficult to extract and
maintain the global information of input images. Therefore, traditional neural
style transfer methods are usually biased and content leak can be observed by
running several times of the style transfer process with the same reference
style image. To address this critical issue, we take long-range dependencies of
input images into account for unbiased style transfer by proposing a
transformer-based approach, namely StyTr^2. In contrast with visual
transformers for other vision tasks, our StyTr^2 contains two different
transformer encoders to generate domain-specific sequences for content and
style, respectively. Following the encoders, a multi-layer transformer decoder
is adopted to stylize the content sequence according to the style sequence. In
addition, we analyze the deficiency of existing positional encoding methods and
propose the content-aware positional encoding (CAPE) which is scale-invariant
and more suitable for image style transfer task. Qualitative and quantitative
experiments demonstrate the effectiveness of the proposed StyTr^2 compared to
state-of-the-art CNN-based and flow-based approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SWAD: Domain Generalization by Seeking Flat Minima. (arXiv:2102.08604v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cha_J/0/1/0/all/0/1">Junbum Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Sanghyuk Chun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyungjae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Han-Cheol Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yunsung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sungrae Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08604">
                                    <div class="article-summary-box-inner">
                                        <span>Domain generalization (DG) methods aim to achieve generalizability to an
unseen target domain by using only training data from the source domains.
Although a variety of DG methods have been proposed, a recent study shows that
under a fair evaluation protocol, called DomainBed, the simple empirical risk
minimization (ERM) approach works comparable to or even outperforms previous
methods. Unfortunately, simply solving ERM on a complex, non-convex loss
function can easily lead to sub-optimal generalizability by seeking sharp
minima. In this paper, we theoretically show that finding flat minima results
in a smaller domain generalization gap. We also propose a simple yet effective
method, named Stochastic Weight Averaging Densely (SWAD), to find flat minima.
SWAD finds flatter minima and suffers less from overfitting than does the
vanilla SWA by a dense and overfit-aware stochastic weight sampling strategy.
SWAD shows state-of-the-art performances on five DG benchmarks, namely PACS,
VLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large
margins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with
conventional generalization methods, such as data augmentation and consistency
regularization methods, to verify that the remarkable performance improvements
are originated from by seeking flat minima, not from better in-domain
generalizability. Last but not least, SWAD is readily adaptable to existing DG
methods without modification; the combination of SWAD and an existing DG method
further improves DG performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Synchronized Reprojection-based Model for 3D Human Pose Estimation. (arXiv:2106.04274v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yicheng Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Cheng Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yongqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiahui Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04274">
                                    <div class="article-summary-box-inner">
                                        <span>3D human pose estimation is still a challenging problem despite the large
amount of work that has been done in this field. Generally, most methods
directly use neural networks and ignore certain constraints (e.g., reprojection
constraints and joint angle and bone length constraints). This paper proposes a
weakly supervised GAN-based model for 3D human pose estimation that considers
3D information along with 2D information simultaneously, in which a
reprojection network is employed to learn the mapping of the distribution from
3D poses to 2D poses. In particular, we train the reprojection network and the
generative adversarial network synchronously. Furthermore, inspired by the
typical kinematic chain space (KCS) matrix, we propose a weighted KCS matrix,
which is added into the discriminator&#x27;s input to impose joint angle and bone
length constraints. The experimental results on Human3.6M show that our method
outperforms state-of-the-art methods by approximately 5.1\%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interaction-GCN: A Graph Convolutional Network based framework for social interaction recognition in egocentric videos. (arXiv:2104.14007v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Felicioni_S/0/1/0/all/0/1">Simone Felicioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimiccoli_M/0/1/0/all/0/1">Mariella Dimiccoli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14007">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we propose a new framework to categorize social interactions in
egocentric videos, we named InteractionGCN. Our method extracts patterns of
relational and non-relational cues at the frame level and uses them to build a
relational graph from which the interactional context at the frame level is
estimated via a Graph Convolutional Network based approach. Then it propagates
this context over time, together with first-person motion information, through
a Gated Recurrent Unit architecture. Ablation studies and experimental
evaluation on two publicly available datasets validate the proposed approach
and establish state of the art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mean-Shifted Contrastive Loss for Anomaly Detection. (arXiv:2106.03844v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1">Tal Reiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Deep anomaly detection methods learn representations that separate between
normal and anomalous samples. Very effective representations are obtained when
powerful externally trained feature extractors (e.g. ResNets pre-trained on
ImageNet) are fine-tuned on the training data which consists of normal samples
and no anomalies. However, this is a difficult task that can suffer from
catastrophic collapse, i.e. it is prone to learning trivial and non-specific
features. In this paper, we propose a new loss function which can overcome
failure modes of both center-loss and contrastive-loss methods. Furthermore, we
combine it with a confidence-invariant angular center loss, which replaces the
Euclidean distance used in previous work, that was sensitive to prediction
confidence. Our improvements yield a new anomaly detection approach, based on
$\textit{Mean-Shifted Contrastive Loss}$, which is both more accurate and less
sensitive to catastrophic collapse than previous methods. Our method achieves
state-of-the-art anomaly detection performance on multiple benchmarks including
$97.5\%$ ROC-AUC on the CIFAR-10 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DoubleField: Bridging the Neural Surface and Radiance Fields for High-fidelity Human Rendering. (arXiv:2106.03798v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1">Ruizhi Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">He Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yanpei Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yebin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03798">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce DoubleField, a novel representation combining the merits of both
surface field and radiance field for high-fidelity human rendering. Within
DoubleField, the surface field and radiance field are associated together by a
shared feature embedding and a surface-guided sampling strategy. In this way,
DoubleField has a continuous but disentangled learning space for geometry and
appearance modeling, which supports fast training, inference, and finetuning.
To achieve high-fidelity free-viewpoint rendering, DoubleField is further
augmented to leverage ultra-high-resolution inputs, where a view-to-view
transformer and a transfer learning scheme are introduced for more efficient
learning and finetuning from sparse-view inputs at original resolutions. The
efficacy of DoubleField is validated by the quantitative evaluations on several
datasets and the qualitative results in a real-world sparse multi-view system,
showing its superior capability for photo-realistic free-viewpoint human
rendering. For code and demo video, please refer to our project page:
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SeasonDepth: Cross-Season Monocular Depth Prediction Dataset and Benchmark under Multiple Environments. (arXiv:2011.04408v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hanjiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Baoquan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1">Zhijian Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hesheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04408">
                                    <div class="article-summary-box-inner">
                                        <span>Changing environments poses a great challenge on the outdoor visual
perception and scene understanding for robust long-term autonomous driving and
mobile robots, where depth-auxiliary geometric information plays an essential
role to the robustness under challenging scenes. Although monocular depth
prediction has been well studied recently, there are few work focusing on the
depth prediction across multiple environmental conditions, e.g. changing
illumination and seasons, owing to the lack of such a real-world dataset and
benchmark. In this work, a new cross-season monocular depth prediction dataset
SeasonDepth (available on https://seasondepth.github.io) is derived from CMU
Visual Localization dataset through structure from motion. To benchmark the
depth estimation performance under different environments, we investigate
representative and recent state-of-the-art open-source supervised,
self-supervised and domain adaptation depth prediction methods from KITTI
benchmark using several newly-formulated metrics. Through extensive
experimental evaluation on the proposed dataset without fine-tuning, the
influence of multiple environments on performance and robustness is analyzed
both qualitatively and quantitatively, showing that the long-term monocular
depth prediction is far from solved. We further give promising solutions
especially with stereo geometry and multi-task sequential self-supervised
training to enhance the robustness to changing environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Channel Dimensions for Efficient Model Design. (arXiv:2007.00992v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dongyoon Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Sangdoo Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Heo_B/0/1/0/all/0/1">Byeongho Heo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1">YoungJoon Yoo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00992">
                                    <div class="article-summary-box-inner">
                                        <span>Designing an efficient model within the limited computational cost is
challenging. We argue the accuracy of a lightweight model has been further
limited by the design convention: a stage-wise configuration of the channel
dimensions, which looks like a piecewise linear function of the network stage.
In this paper, we study an effective channel dimension configuration towards
better performance than the convention. To this end, we empirically study how
to design a single layer properly by analyzing the rank of the output feature.
We then investigate the channel configuration of a model by searching network
architectures concerning the channel configuration under the computational cost
restriction. Based on the investigation, we propose a simple yet effective
channel configuration that can be parameterized by the layer index. As a
result, our proposed model following the channel parameterization achieves
remarkable performance on ImageNet classification and transfer learning tasks
including COCO object detection, COCO instance segmentation, and fine-grained
classifications. Code and ImageNet pretrained models are available at
https://github.com/clovaai/rexnet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intriguing Properties of Vision Transformers. (arXiv:2105.10497v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1">Muzammal Naseer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1">Kanchana Ranasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1">Munawar Hayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Fahad Shahbaz Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10497">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformers (ViT) have demonstrated impressive performance across
various machine vision problems. These models are based on multi-head
self-attention mechanisms that can flexibly attend to a sequence of image
patches to encode contextual cues. An important question is how such
flexibility in attending image-wide context conditioned on a given patch can
facilitate handling nuisances in natural images e.g., severe occlusions, domain
shifts, spatial permutations, adversarial and natural perturbations. We
systematically study this question via an extensive set of experiments
encompassing three ViT families and comparisons with a high-performing
convolutional neural network (CNN). We show and analyze the following
intriguing properties of ViT: (a) Transformers are highly robust to severe
occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1
accuracy on ImageNet even after randomly occluding 80% of the image content.
(b) The robust performance to occlusions is not due to a bias towards local
textures, and ViTs are significantly less biased towards textures compared to
CNNs. When properly trained to encode shape-based features, ViTs demonstrate
shape recognition capability comparable to that of human visual system,
previously unmatched in the literature. (c) Using ViTs to encode shape
representation leads to an interesting consequence of accurate semantic
segmentation without pixel-level supervision. (d) Off-the-shelf features from a
single ViT model can be combined to create a feature ensemble, leading to high
accuracy rates across a range of classification datasets in both traditional
and few-shot learning paradigms. We show effective features of ViTs are due to
flexible and dynamic receptive fields possible via the self-attention
mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patch-wise++ Perturbation for Adversarial Targeted Attacks. (arXiv:2012.15503v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Lianli Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qilong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jingkuan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1">Heng Tao Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15503">
                                    <div class="article-summary-box-inner">
                                        <span>Although great progress has been made on adversarial attacks for deep neural
networks (DNNs), their transferability is still unsatisfactory, especially for
targeted attacks. There are two problems behind that have been long overlooked:
1) the conventional setting of $T$ iterations with the step size of
$\epsilon/T$ to comply with the $\epsilon$-constraint. In this case, most of
the pixels are allowed to add very small noise, much less than $\epsilon$; and
2) usually manipulating pixel-wise noise. However, features of a pixel
extracted by DNNs are influenced by its surrounding regions, and different DNNs
generally focus on different discriminative regions in recognition. To tackle
these issues, our previous work proposes a patch-wise iterative method (PIM)
aimed at crafting adversarial examples with high transferability. Specifically,
we introduce an amplification factor to the step size in each iteration, and
one pixel&#x27;s overall gradient overflowing the $\epsilon$-constraint is properly
assigned to its surrounding regions by a project kernel. But targeted attacks
aim to push the adversarial examples into the territory of a specific class,
and the amplification factor may lead to underfitting. Thus, we introduce the
temperature and propose a patch-wise++ iterative method (PIM++) to further
improve transferability without significantly sacrificing the performance of
the white-box attack. Our method can be generally integrated to any
gradient-based attack methods. Compared with the current state-of-the-art
attack methods, we significantly improve the success rate by 33.1\% for defense
models and 31.4\% for normally trained models on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GSVNet: Guided Spatially-Varying Convolution for Fast Semantic Segmentation on Video. (arXiv:2103.08834v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Shih-Po Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Si-Cun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wen-Hsiao Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08834">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses fast semantic segmentation on video.Video segmentation
often calls for real-time, or even fasterthan real-time, processing. One common
recipe for conserving computation arising from feature extraction is to
propagate features of few selected keyframes. However, recent advances in fast
image segmentation make these solutions less attractive. To leverage fast image
segmentation for furthering video segmentation, we propose a simple yet
efficient propagation framework. Specifically, we perform lightweight flow
estimation in 1/8-downscaled image space for temporal warping in segmentation
outpace space. Moreover, we introduce a guided spatially-varying convolution
for fusing segmentations derived from the previous and current frames, to
mitigate propagation error and enable lightweight feature extraction on
non-keyframes. Experimental results on Cityscapes and CamVid show that our
scheme achieves the state-of-the-art accuracy-throughput trade-off on video
segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Whitening Batch Normalization. (arXiv:2106.04413v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nezhadarya_E/0/1/0/all/0/1">Ehsan Nezhadarya</a>, <a href="http://arxiv.org/find/cs/1/au:+Fashandi_H/0/1/0/all/0/1">Homa Fashandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiayi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_D/0/1/0/all/0/1">Darin Graham</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mohak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04413">
                                    <div class="article-summary-box-inner">
                                        <span>Batch Normalization (BN) is a popular technique for training Deep Neural
Networks (DNNs). BN uses scaling and shifting to normalize activations of
mini-batches to accelerate convergence and improve generalization. The recently
proposed Iterative Normalization (IterNorm) method improves these properties by
whitening the activations iteratively using Newton&#x27;s method. However, since
Newton&#x27;s method initializes the whitening matrix independently at each training
step, no information is shared between consecutive steps. In this work, instead
of exact computation of whitening matrix at each time step, we estimate it
gradually during training in an online fashion, using our proposed Stochastic
Whitening Batch Normalization (SWBN) algorithm. We show that while SWBN
improves the convergence rate and generalization of DNNs, its computational
overhead is less than that of IterNorm. Due to the high efficiency of the
proposed method, it can be easily employed in most DNN architectures with a
large number of layers. We provide comprehensive experiments and comparisons
between BN, IterNorm, and SWBN layers to demonstrate the effectiveness of the
proposed technique in conventional (many-shot) image classification and
few-shot classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Elastic Lottery Ticket Hypothesis. (arXiv:2103.16547v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuohang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16547">
                                    <div class="article-summary-box-inner">
                                        <span>Lottery Ticket Hypothesis (LTH) raises keen attention to identifying sparse
trainable subnetworks, or winning tickets, of training, which can be trained in
isolation to achieve similar or even better performance compared to the full
models. Despite many efforts being made, the most effective method to identify
such winning tickets is still Iterative Magnitude-based Pruning (IMP), which is
computationally expensive and has to be run thoroughly for every different
network. A natural question that comes in is: can we &quot;transform&quot; the winning
ticket found in one network to another with a different architecture, yielding
a winning ticket for the latter at the beginning, without re-doing the
expensive IMP? Answering this question is not only practically relevant for
efficient &quot;once-for-all&quot; winning ticket finding, but also theoretically
appealing for uncovering inherently scalable sparse patterns in networks. We
conduct extensive experiments on CIFAR-10 and ImageNet, and propose a variety
of strategies to tweak the winning tickets found from different networks of the
same model family (e.g., ResNets). Based on these results, we articulate the
Elastic Lottery Ticket Hypothesis (E-LTH): by mindfully replicating (or
dropping) and re-ordering layers for one network, its corresponding winning
ticket could be stretched (or squeezed) into a subnetwork for another deeper
(or shallower) network from the same family, whose performance is nearly the
same competitive as the latter&#x27;s winning ticket directly found by IMP. We have
also thoroughly compared E-LTH with pruning-at-initialization and dynamic
sparse training methods, and discuss the generalizability of E-LTH to different
model families, layer types, or across datasets. Code is available at
https://github.com/VITA-Group/ElasticLTH.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NWT: Towards natural audio-to-video generation with representation learning. (arXiv:2106.04283v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mama_R/0/1/0/all/0/1">Rayhane Mama</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyndel_M/0/1/0/all/0/1">Marc S. Tyndel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadhim_H/0/1/0/all/0/1">Hashiam Kadhim</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifford_C/0/1/0/all/0/1">Cole Clifford</a>, <a href="http://arxiv.org/find/cs/1/au:+Thurairatnam_R/0/1/0/all/0/1">Ragavan Thurairatnam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04283">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we introduce NWT, an expressive speech-to-video model. Unlike
approaches that use domain-specific intermediate representations such as pose
keypoints, NWT learns its own latent representations, with minimal assumptions
about the audio and video content. To this end, we propose a novel discrete
variational autoencoder with adversarial loss, dVAE-Adv, which learns a new
discrete latent representation we call Memcodes. Memcodes are straightforward
to implement, require no additional loss terms, are stable to train compared
with other approaches, and show evidence of interpretability. To predict on the
Memcode space, we use an autoregressive encoder-decoder model conditioned on
audio. Additionally, our model can control latent attributes in the generated
video that are not annotated in the data. We train NWT on clips from HBO&#x27;s Last
Week Tonight with John Oliver. NWT consistently scores above other approaches
in Mean Opinion Score (MOS) on tests of overall video naturalness, facial
naturalness and expressiveness, and lipsync quality. This work sets a strong
baseline for generalized audio-to-video synthesis. Samples are available at
https://next-week-tonight.github.io/NWT/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Medical Image Alignment with Curriculum Learning. (arXiv:2102.10438v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burduja_M/0/1/0/all/0/1">Mihail Burduja</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10438">
                                    <div class="article-summary-box-inner">
                                        <span>We explore different curriculum learning methods for training convolutional
neural networks on the task of deformable pairwise 3D medical image
registration. To the best of our knowledge, we are the first to attempt to
improve performance by training medical image registration models using
curriculum learning, starting from an easy training setup in the first training
stages, and gradually increasing the complexity of the setup. On the one hand,
we consider two existing curriculum learning approaches, namely curriculum
dropout and curriculum by smoothing. On the other hand, we propose a novel and
simple strategy to achieve curriculum, namely to use purposely blurred images
at the beginning, then gradually transit to sharper images in the later
training stages. Our experiments with an underlying state-of-the-art deep
learning model show that curriculum learning can lead to superior results
compared to conventional training. Additionally, we show that curriculum by
input blur has the best accuracy versus speed trade-off among the compared
curriculum learning approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Too-Good-to-be-True Prior to Reduce Shortcut Reliance. (arXiv:2102.06406v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dagaev_N/0/1/0/all/0/1">Nikolay Dagaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Roads_B/0/1/0/all/0/1">Brett D. Roads</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiaoliang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Barry_D/0/1/0/all/0/1">Daniel N. Barry</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_K/0/1/0/all/0/1">Kaustubh R. Patil</a>, <a href="http://arxiv.org/find/cs/1/au:+Love_B/0/1/0/all/0/1">Bradley C. Love</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06406">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their impressive performance in object recognition and other tasks
under standard testing conditions, deep networks often fail to generalize to
out-of-distribution (o.o.d.) samples. One cause for this shortcoming is that
modern architectures tend to rely on &quot;shortcuts&quot; - superficial features that
correlate with categories without capturing deeper invariants that hold across
contexts. Real-world concepts often possess a complex structure that can vary
superficially across contexts, which can make the most intuitive and promising
solutions in one context not generalize to others. One potential way to improve
o.o.d. generalization is to assume simple solutions are unlikely to be valid
across contexts and avoid them, which we refer to as the too-good-to-be-true
prior. A low-capacity network (LCN) with a shallow architecture should only be
able to learn surface relationships, including shortcuts. We find that LCNs can
serve as shortcut detectors. Furthermore, an LCN&#x27;s predictions can be used in a
two-stage approach to encourage a high-capacity network (HCN) to rely on deeper
invariant features that should generalize broadly. In particular, items that
the LCN can master are downweighted when training the HCN. Using a modified
version of the CIFAR-10 dataset in which we introduced shortcuts, we found that
the two-stage LCN-HCN approach reduced reliance on shortcuts and facilitated
o.o.d. generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Feature Distillation for Visual Recognition. (arXiv:2106.04411v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Sangwon Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Donggyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1">Taeeon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Moon_T/0/1/0/all/0/1">Taesup Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04411">
                                    <div class="article-summary-box-inner">
                                        <span>Fairness is becoming an increasingly crucial issue for computer vision,
especially in the human-related decision systems. However, achieving
algorithmic fairness, which makes a model produce indiscriminative outcomes
against protected groups, is still an unresolved problem. In this paper, we
devise a systematic approach which reduces algorithmic biases via feature
distillation for visual recognition tasks, dubbed as MMD-based Fair
Distillation (MFD). While the distillation technique has been widely used in
general to improve the prediction accuracy, to the best of our knowledge, there
has been no explicit work that also tries to improve fairness via distillation.
Furthermore, We give a theoretical justification of our MFD on the effect of
knowledge distillation and fairness. Throughout the extensive experiments, we
show our MFD significantly mitigates the bias against specific minorities
without any loss of the accuracy on both synthetic and real-world face
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust R-Peak Detection in Low-Quality Holter ECGs using 1D Convolutional Neural Network. (arXiv:2101.01666v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zahid_M/0/1/0/all/0/1">Muhammad Uzair Zahid</a>, <a href="http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1">Serkan Kiranyaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Ince_T/0/1/0/all/0/1">Turker Ince</a>, <a href="http://arxiv.org/find/eess/1/au:+Devecioglu_O/0/1/0/all/0/1">Ozer Can Devecioglu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chowdhury_M/0/1/0/all/0/1">Muhammad E. H. Chowdhury</a>, <a href="http://arxiv.org/find/eess/1/au:+Khandakar_A/0/1/0/all/0/1">Amith Khandakar</a>, <a href="http://arxiv.org/find/eess/1/au:+Tahir_A/0/1/0/all/0/1">Anas Tahir</a>, <a href="http://arxiv.org/find/eess/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01666">
                                    <div class="article-summary-box-inner">
                                        <span>Noise and low quality of ECG signals acquired from Holter or wearable devices
deteriorate the accuracy and robustness of R-peak detection algorithms. This
paper presents a generic and robust system for R-peak detection in Holter ECG
signals. While many proposed algorithms have successfully addressed the problem
of ECG R-peak detection, there is still a notable gap in the performance of
these detectors on such low-quality ECG records. Therefore, in this study, a
novel implementation of the 1D Convolutional Neural Network (CNN) is used
integrated with a verification model to reduce the number of false alarms. This
CNN architecture consists of an encoder block and a corresponding decoder block
followed by a sample-wise classification layer to construct the 1D segmentation
map of R- peaks from the input ECG signal. Once the proposed model has been
trained, it can solely be used to detect R-peaks possibly in a single channel
ECG data stream quickly and accurately, or alternatively, such a solution can
be conveniently employed for real-time monitoring on a lightweight portable
device. The model is tested on two open-access ECG databases: The China
Physiological Signal Challenge (2020) database (CPSC-DB) with more than one
million beats, and the commonly used MIT-BIH Arrhythmia Database (MIT-DB).
Experimental results demonstrate that the proposed systematic approach achieves
99.30% F1-score, 99.69% recall, and 98.91% precision in CPSC-DB, which is the
best R-peak detection performance ever achieved. Compared to all competing
methods, the proposed approach can reduce the false-positives and
false-negatives in Holter ECG signals by more than 54% and 82%, respectively.
Results also demonstrate similar or better performance than most competing
algorithms on MIT-DB with 99.83% F1-score, 99.85% recall, and 99.82% precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RobustNav: Towards Benchmarking Robustness in Embodied Navigation. (arXiv:2106.04531v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chattopadhyay_P/0/1/0/all/0/1">Prithvijit Chattopadhyay</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1">Judy Hoffman</a>, <a href="http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1">Roozbeh Mottaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1">Aniruddha Kembhavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04531">
                                    <div class="article-summary-box-inner">
                                        <span>As an attempt towards assessing the robustness of embodied navigation agents,
we propose RobustNav, a framework to quantify the performance of embodied
navigation agents when exposed to a wide variety of visual - affecting RGB
inputs - and dynamics - affecting transition dynamics - corruptions. Most
recent efforts in visual navigation have typically focused on generalizing to
novel target environments with similar appearance and dynamics characteristics.
With RobustNav, we find that some standard embodied navigation agents
significantly underperform (or fail) in the presence of visual or dynamics
corruptions. We systematically analyze the kind of idiosyncrasies that emerge
in the behavior of such agents when operating under corruptions. Finally, for
visual corruptions in RobustNav, we show that while standard techniques to
improve robustness such as data-augmentation and self-supervised adaptation
offer some zero-shot resistance and improvements in navigation performance,
there is still a long way to go in terms of recovering lost performance
relative to clean &quot;non-corrupt&quot; settings, warranting more research in this
direction. Our code is available at https://github.com/allenai/robustnav</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation. (arXiv:2009.07526v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1">Yuan Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yujing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yue Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07526">
                                    <div class="article-summary-box-inner">
                                        <span>Scene graphs are semantic abstraction of images that encourage visual
understanding and reasoning. However, the performance of Scene Graph Generation
(SGG) is unsatisfactory when faced with biased data in real-world scenarios.
Conventional debiasing research mainly studies from the view of balancing data
distribution or learning unbiased models and representations, ignoring the
correlations among the biased classes. In this work, we analyze this problem
from a novel cognition perspective: automatically building a hierarchical
cognitive structure from the biased predictions and navigating that hierarchy
to locate the relationships, making the tail relationships receive more
attention in a coarse-to-fine mode. To this end, we propose a novel debiasing
Cognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive
structure CogTree to organize the relationships based on the prediction of a
biased SGG model. The CogTree distinguishes remarkably different relationships
at first and then focuses on a small portion of easily confused ones. Then, we
propose a debiasing loss specially for this cognitive structure, which supports
coarse-to-fine distinction for the correct relationships. The loss is
model-agnostic and consistently boosting the performance of several
state-of-the-art models. The code is available at:
https://github.com/CYVincent/Scene-Graph-Transformer-CogTree.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Representation Learning for Efficient Medical Image Analysis. (arXiv:2006.11223v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1">Ghada Zamzmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaraman_S/0/1/0/all/0/1">Sivaramakrishnan Rajaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Antani_S/0/1/0/all/0/1">Sameer Antani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11223">
                                    <div class="article-summary-box-inner">
                                        <span>Medical image analysis typically includes several tasks such as enhancement,
segmentation, and classification. Traditionally, these tasks are implemented
using separate deep learning models for separate tasks, which is not efficient
because it involves unnecessary training repetitions, demands greater
computational resources, and requires a relatively large amount of labeled
data. In this paper, we propose a multi-task training approach for medical
image analysis, where individual tasks are fine-tuned simultaneously through
relevant knowledge transfer using a unified modality-specific feature
representation (UMS-Rep). We explore different fine-tuning strategies to
demonstrate the impact of the strategy on the performance of target medical
image tasks. We experiment with different visual tasks (e.g., image denoising,
segmentation, and classification) to highlight the advantages offered with our
approach for two imaging modalities, chest X-ray and Doppler echocardiography.
Our results demonstrate that the proposed approach reduces the overall demand
for computational resources and improves target task generalization and
performance. Further, our results prove that the performance of target tasks in
medical images is highly influenced by the utilized fine-tuning strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViTA: Visual-Linguistic Translation by Aligning Object Tags. (arXiv:2106.00250v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1">Kshitij Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Gautam_D/0/1/0/all/0/1">Devansh Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1">Radhika Mamidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00250">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal Machine Translation (MMT) enriches the source text with visual
information for translation. It has gained popularity in recent years, and
several pipelines have been proposed in the same direction. Yet, the task lacks
quality datasets to illustrate the contribution of visual modality in the
translation systems. In this paper, we propose our system under the team name
Volta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We
also participate in the textual-only subtask of the same language pair for
which we use mBART, a pretrained multilingual sequence-to-sequence model. For
multimodal translation, we propose to enhance the textual input by bringing the
visual information to a textual domain by extracting object tags from the
image. We also explore the robustness of our system by systematically degrading
the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test
set and challenge set of the multimodal task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation. (arXiv:2106.04151v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zhekai Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hongzu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Ke Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04151">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned
from a well-labeled source domain to an unlabeled target domain. Recently,
adversarial domain adaptation with two distinct classifiers (bi-classifier) has
been introduced into UDA which is effective to align distributions between
different domains. Previous bi-classifier adversarial learning methods only
focus on the similarity between the outputs of two distinct classifiers.
However, the similarity of the outputs cannot guarantee the accuracy of target
samples, i.e., target samples may match to wrong categories even if the
discrepancy between two classifiers is small. To challenge this issue, in this
paper, we propose a cross-domain gradient discrepancy minimization (CGDM)
method which explicitly minimizes the discrepancy of gradients generated by
source samples and target samples. Specifically, the gradient gives a cue for
the semantic information of target samples so it can be used as a good
supervision to improve the accuracy of target samples. In order to compute the
gradient signal of target samples, we further obtain target pseudo labels
through a clustering-based self-supervised learning. Extensive experiments on
three widely used UDA datasets show that our method surpasses many previous
state-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-dataset Pretraining: A Unified Model for Semantic Segmentation. (arXiv:2106.04121v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Bowen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaopeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haohang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wenrui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Junni Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hongkai Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04121">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting annotated data for semantic segmentation is time-consuming and
hard to scale up. In this paper, we for the first time propose a unified
framework, termed as Multi-Dataset Pretraining, to take full advantage of the
fragmented annotations of different datasets. The highlight is that the
annotations from different domains can be efficiently reused and consistently
boost performance for each specific domain. This is achieved by first
pretraining the network via the proposed pixel-to-prototype contrastive loss
over multiple datasets regardless of their taxonomy labels, and followed by
fine-tuning the pretrained model over specific dataset as usual. In order to
better model the relationship among images and classes from different datasets,
we extend the pixel level embeddings via cross dataset mixing and propose a
pixel-to-class sparse coding strategy that explicitly models the pixel-class
similarity over the manifold embedding space. In this way, we are able to
increase intra-class compactness and inter-class separability, as well as
considering inter-class similarity across different datasets for better
transferability. Experiments conducted on several benchmarks demonstrate its
superior performance. Notably, MDP consistently outperforms the pretrained
models over ImageNet by a considerable margin, while only using less than 10%
samples for pretraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demystifying Local Vision Transformer: Sparse Connectivity, Weight Sharing, and Dynamic Weight. (arXiv:2106.04263v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_Q/0/1/0/all/0/1">Qi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zejia Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1">Qi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04263">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformer (ViT) attains state-of-the-art performance in visual
recognition, and the variant, Local Vision Transformer, makes further
improvements. The major component in Local Vision Transformer, local attention,
performs the attention separately over small local windows. We rephrase local
attention as a channel-wise locally-connected layer and analyze it from two
network regularization manners, sparse connectivity and weight sharing, as well
as weight computation. Sparse connectivity: there is no connection across
channels, and each position is connected to the positions within a small local
window. Weight sharing: the connection weights for one position are shared
across channels or within each group of channels. Dynamic weight: the
connection weights are dynamically predicted according to each image instance.
We point out that local attention resembles depth-wise convolution and its
dynamic version in sparse connectivity. The main difference lies in weight
sharing - depth-wise convolution shares connection weights (kernel weights)
across spatial positions. We empirically observe that the models based on
depth-wise convolution and the dynamic variant with lower computation
complexity perform on-par with or sometimes slightly better than Swin
Transformer, an instance of Local Vision Transformer, for ImageNet
classification, COCO object detection and ADE semantic segmentation. These
observations suggest that Local Vision Transformer takes advantage of two
regularization forms and dynamic weight to increase the network capacity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super-Human Performance in Online Low-latency Recognition of Conversational Speech. (arXiv:2010.03449v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thai-Son Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stueker_S/0/1/0/all/0/1">Sebastian Stueker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alex Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03449">
                                    <div class="article-summary-box-inner">
                                        <span>Achieving super-human performance in recognizing human speech has been a goal
for several decades, as researchers have worked on increasingly challenging
tasks. In the 1990&#x27;s it was discovered, that conversational speech between two
humans turns out to be considerably more difficult than read speech as
hesitations, disfluencies, false starts and sloppy articulation complicate
acoustic processing and require robust handling of acoustic, lexical and
language context, jointly. Early attempts with statistical models could only
reach error rates over 50% and far from human performance (WER of around 5.5%).
Neural hybrid models and recent attention-based encoder-decoder models have
considerably improved performance as such contexts can now be learned in an
integral fashion. However, processing such contexts requires an entire
utterance presentation and thus introduces unwanted delays before a recognition
result can be output. In this paper, we address performance as well as latency.
We present results for a system that can achieve super-human performance (at a
WER of 5.0%, over the Switchboard conversational benchmark) at a word based
latency of only 1 second behind a speaker&#x27;s speech. The system uses multiple
attention-based encoder-decoder networks integrated within a novel low latency
incremental inference approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the use of automatically generated synthetic image datasets for benchmarking face recognition. (arXiv:2106.04215v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colbois_L/0/1/0/all/0/1">Laurent Colbois</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_T/0/1/0/all/0/1">Tiago de Freitas Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcel_S/0/1/0/all/0/1">S&#xe9;bastien Marcel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04215">
                                    <div class="article-summary-box-inner">
                                        <span>The availability of large-scale face datasets has been key in the progress of
face recognition. However, due to licensing issues or copyright infringement,
some datasets are not available anymore (e.g. MS-Celeb-1M). Recent advances in
Generative Adversarial Networks (GANs), to synthesize realistic face images,
provide a pathway to replace real datasets by synthetic datasets, both to train
and benchmark face recognition (FR) systems. The work presented in this paper
provides a study on benchmarking FR systems using a synthetic dataset. First,
we introduce the proposed methodology to generate a synthetic dataset, without
the need for human intervention, by exploiting the latent structure of a
StyleGAN2 model with multiple controlled factors of variation. Then, we confirm
that (i) the generated synthetic identities are not data subjects from the
GAN&#x27;s training dataset, which is verified on a synthetic dataset with 10K+
identities; (ii) benchmarking results on the synthetic dataset are a good
substitution, often providing error rates and system ranking similar to the
benchmarking on the real dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HPRNet: Hierarchical Point Regression for Whole-Body Human Pose Estimation. (arXiv:2106.04269v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samet_N/0/1/0/all/0/1">Nermin Samet</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbas_E/0/1/0/all/0/1">Emre Akbas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04269">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a new bottom-up one-stage method for whole-body
pose estimation, which we name &quot;hierarchical point regression,&quot; or HPRNet for
short, referring to the network that implements this method. To handle the
scale variance among different body parts, we build a hierarchical point
representation of body parts and jointly regress them. Unlike the existing
two-stage methods, our method predicts whole-body pose in a constant time
independent of the number of people in an image. On the COCO WholeBody dataset,
HPRNet significantly outperforms all previous bottom-up methods on the keypoint
detection of all whole-body parts (i.e. body, foot, face and hand); it also
achieves state-of-the-art results in the face (75.4 AP) and hand (50.4 AP)
keypoint detection. Code and models are available at
https://github.com/nerminsamet/HPRNet.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SynthRef: Generation of Synthetic Referring Expressions for Object Segmentation. (arXiv:2106.04403v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazakos_I/0/1/0/all/0/1">Ioannis Kazakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventura_C/0/1/0/all/0/1">Carles Ventura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellver_M/0/1/0/all/0/1">Miriam Bellver</a>, <a href="http://arxiv.org/find/cs/1/au:+Silberer_C/0/1/0/all/0/1">Carina Silberer</a>, <a href="http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1">Xavier Giro-i-Nieto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04403">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep learning have brought significant progress in visual
grounding tasks such as language-guided video object segmentation. However,
collecting large datasets for these tasks is expensive in terms of annotation
time, which represents a bottleneck. To this end, we propose a novel method,
namely SynthRef, for generating synthetic referring expressions for target
objects in an image (or video frame), and we also present and disseminate the
first large-scale dataset with synthetic referring expressions for video object
segmentation. Our experiments demonstrate that by training with our synthetic
referring expressions one can improve the ability of a model to generalize
across different datasets, without any additional annotation cost. Moreover,
our formulation allows its application to any object detection or segmentation
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Vehicles Trajectories in Urban Scenarios with Transformer Networks and Augmented Information. (arXiv:2106.00559v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Quintanar_A/0/1/0/all/0/1">A. Quintanar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Llorca_D/0/1/0/all/0/1">D. Fern&#xe1;ndez-Llorca</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_I/0/1/0/all/0/1">I. Parra</a>, <a href="http://arxiv.org/find/cs/1/au:+Izquierdo_R/0/1/0/all/0/1">R. Izquierdo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotelo_M/0/1/0/all/0/1">M. A. Sotelo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00559">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the behavior of road users is of vital importance for the
development of trajectory prediction systems. In this context, the latest
advances have focused on recurrent structures, establishing the social
interaction between the agents involved in the scene. More recently, simpler
structures have also been introduced for predicting pedestrian trajectories,
based on Transformer Networks, and using positional information. They allow the
individual modelling of each agent&#x27;s trajectory separately without any complex
interaction terms. Our model exploits these simple structures by adding
augmented data (position and heading), and adapting their use to the problem of
vehicle trajectory prediction in urban scenarios in prediction horizons up to 5
seconds. In addition, a cross-performance analysis is performed between
different types of scenarios, including highways, intersections and
roundabouts, using recent datasets (inD, rounD, highD and INTERACTION). Our
model achieves state-of-the-art results and proves to be flexible and adaptable
to different types of urban contexts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Spatio-Temporal Bilinear Network with Monte Carlo Dropout for Landmark-based Facial Expression Recognition with Uncertainty Estimation. (arXiv:2106.04332v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heidari_N/0/1/0/all/0/1">Negar Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1">Alexandros Iosifidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04332">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have been widely used for feature learning in facial
expression recognition systems. However, small datasets and large intra-class
variability can lead to overfitting. In this paper, we propose a method which
learns an optimized compact network topology for real-time facial expression
recognition utilizing localized facial landmark features. Our method employs a
spatio-temporal bilinear layer as backbone to capture the motion of facial
landmarks during the execution of a facial expression effectively. Besides, it
takes advantage of Monte Carlo Dropout to capture the model&#x27;s uncertainty which
is of great importance to analyze and treat uncertain cases. The performance of
our method is evaluated on three widely used datasets and it is comparable to
that of video-based state-of-the-art methods while it has much less complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Representation Learning for Hand Shape Estimation. (arXiv:2106.04324v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmermann_C/0/1/0/all/0/1">Christian Zimmermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Argus_M/0/1/0/all/0/1">Max Argus</a>, <a href="http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04324">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents improvements in monocular hand shape estimation by
building on top of recent advances in unsupervised learning. We extend momentum
contrastive learning and contribute a structured collection of hand images,
well suited for visual representation learning, which we call HanCo. We find
that the representation learned by established contrastive learning methods can
be improved significantly by exploiting advanced background removal techniques
and multi-view information. These allow us to generate more diverse instance
pairs than those obtained by augmentations commonly used in exemplar based
approaches. Our method leads to a more suitable representation for the hand
shape estimation task and shows a 4.7% reduction in mesh error and a 3.6%
improvement in F-score compared to an ImageNet pretrained baseline. We make our
benchmark dataset publicly available, to encourage further research into this
direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting Deep Learning based Cerebral Palsy Prediction with Channel Attention. (arXiv:2106.04471v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Manli Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_Q/0/1/0/all/0/1">Qianhui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1">Edmond S. L. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_H/0/1/0/all/0/1">Howard Leung</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1">Hubert P. H. Shum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04471">
                                    <div class="article-summary-box-inner">
                                        <span>Early prediction of cerebral palsy is essential as it leads to early
treatment and monitoring. Deep learning has shown promising results in
biomedical engineering thanks to its capacity of modelling complicated data
with its non-linear architecture. However, due to their complex structure, deep
learning models are generally not interpretable by humans, making it difficult
for clinicians to rely on the findings. In this paper, we propose a channel
attention module for deep learning models to predict cerebral palsy from
infants&#x27; body movements, which highlights the key features (i.e. body joints)
the model identifies as important, thereby indicating why certain diagnostic
results are found. To highlight the capacity of the deep network in modelling
input features, we utilize raw joint positions instead of hand-crafted
features. We validate our system with a real-world infant movement dataset. Our
proposed channel attention module enables the visualization of the vital joints
to this disease that the network considers. Our system achieves 91.67%
accuracy, suppressing other state-of-the-art deep learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">White Paper Assistance: A Step Forward Beyond the Shortcut Learning. (arXiv:2106.04178v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tianshu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaomin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiali Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minghui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04178">
                                    <div class="article-summary-box-inner">
                                        <span>The promising performances of CNNs often overshadow the need to examine
whether they are doing in the way we are actually interested. We show through
experiments that even over-parameterized models would still solve a dataset by
recklessly leveraging spurious correlations, or so-called &#x27;shortcuts&#x27;. To
combat with this unintended propensity, we borrow the idea of printer test page
and propose a novel approach called White Paper Assistance. Our proposed method
involves the white paper to detect the extent to which the model has preference
for certain characterized patterns and alleviates it by forcing the model to
make a random guess on the white paper. We show the consistent accuracy
improvements that are manifest in various architectures, datasets and
combinations with other techniques. Experiments have also demonstrated the
versatility of our approach on fine-grained recognition, imbalanced
classification and robustness to corruptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary Monocular Cameras. (arXiv:2106.04477v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuelin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weiyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1">Niloy J. Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Baoquan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04477">
                                    <div class="article-summary-box-inner">
                                        <span>Synthesizing novel views of dynamic humans from stationary monocular cameras
is a popular scenario. This is particularly attractive as it does not require
static scenes, controlled environments, or specialized hardware. In contrast to
techniques that exploit multi-view observations to constrain the modeling,
given a single fixed viewpoint only, the problem of modeling the dynamic scene
is significantly more under-constrained and ill-posed. In this paper, we
introduce Neural Motion Consensus Flow (MoCo-Flow), a representation that
models the dynamic scene using a 4D continuous time-variant function. The
proposed representation is learned by an optimization which models a dynamic
scene that minimizes the error of rendering all observation images. At the
heart of our work lies a novel optimization formulation, which is constrained
by a motion consensus regularization on the motion flow. We extensively
evaluate MoCo-Flow on several datasets that contain human motions of varying
complexity, and compare, both qualitatively and quantitatively, to several
baseline methods and variants of our methods. Pretrained model, code, and data
will be released for research purposes upon paper acceptance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical VAEs Know What They Don&#x27;t Know. (arXiv:2102.08248v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Havtorn_J/0/1/0/all/0/1">Jakob D. Havtorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1">Jes Frellsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Maaloe_L/0/1/0/all/0/1">Lars Maal&#xf8;e</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08248">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models have been demonstrated as state-of-the-art density
estimators. Yet, recent work has found that they often assign a higher
likelihood to data from outside the training distribution. This seemingly
paradoxical behavior has caused concerns over the quality of the attained
density estimates. In the context of hierarchical variational autoencoders, we
provide evidence to explain this behavior by out-of-distribution data having
in-distribution low-level features. We argue that this is both expected and
desirable behavior. With this insight in hand, we develop a fast, scalable and
fully unsupervised likelihood-ratio score for OOD detection that requires data
to be in-distribution across all feature-levels. We benchmark the method on a
vast set of data and model combinations and achieve state-of-the-art results on
out-of-distribution detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Easy-GT: Open-Source Software to Facilitate Making the Ground Truth for White Blood Cells Nucleus. (arXiv:2101.11654v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kouzehkanan_Z/0/1/0/all/0/1">Zahra Mousavi Kouzehkanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Tavakoli_S/0/1/0/all/0/1">Sajad Tavakoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Alipanah_A/0/1/0/all/0/1">Arezoo Alipanah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11654">
                                    <div class="article-summary-box-inner">
                                        <span>The nucleus of white blood cells (WBCs) plays a significant role in their
detection and classification. Appropriate feature extraction of the nucleus is
necessary to fit a suitable artificial intelligence model to classify WBCs.
Therefore, designing a method is needed to segment the nucleus accurately.
There should be a comparison between the ground truths distinguished by a
hematologist and the detected nuclei to evaluate the performance of the nucleus
segmentation method accurately. It is a time-consuming and tedious task for
experts to establish the ground truth manually. This paper presents an
intelligent open-source software called Easy-GT to create the ground truth of
WBCs&#x27; nucleus faster and easier. This software first detects the nucleus by
employing a new Otsu&#x27;s thresholding-based method with a dice similarity
coefficient (DSC) of 95.42 %; the hematologist can then create a more accurate
ground truth, using the designed buttons to modify the threshold value. This
software can speed up ground truth&#x27;s forming process more than six times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Rank Subspaces in GANs. (arXiv:2106.04488v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jiapeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_R/0/1/0/all/0/1">Ruili Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yujun Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Deli Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zhengjun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04488">
                                    <div class="article-summary-box-inner">
                                        <span>The latent space of a Generative Adversarial Network (GAN) has been shown to
encode rich semantics within some subspaces. To identify these subspaces,
researchers typically analyze the statistical information from a collection of
synthesized data, and the identified subspaces tend to control image attributes
globally (i.e., manipulating an attribute causes the change of an entire
image). By contrast, this work introduces low-rank subspaces that enable more
precise control of GAN generation. Concretely, given an arbitrary image and a
region of interest (e.g., eyes of face images), we manage to relate the latent
space to the image region with the Jacobian matrix and then use low-rank
factorization to discover steerable latent subspaces. There are three
distinguishable strengths of our approach that can be aptly called LowRankGAN.
First, compared to analytic algorithms in prior work, our low-rank
factorization of Jacobians is able to find the low-dimensional representation
of attribute manifold, making image editing more precise and controllable.
Second, low-rank factorization naturally yields a null space of attributes such
that moving the latent code within it only affects the outer region of
interest. Therefore, local image editing can be simply achieved by projecting
an attribute vector into the null space without relying on a spatial mask as
existing methods do. Third, our method can robustly work with a local region
from one image for analysis yet well generalize to other images, making it much
easy to use in practice. Extensive experiments on state-of-the-art GAN models
(including StyleGAN2 and BigGAN) trained on various datasets demonstrate the
effectiveness of our LowRankGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Robust Detection of Out-of-distribution Data (almost) for free. (arXiv:2106.04260v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meinke_A/0/1/0/all/0/1">Alexander Meinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Bitterwolf_J/0/1/0/all/0/1">Julian Bitterwolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1">Matthias Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04260">
                                    <div class="article-summary-box-inner">
                                        <span>When applying machine learning in safety-critical systems, a reliable
assessment of the uncertainy of a classifier is required. However, deep neural
networks are known to produce highly overconfident predictions on
out-of-distribution (OOD) data and even if trained to be non-confident on OOD
data one can still adversarially manipulate OOD data so that the classifer
again assigns high confidence to the manipulated samples. In this paper we
propose a novel method where from first principles we combine a certifiable OOD
detector with a standard classifier into an OOD aware classifier. In this way
we achieve the best of two worlds: certifiably adversarially robust OOD
detection, even for OOD samples close to the in-distribution, without loss in
prediction accuracy and close to state-of-the-art OOD detection performance for
non-manipulated OOD data. Moreover, due to the particular construction our
classifier provably avoids the asymptotic overconfidence problem of standard
neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Lov\&#x27;asz Embeddings for Proposal-free Panoptic Segmentation. (arXiv:2106.04555v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kerola_T/0/1/0/all/0/1">Tommi Kerola</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanehira_A/0/1/0/all/0/1">Atsushi Kanehira</a>, <a href="http://arxiv.org/find/cs/1/au:+Kudo_Y/0/1/0/all/0/1">Yasunori Kudo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallet_A/0/1/0/all/0/1">Alexis Vallet</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04555">
                                    <div class="article-summary-box-inner">
                                        <span>Panoptic segmentation brings together two separate tasks: instance and
semantic segmentation. Although they are related, unifying them faces an
apparent paradox: how to learn simultaneously instance-specific and
category-specific (i.e. instance-agnostic) representations jointly. Hence,
state-of-the-art panoptic segmentation methods use complex models with a
distinct stream for each task. In contrast, we propose Hierarchical Lov\&#x27;asz
Embeddings, per pixel feature vectors that simultaneously encode instance- and
category-level discriminative information. We use a hierarchical Lov\&#x27;asz hinge
loss to learn a low-dimensional embedding space structured into a unified
semantic and instance hierarchy without requiring separate network branches or
object proposals. Besides modeling instances precisely in a proposal-free
manner, our Hierarchical Lov\&#x27;asz Embeddings generalize to categories by using
a simple Nearest-Class-Mean classifier, including for non-instance &quot;stuff&quot;
classes where instance segmentation methods are not applicable. Our simple
model achieves state-of-the-art results compared to existing proposal-free
panoptic segmentation methods on Cityscapes, COCO, and Mapillary Vistas.
Furthermore, our model demonstrates temporal stability between video frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Image Reconstruction using Deep Generative Models. (arXiv:2012.04567v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marinescu_R/0/1/0/all/0/1">Razvan V Marinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1">Daniel Moyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Golland_P/0/1/0/all/0/1">Polina Golland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04567">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models are commonly trained end-to-end and in a supervised
setting, using paired (input, output) data. Examples include recent
super-resolution methods that train on pairs of (low-resolution,
high-resolution) images. However, these end-to-end approaches require
re-training every time there is a distribution shift in the inputs (e.g., night
images vs daylight) or relevant latent variables (e.g., camera blur or hand
motion). In this work, we leverage state-of-the-art (SOTA) generative models
(here StyleGAN2) for building powerful image priors, which enable application
of Bayes&#x27; theorem for many downstream reconstruction tasks. Our method,
Bayesian Reconstruction through Generative Models (BRGM), uses a single
pre-trained generator model to solve different image restoration tasks, i.e.,
super-resolution and in-painting, by combining it with different forward
corruption models. We keep the weights of the generator model fixed, and
reconstruct the image by estimating the Bayesian maximum a-posteriori (MAP)
estimate over the input latent vector that generated the reconstructed image.
We further use variational inference to approximate the posterior distribution
over the latent vectors, from which we sample multiple solutions. We
demonstrate BRGM on three large and diverse datasets: (i) 60,000 images from
the Flick Faces High Quality dataset (ii) 240,000 chest X-rays from MIMIC III
and (iii) a combined collection of 5 brain MRI datasets with 7,329 scans.
Across all three datasets and without any dataset-specific hyperparameter
tuning, our simple approach yields performance competitive with current
task-specific state-of-the-art methods on super-resolution and in-painting,
while being more generalisable and without requiring any training. Our source
code and pre-trained models are available online:
https://razvanmarinescu.github.io/brgm/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Hybrid Model for Identity Document Classification. (arXiv:2106.04345v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khandan_N/0/1/0/all/0/1">Nouna Khandan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04345">
                                    <div class="article-summary-box-inner">
                                        <span>Digitization, i.e., the process of converting information into a digital
format, may provide various opportunities (e.g., increase in productivity,
disaster recovery, and environmentally friendly solutions) and challenges for
businesses. In this context, one of the main challenges would be to accurately
classify numerous scanned documents uploaded every day by customers as usual
business processes. For example, processes in banking (e.g., applying for
loans) or the Government Registry of BDM (Births, Deaths, and Marriages)
applications may involve uploading several documents such as a driver&#x27;s license
and passport. There are not many studies available to address the challenge as
an application of image classification. Although some studies are available
which used various methods, a more accurate model is still required. The
current study has proposed a robust fusion model to define the type of identity
documents accurately. The proposed approach is based on two different methods
in which images are classified based on their visual features and text
features. A novel model based on statistics and regression has been proposed to
calculate the confidence level for the feature-based classifier. A fuzzy-mean
fusion model has been proposed to combine the classifier results based on their
confidence score. The proposed approach has been implemented using Python and
experimentally validated on synthetic and real-world datasets. The performance
of the proposed model is evaluated using the Receiver Operating Characteristic
(ROC) curve analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection of marine floating plastic using Sentinel-2 imagery and machine learning models. (arXiv:2106.03694v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sannigrahi_S/0/1/0/all/0/1">Srikanta Sannigrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_B/0/1/0/all/0/1">Bidroha Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1">Arunima Sarkar Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilla_F/0/1/0/all/0/1">Francesco Pilla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03694">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing level of marine plastic pollution poses severe threats to the
marine ecosystem and biodiversity. The present study attempted to explore the
full functionality of open Sentinel satellite data and ML models for detecting
and classifying floating plastic debris in Mytilene (Greece), Limassol
(Cyprus), Calabria (Italy), and Beirut (Lebanon). Two ML models, i.e. Support
Vector Machine (SVM) and Random Forest (RF) were utilized to carry out the
classification analysis. In-situ plastic location data was collected from the
control experiment conducted in Mytilene, Greece and Limassol, Cyprus, and the
same was considered for training the models. Both remote sensing bands and
spectral indices were used for developing the ML models. A spectral signature
profile for plastic was created for discriminating the floating plastic from
other marine debris. A newly developed index, kernel Normalized Difference
Vegetation Index (kNDVI), was incorporated into the modelling to examine its
contribution to model performances. Both SVM and RF were performed well in five
models and test case combinations. Among the two ML models, the highest
performance was measured for the RF. The inclusion of kNDVI was found effective
and increased the model performances, reflected by high balanced accuracy
measured for model 2 (~80% to ~98 % for SVM and ~87% to ~97 % for RF). Using
the best-performed model, an automated floating plastic detection system was
developed and tested in Calabria and Beirut. For both sites, the trained model
had detected the floating plastic with ~99% accuracy. Among the six predictors,
the FDI was found the most important variable for detecting marine floating
plastic. These findings collectively suggest that high-resolution remote
sensing imagery and the automated ML models can be an effective alternative for
the cost-effective detection of marine floating plastic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Chasing Sparsity in Vision Transformers:An End-to-End Exploration. (arXiv:2106.04533v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Lu Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04533">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformers (ViTs) have recently received explosive popularity, but
their enormous model sizes and training costs remain daunting. Conventional
post-training pruning often incurs higher training budgets. In contrast, this
paper aims to trim down both the training memory overhead and the inference
complexity, without scarifying the achievable accuracy. We launch and report
the first-of-its-kind comprehensive exploration, on taking a unified approach
of integrating sparsity in ViTs &quot;from end to end&quot;. Specifically, instead of
training full ViTs, we dynamically extract and train sparse subnetworks, while
sticking to a fixed small parameter budget. Our approach jointly optimizes
model parameters and explores connectivity throughout training, ending up with
one sparse network as the final output. The approach is seamlessly extended
from unstructured to structured sparsity, the latter by considering to guide
the prune-and-grow of self-attention heads inside ViTs. For additional
efficiency gains, we further co-explore data and architecture sparsity, by
plugging in a novel learnable token selector to adaptively determine the
currently most vital patches. Extensive results validate the effectiveness of
our proposals on ImageNet with diverse ViT backbones. For instance, at 40%
structured sparsity, our sparsified DeiT-Base can achieve 0.42% accuracy gain,
at 33.13% and 24.70% running time} savings, compared to its dense counterpart.
Perhaps most surprisingly, we find that the proposed sparse (co-)training can
even improve the ViT accuracy rather than compromising it, making sparsity a
tantalizing &quot;free lunch&quot;. For example, our sparsified DeiT-Small at 5%, 50%
sparsity for (data, architecture), improves 0.28% top-1 accuracy and meanwhile
enjoys 49.32% FLOPs and 4.40% running time savings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computer-Assisted Analysis of Biomedical Images. (arXiv:2106.04381v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rundo_L/0/1/0/all/0/1">Leonardo Rundo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04381">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, the amount of heterogeneous biomedical data is increasing more and
more thanks to novel sensing techniques and high-throughput technologies. In
reference to biomedical image analysis, the advances in image acquisition
modalities and high-throughput imaging experiments are creating new challenges.
This huge information ensemble could overwhelm the analytic capabilities needed
by physicians in their daily decision-making tasks as well as by biologists
investigating complex biochemical systems. In particular, quantitative imaging
methods convey scientifically and clinically relevant information in
prediction, prognosis or treatment response assessment, by also considering
radiomics approaches. Therefore, the computational analysis of medical and
biological images plays a key role in radiology and laboratory applications. In
this regard, frameworks based on advanced Machine Learning and Computational
Intelligence can significantly improve traditional Image Processing and Pattern
Recognition approaches. However, conventional Artificial Intelligence
techniques must be tailored to address the unique challenges concerning
biomedical imaging data. This thesis aims at proposing novel and advanced
computer-assisted methods for biomedical image analysis, also as an instrument
in the development of Clinical Decision Support Systems, by always keeping in
mind the clinical feasibility of the developed solutions. In conclusion, the
ultimate goal of these research studies is to gain clinically and biologically
useful insights that can guide differential diagnosis and therapies, leading
towards biomedical data integration for personalized medicine. As a matter of
fact, the proposed computer-assisted bioimage analysis methods can be
beneficial for the definition of imaging biomarkers, as well as for
quantitative medicine and biology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient training for future video generation based on hierarchical disentangled representation of latent variables. (arXiv:2106.03502v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fushishita_N/0/1/0/all/0/1">Naoya Fushishita</a>, <a href="http://arxiv.org/find/cs/1/au:+Tejero_de_Pablos_A/0/1/0/all/0/1">Antonio Tejero-de-Pablos</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukuta_Y/0/1/0/all/0/1">Yusuke Mukuta</a>, <a href="http://arxiv.org/find/cs/1/au:+Harada_T/0/1/0/all/0/1">Tatsuya Harada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03502">
                                    <div class="article-summary-box-inner">
                                        <span>Generating videos predicting the future of a given sequence has been an area
of active research in recent years. However, an essential problem remains
unsolved: most of the methods require large computational cost and memory usage
for training. In this paper, we propose a novel method for generating future
prediction videos with less memory usage than the conventional methods. This is
a critical stepping stone in the path towards generating videos with high image
quality, similar to that of generated images in the latest works in the field
of image generation. We achieve high-efficiency by training our method in two
stages: (1) image reconstruction to encode video frames into latent variables,
and (2) latent variable prediction to generate the future sequence. Our method
achieves an efficient compression of video into low-dimensional latent
variables by decomposing each frame according to its hierarchical structure.
That is, we consider that video can be separated into background and foreground
objects, and that each object holds time-varying and time-independent
information independently. Our experiments show that the proposed method can
efficiently generate future prediction videos, even for complex datasets that
cannot be handled by previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymmetrical Bi-RNN for pedestrian trajectory encoding. (arXiv:2106.04419v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rozenberg_R/0/1/0/all/0/1">Rapha&#xeb;l Rozenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gesnouin_J/0/1/0/all/0/1">Joseph Gesnouin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moutarde_F/0/1/0/all/0/1">Fabien Moutarde</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04419">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian motion behavior involves a combination of individual goals and
social interactions with other agents. In this article, we present a
non-symmetrical bidirectional recurrent neural network architecture called
U-RNN as a sequence encoder and evaluate its relevance to replace LSTMs for
various forecasting models. Experimental results on the Trajnet++ benchmark
show that the U-LSTM variant can yield better results regarding every available
metric (ADE, FDE, Collision rate) than common LSTMs sequence encoders for a
variety of approaches and interaction modules.

Our implementation of the asymmetrical Bi-RNNs for the Trajnet++ benchmark is
available at:
github.com/JosephGesnouin/Asymmetrical-Bi-RNNs-to-encode-pedestrian-trajectories</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Harnessing Unrecognizable Faces for Face Recognition. (arXiv:2106.04112v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Siqi Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04112">
                                    <div class="article-summary-box-inner">
                                        <span>The common implementation of face recognition systems as a cascade of a
detection stage and a recognition or verification stage can cause problems
beyond failures of the detector. When the detector succeeds, it can detect
faces that cannot be recognized, no matter how capable the recognition system.
Recognizability, a latent variable, should therefore be factored into the
design and implementation of face recognition systems. We propose a measure of
recognizability of a face image that leverages a key empirical observation: an
embedding of face images, implemented by a deep neural network trained using
mostly recognizable identities, induces a partition of the hypersphere whereby
unrecognizable identities cluster together. This occurs regardless of the
phenomenon that causes a face to be unrecognizable, it be optical or motion
blur, partial occlusion, spatial quantization, poor illumination. Therefore, we
use the distance from such an &quot;unrecognizable identity&quot; as a measure of
recognizability, and incorporate it in the design of the over-all system. We
show that accounting for recognizability reduces error rate of single-image
face recognition by 58% at FAR&#x3D;1e-5 on the IJB-C Covariate Verification
benchmark, and reduces verification error rate by 24% at FAR&#x3D;1e-5 in set-based
recognition on the IJB-C benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discover the Unknown Biased Attribute of an Image Classifier. (arXiv:2104.14556v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenliang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14556">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works find that AI algorithms learn biases from data. Therefore, it is
urgent and vital to identify biases in AI algorithms. However, the previous
bias identification pipeline overly relies on human experts to conjecture
potential biases (e.g., gender), which may neglect other underlying biases not
realized by humans. To help human experts better find the AI algorithms&#x27;
biases, we study a new problem in this work -- for a classifier that predicts a
target attribute of the input image, discover its unknown biased attribute.

To solve this challenging problem, we use a hyperplane in the generative
model&#x27;s latent space to represent an image attribute; thus, the original
problem is transformed to optimizing the hyperplane&#x27;s normal vector and offset.
We propose a novel total-variation loss within this framework as the objective
function and a new orthogonalization penalty as a constraint. The latter
prevents trivial solutions in which the discovered biased attribute is
identical with the target or one of the known-biased attributes. Extensive
experiments on both disentanglement datasets and real-world datasets show that
our method can discover biased attributes and achieve better disentanglement
w.r.t. target attributes. Furthermore, the qualitative results show that our
method can discover unnoticeable biased attributes for various object and scene
classifiers, proving our method&#x27;s generalizability for detecting biased
attributes in diverse domains of images. The code is available at
https://git.io/J3kMh.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuralFusion: Online Depth Fusion in Latent Space. (arXiv:2011.14791v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weder_S/0/1/0/all/0/1">Silvan Weder</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonberger_J/0/1/0/all/0/1">Johannes L. Sch&#xf6;nberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Pollefeys_M/0/1/0/all/0/1">Marc Pollefeys</a>, <a href="http://arxiv.org/find/cs/1/au:+Oswald_M/0/1/0/all/0/1">Martin R. Oswald</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14791">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel online depth map fusion approach that learns depth map
aggregation in a latent feature space. While previous fusion methods use an
explicit scene representation like signed distance functions (SDFs), we propose
a learned feature representation for the fusion. The key idea is a separation
between the scene representation used for the fusion and the output scene
representation, via an additional translator network. Our neural network
architecture consists of two main parts: a depth and feature fusion
sub-network, which is followed by a translator sub-network to produce the final
surface representation (e.g. TSDF) for visualization or other tasks. Our
approach is an online process, handles high noise levels, and is particularly
able to deal with gross outliers common for photometric stereo-based depth
maps. Experiments on real and synthetic data demonstrate improved results
compared to the state of the art, especially in challenging scenarios with
large amounts of noise and outliers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning by Distillation: A Self-Supervised Learning Framework for Optical Flow Estimation. (arXiv:2106.04195v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengpeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael R. Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jia Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04195">
                                    <div class="article-summary-box-inner">
                                        <span>We present DistillFlow, a knowledge distillation approach to learning optical
flow. DistillFlow trains multiple teacher models and a student model, where
challenging transformations are applied to the input of the student model to
generate hallucinated occlusions as well as less confident predictions. Then, a
self-supervised learning framework is constructed: confident predictions from
teacher models are served as annotations to guide the student model to learn
optical flow for those less confident predictions. The self-supervised learning
framework enables us to effectively learn optical flow from unlabeled data, not
only for non-occluded pixels, but also for occluded pixels. DistillFlow
achieves state-of-the-art unsupervised learning performance on both KITTI and
Sintel datasets. Our self-supervised pre-trained model also provides an
excellent initialization for supervised fine-tuning, suggesting an alternate
training paradigm in contrast to current supervised learning methods that
highly rely on pre-training on synthetic data. At the time of writing, our
fine-tuned models ranked 1st among all monocular methods on the KITTI 2015
benchmark, and outperform all published methods on the Sintel Final benchmark.
More importantly, we demonstrate the generalization capability of DistillFlow
in three aspects: framework generalization, correspondence generalization and
cross-dataset generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Space-time Video Super Resolution using Low-Resolution Flow and Mask Upsampling. (arXiv:2104.05778v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Dutta_S/0/1/0/all/0/1">Saikat Dutta</a>, <a href="http://arxiv.org/find/eess/1/au:+Shah_N/0/1/0/all/0/1">Nisarg A. Shah</a>, <a href="http://arxiv.org/find/eess/1/au:+Mittal_A/0/1/0/all/0/1">Anurag Mittal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05778">
                                    <div class="article-summary-box-inner">
                                        <span>This paper explores an efficient solution for Space-time Super-Resolution,
aiming to generate High-resolution Slow-motion videos from Low Resolution and
Low Frame rate videos. A simplistic solution is the sequential running of Video
Super Resolution and Video Frame interpolation models. However, this type of
solutions are memory inefficient, have high inference time, and could not make
the proper use of space-time relation property. To this extent, we first
interpolate in LR space using quadratic modeling. Input LR frames are
super-resolved using a state-of-the-art Video Super-Resolution method. Flowmaps
and blending mask which are used to synthesize LR interpolated frame is reused
in HR space using bilinear upsampling. This leads to a coarse estimate of HR
intermediate frame which often contains artifacts along motion boundaries. We
use a refinement network to improve the quality of HR intermediate frame via
residual learning. Our model is lightweight and performs better than current
state-of-the-art models in REDS STSR Validation set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1">Nataniel Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kortylewski_A/0/1/0/all/0/1">Adam Kortylewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Weichao Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Cihang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1">Sarah Adel Bargal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1">Stan Sclaroff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04569">
                                    <div class="article-summary-box-inner">
                                        <span>Most machine learning models are validated and tested on fixed datasets. This
can give an incomplete picture of the capabilities and weaknesses of the model.
Such weaknesses can be revealed at test time in the real world. The risks
involved in such failures can be loss of profits, loss of time or even loss of
life in certain critical applications. In order to alleviate this issue,
simulators can be controlled in a fine-grained manner using interpretable
parameters to explore the semantic image manifold. In this work, we propose a
framework for learning how to test machine learning algorithms using simulators
in an adversarial manner in order to find weaknesses in the model before
deploying it in critical scenarios. We apply this model in a face recognition
scenario. We are the first to show that weaknesses of models trained on real
data can be discovered using simulated samples. Using our proposed method, we
can find adversarial synthetic faces that fool contemporary face recognition
models. This demonstrates the fact that these models have weaknesses that are
not measured by commonly used validation datasets. We hypothesize that this
type of adversarial examples are not isolated, but usually lie in connected
components in the latent space of the simulator. We present a method to find
these adversarial regions as opposed to the typical adversarial points found in
the adversarial example literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the role of feedback in visual processing: a predictive coding perspective. (arXiv:2106.04225v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1">Andrea Alamia</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozafari_M/0/1/0/all/0/1">Milad Mozafari</a>, <a href="http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1">Bhavin Choksi</a>, <a href="http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1">Rufin VanRullen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04225">
                                    <div class="article-summary-box-inner">
                                        <span>Brain-inspired machine learning is gaining increasing consideration,
particularly in computer vision. Several studies investigated the inclusion of
top-down feedback connections in convolutional networks; however, it remains
unclear how and when these connections are functionally helpful. Here we
address this question in the context of object recognition under noisy
conditions. We consider deep convolutional networks (CNNs) as models of
feed-forward visual processing and implement Predictive Coding (PC) dynamics
through feedback connections (predictive feedback) trained for reconstruction
or classification of clean images. To directly assess the computational role of
predictive feedback in various experimental situations, we optimize and
interpret the hyper-parameters controlling the network&#x27;s recurrent dynamics.
That is, we let the optimization process determine whether top-down connections
and predictive coding dynamics are functionally beneficial. Across different
model depths and architectures (3-layer CNN, ResNet18, and EfficientNetB0) and
against various types of noise (CIFAR100-C), we find that the network
increasingly relies on top-down predictions as the noise level increases; in
deeper networks, this effect is most prominent at lower layers. In addition,
the accuracy of the network implementing PC dynamics significantly increases
over time-steps, compared to its equivalent forward network. All in all, our
results provide novel insights relevant to Neuroscience by confirming the
computational role of feedback connections in sensory systems, and to Machine
Learning by revealing how these can improve the robustness of current vision
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Person Re-Identification with a Locally Aware Transformer. (arXiv:2106.03720v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_C/0/1/0/all/0/1">Charu Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapil_S/0/1/0/all/0/1">Siddhant R. Kapil</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapman_D/0/1/0/all/0/1">David Chapman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03720">
                                    <div class="article-summary-box-inner">
                                        <span>Person Re-Identification is an important problem in computer vision-based
surveillance applications, in which the same person is attempted to be
identified from surveillance photographs in a variety of nearby zones. At
present, the majority of Person re-ID techniques are based on Convolutional
Neural Networks (CNNs), but Vision Transformers are beginning to displace pure
CNNs for a variety of object recognition tasks. The primary output of a vision
transformer is a global classification token, but vision transformers also
yield local tokens which contain additional information about local regions of
the image. Techniques to make use of these local tokens to improve
classification accuracy are an active area of research. We propose a novel
Locally Aware Transformer (LA-Transformer) that employs a Parts-based
Convolution Baseline (PCB)-inspired strategy for aggregating globally enhanced
local classification tokens into an ensemble of $\sqrt{N}$ classifiers, where
$N$ is the number of patches. An additional novelty is that we incorporate
blockwise fine-tuning which further improves re-ID accuracy. LA-Transformer
with blockwise fine-tuning achieves rank-1 accuracy of $98.27 \%$ with standard
deviation of $0.13$ on the Market-1501 and $98.7\%$ with standard deviation of
$0.2$ on the CUHK03 dataset respectively, outperforming all other
state-of-the-art published methods at the time of writing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Vision Transformers. (arXiv:2106.04560v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04560">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based neural networks such as the Vision Transformer (ViT) have
recently attained state-of-the-art results on many computer vision benchmarks.
Scale is a primary ingredient in attaining excellent results, therefore,
understanding a model&#x27;s scaling properties is a key to designing future
generations effectively. While the laws for scaling Transformer language models
have been studied, it is unknown how Vision Transformers scale. To address
this, we scale ViT models and data, both up and down, and characterize the
relationships between error rate, data, and compute. Along the way, we refine
the architecture and training of ViT, reducing memory consumption and
increasing accuracy the resulting models. As a result, we successfully train a
ViT model with two billion parameters, which attains a new state-of-the-art on
ImageNet of 90.45% top-1 accuracy. The model also performs well on few-shot
learning, for example, attaining 84.86% top-1 accuracy on ImageNet with only 10
examples per class.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta Learning for Knowledge Distillation. (arXiv:2106.04570v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Canwen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04570">
                                    <div class="article-summary-box-inner">
                                        <span>We present Meta Learning for Knowledge Distillation (MetaDistil), a simple
yet effective alternative to traditional knowledge distillation (KD) methods
where the teacher model is fixed during training. We show the teacher network
can learn to better transfer knowledge to the student network (i.e., learning
to teach) with the feedback from the performance of the distilled student
network in a meta learning framework. Moreover, we introduce a pilot update
mechanism to improve the alignment between the inner-learner and meta-learner
in meta learning algorithms that focus on an improved inner-learner.
Experiments on various benchmarks show that MetaDistil can yield significant
improvements compared with traditional KD algorithms and is less sensitive to
the choice of different student capacity and hyperparameters, facilitating the
use of KD on different tasks and models. The code is available at
https://github.com/JetRunner/MetaDistil</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruocheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1">Jiayuan Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1">Samuel J. Gershman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15814">
                                    <div class="article-summary-box-inner">
                                        <span>We present Language-mediated, Object-centric Representation Learning (LORL),
a paradigm for learning disentangled, object-centric scene representations from
vision and language. LORL builds upon recent advances in unsupervised object
discovery and segmentation, notably MONet and Slot Attention. While these
algorithms learn an object-centric representation just by reconstructing the
input image, LORL enables them to further learn to associate the learned
representations to concepts, i.e., words for object categories, properties, and
spatial relationships, from language input. These object-centric concepts
derived from language facilitate the learning of object-centric
representations. LORL can be integrated with various unsupervised object
discovery algorithms that are language-agnostic. Experiments show that the
integration of LORL consistently improves the performance of unsupervised
object discovery methods on two datasets via the help of language. We also show
that concepts learned by LORL, in conjunction with object discovery methods,
aid downstream tasks such as referring expression comprehension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">f-CNN$^{\text{x}}$: A Toolflow for Mapping Multi-CNN Applications on FPGAs. (arXiv:1805.10174v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1">Stylianos I. Venieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1">Christos-Savvas Bouganis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1805.10174">
                                    <div class="article-summary-box-inner">
                                        <span>The predictive power of Convolutional Neural Networks (CNNs) has been an
integral factor for emerging latency-sensitive applications, such as autonomous
drones and vehicles. Such systems employ multiple CNNs, each one trained for a
particular task. The efficient mapping of multiple CNNs on a single FPGA device
is a challenging task as the allocation of compute resources and external
memory bandwidth needs to be optimised at design time. This paper proposes
f-CNN$^{\text{x}}$, an automated toolflow for the optimised mapping of multiple
CNNs on FPGAs, comprising a novel multi-CNN hardware architecture together with
an automated design space exploration method that considers the user-specified
performance requirements for each model to allocate compute resources and
generate a synthesisable accelerator. Moreover, f-CNN$^{\text{x}}$ employs a
novel scheduling algorithm that alleviates the limitations of the memory
bandwidth contention between CNNs and sustains the high utilisation of the
architecture. Experimental evaluation shows that f-CNN$^{\text{x}}$&#x27;s designs
outperform contention-unaware FPGA mappings by up to 50% and deliver up to 6.8x
higher performance-per-Watt over highly optimised GPU designs for multi-CNN
systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DETReg: Unsupervised Pretraining with Region Priors for Object Detection. (arXiv:2106.04550v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bar_A/0/1/0/all/0/1">Amir Bar</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kantorov_V/0/1/0/all/0/1">Vadim Kantorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Reed_C/0/1/0/all/0/1">Colorado J Reed</a>, <a href="http://arxiv.org/find/cs/1/au:+Herzig_R/0/1/0/all/0/1">Roei Herzig</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_A/0/1/0/all/0/1">Anna Rohrbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1">Amir Globerson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04550">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised pretraining has recently proven beneficial for computer vision
tasks, including object detection. However, previous self-supervised approaches
are not designed to handle a key aspect of detection: localizing objects. Here,
we present DETReg, an unsupervised pretraining approach for object DEtection
with TRansformers using Region priors. Motivated by the two tasks underlying
object detection: localization and categorization, we combine two complementary
signals for self-supervision. For an object localization signal, we use pseudo
ground truth object bounding boxes from an off-the-shelf unsupervised region
proposal method, Selective Search, which does not require training data and can
detect objects at a high recall rate and very low precision. The categorization
signal comes from an object embedding loss that encourages invariant object
representations, from which the object category can be inferred. We show how to
combine these two signals to train the Deformable DETR detection architecture
from large amounts of unlabeled data. DETReg improves the performance over
competitive baselines and previous self-supervised methods on standard
benchmarks like MS COCO and PASCAL VOC. DETReg also outperforms previous
supervised and unsupervised baseline approaches on low-data regime when trained
with only 1%, 2%, 5%, and 10% of the labeled data on MS COCO. For code and
pretrained models, visit the project page at https://amirbar.net/detreg</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object Based Attention Through Internal Gating. (arXiv:2106.04540v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Lei_J/0/1/0/all/0/1">Jordan Lei</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Benjamin_A/0/1/0/all/0/1">Ari S. Benjamin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kording_K/0/1/0/all/0/1">Konrad P. Kording</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04540">
                                    <div class="article-summary-box-inner">
                                        <span>Object-based attention is a key component of the visual system, relevant for
perception, learning, and memory. Neurons tuned to features of attended objects
tend to be more active than those associated with non-attended objects. There
is a rich set of models of this phenomenon in computational neuroscience.
However, there is currently a divide between models that successfully match
physiological data but can only deal with extremely simple problems and models
of attention used in computer vision. For example, attention in the brain is
known to depend on top-down processing, whereas self-attention in deep learning
does not. Here, we propose an artificial neural network model of object-based
attention that captures the way in which attention is both top-down and
recurrent. Our attention model works well both on simple test stimuli, such as
those using images of handwritten digits, and on more complex stimuli, such as
natural images drawn from the COCO dataset. We find that our model replicates a
range of findings from neuroscience, including attention-invariant tuning,
inhibition of return, and attention-mediated scaling of activity. Understanding
object based attention is both computationally interesting and a key problem
for computational neuroscience.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MViT: Mask Vision Transformer for Facial Expression Recognition in the wild. (arXiv:2106.04520v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hanting Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_M/0/1/0/all/0/1">Mingzhe Sui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Feng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zhengjun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04520">
                                    <div class="article-summary-box-inner">
                                        <span>Facial Expression Recognition (FER) in the wild is an extremely challenging
task in computer vision due to variant backgrounds, low-quality facial images,
and the subjectiveness of annotators. These uncertainties make it difficult for
neural networks to learn robust features on limited-scale datasets. Moreover,
the networks can be easily distributed by the above factors and perform
incorrect decisions. Recently, vision transformer (ViT) and data-efficient
image transformers (DeiT) present their significant performance in traditional
classification tasks. The self-attention mechanism makes transformers obtain a
global receptive field in the first layer which dramatically enhances the
feature extraction capability. In this work, we first propose a novel pure
transformer-based mask vision transformer (MViT) for FER in the wild, which
consists of two modules: a transformer-based mask generation network (MGN) to
generate a mask that can filter out complex backgrounds and occlusion of face
images, and a dynamic relabeling module to rectify incorrect labels in FER
datasets in the wild. Extensive experimental results demonstrate that our MViT
outperforms state-of-the-art methods on RAF-DB with 88.62%, FERPlus with
89.22%, and AffectNet-7 with 64.57%, respectively, and achieves a comparable
result on AffectNet-8 with 61.40%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise Conditional Flow Model for Learning the Super-Resolution Space. (arXiv:2106.04428v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Younggeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Son_D/0/1/0/all/0/1">Donghee Son</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04428">
                                    <div class="article-summary-box-inner">
                                        <span>Fundamentally, super-resolution is ill-posed problem because a low-resolution
image can be obtained from many high-resolution images. Recent studies for
super-resolution cannot create diverse super-resolution images. Although SRFlow
tried to account for ill-posed nature of the super-resolution by predicting
multiple high-resolution images given a low-resolution image, there is room to
improve the diversity and visual quality. In this paper, we propose Noise
Conditional flow model for Super-Resolution, NCSR, which increases the visual
quality and diversity of images through noise conditional layer. To learn more
diverse data distribution, we add noise to training data. However, low-quality
images are resulted from adding noise. We propose the noise conditional layer
to overcome this phenomenon. The noise conditional layer makes our model
generate more diverse images with higher visual quality than other works.
Furthermore, we show that this layer can overcome data distribution mismatch, a
problem that arises in normalizing flow models. With these benefits, NCSR
outperforms baseline in diversity and visual quality and achieves better visual
quality than traditional GAN-based models. We also get outperformed scores at
NTIRE 2021 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hwanjun Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minseok Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dongmin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yooju Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae-Gil Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08199">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has achieved remarkable success in numerous domains with help
from large amounts of big data. However, the quality of data labels is a
concern because of the lack of high-quality labels in many real-world
scenarios. As noisy labels severely degrade the generalization performance of
deep neural networks, learning from noisy labels (robust training) is becoming
an important task in modern deep learning applications. In this survey, we
first describe the problem of learning with label noise from a supervised
learning perspective. Next, we provide a comprehensive review of 57
state-of-the-art robust training methods, all of which are categorized into
five groups according to their methodological difference, followed by a
systematic comparison of six properties used to evaluate their superiority.
Subsequently, we perform an in-depth analysis of noise rate estimation and
summarize the typically used evaluation methodology, including public noisy
datasets and evaluation metrics. Finally, we present several promising research
directions that can serve as a guideline for future studies. All the contents
will be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The PREVENTION Challenge: How Good Are Humans Predicting Lane Changes?. (arXiv:2009.05331v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Quintanar_A/0/1/0/all/0/1">A. Quintanar</a>, <a href="http://arxiv.org/find/cs/1/au:+Izquierdo_R/0/1/0/all/0/1">R. Izquierdo</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_I/0/1/0/all/0/1">I. Parra</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Llorca_D/0/1/0/all/0/1">D. Fern&#xe1;ndez-Llorca</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotelo_M/0/1/0/all/0/1">M. A. Sotelo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05331">
                                    <div class="article-summary-box-inner">
                                        <span>While driving on highways, every driver tries to be aware of the behavior of
surrounding vehicles, including possible emergency braking, evasive maneuvers
trying to avoid obstacles, unexpected lane changes, or other emergencies that
could lead to an accident. In this paper, human&#x27;s ability to predict lane
changes in highway scenarios is analyzed through the use of video sequences
extracted from the PREVENTION dataset, a database focused on the development of
research on vehicle intention and trajectory prediction. Thus, users had to
indicate the moment at which they considered that a lane change maneuver was
taking place in a target vehicle, subsequently indicating its direction: left
or right. The results retrieved have been carefully analyzed and compared to
ground truth labels, evaluating statistical models to understand whether humans
can actually predict. The study has revealed that most participants are unable
to anticipate lane-change maneuvers, detecting them after they have started.
These results might serve as a baseline for AI&#x27;s prediction ability evaluation,
grading if those systems can outperform human skills by analyzing hidden cues
that seem unnoticed, improving the detection time, and even anticipating
maneuvers in some cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-Efficient Instance Generation from Instance Discrimination. (arXiv:2106.04566v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Ceyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yujun Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yinghao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04566">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have significantly advanced image
synthesis, however, the synthesis quality drops significantly given a limited
amount of training data. To improve the data efficiency of GAN training, prior
work typically employs data augmentation to mitigate the overfitting of the
discriminator yet still learn the discriminator with a bi-classification (i.e.,
real vs. fake) task. In this work, we propose a data-efficient Instance
Generation (InsGen) method based on instance discrimination. Concretely,
besides differentiating the real domain from the fake domain, the discriminator
is required to distinguish every individual image, no matter it comes from the
training set or from the generator. In this way, the discriminator can benefit
from the infinite synthesized samples for training, alleviating the overfitting
problem caused by insufficient training data. A noise perturbation strategy is
further introduced to improve its discriminative power. Meanwhile, the learned
instance discrimination capability from the discriminator is in turn exploited
to encourage the generator for diverse generation. Extensive experiments
demonstrate the effectiveness of our method on a variety of datasets and
training settings. Noticeably, on the setting of 2K training images from the
FFHQ dataset, we outperform the state-of-the-art approach with 23.5% FID
improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1">Daniel Rosenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1">Itai Gat</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04484">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms have shown promising results in visual question
answering (VQA) tasks, but a more careful look reveals that they often do not
understand the rich signal they are being fed with. To understand and better
measure the generalization capabilities of VQA systems, we look at their
robustness to counterfactually augmented data. Our proposed augmentations are
designed to make a focused intervention on a specific property of the question
such that the answer changes. Using these augmentations, we propose a new
robustness measure, Robustness to Augmented Data (RAD), which measures the
consistency of model predictions between original and augmented examples.
Through extensive experimentation, we show that RAD, unlike classical accuracy
measures, can quantify when state-of-the-art systems are not robust to
counterfactuals. We find substantial failure cases which reveal that current
VQA systems are still brittle. Finally, we connect between robustness and
generalization, demonstrating the predictive power of RAD for performance on
unseen augmentations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the benefits of defining vicinal distributions in latent space. (arXiv:2003.06566v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mangla_P/0/1/0/all/0/1">Puneet Mangla</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1">Vedant Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1">Shreyas Jayant Havaldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06566">
                                    <div class="article-summary-box-inner">
                                        <span>The vicinal risk minimization (VRM) principle is an empirical risk
minimization (ERM) variant that replaces Dirac masses with vicinal functions.
There is strong numerical and theoretical evidence showing that VRM outperforms
ERM in terms of generalization if appropriate vicinal functions are chosen.
Mixup Training (MT), a popular choice of vicinal distribution, improves the
generalization performance of models by introducing globally linear behavior in
between training examples. Apart from generalization, recent works have shown
that mixup trained models are relatively robust to input
perturbations/corruptions and at the same time are calibrated better than their
non-mixup counterparts. In this work, we investigate the benefits of defining
these vicinal distributions like mixup in latent space of generative models
rather than in input space itself. We propose a new approach - \textit{VarMixup
(Variational Mixup)} - to better sample mixup images by using the latent
manifold underlying the data. Our empirical studies on CIFAR-10, CIFAR-100, and
Tiny-ImageNet demonstrate that models trained by performing mixup in the latent
manifold learned by VAEs are inherently more robust to various input
corruptions/perturbations, are significantly better calibrated, and exhibit
more local-linear loss landscapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the relation between statistical learning and perceptual distances. (arXiv:2106.04427v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hepburn_A/0/1/0/all/0/1">Alexander Hepburn</a>, <a href="http://arxiv.org/find/cs/1/au:+Laparra_V/0/1/0/all/0/1">Valero Laparra</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1">Raul Santos-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Balle_J/0/1/0/all/0/1">Johannes Ball&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Malo_J/0/1/0/all/0/1">Jes&#xfa;s Malo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04427">
                                    <div class="article-summary-box-inner">
                                        <span>It has been demonstrated many times that the behavior of the human visual
system is connected to the statistics of natural images. Since machine learning
relies on the statistics of training data as well, the above connection has
interesting implications when using perceptual distances (which mimic the
behavior of the human visual system) as a loss function. In this paper, we aim
to unravel the non-trivial relationship between the probability distribution of
the data, perceptual distances, and unsupervised machine learning. To this end,
we show that perceptual sensitivity is correlated with the probability of an
image in its close neighborhood. We also explore the relation between distances
induced by autoencoders and the probability distribution of the data used for
training them, as well as how these induced distances are correlated with human
perception. Finally, we discuss why perceptual distances might not lead to
noticeable gains in performance over standard Euclidean distances in common
image processing tasks except when data is scarce and the perceptual distance
provides regularization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PolypGen: A multi-center polyp detection and segmentation dataset for generalisability assessment. (arXiv:2106.04463v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1">Sharib Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1">Debesh Jha</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghatwary_N/0/1/0/all/0/1">Noha Ghatwary</a>, <a href="http://arxiv.org/find/eess/1/au:+Realdon_S/0/1/0/all/0/1">Stefano Realdon</a>, <a href="http://arxiv.org/find/eess/1/au:+Cannizzaro_R/0/1/0/all/0/1">Renato Cannizzaro</a>, <a href="http://arxiv.org/find/eess/1/au:+Salem_O/0/1/0/all/0/1">Osama E. Salem</a>, <a href="http://arxiv.org/find/eess/1/au:+Lamarque_D/0/1/0/all/0/1">Dominique Lamarque</a>, <a href="http://arxiv.org/find/eess/1/au:+Daul_C/0/1/0/all/0/1">Christian Daul</a>, <a href="http://arxiv.org/find/eess/1/au:+Anonsen_K/0/1/0/all/0/1">Kim V. Anonsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Rittscher_J/0/1/0/all/0/1">Jens Rittscher</a>, <a href="http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/eess/1/au:+East_J/0/1/0/all/0/1">James E. East</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04463">
                                    <div class="article-summary-box-inner">
                                        <span>Polyps in the colon are widely known as cancer precursors identified by
colonoscopy either related to diagnostic work-up for symptoms, colorectal
cancer screening or systematic surveillance of certain diseases. Whilst most
polyps are benign, the number, size and the surface structure of the polyp are
tightly linked to the risk of colon cancer. There exists a high missed
detection rate and incomplete removal of colon polyps due to the variable
nature, difficulties to delineate the abnormality, high recurrence rates and
the anatomical topography of the colon. In the past, several methods have been
built to automate polyp detection and segmentation. However, the key issue of
most methods is that they have not been tested rigorously on a large
multi-center purpose-built dataset. Thus, these methods may not generalise to
different population datasets as they overfit to a specific population and
endoscopic surveillance. To this extent, we have curated a dataset from 6
different centers incorporating more than 300 patients. The dataset includes
both single frame and sequence data with 3446 annotated polyp labels with
precise delineation of polyp boundaries verified by six senior
gastroenterologists. To our knowledge, this is the most comprehensive detection
and pixel-level segmentation dataset curated by a team of computational
scientists and expert gastroenterologists. This dataset has been originated as
the part of the Endocv2021 challenge aimed at addressing generalisability in
polyp detection and segmentation. In this paper, we provide comprehensive
insight into data construction and annotation strategies, annotation quality
assurance and technical validation for our extended EndoCV2021 dataset which we
refer to as PolypGen.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grapevine Winter Pruning Automation: On Potential Pruning Points Detection through 2D Plant Modeling using Grapevine Segmentation. (arXiv:2106.04208v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandes_M/0/1/0/all/0/1">Miguel Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Scaldaferri_A/0/1/0/all/0/1">Antonello Scaldaferri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fiameni_G/0/1/0/all/0/1">Giuseppe Fiameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Teng_T/0/1/0/all/0/1">Tao Teng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatti_M/0/1/0/all/0/1">Matteo Gatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Poni_S/0/1/0/all/0/1">Stefano Poni</a>, <a href="http://arxiv.org/find/cs/1/au:+Semini_C/0/1/0/all/0/1">Claudio Semini</a>, <a href="http://arxiv.org/find/cs/1/au:+Caldwell_D/0/1/0/all/0/1">Darwin Caldwell</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fei Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04208">
                                    <div class="article-summary-box-inner">
                                        <span>Grapevine winter pruning is a complex task, that requires skilled workers to
execute it correctly. The complexity of this task is also the reason why it is
time consuming. Considering that this operation takes about 80-120 hours/ha to
be completed, and therefore is even more crucial in large-size vineyards, an
automated system can help to speed up the process. To this end, this paper
presents a novel multidisciplinary approach that tackles this challenging task
by performing object segmentation on grapevine images, used to create a
representative model of the grapevine plants. Second, a set of potential
pruning points is generated from this plant representation. We will describe
(a) a methodology for data acquisition and annotation, (b) a neural network
fine-tuning for grapevine segmentation, (c) an image processing based method
for creating the representative model of grapevines, starting from the inferred
segmentation and (d) potential pruning points detection and localization, based
on the plant model which is a simplification of the grapevine structure. With
this approach, we are able to identify a significant set of potential pruning
points on the canes, that can be used, with further selection, to derive the
final set of the real pruning points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image2Point: 3D Point-Cloud Understanding with Pretrained 2D ConvNets. (arXiv:2106.04180v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenfeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shijia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_B/0/1/0/all/0/1">Bohan Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bichen Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1">Xiangyu Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1">Wei Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vajda_P/0/1/0/all/0/1">Peter Vajda</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1">Masayoshi Tomizuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04180">
                                    <div class="article-summary-box-inner">
                                        <span>3D point-clouds and 2D images are different visual representations of the
physical world. While human vision can understand both representations,
computer vision models designed for 2D image and 3D point-cloud understanding
are quite different. Our paper investigates the potential for transferability
between these two representations by empirically investigating whether this
approach works, what factors affect the transfer performance, and how to make
it work even better. We discovered that we can indeed use the same neural net
model architectures to understand both images and point-clouds. Moreover, we
can transfer pretrained weights from image models to point-cloud models with
minimal effort. Specifically, based on a 2D ConvNet pretrained on an image
dataset, we can transfer the image model to a point-cloud model by
\textit{inflating} 2D convolutional filters to 3D then finetuning its input,
output, and optionally normalization layers. The transferred model can achieve
competitive performance on 3D point-cloud classification, indoor and driving
scene segmentation, even beating a wide range of point-cloud models that adopt
task-specific architectures and use a variety of tricks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSRNet: Cascaded Selective Resolution Network for Real-time Semantic Segmentation. (arXiv:2106.04400v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Jingjing Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Po_L/0/1/0/all/0/1">Lai-Man Po</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wing-Yin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xian_P/0/1/0/all/0/1">Pengfei Xian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_W/0/1/0/all/0/1">Weifeng Ou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04400">
                                    <div class="article-summary-box-inner">
                                        <span>Real-time semantic segmentation has received considerable attention due to
growing demands in many practical applications, such as autonomous vehicles,
robotics, etc. Existing real-time segmentation approaches often utilize feature
fusion to improve segmentation accuracy. However, they fail to fully consider
the feature information at different resolutions and the receptive fields of
the networks are relatively limited, thereby compromising the performance. To
tackle this problem, we propose a light Cascaded Selective Resolution Network
(CSRNet) to improve the performance of real-time segmentation through multiple
context information embedding and enhanced feature aggregation. The proposed
network builds a three-stage segmentation system, which integrates feature
information from low resolution to high resolution and achieves feature
refinement progressively. CSRNet contains two critical modules: the Shorted
Pyramid Fusion Module (SPFM) and the Selective Resolution Module (SRM). The
SPFM is a computationally efficient module to incorporate the global context
information and significantly enlarge the receptive field at each stage. The
SRM is designed to fuse multi-resolution feature maps with various receptive
fields, which assigns soft channel attentions across the feature maps and helps
to remedy the problem caused by multi-scale objects. Comprehensive experiments
on two well-known datasets demonstrate that the proposed CSRNet effectively
improves the performance for real-time segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-frame sequence generator of 4D human body motion. (arXiv:2106.04387v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathieu_M/0/1/0/all/0/1">Marsot Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Stefanie_W/0/1/0/all/0/1">Wuhrer Stefanie</a>, <a href="http://arxiv.org/find/cs/1/au:+Jean_Sebastien_F/0/1/0/all/0/1">Franco Jean-Sebastien</a>, <a href="http://arxiv.org/find/cs/1/au:+Stephane_D/0/1/0/all/0/1">Durocher Stephane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04387">
                                    <div class="article-summary-box-inner">
                                        <span>We examine the problem of generating temporally and spatially dense 4D human
body motion. On the one hand generative modeling has been extensively studied
as a per time-frame static fitting problem for dense 3D models such as mesh
representations, where the temporal aspect is left out of the generative model.
On the other hand, temporal generative models exist for sparse human models
such as marker-based capture representations, but have not to our knowledge
been extended to dense 3D shapes. We propose to bridge this gap with a
generative auto-encoder-based framework, which encodes morphology, global
locomotion including translation and rotation, and multi-frame temporal motion
as a single latent space vector. To assess its generalization and factorization
abilities, we train our model on a cyclic locomotion subset of AMASS,
leveraging the dense surface models it provides for an extensive set of motion
captures. Our results validate the ability of the model to reconstruct 4D
sequences of human locomotions within a low error bound, and the meaningfulness
of latent space interpolation between latent vectors representing different
multi-frame sequences and locomotion types. We also illustrate the benefits of
the approach for 4D human motion prediction of future frames from initial human
locomotion frames, showing promising abilities of our model to learn realistic
spatio-temporal features of human motion. We show that our model allows for
data completion of both spatially and temporally sparse data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Improving Adversarial Transferability of Vision Transformers. (arXiv:2106.04169v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1">Muzammal Naseer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1">Kanchana Ranasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Fahad Shahbaz Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1">Fatih Porikli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04169">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformers (ViTs) process input images as sequences of patches via
self-attention; a radically different architecture than convolutional neural
networks (CNNs). This makes it interesting to study the adversarial feature
space of ViT models and their transferability. In particular, we observe that
adversarial patterns found via conventional adversarial attacks show very low
black-box transferability even for large ViT models. However, we show that this
phenomenon is only due to the sub-optimal attack procedures that do not
leverage the true representation potential of ViTs. A deep ViT is composed of
multiple blocks, with a consistent architecture comprising of self-attention
and feed-forward layers, where each block is capable of independently producing
a class token. Formulating an attack using only the last class token
(conventional approach) does not directly leverage the discriminative
information stored in the earlier tokens, leading to poor adversarial
transferability of ViTs. Using the compositional nature of ViT models, we
enhance the transferability of existing attacks by introducing two novel
strategies specific to the architecture of ViT models. (i) Self-Ensemble: We
propose a method to find multiple discriminative pathways by dissecting a
single ViT model into an ensemble of networks. This allows explicitly utilizing
class-specific information at each ViT block. (ii) Token Refinement: We then
propose to refine the tokens to further enhance the discriminative capacity at
each block of ViT. Our token refinement systematically combines the class
tokens with structural information preserved within the patch tokens. An
adversarial attack, when applied to such refined tokens within the ensemble of
classifiers found in a single vision transformer, has significantly higher
transferability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Concise yet Effective model for Non-Aligned Incomplete Multi-view and Missing Multi-label Learning. (arXiv:2005.00976v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Songcan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00976">
                                    <div class="article-summary-box-inner">
                                        <span>In reality, learning from multi-view multi-label data inevitably confronts
three challenges: missing labels, incomplete views, and non-aligned views.
Existing methods mainly concern the first two and commonly need multiple
assumptions to attack them, making even state-of-the-arts involve at least two
explicit hyper-parameters such that model selection is quite difficult. More
roughly, they will fail in handling the third challenge, let alone addressing
the three jointly. In this paper, we aim at meeting these under the least
assumption by building a concise yet effective model with just one
hyper-parameter. To ease insufficiency of available labels, we exploit not only
the consensus of multiple views but also the global and local structures hidden
among multiple labels. Specifically, we introduce an indicator matrix to tackle
the first two challenges in a regression form while aligning the same
individual labels and all labels of different views in a common label space to
battle the third challenge. In aligning, we characterize the global and local
structures of multiple labels to be high-rank and low-rank, respectively.
Subsequently, an efficient algorithm with linear time complexity in the number
of samples is established. Finally, even without view-alignment, our method
substantially outperforms state-of-the-arts with view-alignment on five real
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SDGMNet: Statistic-based Dynamic Gradient Modulation for Local Descriptor Learning. (arXiv:2106.04434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuxin Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04434">
                                    <div class="article-summary-box-inner">
                                        <span>Modifications on triplet loss that rescale the back-propagated gradients of
special pairs have made significant progress on local descriptor learning.
However, current gradient modulation strategies are mainly static so that they
would suffer from changes of training phases or datasets. In this paper, we
propose a dynamic gradient modulation, named SDGMNet, to improve triplet loss
for local descriptor learning. The core of our method is formulating modulation
functions with statistical characteristics which are estimated dynamically.
Firstly, we perform deep analysis on back propagation of general triplet-based
loss and introduce included angle for distance measure. On this basis,
auto-focus modulation is employed to moderate the impact of statistically
uncommon individual pairs in stochastic gradient descent optimization;
probabilistic margin cuts off the gradients of proportional Siamese pairs that
are believed to reach the optimum; power adjustment balances the total weights
of negative pairs and positive pairs. Extensive experiments demonstrate that
our novel descriptor surpasses previous state-of-the-arts on standard
benchmarks including patch verification, matching and retrieval tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans. (arXiv:2106.04281v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Posilovic_L/0/1/0/all/0/1">Luka Posilovi&#x107;</a>, <a href="http://arxiv.org/find/eess/1/au:+Medak_D/0/1/0/all/0/1">Duje Medak</a>, <a href="http://arxiv.org/find/eess/1/au:+Subasic_M/0/1/0/all/0/1">Marko Subasic</a>, <a href="http://arxiv.org/find/eess/1/au:+Budimir_M/0/1/0/all/0/1">Marko Budimir</a>, <a href="http://arxiv.org/find/eess/1/au:+Loncaric_S/0/1/0/all/0/1">Sven Loncaric</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04281">
                                    <div class="article-summary-box-inner">
                                        <span>Non-destructive testing is a set of techniques for defect detection in
materials. While the set of imaging techniques are manifold, ultrasonic imaging
is the one used the most. The analysis is mainly performed by human inspectors
manually analyzing recorded images. The low number of defects in real
ultrasonic inspections and legal issues considering data from such inspections
make it difficult to obtain proper results from automatic ultrasonic image
(B-scan) analysis. In this paper, we present a novel deep learning Generative
Adversarial Network model for generating ultrasonic B-scans with defects in
distinct locations. Furthermore, we show that generated B-scans can be used for
synthetic data augmentation, and can improve the performance of deep
convolutional neural object detection networks. Our novel method is
demonstrated on a dataset of almost 4000 B-scans with more than 6000 annotated
defects. Defect detection performance when training on real data yielded
average precision of 71%. By training only on generated data the results
increased to 72.1%, and by mixing generated and real data we achieve 75.7%
average precision. We believe that synthetic data generation can generalize to
other challenges with limited datasets and could be used for training human
personnel.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmentation and ABCD rule extraction for skin tumors classification. (arXiv:2106.04372v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Messadi_M/0/1/0/all/0/1">Mahammed Messadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cherifi_H/0/1/0/all/0/1">Hocine Cherifi</a> (Le2i), <a href="http://arxiv.org/find/cs/1/au:+Bessaid_A/0/1/0/all/0/1">Abdelhafid Bessaid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04372">
                                    <div class="article-summary-box-inner">
                                        <span>During the last years, computer vision-based diagnosis systems have been
widely used in several hospitals and dermatology clinics, aiming at the early
detection of malignant melanoma tumor, which is among the most frequent types
of skin cancer. In this work, we present an automated diagnosis system based on
the ABCD rule used in clinical diagnosis in order to discriminate benign from
malignant skin lesions. First, to reduce the influence of small structures, a
preprocessing step based on morphological and fast marching schemes is used. In
the second step, an unsupervised approach for lesion segmentation is proposed.
Iterative thresholding is applied to initialize level set automatically. As the
detection of an automated border is an important step for the correctness of
subsequent phases in the computerized melanoma recognition systems, we compare
its accuracy with growcut and mean shift algorithms, and discuss how these
results may influence in the following steps: the feature extraction and the
final lesion classification. Relying on visual diagnosis four features:
Asymmetry (A), Border (B), Color (C) and Diversity (D) are computed and used to
construct a classification module based on artificial neural network for the
recognition of malignant melanoma. This framework has been tested on a
dermoscopic database [16] of 320 images. The classification results show an
increasing true detection rate and a decreasing false positive rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Action Localization without Knowing Boundaries. (arXiv:2106.04150v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Ting-Ting Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Tzelepis_C/0/1/0/all/0/1">Christos Tzelepis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_F/0/1/0/all/0/1">Fan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patras_I/0/1/0/all/0/1">Ioannis Patras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04150">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to localize actions in long, cluttered, and untrimmed videos is a
hard task, that in the literature has typically been addressed assuming the
availability of large amounts of annotated training samples for each class --
either in a fully-supervised setting, where action boundaries are known, or in
a weakly-supervised setting, where only class labels are known for each video.
In this paper, we go a step further and show that it is possible to learn to
localize actions in untrimmed videos when a) only one/few trimmed examples of
the target action are available at test time, and b) when a large collection of
videos with only class label annotation (some trimmed and some weakly annotated
untrimmed ones) are available for training; with no overlap between the classes
used during training and testing. To do so, we propose a network that learns to
estimate Temporal Similarity Matrices (TSMs) that model a fine-grained
similarity pattern between pairs of videos (trimmed or untrimmed), and uses
them to generate Temporal Class Activation Maps (TCAMs) for seen or unseen
classes. The TCAMs serve as temporal attention mechanisms to extract
video-level representations of untrimmed videos, and to temporally localize
actions at test time. To the best of our knowledge, we are the first to propose
a weakly-supervised, one/few-shot action localization network that can be
trained in an end-to-end fashion. Experimental results on THUMOS14 and
ActivityNet1.2 datasets, show that our method achieves performance comparable
or better to state-of-the-art fully-supervised, few-shot learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Semantic Hallucination for Domain Generalized Semantic Segmentation. (arXiv:2106.04144v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tjio_G/0/1/0/all/0/1">Gabriel Tjio</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_R/0/1/0/all/0/1">Rick Siow Mong Goh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04144">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks may perform poorly when the test and train data
are from different domains. While this problem can be mitigated by using the
target domain data to align the source and target domain feature
representations, the target domain data may be unavailable due to privacy
concerns. Consequently, there is a need for methods that generalize well
without access to target domain data during training. In this work, we propose
an adversarial hallucination approach, which combines a class-wise
hallucination module and a semantic segmentation module. Since the segmentation
performance varies across different classes, we design a semantic-conditioned
style hallucination layer to adaptively stylize each class. The classwise
stylization parameters are generated from the semantic knowledge in the
segmentation probability maps of the source domain image. Both modules compete
adversarially, with the hallucination module generating increasingly
&#x27;difficult&#x27; style images to challenge the segmentation module. In response, the
segmentation module improves its performance as it is trained with generated
samples at an appropriate class-wise difficulty level. Experiments on state of
the art domain adaptation work demonstrate the efficacy of our proposed method
when no target domain data are available for training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Left Ventricle Contouring in Cardiac Images Based on Deep Reinforcement Learning. (arXiv:2106.04127v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1">Sixing Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1">Yameng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shufang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04127">
                                    <div class="article-summary-box-inner">
                                        <span>Medical image segmentation is one of the important tasks of computer-aided
diagnosis in medical image analysis. Since most medical images have the
characteristics of blurred boundaries and uneven intensity distribution,
through existing segmentation methods, the discontinuity within the target area
and the discontinuity of the target boundary are likely to lead to rough or
even erroneous boundary delineation. In this paper, we propose a new iterative
refined interactive segmentation method for medical images based on agent
reinforcement learning, which focuses on the problem of target segmentation
boundaries. We model the dynamic process of drawing the target contour in a
certain order as a Markov Decision Process (MDP) based on a deep reinforcement
learning method. In the dynamic process of continuous interaction between the
agent and the image, the agent tracks the boundary point by point in order
within a limited length range until the contour of the target is completely
drawn. In this process, the agent can quickly improve the segmentation
performance by exploring an interactive policy in the image. The method we
proposed is simple and effective. At the same time, we evaluate our method on
the cardiac MRI scan data set. Experimental results show that our method has a
better segmentation effect on the left ventricle in a small number of medical
image data sets, especially in terms of segmentation boundaries, this method is
better than existing methods. Based on our proposed method, the dynamic
generation process of the predicted contour trajectory of the left ventricle
will be displayed online at https://github.com/H1997ym/LV-contour-trajectory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EnMcGAN: Adversarial Ensemble Learning for 3D Complete Renal Structures Segmentation. (arXiv:2106.04130v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1">Yuting He</a>, <a href="http://arxiv.org/find/eess/1/au:+Ge_R/0/1/0/all/0/1">Rongjun Ge</a>, <a href="http://arxiv.org/find/eess/1/au:+Qi_X/0/1/0/all/0/1">Xiaoming Qi</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_G/0/1/0/all/0/1">Guanyu Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Yang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Kong_Y/0/1/0/all/0/1">Youyong Kong</a>, <a href="http://arxiv.org/find/eess/1/au:+Shu_H/0/1/0/all/0/1">Huazhong Shu</a>, <a href="http://arxiv.org/find/eess/1/au:+Coatrieux_J/0/1/0/all/0/1">Jean-Louis Coatrieux</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1">Shuo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04130">
                                    <div class="article-summary-box-inner">
                                        <span>3D complete renal structures(CRS) segmentation targets on segmenting the
kidneys, tumors, renal arteries and veins in one inference. Once successful, it
will provide preoperative plans and intraoperative guidance for laparoscopic
partial nephrectomy(LPN), playing a key role in the renal cancer treatment.
However, no success has been reported in 3D CRS segmentation due to the complex
shapes of renal structures, low contrast and large anatomical variation. In
this study, we utilize the adversarial ensemble learning and propose Ensemble
Multi-condition GAN(EnMcGAN) for 3D CRS segmentation for the first time. Its
contribution is three-fold. 1)Inspired by windowing, we propose the
multi-windowing committee which divides CTA image into multiple narrow windows
with different window centers and widths enhancing the contrast for salient
boundaries and soft tissues. And then, it builds an ensemble segmentation model
on these narrow windows to fuse the segmentation superiorities and improve
whole segmentation quality. 2)We propose the multi-condition GAN which equips
the segmentation model with multiple discriminators to encourage the segmented
structures meeting their real shape conditions, thus improving the shape
feature extraction ability. 3)We propose the adversarial weighted ensemble
module which uses the trained discriminators to evaluate the quality of
segmented structures, and normalizes these evaluation scores for the ensemble
weights directed at the input image, thus enhancing the ensemble results. 122
patients are enrolled in this study and the mean Dice coefficient of the renal
structures achieves 84.6%. Extensive experiments with promising results on
renal structures reveal powerful segmentation accuracy and great clinical
significance in renal cancer treatment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Deformation Estimation via Multi-Objective Optimization. (arXiv:2106.04139v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nakane_T/0/1/0/all/0/1">Takumi Nakane</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xuequan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Haoran Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04139">
                                    <div class="article-summary-box-inner">
                                        <span>The free-form deformation model can represent a wide range of non-rigid
deformations by manipulating a control point lattice over the image. However,
due to a large number of parameters, it is challenging to fit the free-form
deformation model directly to the deformed image for deformation estimation
because of the complexity of the fitness landscape. In this paper, we cast the
registration task as a multi-objective optimization problem (MOP) according to
the fact that regions affected by each control point overlap with each other.
Specifically, by partitioning the template image into several regions and
measuring the similarity of each region independently, multiple objectives are
built and deformation estimation can thus be realized by solving the MOP with
off-the-shelf multi-objective evolutionary algorithms (MOEAs). In addition, a
coarse-to-fine strategy is realized by image pyramid combined with control
point mesh subdivision. Specifically, the optimized candidate solutions of the
current image level are inherited by the next level, which increases the
ability to deal with large deformation. Also, a post-processing procedure is
proposed to generate a single output utilizing the Pareto optimal solutions.
Comparative experiments on both synthetic and real-world images show the
effectiveness and usefulness of our deformation estimation method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization. (arXiv:2106.04185v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lahiri_A/0/1/0/all/0/1">Avisek Lahiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwatra_V/0/1/0/all/0/1">Vivek Kwatra</a>, <a href="http://arxiv.org/find/cs/1/au:+Frueh_C/0/1/0/all/0/1">Christian Frueh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_J/0/1/0/all/0/1">John Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bregler_C/0/1/0/all/0/1">Chris Bregler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04185">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a video-based learning framework for animating
personalized 3D talking faces from audio. We introduce two training-time data
normalizations that significantly improve data sample efficiency. First, we
isolate and represent faces in a normalized space that decouples 3D geometry,
head pose, and texture. This decomposes the prediction problem into regressions
over the 3D face shape and the corresponding 2D texture atlas. Second, we
leverage facial symmetry and approximate albedo constancy of skin to isolate
and remove spatio-temporal lighting variations. Together, these normalizations
allow simple networks to generate high fidelity lip-sync videos under novel
ambient illumination while training with just a single speaker-specific video.
Further, to stabilize temporal dynamics, we introduce an auto-regressive
approach that conditions the model on its previous visual state. Human ratings
and objective metrics demonstrate that our method outperforms contemporary
state-of-the-art audio-driven video reenactment benchmarks in terms of realism,
lip-sync and visual quality scores. We illustrate several applications enabled
by our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Highly accurate digital traffic recording as a basis for future mobility research: Methods and concepts of the research project HDV-Mess. (arXiv:2106.04175v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kloeker_L/0/1/0/all/0/1">Laurent Kloeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomsen_F/0/1/0/all/0/1">Fabian Thomsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eckstein_L/0/1/0/all/0/1">Lutz Eckstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Trettner_P/0/1/0/all/0/1">Philip Trettner</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsner_T/0/1/0/all/0/1">Tim Elsner</a>, <a href="http://arxiv.org/find/cs/1/au:+Nehring_Wirxel_J/0/1/0/all/0/1">Julius Nehring-Wirxel</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuster_K/0/1/0/all/0/1">Kersten Schuster</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobbelt_L/0/1/0/all/0/1">Leif Kobbelt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoesch_M/0/1/0/all/0/1">Michael Hoesch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04175">
                                    <div class="article-summary-box-inner">
                                        <span>The research project HDV-Mess aims at a currently missing, but very crucial
component for addressing important challenges in the field of connected and
automated driving on public roads. The goal is to record traffic events at
various relevant locations with high accuracy and to collect real traffic data
as a basis for the development and validation of current and future sensor
technologies as well as automated driving functions. For this purpose, it is
necessary to develop a concept for a mobile modular system of measuring
stations for highly accurate traffic data acquisition, which enables a
temporary installation of a sensor and communication infrastructure at
different locations. Within this paper, we first discuss the project goals
before we present our traffic detection concept using mobile modular
intelligent transport systems stations (ITS-Ss). We then explain the approaches
for data processing of sensor raw data to refined trajectories, data
communication, and data validation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversational Fashion Image Retrieval via Multiturn Natural Language Feedback. (arXiv:2106.04128v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yifei Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1">Wai Lam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04128">
                                    <div class="article-summary-box-inner">
                                        <span>We study the task of conversational fashion image retrieval via multiturn
natural language feedback. Most previous studies are based on single-turn
settings. Existing models on multiturn conversational fashion image retrieval
have limitations, such as employing traditional models, and leading to
ineffective performance. We propose a novel framework that can effectively
handle conversational fashion image retrieval with multiturn natural language
feedback texts. One characteristic of the framework is that it searches for
candidate images based on exploitation of the encoded reference image and
feedback text information together with the conversation history. Furthermore,
the image fashion attribute information is leveraged via a mutual attention
strategy. Since there is no existing fashion dataset suitable for the multiturn
setting of our task, we derive a large-scale multiturn fashion dataset via
additional manual annotation efforts on an existing single-turn dataset. The
experiments show that our proposed model significantly outperforms existing
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fully Transformer Networks for Semantic ImageSegmentation. (arXiv:2106.04108v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Sitong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tianyi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fangjian Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1">Shengwei Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1">Guodong Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04108">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have shown impressive performance in various natural language
processing and computer vision tasks, due to the capability of modeling
long-range dependencies. Recent progress has demonstrated to combine such
transformers with CNN-based semantic image segmentation models is very
promising. However, it is not well studied yet on how well a pure transformer
based approach can achieve for image segmentation. In this work, we explore a
novel framework for semantic image segmentation, which is encoder-decoder based
Fully Transformer Networks (FTN). Specifically, we first propose a Pyramid
Group Transformer (PGT) as the encoder for progressively learning hierarchical
features, while reducing the computation complexity of the standard visual
transformer(ViT). Then, we propose a Feature Pyramid Transformer (FPT) to fuse
semantic-level and spatial-level information from multiple levels of the PGT
encoder for semantic image segmentation. Surprisingly, this simple baseline can
achieve new state-of-the-art results on multiple challenging semantic
segmentation benchmarks, including PASCAL Context, ADE20K and COCO-Stuff. The
source code will be released upon the publication of this work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design of Low-Artifact Interpolation Kernels by Means of Computer Algebra. (arXiv:2106.04104v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karpov_P/0/1/0/all/0/1">Peter Karpov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04104">
                                    <div class="article-summary-box-inner">
                                        <span>We present a number of new piecewise-polynomial kernels for image
interpolation. The kernels are constructed by optimizing a measure of
interpolation quality based on the magnitude of anisotropic artifacts. The
kernel design process is performed symbolically using Mathematica computer
algebra system. Experimental evaluation involving 14 image quality assessment
methods demonstrates that our results compare favorably with the existing
linear interpolators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task-Generic Hierarchical Human Motion Prior using VAEs. (arXiv:2106.04004v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiaman Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Villegas_R/0/1/0/all/0/1">Ruben Villegas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceylan_D/0/1/0/all/0/1">Duygu Ceylan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jimei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1">Zhengfei Kuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yajie Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04004">
                                    <div class="article-summary-box-inner">
                                        <span>A deep generative model that describes human motions can benefit a wide range
of fundamental computer vision and graphics tasks, such as providing robustness
to video-based human pose estimation, predicting complete body movements for
motion capture systems during occlusions, and assisting key frame animation
with plausible movements. In this paper, we present a method for learning
complex human motions independent of specific tasks using a combined global and
local latent space to facilitate coarse and fine-grained modeling.
Specifically, we propose a hierarchical motion variational autoencoder (HM-VAE)
that consists of a 2-level hierarchical latent space. While the global latent
space captures the overall global body motion, the local latent space enables
to capture the refined poses of the different body parts. We demonstrate the
effectiveness of our hierarchical motion variational autoencoder in a variety
of tasks including video-based human pose estimation, motion completion from
partial observations, and motion synthesis from sparse key-frames. Even though,
our model has not been trained for any of these tasks specifically, it provides
superior performance than task-specific alternatives. Our general-purpose human
motion prior model can fix corrupted human body animations and generate
complete movements from incomplete observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation. (arXiv:2106.04054v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bingfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jimin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1">Jianbo Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04054">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly supervised semantic segmentation is receiving great attention due to
its low human annotation cost. In this paper, we aim to tackle bounding box
supervised semantic segmentation, i.e., training accurate semantic segmentation
models using bounding box annotations as supervision. To this end, we propose
Affinity Attention Graph Neural Network ($A^2$GNN). Following previous
practices, we first generate pseudo semantic-aware seeds, which are then formed
into semantic graphs based on our newly proposed affinity Convolutional Neural
Network (CNN). Then the built graphs are input to our $A^2$GNN, in which an
affinity attention layer is designed to acquire the short- and long- distance
information from soft graph edges to accurately propagate semantic labels from
the confident seeds to the unlabeled pixels. However, to guarantee the
precision of the seeds, we only adopt a limited number of confident pixel seed
labels for $A^2$GNN, which may lead to insufficient supervision for training.
To alleviate this issue, we further introduce a new loss function and a
consistency-checking mechanism to leverage the bounding box constraint, so that
more reliable guidance can be included for the model optimization. Experiments
show that our approach achieves new state-of-the-art performances on Pascal VOC
2012 datasets (val: 76.5\%, test: 75.2\%). More importantly, our approach can
be readily applied to bounding box supervised instance segmentation task or
other weakly supervised semantic segmentation tasks, with state-of-the-art or
comparable performance among almot all weakly supervised tasks on PASCAL VOC or
COCO dataset. Our source code will be available at
https://github.com/zbf1991/A2GNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation. (arXiv:2106.04067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1">Ruizhi Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Gaochang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yuemei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Ying Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Lu Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yebin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04067">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-resolution image alignment is a key problem in multiscale gigapixel
photography, which requires to estimate homography matrix using images with
large resolution gap. Existing deep homography methods concatenate the input
images or features, neglecting the explicit formulation of correspondences
between them, which leads to degraded accuracy in cross-resolution challenges.
In this paper, we consider the cross-resolution homography estimation as a
multimodal problem, and propose a local transformer network embedded within a
multiscale structure to explicitly learn correspondences between the multimodal
inputs, namely, input images with different resolutions. The proposed local
transformer adopts a local attention map specifically for each position in the
feature. By combining the local transformer with the multiscale structure, the
network is able to capture long-short range correspondences efficiently and
accurately. Experiments on both the MS-COCO dataset and the real-captured
cross-resolution dataset show that the proposed network outperforms existing
state-of-the-art feature-based and deep-learning-based homography estimation
methods, and is able to accurately align images under $10\times$ resolution
gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoPtosis. (arXiv:2106.03905v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Aleem_A/0/1/0/all/0/1">Abdullah Aleem</a>, <a href="http://arxiv.org/find/eess/1/au:+Nallabothula_M/0/1/0/all/0/1">Manoj Prabhakar Nallabothula</a>, <a href="http://arxiv.org/find/eess/1/au:+Setabutr_P/0/1/0/all/0/1">Pete Setabutr</a>, <a href="http://arxiv.org/find/eess/1/au:+Hallak_J/0/1/0/all/0/1">Joelle A. Hallak</a>, <a href="http://arxiv.org/find/eess/1/au:+Yi_D/0/1/0/all/0/1">Darvin Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03905">
                                    <div class="article-summary-box-inner">
                                        <span>Blepharoptosis, or ptosis as it is more commonly referred to, is a condition
of the eyelid where the upper eyelid droops. The current diagnosis for ptosis
involves cumbersome manual measurements that are time-consuming and prone to
human error. In this paper, we present AutoPtosis, an artificial intelligence
based system with interpretable results for rapid diagnosis of ptosis. We
utilize a diverse dataset collected at the University of Illinois Hospital and
Health to successfully develop a robust deep learning model for prediction and
also develop a clinically inspired model that calculates the marginal reflex
distance and iris ratio. AutoPtosis achieved 95.5% accuracy on physician
verified data that had an equal class balance. The proposed algorithm can help
in the rapid and timely diagnosis of ptosis, significantly reduce the burden on
the healthcare system, and save the patients and clinics valuable resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Triad Matching and Reconstruction for Weakly Referring Expression Grounding. (arXiv:2106.04053v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mingjie Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jimin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1">Eng Gee Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Si Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulermas_J/0/1/0/all/0/1">John Y. Goulermas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04053">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we are tackling the weakly-supervised referring expression
grounding task, for the localization of a referent object in an image according
to a query sentence, where the mapping between image regions and queries are
not available during the training stage. In traditional methods, an object
region that best matches the referring expression is picked out, and then the
query sentence is reconstructed from the selected region, where the
reconstruction difference serves as the loss for back-propagation. The existing
methods, however, conduct both the matching and the reconstruction
approximately as they ignore the fact that the matching correctness is unknown.
To overcome this limitation, a discriminative triad is designed here as the
basis to the solution, through which a query can be converted into one or
multiple discriminative triads in a very scalable way. Based on the
discriminative triad, we further propose the triad-level matching and
reconstruction modules which are lightweight yet effective for the
weakly-supervised training, making it three times lighter and faster than the
previous state-of-the-art methods. One important merit of our work is its
superior performance despite the simple and neat design. Specifically, the
proposed method achieves a new state-of-the-art accuracy when evaluated on
RefCOCO (39.21%), RefCOCO+ (39.18%) and RefCOCOg (43.24%) datasets, that is
4.17%, 4.08% and 7.8% higher than the previous one, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Novel View Video Prediction Using a Dual Representation. (arXiv:2106.03956v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shiraz_S/0/1/0/all/0/1">Sarah Shiraz</a>, <a href="http://arxiv.org/find/cs/1/au:+Regmi_K/0/1/0/all/0/1">Krishna Regmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vyas_S/0/1/0/all/0/1">Shruti Vyas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rawat_Y/0/1/0/all/0/1">Yogesh S. Rawat</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03956">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of novel view video prediction; given a set of input
video clips from a single/multiple views, our network is able to predict the
video from a novel view. The proposed approach does not require any priors and
is able to predict the video from wider angular distances, upto 45 degree, as
compared to the recent studies predicting small variations in viewpoint.
Moreover, our method relies only onRGB frames to learn a dual representation
which is used to generate the video from a novel viewpoint. The dual
representation encompasses a view-dependent and a global representation which
incorporates complementary details to enable novel view video prediction. We
demonstrate the effectiveness of our framework on two real world datasets:
NTU-RGB+D and CMU Panoptic. A comparison with the State-of-the-art novel view
video prediction methods shows an improvement of 26.1% in SSIM, 13.6% in PSNR,
and 60% inFVD scores without using explicit priors from target views.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Volumetric Image Segmentation with Deformed Templates. (arXiv:2106.03987v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1">Udaranga Wickramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1">Pascal Fua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03987">
                                    <div class="article-summary-box-inner">
                                        <span>There are many approaches that use weak-supervision to train networks to
segment 2D images. By contrast, existing 3D approaches rely on full-supervision
of a subset of 2D slices of the 3D image volume. In this paper, we propose an
approach that is truly weakly-supervised in the sense that we only need to
provide a sparse set of 3D point on the surface of target objects, an easy task
that can be quickly done. We use the 3D points to deform a 3D template so that
it roughly matches the target object outlines and we introduce an architecture
that exploits the supervision provided by coarse template to train a network to
find accurate boundaries.

We evaluate the performance of our approach on Computed Tomography (CT),
Magnetic Resonance Imagery (MRI) and Electron Microscopy (EM) image datasets.
We will show that it outperforms a more traditional approach to
weak-supervision in 3D at a reduced supervision cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational AutoEncoder for Reference based Image Super-Resolution. (arXiv:2106.04090v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhi-Song Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Siu_W/0/1/0/all/0/1">Wan-Chi Siu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Li-Wen Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04090">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel reference based image super-resolution
approach via Variational AutoEncoder (RefVAE). Existing state-of-the-art
methods mainly focus on single image super-resolution which cannot perform well
on large upsampling factors, e.g., 8$\times$. We propose a reference based
image super-resolution, for which any arbitrary image can act as a reference
for super-resolution. Even using random map or low-resolution image itself, the
proposed RefVAE can transfer the knowledge from the reference to the
super-resolved images. Depending upon different references, the proposed method
can generate different versions of super-resolved images from a hidden
super-resolution space. Besides using different datasets for some standard
evaluations with PSNR and SSIM, we also took part in the NTIRE2021 SR Space
challenge and have provided results of the randomness evaluation of our
approach. Compared to other state-of-the-art methods, our approach achieves
higher diverse scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpaceMeshLab: Spatial Context Memoization and Meshgrid Atrous Convolution Consensus for Semantic Segmentation. (arXiv:2106.04025v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taehun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jinseong Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Daijin Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04025">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation networks adopt transfer learning from image
classification networks which occurs a shortage of spatial context information.
For this reason, we propose Spatial Context Memoization (SpaM), a bypassing
branch for spatial context by retaining the input dimension and constantly
communicating its spatial context and rich semantic information mutually with
the backbone network. Multi-scale context information for semantic segmentation
is crucial for dealing with diverse sizes and shapes of target objects in the
given scene. Conventional multi-scale context scheme adopts multiple effective
receptive fields by multiple dilation rates or pooling operations, but often
suffer from misalignment problem with respect to the target pixel. To this end,
we propose Meshgrid Atrous Convolution Consensus (MetroCon^2) which brings
multi-scale scheme into fine-grained multi-scale object context using
convolutions with meshgrid-like scattered dilation rates. SpaceMeshLab
(ResNet-101 + SpaM + MetroCon^2) achieves 82.0% mIoU in Cityscapes test and
53.5% mIoU on Pascal-Context validation set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-MLP: Node Classification without Message Passing in Graph. (arXiv:2106.04051v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1">Haoxuan You</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhecan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Erjin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04051">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Network (GNN) has been demonstrated its effectiveness in dealing
with non-Euclidean structural data. Both spatial-based and spectral-based GNNs
are relying on adjacency matrix to guide message passing among neighbors during
feature aggregation. Recent works have mainly focused on powerful message
passing modules, however, in this paper, we show that none of the message
passing modules is necessary. Instead, we propose a pure
multilayer-perceptron-based framework, Graph-MLP with the supervision signal
leveraging graph structure, which is sufficient for learning discriminative
node representation. In model-level, Graph-MLP only includes multi-layer
perceptrons, activation function, and layer normalization. In the loss level,
we design a neighboring contrastive (NContrast) loss to bridge the gap between
GNNs and MLPs by utilizing the adjacency information implicitly. This design
allows our model to be lighter and more robust when facing large-scale graph
data and corrupted adjacency information. Extensive experiments prove that even
without adjacency information in testing phase, our framework can still reach
comparable and even superior performance against the state-of-the-art models in
the graph node classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diverse Part Discovery: Occluded Person Re-identification with Part-Aware Transformer. (arXiv:2106.04095v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yulin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1">Jianfeng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianzhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04095">
                                    <div class="article-summary-box-inner">
                                        <span>Occluded person re-identification (Re-ID) is a challenging task as persons
are frequently occluded by various obstacles or other persons, especially in
the crowd scenario. To address these issues, we propose a novel end-to-end
Part-Aware Transformer (PAT) for occluded person Re-ID through diverse part
discovery via a transformer encoderdecoder architecture, including a pixel
context based transformer encoder and a part prototype based transformer
decoder. The proposed PAT model enjoys several merits. First, to the best of
our knowledge, this is the first work to exploit the transformer
encoder-decoder architecture for occluded person Re-ID in a unified deep model.
Second, to learn part prototypes well with only identity labels, we design two
effective mechanisms including part diversity and part discriminability.
Consequently, we can achieve diverse part discovery for occluded person Re-ID
in a weakly supervised manner. Extensive experimental results on six
challenging benchmarks for three tasks (occluded, partial and holistic Re-ID)
demonstrate that our proposed PAT performs favorably against stat-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Salvage of Supervision in Weakly Supervised Detection. (arXiv:2106.04073v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sui_L/0/1/0/all/0/1">Lin Sui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chen-Lin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jianxin Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04073">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly supervised object detection (WSOD) has recently attracted much
attention. However, the method, performance and speed gaps between WSOD and
fully supervised detection prevent WSOD from being applied in real-world tasks.
To bridge the gaps, this paper proposes a new framework, Salvage of Supervision
(SoS), with the key idea being to harness every potentially useful supervisory
signal in WSOD: the weak image-level labels, the pseudo-labels, and the power
of semi-supervised object detection. This paper shows that each type of
supervisory signal brings in notable improvements, outperforms existing WSOD
methods (which mainly use only the weak labels) by large margins. The proposed
SoS-WSOD method achieves 64.4 $m\text{AP}_{50}$ on VOC2007, 61.9
$m\text{AP}_{50}$ on VOC2012 and 16.4 $m\text{AP}_{50:95}$ on MS-COCO, and also
has fast inference speed. Ablations and visualization further verify the
effectiveness of SoS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Structure-from-Motion through Tightly-Coupled Depth and Egomotion Networks. (arXiv:2106.04007v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wagstaff_B/0/1/0/all/0/1">Brandon Wagstaff</a>, <a href="http://arxiv.org/find/cs/1/au:+Peretroukhin_V/0/1/0/all/0/1">Valentin Peretroukhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1">Jonathan Kelly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04007">
                                    <div class="article-summary-box-inner">
                                        <span>Much recent literature has formulated structure-from-motion (SfM) as a
self-supervised learning problem where the goal is to jointly learn neural
network models of depth and egomotion through view synthesis. Herein, we
address the open problem of how to optimally couple the depth and egomotion
network components. Toward this end, we introduce several notions of coupling,
categorize existing approaches, and present a novel tightly-coupled approach
that leverages the interdependence of depth and egomotion at training and at
inference time. Our approach uses iterative view synthesis to recursively
update the egomotion network input, permitting contextual information to be
passed between the components without explicit weight sharing. Through
substantial experiments, we demonstrate that our approach promotes consistency
between the depth and egomotion predictions at test time, improves
generalization on new data, and leads to state-of-the-art accuracy on indoor
and outdoor depth and egomotion evaluation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subject-Independent Brain-Computer Interface for Decoding High-Level Visual Imagery Tasks. (arXiv:2106.04026v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dae-Hyeok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dong-Kyun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sung-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1">Ji-Hoon Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04026">
                                    <div class="article-summary-box-inner">
                                        <span>Brain-computer interface (BCI) is used for communication between humans and
devices by recognizing status and intention of humans. Communication between
humans and a drone using electroencephalogram (EEG) signals is one of the most
challenging issues in the BCI domain. In particular, the control of drone
swarms (the direction and formation) has more advantages compared to the
control of a drone. The visual imagery (VI) paradigm is that subjects visually
imagine specific objects or scenes. Reduction of the variability among EEG
signals of subjects is essential for practical BCI-based systems. In this
study, we proposed the subepoch-wise feature encoder (SEFE) to improve the
performances in the subject-independent tasks by using the VI dataset. This
study is the first attempt to demonstrate the possibility of generalization
among subjects in the VI-based BCI. We used the leave-one-subject-out
cross-validation for evaluating the performances. We obtained higher
performances when including our proposed module than excluding our proposed
module. The DeepConvNet with SEFE showed the highest performance of 0.72 among
six different decoding models. Hence, we demonstrated the feasibility of
decoding the VI dataset in the subject-independent task with robust
performances by using our proposed module.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Design a Three-Stage Architecture for Audio-Visual Active Speaker Detection in the Wild. (arXiv:2106.03932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kopuklu_O/0/1/0/all/0/1">Okan K&#xf6;p&#xfc;kl&#xfc;</a>, <a href="http://arxiv.org/find/cs/1/au:+Taseska_M/0/1/0/all/0/1">Maja Taseska</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1">Gerhard Rigoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03932">
                                    <div class="article-summary-box-inner">
                                        <span>Successful active speaker detection requires a three-stage pipeline: (i)
audio-visual encoding for all speakers in the clip, (ii) inter-speaker relation
modeling between a reference speaker and the background speakers within each
frame, and (iii) temporal modeling for the reference speaker. Each stage of
this pipeline plays an important role for the final performance of the created
architecture. Based on a series of controlled experiments, this work presents
several practical guidelines for audio-visual active speaker detection.
Correspondingly, we present a new architecture called ASDNet, which achieves a
new state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5%
outperforming the second best with a large margin of 4.7%. Our code and
pretrained models are publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FEAR: A Simple Lightweight Method to Rank Architectures. (arXiv:2106.04010v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1">Debadeepta Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1">Shital Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1">Sebastien Bubeck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04010">
                                    <div class="article-summary-box-inner">
                                        <span>The fundamental problem in Neural Architecture Search (NAS) is to efficiently
find high-performing architectures from a given search space. We propose a
simple but powerful method which we call FEAR, for ranking architectures in any
search space. FEAR leverages the viewpoint that neural networks are powerful
non-linear feature extractors. First, we train different architectures in the
search space to the same training or validation error. Then, we compare the
usefulness of the features extracted by each architecture. We do so with a
quick training keeping most of the architecture frozen. This gives fast
estimates of the relative performance. We validate FEAR on Natsbench topology
search space on three different datasets against competing baselines and show
strong ranking correlation especially compared to recently proposed zero-cost
methods. FEAR particularly excels at ranking high-performance architectures in
the search space. When used in the inner loop of discrete search algorithms
like random search, FEAR can cut down the search time by approximately 2.4X
without losing accuracy. We additionally empirically study very recently
proposed zero-cost measures for ranking and find that they breakdown in ranking
performance as training proceeds and also that data-agnostic ranking scores
which ignore the dataset do not generalize across dissimilar datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantically Controllable Scene Generation with Guidance of Explicit Knowledge. (arXiv:2106.04066v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenhao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eun_K/0/1/0/all/0/1">Kim Ji Eun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04066">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Generative Models (DGMs) are known for their superior capability in
generating realistic data. Extending purely data-driven approaches, recent
specialized DGMs may satisfy additional controllable requirements such as
embedding a traffic sign in a driving scene, by manipulating patterns
\textit{implicitly} in the neuron or feature level. In this paper, we introduce
a novel method to incorporate domain knowledge \textit{explicitly} in the
generation process to achieve semantically controllable scene generation. We
categorize our knowledge into two types to be consistent with the composition
of natural scenes, where the first type represents the property of objects and
the second type represents the relationship among objects. We then propose a
tree-structured generative model to learn complex scene representation, whose
nodes and edges are naturally corresponding to the two types of knowledge
respectively. Knowledge can be explicitly integrated to enable semantically
controllable scene generation by imposing semantic rules on properties of nodes
and edges in the tree structure. We construct a synthetic example to illustrate
the controllability and explainability of our method in a clean setting. We
further extend the synthetic example to realistic autonomous vehicle driving
environments and conduct extensive experiments to show that our method
efficiently identifies adversarial traffic scenes against different
state-of-the-art 3D point cloud segmentation models satisfying the traffic
rules specified as the explicit knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Topology Divergence: a Framework for Comparing Data Manifolds. (arXiv:2106.04024v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1">Serguei Barannikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1">Ilya Trofimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotnikov_G/0/1/0/all/0/1">Grigorii Sotnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Trimbach_E/0/1/0/all/0/1">Ekaterina Trimbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1">Alexander Korotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Filippov_A/0/1/0/all/0/1">Alexander Filippov</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04024">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a framework for comparing data manifolds, aimed, in particular,
towards the evaluation of deep generative models. We describe a novel tool,
Cross-Barcode(P,Q), that, given a pair of distributions in a high-dimensional
space, tracks multiscale topology spacial discrepancies between manifolds on
which the distributions are concentrated. Based on the Cross-Barcode, we
introduce the Manifold Topology Divergence score (MTop-Divergence) and apply it
to assess the performance of deep generative models in various domains: images,
3D-shapes, time-series, and on different datasets: MNIST, Fashion MNIST, SVHN,
CIFAR10, FFHQ, chest X-ray images, market stock data, ShapeNet. We demonstrate
that the MTop-Divergence accurately detects various degrees of mode-dropping,
intra-mode collapse, mode invention, and image disturbance. Our algorithm
scales well (essentially linearly) with the increase of the dimension of the
ambient high-dimensional space. It is one of the first TDA-based practical
methodologies that can be applied universally to datasets of different sizes
and dimensions, including the ones on which the most recent GANs in the visual
domain are trained. The proposed method is domain agnostic and does not rely on
pre-trained networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Multi-scale Fusion Network for RGB-D Salient Object Detection. (arXiv:2106.03941v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1">Guangyu Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yanchu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1">Tianhong Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Stathaki_T/0/1/0/all/0/1">Tania Stathaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03941">
                                    <div class="article-summary-box-inner">
                                        <span>Salient object detection(SOD) aims at locating the most significant object
within a given image. In recent years, great progress has been made in applying
SOD on many vision tasks. The depth map could provide additional spatial prior
and boundary cues to boost the performance. Combining the depth information
with image data obtained from standard visual cameras has been widely used in
recent SOD works, however, introducing depth information in a suboptimal fusion
strategy may have negative influence in the performance of SOD. In this paper,
we discuss about the advantages of the so-called progressive multi-scale fusion
method and propose a mask-guided feature aggregation module(MGFA). The proposed
framework can effectively combine the two features of different modalities and,
furthermore, alleviate the impact of erroneous depth features, which are
inevitably caused by the variation of depth quality. We further introduce a
mask-guided refinement module(MGRM) to complement the high-level semantic
features and reduce the irrelevant features from multi-scale fusion, leading to
an overall refinement of detection. Experiments on five challenging benchmarks
demonstrate that the proposed method outperforms 11 state-of-the-art methods
under different evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Flows with Invertible Attentions. (arXiv:2106.03959v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1">Rhea Sanjay Sukthanker</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiwu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Suryansh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03959">
                                    <div class="article-summary-box-inner">
                                        <span>Flow-based generative models have shown excellent ability to explicitly learn
the probability density function of data via a sequence of invertible
transformations. Yet, modeling long-range dependencies over normalizing flows
remains understudied. To fill the gap, in this paper, we introduce two types of
invertible attention mechanisms for generative flow models. To be precise, we
propose map-based and scaled dot-product attention for unconditional and
conditional generative flow models. The key idea is to exploit split-based
attention mechanisms to learn the attention weights and input representations
on every two splits of flow feature maps. Our method provides invertible
attention modules with tractable Jacobian determinants, enabling seamless
integration of it at any positions of the flow-based models. The proposed
attention mechanism can model the global data dependencies, leading to more
comprehensive flow models. Evaluation on multiple generation tasks demonstrates
that the introduced attention flow idea results in efficient flow models and
compares favorably against the state-of-the-art unconditional and conditional
generative flow methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-task Transformation Learning for Robust Out-of-Distribution Detection. (arXiv:2106.03899v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohseni_S/0/1/0/all/0/1">Sina Mohseni</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahdat_A/0/1/0/all/0/1">Arash Vahdat</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadawa_J/0/1/0/all/0/1">Jay Yadawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03899">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting out-of-distribution (OOD) samples plays a key role in open-world
and safety-critical applications such as autonomous systems and healthcare.
Self-supervised representation learning techniques (e.g., contrastive learning
and pretext learning) are well suited for learning representation that can
identify OOD samples. In this paper, we propose a simple framework that
leverages multi-task transformation learning for training effective
representation for OOD detection which outperforms state-of-the-art OOD
detection performance and robustness on several image datasets. We empirically
observe that the OOD performance depends on the choice of data transformations
which itself depends on the in-domain training set. To address this problem, we
propose a simple mechanism for selecting the transformations automatically and
modulate their effect on representation learning without requiring any OOD
training samples. We characterize the criteria for a desirable OOD detector for
real-world applications and demonstrate the efficacy of our proposed technique
against a diverse range of the state-of-the-art OOD detection techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Graph enhanced Embedding Neural Network for CTR Prediction. (arXiv:2106.00314v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Wei Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_R/0/1/0/all/0/1">Rong Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_R/0/1/0/all/0/1">Renhao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Huifeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yingxue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhirong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Ruiming Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiuqiang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00314">
                                    <div class="article-summary-box-inner">
                                        <span>CTR prediction, which aims to estimate the probability that a user will click
an item, plays a crucial role in online advertising and recommender system.
Feature interaction modeling based and user interest mining based methods are
the two kinds of most popular techniques that have been extensively explored
for many years and have made great progress for CTR prediction. However, (1)
feature interaction based methods which rely heavily on the co-occurrence of
different features, may suffer from the feature sparsity problem (i.e., many
features appear few times); (2) user interest mining based methods which need
rich user behaviors to obtain user&#x27;s diverse interests, are easy to encounter
the behavior sparsity problem (i.e., many users have very short behavior
sequences). To solve these problems, we propose a novel module named Dual Graph
enhanced Embedding, which is compatible with various CTR prediction models to
alleviate these two problems. We further propose a Dual Graph enhanced
Embedding Neural Network (DG-ENN) for CTR prediction. Dual Graph enhanced
Embedding exploits the strengths of graph representation with two carefully
designed learning strategies (divide-and-conquer, curriculum-learning-inspired
organized learning) to refine the embedding. We conduct comprehensive
experiments on three real-world industrial datasets. The experimental results
show that our proposed DG-ENN significantly outperforms state-of-the-art CTR
prediction models. Moreover, when applying to state-of-the-art CTR prediction
models, Dual graph enhanced embedding always obtains better performance.
Further case studies prove that our proposed dual graph enhanced embedding
could alleviate the feature sparsity and behavior sparsity problems. Our
framework will be open-source based on MindSpore in the near future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness Through Regularization for Learning to Rank. (arXiv:2102.05996v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1">Nikola Konstantinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1">Christoph H. Lampert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05996">
                                    <div class="article-summary-box-inner">
                                        <span>Given the abundance of applications of ranking in recent years, addressing
fairness concerns around automated ranking systems becomes necessary for
increasing the trust among end-users. Previous work on fair ranking has mostly
focused on application-specific fairness notions, often tailored to online
advertising, and it rarely considers learning as part of the process. In this
work, we show how to transfer numerous fairness notions from binary
classification to a learning to rank setting. Our formalism allows us to design
methods for incorporating fairness objectives with provable generalization
guarantees. An extensive experimental evaluation shows that our method can
improve ranking fairness substantially with no or only little loss of model
quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Liyi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Junqi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhenzhe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiye Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhizhuang Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Fei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1">Lvyin Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Chuan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuning Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoqiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14188">
                                    <div class="article-summary-box-inner">
                                        <span>Advertising expenditures have become the major source of revenue for
e-commerce platforms. Providing good advertising experiences for advertisers
through reducing their costs of trial and error for discovering the optimal
advertising strategies is crucial for the long-term prosperity of online
advertising. To achieve this goal, the advertising platform needs to identify
the advertisers&#x27; marketing objectives, and then recommend the corresponding
strategies to fulfill this objective. In this work, we first deploy a prototype
of strategy recommender system on Taobao display advertising platform,
recommending bid prices and targeted users to advertisers. We further augment
this prototype system by directly revealing the advertising performance, and
then infer the advertisers&#x27; marketing objectives through their adoptions of
different recommending advertising performance. We use the techniques from
context bandit to jointly learn the advertisers&#x27; marketing objectives and the
recommending strategies. Online evaluations show that the designed advertising
strategy recommender system can optimize the advertisers&#x27; advertising
performance and increase the platform&#x27;s revenue. Simulation experiments based
on Taobao online bidding data show that the designed contextual bandit
algorithm can effectively optimize the strategy adoption rate of advertisers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic selection of clustering algorithms using supervised graph embedding. (arXiv:2011.08225v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_Shapira_N/0/1/0/all/0/1">Noy Cohen-Shapira</a>, <a href="http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1">Lior Rokach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08225">
                                    <div class="article-summary-box-inner">
                                        <span>The widespread adoption of machine learning (ML) techniques and the extensive
expertise required to apply them have led to increased interest in automated ML
solutions that reduce the need for human intervention. One of the main
challenges in applying ML to previously unseen problems is algorithm selection
- the identification of high-performing algorithm(s) for a given dataset, task,
and evaluation measure. This study addresses the algorithm selection challenge
for data clustering, a fundamental task in data mining that is aimed at
grouping similar objects. We present MARCO-GE, a novel meta-learning approach
for the automated recommendation of clustering algorithms. MARCO-GE first
transforms datasets into graphs and then utilizes a graph convolutional neural
network technique to extract their latent representation. Using the embedding
representations obtained, MARCO-GE trains a ranking meta-model capable of
accurately recommending top-performing algorithms for a new dataset and
clustering evaluation measure. Extensive evaluation on 210 datasets, 13
clustering algorithms, and 10 clustering measures demonstrates the
effectiveness of our approach and its superiority in terms of predictive and
generalization performance over state-of-the-art clustering meta-learning
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NaturalProofs: Mathematical Theorem Proving in Natural Language. (arXiv:2104.01112v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1">Sean Welleck</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiacheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1">Ronan Le Bras</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01112">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding and creating mathematics using natural mathematical language -
the mixture of symbolic and natural language used by humans - is a challenging
and important problem for driving progress in machine learning. As a step in
this direction, we develop NaturalProofs, a multi-domain corpus of mathematical
statements and their proofs, written in natural mathematical language.
NaturalProofs unifies broad coverage, deep coverage, and low-resource
mathematical sources, allowing for evaluating both in-distribution and
zero-shot generalization. Using NaturalProofs, we benchmark strong neural
methods on mathematical reference retrieval and generation tasks which test a
system&#x27;s ability to determine key results that appear in a proof. Large-scale
sequence models show promise compared to classical information retrieval
methods, yet their performance and out-of-domain generalization leave
substantial room for improvement. NaturalProofs opens many avenues for research
on challenging mathematical tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Session-Aware Query Auto-completion using Extreme Multi-label Ranking. (arXiv:2012.07654v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1">Nishant Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_R/0/1/0/all/0/1">Rajat Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1">Daniel N. Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1">Arya Mazumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1">Inderjit S. Dhillon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07654">
                                    <div class="article-summary-box-inner">
                                        <span>Query auto-completion (QAC) is a fundamental feature in search engines where
the task is to suggest plausible completions of a prefix typed in the search
bar. Previous queries in the user session can provide useful context for the
user&#x27;s intent and can be leveraged to suggest auto-completions that are more
relevant while adhering to the user&#x27;s prefix. Such session-aware QACs can be
generated by recent sequence-to-sequence deep learning models; however, these
generative approaches often do not meet the stringent latency requirements of
responding to each user keystroke. Moreover, these generative approaches pose
the risk of showing nonsensical queries.

In this paper, we provide a solution to this problem: we take the novel
approach of modeling session-aware QAC as an eXtreme Multi-Label Ranking (XMR)
problem where the input is the previous query in the session and the user&#x27;s
current prefix, while the output space is the set of tens of millions of
queries entered by users in the recent past. We adapt a popular XMR algorithm
for this purpose by proposing several modifications to the key steps in the
algorithm. The proposed modifications yield a 10x improvement in terms of Mean
Reciprocal Rank (MRR) over the baseline XMR approach on a public search logs
dataset. We are able to maintain an inference latency of less than 10 ms while
still using session context. When compared against baseline models of
acceptable latency, we observed a 33% improvement in MRR for short prefixes of
up to 3 characters. Moreover, our model yielded a statistically significant
improvement of 2.81% over a production QAC system in terms of suggestion
acceptance rate, when deployed on the search bar of an online shopping store as
part of an A/B test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Document Collection Visual Question Answering. (arXiv:2104.14336v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tito_R/0/1/0/all/0/1">Rub&#xe8;n Tito</a>, <a href="http://arxiv.org/find/cs/1/au:+Karatzas_D/0/1/0/all/0/1">Dimosthenis Karatzas</a>, <a href="http://arxiv.org/find/cs/1/au:+Valveny_E/0/1/0/all/0/1">Ernest Valveny</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14336">
                                    <div class="article-summary-box-inner">
                                        <span>Current tasks and methods in Document Understanding aims to process documents
as single elements. However, documents are usually organized in collections
(historical records, purchase invoices), that provide context useful for their
interpretation. To address this problem, we introduce Document Collection
Visual Question Answering (DocCVQA) a new dataset and related task, where
questions are posed over a whole collection of document images and the goal is
not only to provide the answer to the given question, but also to retrieve the
set of documents that contain the information needed to infer the answer. Along
with the dataset we propose a new evaluation metric and baselines which provide
further insights to the new dataset and task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Large-Scale Analysis of Mixed Initiative in Information-Seeking Dialogues for Conversational Search. (arXiv:2104.07096v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1">Svitlana Vakulenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1">Evangelos Kanoulas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07096">
                                    <div class="article-summary-box-inner">
                                        <span>Conversational search is a relatively young area of research that aims at
automating an information-seeking dialogue. In this paper we help to position
it with respect to other research areas within conversational Artificial
Intelligence (AI) by analysing the structural properties of an
information-seeking dialogue. To this end, we perform a large-scale dialogue
analysis of more than 150K transcripts from 16 publicly available dialogue
datasets. These datasets were collected to inform different dialogue-based
tasks including conversational search. We extract different patterns of mixed
initiative from these dialogue transcripts and use them to compare dialogues of
different types. Moreover, we contrast the patterns found in
information-seeking dialogues that are being used for research purposes with
the patterns found in virtual reference interviews that were conducted by
professional librarians. The insights we provide (1) establish close relations
between conversational search and other conversational AI tasks; and (2)
uncover limitations of existing conversational datasets to inform future data
collection tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing Fairness in Classification with a Model-Agnostic Multi-Objective Algorithm. (arXiv:2009.04441v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Padh_K/0/1/0/all/0/1">Kirtan Padh</a>, <a href="http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1">Diego Antognini</a>, <a href="http://arxiv.org/find/cs/1/au:+Glaude_E/0/1/0/all/0/1">Emma Lejal Glaude</a>, <a href="http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1">Boi Faltings</a>, <a href="http://arxiv.org/find/cs/1/au:+Musat_C/0/1/0/all/0/1">Claudiu Musat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04441">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of fairness in classification is to learn a classifier that does not
discriminate against groups of individuals based on sensitive attributes, such
as race and gender. One approach to designing fair algorithms is to use
relaxations of fairness notions as regularization terms or in a constrained
optimization problem. We observe that the hyperbolic tangent function can
approximate the indicator function. We leverage this property to define a
differentiable relaxation that approximates fairness notions provably better
than existing relaxations. In addition, we propose a model-agnostic
multi-objective architecture that can simultaneously optimize for multiple
fairness notions and multiple sensitive attributes and supports all statistical
parity-based notions of fairness. We use our relaxation with the
multi-objective architecture to learn fair classifiers. Experiments on public
datasets show that our method suffers a significantly lower loss of accuracy
than current debiasing algorithms relative to the unconstrained model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surveillance of COVID-19 Pandemic using Social Media: A Reddit Study in North Carolina. (arXiv:2106.04515v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whitfield_C/0/1/0/all/0/1">Christopher Whitfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_M/0/1/0/all/0/1">Mohad Anwar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04515">
                                    <div class="article-summary-box-inner">
                                        <span>Coronavirus disease (COVID-19) pandemic has changed various aspects of
people&#x27;s lives and behaviors. At this stage, there are no other ways to control
the natural progression of the disease than adopting mitigation strategies such
as wearing masks, watching distance, and washing hands. Moreover, at this time
of social distancing, social media plays a key role in connecting people and
providing a platform for expressing their feelings. In this study, we tap into
social media to surveil the uptake of mitigation and detection strategies, and
capture issues and concerns about the pandemic. In particular, we explore the
research question, &quot;how much can be learned regarding the public uptake of
mitigation strategies and concerns about COVID-19 pandemic by using natural
language processing on Reddit posts?&quot; After extracting COVID-related posts from
the four largest subreddit communities of North Carolina over six months, we
performed NLP-based preprocessing to clean the noisy data. We employed a custom
Named-entity Recognition (NER) system and a Latent Dirichlet Allocation (LDA)
method for topic modeling on a Reddit corpus. We observed that &#x27;mask&#x27;, &#x27;flu&#x27;,
and &#x27;testing&#x27; are the most prevalent named-entities for &quot;Personal Protective
Equipment&quot;, &quot;symptoms&quot;, and &quot;testing&quot; categories, respectively. We also
observed that the most discussed topics are related to testing, masks, and
employment. The mitigation measures are the most prevalent theme of discussion
across all subreddits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A highly scalable repository of waveform and vital signs data from bedside monitoring devices. (arXiv:2106.03965v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malunjkar_S/0/1/0/all/0/1">Sanjay Malunjkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_S/0/1/0/all/0/1">Susan Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1">Somalee Datta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03965">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of cost effective cloud computing over the past decade and
ever-growing accumulation of high-fidelity clinical data in a modern hospital
setting is leading to new opportunities for translational medicine. Machine
learning is driving the appetite of the research community for various types of
signal data such as patient vitals. Health care systems, however, are ill
suited for massive processing of large volumes of data. In addition, due to the
sheer magnitude of the data being collected, it is not feasible to retain all
of the data in health care systems in perpetuity. This gold mine of information
gets purged periodically thereby losing invaluable future research
opportunities. We have developed a highly scalable solution that: a) siphons
off patient vital data on a nightly basis from on-premises bio-medical systems
to a cloud storage location as a permanent archive, b) reconstructs the
database in the cloud, c) generates waveforms, alarms and numeric data in a
research-ready format, and d) uploads the processed data to a storage location
in the cloud ready for research.

The data is de-identified and catalogued such that it can be joined with
Electronic Medical Records (EMR) and other ancillary data types such as
electroencephalogram (EEG), radiology, video monitoring etc. This technique
eliminates the research burden from health care systems. This highly scalable
solution is used to process high density patient monitoring data aggregated by
the Philips Patient Information Center iX (PIC iX) hospital surveillance system
for archival storage in the Philips Data Warehouse Connect enterprise-level
database. The solution is part of a broader platform that supports a secure
high performance clinical data science platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Periodicity and Interactivity in Multi-Interest Framework for Sequential Recommendation. (arXiv:2106.04415v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gaode Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinghua Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yanyan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1">Cong Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1">Ji Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04415">
                                    <div class="article-summary-box-inner">
                                        <span>Sequential recommendation systems alleviate the problem of information
overload, and have attracted increasing attention in the literature. Most prior
works usually obtain an overall representation based on the user&#x27;s behavior
sequence, which can not sufficiently reflect the multiple interests of the
user. To this end, we propose a novel method called PIMI to mitigate this
issue. PIMI can model the user&#x27;s multi-interest representation effectively by
considering both the periodicity and interactivity in the item sequence.
Specifically, we design a periodicity-aware module to utilize the time interval
information between user&#x27;s behaviors. Meanwhile, an ingenious graph is proposed
to enhance the interactivity between items in user&#x27;s behavior sequence, which
can capture both global and local item features. Finally, a multi-interest
extraction module is applied to describe user&#x27;s multiple interests based on the
obtained item representation. Extensive experiments on two real-world datasets
Amazon and Taobao show that PIMI outperforms state-of-the-art methods
consistently.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HieRec: Hierarchical User Interest Modeling for Personalized News Recommendation. (arXiv:2106.04408v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1">Tao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Peiru Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04408">
                                    <div class="article-summary-box-inner">
                                        <span>User interest modeling is critical for personalized news recommendation.
Existing news recommendation methods usually learn a single user embedding for
each user from their previous behaviors to represent their overall interest.
However, user interest is usually diverse and multi-grained, which is difficult
to be accurately modeled by a single user embedding. In this paper, we propose
a news recommendation method with hierarchical user interest modeling, named
HieRec. Instead of a single user embedding, in our method each user is
represented in a hierarchical interest tree to better capture their diverse and
multi-grained interest in news. We use a three-level hierarchy to represent 1)
overall user interest; 2) user interest in coarse-grained topics like sports;
and 3) user interest in fine-grained topics like football. Moreover, we propose
a hierarchical user interest matching framework to match candidate news with
different levels of user interest for more accurate user interest targeting.
Extensive experiments on two real-world datasets validate our method can
effectively improve the performance of user modeling for personalized news
recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversational Fashion Image Retrieval via Multiturn Natural Language Feedback. (arXiv:2106.04128v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yifei Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1">Wai Lam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04128">
                                    <div class="article-summary-box-inner">
                                        <span>We study the task of conversational fashion image retrieval via multiturn
natural language feedback. Most previous studies are based on single-turn
settings. Existing models on multiturn conversational fashion image retrieval
have limitations, such as employing traditional models, and leading to
ineffective performance. We propose a novel framework that can effectively
handle conversational fashion image retrieval with multiturn natural language
feedback texts. One characteristic of the framework is that it searches for
candidate images based on exploitation of the encoded reference image and
feedback text information together with the conversation history. Furthermore,
the image fashion attribute information is leveraged via a mutual attention
strategy. Since there is no existing fashion dataset suitable for the multiturn
setting of our task, we derive a large-scale multiturn fashion dataset via
additional manual annotation efforts on an existing single-turn dataset. The
experiments show that our proposed model significantly outperforms existing
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-Start Users. (arXiv:2005.12979v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shijun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1">Wenqiang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Peng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.12979">
                                    <div class="article-summary-box-inner">
                                        <span>Static recommendation methods like collaborative filtering suffer from the
inherent limitation of performing real-time personalization for cold-start
users. Online recommendation, e.g., multi-armed bandit approach, addresses this
limitation by interactively exploring user preference online and pursuing the
exploration-exploitation (EE) trade-off. However, existing bandit-based methods
model recommendation actions homogeneously. Specifically, they only consider
the items as the arms, being incapable of handling the item attributes, which
naturally provide interpretable information of user&#x27;s current demands and can
effectively filter out undesired items. In this work, we consider the
conversational recommendation for cold-start users, where a system can both ask
the attributes from and recommend items to a user interactively. This important
scenario was studied in a recent work. However, it employs a hand-crafted
function to decide when to ask attributes or make recommendations. Such
separate modeling of attributes and items makes the effectiveness of the system
highly rely on the choice of the hand-crafted function, thus introducing
fragility to the system. To address this limitation, we seamlessly unify
attributes and items in the same arm space and achieve their EE trade-offs
automatically using the framework of Thompson Sampling. Our Conversational
Thompson Sampling (ConTS) model holistically solves all questions in
conversational recommendation by choosing the arm with the maximal reward to
play. Extensive experiments on three benchmark datasets show that ConTS
outperforms the state-of-the-art methods Conversational UCB (ConUCB) and
Estimation-Action-Reflection model in both metrics of success rate and average
number of conversation turns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defining definition: a Text mining Approach to Define Innovative Technological Fields. (arXiv:2106.04210v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Giordano_V/0/1/0/all/0/1">Vito Giordano</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiarello_F/0/1/0/all/0/1">Filippo Chiarello</a>, <a href="http://arxiv.org/find/cs/1/au:+Cervelli_E/0/1/0/all/0/1">Elena Cervelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04210">
                                    <div class="article-summary-box-inner">
                                        <span>One of the first task of an innovative project is delineating the scope of
the project itself or of the product/service to be developed. A wrong scope
definition can determine (in the worst case) project failure. A good scope
definition become even more relevant in technological intensive innovation
projects, nowadays characterized by a highly dynamic multidisciplinary,
turbulent and uncertain environment. In these cases, the boundaries of the
project are not easily detectable and it is difficult to decide what it is
in-scope and out-of-scope. The present work proposes a tool for the scope
delineation process, that automatically define an innovative technological
field or a new technology. The tool is based on Text Mining algorithm that
exploits Elsevier&#x27;s Scopus abstracts in order to the extract relevant data to
define a technological scope. The automatic definition tool is then applied on
four case studies: Artificial Intelligence and Data Science. The results show
how the tool can provide many crucial information in the definition process of
a technological field. In particular for the target technological field (or
technology), it provides the definition and other elements related to the
target.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings. (arXiv:2106.04209v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brams_A/0/1/0/all/0/1">Anders H. Brams</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakobsen_A/0/1/0/all/0/1">Anders L. Jakobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jendal_T/0/1/0/all/0/1">Theis E. Jendal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lissandrini_M/0/1/0/all/0/1">Matteo Lissandrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolog_P/0/1/0/all/0/1">Peter Dolog</a>, <a href="http://arxiv.org/find/cs/1/au:+Hose_K/0/1/0/all/0/1">Katja Hose</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04209">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graphs (KGs) have been integrated in several models of
recommendation to augment the informational value of an item by means of its
related entities in the graph. Yet, existing datasets only provide explicit
ratings on items and no information is provided about user opinions of other
(non-recommendable) entities. To overcome this limitation, we introduce a new
dataset, called the MindReader, providing explicit user ratings both for items
and for KG entities. In this first version, the MindReader dataset provides
more than 102 thousands explicit ratings collected from 1,174 real users on
both items and entities from a KG in the movie domain. This dataset has been
collected through an online interview application that we also release open
source. As a demonstration of the importance of this new dataset, we present a
comparative study of the effect of the inclusion of ratings on non-item KG
entities in a variety of state-of-the-art recommendation models. In particular,
we show that most models, whether designed specifically for graph data or not,
see improvements in recommendation quality when trained on explicit non-item
ratings. Moreover, for some models, we show that non-item ratings can
effectively replace item ratings without loss of recommendation quality. This
finding, thanks also to an observed greater familiarity of users towards common
KG entities than towards long-tail items, motivates the use of KG entities for
both warm and cold-start recommendations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Neural Collaborative Filtering. (arXiv:2106.04405v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perifanis_V/0/1/0/all/0/1">Vasileios Perifanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Efraimidis_P/0/1/0/all/0/1">Pavlos S. Efraimidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04405">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present a federated version of the state-of-the-art Neural
Collaborative Filtering (NCF) approach for item recommendations. The system,
named FedNCF, allows learning without requiring users to expose or transmit
their raw data. Experimental validation shows that FedNCF achieves comparable
recommendation quality to the original NCF system. Although federated learning
(FL) enables learning without raw data transmission, recent attacks showed that
FL alone does not eliminate privacy concerns. To overcome this challenge, we
integrate a privacy-preserving enhancement with a secure aggregation scheme
that satisfies the security requirements against an honest-but-curious (HBC)
entity, without affecting the quality of the original model. Finally, we
discuss the peculiarities observed in the application of FL in a collaborative
filtering (CF) task as well as we evaluate the privacy-preserving mechanism in
terms of computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConSTR: A Contextual Search Term Recommender. (arXiv:2106.04376v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kramer_T/0/1/0/all/0/1">Thomas Kr&#xe4;mer</a>, <a href="http://arxiv.org/find/cs/1/au:+Carevic_Z/0/1/0/all/0/1">Zeljko Carevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1">Dwaipayan Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Klas_C/0/1/0/all/0/1">Claus-Peter Klas</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayr_P/0/1/0/all/0/1">Philipp Mayr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04376">
                                    <div class="article-summary-box-inner">
                                        <span>In this demo paper, we present ConSTR, a novel Contextual Search Term
Recommender that utilises the user&#x27;s interaction context for search term
recommendation and literature retrieval. ConSTR integrates a two-layered
recommendation interface: the first layer suggests terms with respect to a
user&#x27;s current search term, and the second layer suggests terms based on the
users&#x27; previous search activities (interaction context). For the demonstration,
ConSTR is built on the arXiv, an academic repository consisting of 1.8 million
documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Struggle with Academic Plagiarism: Approaches based on Semantic Similarity. (arXiv:2106.04404v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vrbanec_T/0/1/0/all/0/1">Tedo Vrbanec</a>, <a href="http://arxiv.org/find/cs/1/au:+Mestrovic_A/0/1/0/all/0/1">Ana Mestrovic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04404">
                                    <div class="article-summary-box-inner">
                                        <span>Academic plagiarism is a serious problem nowadays. Due to the existence of
inexhaustible sources of digital information, today it is easier to plagiarize
more than ever before. The good thing is that plagiarism detection techniques
have improved and are powerful enough to detect attempts of plagiarism in
education. We are now witnessing efficient plagiarism detection software in
action, such as Turnitin, iThenticate or SafeAssign. In the introduction we
explore software that is used within the Croatian academic community for
plagiarism detection in universities and/or in scientific journals. The
question is: is this enough? Current software has proven to be successful,
however the problem of identifying paraphrasing or obfuscation plagiarism
remains unresolved. In this paper we present a report of how semantic
similarity measures can be used in the plagiarism detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Geand Trindade Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1">Moises Rocha dos Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03954">
                                    <div class="article-summary-box-inner">
                                        <span>With the popularity of Machine Learning (ML) solutions, algorithms and data
have been released faster than the capacity of processing them. In this
context, the problem of Algorithm Recommendation (AR) is receiving a
significant deal of attention recently. This problem has been addressed in the
literature as a learning task, often as a Meta-Learning problem where the aim
is to recommend the best alternative for a specific dataset. For such, datasets
encoded by meta-features are explored by ML algorithms that try to learn the
mapping between meta-representations and the best technique to be used. One of
the challenges for the successful use of ML is to define which features are the
most valuable for a specific dataset since several meta-features can be used,
which increases the meta-feature dimension. This paper presents an empirical
analysis of Feature Selection and Feature Extraction in the meta-level for the
AR problem. The present study was focused on three criteria: predictive
performance, dimensionality reduction, and pipeline runtime. As we verified,
applying Dimensionality Reduction (DR) methods did not improve predictive
performances in general. However, DR solutions reduced about 80% of the
meta-features, obtaining pretty much the same performance as the original setup
but with lower runtimes. The only exception was PCA, which presented about the
same runtime as the original meta-features. Experimental results also showed
that various datasets have many non-informative meta-features and that it is
possible to obtain high predictive performance using around 20% of the original
meta-features. Therefore, due to their natural trend for high dimensionality,
DR methods should be used for Meta-Feature Selection and Meta-Feature
Extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimization of Service Addition in Multilevel Index Model for Edge Computing. (arXiv:2106.04494v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiayan Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anjum_A/0/1/0/all/0/1">Ashiq Anjum</a>, <a href="http://arxiv.org/find/cs/1/au:+Panneerselvam_J/0/1/0/all/0/1">John Panneerselvam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Bo Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04494">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of Edge Computing and Artificial Intelligence (AI)
technologies, edge devices are witnessed to generate data at unprecedented
volume. The Edge Intelligence (EI) has led to the emergence of edge devices in
various application domains. The EI can provide efficient services to
delay-sensitive applications, where the edge devices are deployed as edge nodes
to host the majority of execution, which can effectively manage services and
improve service discovery efficiency. The multilevel index model is a
well-known model used for indexing service, such a model is being introduced
and optimized in the edge environments to efficiently services discovery whilst
managing large volumes of data. However, effectively updating the multilevel
index model by adding new services timely and precisely in the dynamic Edge
Computing environments is still a challenge. Addressing this issue, this paper
proposes a designated key selection method to improve the efficiency of adding
services in the multilevel index models. Our experimental results show that in
the partial index and the full index of multilevel index model, our method
reduces the service addition time by around 84% and 76%, respectively when
compared with the original key selection method and by around 78% and 66%,
respectively when compared with the random selection method. Our proposed
method significantly improves the service addition efficiency in the multilevel
index model, when compared with existing state-of-the-art key selection
methods, without compromising the service retrieval stability to any notable
level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Review Polarity-wise Recommender. (arXiv:2106.04155v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Han Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yangyang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Jianhua Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Liqiang Nie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04155">
                                    <div class="article-summary-box-inner">
                                        <span>Utilizing review information to enhance recommendation, the de facto
review-involved recommender systems, have received increasing interests over
the past few years. Thereinto, one advanced branch is to extract salient
aspects from textual reviews (i.e., the item attributes that users express) and
combine them with the matrix factorization technique. However, existing
approaches all ignore the fact that semantically different reviews often
include opposite aspect information. In particular, positive reviews usually
express aspects that users prefer, while negative ones describe aspects that
users reject. As a result, it may mislead the recommender systems into making
incorrect decisions pertaining to user preference modeling. Towards this end,
in this paper, we propose a Review Polarity-wise Recommender model, dubbed as
RPR, to discriminately treat reviews with different polarities. To be specific,
in this model, positive and negative reviews are separately gathered and
utilized to model the user-preferred and user-rejected aspects, respectively.
Besides, in order to overcome the imbalance problem of semantically different
reviews, we also develop an aspect-aware importance weighting approach to align
the aspect importance for these two kinds of reviews. Extensive experiments
conducted on eight benchmark datasets have demonstrated the superiority of our
model as compared to a series of state-of-the-art review-involved baselines.
Moreover, our method can provide certain explanations to the real-world rating
prediction scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Theoretic Measures for Fairness-aware Feature Selection. (arXiv:2106.00772v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1">Sajad Khodadadian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nafea_M/0/1/0/all/0/1">Mohamed Nafea</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1">AmirEmad Ghassami</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1">Negar Kiyavash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00772">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning algorithms are increasingly used for consequential decision
making regarding individuals based on their relevant features. Features that
are relevant for accurate decisions may however lead to either explicit or
implicit forms of discrimination against unprivileged groups, such as those of
certain race or gender. This happens due to existing biases in the training
data, which are often replicated or even exacerbated by the learning algorithm.
Identifying and measuring these biases at the data level is a challenging
problem due to the interdependence among the features, and the decision
outcome. In this work, we develop a framework for fairness-aware feature
selection which takes into account the correlation among the features and the
decision outcome, and is based on information theoretic measures for the
accuracy and discriminatory impacts of features. In particular, we first
propose information theoretic measures which quantify the impact of different
subsets of features on the accuracy and discrimination of the decision
outcomes. We then deduce the marginal impact of each feature using Shapley
value function; a solution concept in cooperative game theory used to estimate
marginal contributions of players in a coalitional game. Finally, we design a
fairness utility score for each feature (for feature selection) which
quantifies how this feature influences accurate as well as nondiscriminatory
decisions. Our framework depends on the joint statistics of the data rather
than a particular classifier design. We examine our proposed framework on real
and synthetic data to evaluate its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Active Surface Models. (arXiv:2011.08826v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1">Udaranga Wickramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1">Graham Knott</a>, <a href="http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1">Pascal Fua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08826">
                                    <div class="article-summary-box-inner">
                                        <span>Active Surface Models have a long history of being useful to model complex 3D
surfaces but only Active Contours have been used in conjunction with deep
networks, and then only to produce the data term as well as meta-parameter maps
controlling them. In this paper, we advocate a much tighter integration. We
introduce layers that implement them that can be integrated seamlessly into
Graph Convolutional Networks to enforce sophisticated smoothness priors at an
acceptable computational cost. We will show that the resulting Deep Active
Surface Models outperform equivalent architectures that use traditional
regularization loss terms to impose smoothness priors for 3D surface
reconstruction from 2D images and for 3D volume segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalizable Approach to Learning Optimizers. (arXiv:2106.00958v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1">Diogo Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1">Clemens Winter</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1">Wojciech Zaremba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00958">
                                    <div class="article-summary-box-inner">
                                        <span>A core issue with learning to optimize neural networks has been the lack of
generalization to real world problems. To address this, we describe a system
designed from a generalization-first perspective, learning to update optimizer
hyperparameters instead of model parameters directly using novel features,
actions, and a reward function. This system outperforms Adam at all neural
network tasks including on modalities not seen during training. We achieve 2x
speedups on ImageNet, and a 2.5x speedup on a language modeling task using over
5 orders of magnitude more compute than the training tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NaturalProofs: Mathematical Theorem Proving in Natural Language. (arXiv:2104.01112v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1">Sean Welleck</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiacheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1">Ronan Le Bras</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01112">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding and creating mathematics using natural mathematical language -
the mixture of symbolic and natural language used by humans - is a challenging
and important problem for driving progress in machine learning. As a step in
this direction, we develop NaturalProofs, a multi-domain corpus of mathematical
statements and their proofs, written in natural mathematical language.
NaturalProofs unifies broad coverage, deep coverage, and low-resource
mathematical sources, allowing for evaluating both in-distribution and
zero-shot generalization. Using NaturalProofs, we benchmark strong neural
methods on mathematical reference retrieval and generation tasks which test a
system&#x27;s ability to determine key results that appear in a proof. Large-scale
sequence models show promise compared to classical information retrieval
methods, yet their performance and out-of-domain generalization leave
substantial room for improvement. NaturalProofs opens many avenues for research
on challenging mathematical tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAC Best Arm Identification Under a Deadline. (arXiv:2106.03221v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1">Brijen Thananjeyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1">Kirthevasan Kandasamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1">Ken Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03221">
                                    <div class="article-summary-box-inner">
                                        <span>We study $(\epsilon, \delta)$-PAC best arm identification, where a
decision-maker must identify an $\epsilon$-optimal arm with probability at
least $1 - \delta$, while minimizing the number of arm pulls (samples). Most of
the work on this topic is in the sequential setting, where there is no
constraint on the time taken to identify such an arm; this allows the
decision-maker to pull one arm at a time. In this work, the decision-maker is
given a deadline of $T$ rounds, where, on each round, it can adaptively choose
which arms to pull and how many times to pull them; this distinguishes the
number of decisions made (i.e., time or number of rounds) from the number of
samples acquired (cost). Such situations occur in clinical trials, where one
may need to identify a promising treatment under a deadline while minimizing
the number of test subjects, or in simulation-based studies run on the cloud,
where we can elastically scale up or down the number of virtual machines to
conduct as many experiments as we wish, but need to pay for the resource-time
used. As the decision-maker can only make $T$ decisions, she may need to pull
some arms excessively relative to a sequential algorithm in order to perform
well on all possible problems. We formalize this added difficulty with two
hardness results that indicate that unlike sequential settings, the ability to
adapt to the problem difficulty is constrained by the finite deadline. We
propose Elastic Batch Racing (EBR), a novel algorithm for this setting and
bound its sample complexity, showing that EBR is optimal with respect to both
hardness results. We present simulations evaluating EBR in this setting, where
it outperforms baselines by several orders of magnitude.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Whitening Batch Normalization. (arXiv:2106.04413v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shengdong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nezhadarya_E/0/1/0/all/0/1">Ehsan Nezhadarya</a>, <a href="http://arxiv.org/find/cs/1/au:+Fashandi_H/0/1/0/all/0/1">Homa Fashandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiayi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_D/0/1/0/all/0/1">Darin Graham</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mohak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04413">
                                    <div class="article-summary-box-inner">
                                        <span>Batch Normalization (BN) is a popular technique for training Deep Neural
Networks (DNNs). BN uses scaling and shifting to normalize activations of
mini-batches to accelerate convergence and improve generalization. The recently
proposed Iterative Normalization (IterNorm) method improves these properties by
whitening the activations iteratively using Newton&#x27;s method. However, since
Newton&#x27;s method initializes the whitening matrix independently at each training
step, no information is shared between consecutive steps. In this work, instead
of exact computation of whitening matrix at each time step, we estimate it
gradually during training in an online fashion, using our proposed Stochastic
Whitening Batch Normalization (SWBN) algorithm. We show that while SWBN
improves the convergence rate and generalization of DNNs, its computational
overhead is less than that of IterNorm. Due to the high efficiency of the
proposed method, it can be easily employed in most DNN architectures with a
large number of layers. We provide comprehensive experiments and comparisons
between BN, IterNorm, and SWBN layers to demonstrate the effectiveness of the
proposed technique in conventional (many-shot) image classification and
few-shot classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Meta-Feature Selection for the Algorithm Recommendation Problem. (arXiv:2106.03954v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Geand Trindade Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_M/0/1/0/all/0/1">Moises Rocha dos Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1">Andre Carlos Ponce de Leon Ferreira de Carvalho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03954">
                                    <div class="article-summary-box-inner">
                                        <span>With the popularity of Machine Learning (ML) solutions, algorithms and data
have been released faster than the capacity of processing them. In this
context, the problem of Algorithm Recommendation (AR) is receiving a
significant deal of attention recently. This problem has been addressed in the
literature as a learning task, often as a Meta-Learning problem where the aim
is to recommend the best alternative for a specific dataset. For such, datasets
encoded by meta-features are explored by ML algorithms that try to learn the
mapping between meta-representations and the best technique to be used. One of
the challenges for the successful use of ML is to define which features are the
most valuable for a specific dataset since several meta-features can be used,
which increases the meta-feature dimension. This paper presents an empirical
analysis of Feature Selection and Feature Extraction in the meta-level for the
AR problem. The present study was focused on three criteria: predictive
performance, dimensionality reduction, and pipeline runtime. As we verified,
applying Dimensionality Reduction (DR) methods did not improve predictive
performances in general. However, DR solutions reduced about 80% of the
meta-features, obtaining pretty much the same performance as the original setup
but with lower runtimes. The only exception was PCA, which presented about the
same runtime as the original meta-features. Experimental results also showed
that various datasets have many non-informative meta-features and that it is
possible to obtain high predictive performance using around 20% of the original
meta-features. Therefore, due to their natural trend for high dimensionality,
DR methods should be used for Meta-Feature Selection and Meta-Feature
Extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PolypGen: A multi-center polyp detection and segmentation dataset for generalisability assessment. (arXiv:2106.04463v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1">Sharib Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1">Debesh Jha</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghatwary_N/0/1/0/all/0/1">Noha Ghatwary</a>, <a href="http://arxiv.org/find/eess/1/au:+Realdon_S/0/1/0/all/0/1">Stefano Realdon</a>, <a href="http://arxiv.org/find/eess/1/au:+Cannizzaro_R/0/1/0/all/0/1">Renato Cannizzaro</a>, <a href="http://arxiv.org/find/eess/1/au:+Salem_O/0/1/0/all/0/1">Osama E. Salem</a>, <a href="http://arxiv.org/find/eess/1/au:+Lamarque_D/0/1/0/all/0/1">Dominique Lamarque</a>, <a href="http://arxiv.org/find/eess/1/au:+Daul_C/0/1/0/all/0/1">Christian Daul</a>, <a href="http://arxiv.org/find/eess/1/au:+Anonsen_K/0/1/0/all/0/1">Kim V. Anonsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Rittscher_J/0/1/0/all/0/1">Jens Rittscher</a>, <a href="http://arxiv.org/find/eess/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/eess/1/au:+East_J/0/1/0/all/0/1">James E. East</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04463">
                                    <div class="article-summary-box-inner">
                                        <span>Polyps in the colon are widely known as cancer precursors identified by
colonoscopy either related to diagnostic work-up for symptoms, colorectal
cancer screening or systematic surveillance of certain diseases. Whilst most
polyps are benign, the number, size and the surface structure of the polyp are
tightly linked to the risk of colon cancer. There exists a high missed
detection rate and incomplete removal of colon polyps due to the variable
nature, difficulties to delineate the abnormality, high recurrence rates and
the anatomical topography of the colon. In the past, several methods have been
built to automate polyp detection and segmentation. However, the key issue of
most methods is that they have not been tested rigorously on a large
multi-center purpose-built dataset. Thus, these methods may not generalise to
different population datasets as they overfit to a specific population and
endoscopic surveillance. To this extent, we have curated a dataset from 6
different centers incorporating more than 300 patients. The dataset includes
both single frame and sequence data with 3446 annotated polyp labels with
precise delineation of polyp boundaries verified by six senior
gastroenterologists. To our knowledge, this is the most comprehensive detection
and pixel-level segmentation dataset curated by a team of computational
scientists and expert gastroenterologists. This dataset has been originated as
the part of the Endocv2021 challenge aimed at addressing generalisability in
polyp detection and segmentation. In this paper, we provide comprehensive
insight into data construction and annotation strategies, annotation quality
assurance and technical validation for our extended EndoCV2021 dataset which we
refer to as PolypGen.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DisTop: Discovering a Topological representation to learn diverse and rewarding skills. (arXiv:2106.03853v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aubret_A/0/1/0/all/0/1">Arthur Aubret</a>, <a href="http://arxiv.org/find/cs/1/au:+matignon_L/0/1/0/all/0/1">Laetitia matignon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassas_S/0/1/0/all/0/1">Salima Hassas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03853">
                                    <div class="article-summary-box-inner">
                                        <span>The optimal way for a deep reinforcement learning (DRL) agent to explore is
to learn a set of skills that achieves a uniform distribution of states.
Following this,we introduce DisTop, a new model that simultaneously learns
diverse skills and focuses on improving rewarding skills. DisTop progressively
builds a discrete topology of the environment using an unsupervised contrastive
loss, a growing network and a goal-conditioned policy. Using this topology, a
state-independent hierarchical policy can select where the agent has to keep
discovering skills in the state space. In turn, the newly visited states allows
an improved learnt representation and the learning loop continues. Our
experiments emphasize that DisTop is agnostic to the ground state
representation and that the agent can discover the topology of its environment
whether the states are high-dimensional binary data, images, or proprioceptive
inputs. We demonstrate that this paradigm is competitiveon MuJoCo benchmarks
with state-of-the-art algorithms on both single-task dense rewards and diverse
skill discovery. By combining these two aspects, we showthat DisTop achieves
state-of-the-art performance in comparison with hierarchical reinforcement
learning (HRL) when rewards are sparse. We believe DisTop opens new
perspectives by showing that bottom-up skill discovery combined with
representation learning can unlock the exploration challenge in DRL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Practical Credit Assignment for Deep Reinforcement Learning. (arXiv:2106.04499v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alipov_V/0/1/0/all/0/1">Vyacheslav Alipov</a>, <a href="http://arxiv.org/find/cs/1/au:+Simmons_Edler_R/0/1/0/all/0/1">Riley Simmons-Edler</a>, <a href="http://arxiv.org/find/cs/1/au:+Putintsev_N/0/1/0/all/0/1">Nikita Putintsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalinin_P/0/1/0/all/0/1">Pavel Kalinin</a>, <a href="http://arxiv.org/find/cs/1/au:+Vetrov_D/0/1/0/all/0/1">Dmitry Vetrov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04499">
                                    <div class="article-summary-box-inner">
                                        <span>Credit assignment is a fundamental problem in reinforcement learning, the
problem of measuring an action&#x27;s influence on future rewards. Improvements in
credit assignment methods have the potential to boost the performance of RL
algorithms on many tasks, but thus far have not seen widespread adoption.
Recently, a family of methods called Hindsight Credit Assignment (HCA) was
proposed, which explicitly assign credit to actions in hindsight based on the
probability of the action having led to an observed outcome. This approach is
appealing as a means to more efficient data usage, but remains a largely
theoretical idea applicable to a limited set of tabular RL tasks, and it is
unclear how to extend HCA to Deep RL environments. In this work, we explore the
use of HCA-style credit in a deep RL context. We first describe the limitations
of existing HCA algorithms in deep RL, then propose several
theoretically-justified modifications to overcome them. Based on this
exploration, we present a new algorithm, Credit-Constrained Advantage
Actor-Critic (C2A2C), which ignores policy updates for actions which don&#x27;t
affect future outcomes based on credit in hindsight, while updating the policy
as normal for those that do. We find that C2A2C outperforms Advantage
Actor-Critic (A2C) on the Arcade Learning Environment (ALE) benchmark, showing
broad improvements over A2C and motivating further work on credit-constrained
update rules for deep RL methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Error Loss Networks. (arXiv:2106.03722v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Badong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yunfei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Pengju Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03722">
                                    <div class="article-summary-box-inner">
                                        <span>A novel model called error loss network (ELN) is proposed to build an error
loss function for supervised learning. The ELN is in structure similar to a
radial basis function (RBF) neural network, but its input is an error sample
and output is a loss corresponding to that error sample. That means the
nonlinear input-output mapper of ELN creates an error loss function. The
proposed ELN provides a unified model for a large class of error loss
functions, which includes some information theoretic learning (ITL) loss
functions as special cases. The activation function, weight parameters and
network size of the ELN can be predetermined or learned from the error samples.
On this basis, we propose a new machine learning paradigm where the learning
process is divided into two stages: first, learning a loss function using an
ELN; second, using the learned loss function to continue to perform the
learning. Experimental results are presented to demonstrate the desirable
performance of the new method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Are VQA Systems RAD? Measuring Robustness to Augmented Data with Focused Interventions. (arXiv:2106.04484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosenberg_D/0/1/0/all/0/1">Daniel Rosenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gat_I/0/1/0/all/0/1">Itai Gat</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04484">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms have shown promising results in visual question
answering (VQA) tasks, but a more careful look reveals that they often do not
understand the rich signal they are being fed with. To understand and better
measure the generalization capabilities of VQA systems, we look at their
robustness to counterfactually augmented data. Our proposed augmentations are
designed to make a focused intervention on a specific property of the question
such that the answer changes. Using these augmentations, we propose a new
robustness measure, Robustness to Augmented Data (RAD), which measures the
consistency of model predictions between original and augmented examples.
Through extensive experimentation, we show that RAD, unlike classical accuracy
measures, can quantify when state-of-the-art systems are not robust to
counterfactuals. We find substantial failure cases which reveal that current
VQA systems are still brittle. Finally, we connect between robustness and
generalization, demonstrating the predictive power of RAD for performance on
unseen augmentations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition. (arXiv:2106.04117v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_T/0/1/0/all/0/1">Tiancheng Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longbo Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haipeng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04117">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the best-of-both-worlds problem for learning an episodic Markov
Decision Process through $T$ episodes, with the goal of achieving
$\widetilde{\mathcal{O}}(\sqrt{T})$ regret when the losses are adversarial and
simultaneously $\mathcal{O}(\text{polylog}(T))$ regret when the losses are
(almost) stochastic. Recent work by [Jin and Luo, 2020] achieves this goal when
the fixed transition is known, and leaves the case of unknown transition as a
major open question. In this work, we resolve this open problem by using the
same Follow-the-Regularized-Leader ($\text{FTRL}$) framework together with a
set of new techniques. Specifically, we first propose a loss-shifting trick in
the $\text{FTRL}$ analysis, which greatly simplifies the approach of [Jin and
Luo, 2020] and already improves their results for the known transition case.
Then, we extend this idea to the unknown transition case and develop a novel
analysis which upper bounds the transition estimation error by (a fraction of)
the regret itself in the stochastic setting, a key property to ensure
$\mathcal{O}(\text{polylog}(T))$ regret.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Hybrid Automata: Learning Dynamics with Multiple Modes and Stochastic Transitions. (arXiv:2106.04165v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poli_M/0/1/0/all/0/1">Michael Poli</a>, <a href="http://arxiv.org/find/cs/1/au:+Massaroli_S/0/1/0/all/0/1">Stefano Massaroli</a>, <a href="http://arxiv.org/find/cs/1/au:+Scimeca_L/0/1/0/all/0/1">Luca Scimeca</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Seong Joon Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Sanghyuk Chun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamashita_A/0/1/0/all/0/1">Atsushi Yamashita</a>, <a href="http://arxiv.org/find/cs/1/au:+Asama_H/0/1/0/all/0/1">Hajime Asama</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinkyoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1">Animesh Garg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04165">
                                    <div class="article-summary-box-inner">
                                        <span>Effective control and prediction of dynamical systems often require
appropriate handling of continuous-time and discrete, event-triggered
processes. Stochastic hybrid systems (SHSs), common across engineering domains,
provide a formalism for dynamical systems subject to discrete, possibly
stochastic, state jumps and multi-modal continuous-time flows. Despite the
versatility and importance of SHSs across applications, a general procedure for
the explicit learning of both discrete events and multi-mode continuous
dynamics remains an open problem. This work introduces Neural Hybrid Automata
(NHAs), a recipe for learning SHS dynamics without a priori knowledge on the
number of modes and inter-modal transition dynamics. NHAs provide a systematic
inference method based on normalizing flows, neural differential equations and
self-supervision. We showcase NHAs on several tasks, including mode recovery
and flow learning in systems with stochastic transitions, and end-to-end
learning of hierarchical robot controllers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weighted Sparse Subspace Representation: A Unified Framework for Subspace Clustering, Constrained Clustering, and Active Learning. (arXiv:2106.04330v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Peng_H/0/1/0/all/0/1">Hankui Peng</a>, <a href="http://arxiv.org/find/stat/1/au:+Pavlidis_N/0/1/0/all/0/1">Nicos G. Pavlidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04330">
                                    <div class="article-summary-box-inner">
                                        <span>Spectral-based subspace clustering methods have proved successful in many
challenging applications such as gene sequencing, image recognition, and motion
segmentation. In this work, we first propose a novel spectral-based subspace
clustering algorithm that seeks to represent each point as a sparse convex
combination of a few nearby points. We then extend the algorithm to constrained
clustering and active learning settings. Our motivation for developing such a
framework stems from the fact that typically either a small amount of labelled
data is available in advance; or it is possible to label some points at a cost.
The latter scenario is typically encountered in the process of validating a
cluster assignment. Extensive experiments on simulated and real data sets show
that the proposed approach is effective and competitive with state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonsmooth Implicit Differentiation for Machine Learning and Optimization. (arXiv:2106.04350v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bolte_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Bolte</a> (TSE), <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Tam Le</a> (TSE), <a href="http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1">Edouard Pauwels</a> (IRIT), <a href="http://arxiv.org/find/cs/1/au:+Silveti_Falls_A/0/1/0/all/0/1">Antonio Silveti-Falls</a> (TSE)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04350">
                                    <div class="article-summary-box-inner">
                                        <span>In view of training increasingly complex learning architectures, we establish
a nonsmooth implicit function theorem with an operational calculus. Our result
applies to most practical problems (i.e., definable problems) provided that a
nonsmooth form of the classical invertibility condition is fulfilled. This
approach allows for formal subdifferentiation: for instance, replacing
derivatives by Clarke Jacobians in the usual differentiation formulas is fully
justified for a wide class of nonsmooth problems. Moreover this calculus is
entirely compatible with algorithmic differentiation (e.g., backpropagation).
We provide several applications such as training deep equilibrium networks,
training neural nets with conic optimization layers, or hyperparameter-tuning
for nonsmooth Lasso-type models. To show the sharpness of our assumptions, we
present numerical experiments showcasing the extremely pathological gradient
dynamics one can encounter when applying implicit algorithmic differentiation
without any hypothesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixture of Robust Experts (MoRE): A Flexible Defense Against Multiple Perturbations. (arXiv:2104.10586v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaidi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xue Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldhahn_R/0/1/0/all/0/1">Ryan Goldhahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10586">
                                    <div class="article-summary-box-inner">
                                        <span>To tackle the susceptibility of deep neural networks to adversarial examples,
the adversarial training has been proposed which provides a notion of security
through an inner maximization problem presenting the first-order adversaries
embedded within the outer minimization of the training loss. To generalize the
adversarial robustness over different perturbation types, the adversarial
training method has been augmented with the improved inner maximization
presenting a union of multiple perturbations e.g., various $\ell_p$
norm-bounded perturbations. However, the improved inner maximization only
enjoys limited flexibility in terms of the allowable perturbation types. In
this work, through a gating mechanism, we assemble a set of expert networks,
each one either adversarially trained to deal with a particular perturbation
type or normally trained for boosting accuracy on clean data. The gating module
assigns weights dynamically to each expert to achieve superior accuracy under
various data types e.g., adversarial examples, adverse weather perturbations,
and clean input. In order to deal with the obfuscated gradients issue, the
training of the gating module is conducted together with fine-tuning of the
last fully connected layers of expert networks through adversarial training
approach. Using extensive experiments, we show that our Mixture of Robust
Experts (MoRE) approach enables flexible integration of a broad range of robust
experts with superior performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Expressive Power of Self-Attention Matrices. (arXiv:2106.03764v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1">Valerii Likhosherstov</a>, <a href="http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1">Krzysztof Choromanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03764">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer networks are able to capture patterns in data coming from many
domains (text, images, videos, proteins, etc.) with little or no change to
architecture components. We perform a theoretical analysis of the core
component responsible for signal propagation between elements, i.e. the
self-attention matrix. In practice, this matrix typically exhibits two
properties: (1) it is sparse, meaning that each token only attends to a small
subset of other tokens; and (2) it changes dynamically depending on the input
to the module. With these considerations in mind, we ask the following
question: Can a fixed self-attention module approximate arbitrary sparse
patterns depending on the input? How small is the hidden size $d$ required for
such approximation? We make progress in answering this question and show that
the self-attention matrix can provably approximate sparse matrices, where
sparsity is in terms of a bounded number of nonzero elements in each row and
column. While the parameters of self-attention are fixed, various sparse
matrices can be approximated by only modifying the inputs. Our proof is based
on the random projection technique and uses the seminal Johnson-Lindenstrauss
lemma. Our proof is constructive, enabling us to propose an algorithm for
finding adaptive inputs and fixed self-attention parameters in order to
approximate a given matrix. In particular, we show that, in order to
approximate any sparse matrix up to a given precision defined in terms of
preserving matrix element ratios, $d$ grows only logarithmically with the
sequence length $L$ (i.e. $d &#x3D; O(\log L)$).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lower Bounds and Optimal Algorithms for Smooth and Strongly Convex Decentralized Optimization Over Time-Varying Networks. (arXiv:2106.04469v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kovalev_D/0/1/0/all/0/1">Dmitry Kovalev</a>, <a href="http://arxiv.org/find/math/1/au:+Gasanov_E/0/1/0/all/0/1">Elnur Gasanov</a>, <a href="http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1">Peter Richt&#xe1;rik</a>, <a href="http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1">Alexander Gasnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04469">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the task of minimizing the sum of smooth and strongly convex
functions stored in a decentralized manner across the nodes of a communication
network whose links are allowed to change in time. We solve two fundamental
problems for this task. First, we establish the first lower bounds on the
number of decentralized communication rounds and the number of local
computations required to find an $\epsilon$-accurate solution. Second, we
design two optimal algorithms that attain these lower bounds: (i) a variant of
the recently proposed algorithm ADOM (Kovalev et al., 2021) enhanced via a
multi-consensus subroutine, which is optimal in the case when access to the
dual gradients is assumed, and (ii) a novel algorithm, called ADOM+, which is
optimal in the case when access to the primal gradients is assumed. We
corroborate the theoretical efficiency of these algorithms by performing an
experimental comparison with existing state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Doing Natural Language Processing in A Natural Way: An NLP toolkit based on object-oriented knowledge base and multi-level grammar base. (arXiv:2105.05227v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yu Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05227">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce an NLP toolkit based on object-oriented knowledge base and
multi-level grammar base. This toolkit focuses on semantic parsing, it also has
abilities to discover new knowledge and grammar automatically, new discovered
knowledge and grammar will be identified by human, and will be used to update
the knowledge base and grammar base. This process can be iterated many times to
improve the toolkit continuously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stability and Generalization of Bilevel Programming in Hyperparameter Optimization. (arXiv:2106.04188v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1">Fan Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guoqiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chongxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04188">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the (gradient-based) bilevel programming framework is widely used
in hyperparameter optimization and has achieved excellent performance
empirically. Previous theoretical work mainly focuses on its optimization
properties, while leaving the analysis on generalization largely open. This
paper attempts to address the issue by presenting an expectation bound w.r.t.
the validation set based on uniform stability. Our results can explain some
mysterious behaviours of the bilevel programming in practice, for instance,
overfitting to the validation set. We also present an expectation bound for the
classical cross-validation algorithm. Our results suggest that gradient-based
algorithms can be better than cross-validation under certain conditions in a
theoretical perspective. Furthermore, we prove that regularization terms in
both the outer and inner levels can relieve the overfitting problem in
gradient-based algorithms. In experiments on feature learning and data
reweighting for noisy labels, we corroborate our theoretical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reconciling Rewards with Predictive State Representations. (arXiv:2106.03926v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baisero_A/0/1/0/all/0/1">Andrea Baisero</a>, <a href="http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1">Christopher Amato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03926">
                                    <div class="article-summary-box-inner">
                                        <span>Predictive state representations (PSRs) are models of controlled non-Markov
observation sequences which exhibit the same generative process governing POMDP
observations without relying on an underlying latent state. In that respect, a
PSR is indistinguishable from the corresponding POMDP. However, PSRs
notoriously ignore the notion of rewards, which undermines the general utility
of PSR models for control, planning, or reinforcement learning. Therefore, we
describe a sufficient and necessary accuracy condition which determines whether
a PSR is able to accurately model POMDP rewards, we show that rewards can be
approximated even when the accuracy condition is not satisfied, and we find
that a non-trivial number of POMDPs taken from a well-known third-party
repository do not satisfy the accuracy condition. We propose reward-predictive
state representations (R-PSRs), a generalization of PSRs which accurately
models both observations and rewards, and develop value iteration for R-PSRs.
We show that there is a mismatch between optimal POMDP policies and the optimal
PSR policies derived from approximate rewards. On the other hand, optimal R-PSR
policies perfectly match optimal POMDP policies, reconfirming R-PSRs as
accurate state-less generative models of observations and rewards.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Householder-Absolute Neural Layers For High Variability and Deep Trainability. (arXiv:2106.04088v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yueyao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04088">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new architecture for artificial neural networks called
Householder-absolute neural layers, or Han-layers for short, that use
Householder reflectors as weight matrices and the absolute-value function for
activation. Han-layers, functioning as fully connected layers, are motivated by
recent results on neural-network variability and are designed to increase
activation ratio and reduce the chance of Collapse to Constants. Neural
networks constructed chiefly from Han-layers are called HanNets. By
construction, HanNets enjoy a theoretical guarantee that vanishing or exploding
gradient never occurs. We conduct several proof-of-concept experiments. Some
surprising results obtained on styled test problems suggest that, under certain
conditions, HanNets exhibit an unusual ability to produce nearly perfect
solutions unattainable by fully connected networks. Experiments on regression
datasets show that HanNets can significantly reduce the number of model
parameters while maintaining or improving the level of generalization accuracy.
In addition, by adding a few Han-layers into the pre-classification FC-layer of
a convolutional neural network, we are able to quickly improve a
state-of-the-art result on CIFAR10 dataset. These proof-of-concept results are
sufficient to necessitate further studies on HanNets to understand their
capacities and limits, and to exploit their potentials in real-world
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StutterNet: Stuttering Detection Using Time Delay Neural Network. (arXiv:2105.05599v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sheikh_S/0/1/0/all/0/1">Shakeel A. Sheikh</a>, <a href="http://arxiv.org/find/eess/1/au:+Sahidullah_M/0/1/0/all/0/1">Md Sahidullah</a>, <a href="http://arxiv.org/find/eess/1/au:+Hirsch_F/0/1/0/all/0/1">Fabrice Hirsch</a>, <a href="http://arxiv.org/find/eess/1/au:+Ouni_S/0/1/0/all/0/1">Slim Ouni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05599">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces StutterNet, a novel deep learning based stuttering
detection capable of detecting and identifying various types of disfluencies.
Most of the existing work in this domain uses automatic speech recognition
(ASR) combined with language models for stuttering detection. Compared to the
existing work, which depends on the ASR module, our method relies solely on the
acoustic signal. We use a time-delay neural network (TDNN) suitable for
capturing contextual aspects of the disfluent utterances. We evaluate our
system on the UCLASS stuttering dataset consisting of more than 100 speakers.
Our method achieves promising results and outperforms the state-of-the-art
residual neural network based method. The number of trainable parameters of the
proposed method is also substantially less due to the parameter sharing scheme
of TDNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bangla Natural Language Processing: A Comprehensive Review of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sen_O/0/1/0/all/0/1">Ovishake Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1">Mohtasim Fuad</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">MD. Nazrul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabbi_J/0/1/0/all/0/1">Jakaria Rabbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">MD. Kamrul Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Baz_M/0/1/0/all/0/1">Mohammed Baz</a>, <a href="http://arxiv.org/find/cs/1/au:+Masud_M/0/1/0/all/0/1">Mehedi Masud</a>, <a href="http://arxiv.org/find/cs/1/au:+Awal_M/0/1/0/all/0/1">Md. Abdul Awal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fime_A/0/1/0/all/0/1">Awal Ahmed Fime</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuad_M/0/1/0/all/0/1">Md. Tahmid Hasan Fuad</a>, <a href="http://arxiv.org/find/cs/1/au:+Sikder_D/0/1/0/all/0/1">Delowar Sikder</a>, <a href="http://arxiv.org/find/cs/1/au:+Iftee_M/0/1/0/all/0/1">MD. Akil Raihan Iftee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14875">
                                    <div class="article-summary-box-inner">
                                        <span>The Bangla language is the seventh most spoken language, with 265 million
native and non-native speakers worldwide. However, English is the predominant
language for online resources and technical knowledge, journals, and
documentation. Consequently, many Bangla-speaking people, who have limited
command of English, face hurdles to utilize English resources. To bridge the
gap between limited support and increasing demand, researchers conducted many
experiments and developed valuable tools and techniques to create and process
Bangla language materials. Many efforts are also ongoing to make it easy to use
the Bangla language in the online and technical domains. There are some review
papers to understand the past, previous, and future Bangla Natural Language
Processing (BNLP) trends. The studies are mainly concentrated on the specific
domains of BNLP, such as sentiment analysis, speech recognition, optical
character recognition, and text summarization. There is an apparent scarcity of
resources that contain a comprehensive study of the recent BNLP tools and
methods. Therefore, in this paper, we present a thorough review of 71 BNLP
research papers and categorize them into 11 categories, namely Information
Extraction, Machine Translation, Named Entity Recognition, Parsing, Parts of
Speech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake
Detection, Text Summarization, Word Sense Disambiguation, and Speech Processing
and Recognition. We study articles published between 1999 to 2021, and 50% of
the papers were published after 2015. We discuss Classical, Machine Learning
and Deep Learning approaches with different datasets while addressing the
limitations and current and future trends of the BNLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">We Know What You Want: An Advertising Strategy Recommender System for Online Advertising. (arXiv:2105.14188v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1">Liyi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Junqi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhenzhe Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiye Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhizhuang Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Fei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1">Lvyin Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Chuan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuning Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoqiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14188">
                                    <div class="article-summary-box-inner">
                                        <span>Advertising expenditures have become the major source of revenue for
e-commerce platforms. Providing good advertising experiences for advertisers
through reducing their costs of trial and error for discovering the optimal
advertising strategies is crucial for the long-term prosperity of online
advertising. To achieve this goal, the advertising platform needs to identify
the advertisers&#x27; marketing objectives, and then recommend the corresponding
strategies to fulfill this objective. In this work, we first deploy a prototype
of strategy recommender system on Taobao display advertising platform,
recommending bid prices and targeted users to advertisers. We further augment
this prototype system by directly revealing the advertising performance, and
then infer the advertisers&#x27; marketing objectives through their adoptions of
different recommending advertising performance. We use the techniques from
context bandit to jointly learn the advertisers&#x27; marketing objectives and the
recommending strategies. Online evaluations show that the designed advertising
strategy recommender system can optimize the advertisers&#x27; advertising
performance and increase the platform&#x27;s revenue. Simulation experiments based
on Taobao online bidding data show that the designed contextual bandit
algorithm can effectively optimize the strategy adoption rate of advertisers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Medkit-Learn(ing) Environment: Medical Decision Modelling through Simulation. (arXiv:2106.04240v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Alex J. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bica_I/0/1/0/all/0/1">Ioana Bica</a>, <a href="http://arxiv.org/find/cs/1/au:+Huyuk_A/0/1/0/all/0/1">Alihan Huyuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Jarrett_D/0/1/0/all/0/1">Daniel Jarrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04240">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding decision-making in clinical environments is of paramount
importance if we are to bring the strengths of machine learning to ultimately
improve patient outcomes. Several factors including the availability of public
data, the intrinsically offline nature of the problem, and the complexity of
human decision making, has meant that the mainstream development of algorithms
is often geared towards optimal performance in tasks that do not necessarily
translate well into the medical regime; often overlooking more niche issues
commonly associated with the area. We therefore present a new benchmarking
suite designed specifically for medical sequential decision making: the
Medkit-Learn(ing) Environment, a publicly available Python package providing
simple and easy access to high-fidelity synthetic medical data. While providing
a standardised way to compare algorithms in a realistic medical setting we
employ a generating process that disentangles the policy and environment
dynamics to allow for a range of customisations, thus enabling systematic
evaluation of algorithms&#x27; robustness against specific challenges prevalent in
healthcare.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable agent communication from scratch(with a generic visual processor emerging on the side). (arXiv:2106.04258v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dessi_R/0/1/0/all/0/1">Roberto Dess&#xec;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1">Marco Baroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04258">
                                    <div class="article-summary-box-inner">
                                        <span>As deep networks begin to be deployed as autonomous agents, the issue of how
they can communicate with each other becomes important. Here, we train two deep
nets from scratch to perform realistic referent identification through
unsupervised emergent communication. We show that the largely interpretable
emergent protocol allows the nets to successfully communicate even about object
types they did not see at training time. The visual representations induced as
a by-product of our training regime, moreover, show comparable quality, when
re-used as generic visual features, to a recent self-supervised learning model.
Our results provide concrete evidence of the viability of (interpretable)
emergent deep net communication in a more realistic scenario than previously
considered, as well as establishing an intriguing link between this field and
self-supervised visual learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models. (arXiv:2106.03969v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boix_Adsera_E/0/1/0/all/0/1">Enric Boix-Adsera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bresler_G/0/1/0/all/0/1">Guy Bresler</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1">Frederic Koehler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03969">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning a tree-structured Ising model from data,
such that subsequent predictions computed using the model are accurate.
Concretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small
sets of variables $S$ are accurate. Since its introduction more than 50 years
ago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood
tree, has been the benchmark algorithm for learning tree-structured graphical
models. A bound on the sample complexity of the Chow-Liu algorithm with respect
to the prediction-centric local total variation loss was shown in [BK19]. While
those results demonstrated that it is possible to learn a useful model even
when recovering the true underlying graph is impossible, their bound depends on
the maximum strength of interactions and thus does not achieve the
information-theoretic optimum. In this paper, we introduce a new algorithm that
carefully combines elements of the Chow-Liu algorithm with tree metric
reconstruction methods to efficiently and optimally learn tree Ising models
under a prediction-centric loss. Our algorithm is robust to model
misspecification and adversarial corruptions. In contrast, we show that the
celebrated Chow-Liu algorithm can be arbitrarily suboptimal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Data Augmentation Do We Need for Deep-Learning-Based Finance?. (arXiv:2106.04114v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1">Liu Ziyin</a>, <a href="http://arxiv.org/find/cs/1/au:+Minami_K/0/1/0/all/0/1">Kentaro Minami</a>, <a href="http://arxiv.org/find/cs/1/au:+Imajo_K/0/1/0/all/0/1">Kentaro Imajo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04114">
                                    <div class="article-summary-box-inner">
                                        <span>The main task we consider is portfolio construction in a speculative market,
a fundamental problem in modern finance. While various empirical works now
exist to explore deep learning in finance, the theory side is almost
non-existent. In this work, we focus on developing a theoretical framework for
understanding the use of data augmentation for deep-learning-based approaches
to quantitative finance. The proposed theory clarifies the role and necessity
of data augmentation for finance; moreover, our theory motivates a simple
algorithm of injecting a random noise of strength $\sqrt{|r_{t-1}|}$ to the
observed return $r_{t}$. This algorithm is shown to work well in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E(n) Equivariant Normalizing Flows. (arXiv:2105.09016v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Satorras_V/0/1/0/all/0/1">Victor Garcia Satorras</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1">Emiel Hoogeboom</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuchs_F/0/1/0/all/0/1">Fabian B. Fuchs</a>, <a href="http://arxiv.org/find/cs/1/au:+Posner_I/0/1/0/all/0/1">Ingmar Posner</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09016">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a generative model equivariant to Euclidean symmetries:
E(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the
discriminative E(n) graph neural networks and integrate them as a differential
equation to obtain an invertible equivariant function: a continuous-time
normalizing flow. We demonstrate that E-NFs considerably outperform baselines
and existing methods from the literature on particle systems such as DW4 and
LJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our
knowledge, this is the first flow that jointly generates molecule features and
positions in 3D.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Makes Multimodal Learning Better than Single (Provably). (arXiv:2106.04538v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_C/0/1/0/all/0/1">Chenzhuang Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1">Zihui Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuanyao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longbo Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04538">
                                    <div class="article-summary-box-inner">
                                        <span>The world provides us with data of multiple modalities. Intuitively, models
fusingdata from different modalities outperform unimodal models, since more
informationis aggregated. Recently, joining the success of deep learning, there
is an influentialline of work on deep multimodal learning, which has remarkable
empirical resultson various applications. However, theoretical justifications
in this field are notablylacking.Can multimodal provably perform better than
unimodal? In this paper, we answer this question under a most popular
multimodal learningframework, which firstly encodes features from different
modalities into a commonlatent space and seamlessly maps the latent
representations into the task space. Weprove that learning with multiple
modalities achieves a smaller population risk thanonly using its subset of
modalities. The main intuition is that the former has moreaccurate estimate of
the latent space representation. To the best of our knowledge,this is the first
theoretical treatment to capture important qualitative phenomenaobserved in
real multimodal applications. Combining with experiment results, weshow that
multimodal learning does possess an appealing formal guarantee.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incentive Mechanism for Privacy-Preserving Federated Learning. (arXiv:2106.04384v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuyuan Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1">Masatoshi Yoshikawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04384">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is an emerging paradigm for machine learning, in
which data owners can collaboratively train a model by sharing gradients
instead of their raw data. Two fundamental research problems in FL are
incentive mechanism and privacy protection. The former focuses on how to
incentivize data owners to participate in FL. The latter studies how to protect
data owners&#x27; privacy while maintaining high utility of trained models. However,
incentive mechanism and privacy protection in FL have been studied separately
and no work solves both problems at the same time. In this work, we address the
two problems simultaneously by an FL-Market that incentivizes data owners&#x27;
participation by providing appropriate payments and privacy protection.
FL-Market enables data owners to obtain compensation according to their privacy
loss quantified by local differential privacy (LDP). Our insight is that, by
meeting data owners&#x27; personalized privacy preferences and providing appropriate
payments, we can (1) incentivize privacy risk-tolerant data owners to set
larger privacy parameters (i.e., gradients with less noise) and (2) provide
preferred privacy protection for privacy risk-averse data owners. To achieve
this, we design a personalized LDP-based FL framework with a deep
learning-empowered auction mechanism for incentivizing trading gradients with
less noise and optimal aggregation mechanisms for model updates. Our
experiments verify the effectiveness of the proposed framework and mechanisms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Policy Comparison under Limited Historical Agent-Environment Interactions. (arXiv:2106.03934v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dereventsov_A/0/1/0/all/0/1">Anton Dereventsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Daws_J/0/1/0/all/0/1">Joseph D. Daws Jr.</a>, <a href="http://arxiv.org/find/cs/1/au:+Webster_C/0/1/0/all/0/1">Clayton Webster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03934">
                                    <div class="article-summary-box-inner">
                                        <span>We address the challenge of policy evaluation in real-world applications of
reinforcement learning systems where the available historical data is limited
due to ethical, practical, or security considerations. This constrained
distribution of data samples often leads to biased policy evaluation estimates.
To remedy this, we propose that instead of policy evaluation, one should
perform policy comparison, i.e. to rank the policies of interest in terms of
their value based on available historical data. In addition we present the
Limited Data Estimator (LDE) as a simple method for evaluating and comparing
policies from a small number of interactions with the environment. According to
our theoretical analysis, the LDE is shown to be statistically reliable on
policy comparison tasks under mild assumptions on the distribution of the
historical data. Additionally, our numerical experiments compare the LDE to
other policy evaluation methods on the task of policy ranking and demonstrate
its advantage in various settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Online Learning for Dynamic k-Clustering. (arXiv:2106.04336v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fotakis_D/0/1/0/all/0/1">Dimitris Fotakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1">Georgios Piliouras</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoulakis_S/0/1/0/all/0/1">Stratis Skoulakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04336">
                                    <div class="article-summary-box-inner">
                                        <span>We study dynamic clustering problems from the perspective of online learning.
We consider an online learning problem, called \textit{Dynamic $k$-Clustering},
in which $k$ centers are maintained in a metric space over time (centers may
change positions) such as a dynamically changing set of $r$ clients is served
in the best possible way. The connection cost at round $t$ is given by the
\textit{$p$-norm} of the vector consisting of the distance of each client to
its closest center at round $t$, for some $p\geq 1$ or $p &#x3D; \infty$. We present
a \textit{$\Theta\left( \min(k,r) \right)$-regret} polynomial-time online
learning algorithm and show that, under some well-established computational
complexity conjectures, \textit{constant-regret} cannot be achieved in
polynomial-time. In addition to the efficient solution of Dynamic
$k$-Clustering, our work contributes to the long line of research on
combinatorial online learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Topology Divergence: a Framework for Comparing Data Manifolds. (arXiv:2106.04024v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barannikov_S/0/1/0/all/0/1">Serguei Barannikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Trofimov_I/0/1/0/all/0/1">Ilya Trofimov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sotnikov_G/0/1/0/all/0/1">Grigorii Sotnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Trimbach_E/0/1/0/all/0/1">Ekaterina Trimbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1">Alexander Korotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Filippov_A/0/1/0/all/0/1">Alexander Filippov</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04024">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a framework for comparing data manifolds, aimed, in particular,
towards the evaluation of deep generative models. We describe a novel tool,
Cross-Barcode(P,Q), that, given a pair of distributions in a high-dimensional
space, tracks multiscale topology spacial discrepancies between manifolds on
which the distributions are concentrated. Based on the Cross-Barcode, we
introduce the Manifold Topology Divergence score (MTop-Divergence) and apply it
to assess the performance of deep generative models in various domains: images,
3D-shapes, time-series, and on different datasets: MNIST, Fashion MNIST, SVHN,
CIFAR10, FFHQ, chest X-ray images, market stock data, ShapeNet. We demonstrate
that the MTop-Divergence accurately detects various degrees of mode-dropping,
intra-mode collapse, mode invention, and image disturbance. Our algorithm
scales well (essentially linearly) with the increase of the dimension of the
ambient high-dimensional space. It is one of the first TDA-based practical
methodologies that can be applied universally to datasets of different sizes
and dimensions, including the ones on which the most recent GANs in the visual
domain are trained. The proposed method is domain agnostic and does not rely on
pre-trained networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Anomalous Event Sequences with Temporal Point Processes. (arXiv:2106.04465v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1">Oleksandr Shchur</a>, <a href="http://arxiv.org/find/cs/1/au:+Turkmen_A/0/1/0/all/0/1">Ali Caner T&#xfc;rkmen</a>, <a href="http://arxiv.org/find/cs/1/au:+Januschowski_T/0/1/0/all/0/1">Tim Januschowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasthaus_J/0/1/0/all/0/1">Jan Gasthaus</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04465">
                                    <div class="article-summary-box-inner">
                                        <span>Automatically detecting anomalies in event data can provide substantial value
in domains such as healthcare, DevOps, and information security. In this paper,
we frame the problem of detecting anomalous continuous-time event sequences as
out-of-distribution (OoD) detection for temporal point processes (TPPs). First,
we show how this problem can be approached using goodness-of-fit (GoF) tests.
We then demonstrate the limitations of popular GoF statistics for TPPs and
propose a new test that addresses these shortcomings. The proposed method can
be combined with various TPP models, such as neural TPPs, and is easy to
implement. In our experiments, we show that the proposed statistic excels at
both traditional GoF testing, as well as at detecting anomalies in simulated
and real-world data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GSVNet: Guided Spatially-Varying Convolution for Fast Semantic Segmentation on Video. (arXiv:2103.08834v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Shih-Po Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Si-Cun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wen-Hsiao Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08834">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses fast semantic segmentation on video.Video segmentation
often calls for real-time, or even fasterthan real-time, processing. One common
recipe for conserving computation arising from feature extraction is to
propagate features of few selected keyframes. However, recent advances in fast
image segmentation make these solutions less attractive. To leverage fast image
segmentation for furthering video segmentation, we propose a simple yet
efficient propagation framework. Specifically, we perform lightweight flow
estimation in 1/8-downscaled image space for temporal warping in segmentation
outpace space. Moreover, we introduce a guided spatially-varying convolution
for fusing segmentations derived from the previous and current frames, to
mitigate propagation error and enable lightweight feature extraction on
non-keyframes. Experimental results on Cityscapes and CamVid show that our
scheme achieves the state-of-the-art accuracy-throughput trade-off on video
segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of data-splits on generalization: Identifying COVID-19 from cough and context. (arXiv:2106.03851v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1">Makkunda Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenoy_N/0/1/0/all/0/1">Nikhil Shenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_J/0/1/0/all/0/1">Jigar Doshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagad_P/0/1/0/all/0/1">Piyush Bagad</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalmia_A/0/1/0/all/0/1">Aman Dalmia</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhamare_P/0/1/0/all/0/1">Parag Bhamare</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahale_A/0/1/0/all/0/1">Amrita Mahale</a>, <a href="http://arxiv.org/find/cs/1/au:+Rane_S/0/1/0/all/0/1">Saurabh Rane</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_N/0/1/0/all/0/1">Neeraj Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Panicker_R/0/1/0/all/0/1">Rahul Panicker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03851">
                                    <div class="article-summary-box-inner">
                                        <span>Rapidly scaling screening, testing and quarantine has shown to be an
effective strategy to combat the COVID-19 pandemic. We consider the application
of deep learning techniques to distinguish individuals with COVID from
non-COVID by using data acquirable from a phone. Using cough and context
(symptoms and meta-data) represent such a promising approach. Several
independent works in this direction have shown promising results. However, none
of them report performance across clinically relevant data splits.
Specifically, the performance where the development and test sets are split in
time (retrospective validation) and across sites (broad validation). Although
there is meaningful generalization across these splits the performance
significantly varies (up to 0.1 AUC score). In addition, we study the
performance of symptomatic and asymptomatic individuals across these three
splits. Finally, we show that our model focuses on meaningful features of the
input, cough bouts for cough and relevant symptoms for context. The code and
checkpoints are available at https://github.com/WadhwaniAI/cough-against-covid</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">There Is No Turning Back: A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning. (arXiv:2106.04480v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grinsztajn_N/0/1/0/all/0/1">Nathan Grinsztajn</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferret_J/0/1/0/all/0/1">Johan Ferret</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1">Olivier Pietquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Preux_P/0/1/0/all/0/1">Philippe Preux</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04480">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to learn to distinguish reversible from irreversible actions for
better informed decision-making in Reinforcement Learning (RL). From
theoretical considerations, we show that approximate reversibility can be
learned through a simple surrogate task: ranking randomly sampled trajectory
events in chronological order. Intuitively, pairs of events that are always
observed in the same order are likely to be separated by an irreversible
sequence of actions. Conveniently, learning the temporal order of events can be
done in a fully self-supervised way, which we use to estimate the reversibility
of actions from experience, without any priors. We propose two different
strategies that incorporate reversibility in RL agents, one strategy for
exploration (RAE) and one strategy for control (RAC). We demonstrate the
potential of reversibility-aware agents in several environments, including the
challenging Sokoban game. In synthetic tasks, we show that we can learn control
policies that never fail and reduce to zero the side-effects of interactions,
even without access to the reward function.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive transfer learning. (arXiv:2106.04455v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Reeve_H/0/1/0/all/0/1">Henry W. J. Reeve</a>, <a href="http://arxiv.org/find/stat/1/au:+Cannings_T/0/1/0/all/0/1">Timothy I. Cannings</a>, <a href="http://arxiv.org/find/stat/1/au:+Samworth_R/0/1/0/all/0/1">Richard J. Samworth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04455">
                                    <div class="article-summary-box-inner">
                                        <span>In transfer learning, we wish to make inference about a target population
when we have access to data both from the distribution itself, and from a
different but related source distribution. We introduce a flexible framework
for transfer learning in the context of binary classification, allowing for
covariate-dependent relationships between the source and target distributions
that are not required to preserve the Bayes decision boundary. Our main
contributions are to derive the minimax optimal rates of convergence (up to
poly-logarithmic factors) in this problem, and show that the optimal rate can
be achieved by an algorithm that adapts to key aspects of the unknown transfer
relationship, as well as the smoothness and tail parameters of our
distributional classes. This optimal rate turns out to have several regimes,
depending on the interplay between the relative sample sizes and the strength
of the transfer relationship, and our algorithm achieves optimality by careful,
decision tree-based calibration of local nearest-neighbour procedures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Elastic Lottery Ticket Hypothesis. (arXiv:2103.16547v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuohang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16547">
                                    <div class="article-summary-box-inner">
                                        <span>Lottery Ticket Hypothesis (LTH) raises keen attention to identifying sparse
trainable subnetworks, or winning tickets, of training, which can be trained in
isolation to achieve similar or even better performance compared to the full
models. Despite many efforts being made, the most effective method to identify
such winning tickets is still Iterative Magnitude-based Pruning (IMP), which is
computationally expensive and has to be run thoroughly for every different
network. A natural question that comes in is: can we &quot;transform&quot; the winning
ticket found in one network to another with a different architecture, yielding
a winning ticket for the latter at the beginning, without re-doing the
expensive IMP? Answering this question is not only practically relevant for
efficient &quot;once-for-all&quot; winning ticket finding, but also theoretically
appealing for uncovering inherently scalable sparse patterns in networks. We
conduct extensive experiments on CIFAR-10 and ImageNet, and propose a variety
of strategies to tweak the winning tickets found from different networks of the
same model family (e.g., ResNets). Based on these results, we articulate the
Elastic Lottery Ticket Hypothesis (E-LTH): by mindfully replicating (or
dropping) and re-ordering layers for one network, its corresponding winning
ticket could be stretched (or squeezed) into a subnetwork for another deeper
(or shallower) network from the same family, whose performance is nearly the
same competitive as the latter&#x27;s winning ticket directly found by IMP. We have
also thoroughly compared E-LTH with pruning-at-initialization and dynamic
sparse training methods, and discuss the generalizability of E-LTH to different
model families, layer types, or across datasets. Code is available at
https://github.com/VITA-Group/ElasticLTH.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustifying $\ell_\infty$ Adversarial Training to the Union of Perturbation Models. (arXiv:2105.14710v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1">Ameya D. Patil</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuttle_M/0/1/0/all/0/1">Michael Tuttle</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwing_A/0/1/0/all/0/1">Alexander G. Schwing</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanbhag_N/0/1/0/all/0/1">Naresh R. Shanbhag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14710">
                                    <div class="article-summary-box-inner">
                                        <span>Classical adversarial training (AT) frameworks are designed to achieve high
adversarial accuracy against a single attack type, typically $\ell_\infty$
norm-bounded perturbations. Recent extensions in AT have focused on defending
against the union of multiple perturbations but this benefit is obtained at the
expense of a significant (up to $10\times$) increase in training complexity
over single-attack $\ell_\infty$ AT. In this work, we expand the capabilities
of widely popular single-attack $\ell_\infty$ AT frameworks to provide
robustness to the union of ($\ell_\infty, \ell_2, \ell_1$) perturbations while
preserving their training efficiency. Our technique, referred to as Shaped
Noise Augmented Processing (SNAP), exploits a well-established byproduct of
single-attack AT frameworks -- the reduction in the curvature of the decision
boundary of networks. SNAP prepends a given deep net with a shaped noise
augmentation layer whose distribution is learned along with network parameters
using any standard single-attack AT. As a result, SNAP enhances adversarial
accuracy of ResNet-18 on CIFAR-10 against the union of ($\ell_\infty, \ell_2,
\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)
single-attack $\ell_\infty$ AT frameworks, and, for the first time, establishes
a benchmark for ResNet-50 and ResNet-101 on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Feature Learning for Manipulation with Contrastive Domain Randomization. (arXiv:2103.11144v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rabinovitz_C/0/1/0/all/0/1">Carmel Rabinovitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Grupen_N/0/1/0/all/0/1">Niko Grupen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1">Aviv Tamar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11144">
                                    <div class="article-summary-box-inner">
                                        <span>Robotic tasks such as manipulation with visual inputs require image features
that capture the physical properties of the scene, e.g., the position and
configuration of objects. Recently, it has been suggested to learn such
features in an unsupervised manner from simulated, self-supervised, robot
interaction; the idea being that high-level physical properties are well
captured by modern physical simulators, and their representation from visual
inputs may transfer well to the real world. In particular, learning methods
based on noise contrastive estimation have shown promising results. To
robustify the simulation-to-real transfer, domain randomization (DR) was
suggested for learning features that are invariant to irrelevant visual
properties such as textures or lighting. In this work, however, we show that a
naive application of DR to unsupervised learning based on contrastive
estimation does not promote invariance, as the loss function maximizes mutual
information between the features and both the relevant and irrelevant visual
properties. We propose a simple modification of the contrastive loss to fix
this, exploiting the fact that we can control the simulated randomization of
visual properties. Our approach learns physical features that are significantly
more robust to visual domain variation, as we demonstrate using both rigid and
non-rigid objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Integrated Variational Autoencoders for Robust and Interpretable Generative Modeling. (arXiv:2102.13156v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takeishi_N/0/1/0/all/0/1">Naoya Takeishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1">Alexandros Kalousis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13156">
                                    <div class="article-summary-box-inner">
                                        <span>Integrating physics models within machine learning models holds considerable
promise toward learning robust models with improved interpretability and
abilities to extrapolate. In this work, we focus on the integration of
incomplete physics models into deep generative models. In particular, we
introduce an architecture of variational autoencoders (VAEs) in which a part of
the latent space is grounded by physics. A key technical challenge is to strike
a balance between the incomplete physics and trainable components such as
neural networks for ensuring that the physics part is used in a meaningful
manner. To this end, we propose a regularized learning method that controls the
effect of the trainable components and preserves the semantics of the
physics-based latent variables as intended. We not only demonstrate generative
performance improvements over a set of synthetic and real-world datasets, but
we also show that we learn robust models that can consistently extrapolate
beyond the training distribution in a meaningful manner. Moreover, we show that
we can control the generative process in an interpretable manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deeply-Debiased Off-Policy Interval Estimation. (arXiv:2105.04646v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1">Chengchun Shi</a>, <a href="http://arxiv.org/find/stat/1/au:+Wan_R/0/1/0/all/0/1">Runzhe Wan</a>, <a href="http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1">Victor Chernozhukov</a>, <a href="http://arxiv.org/find/stat/1/au:+Song_R/0/1/0/all/0/1">Rui Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04646">
                                    <div class="article-summary-box-inner">
                                        <span>Off-policy evaluation learns a target policy&#x27;s value with a historical
dataset generated by a different behavior policy. In addition to a point
estimate, many applications would benefit significantly from having a
confidence interval (CI) that quantifies the uncertainty of the point estimate.
In this paper, we propose a novel deeply-debiasing procedure to construct an
efficient, robust, and flexible CI on a target policy&#x27;s value. Our method is
justified by theoretical results and numerical experiments. A Python
implementation of the proposed procedure is available at
https://github.com/RunzheStat/D2OPE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sublinear Least-Squares Value Iteration via Locality Sensitive Hashing. (arXiv:2105.08285v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Anshumali Shrivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhaozhuo Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08285">
                                    <div class="article-summary-box-inner">
                                        <span>We present the first provable Least-Squares Value Iteration (LSVI) algorithms
that have runtime complexity sublinear in the number of actions. We formulate
the value function estimation procedure in value iteration as an approximate
maximum inner product search problem and propose a locality sensitive hashing
(LSH) [Indyk and Motwani STOC&#x27;98, Andoni and Razenshteyn STOC&#x27;15, Andoni,
Laarhoven, Razenshteyn and Waingarten SODA&#x27;17] type data structure to solve
this problem with sublinear time complexity. Moreover, we build the connections
between the theory of approximate maximum inner product search and the regret
analysis of reinforcement learning. We prove that, with our choice of
approximation factor, our Sublinear LSVI algorithms maintain the same regret as
the original LSVI algorithms while reducing the runtime complexity to sublinear
in the number of actions. To the best of our knowledge, this is the first work
that combines LSH with reinforcement learning resulting in provable
improvements. We hope that our novel way of combining data-structures and
iterative algorithm will open the door for further study into cost reduction in
optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Learning in Online Queuing Systems. (arXiv:2106.04228v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sentenac_F/0/1/0/all/0/1">Flore Sentenac</a>, <a href="http://arxiv.org/find/stat/1/au:+Boursier_E/0/1/0/all/0/1">Etienne Boursier</a>, <a href="http://arxiv.org/find/stat/1/au:+Perchet_V/0/1/0/all/0/1">Vianney Perchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04228">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by packet routing in computer networks, online queuing systems are
composed of queues receiving packets at different rates. Repeatedly, they send
packets to servers, each of them treating only at most one packet at a time. In
the centralized case, the number of accumulated packets remains bounded (i.e.,
the system is \textit{stable}) as long as the ratio between service rates and
arrival rates is larger than $1$. In the decentralized case, individual
no-regret strategies ensures stability when this ratio is larger than $2$. Yet,
myopically minimizing regret disregards the long term effects due to the
carryover of packets to further rounds. On the other hand, minimizing long term
costs leads to stable Nash equilibria as soon as the ratio exceeds
$\frac{e}{e-1}$. Stability with decentralized learning strategies with a ratio
below $2$ was a major remaining question. We first argue that for ratios up to
$2$, cooperation is required for stability of learning strategies, as selfish
minimization of policy regret, a \textit{patient} notion of regret, might
indeed still be unstable in this case. We therefore consider cooperative queues
and propose the first learning decentralized algorithm guaranteeing stability
of the system as long as the ratio of rates is larger than $1$, thus reaching
performances comparable to centralized strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cyberbullying Detection Using Deep Neural Network from Social Media Comments in Bangla Language. (arXiv:2106.04506v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1">Md Faisal Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_Z/0/1/0/all/0/1">Zalish Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Biash_Z/0/1/0/all/0/1">Zarin Tasnim Biash</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryen_A/0/1/0/all/0/1">Ahmed Ann Noor Ryen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_A/0/1/0/all/0/1">Arman Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashraf_F/0/1/0/all/0/1">Faisal Bin Ashraf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04506">
                                    <div class="article-summary-box-inner">
                                        <span>Cyberbullying or Online harassment detection on social media for various
major languages is currently being given a good amount of focus by researchers
worldwide. Being the seventh most speaking language in the world and increasing
usage of online platform among the Bengali speaking people urge to find
effective detection technique to handle the online harassment. In this paper,
we have proposed binary and multiclass classification model using hybrid neural
network for bully expression detection in Bengali language. We have used 44,001
users comments from popular public Facebook pages, which fall into five classes
- Non-bully, Sexual, Threat, Troll and Religious. We have examined the
performance of our proposed models from different perspective. Our binary
classification model gives 87.91% accuracy, whereas introducing ensemble
technique after neural network for multiclass classification, we got 85%
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Struggle with Academic Plagiarism: Approaches based on Semantic Similarity. (arXiv:2106.04404v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vrbanec_T/0/1/0/all/0/1">Tedo Vrbanec</a>, <a href="http://arxiv.org/find/cs/1/au:+Mestrovic_A/0/1/0/all/0/1">Ana Mestrovic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04404">
                                    <div class="article-summary-box-inner">
                                        <span>Academic plagiarism is a serious problem nowadays. Due to the existence of
inexhaustible sources of digital information, today it is easier to plagiarize
more than ever before. The good thing is that plagiarism detection techniques
have improved and are powerful enough to detect attempts of plagiarism in
education. We are now witnessing efficient plagiarism detection software in
action, such as Turnitin, iThenticate or SafeAssign. In the introduction we
explore software that is used within the Croatian academic community for
plagiarism detection in universities and/or in scientific journals. The
question is: is this enough? Current software has proven to be successful,
however the problem of identifying paraphrasing or obfuscation plagiarism
remains unresolved. In this paper we present a report of how semantic
similarity measures can be used in the plagiarism detection task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Property-Aware Robot Object Manipulation: a Generative Approach. (arXiv:2106.04385v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garello_L/0/1/0/all/0/1">Luca Garello</a>, <a href="http://arxiv.org/find/cs/1/au:+Lastrico_L/0/1/0/all/0/1">Linda Lastrico</a>, <a href="http://arxiv.org/find/cs/1/au:+Rea_F/0/1/0/all/0/1">Francesco Rea</a>, <a href="http://arxiv.org/find/cs/1/au:+Mastrogiovanni_F/0/1/0/all/0/1">Fulvio Mastrogiovanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Noceti_N/0/1/0/all/0/1">Nicoletta Noceti</a>, <a href="http://arxiv.org/find/cs/1/au:+Sciutti_A/0/1/0/all/0/1">Alessandra Sciutti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04385">
                                    <div class="article-summary-box-inner">
                                        <span>When transporting an object, we unconsciously adapt our movement to its
properties, for instance by slowing down when the item is fragile. The most
relevant features of an object are immediately revealed to a human observer by
the way the handling occurs, without any need for verbal description. It would
greatly facilitate collaboration to enable humanoid robots to perform movements
that convey similar intuitive cues to the observers. In this work, we focus on
how to generate robot motion adapted to the hidden properties of the
manipulated objects, such as their weight and fragility. We explore the
possibility of leveraging Generative Adversarial Networks to synthesize new
actions coherent with the properties of the object. The use of a generative
approach allows us to create new and consistent motion patterns, without the
need of collecting a large number of recorded human-led demonstrations.
Besides, the informative content of the actions is preserved. Our results show
that Generative Adversarial Nets can be a powerful tool for the generation of
novel and meaningful transportation actions, which result effectively modulated
as a function of the object weight and the carefulness required in its
handling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Generation of Machine Learning Synthetic Data Using ROS. (arXiv:2106.04547v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hart_K/0/1/0/all/0/1">Kyle M. Hart</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Goodman_A/0/1/0/all/0/1">Ari B. Goodman</a> (1), <a href="http://arxiv.org/find/cs/1/au:+OShea_R/0/1/0/all/0/1">Ryan P. O&#x27;Shea</a> (1) ((1) Naval Air Warfare Center - Aircraft Division - Lakehurst)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04547">
                                    <div class="article-summary-box-inner">
                                        <span>Data labeling is a time intensive process. As such, many data scientists use
various tools to aid in the data generation and labeling process. While these
tools help automate labeling, many still require user interaction throughout
the process. Additionally, most target only a few network frameworks. Any
researchers exploring multiple frameworks must find additional tools orwrite
conversion scripts. This paper presents an automated tool for generating
synthetic data in arbitrary network formats. It uses Robot Operating System
(ROS) and Gazebo, which are common tools in the robotics community. Through ROS
paradigms, it allows extensive user customization of the simulation environment
and data generation process. Additionally, a plugin-like framework allows the
development of arbitrary data format writers without the need to change the
main body of code. Using this tool, the authors were able to generate an
arbitrarily large image dataset for three unique training formats using
approximately 15 min of user setup time and a variable amount of hands-off run
time, depending on the dataset size. The source code for this data generation
tool is available at https://github.com/Navy-RISE-Lab/nn_data_collection</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Control with Graph Neural Networks. (arXiv:2012.14906v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gama_F/0/1/0/all/0/1">Fernando Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingbiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolstaya_E/0/1/0/all/0/1">Ekaterina Tolstaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Prorok_A/0/1/0/all/0/1">Amanda Prorok</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14906">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamical systems consisting of a set of autonomous agents face the challenge
of having to accomplish a global task, relying only on local information. While
centralized controllers are readily available, they face limitations in terms
of scalability and implementation, as they do not respect the distributed
information structure imposed by the network system of agents. Given the
difficulties in finding optimal decentralized controllers, we propose a novel
framework using graph neural networks (GNNs) to \emph{learn} these controllers.
GNNs are well-suited for the task since they are naturally distributed
architectures and exhibit good scalability and transferability properties. The
problems of flocking and multi-agent path planning are explored to illustrate
the potential of GNNs in learning decentralized controllers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Deep Inverse Rosenblatt Transports. (arXiv:2106.04170v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Cui_T/0/1/0/all/0/1">Tiangang Cui</a>, <a href="http://arxiv.org/find/stat/1/au:+Dolgov_S/0/1/0/all/0/1">Sergey Dolgov</a>, <a href="http://arxiv.org/find/stat/1/au:+Zahm_O/0/1/0/all/0/1">Olivier Zahm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04170">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel offline-online method to mitigate the computational burden
of the characterization of conditional beliefs in statistical learning. In the
offline phase, the proposed method learns the joint law of the belief random
variables and the observational random variables in the tensor-train (TT)
format. In the online phase, it utilizes the resulting order-preserving
conditional transport map to issue real-time characterization of the
conditional beliefs given new observed information. Compared with the
state-of-the-art normalizing flows techniques, the proposed method relies on
function approximation and is equipped with thorough performance analysis. This
also allows us to further extend the capability of transport maps in
challenging problems with high-dimensional observations and high-dimensional
belief variables. On the one hand, we present novel heuristics to reorder
and/or reparametrize the variables to enhance the approximation power of TT. On
the other, we integrate the TT-based transport maps and the parameter
reordering/reparametrization into layered compositions to further improve the
performance of the resulting transport maps. We demonstrate the efficiency of
the proposed method on various statistical learning tasks in ordinary
differential equations (ODEs) and partial differential equations (PDEs).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Loss Surfaces of Neural Networks with General Activation Functions. (arXiv:2004.03959v3 [math.PR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Baskerville_N/0/1/0/all/0/1">Nicholas P. Baskerville</a>, <a href="http://arxiv.org/find/math/1/au:+Keating_J/0/1/0/all/0/1">Jonathan P. Keating</a>, <a href="http://arxiv.org/find/math/1/au:+Mezzadri_F/0/1/0/all/0/1">Francesco Mezzadri</a>, <a href="http://arxiv.org/find/math/1/au:+Najnudel_J/0/1/0/all/0/1">Joseph Najnudel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03959">
                                    <div class="article-summary-box-inner">
                                        <span>The loss surfaces of deep neural networks have been the subject of several
studies, theoretical and experimental, over the last few years. One strand of
work considers the complexity, in the sense of local optima, of high
dimensional random functions with the aim of informing how local optimisation
methods may perform in such complicated settings. Prior work of Choromanska et
al (2015) established a direct link between the training loss surfaces of deep
multi-layer perceptron networks and spherical multi-spin glass models under
some very strong assumptions on the network and its data. In this work, we test
the validity of this approach by removing the undesirable restriction to ReLU
activation functions. In doing so, we chart a new path through the spin glass
complexity calculations using supersymmetric methods in Random Matrix Theory
which may prove useful in other contexts. Our results shed new light on both
the strengths and the weaknesses of spin glass models in this context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deterministic Neural Networks with Inductive Biases Capture Epistemic and Aleatoric Uncertainty. (arXiv:2102.11582v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mukhoti_J/0/1/0/all/0/1">Jishnu Mukhoti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirsch_A/0/1/0/all/0/1">Andreas Kirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1">Joost van Amersfoort</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11582">
                                    <div class="article-summary-box-inner">
                                        <span>We show that a single softmax neural net with minimal changes can beat the
uncertainty predictions of Deep Ensembles and other more complex
single-forward-pass uncertainty approaches. Standard softmax neural nets suffer
from feature collapse and extrapolate arbitrarily for OoD points. This results
in arbitrary softmax entropies for OoD points which can have high entropy, low,
or anything in between, thus cannot capture epistemic uncertainty reliably. We
prove that this failure lies at the core of &quot;why&quot; Deep Ensemble Uncertainty
works well. Instead of using softmax entropy, we show that with appropriate
inductive biases softmax neural nets trained with maximum likelihood reliably
capture epistemic uncertainty through their feature-space density. This density
is obtained using simple Gaussian Discriminant Analysis, but it cannot
represent aleatoric uncertainty reliably. We show that it is necessary to
combine feature-space density with softmax entropy to disentangle uncertainties
well. We evaluate the epistemic uncertainty quality on active learning and OoD
detection, achieving SOTA ~98 AUROC on CIFAR-10 vs SVHN without fine-tuning on
OoD data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A low discrepancy sequence on graphs. (arXiv:2010.04227v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1">A. Cloninger</a>, <a href="http://arxiv.org/find/cs/1/au:+Mhaskar_H/0/1/0/all/0/1">H. N. Mhaskar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04227">
                                    <div class="article-summary-box-inner">
                                        <span>Many applications such as election forecasting, environmental monitoring,
health policy, and graph based machine learning require taking expectation of
functions defined on the vertices of a graph. We describe a construction of a
sampling scheme analogous to the so called Leja points in complex potential
theory that can be proved to give low discrepancy estimates for the
approximation of the expected value by the impirical expected value based on
these points. In contrast to classical potential theory where the kernel is
fixed and the equilibrium distribution depends upon the kernel, we fix a
probability distribution and construct a kernel (which represents the graph
structure) for which the equilibrium distribution is the given probability
distribution. Our estimates do not depend upon the size of the graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the benefits of defining vicinal distributions in latent space. (arXiv:2003.06566v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mangla_P/0/1/0/all/0/1">Puneet Mangla</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1">Vedant Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1">Shreyas Jayant Havaldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1">Vineeth N Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06566">
                                    <div class="article-summary-box-inner">
                                        <span>The vicinal risk minimization (VRM) principle is an empirical risk
minimization (ERM) variant that replaces Dirac masses with vicinal functions.
There is strong numerical and theoretical evidence showing that VRM outperforms
ERM in terms of generalization if appropriate vicinal functions are chosen.
Mixup Training (MT), a popular choice of vicinal distribution, improves the
generalization performance of models by introducing globally linear behavior in
between training examples. Apart from generalization, recent works have shown
that mixup trained models are relatively robust to input
perturbations/corruptions and at the same time are calibrated better than their
non-mixup counterparts. In this work, we investigate the benefits of defining
these vicinal distributions like mixup in latent space of generative models
rather than in input space itself. We propose a new approach - \textit{VarMixup
(Variational Mixup)} - to better sample mixup images by using the latent
manifold underlying the data. Our empirical studies on CIFAR-10, CIFAR-100, and
Tiny-ImageNet demonstrate that models trained by performing mixup in the latent
manifold learned by VAEs are inherently more robust to various input
corruptions/perturbations, are significantly better calibrated, and exhibit
more local-linear loss landscapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms and Its Applications. (arXiv:1703.01610v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qinshi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1703.01610">
                                    <div class="article-summary-box-inner">
                                        <span>We study combinatorial multi-armed bandit with probabilistically triggered
arms (CMAB-T) and semi-bandit feedback. We resolve a serious issue in the prior
CMAB-T studies where the regret bounds contain a possibly exponentially large
factor of $1/p^*$, where $p^*$ is the minimum positive probability that an arm
is triggered by any action. We address this issue by introducing a triggering
probability modulated (TPM) bounded smoothness condition into the general
CMAB-T framework, and show that many applications such as influence
maximization bandit and combinatorial cascading bandit satisfy this TPM
condition. As a result, we completely remove the factor of $1/p^*$ from the
regret bounds, achieving significantly better regret bounds for influence
maximization and cascading bandits than before. Finally, we provide lower bound
results showing that the factor $1/p^*$ is unavoidable for general CMAB-T
problems, suggesting that the TPM condition is crucial in removing this factor.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Study of Assumptions in Bayesian Optimisation. (arXiv:2012.03826v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cowen_Rivers_A/0/1/0/all/0/1">Alexander I. Cowen-Rivers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_W/0/1/0/all/0/1">Wenlong Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1">Rasul Tutunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Grosnit_A/0/1/0/all/0/1">Antoine Grosnit</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_R/0/1/0/all/0/1">Ryan Rhys Griffiths</a>, <a href="http://arxiv.org/find/cs/1/au:+Jianye_H/0/1/0/all/0/1">Hao Jianye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Ammar_H/0/1/0/all/0/1">Haitham Bou Ammar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03826">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by the increasing desire to efficiently tune machine learning
hyper-parameters, in this work we rigorously analyse conventional and
non-conventional assumptions inherent to Bayesian optimisation. Across an
extensive set of experiments we conclude that: 1) the majority of
hyper-parameter tuning tasks exhibit heteroscedasticity and non-stationarity,
2) multi-objective acquisition ensembles with Pareto-front solutions
significantly improve queried configurations, and 3) robust acquisition
maximisation affords empirical advantages relative to its non-robust
counterparts. We hope these findings may serve as guiding principles, both for
practitioners and for further research in the field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super Tickets in Pre-Trained Language Models: From Model Compression to Improving Generalization. (arXiv:2105.12002v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1">Simiao Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minshuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haoming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tuo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12002">
                                    <div class="article-summary-box-inner">
                                        <span>The Lottery Ticket Hypothesis suggests that an over-parametrized network
consists of &#x60;&#x60;lottery tickets&#x27;&#x27;, and training a certain collection of them
(i.e., a subnetwork) can match the performance of the full model. In this
paper, we study such a collection of tickets, which is referred to as &#x60;&#x60;winning
tickets&#x27;&#x27;, in extremely over-parametrized models, e.g., pre-trained language
models. We observe that at certain compression ratios, the generalization
performance of the winning tickets can not only match but also exceed that of
the full model. In particular, we observe a phase transition phenomenon: As the
compression ratio increases, generalization performance of the winning tickets
first improves then deteriorates after a certain threshold. We refer to the
tickets on the threshold as &#x60;&#x60;super tickets&#x27;&#x27;. We further show that the phase
transition is task and model dependent -- as the model size becomes larger and
the training data set becomes smaller, the transition becomes more pronounced.
Our experiments on the GLUE benchmark show that the super tickets improve
single task fine-tuning by $0.9$ points on BERT-base and $1.0$ points on
BERT-large, in terms of task-average score. We also demonstrate that adaptively
sharing the super tickets across tasks benefits multi-task learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lattice Paths for Persistent Diagrams with Application to COVID-19 Virus Spike Proteins. (arXiv:2105.00351v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chung_M/0/1/0/all/0/1">Moo K. Chung</a>, <a href="http://arxiv.org/find/stat/1/au:+Ombao_H/0/1/0/all/0/1">Hernando Ombao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00351">
                                    <div class="article-summary-box-inner">
                                        <span>Topological data analysis, including persistent homology, has undergone
significant development in recent years. However, one outstanding challenge is
to build a coherent statistical inference procedure on persistent diagrams. The
paired dependent data structure, as birth and death in persistent diagrams,
adds additional complexity to the development. In this paper, we present a new
lattice path representation for persistent diagrams. A new exact statistical
inference procedure is developed for lattice paths via combinatorial
enumerations. The proposed lattice path method is applied to the topological
characterization of the protein structures of COVID-19 viruse. We demonstrate
that there are topological changes during the conformation change of spike
proteins that are needed to initiate the infection of host cells.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness Through Regularization for Learning to Rank. (arXiv:2102.05996v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1">Nikola Konstantinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1">Christoph H. Lampert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05996">
                                    <div class="article-summary-box-inner">
                                        <span>Given the abundance of applications of ranking in recent years, addressing
fairness concerns around automated ranking systems becomes necessary for
increasing the trust among end-users. Previous work on fair ranking has mostly
focused on application-specific fairness notions, often tailored to online
advertising, and it rarely considers learning as part of the process. In this
work, we show how to transfer numerous fairness notions from binary
classification to a learning to rank setting. Our formalism allows us to design
methods for incorporating fairness objectives with provable generalization
guarantees. An extensive experimental evaluation shows that our method can
improve ranking fairness substantially with no or only little loss of model
quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactuals and Causability in Explainable Artificial Intelligence: Theory, Algorithms, and Applications. (arXiv:2103.04244v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1">Yu-Liang Chou</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1">Catarina Moreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruza_P/0/1/0/all/0/1">Peter Bruza</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_C/0/1/0/all/0/1">Chun Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jorge_J/0/1/0/all/0/1">Joaquim Jorge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04244">
                                    <div class="article-summary-box-inner">
                                        <span>There has been a growing interest in model-agnostic methods that can make
deep learning models more transparent and explainable to a user. Some
researchers recently argued that for a machine to achieve a certain degree of
human-level explainability, this machine needs to provide human causally
understandable explanations, also known as causability. A specific class of
algorithms that have the potential to provide causability are counterfactuals.
This paper presents an in-depth systematic review of the diverse existing body
of literature on counterfactuals and causability for explainable artificial
intelligence. We performed an LDA topic modelling analysis under a PRISMA
framework to find the most relevant literature articles. This analysis resulted
in a novel taxonomy that considers the grounding theories of the surveyed
algorithms, together with their underlying properties and applications in
real-world data. This research suggests that current model-agnostic
counterfactual algorithms for explainable AI are not grounded on a causal
theoretical formalism and, consequently, cannot promote causability to a human
decision-maker. Our findings suggest that the explanations derived from major
algorithms in the literature provide spurious correlations rather than
cause/effects relationships, leading to sub-optimal, erroneous or even biased
explanations. This paper also advances the literature with new directions and
challenges on promoting causability in model-agnostic approaches for
explainable artificial intelligence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Universal Law of Robustness via Isoperimetry. (arXiv:2105.12806v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1">S&#xe9;bastien Bubeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1">Mark Sellke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12806">
                                    <div class="article-summary-box-inner">
                                        <span>Classically, data interpolation with a parametrized model class is possible
as long as the number of parameters is larger than the number of equations to
be satisfied. A puzzling phenomenon in deep learning is that models are trained
with many more parameters than what this classical theory would suggest. We
propose a theoretical explanation for this phenomenon. We prove that for a
broad class of data distributions and model classes, overparametrization is
necessary if one wants to interpolate the data smoothly. Namely we show that
smooth interpolation requires $d$ times more parameters than mere
interpolation, where $d$ is the ambient data dimension. We prove this universal
law of robustness for any smoothly parametrized function class with polynomial
size weights, and any covariate distribution verifying isoperimetry. In the
case of two-layers neural networks and Gaussian covariates, this law was
conjectured in prior work by Bubeck, Li and Nagaraj. We also give an
interpretation of our result as an improved generalization bound for model
classes consisting of smooth functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Greedy-Step Bellman Optimality Equation for Efficient Value Propagation. (arXiv:2102.11717v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiaoyang Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11717">
                                    <div class="article-summary-box-inner">
                                        <span>Efficiently propagating credit to responsible actions is a central and
challenging task in reinforcement learning. To accelerate information
propagation, this paper presents a new method that bridges a highway that
allows unimpeded information to flow across long horizons. The key to our
method is a newly proposed Bellman equation, called Greedy-Step Bellman
Optimality Equation, through which the high-credit information can fast
propagate across a long horizon. We theoretically show that the solution of the
new equation is exactly the optimal value function and the corresponding
operator converges faster than the classical operator. Besides, it leads to a
new multi-step off-policy algorithm, which is capable of safely utilizing any
off-policy data collected by the arbitrary policy. Experiments reveal that the
proposed method is reliable, easy to implement. Moreover, without employing
additional components of Rainbow except Double DQN, our method achieves
competitive performance with Rainbow on the benchmark tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Policy Gradient against Strong Data Corruption. (arXiv:2102.05800v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuezhou Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiding Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaojin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wen Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05800">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of robust reinforcement learning under adversarial
corruption on both rewards and transitions. Our attack model assumes an
\textit{adaptive} adversary who can arbitrarily corrupt the reward and
transition at every step within an episode, for at most $\epsilon$-fraction of
the learning episodes. Our attack model is strictly stronger than those
considered in prior works. Our first result shows that no algorithm can find a
better than $O(\epsilon)$-optimal policy under our attack model. Next, we show
that surprisingly the natural policy gradient (NPG) method retains a natural
robustness property if the reward corruption is bounded, and can find an
$O(\sqrt{\epsilon})$-optimal policy. Consequently, we develop a Filtered Policy
Gradient (FPG) algorithm that can tolerate even unbounded reward corruption and
can find an $O(\epsilon^{1/4})$-optimal policy. We emphasize that FPG is the
first that can achieve a meaningful learning guarantee when a constant fraction
of episodes are corrupted. Complimentary to the theoretical results, we show
that a neural implementation of FPG achieves strong robust learning performance
on the MuJoCo continuous control benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Local Pseudorandom Generators to Hardness of Learning. (arXiv:2101.08303v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daniely_A/0/1/0/all/0/1">Amit Daniely</a>, <a href="http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1">Gal Vardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08303">
                                    <div class="article-summary-box-inner">
                                        <span>We prove hardness-of-learning results under a well-studied assumption on the
existence of local pseudorandom generators. As we show, this assumption allows
us to surpass the current state of the art, and prove hardness of various basic
problems, with no hardness results to date.

Our results include: hardness of learning shallow ReLU neural networks under
the Gaussian distribution and other distributions; hardness of learning
intersections of $\omega(1)$ halfspaces, DNF formulas with $\omega(1)$ terms,
and ReLU networks with $\omega(1)$ hidden neurons; hardness of weakly learning
deterministic finite automata under the uniform distribution; hardness of
weakly learning depth-$3$ Boolean circuits under the uniform distribution, as
well as distribution-specific hardness results for learning DNF formulas and
intersections of halfspaces. We also establish lower bounds on the complexity
of learning intersections of a constant number of halfspaces, and ReLU networks
with a constant number of hidden neurons. Moreover, our results imply the
hardness of virtually all improper PAC-learning problems (both
distribution-free and distribution-specific) that were previously shown hard
under other assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Hyperparameter Tuning: Challenges, Baselines, and Connections to Weight-Sharing. (arXiv:2106.04502v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1">Mikhail Khodak</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_R/0/1/0/all/0/1">Renbo Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Liam Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1">Maria-Florina Balcan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1">Virginia Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1">Ameet Talwalkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04502">
                                    <div class="article-summary-box-inner">
                                        <span>Tuning hyperparameters is a crucial but arduous part of the machine learning
pipeline. Hyperparameter optimization is even more challenging in federated
learning, where models are learned over a distributed network of heterogeneous
devices; here, the need to keep data on device and perform local training makes
it difficult to efficiently train and evaluate configurations. In this work, we
investigate the problem of federated hyperparameter tuning. We first identify
key challenges and show how standard approaches may be adapted to form
baselines for the federated setting. Then, by making a novel connection to the
neural architecture search technique of weight-sharing, we introduce a new
method, FedEx, to accelerate federated hyperparameter tuning that is applicable
to widely-used federated optimization methods such as FedAvg and recent
variants. Theoretically, we show that a FedEx variant correctly tunes the
on-device learning rate in the setting of online convex optimization across
devices. Empirically, we show that FedEx can outperform natural baselines for
federated hyperparameter tuning by several percentage points on the
Shakespeare, FEMNIST, and CIFAR-10 benchmarks, obtaining higher accuracy using
the same training budget.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Regularization in ReLU Networks with the Square Loss. (arXiv:2012.05156v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1">Gal Vardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1">Ohad Shamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05156">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the implicit regularization (or implicit bias) of gradient
descent has recently been a very active research area. However, the implicit
regularization in nonlinear neural networks is still poorly understood,
especially for regression losses such as the square loss. Perhaps surprisingly,
we prove that even for a single ReLU neuron, it is impossible to characterize
the implicit regularization with the square loss by any explicit function of
the model parameters (although on the positive side, we show it can be
characterized approximately). For one hidden-layer networks, we prove a similar
result, where in general it is impossible to characterize implicit
regularization properties in this manner, except for the &quot;balancedness&quot;
property identified in Du et al. [2018]. Our results suggest that a more
general framework than the one considered so far may be needed to understand
implicit regularization for nonlinear predictors, and provides some clues on
what this framework should be.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-MLP: Node Classification without Message Passing in Graph. (arXiv:2106.04051v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1">Haoxuan You</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhecan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Erjin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04051">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Network (GNN) has been demonstrated its effectiveness in dealing
with non-Euclidean structural data. Both spatial-based and spectral-based GNNs
are relying on adjacency matrix to guide message passing among neighbors during
feature aggregation. Recent works have mainly focused on powerful message
passing modules, however, in this paper, we show that none of the message
passing modules is necessary. Instead, we propose a pure
multilayer-perceptron-based framework, Graph-MLP with the supervision signal
leveraging graph structure, which is sufficient for learning discriminative
node representation. In model-level, Graph-MLP only includes multi-layer
perceptrons, activation function, and layer normalization. In the loss level,
we design a neighboring contrastive (NContrast) loss to bridge the gap between
GNNs and MLPs by utilizing the adjacency information implicitly. This design
allows our model to be lighter and more robust when facing large-scale graph
data and corrupted adjacency information. Extensive experiments prove that even
without adjacency information in testing phase, our framework can still reach
comparable and even superior performance against the state-of-the-art models in
the graph node classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust R-Peak Detection in Low-Quality Holter ECGs using 1D Convolutional Neural Network. (arXiv:2101.01666v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zahid_M/0/1/0/all/0/1">Muhammad Uzair Zahid</a>, <a href="http://arxiv.org/find/eess/1/au:+Kiranyaz_S/0/1/0/all/0/1">Serkan Kiranyaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Ince_T/0/1/0/all/0/1">Turker Ince</a>, <a href="http://arxiv.org/find/eess/1/au:+Devecioglu_O/0/1/0/all/0/1">Ozer Can Devecioglu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chowdhury_M/0/1/0/all/0/1">Muhammad E. H. Chowdhury</a>, <a href="http://arxiv.org/find/eess/1/au:+Khandakar_A/0/1/0/all/0/1">Amith Khandakar</a>, <a href="http://arxiv.org/find/eess/1/au:+Tahir_A/0/1/0/all/0/1">Anas Tahir</a>, <a href="http://arxiv.org/find/eess/1/au:+Gabbouj_M/0/1/0/all/0/1">Moncef Gabbouj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01666">
                                    <div class="article-summary-box-inner">
                                        <span>Noise and low quality of ECG signals acquired from Holter or wearable devices
deteriorate the accuracy and robustness of R-peak detection algorithms. This
paper presents a generic and robust system for R-peak detection in Holter ECG
signals. While many proposed algorithms have successfully addressed the problem
of ECG R-peak detection, there is still a notable gap in the performance of
these detectors on such low-quality ECG records. Therefore, in this study, a
novel implementation of the 1D Convolutional Neural Network (CNN) is used
integrated with a verification model to reduce the number of false alarms. This
CNN architecture consists of an encoder block and a corresponding decoder block
followed by a sample-wise classification layer to construct the 1D segmentation
map of R- peaks from the input ECG signal. Once the proposed model has been
trained, it can solely be used to detect R-peaks possibly in a single channel
ECG data stream quickly and accurately, or alternatively, such a solution can
be conveniently employed for real-time monitoring on a lightweight portable
device. The model is tested on two open-access ECG databases: The China
Physiological Signal Challenge (2020) database (CPSC-DB) with more than one
million beats, and the commonly used MIT-BIH Arrhythmia Database (MIT-DB).
Experimental results demonstrate that the proposed systematic approach achieves
99.30% F1-score, 99.69% recall, and 98.91% precision in CPSC-DB, which is the
best R-peak detection performance ever achieved. Compared to all competing
methods, the proposed approach can reduce the false-positives and
false-negatives in Holter ECG signals by more than 54% and 82%, respectively.
Results also demonstrate similar or better performance than most competing
algorithms on MIT-DB with 99.83% F1-score, 99.85% recall, and 99.82% precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FastAdaBelief: Improving Convergence Rate for Belief-based Adaptive Optimizers by Exploiting Strong Convexity. (arXiv:2104.13790v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yangfan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Cheng Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1">Amir Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13790">
                                    <div class="article-summary-box-inner">
                                        <span>AdaBelief, one of the current best optimizers, demonstrates superior
generalization ability compared to the popular Adam algorithm by viewing the
exponential moving average of observed gradients. AdaBelief is theoretically
appealing in that it has a data-dependent $O(\sqrt{T})$ regret bound when
objective functions are convex, where $T$ is a time horizon. It remains however
an open problem whether the convergence rate can be further improved without
sacrificing its generalization ability. %on how to exploit strong convexity to
further improve the convergence rate of AdaBelief. To this end, we make a first
attempt in this work and design a novel optimization algorithm called
FastAdaBelief that aims to exploit its strong convexity in order to achieve an
even faster convergence rate. In particular, by adjusting the step size that
better considers strong convexity and prevents fluctuation, our proposed
FastAdaBelief demonstrates excellent generalization ability as well as superior
convergence. As an important theoretical contribution, we prove that
FastAdaBelief attains a data-dependant $O(\log T)$ regret bound, which is
substantially lower than AdaBelief. On the empirical side, we validate our
theoretical analysis with extensive experiments in both scenarios of strong and
non-strong convexity on three popular baseline models. Experimental results are
very encouraging: FastAdaBelief converges the quickest in comparison to all
mainstream algorithms while maintaining an excellent generalization ability, in
cases of both strong or non-strong convexity. FastAdaBelief is thus posited as
a new benchmark model for the research community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical VAEs Know What They Don&#x27;t Know. (arXiv:2102.08248v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Havtorn_J/0/1/0/all/0/1">Jakob D. Havtorn</a>, <a href="http://arxiv.org/find/cs/1/au:+Frellsen_J/0/1/0/all/0/1">Jes Frellsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Maaloe_L/0/1/0/all/0/1">Lars Maal&#xf8;e</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08248">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models have been demonstrated as state-of-the-art density
estimators. Yet, recent work has found that they often assign a higher
likelihood to data from outside the training distribution. This seemingly
paradoxical behavior has caused concerns over the quality of the attained
density estimates. In the context of hierarchical variational autoencoders, we
provide evidence to explain this behavior by out-of-distribution data having
in-distribution low-level features. We argue that this is both expected and
desirable behavior. With this insight in hand, we develop a fast, scalable and
fully unsupervised likelihood-ratio score for OOD detection that requires data
to be in-distribution across all feature-levels. We benchmark the method on a
vast set of data and model combinations and achieve state-of-the-art results on
out-of-distribution detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Vision Transformers. (arXiv:2106.04560v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04560">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based neural networks such as the Vision Transformer (ViT) have
recently attained state-of-the-art results on many computer vision benchmarks.
Scale is a primary ingredient in attaining excellent results, therefore,
understanding a model&#x27;s scaling properties is a key to designing future
generations effectively. While the laws for scaling Transformer language models
have been studied, it is unknown how Vision Transformers scale. To address
this, we scale ViT models and data, both up and down, and characterize the
relationships between error rate, data, and compute. Along the way, we refine
the architecture and training of ViT, reducing memory consumption and
increasing accuracy the resulting models. As a result, we successfully train a
ViT model with two billion parameters, which attains a new state-of-the-art on
ImageNet of 90.45% top-1 accuracy. The model also performs well on few-shot
learning, for example, attaining 84.86% top-1 accuracy on ImageNet with only 10
examples per class.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Balancing Geometry and Density: Path Distances on High-Dimensional Data. (arXiv:2012.09385v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Little_A/0/1/0/all/0/1">Anna Little</a>, <a href="http://arxiv.org/find/stat/1/au:+McKenzie_D/0/1/0/all/0/1">Daniel McKenzie</a>, <a href="http://arxiv.org/find/stat/1/au:+Murphy_J/0/1/0/all/0/1">James Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09385">
                                    <div class="article-summary-box-inner">
                                        <span>New geometric and computational analyses of power-weighted shortest-path
distances (PWSPDs) are presented. By illuminating the way these metrics balance
density and geometry in the underlying data, we clarify their key parameters
and discuss how they may be chosen in practice. Comparisons are made with
related data-driven metrics, which illustrate the broader role of density in
kernel-based unsupervised and semi-supervised machine learning.
Computationally, we relate PWSPDs on complete weighted graphs to their
analogues on weighted nearest neighbor graphs, providing high probability
guarantees on their equivalence that are near-optimal. Connections with
percolation theory are developed to establish estimates on the bias and
variance of PWSPDs in the finite sample setting. The theoretical results are
bolstered by illustrative experiments, demonstrating the versatility of PWSPDs
for a wide range of data settings. Throughout the paper, our results require
only that the underlying data is sampled from a low-dimensional manifold, and
depend crucially on the intrinsic dimension of this manifold, rather than its
ambient dimension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autoequivariant Network Search via Group Decomposition. (arXiv:2104.04848v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1">Sourya Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Magesh_A/0/1/0/all/0/1">Akshayaa Magesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_H/0/1/0/all/0/1">Harshit Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Varshney_L/0/1/0/all/0/1">Lav R. Varshney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04848">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works show that group equivariance as an inductive bias improves
neural network performance for both classification and generation. However,
designing group-equivariant neural networks is challenging when the group of
interest is large and is unknown. Moreover, inducing equivariance can
significantly reduce the number of independent parameters in a network with
fixed feature size, affecting its overall performance. We address these
problems by proving a new group-theoretic result in the context of equivariant
neural networks that shows that a network is equivariant to a large group if
and only if it is equivariant to smaller groups from which it is constructed.
Using this result, we design a novel fast group equivariant construction
algorithm, and a deep Q-learning-based search algorithm in a reduced search
space, yielding what we call autoequivariant networks (AENs). AENs find the
right balance between equivariance and network size when tested on new
benchmark datasets, G-MNIST and G-Fashion-MNIST, obtained via group
transformations on MNIST and Fashion-MNIST respectively that we release.
Extending these results to group convolutional neural networks, where we
optimize between equivariances, augmentations, and network sizes, we find group
equivariance to be the most dominating factor in all high-performing GCNNs on
several datasets like CIFAR10, SVHN, RotMNIST, ASL, EMNIST, and KMNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intriguing Properties of Vision Transformers. (arXiv:2105.10497v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1">Muzammal Naseer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1">Kanchana Ranasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayat_M/0/1/0/all/0/1">Munawar Hayat</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Fahad Shahbaz Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10497">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformers (ViT) have demonstrated impressive performance across
various machine vision problems. These models are based on multi-head
self-attention mechanisms that can flexibly attend to a sequence of image
patches to encode contextual cues. An important question is how such
flexibility in attending image-wide context conditioned on a given patch can
facilitate handling nuisances in natural images e.g., severe occlusions, domain
shifts, spatial permutations, adversarial and natural perturbations. We
systematically study this question via an extensive set of experiments
encompassing three ViT families and comparisons with a high-performing
convolutional neural network (CNN). We show and analyze the following
intriguing properties of ViT: (a) Transformers are highly robust to severe
occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1
accuracy on ImageNet even after randomly occluding 80% of the image content.
(b) The robust performance to occlusions is not due to a bias towards local
textures, and ViTs are significantly less biased towards textures compared to
CNNs. When properly trained to encode shape-based features, ViTs demonstrate
shape recognition capability comparable to that of human visual system,
previously unmatched in the literature. (c) Using ViTs to encode shape
representation leads to an interesting consequence of accurate semantic
segmentation without pixel-level supervision. (d) Off-the-shelf features from a
single ViT model can be combined to create a feature ensemble, leading to high
accuracy rates across a range of classification datasets in both traditional
and few-shot learning paradigms. We show effective features of ViTs are due to
flexible and dynamic receptive fields possible via the self-attention
mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-paced ensemble learning for speech and audio classification. (arXiv:2103.11988v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1">Nicolae-Catalin Ristea</a>, <a href="http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1">Radu Tudor Ionescu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11988">
                                    <div class="article-summary-box-inner">
                                        <span>Combining multiple machine learning models into an ensemble is known to
provide superior performance levels compared to the individual components
forming the ensemble. This is because models can complement each other in
taking better decisions. Instead of just combining the models, we propose a
self-paced ensemble learning scheme in which models learn from each other over
several iterations. During the self-paced learning process based on
pseudo-labeling, in addition to improving the individual models, our ensemble
also gains knowledge about the target domain. To demonstrate the generality of
our self-paced ensemble learning (SPEL) scheme, we conduct experiments on three
audio tasks. Our empirical results indicate that SPEL significantly outperforms
the baseline ensemble models. We also show that applying self-paced learning on
individual models is less effective, illustrating the idea that models in the
ensemble actually learn from each other.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proactive and AoI-aware Failure Recovery for Stateful NFV-enabled Zero-Touch 6G Networks: Model-Free DRL Approach. (arXiv:2103.03817v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shaghaghi_A/0/1/0/all/0/1">Amirhossein Shaghaghi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zakeri_A/0/1/0/all/0/1">Abolfazl Zakeri</a> (Student Member, IEEE), <a href="http://arxiv.org/find/eess/1/au:+Mokari_N/0/1/0/all/0/1">Nader Mokari</a> (Senior Member, IEEE), <a href="http://arxiv.org/find/eess/1/au:+Javan_M/0/1/0/all/0/1">Mohammad Reza Javan</a> (Senior Member, IEEE), <a href="http://arxiv.org/find/eess/1/au:+Behdadfar_M/0/1/0/all/0/1">Mohammad Behdadfar</a>, <a href="http://arxiv.org/find/eess/1/au:+Jorswieck_E/0/1/0/all/0/1">Eduard A Jorswieck</a> (Fellow, IEEE)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03817">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a Zero-Touch, deep reinforcement learning
(DRL)-based Proactive Failure Recovery framework called ZT-PFR for stateful
network function virtualization (NFV)-enabled networks. To this end, we
formulate a resource-efficient optimization problem minimizing the network cost
function including resource cost and wrong decision penalty. As a solution, we
propose state-of-the-art DRL-based methods such as soft-actor-critic (SAC) and
proximal-policy-optimization (PPO). In addition, to train and test our DRL
agents, we propose a novel impending failure model. Moreover, to keep network
status information at an acceptable freshness level for appropriate
decision-making, we apply the concept of age of information to strike a balance
between the event and scheduling-based monitoring. Several key systems and DRL
algorithm design insights for ZT-PFR are drawn from our analysis and simulation
results. For example, we use a hybrid neural network, consisting long
short-term memory layers in the DRL agents</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many-Speakers Single Channel Speech Separation with Optimal Permutation Training. (arXiv:2104.08955v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dovrat_S/0/1/0/all/0/1">Shaked Dovrat</a>, <a href="http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1">Eliya Nachmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08955">
                                    <div class="article-summary-box-inner">
                                        <span>Single channel speech separation has experienced great progress in the last
few years. However, training neural speech separation for a large number of
speakers (e.g., more than 10 speakers) is out of reach for the current methods,
which rely on the Permutation Invariant Loss (PIT). In this work, we present a
permutation invariant training that employs the Hungarian algorithm in order to
train with an $O(C^3)$ time complexity, where $C$ is the number of speakers, in
comparison to $O(C!)$ of PIT based methods. Furthermore, we present a modified
architecture that can handle the increased number of speakers. Our approach
separates up to $20$ speakers and improves the previous results for large $C$
by a wide margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Too-Good-to-be-True Prior to Reduce Shortcut Reliance. (arXiv:2102.06406v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dagaev_N/0/1/0/all/0/1">Nikolay Dagaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Roads_B/0/1/0/all/0/1">Brett D. Roads</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiaoliang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Barry_D/0/1/0/all/0/1">Daniel N. Barry</a>, <a href="http://arxiv.org/find/cs/1/au:+Patil_K/0/1/0/all/0/1">Kaustubh R. Patil</a>, <a href="http://arxiv.org/find/cs/1/au:+Love_B/0/1/0/all/0/1">Bradley C. Love</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06406">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their impressive performance in object recognition and other tasks
under standard testing conditions, deep networks often fail to generalize to
out-of-distribution (o.o.d.) samples. One cause for this shortcoming is that
modern architectures tend to rely on &quot;shortcuts&quot; - superficial features that
correlate with categories without capturing deeper invariants that hold across
contexts. Real-world concepts often possess a complex structure that can vary
superficially across contexts, which can make the most intuitive and promising
solutions in one context not generalize to others. One potential way to improve
o.o.d. generalization is to assume simple solutions are unlikely to be valid
across contexts and avoid them, which we refer to as the too-good-to-be-true
prior. A low-capacity network (LCN) with a shallow architecture should only be
able to learn surface relationships, including shortcuts. We find that LCNs can
serve as shortcut detectors. Furthermore, an LCN&#x27;s predictions can be used in a
two-stage approach to encourage a high-capacity network (HCN) to rely on deeper
invariant features that should generalize broadly. In particular, items that
the LCN can master are downweighted when training the HCN. Using a modified
version of the CIFAR-10 dataset in which we introduced shortcuts, we found that
the two-stage LCN-HCN approach reduced reliance on shortcuts and facilitated
o.o.d. generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PILOT: Introducing Transformers for Probabilistic Sound Event Localization. (arXiv:2106.03903v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schymura_C/0/1/0/all/0/1">Christopher Schymura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonninghoff_B/0/1/0/all/0/1">Benedikt B&#xf6;nninghoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochiai_T/0/1/0/all/0/1">Tsubasa Ochiai</a>, <a href="http://arxiv.org/find/cs/1/au:+Delcroix_M/0/1/0/all/0/1">Marc Delcroix</a>, <a href="http://arxiv.org/find/cs/1/au:+Kinoshita_K/0/1/0/all/0/1">Keisuke Kinoshita</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakatani_T/0/1/0/all/0/1">Tomohiro Nakatani</a>, <a href="http://arxiv.org/find/cs/1/au:+Araki_S/0/1/0/all/0/1">Shoko Araki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolossa_D/0/1/0/all/0/1">Dorothea Kolossa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03903">
                                    <div class="article-summary-box-inner">
                                        <span>Sound event localization aims at estimating the positions of sound sources in
the environment with respect to an acoustic receiver (e.g. a microphone array).
Recent advances in this domain most prominently focused on utilizing deep
recurrent neural networks. Inspired by the success of transformer architectures
as a suitable alternative to classical recurrent neural networks, this paper
introduces a novel transformer-based sound event localization framework, where
temporal dependencies in the received multi-channel audio signals are captured
via self-attention mechanisms. Additionally, the estimated sound event
positions are represented as multivariate Gaussian variables, yielding an
additional notion of uncertainty, which many previously proposed deep
learning-based systems designed for this application do not provide. The
framework is evaluated on three publicly available multi-source sound event
localization datasets and compared against state-of-the-art methods in terms of
localization error and event detection accuracy. It outperforms all competing
systems on all datasets with statistical significant differences in
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batch Reinforcement Learning with a Nonparametric Off-Policy Policy Gradient. (arXiv:2010.14771v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tosatto_S/0/1/0/all/0/1">Samuele Tosatto</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_J/0/1/0/all/0/1">Jo&#xe3;o Carvalho</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14771">
                                    <div class="article-summary-box-inner">
                                        <span>Off-policy Reinforcement Learning (RL) holds the promise of better data
efficiency as it allows sample reuse and potentially enables safe interaction
with the environment. Current off-policy policy gradient methods either suffer
from high bias or high variance, delivering often unreliable estimates. The
price of inefficiency becomes evident in real-world scenarios such as
interaction-driven robot learning, where the success of RL has been rather
limited, and a very high sample cost hinders straightforward application. In
this paper, we propose a nonparametric Bellman equation, which can be solved in
closed form. The solution is differentiable w.r.t the policy parameters and
gives access to an estimation of the policy gradient. In this way, we avoid the
high variance of importance sampling approaches, and the high bias of
semi-gradient methods. We empirically analyze the quality of our gradient
estimate against state-of-the-art methods, and show that it outperforms the
baselines in terms of sample efficiency on classical control tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection of marine floating plastic using Sentinel-2 imagery and machine learning models. (arXiv:2106.03694v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sannigrahi_S/0/1/0/all/0/1">Srikanta Sannigrahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_B/0/1/0/all/0/1">Bidroha Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1">Arunima Sarkar Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilla_F/0/1/0/all/0/1">Francesco Pilla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03694">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing level of marine plastic pollution poses severe threats to the
marine ecosystem and biodiversity. The present study attempted to explore the
full functionality of open Sentinel satellite data and ML models for detecting
and classifying floating plastic debris in Mytilene (Greece), Limassol
(Cyprus), Calabria (Italy), and Beirut (Lebanon). Two ML models, i.e. Support
Vector Machine (SVM) and Random Forest (RF) were utilized to carry out the
classification analysis. In-situ plastic location data was collected from the
control experiment conducted in Mytilene, Greece and Limassol, Cyprus, and the
same was considered for training the models. Both remote sensing bands and
spectral indices were used for developing the ML models. A spectral signature
profile for plastic was created for discriminating the floating plastic from
other marine debris. A newly developed index, kernel Normalized Difference
Vegetation Index (kNDVI), was incorporated into the modelling to examine its
contribution to model performances. Both SVM and RF were performed well in five
models and test case combinations. Among the two ML models, the highest
performance was measured for the RF. The inclusion of kNDVI was found effective
and increased the model performances, reflected by high balanced accuracy
measured for model 2 (~80% to ~98 % for SVM and ~87% to ~97 % for RF). Using
the best-performed model, an automated floating plastic detection system was
developed and tested in Calabria and Beirut. For both sites, the trained model
had detected the floating plastic with ~99% accuracy. Among the six predictors,
the FDI was found the most important variable for detecting marine floating
plastic. These findings collectively suggest that high-resolution remote
sensing imagery and the automated ML models can be an effective alternative for
the cost-effective detection of marine floating plastic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample-Efficient Learning of Stackelberg Equilibria in General-Sum Games. (arXiv:2102.11494v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yu Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11494">
                                    <div class="article-summary-box-inner">
                                        <span>Real world applications such as economics and policy making often involve
solving multi-agent games with two unique features: (1) The agents are
inherently asymmetric and partitioned into leaders and followers; (2) The
agents have different reward functions, thus the game is general-sum. The
majority of existing results in this field focuses on either symmetric solution
concepts (e.g. Nash equilibrium) or zero-sum games. It remains vastly open how
to learn the Stackelberg equilibrium -- an asymmetric analog of the Nash
equilibrium -- in general-sum games efficiently from samples.

This paper initiates the theoretical study of sample-efficient learning of
the Stackelberg equilibrium, in the bandit feedback setting where we only
observe noisy samples of the reward. We consider three representative
two-player general-sum games: bandit games, bandit-reinforcement learning
(bandit-RL) games, and linear bandit games. In all these games, we identify a
fundamental gap between the exact value of the Stackelberg equilibrium and its
estimated version using finitely many noisy samples, which can not be closed
information-theoretically regardless of the algorithm. We then establish sharp
positive results on sample-efficient learning of Stackelberg equilibrium with
value optimal up to the gap identified above, with matching lower bounds in the
dependency on the gap, error tolerance, and the size of the action spaces.
Overall, our results unveil unique challenges in learning Stackelberg
equilibria under noisy bandit feedback, which we hope could shed light on
future research on this topic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes. (arXiv:2102.12894v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sangalli_S/0/1/0/all/0/1">Sara Sangalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdil_E/0/1/0/all/0/1">Ertunc Erdil</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoetker_A/0/1/0/all/0/1">Andreas Hoetker</a>, <a href="http://arxiv.org/find/cs/1/au:+Donati_O/0/1/0/all/0/1">Olivio Donati</a>, <a href="http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1">Ender Konukoglu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12894">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are notorious for making more mistakes for the
classes that have substantially fewer samples than the others during training.
Such class imbalance is ubiquitous in clinical applications and very crucial to
handle because the classes with fewer samples most often correspond to critical
cases (e.g., cancer) where misclassifications can have severe consequences. Not
to miss such cases, binary classifiers need to be operated at high True
Positive Rates (TPR) by setting a higher threshold but this comes at the cost
of very high False Positive Rates (FPR) for problems with class imbalance.
Existing methods for learning under class imbalance most often do not take this
into account. We argue that prediction accuracy should be improved by
emphasizing reducing FPRs at high TPRs for problems where misclassification of
the positive, i.e., critical, class samples are associated with higher cost. To
this end, we pose the training of a DNN for binary classification as a
constrained optimization problem and introduce a novel constraint that can be
used with existing loss functions to enforce maximal area under the ROC curve
(AUC) through prioritizing FPR reduction at high TPR. We solve the resulting
constrained optimization problem using an Augmented Lagrangian method (ALM).
Going beyond binary, we also propose two possible extensions of the proposed
constraint for multi-class classification problems. We present experimental
results for image-based binary and multi-class classification applications
using an in-house medical imaging dataset, CIFAR10, and CIFAR100. Our results
demonstrate that the proposed method improves the baselines in majority of the
cases by attaining higher accuracy on critical classes while reducing the
misclassification rate for the non-critical class samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine Imitation Learning: Robot Manipulation from a Single Demonstration. (arXiv:2105.06411v1 [cs.RO] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1">Edward Johns</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06411">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a simple new method for visual imitation learning, which allows
a novel robot manipulation task to be learned from a single human
demonstration, without requiring any prior knowledge of the object being
interacted with. Our method models imitation learning as a state estimation
problem, with the state defined as the end-effector&#x27;s pose at the point where
object interaction begins, as observed from the demonstration. By modelling a
manipulation task as a coarse, approach trajectory followed by a fine,
interaction trajectory, this state estimator can be trained in a
self-supervised manner, by automatically moving the end-effector&#x27;s camera
around the object. At test time, the end-effector is moved to the estimated
state through a linear path, at which point the demonstration&#x27;s end-effector
velocities are simply repeated, enabling convenient acquisition of a complex
interaction trajectory without actually needing to explicitly learn a policy.
Real-world experiments on 8 everyday tasks show that our method can learn a
diverse range of skills from just a single human demonstration, whilst also
yielding a stable and interpretable controller.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential- and Parallel- Constrained Max-value Entropy Search via Information Lower Bound. (arXiv:2102.09788v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takeno_S/0/1/0/all/0/1">Shion Takeno</a>, <a href="http://arxiv.org/find/cs/1/au:+Tamura_T/0/1/0/all/0/1">Tomoyuki Tamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Shitara_K/0/1/0/all/0/1">Kazuki Shitara</a>, <a href="http://arxiv.org/find/cs/1/au:+Karasuyama_M/0/1/0/all/0/1">Masayuki Karasuyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09788">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is known as a powerful tool for optimizing an
unknown, expensive function through querying the function values sequentially.
On the other hand, in many practical problems, additional unknown constraints
also need to be considered. In this paper, we propose an information-theoretic
approach called Constrained Max-value Entropy Search via Information lower
BOund (CMES-IBO) for the constrained BO (CBO). Although information-theoretic
methods have been studied in CBO literature, they have not revealed any
relation between their acquisition functions and the original mutual
information. In contrast, our acquisition function is an unbiased consistent
estimator of a lower bound of mutual information. We show that our CMES-IBO has
several advantageous properties such as non-negativity, estimation error bounds
of the acquisition function, and well-definedness of the criterion, none of
which have been shown for the existing information-theoretic CBO. Furthermore,
by using conditional mutual information, we extend CMES-IBO to the parallel
setting in which multiple queries can be issued simultaneously. We demonstrate
the effectiveness of CMES-IBO by several benchmark functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mean-Shifted Contrastive Loss for Anomaly Detection. (arXiv:2106.03844v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiss_T/0/1/0/all/0/1">Tal Reiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1">Yedid Hoshen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Deep anomaly detection methods learn representations that separate between
normal and anomalous samples. Very effective representations are obtained when
powerful externally trained feature extractors (e.g. ResNets pre-trained on
ImageNet) are fine-tuned on the training data which consists of normal samples
and no anomalies. However, this is a difficult task that can suffer from
catastrophic collapse, i.e. it is prone to learning trivial and non-specific
features. In this paper, we propose a new loss function which can overcome
failure modes of both center-loss and contrastive-loss methods. Furthermore, we
combine it with a confidence-invariant angular center loss, which replaces the
Euclidean distance used in previous work, that was sensitive to prediction
confidence. Our improvements yield a new anomaly detection approach, based on
$\textit{Mean-Shifted Contrastive Loss}$, which is both more accurate and less
sensitive to catastrophic collapse than previous methods. Our method achieves
state-of-the-art anomaly detection performance on multiple benchmarks including
$97.5\%$ ROC-AUC on the CIFAR-10 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ForecastQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data. (arXiv:2005.00792v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1">Woojeong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khanna_R/0/1/0/all/0/1">Rahul Khanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Suji Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dong-Ho Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1">Fred Morstatter</a>, <a href="http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1">Aram Galstyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00792">
                                    <div class="article-summary-box-inner">
                                        <span>Event forecasting is a challenging, yet important task, as humans seek to
constantly plan for the future. Existing automated forecasting studies rely
mostly on structured data, such as time-series or event-based knowledge graphs,
to help predict future events. In this work, we aim to formulate a task,
construct a dataset, and provide benchmarks for developing methods for event
forecasting with large volumes of unstructured text data. To simulate the
forecasting scenario on temporal news documents, we formulate the problem as a
restricted-domain, multiple-choice, question-answering (QA) task. Unlike
existing QA tasks, our task limits accessible information, and thus a model has
to make a forecasting judgement. To showcase the usefulness of this task
formulation, we introduce ForecastQA, a question-answering dataset consisting
of 10,392 event forecasting questions, which have been collected and verified
via crowdsourcing efforts. We present our experiments on ForecastQA using
BERT-based models and find that our best model achieves 60.1% accuracy on the
dataset, which still lags behind human performance by about 19%. We hope
ForecastQA will support future research efforts in bridging this gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Thompson Sampling using Sparse Gaussian Process Models. (arXiv:2006.05356v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vakili_S/0/1/0/all/0/1">Sattar Vakili</a>, <a href="http://arxiv.org/find/stat/1/au:+Moss_H/0/1/0/all/0/1">Henry Moss</a>, <a href="http://arxiv.org/find/stat/1/au:+Artemev_A/0/1/0/all/0/1">Artem Artemev</a>, <a href="http://arxiv.org/find/stat/1/au:+Dutordoir_V/0/1/0/all/0/1">Vincent Dutordoir</a>, <a href="http://arxiv.org/find/stat/1/au:+Picheny_V/0/1/0/all/0/1">Victor Picheny</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05356">
                                    <div class="article-summary-box-inner">
                                        <span>Thompson Sampling (TS) from Gaussian Process (GP) models is a powerful tool
for the optimization of black-box functions. Although TS enjoys strong
theoretical guarantees and convincing empirical performance, it incurs a large
computational overhead that scales polynomially with the optimization budget.
Recently, scalable TS methods based on sparse GP models have been proposed to
increase the scope of TS, enabling its application to problems that are
sufficiently multi-modal, noisy or combinatorial to require more than a few
hundred evaluations to be solved. However, the approximation error introduced
by sparse GPs invalidates all existing regret bounds. In this work, we perform
a theoretical and empirical analysis of scalable TS. We provide theoretical
guarantees and show that the drastic reduction in computational complexity of
scalable TS can be enjoyed without loss in the regret performance over the
standard TS. These conceptual claims are validated for practical
implementations of scalable TS on synthetic benchmarks and as part of a
real-world high-throughput molecular design task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Binary Neural Network Training on the Edge. (arXiv:2102.04270v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1">Erwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James J. Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Moro_D/0/1/0/all/0/1">Daniele Moro</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_P/0/1/0/all/0/1">Piotr Zielinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Coelho_C/0/1/0/all/0/1">Claudionor Coelho</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1">Satrajit Chatterjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_P/0/1/0/all/0/1">Peter Y. K. Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Constantinides_G/0/1/0/all/0/1">George A. Constantinides</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04270">
                                    <div class="article-summary-box-inner">
                                        <span>The ever-growing computational demands of increasingly complex machine
learning models frequently necessitate the use of powerful cloud-based
infrastructure for their training. Binary neural networks are known to be
promising candidates for on-device inference due to their extreme compute and
memory savings over higher-precision alternatives. However, their existing
training methods require the concurrent storage of high-precision activations
for all layers, generally making learning on memory-constrained devices
infeasible. In this paper, we demonstrate that the backward propagation
operations needed for binary neural network training are strongly robust to
quantization, thereby making on-the-edge learning with modern models a
practical proposition. We introduce a low-cost binary neural network training
strategy exhibiting sizable memory footprint and energy reductions while
inducing little to no accuracy loss vs Courbariaux &amp; Bengio&#x27;s standard
approach. These resource decreases are primarily enabled through the retention
of activations exclusively in binary format. Against the latter algorithm, our
drop-in replacement sees coincident memory requirement and energy consumption
drops of 2--6$\times$, while reaching similar test accuracy in comparable time,
across a range of small-scale models trained to classify popular datasets. We
also demonstrate from-scratch ImageNet training of binarized ResNet-18,
achieving a 3.12$\times$ memory reduction. Such savings will allow for
unnecessary cloud offloading to be avoided, reducing latency, increasing energy
efficiency and safeguarding privacy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MoCL: Contrastive Learning on Molecular Graphs with Multi-level Domain Knowledge. (arXiv:2106.04509v1 [physics.bio-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Sun_M/0/1/0/all/0/1">Mengying Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Xing_J/0/1/0/all/0/1">Jing Xing</a>, <a href="http://arxiv.org/find/physics/1/au:+Wang_H/0/1/0/all/0/1">Huijun Wang</a>, <a href="http://arxiv.org/find/physics/1/au:+Chen_B/0/1/0/all/0/1">Bin Chen</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhou_J/0/1/0/all/0/1">Jiayu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04509">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen a rapid growth of utilizing graph neural networks
(GNNs) in the biomedical domain for tackling drug-related problems. However,
like any other deep architectures, GNNs are data hungry. While requiring labels
in real world is often expensive, pretraining GNNs in an unsupervised manner
has been actively explored. Among them, graph contrastive learning, by
maximizing the mutual information between paired graph augmentations, has been
shown to be effective on various downstream tasks. However, the current graph
contrastive learning framework has two limitations. First, the augmentations
are designed for general graphs and thus may not be suitable or powerful enough
for certain domains. Second, the contrastive scheme only learns representations
that are invariant to local perturbations and thus does not consider the global
structure of the dataset, which may also be useful for downstream tasks.
Therefore, in this paper, we study graph contrastive learning in the context of
biomedical domain, where molecular graphs are present. We propose a novel
framework called MoCL, which utilizes domain knowledge at both local- and
global-level to assist representation learning. The local-level domain
knowledge guides the augmentation process such that variation is introduced
without changing graph semantics. The global-level knowledge encodes the
similarity information between graphs in the entire dataset and helps to learn
representations with richer semantics. The entire model is learned through a
double contrast objective. We evaluate MoCL on various molecular datasets under
both linear and semi-supervised settings and results show that MoCL achieves
state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Worst-Case Regret Bounds for Randomized Least-Squares Value Iteration. (arXiv:2010.12163v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Priyank Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jinglin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12163">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies regret minimization with randomized value functions in
reinforcement learning. In tabular finite-horizon Markov Decision Processes, we
introduce a clipping variant of one classical Thompson Sampling (TS)-like
algorithm, randomized least-squares value iteration (RLSVI). Our
$\tilde{\mathrm{O}}(H^2S\sqrt{AT})$ high-probability worst-case regret bound
improves the previous sharpest worst-case regret bounds for RLSVI and matches
the existing state-of-the-art worst-case TS-based regret bounds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Softmax Policy Gradient Methods Can Take Exponential Time to Converge. (arXiv:2102.11270v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yuting Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1">Yuejie Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yuantao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11270">
                                    <div class="article-summary-box-inner">
                                        <span>The softmax policy gradient (PG) method, which performs gradient ascent under
softmax policy parameterization, is arguably one of the de facto
implementations of policy optimization in modern reinforcement learning. For
$\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs),
remarkable progress has recently been achieved towards establishing global
convergence of softmax PG methods in finding a near-optimal policy. However,
prior results fall short of delineating clear dependencies of convergence rates
on salient parameters such as the cardinality of the state space $\mathcal{S}$
and the effective horizon $\frac{1}{1-\gamma}$, both of which could be
excessively large. In this paper, we deliver a pessimistic message regarding
the iteration complexity of softmax PG methods, despite assuming access to
exact gradient computation. Specifically, we demonstrate that the softmax PG
method with stepsize $\eta$ can take \[

\frac{1}{\eta} |\mathcal{S}|^{2^{\Omega\big(\frac{1}{1-\gamma}\big)}}
~\text{iterations} \] to converge, even in the presence of a benign policy
initialization and an initial state distribution amenable to exploration (so
that the distribution mismatch coefficient is not exceedingly large). This is
accomplished by characterizing the algorithmic dynamics over a
carefully-constructed MDP containing only three actions. Our exponential lower
bound hints at the necessity of carefully adjusting update rules or enforcing
proper regularization in accelerating PG methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximation and Learning with Deep Convolutional Models: a Kernel Perspective. (arXiv:2102.10032v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1">Alberto Bietti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10032">
                                    <div class="article-summary-box-inner">
                                        <span>The empirical success of deep convolutional networks on tasks involving
high-dimensional data such as images or audio suggests that they can
efficiently approximate certain functions that are well-suited for such tasks.
In this paper, we study this through the lens of kernel methods, by considering
simple hierarchical kernels with two or three convolution and pooling layers,
inspired by convolutional kernel networks. These achieve good empirical
performance on standard vision datasets, while providing a simple enough
description of the functional space to shed light on their inductive bias. We
show that the RKHS consists of additive models of interaction terms between
patches, and that its norm encourages structured spatial similarities between
these terms through pooling layers. We then provide generalization bounds which
illustrate how pooling yields improved sample complexity guarantees when the
target function presents such regularities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Image Reconstruction using Deep Generative Models. (arXiv:2012.04567v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marinescu_R/0/1/0/all/0/1">Razvan V Marinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moyer_D/0/1/0/all/0/1">Daniel Moyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Golland_P/0/1/0/all/0/1">Polina Golland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04567">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models are commonly trained end-to-end and in a supervised
setting, using paired (input, output) data. Examples include recent
super-resolution methods that train on pairs of (low-resolution,
high-resolution) images. However, these end-to-end approaches require
re-training every time there is a distribution shift in the inputs (e.g., night
images vs daylight) or relevant latent variables (e.g., camera blur or hand
motion). In this work, we leverage state-of-the-art (SOTA) generative models
(here StyleGAN2) for building powerful image priors, which enable application
of Bayes&#x27; theorem for many downstream reconstruction tasks. Our method,
Bayesian Reconstruction through Generative Models (BRGM), uses a single
pre-trained generator model to solve different image restoration tasks, i.e.,
super-resolution and in-painting, by combining it with different forward
corruption models. We keep the weights of the generator model fixed, and
reconstruct the image by estimating the Bayesian maximum a-posteriori (MAP)
estimate over the input latent vector that generated the reconstructed image.
We further use variational inference to approximate the posterior distribution
over the latent vectors, from which we sample multiple solutions. We
demonstrate BRGM on three large and diverse datasets: (i) 60,000 images from
the Flick Faces High Quality dataset (ii) 240,000 chest X-rays from MIMIC III
and (iii) a combined collection of 5 brain MRI datasets with 7,329 scans.
Across all three datasets and without any dataset-specific hyperparameter
tuning, our simple approach yields performance competitive with current
task-specific state-of-the-art methods on super-resolution and in-painting,
while being more generalisable and without requiring any training. Our source
code and pre-trained models are available online:
https://razvanmarinescu.github.io/brgm/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GSGP-CUDA -- a CUDA framework for Geometric Semantic Genetic Programming. (arXiv:2106.04034v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trujillo_L/0/1/0/all/0/1">Leonardo Trujillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Contreras_J/0/1/0/all/0/1">Jose Manuel Mu&#xf1;oz Contreras</a>, <a href="http://arxiv.org/find/cs/1/au:+Hernandez_D/0/1/0/all/0/1">Daniel E Hernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Castelli_M/0/1/0/all/0/1">Mauro Castelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tapia_J/0/1/0/all/0/1">Juan J Tapia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04034">
                                    <div class="article-summary-box-inner">
                                        <span>Geometric Semantic Genetic Programming (GSGP) is a state-of-the-art machine
learning method based on evolutionary computation. GSGP performs search
operations directly at the level of program semantics, which can be done more
efficiently then operating at the syntax level like most GP systems. Efficient
implementations of GSGP in C++ exploit this fact, but not to its full
potential. This paper presents GSGP-CUDA, the first CUDA implementation of GSGP
and the most efficient, which exploits the intrinsic parallelism of GSGP using
GPUs. Results show speedups greater than 1,000X relative to the
state-of-the-art sequential implementation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language-Mediated, Object-Centric Representation Learning. (arXiv:2012.15814v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruocheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1">Jiayuan Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1">Samuel J. Gershman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15814">
                                    <div class="article-summary-box-inner">
                                        <span>We present Language-mediated, Object-centric Representation Learning (LORL),
a paradigm for learning disentangled, object-centric scene representations from
vision and language. LORL builds upon recent advances in unsupervised object
discovery and segmentation, notably MONet and Slot Attention. While these
algorithms learn an object-centric representation just by reconstructing the
input image, LORL enables them to further learn to associate the learned
representations to concepts, i.e., words for object categories, properties, and
spatial relationships, from language input. These object-centric concepts
derived from language facilitate the learning of object-centric
representations. LORL can be integrated with various unsupervised object
discovery algorithms that are language-agnostic. Experiments show that the
integration of LORL consistently improves the performance of unsupervised
object discovery methods on two datasets via the help of language. We also show
that concepts learned by LORL, in conjunction with object discovery methods,
aid downstream tasks such as referring expression comprehension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Recombine and Resample Data for Compositional Generalization. (arXiv:2010.03706v6 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1">Ekin Aky&#xfc;rek</a>, <a href="http://arxiv.org/find/cs/1/au:+Akyurek_A/0/1/0/all/0/1">Afra Feyza Aky&#xfc;rek</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03706">
                                    <div class="article-summary-box-inner">
                                        <span>Flexible neural sequence models outperform grammar- and automaton-based
counterparts on a variety of tasks. However, neural models perform poorly in
settings requiring compositional generalization beyond the training data --
particularly to rare or unseen subsequences. Past work has found symbolic
scaffolding (e.g. grammars or automata) essential in these settings. We
describe R&amp;R, a learned data augmentation scheme that enables a large category
of compositional generalizations without appeal to latent symbolic structure.
R&amp;R has two components: recombination of original training examples via a
prototype-based generative model and resampling of generated examples to
encourage extrapolation. Training an ordinary neural sequence model on a
dataset augmented with recombined and resampled examples significantly improves
generalization in two language processing problems -- instruction following
(SCAN) and morphological analysis (SIGMORPHON 2018) -- where R&amp;R enables
learning of new constructions and tenses from as few as eight initial examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SWAD: Domain Generalization by Seeking Flat Minima. (arXiv:2102.08604v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cha_J/0/1/0/all/0/1">Junbum Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1">Sanghyuk Chun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyungjae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Han-Cheol Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Seunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yunsung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sungrae Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08604">
                                    <div class="article-summary-box-inner">
                                        <span>Domain generalization (DG) methods aim to achieve generalizability to an
unseen target domain by using only training data from the source domains.
Although a variety of DG methods have been proposed, a recent study shows that
under a fair evaluation protocol, called DomainBed, the simple empirical risk
minimization (ERM) approach works comparable to or even outperforms previous
methods. Unfortunately, simply solving ERM on a complex, non-convex loss
function can easily lead to sub-optimal generalizability by seeking sharp
minima. In this paper, we theoretically show that finding flat minima results
in a smaller domain generalization gap. We also propose a simple yet effective
method, named Stochastic Weight Averaging Densely (SWAD), to find flat minima.
SWAD finds flatter minima and suffers less from overfitting than does the
vanilla SWA by a dense and overfit-aware stochastic weight sampling strategy.
SWAD shows state-of-the-art performances on five DG benchmarks, namely PACS,
VLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large
margins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with
conventional generalization methods, such as data augmentation and consistency
regularization methods, to verify that the remarkable performance improvements
are originated from by seeking flat minima, not from better in-domain
generalizability. Last but not least, SWAD is readily adaptable to existing DG
methods without modification; the combination of SWAD and an existing DG method
further improves DG performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic selection of clustering algorithms using supervised graph embedding. (arXiv:2011.08225v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_Shapira_N/0/1/0/all/0/1">Noy Cohen-Shapira</a>, <a href="http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1">Lior Rokach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08225">
                                    <div class="article-summary-box-inner">
                                        <span>The widespread adoption of machine learning (ML) techniques and the extensive
expertise required to apply them have led to increased interest in automated ML
solutions that reduce the need for human intervention. One of the main
challenges in applying ML to previously unseen problems is algorithm selection
- the identification of high-performing algorithm(s) for a given dataset, task,
and evaluation measure. This study addresses the algorithm selection challenge
for data clustering, a fundamental task in data mining that is aimed at
grouping similar objects. We present MARCO-GE, a novel meta-learning approach
for the automated recommendation of clustering algorithms. MARCO-GE first
transforms datasets into graphs and then utilizes a graph convolutional neural
network technique to extract their latent representation. Using the embedding
representations obtained, MARCO-GE trains a ranking meta-model capable of
accurately recommending top-performing algorithms for a new dataset and
clustering evaluation measure. Extensive evaluation on 210 datasets, 13
clustering algorithms, and 10 clustering measures demonstrates the
effectiveness of our approach and its superiority in terms of predictive and
generalization performance over state-of-the-art clustering meta-learning
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Reordering for Modeling Latent Alignments in Sequence Transduction. (arXiv:2106.03257v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bailin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1">Mirella Lapata</a>, <a href="http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1">Ivan Titov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03257">
                                    <div class="article-summary-box-inner">
                                        <span>Despite success in many domains, neural models struggle in settings where
train and test examples are drawn from different distributions. In particular,
in contrast to humans, conventional sequence-to-sequence (seq2seq) models fail
to generalize systematically, i.e., interpret sentences representing novel
combinations of concepts (e.g., text segments) seen in training. Traditional
grammar formalisms excel in such settings by implicitly encoding alignments
between input and output segments, but are hard to scale and maintain. Instead
of engineering a grammar, we directly model segment-to-segment alignments as
discrete structured latent variables within a neural seq2seq model. To
efficiently explore the large space of alignments, we introduce a reorder-first
align-later framework whose central component is a neural reordering module
producing {\it separable} permutations. We present an efficient dynamic
programming algorithm performing exact marginal inference of separable
permutations, and, thus, enabling end-to-end differentiable training of our
model. The resulting seq2seq model exhibits better systematic generalization
than standard models on synthetic problems and NLP tasks (i.e., semantic
parsing and machine translation).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of Anomaly Detectors: Context Matters. (arXiv:2012.06260v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Skvara_V/0/1/0/all/0/1">V&#xed;t &#x160;kv&#xe1;ra</a>, <a href="http://arxiv.org/find/cs/1/au:+Franc%5Cr%7Bu%7D_J/0/1/0/all/0/1">Jan Franc&#x16f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Zorek_M/0/1/0/all/0/1">Mat&#x11b;j Zorek</a>, <a href="http://arxiv.org/find/cs/1/au:+Pevny_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Pevn&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Smidl_V/0/1/0/all/0/1">V&#xe1;clav &#x160;m&#xed;dl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06260">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models are challenging the classical methods in the field of
anomaly detection nowadays. Every new method provides evidence of outperforming
its predecessors, often with contradictory results. The objective of this
comparison is twofold: to compare anomaly detection methods of various
paradigms with focus on deep generative models, and identification of sources
of variability that can yield different results. The methods were compared on
popular tabular and image datasets. We identified the main sources of
variability to be experimental conditions: i) the type data set (tabular or
image) and the nature of anomalies (statistical or semantic), and ii) strategy
of selection of hyperparameters, especially the number of available anomalies
in the validation set. Different methods perform the best in different
contexts, i.e. combination of experimental conditions together with
computational time. This explains the variability of the previous results and
highlights the importance of careful specification of the context in the
publication of a new method. All our code and results are available for
download.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta Learning for Knowledge Distillation. (arXiv:2106.04570v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wangchunshu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Canwen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04570">
                                    <div class="article-summary-box-inner">
                                        <span>We present Meta Learning for Knowledge Distillation (MetaDistil), a simple
yet effective alternative to traditional knowledge distillation (KD) methods
where the teacher model is fixed during training. We show the teacher network
can learn to better transfer knowledge to the student network (i.e., learning
to teach) with the feedback from the performance of the distilled student
network in a meta learning framework. Moreover, we introduce a pilot update
mechanism to improve the alignment between the inner-learner and meta-learner
in meta learning algorithms that focus on an improved inner-learner.
Experiments on various benchmarks show that MetaDistil can yield significant
improvements compared with traditional KD algorithms and is less sensitive to
the choice of different student capacity and hyperparameters, facilitating the
use of KD on different tasks and models. The code is available at
https://github.com/JetRunner/MetaDistil</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-aware Spatiotemporal Modules with Auxiliary Tasks for Meta-Learning. (arXiv:2006.08831v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1">Sungyong Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_C/0/1/0/all/0/1">Chuizheng Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambhatla_S/0/1/0/all/0/1">Sirisha Rambhatla</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08831">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling the dynamics of real-world physical systems is critical for
spatiotemporal prediction tasks, but challenging when data is limited. The
scarcity of real-world data and the difficulty in reproducing the data
distribution hinder directly applying meta-learning techniques. Although the
knowledge of governing partial differential equations (PDE) of data can be
helpful for the fast adaptation to few observations, it is mostly infeasible to
exactly find the equation for observations in real-world physical systems. In
this work, we propose a framework, physics-aware meta-learning with auxiliary
tasks, whose spatial modules incorporate PDE-independent knowledge and temporal
modules utilize the generalized features from the spatial modules to be adapted
to the limited data, respectively. The framework is inspired by a local
conservation law expressed mathematically as a continuity equation and does not
require the exact form of governing equation to model the spatiotemporal
observations. The proposed method mitigates the need for a large number of
real-world tasks for meta-learning by leveraging spatial information in
simulated data to meta-initialize the spatial modules. We apply the proposed
framework to both synthetic and real-world spatiotemporal prediction tasks and
demonstrate its superior performance with limited observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unified Representation Learning for Efficient Medical Image Analysis. (arXiv:2006.11223v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zamzmi_G/0/1/0/all/0/1">Ghada Zamzmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajaraman_S/0/1/0/all/0/1">Sivaramakrishnan Rajaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Antani_S/0/1/0/all/0/1">Sameer Antani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11223">
                                    <div class="article-summary-box-inner">
                                        <span>Medical image analysis typically includes several tasks such as enhancement,
segmentation, and classification. Traditionally, these tasks are implemented
using separate deep learning models for separate tasks, which is not efficient
because it involves unnecessary training repetitions, demands greater
computational resources, and requires a relatively large amount of labeled
data. In this paper, we propose a multi-task training approach for medical
image analysis, where individual tasks are fine-tuned simultaneously through
relevant knowledge transfer using a unified modality-specific feature
representation (UMS-Rep). We explore different fine-tuning strategies to
demonstrate the impact of the strategy on the performance of target medical
image tasks. We experiment with different visual tasks (e.g., image denoising,
segmentation, and classification) to highlight the advantages offered with our
approach for two imaging modalities, chest X-ray and Doppler echocardiography.
Our results demonstrate that the proposed approach reduces the overall demand
for computational resources and improves target task generalization and
performance. Further, our results prove that the performance of target tasks in
medical images is highly influenced by the utilized fine-tuning strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Back2Future: Leveraging Backfill Dynamics for Improving Real-time Predictions in Future. (arXiv:2106.04420v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1">Harshavardhan Kamarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Alexander Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1">B. Aditya Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04420">
                                    <div class="article-summary-box-inner">
                                        <span>In real-time forecasting in public health, data collection is a non-trivial
and demanding task. Often after initially released, it undergoes several
revisions later (maybe due to human or technical constraints) - as a result, it
may take weeks until the data reaches to a stable value. This so-called
&#x27;backfill&#x27; phenomenon and its effect on model performance has been barely
studied in the prior literature. In this paper, we introduce the multi-variate
backfill problem using COVID-19 as the motivating example. We construct a
detailed dataset composed of relevant signals over the past year of the
pandemic. We then systematically characterize several patterns in backfill
dynamics and leverage our observations for formulating a novel problem and
neural framework Back2Future that aims to refines a given model&#x27;s predictions
in real-time. Our extensive experiments demonstrate that our method refines the
performance of top models for COVID-19 forecasting, in contrast to non-trivial
baselines, yielding 18% improvement over baselines, enabling us obtain a new
SOTA performance. In addition, we show that our model improves model evaluation
too; hence policy-makers can better understand the true accuracy of forecasting
models in real-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Fairness of Causal Algorithmic Recourse. (arXiv:2010.06529v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kugelgen_J/0/1/0/all/0/1">Julius von K&#xfc;gelgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Karimi_A/0/1/0/all/0/1">Amir-Hossein Karimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatt_U/0/1/0/all/0/1">Umang Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Valera_I/0/1/0/all/0/1">Isabel Valera</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06529">
                                    <div class="article-summary-box-inner">
                                        <span>Algorithmic fairness is typically studied from the perspective of
predictions. Instead, here we investigate fairness from the perspective of
recourse actions suggested to individuals to remedy an unfavourable
classification. We propose two new fairness criteria at the group and
individual level, which -- unlike prior work on equalising the average
group-wise distance from the decision boundary -- explicitly account for causal
relationships between features, thereby capturing downstream effects of
recourse actions performed in the physical world. We explore how our criteria
relate to others, such as counterfactual fairness, and show that fairness of
recourse is complementary to fairness of prediction. We study theoretically and
empirically how to enforce fair causal recourse by altering the classifier and
perform a case study on the Adult dataset. Finally, we discuss whether fairness
violations in the data generating process revealed by our criteria may be
better addressed by societal interventions as opposed to constraints on the
classifier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning. (arXiv:2011.13034v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jingfeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1">Vladimir Braverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin F. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13034">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we consider multi-objective reinforcement learning where the
objectives are balanced using preferences. In practice, the preferences are
often given in an adversarial manner, e.g., customers can be picky in many
applications. We formalize this problem as an episodic learning problem on a
Markov decision process, where transitions are unknown and a reward function is
the inner product of a preference vector with pre-specified multi-objective
reward functions. We consider two settings. In the online setting, the agent
receives a (adversarial) preference every episode and proposes policies to
interact with the environment. We provide a model-based algorithm that achieves
a nearly minimax optimal regret bound
$\widetilde{\mathcal{O}}\bigl(\sqrt{\min\{d,S\}\cdot H^2 SAK}\bigr)$, where $d$
is the number of objectives, $S$ is the number of states, $A$ is the number of
actions, $H$ is the length of the horizon, and $K$ is the number of episodes.
Furthermore, we consider preference-free exploration, i.e., the agent first
interacts with the environment without specifying any preference and then is
able to accommodate arbitrary preference vector up to $\epsilon$ error. Our
proposed algorithm is provably efficient with a nearly optimal trajectory
complexity $\widetilde{\mathcal{O}}\bigl({\min\{d,S\}\cdot H^3
SA}/{\epsilon^2}\bigr)$. This result partly resolves an open problem raised by
\citet{jin2020reward}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Transformers. (arXiv:2106.04554v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiangyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04554">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved great success in many artificial intelligence
fields, such as natural language processing, computer vision, and audio
processing. Therefore, it is natural to attract lots of interest from academic
and industry researchers. Up to the present, a great variety of Transformer
variants (a.k.a. X-formers) have been proposed, however, a systematic and
comprehensive literature review on these Transformer variants is still missing.
In this survey, we provide a comprehensive review of various X-formers. We
first briefly introduce the vanilla Transformer and then propose a new taxonomy
of X-formers. Next, we introduce the various X-formers from three perspectives:
architectural modification, pre-training, and applications. Finally, we outline
some potential directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modular Deep Reinforcement Learning for Continuous Motion Planning with Temporal Logic. (arXiv:2102.12855v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1">Mingyu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasanbeig_M/0/1/0/all/0/1">Mohammadhosein Hasanbeig</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1">Shaoping Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1">Alessandro Abate</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_Z/0/1/0/all/0/1">Zhen Kan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12855">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the motion planning of autonomous dynamical systems
modeled by Markov decision processes (MDP) with unknown transition
probabilities over continuous state and action spaces. Linear temporal logic
(LTL) is used to specify high-level tasks over infinite horizon, which can be
converted into a limit deterministic generalized B\&quot;uchi automaton (LDGBA) with
several accepting sets. The novelty is to design an embedded product MDP
(EP-MDP) between the LDGBA and the MDP by incorporating a synchronous
tracking-frontier function to record unvisited accepting sets of the automaton,
and to facilitate the satisfaction of the accepting conditions. The proposed
LDGBA-based reward shaping and discounting schemes for the model-free
reinforcement learning (RL) only depend on the EP-MDP states and can overcome
the issues of sparse rewards. Rigorous analysis shows that any RL method that
optimizes the expected discounted return is guaranteed to find an optimal
policy whose traces maximize the satisfaction probability. A modular deep
deterministic policy gradient (DDPG) is then developed to generate such
policies over continuous state and action spaces. The performance of our
framework is evaluated via an array of OpenAI gym environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Complexity and Overparameterization Bounds for Temporal Difference Learning with Neural Network Approximation. (arXiv:2103.01391v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1">Semih Cayci</a>, <a href="http://arxiv.org/find/cs/1/au:+Satpathi_S/0/1/0/all/0/1">Siddhartha Satpathi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1">Niao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1">R. Srikant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01391">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the dynamics of temporal difference learning with
neural network-based value function approximation over a general state space,
namely, \emph{Neural TD learning}. We consider two practically used algorithms,
projection-free and max-norm regularized Neural TD learning, and establish the
first convergence bounds for these algorithms. An interesting observation from
our results is that max-norm regularization can dramatically improve the
performance of TD learning algorithms, both in terms of sample complexity and
overparameterization. In particular, we prove that max-norm regularization
appears to be more effective than $\ell_2$-regularization, again both in terms
of sample complexity and overparameterization. The results in this work rely on
a novel Lyapunov drift analysis of the network parameters as a stopped and
controlled random process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Concise yet Effective model for Non-Aligned Incomplete Multi-view and Missing Multi-label Learning. (arXiv:2005.00976v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Songcan Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00976">
                                    <div class="article-summary-box-inner">
                                        <span>In reality, learning from multi-view multi-label data inevitably confronts
three challenges: missing labels, incomplete views, and non-aligned views.
Existing methods mainly concern the first two and commonly need multiple
assumptions to attack them, making even state-of-the-arts involve at least two
explicit hyper-parameters such that model selection is quite difficult. More
roughly, they will fail in handling the third challenge, let alone addressing
the three jointly. In this paper, we aim at meeting these under the least
assumption by building a concise yet effective model with just one
hyper-parameter. To ease insufficiency of available labels, we exploit not only
the consensus of multiple views but also the global and local structures hidden
among multiple labels. Specifically, we introduce an indicator matrix to tackle
the first two challenges in a regression form while aligning the same
individual labels and all labels of different views in a common label space to
battle the third challenge. In aligning, we characterize the global and local
structures of multiple labels to be high-rank and low-rank, respectively.
Subsequently, an efficient algorithm with linear time complexity in the number
of samples is established. Finally, even without view-alignment, our method
substantially outperforms state-of-the-arts with view-alignment on five real
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning. (arXiv:1912.02631v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaudhari_H/0/1/0/all/0/1">Harsh Chaudhari</a>, <a href="http://arxiv.org/find/cs/1/au:+Rachuri_R/0/1/0/all/0/1">Rahul Rachuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1">Ajith Suresh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.02631">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning has started to be deployed in fields such as healthcare and
finance, which propelled the need for and growth of privacy-preserving machine
learning (PPML). We propose an actively secure four-party protocol (4PC), and a
framework for PPML, showcasing its applications on four of the most
widely-known machine learning algorithms -- Linear Regression, Logistic
Regression, Neural Networks, and Convolutional Neural Networks. Our 4PC
protocol tolerating at most one malicious corruption is practically efficient
as compared to the existing works. We use the protocol to build an efficient
mixed-world framework (Trident) to switch between the Arithmetic, Boolean, and
Garbled worlds. Our framework operates in the offline-online paradigm over
rings and is instantiated in an outsourced setting for machine learning. Also,
we propose conversions especially relevant to privacy-preserving machine
learning. The highlights of our framework include using a minimal number of
expensive circuits overall as compared to ABY3. This can be seen in our
technique for truncation, which does not affect the online cost of
multiplication and removes the need for any circuits in the offline phase. Our
B2A conversion has an improvement of $\mathbf{7} \times$ in rounds and
$\mathbf{18} \times$ in the communication complexity. The practicality of our
framework is argued through improvements in the benchmarking of the
aforementioned algorithms when compared with ABY3. All the protocols are
implemented over a 64-bit ring in both LAN and WAN settings. Our improvements
go up to $\mathbf{187} \times$ for the training phase and $\mathbf{158} \times$
for the prediction phase when observed over LAN and WAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inference for Network Regression Models with Community Structure. (arXiv:2106.04271v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pan_M/0/1/0/all/0/1">Mengjie Pan</a>, <a href="http://arxiv.org/find/stat/1/au:+McCormick_T/0/1/0/all/0/1">Tyler H. McCormick</a>, <a href="http://arxiv.org/find/stat/1/au:+Fosdick_B/0/1/0/all/0/1">Bailey K. Fosdick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04271">
                                    <div class="article-summary-box-inner">
                                        <span>Network regression models, where the outcome comprises the valued edge in a
network and the predictors are actor or dyad-level covariates, are used
extensively in the social and biological sciences. Valid inference relies on
accurately modeling the residual dependencies among the relations. Frequently
homogeneity assumptions are placed on the errors which are commonly incorrect
and ignore critical, natural clustering of the actors. In this work, we present
a novel regression modeling framework that models the errors as resulting from
a community-based dependence structure and exploits the subsequent
exchangeability properties of the error distribution to obtain parsimonious
standard errors for regression parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Uncanny Similarity of Recurrence and Depth. (arXiv:2102.11011v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arjun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghiasi_A/0/1/0/all/0/1">Amin Ghiasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11011">
                                    <div class="article-summary-box-inner">
                                        <span>It is widely believed that deep neural networks contain layer specialization,
wherein networks extract hierarchical features representing edges and patterns
in shallow layers and complete objects in deeper layers. Unlike common
feed-forward models that have distinct filters at each layer, recurrent
networks reuse the same parameters at various depths. In this work, we observe
that recurrent models exhibit the same hierarchical behaviors and the same
performance benefits as depth despite reusing the same filters at every
recurrence. By training models of various feed-forward and recurrent
architectures on several datasets for image classification as well as maze
solving, we show that recurrent networks have the ability to closely emulate
the behavior of non-recurrent deep models, often doing so with far fewer
parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Obtaining Better Static Word Embeddings Using Contextual Embedding Models. (arXiv:2106.04302v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1">Prakhar Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04302">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of contextual word embeddings -- representations of words which
incorporate semantic and syntactic information from their context -- has led to
tremendous improvements on a wide variety of NLP tasks. However, recent
contextual models have prohibitively high computational cost in many use-cases
and are often hard to interpret. In this work, we demonstrate that our proposed
distillation method, which is a simple extension of CBOW-based training, allows
to significantly improve computational efficiency of NLP applications, while
outperforming the quality of existing static embeddings trained from scratch as
well as those distilled from previously proposed methods. As a side-effect, our
approach also allows a fair comparison of both contextual and static embeddings
via standard lexical evaluation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Possibility in Algorithmic Fairness: Can Calibration and Equal Error Rates Be Reconciled?. (arXiv:2002.07676v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reich_C/0/1/0/all/0/1">Claire Lazar Reich</a>, <a href="http://arxiv.org/find/cs/1/au:+Vijaykumar_S/0/1/0/all/0/1">Suhas Vijaykumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.07676">
                                    <div class="article-summary-box-inner">
                                        <span>Decision makers increasingly rely on algorithmic risk scores to determine
access to binary treatments including bail, loans, and medical interventions.
In these settings, we reconcile two fairness criteria that were previously
shown to be in conflict: calibration and error rate equality. In particular, we
derive necessary and sufficient conditions for the existence of calibrated
scores that yield classifications achieving equal error rates at any given
group-blind threshold. We then present an algorithm that searches for the most
accurate score subject to both calibration and minimal error rate disparity.
Applied to the COMPAS criminal risk assessment tool, we show that our method
can eliminate error disparities while maintaining calibration. In a separate
application to credit lending, we compare our procedure to the omission of
sensitive features and show that it raises both profit and the probability that
creditworthy individuals receive loans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When in Doubt: Neural Non-Parametric Uncertainty Quantification for Epidemic Forecasting. (arXiv:2106.03904v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamarthi_H/0/1/0/all/0/1">Harshavardhan Kamarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1">Lingkai Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_A/0/1/0/all/0/1">Alexander Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_B/0/1/0/all/0/1">B. Aditya Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03904">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate and trustworthy epidemic forecasting is an important problem that
has impact on public health planning and disease mitigation. Most existing
epidemic forecasting models disregard uncertainty quantification, resulting in
mis-calibrated predictions. Recent works in deep neural models for
uncertainty-aware time-series forecasting also have several limitations; e.g.
it is difficult to specify meaningful priors in Bayesian NNs, while methods
like deep ensembling are computationally expensive in practice. In this paper,
we fill this important gap. We model the forecasting task as a probabilistic
generative process and propose a functional neural process model called EPIFNP,
which directly models the probability density of the forecast value. EPIFNP
leverages a dynamic stochastic correlation graph to model the correlations
between sequences in a non-parametric way, and designs different stochastic
latent variables to capture functional uncertainty from different perspectives.
Our extensive experiments in a real-time flu forecasting setting show that
EPIFNP significantly outperforms previous state-of-the-art models in both
accuracy and calibration metrics, up to 2.5x in accuracy and 2.4x in
calibration. Additionally, due to properties of its generative process,EPIFNP
learns the relations between the current season and similar patterns of
historical seasons,enabling interpretable forecasts. Beyond epidemic
forecasting, the EPIFNP can be of independent interest for advancing principled
uncertainty quantification in deep sequential models for predictive analytics</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Biomanufacturing Harvesting Decisions under Limited Historical Data. (arXiv:2101.03735v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1">Wei Xie</a>, <a href="http://arxiv.org/find/stat/1/au:+Martagan_T/0/1/0/all/0/1">Tugce Martagan</a>, <a href="http://arxiv.org/find/stat/1/au:+Akcay_A/0/1/0/all/0/1">Alp Akcay</a>, <a href="http://arxiv.org/find/stat/1/au:+Ravenstein_B/0/1/0/all/0/1">Bram van Ravenstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03735">
                                    <div class="article-summary-box-inner">
                                        <span>In the biopharmaceutical manufacturing, fermentation process plays a critical
role impacting on productivity and profit. Since biotherapeutics are
manufactured in living cells whose biological mechanisms are complex and have
highly variable outputs, in this paper, we introduce a model-based
reinforcement learning framework accounting for model risk to support
bioprocess online learning and guide the optimal reliable customized stopping
policy for fermentation process. Specifically, built on the dynamic mechanisms
of protein and impurity generation, we first construct a probabilistic model
characterizing the impact of underlying bioprocess stochastic uncertainty on
impurity and protein growth rates. Since biopharmaceutical manufacturing often
has very limited batch data during the development and early stage of
production, we derive the posterior distribution quantifying the process model
risk, and further develop the Bayesian rule based knowledge update to support
bioprocess online learning. With the prediction risk accounting for both
bioprocess stochastic uncertainty and model risk, the proposed reinforcement
learning framework can provide the optimal and reliable decision making. We
conduct the structural analysis of optimal policy and study the impact of model
risk on the policy selection. We can show that it asymptotically converges to
the optimal policy obtained under perfect information of underlying stochastic
process. Our case studies demonstrate that the proposed framework can greatly
improve the biomanufacturing industrial practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principled Hyperedge Prediction with Structural Spectral Features and Neural Networks. (arXiv:2106.04292v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1">Changlin Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Muhan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1">Wei Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Sha Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04292">
                                    <div class="article-summary-box-inner">
                                        <span>Hypergraph offers a framework to depict the multilateral relationships in
real-world complex data. Predicting higher-order relationships, i.e hyperedge,
becomes a fundamental problem for the full understanding of complicated
interactions. The development of graph neural network (GNN) has greatly
advanced the analysis of ordinary graphs with pair-wise relations. However,
these methods could not be easily extended to the case of hypergraph. In this
paper, we generalize the challenges of GNN in representing higher-order data in
principle, which are edge- and node-level ambiguities. To overcome the
challenges, we present \textbf{SNALS} that utilizes bipartite graph neural
network with structural features to collectively tackle the two ambiguity
issues. SNALS captures the joint interactions of a hyperedge by its local
environment, which is retrieved by collecting the spectrum information of their
connections. As a result, SNALS achieves nearly 30% performance increase
compared with most recent GNN-based models. In addition, we applied SNALS to
predict genetic higher-order interactions on 3D genome organization data. SNALS
showed consistently high prediction accuracy across different chromosomes, and
generated novel findings on 4-way gene interaction, which is further validated
by existing literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the stability properties of Gated Recurrent Units neural networks. (arXiv:2011.06806v4 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1">Fabio Bonassi</a>, <a href="http://arxiv.org/find/eess/1/au:+Farina_M/0/1/0/all/0/1">Marcello Farina</a>, <a href="http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1">Riccardo Scattolini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.06806">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of this paper is to provide sufficient conditions for guaranteeing
the Input-to-State Stability (ISS) and the Incremental Input-to-State Stability
({\delta}ISS) of Gated Recurrent Units (GRUs) neural networks. These
conditions, devised for both single-layer and multi-layer architectures,
consist of nonlinear inequalities on network&#x27;s weights. They can be employed to
check the stability of trained networks, or can be enforced as constraints
during the training procedure of a GRU. The resulting training procedure is
tested on a Quadruple Tank nonlinear benchmark system, showing satisfactory
modeling performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Stochastic Multi-agent Multi-armed Bandits Robust to Adversarial Corruptions. (arXiv:2106.04207v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junyan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dapeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04207">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of stochastic bandits with adversarial corruptions in
the cooperative multi-agent setting, where $V$ agents interact with a common
$K$-armed bandit problem, and each pair of agents can communicate with each
other to expedite the learning process. In the problem, the rewards are
independently sampled from distributions across all agents and rounds, but they
may be corrupted by an adversary. Our goal is to minimize both the overall
regret and communication cost across all agents. We first show that an additive
term of corruption is unavoidable for any algorithm in this problem. Then, we
propose a new algorithm that is agnostic to the level of corruption. Our
algorithm not only achieves near-optimal regret in the stochastic setting, but
also obtains a regret with an additive term of corruption in the corrupted
setting, while maintaining efficient communication. The algorithm is also
applicable for the single-agent corruption problem, and achieves a high
probability regret that removes the multiplicative dependence of $K$ on
corruption level. Our result of the single-agent case resolves an open question
from Gupta et al. [2019].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Question Generation for Adaptive Education. (arXiv:2106.04262v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1">Megha Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04262">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent and adaptive online education systems aim to make high-quality
education available for a diverse range of students. However, existing systems
usually depend on a pool of hand-made questions, limiting how fine-grained and
open-ended they can be in adapting to individual students. We explore targeted
question generation as a controllable sequence generation task. We first show
how to fine-tune pre-trained language models for deep knowledge tracing
(LM-KT). This model accurately predicts the probability of a student answering
a question correctly, and generalizes to questions not seen in training. We
then use LM-KT to specify the objective and data for training a model to
generate questions conditioned on the student and target difficulty. Our
results show we succeed at generating novel, well-calibrated language
translation questions for second language learners from a real online education
platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Session-Aware Query Auto-completion using Extreme Multi-label Ranking. (arXiv:2012.07654v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1">Nishant Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_R/0/1/0/all/0/1">Rajat Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_D/0/1/0/all/0/1">Daniel N. Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1">Arya Mazumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1">Inderjit S. Dhillon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07654">
                                    <div class="article-summary-box-inner">
                                        <span>Query auto-completion (QAC) is a fundamental feature in search engines where
the task is to suggest plausible completions of a prefix typed in the search
bar. Previous queries in the user session can provide useful context for the
user&#x27;s intent and can be leveraged to suggest auto-completions that are more
relevant while adhering to the user&#x27;s prefix. Such session-aware QACs can be
generated by recent sequence-to-sequence deep learning models; however, these
generative approaches often do not meet the stringent latency requirements of
responding to each user keystroke. Moreover, these generative approaches pose
the risk of showing nonsensical queries.

In this paper, we provide a solution to this problem: we take the novel
approach of modeling session-aware QAC as an eXtreme Multi-Label Ranking (XMR)
problem where the input is the previous query in the session and the user&#x27;s
current prefix, while the output space is the set of tens of millions of
queries entered by users in the recent past. We adapt a popular XMR algorithm
for this purpose by proposing several modifications to the key steps in the
algorithm. The proposed modifications yield a 10x improvement in terms of Mean
Reciprocal Rank (MRR) over the baseline XMR approach on a public search logs
dataset. We are able to maintain an inference latency of less than 10 ms while
still using session context. When compared against baseline models of
acceptable latency, we observed a 33% improvement in MRR for short prefixes of
up to 3 characters. Moreover, our model yielded a statistically significant
improvement of 2.81% over a production QAC system in terms of suggestion
acceptance rate, when deployed on the search bar of an online shopping store as
part of an A/B test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deciding What to Learn: A Rate-Distortion Approach. (arXiv:2101.06197v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arumugam_D/0/1/0/all/0/1">Dilip Arumugam</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06197">
                                    <div class="article-summary-box-inner">
                                        <span>Agents that learn to select optimal actions represent a prominent focus of
the sequential decision-making literature. In the face of a complex environment
or constraints on time and resources, however, aiming to synthesize such an
optimal policy can become infeasible. These scenarios give rise to an important
trade-off between the information an agent must acquire to learn and the
sub-optimality of the resulting policy. While an agent designer has a
preference for how this trade-off is resolved, existing approaches further
require that the designer translate these preferences into a fixed learning
target for the agent. In this work, leveraging rate-distortion theory, we
automate this process such that the designer need only express their
preferences via a single hyperparameter and the agent is endowed with the
ability to compute its own learning targets that best achieve the desired
trade-off. We establish a general bound on expected discounted regret for an
agent that decides what to learn in this manner along with computational
experiments that illustrate the expressiveness of designer preferences and even
show improvements over Thompson sampling in identifying an optimal policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Privacy-Preserving Text Classification based on Secure Multiparty Computation. (arXiv:2101.07365v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Resende_A/0/1/0/all/0/1">Amanda Resende</a>, <a href="http://arxiv.org/find/cs/1/au:+Railsback_D/0/1/0/all/0/1">Davis Railsback</a>, <a href="http://arxiv.org/find/cs/1/au:+Dowsley_R/0/1/0/all/0/1">Rafael Dowsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_A/0/1/0/all/0/1">Anderson C. A. Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Aranha_D/0/1/0/all/0/1">Diego F. Aranha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07365">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a privacy-preserving Naive Bayes classifier and apply it to the
problem of private text classification. In this setting, a party (Alice) holds
a text message, while another party (Bob) holds a classifier. At the end of the
protocol, Alice will only learn the result of the classifier applied to her
text input and Bob learns nothing. Our solution is based on Secure Multiparty
Computation (SMC). Our Rust implementation provides a fast and secure solution
for the classification of unstructured text. Applying our solution to the case
of spam detection (the solution is generic, and can be used in any other
scenario in which the Naive Bayes classifier can be employed), we can classify
an SMS as spam or ham in less than 340ms in the case where the dictionary size
of Bob&#x27;s model includes all words (n &#x3D; 5200) and Alice&#x27;s SMS has at most m &#x3D;
160 unigrams. In the case with n &#x3D; 369 and m &#x3D; 8 (the average of a spam SMS in
the database), our solution takes only 21ms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Design a Three-Stage Architecture for Audio-Visual Active Speaker Detection in the Wild. (arXiv:2106.03932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kopuklu_O/0/1/0/all/0/1">Okan K&#xf6;p&#xfc;kl&#xfc;</a>, <a href="http://arxiv.org/find/cs/1/au:+Taseska_M/0/1/0/all/0/1">Maja Taseska</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1">Gerhard Rigoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03932">
                                    <div class="article-summary-box-inner">
                                        <span>Successful active speaker detection requires a three-stage pipeline: (i)
audio-visual encoding for all speakers in the clip, (ii) inter-speaker relation
modeling between a reference speaker and the background speakers within each
frame, and (iii) temporal modeling for the reference speaker. Each stage of
this pipeline plays an important role for the final performance of the created
architecture. Based on a series of controlled experiments, this work presents
several practical guidelines for audio-visual active speaker detection.
Correspondingly, we present a new architecture called ASDNet, which achieves a
new state-of-the-art on the AVA-ActiveSpeaker dataset with a mAP of 93.5%
outperforming the second best with a large margin of 4.7%. Our code and
pretrained models are publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NWT: Towards natural audio-to-video generation with representation learning. (arXiv:2106.04283v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mama_R/0/1/0/all/0/1">Rayhane Mama</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyndel_M/0/1/0/all/0/1">Marc S. Tyndel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadhim_H/0/1/0/all/0/1">Hashiam Kadhim</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifford_C/0/1/0/all/0/1">Cole Clifford</a>, <a href="http://arxiv.org/find/cs/1/au:+Thurairatnam_R/0/1/0/all/0/1">Ragavan Thurairatnam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04283">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we introduce NWT, an expressive speech-to-video model. Unlike
approaches that use domain-specific intermediate representations such as pose
keypoints, NWT learns its own latent representations, with minimal assumptions
about the audio and video content. To this end, we propose a novel discrete
variational autoencoder with adversarial loss, dVAE-Adv, which learns a new
discrete latent representation we call Memcodes. Memcodes are straightforward
to implement, require no additional loss terms, are stable to train compared
with other approaches, and show evidence of interpretability. To predict on the
Memcode space, we use an autoregressive encoder-decoder model conditioned on
audio. Additionally, our model can control latent attributes in the generated
video that are not annotated in the data. We train NWT on clips from HBO&#x27;s Last
Week Tonight with John Oliver. NWT consistently scores above other approaches
in Mean Opinion Score (MOS) on tests of overall video naturalness, facial
naturalness and expressiveness, and lipsync quality. This work sets a strong
baseline for generalized audio-to-video synthesis. Samples are available at
https://next-week-tonight.github.io/NWT/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing Fairness in Classification with a Model-Agnostic Multi-Objective Algorithm. (arXiv:2009.04441v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Padh_K/0/1/0/all/0/1">Kirtan Padh</a>, <a href="http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1">Diego Antognini</a>, <a href="http://arxiv.org/find/cs/1/au:+Glaude_E/0/1/0/all/0/1">Emma Lejal Glaude</a>, <a href="http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1">Boi Faltings</a>, <a href="http://arxiv.org/find/cs/1/au:+Musat_C/0/1/0/all/0/1">Claudiu Musat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04441">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of fairness in classification is to learn a classifier that does not
discriminate against groups of individuals based on sensitive attributes, such
as race and gender. One approach to designing fair algorithms is to use
relaxations of fairness notions as regularization terms or in a constrained
optimization problem. We observe that the hyperbolic tangent function can
approximate the indicator function. We leverage this property to define a
differentiable relaxation that approximates fairness notions provably better
than existing relaxations. In addition, we propose a model-agnostic
multi-objective architecture that can simultaneously optimize for multiple
fairness notions and multiple sensitive attributes and supports all statistical
parity-based notions of fairness. We use our relaxation with the
multi-objective architecture to learn fair classifiers. Experiments on public
datasets show that our method suffers a significantly lower loss of accuracy
than current debiasing algorithms relative to the unconstrained model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Stochastic Subgradient Method for Distributionally Robust Non-Convex Learning. (arXiv:2006.04873v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href="http://arxiv.org/find/math/1/au:+Ruszczynski_A/0/1/0/all/0/1">Andrzej Ruszczy&#x144;ski</a>, <a href="http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1">Landi Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04873">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a distributionally robust formulation of stochastic optimization
problems arising in statistical learning, where robustness is with respect to
uncertainty in the underlying data distribution. Our formulation builds on
risk-averse optimization techniques and the theory of coherent risk measures.
It uses semi-deviation risk for quantifying uncertainty, allowing us to compute
solutions that are robust against perturbations in the population data
distribution. We consider a large family of loss functions that can be
non-convex and non-smooth and develop an efficient stochastic subgradient
method. We prove that it converges to a point satisfying the optimality
conditions. To our knowledge, this is the first method with rigorous
convergence guarantees in the context of non-convex non-smooth distributionally
robust stochastic optimization. Our method can achieve any desired level of
robustness with little extra computational cost compared to population risk
minimization. We also illustrate the performance of our algorithm on real
datasets arising in convex and non-convex supervised learning problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Multiple Noisy Partial Labelers. (arXiv:2106.04530v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Peilin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1">Tiffany Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1">Stephen H. Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04530">
                                    <div class="article-summary-box-inner">
                                        <span>Programmatic weak supervision creates models without hand-labeled training
data by combining the outputs of noisy, user-written rules and other heuristic
labelers. Existing frameworks make the restrictive assumption that labelers
output a single class label. Enabling users to create partial labelers that
output subsets of possible class labels would greatly expand the expressivity
of programmatic weak supervision. We introduce this capability by defining a
probabilistic generative model that can estimate the underlying accuracies of
multiple noisy partial labelers without ground truth labels. We prove that this
class of models is generically identifiable up to label swapping under mild
conditions. We also show how to scale up learning to 100k examples in one
minute, a 300X speed up compared to a naive implementation. We evaluate our
framework on three text classification and six object classification tasks. On
text tasks, adding partial labels increases average accuracy by 9.6 percentage
points. On image tasks, we show that partial labels allow us to approach some
zero-shot object classification problems with programmatic weak supervision by
using class attributes as partial labelers. Our framework is able to achieve
accuracy comparable to recent embedding-based zero-shot learning methods using
only pre-trained attribute detectors</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Graph Transformers with Spectral Attention. (arXiv:2106.03893v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kreuzer_D/0/1/0/all/0/1">Devin Kreuzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Beaini_D/0/1/0/all/0/1">Dominique Beaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William L. Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Letourneau_V/0/1/0/all/0/1">Vincent L&#xe9;tourneau</a>, <a href="http://arxiv.org/find/cs/1/au:+Tossou_P/0/1/0/all/0/1">Prudencio Tossou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03893">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the Transformer architecture has proven to be very
successful in sequence processing, but its application to other data
structures, such as graphs, has remained limited due to the difficulty of
properly defining positions. Here, we present the $\textit{Spectral Attention
Network}$ (SAN), which uses a learned positional encoding (LPE) that can take
advantage of the full Laplacian spectrum to learn the position of each node in
a given graph. This LPE is then added to the node features of the graph and
passed to a fully-connected Transformer. By leveraging the full spectrum of the
Laplacian, our model is theoretically powerful in distinguishing graphs, and
can better detect similar sub-structures from their resonance. Further, by
fully connecting the graph, the Transformer does not suffer from
over-squashing, an information bottleneck of most GNNs, and enables better
modeling of physical phenomenons such as heat transfer and electric
interaction. When tested empirically on a set of 4 standard datasets, our model
performs on par or better than state-of-the-art GNNs, and outperforms any
attention-based model by a wide margin, becoming the first fully-connected
architecture to perform well on graph benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring and Improving BERT&#x27;s Mathematical Abilities by Predicting the Order of Reasoning. (arXiv:2106.03921v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Piekos_P/0/1/0/all/0/1">Piotr Pi&#x119;kos</a>, <a href="http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1">Henryk Michalewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1">Mateusz Malinowski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03921">
                                    <div class="article-summary-box-inner">
                                        <span>Imagine you are in a supermarket. You have two bananas in your basket and
want to buy four apples. How many fruits do you have in total? This seemingly
straightforward question can be challenging for data-driven language models,
even if trained at scale. However, we would expect such generic language models
to possess some mathematical abilities in addition to typical linguistic
competence. Towards this goal, we investigate if a commonly used language
model, BERT, possesses such mathematical abilities and, if so, to what degree.
For that, we fine-tune BERT on a popular dataset for word math problems,
AQuA-RAT, and conduct several tests to understand learned representations
better. Since we teach models trained on natural language to do formal
mathematics, we hypothesize that such models would benefit from training on
semi-formal steps that explain how math results are derived. To better
accommodate such training, we also propose new pretext tasks for learning
mathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or
NROP). With this new model, we achieve significantly better outcomes than
data-driven baselines and even on-par with more tailored models. We also show
how to reduce positional bias in such models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correcting Momentum in Temporal Difference Learning. (arXiv:2106.03955v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1">Emmanuel Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03955">
                                    <div class="article-summary-box-inner">
                                        <span>A common optimization tool used in deep reinforcement learning is momentum,
which consists in accumulating and discounting past gradients, reapplying them
at each iteration. We argue that, unlike in supervised learning, momentum in
Temporal Difference (TD) learning accumulates gradients that become doubly
stale: not only does the gradient of the loss change due to parameter updates,
the loss itself changes due to bootstrapping. We first show that this
phenomenon exists, and then propose a first-order correction term to momentum.
We show that this correction term improves sample efficiency in policy
evaluation by correcting target value drift. An important insight of this work
is that deep RL methods are not always best served by directly importing
techniques from the supervised setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Virtual Screening of Pharmaceutical Compounds with hERG Inhibitory Activity (Cardiotoxicity) using Ensemble Learning. (arXiv:2106.04377v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Sarkar_A/0/1/0/all/0/1">Aditya Sarkar</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bhavsar_A/0/1/0/all/0/1">Arnav Bhavsar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04377">
                                    <div class="article-summary-box-inner">
                                        <span>In silico prediction of cardiotoxicity with high sensitivity and specificity
for potential drug molecules can be of immense value. Hence, building machine
learning classification models, based on some features extracted from the
molecular structure of drugs, which are capable of efficiently predicting
cardiotoxicity is critical. In this paper, we consider the application of
various machine learning approaches, and then propose an ensemble classifier
for the prediction of molecular activity on a Drug Discovery Hackathon (DDH)
(1st reference) dataset. We have used only 2-D descriptors of SMILE notations
for our prediction. Our ensemble classification uses 5 classifiers (2 Random
Forest Classifiers, 2 Support Vector Machines and a Dense Neural Network) and
uses Max-Voting technique and Weighted-Average technique for final decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonlinear MPC for Offset-Free Tracking of systems learned by GRU Neural Networks. (arXiv:2103.02383v2 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bonassi_F/0/1/0/all/0/1">Fabio Bonassi</a>, <a href="http://arxiv.org/find/eess/1/au:+Silva_C/0/1/0/all/0/1">Caio Fabio Oliveira da Silva</a>, <a href="http://arxiv.org/find/eess/1/au:+Scattolini_R/0/1/0/all/0/1">Riccardo Scattolini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02383">
                                    <div class="article-summary-box-inner">
                                        <span>The use of Recurrent Neural Networks (RNNs) for system identification has
recently gathered increasing attention, thanks to their black-box modeling
capabilities.Albeit RNNs have been fruitfully adopted in many applications,
only few works are devoted to provide rigorous theoretical foundations that
justify their use for control purposes. The aim of this paper is to describe
how stable Gated Recurrent Units (GRUs), a particular RNN architecture, can be
trained and employed in a Nonlinear MPC framework to perform offset-free
tracking of constant references with guaranteed closed-loop stability. The
proposed approach is tested on a pH neutralization process benchmark, showing
remarkable performances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Federated Learning in the Presence of Arbitrary Device Unavailability. (arXiv:2106.04159v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1">Xinran Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaixuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingzhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Longbo Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04159">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) coordinates with numerous heterogeneous devices to
collaboratively train a shared model while preserving user privacy. Despite its
multiple advantages, FL faces new challenges. One challenge arises when devices
drop out of the training process beyond the control of the central server. In
this case, the convergence of popular FL algorithms such as FedAvg is severely
influenced by the straggling devices. To tackle this challenge, we study
federated learning algorithms under arbitrary device unavailability and propose
an algorithm named Memory-augmented Impatient Federated Averaging (MIFA). Our
algorithm efficiently avoids excessive latency induced by inactive devices, and
corrects the gradient bias using the memorized latest updates from the devices.
We prove that MIFA achieves minimax optimal convergence rates on non-i.i.d.
data for both strongly convex and non-convex smooth functions. We also provide
an explicit characterization of the improvement over baseline algorithms
through a case study, and validate the results by numerical experiments on
real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Broadcasted Residual Learning for Efficient Keyword Spotting. (arXiv:2106.04140v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Byeonggeun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Simyung Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinkyu Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_D/0/1/0/all/0/1">Dooyong Sung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04140">
                                    <div class="article-summary-box-inner">
                                        <span>Keyword spotting is an important research field because it plays a key role
in device wake-up and user interaction on smart devices. However, it is
challenging to minimize errors while operating efficiently in devices with
limited resources such as mobile phones. We present a broadcasted residual
learning method to achieve high accuracy with small model size and
computational load. Our method configures most of the residual functions as 1D
temporal convolution while still allows 2D convolution together using a
broadcasted-residual connection that expands temporal output to
frequency-temporal dimension. This residual mapping enables the network to
effectively represent useful audio features with much less computation than
conventional convolutional neural networks. We also propose a novel network
architecture, Broadcasting-residual network (BC-ResNet), based on broadcasted
residual learning and describe how to scale up the model according to the
target device&#x27;s resources. BC-ResNets achieve state-of-the-art 98.0% and 98.7%
top-1 accuracy on Google speech command datasets v1 and v2, respectively, and
consistently outperform previous approaches, using fewer computations and
parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batch Normalization Orthogonalizes Representations in Deep Random Networks. (arXiv:2106.03970v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Daneshmand_H/0/1/0/all/0/1">Hadi Daneshmand</a>, <a href="http://arxiv.org/find/stat/1/au:+Joudaki_A/0/1/0/all/0/1">Amir Joudaki</a>, <a href="http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03970">
                                    <div class="article-summary-box-inner">
                                        <span>This paper underlines a subtle property of batch-normalization (BN):
Successive batch normalizations with random linear transformations make hidden
representations increasingly orthogonal across layers of a deep neural network.
We establish a non-asymptotic characterization of the interplay between depth,
width, and the orthogonality of deep representations. More precisely, under a
mild assumption, we prove that the deviation of the representations from
orthogonality rapidly decays with depth up to a term inversely proportional to
the network width. This result has two main implications: 1) Theoretically, as
the depth grows, the distribution of the representation -- after the linear
layers -- contracts to a Wasserstein-2 ball around an isotropic Gaussian
distribution. Furthermore, the radius of this Wasserstein ball shrinks with the
width of the network. 2) In practice, the orthogonality of the representations
directly influences the performance of stochastic gradient descent (SGD). When
representations are initially aligned, we observe SGD wastes many iterations to
orthogonalize representations before the classification. Nevertheless, we
experimentally show that starting optimization from orthogonal representations
is sufficient to accelerate SGD, with no need for BN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruiz_N/0/1/0/all/0/1">Nataniel Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Kortylewski_A/0/1/0/all/0/1">Adam Kortylewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Weichao Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Cihang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1">Sarah Adel Bargal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Sclaroff_S/0/1/0/all/0/1">Stan Sclaroff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04569">
                                    <div class="article-summary-box-inner">
                                        <span>Most machine learning models are validated and tested on fixed datasets. This
can give an incomplete picture of the capabilities and weaknesses of the model.
Such weaknesses can be revealed at test time in the real world. The risks
involved in such failures can be loss of profits, loss of time or even loss of
life in certain critical applications. In order to alleviate this issue,
simulators can be controlled in a fine-grained manner using interpretable
parameters to explore the semantic image manifold. In this work, we propose a
framework for learning how to test machine learning algorithms using simulators
in an adversarial manner in order to find weaknesses in the model before
deploying it in critical scenarios. We apply this model in a face recognition
scenario. We are the first to show that weaknesses of models trained on real
data can be discovered using simulated samples. Using our proposed method, we
can find adversarial synthetic faces that fool contemporary face recognition
models. This demonstrates the fact that these models have weaknesses that are
not measured by commonly used validation datasets. We hypothesize that this
type of adversarial examples are not isolated, but usually lie in connected
components in the latent space of the simulator. We present a method to find
these adversarial regions as opposed to the typical adversarial points found in
the adversarial example literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Slot Machines: Discovering Winning Combinations of Random Weights in Neural Networks. (arXiv:2101.06475v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aladago_M/0/1/0/all/0/1">Maxwell Mbabilla Aladago</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1">Lorenzo Torresani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06475">
                                    <div class="article-summary-box-inner">
                                        <span>In contrast to traditional weight optimization in a continuous space, we
demonstrate the existence of effective random networks whose weights are never
updated. By selecting a weight among a fixed set of random values for each
individual connection, our method uncovers combinations of random weights that
match the performance of traditionally-trained networks of the same capacity.
We refer to our networks as &quot;slot machines&quot; where each reel (connection)
contains a fixed set of symbols (random values). Our backpropagation algorithm
&quot;spins&quot; the reels to seek &quot;winning&quot; combinations, i.e., selections of random
weight values that minimize the given loss. Quite surprisingly, we find that
allocating just a few random values to each connection (e.g., 8 values per
connection) yields highly competitive combinations despite being dramatically
more constrained compared to traditionally learned weights. Moreover,
finetuning these combinations often improves performance over the trained
baselines. A randomly initialized VGG-19 with 8 values per connection contains
a combination that achieves 91% test accuracy on CIFAR-10. Our method also
achieves an impressive performance of 98.2% on MNIST for neural networks
containing only random weights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Distributional Treatment Effect with Kernel Conditional Mean Embeddings and U-Statistic Regression. (arXiv:2102.08208v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Park_J/0/1/0/all/0/1">Junhyung Park</a>, <a href="http://arxiv.org/find/stat/1/au:+Shalit_U/0/1/0/all/0/1">Uri Shalit</a>, <a href="http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/stat/1/au:+Muandet_K/0/1/0/all/0/1">Krikamol Muandet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08208">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to analyse the conditional distributional treatment effect
(CoDiTE), which, in contrast to the more common conditional average treatment
effect (CATE), is designed to encode a treatment&#x27;s distributional aspects
beyond the mean. We first introduce a formal definition of the CoDiTE
associated with a distance function between probability measures. Then we
discuss the CoDiTE associated with the maximum mean discrepancy via kernel
conditional mean embeddings, which, coupled with a hypothesis test, tells us
whether there is any conditional distributional effect of the treatment.
Finally, we investigate what kind of conditional distributional effect the
treatment has, both in an exploratory manner via the conditional witness
function, and in a quantitative manner via U-statistic regression, generalising
the CATE to higher-order moments. Experiments on synthetic, semi-synthetic and
real datasets demonstrate the merits of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Machine Learning with Plausible Deniability. (arXiv:2106.04267v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rass_S/0/1/0/all/0/1">Stefan Rass</a>, <a href="http://arxiv.org/find/cs/1/au:+Konig_S/0/1/0/all/0/1">Sandra K&#xf6;nig</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachter_J/0/1/0/all/0/1">Jasmin Wachter</a>, <a href="http://arxiv.org/find/cs/1/au:+Egger_M/0/1/0/all/0/1">Manuel Egger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hobisch_M/0/1/0/all/0/1">Manuel Hobisch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04267">
                                    <div class="article-summary-box-inner">
                                        <span>We study the question of how well machine learning (ML) models trained on a
certain data set provide privacy for the training data, or equivalently,
whether it is possible to reverse-engineer the training data from a given ML
model. While this is easy to answer negatively in the most general case, it is
interesting to note that the protection extends over non-recoverability towards
plausible deniability: Given an ML model $f$, we show that one can take a set
of purely random training data, and from this define a suitable &#x60;&#x60;learning
rule&#x27;&#x27; that will produce a ML model that is exactly $f$. Thus, any speculation
about which data has been used to train $f$ is deniable upon the claim that any
other data could have led to the same results. We corroborate our theoretical
finding with practical examples, and open source implementations of how to find
the learning rules for a chosen set of raining data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from Noisy Labels with Deep Neural Networks: A Survey. (arXiv:2007.08199v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hwanjun Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minseok Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dongmin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yooju Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae-Gil Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08199">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has achieved remarkable success in numerous domains with help
from large amounts of big data. However, the quality of data labels is a
concern because of the lack of high-quality labels in many real-world
scenarios. As noisy labels severely degrade the generalization performance of
deep neural networks, learning from noisy labels (robust training) is becoming
an important task in modern deep learning applications. In this survey, we
first describe the problem of learning with label noise from a supervised
learning perspective. Next, we provide a comprehensive review of 57
state-of-the-art robust training methods, all of which are categorized into
five groups according to their methodological difference, followed by a
systematic comparison of six properties used to evaluate their superiority.
Subsequently, we perform an in-depth analysis of noise rate estimation and
summarize the typically used evaluation methodology, including public noisy
datasets and evaluation metrics. Finally, we present several promising research
directions that can serve as a guideline for future studies. All the contents
will be available at https://github.com/songhwanjun/Awesome-Noisy-Labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NISQ Algorithm for Semidefinite Programming. (arXiv:2106.03891v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Bharti_K/0/1/0/all/0/1">Kishor Bharti</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Haug_T/0/1/0/all/0/1">Tobias Haug</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Vedral_V/0/1/0/all/0/1">Vlatko Vedral</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kwek_L/0/1/0/all/0/1">Leong-Chuan Kwek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03891">
                                    <div class="article-summary-box-inner">
                                        <span>Semidefinite Programming (SDP) is a class of convex optimization programs
with vast applications in control theory, quantum information, combinatorial
optimization and operational research. Noisy intermediate-scale quantum (NISQ)
algorithms aim to make an efficient use of the current generation of quantum
hardware. However, optimizing variational quantum algorithms is a challenge as
it is an NP-hard problem that in general requires an exponential time to solve
and can contain many far from optimal local minima. Here, we present a current
term NISQ algorithm for SDP. The classical optimization program of our NISQ
solver is another SDP over a smaller dimensional ansatz space. We harness the
SDP based formulation of the Hamiltonian ground state problem to design a NISQ
eigensolver. Unlike variational quantum eigensolvers, the classical
optimization program of our eigensolver is convex, can be solved in polynomial
time with the number of ansatz parameters and every local minimum is a global
minimum. Further, we demonstrate the potential of our NISQ SDP solver by
finding the largest eigenvalue of up to $2^{1000}$ dimensional matrices and
solving graph problems related to quantum contextuality. We also discuss NISQ
algorithms for rank-constrained SDPs. Our work extends the application of NISQ
computers onto one of the most successful algorithmic frameworks of the past
few decades.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast rates in structured prediction. (arXiv:2102.00760v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1">Vivien Cabannes</a>, <a href="http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1">Alessandro Rudi</a>, <a href="http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00760">
                                    <div class="article-summary-box-inner">
                                        <span>Discrete supervised learning problems such as classification are often
tackled by introducing a continuous surrogate problem akin to regression.
Bounding the original error, between estimate and solution, by the surrogate
error endows discrete problems with convergence rates already shown for
continuous instances. Yet, current approaches do not leverage the fact that
discrete problems are essentially predicting a discrete output when continuous
problems are predicting a continuous value. In this paper, we tackle this issue
for general structured prediction problems, opening the way to &quot;super fast&quot;
rates, that is, convergence rates for the excess risk faster than $n^{-1}$,
where $n$ is the number of observations, with even exponential rates with the
strongest assumptions. We first illustrate it for predictors based on nearest
neighbors, generalizing rates known for binary classification to any discrete
problem within the framework of structured prediction. We then consider kernel
ridge regression where we improve known rates in $n^{-1/4}$ to arbitrarily fast
rates, depending on a parameter characterizing the hardness of the problem,
thus allowing, under smoothness assumptions, to bypass the curse of
dimensionality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Bin Packing with Predictions. (arXiv:2102.03311v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Angelopoulos_S/0/1/0/all/0/1">Spyros Angelopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamali_S/0/1/0/all/0/1">Shahin Kamali</a>, <a href="http://arxiv.org/find/cs/1/au:+Shadkami_K/0/1/0/all/0/1">Kimia Shadkami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03311">
                                    <div class="article-summary-box-inner">
                                        <span>Bin packing is a classic optimization problem with a wide range of
applications from load balancing in networks to supply chain management. In
this work we study the online variant of the problem, in which a sequence of
items of various sizes must be placed into a minimum number of bins of uniform
capacity. The online algorithm is enhanced with a (potentially erroneous)
prediction concerning the frequency of item sizes in the sequence. We design
and analyze online algorithms with efficient tradeoffs between consistency
(i.e., the competitive ratio assuming no prediction error) and robustness
(i.e., the competitive ratio under adversarial error), and whose performance
degrades gently as a function of the prediction error. This is the first
theoretical study of online bin packing in the realistic setting of erroneous
predictions, as well as the first experimental study in the setting in which
the input is generated according to both static and evolving distributions.
Previous work on this problem has only addressed the extreme cases with respect
to the prediction error, has relied on overly powerful and error-free
prediction oracles, and has focused on experimental evaluation based on static
input distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty Baselines: Benchmarks for Uncertainty &amp; Robustness in Deep Learning. (arXiv:2106.04015v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nado_Z/0/1/0/all/0/1">Zachary Nado</a>, <a href="http://arxiv.org/find/cs/1/au:+Band_N/0/1/0/all/0/1">Neil Band</a>, <a href="http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1">Mark Collier</a>, <a href="http://arxiv.org/find/cs/1/au:+Djolonga_J/0/1/0/all/0/1">Josip Djolonga</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusenberry_M/0/1/0/all/0/1">Michael W. Dusenberry</a>, <a href="http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1">Sebastian Farquhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Filos_A/0/1/0/all/0/1">Angelos Filos</a>, <a href="http://arxiv.org/find/cs/1/au:+Havasi_M/0/1/0/all/0/1">Marton Havasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jenatton_R/0/1/0/all/0/1">Rodolphe Jenatton</a>, <a href="http://arxiv.org/find/cs/1/au:+Jerfel_G/0/1/0/all/0/1">Ghassen Jerfel</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jeremiah Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mariet_Z/0/1/0/all/0/1">Zelda Mariet</a>, <a href="http://arxiv.org/find/cs/1/au:+Nixon_J/0/1/0/all/0/1">Jeremy Nixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Padhy_S/0/1/0/all/0/1">Shreyas Padhy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudner_T/0/1/0/all/0/1">Tim G. J. Rudner</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yeming Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenzel_F/0/1/0/all/0/1">Florian Wenzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1">Kevin Murphy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sculley_D/0/1/0/all/0/1">D. Sculley</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1">Balaji Lakshminarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_J/0/1/0/all/0/1">Jasper Snoek</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1">Dustin Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04015">
                                    <div class="article-summary-box-inner">
                                        <span>High-quality estimates of uncertainty and robustness are crucial for numerous
real-world applications, especially for deep learning which underlies many
deployed ML systems. The ability to compare techniques for improving these
estimates is therefore very important for research and practice alike. Yet,
competitive comparisons of methods are often lacking due to a range of reasons,
including: compute availability for extensive tuning, incorporation of
sufficiently many baselines, and concrete documentation for reproducibility. In
this paper we introduce Uncertainty Baselines: high-quality implementations of
standard and state-of-the-art deep learning methods on a variety of tasks. As
of this writing, the collection spans 19 methods across 9 tasks, each with at
least 5 metrics. Each baseline is a self-contained experiment pipeline with
easily reusable and extendable components. Our goal is to provide immediate
starting points for experimentation with new methods or applications.
Additionally we provide model checkpoints, experiment outputs as Python
notebooks, and leaderboards for comparing results. Code available at
https://github.com/google/uncertainty-baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seeing All From a Few: Nodes Selection Using Graph Pooling for Graph Clustering. (arXiv:2105.05320v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yiming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">Dongxia Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zhiqian Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05320">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been considerable research interest in graph clustering
aimed at data partition using the graph information. However, one limitation of
the most of graph-based methods is that they assume the graph structure to
operate is fixed and reliable. And there are inevitably some edges in the graph
that are not conducive to graph clustering, which we call spurious edges. This
paper is the first attempt to employ graph pooling technique for node
clustering and we propose a novel dual graph embedding network (DGEN), which is
designed as a two-step graph encoder connected by a graph pooling layer to
learn the graph embedding. In our model, it is assumed that if a node and its
nearest neighboring node are close to the same clustering center, this node is
an informative node and this edge can be considered as a cluster-friendly edge.
Based on this assumption, the neighbor cluster pooling (NCPool) is devised to
select the most informative subset of nodes and the corresponding edges based
on the distance of nodes and their nearest neighbors to the cluster centers.
This can effectively alleviate the impact of the spurious edges on the
clustering. Finally, to obtain the clustering assignment of all nodes, a
classifier is trained using the clustering results of the selected nodes.
Experiments on five benchmark graph datasets demonstrate the superiority of the
proposed method over state-of-the-art algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rotating spiders and reflecting dogs: a class conditional approach to learning data augmentation distributions. (arXiv:2106.04009v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahan_S/0/1/0/all/0/1">Scott Mahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1">Henry Kvinge</a>, <a href="http://arxiv.org/find/cs/1/au:+Doster_T/0/1/0/all/0/1">Tim Doster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04009">
                                    <div class="article-summary-box-inner">
                                        <span>Building invariance to non-meaningful transformations is essential to
building efficient and generalizable machine learning models. In practice, the
most common way to learn invariance is through data augmentation. There has
been recent interest in the development of methods that learn distributions on
augmentation transformations from the training data itself. While such
approaches are beneficial since they are responsive to the data, they ignore
the fact that in many situations the range of transformations to which a model
needs to be invariant changes depending on the particular class input belongs
to. For example, if a model needs to be able to predict whether an image
contains a starfish or a dog, we may want to apply random rotations to starfish
images during training (since these do not have a preferred orientation), but
we would not want to do this to images of dogs. In this work we introduce a
method by which we can learn class conditional distributions on augmentation
transformations. We give a number of examples where our methods learn different
non-meaningful transformations depending on class and further show how our
method can be used as a tool to probe the symmetries intrinsic to a potentially
complex dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LEADS: Learning Dynamical Systems that Generalize Across Environments. (arXiv:2106.04546v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yuan Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayed_I/0/1/0/all/0/1">Ibrahim Ayed</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezenac_E/0/1/0/all/0/1">Emmanuel de B&#xe9;zenac</a>, <a href="http://arxiv.org/find/cs/1/au:+Baskiotis_N/0/1/0/all/0/1">Nicolas Baskiotis</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04546">
                                    <div class="article-summary-box-inner">
                                        <span>When modeling dynamical systems from real-world data samples, the
distribution of data often changes according to the environment in which they
are captured, and the dynamics of the system itself vary from one environment
to another. Generalizing across environments thus challenges the conventional
frameworks. The classical settings suggest either considering data as i.i.d.
and learning a single model to cover all situations or learning
environment-specific models. Both are sub-optimal: the former disregards the
discrepancies between environments leading to biased solutions, while the
latter does not exploit their potential commonalities and is prone to scarcity
problems. We propose LEADS, a novel framework that leverages the commonalities
and discrepancies among known environments to improve model generalization.
This is achieved with a tailored training formulation aiming at capturing
common dynamics within a shared model while additional terms capture
environment-specific dynamics. We ground our approach in theory, exhibiting a
decrease in sample complexity with our approach and corroborate these results
empirically, instantiating it for linear dynamics. Moreover, we concretize this
framework for neural networks and evaluate it experimentally on representative
families of nonlinear dynamics. We show that this new setting can exploit
knowledge extracted from environment-dependent data and improves generalization
for both known and novel environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Directional Bias Amplification. (arXiv:2102.12594v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Angelina Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1">Olga Russakovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12594">
                                    <div class="article-summary-box-inner">
                                        <span>Mitigating bias in machine learning systems requires refining our
understanding of bias propagation pathways: from societal structures to
large-scale data to trained models to impact on society. In this work, we focus
on one aspect of the problem, namely bias amplification: the tendency of models
to amplify the biases present in the data they are trained on. A metric for
measuring bias amplification was introduced in the seminal work by Zhao et al.
(2017); however, as we demonstrate, this metric suffers from a number of
shortcomings including conflating different types of bias amplification and
failing to account for varying base rates of protected attributes. We introduce
and analyze a new, decoupled metric for measuring bias amplification,
$\text{BiasAmp}_{\rightarrow}$ (Directional Bias Amplification). We thoroughly
analyze and discuss both the technical assumptions and normative implications
of this metric. We provide suggestions about its measurement by cautioning
against predicting sensitive attributes, encouraging the use of confidence
intervals due to fluctuations in the fairness of models across runs, and
discussing the limitations of what this metric captures. Throughout this paper,
we work to provide an interrogative look at the technical measurement of bias
amplification, guided by our normative ideas of what we want it to encompass.
Code is located at https://github.com/princetonvisualai/directional-bias-amp</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Sparse Training for Deep Reinforcement Learning. (arXiv:2106.04217v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sokar_G/0/1/0/all/0/1">Ghada Sokar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mocanu_E/0/1/0/all/0/1">Elena Mocanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1">Decebal Constantin Mocanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1">Peter Stone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04217">
                                    <div class="article-summary-box-inner">
                                        <span>Deep reinforcement learning has achieved significant success in many
decision-making tasks in various fields. However, it requires a large training
time of dense neural networks to obtain a good performance. This hinders its
applicability on low-resource devices where memory and computation are strictly
constrained. In a step towards enabling deep reinforcement learning agents to
be applied to low-resource devices, in this work, we propose for the first time
to dynamically train deep reinforcement learning agents with sparse neural
networks from scratch. We adopt the evolution principles of dynamic sparse
training in the reinforcement learning paradigm and introduce a training
algorithm that optimizes the sparse topology and the weight values jointly to
dynamically fit the incoming data. Our approach is easy to be integrated into
existing deep reinforcement learning algorithms and has many favorable
advantages. First, it allows for significant compression of the network size
which reduces the memory and computation costs substantially. This would
accelerate not only the agent inference but also its training process. Second,
it speeds up the agent learning process and allows for reducing the number of
required training steps. Third, it can achieve higher performance than training
the dense counterpart network. We evaluate our approach on OpenAI gym
continuous control tasks. The experimental results show the effectiveness of
our approach in achieving higher performance than one of the state-of-art
baselines with a 50\% reduction in the network size and floating-point
operations (FLOPs). Moreover, our proposed approach can reach the same
performance achieved by the dense network with a 40-50\% reduction in the
number of training steps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Graph-level Representation Learning with Local and Global Structure. (arXiv:2106.04113v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Minghao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1">Bingbing Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hongyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04113">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies unsupervised/self-supervised whole-graph representation
learning, which is critical in many tasks such as molecule properties
prediction in drug and material discovery. Existing methods mainly focus on
preserving the local similarity structure between different graph instances but
fail to discover the global semantic structure of the entire data set. In this
paper, we propose a unified framework called Local-instance and Global-semantic
Learning (GraphLoG) for self-supervised whole-graph representation learning.
Specifically, besides preserving the local similarities, GraphLoG introduces
the hierarchical prototypes to capture the global semantic clusters. An
efficient online expectation-maximization (EM) algorithm is further developed
for learning the model. We evaluate GraphLoG by pre-training it on massive
unlabeled graphs followed by fine-tuning on downstream tasks. Extensive
experiments on both chemical and biological benchmark data sets demonstrate the
effectiveness of the proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time-series Imputation of Temporally-occluded Multiagent Trajectories. (arXiv:2106.04219v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Omidshafiei_S/0/1/0/all/0/1">Shayegan Omidshafiei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennes_D/0/1/0/all/0/1">Daniel Hennes</a>, <a href="http://arxiv.org/find/cs/1/au:+Garnelo_M/0/1/0/all/0/1">Marta Garnelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarassov_E/0/1/0/all/0/1">Eugene Tarassov</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Elie_R/0/1/0/all/0/1">Romuald Elie</a>, <a href="http://arxiv.org/find/cs/1/au:+Connor_J/0/1/0/all/0/1">Jerome T. Connor</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_P/0/1/0/all/0/1">Paul Muller</a>, <a href="http://arxiv.org/find/cs/1/au:+Graham_I/0/1/0/all/0/1">Ian Graham</a>, <a href="http://arxiv.org/find/cs/1/au:+Spearman_W/0/1/0/all/0/1">William Spearman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1">Karl Tuyls</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04219">
                                    <div class="article-summary-box-inner">
                                        <span>In multiagent environments, several decision-making individuals interact
while adhering to the dynamics constraints imposed by the environment. These
interactions, combined with the potential stochasticity of the agents&#x27;
decision-making processes, make such systems complex and interesting to study
from a dynamical perspective. Significant research has been conducted on
learning models for forward-direction estimation of agent behaviors, for
example, pedestrian predictions used for collision-avoidance in self-driving
cars. However, in many settings, only sporadic observations of agents may be
available in a given trajectory sequence. For instance, in football, subsets of
players may come in and out of view of broadcast video footage, while
unobserved players continue to interact off-screen. In this paper, we study the
problem of multiagent time-series imputation, where available past and future
observations of subsets of agents are used to estimate missing observations for
other agents. Our approach, called the Graph Imputer, uses forward- and
backward-information in combination with graph networks and variational
autoencoders to enable learning of a distribution of imputed trajectories. We
evaluate our approach on a dataset of football matches, using a projective
camera module to train and evaluate our model for the off-screen player state
estimation setting. We illustrate that our method outperforms several
state-of-the-art approaches, including those hand-crafted for football.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Mixture Density Networks. (arXiv:2012.03085v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Errica_F/0/1/0/all/0/1">Federico Errica</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1">Davide Bacciu</a>, <a href="http://arxiv.org/find/cs/1/au:+Micheli_A/0/1/0/all/0/1">Alessio Micheli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03085">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the Graph Mixture Density Networks, a new family of machine
learning models that can fit multimodal output distributions conditioned on
graphs of arbitrary topology. By combining ideas from mixture models and graph
representation learning, we address a broader class of challenging conditional
density estimation problems that rely on structured data. In this respect, we
evaluate our method on a new benchmark application that leverages random graphs
for stochastic epidemic simulations. We show a significant improvement in the
likelihood of epidemic outcomes when taking into account both multimodality and
structure. The empirical analysis is complemented by two real-world regression
tasks showing the effectiveness of our approach in modeling the output
prediction uncertainty. Graph Mixture Density Networks open appealing research
opportunities in the study of structure-dependent phenomena that exhibit
non-trivial conditional output distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XIRL: Cross-embodiment Inverse Reinforcement Learning. (arXiv:2106.03911v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zakka_K/0/1/0/all/0/1">Kevin Zakka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Andy Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1">Pete Florence</a>, <a href="http://arxiv.org/find/cs/1/au:+Tompson_J/0/1/0/all/0/1">Jonathan Tompson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bohg_J/0/1/0/all/0/1">Jeannette Bohg</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1">Debidatta Dwibedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03911">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the visual cross-embodiment imitation setting, in which agents
learn policies from videos of other agents (such as humans) demonstrating the
same task, but with stark differences in their embodiments -- shape, actions,
end-effector dynamics, etc. In this work, we demonstrate that it is possible to
automatically discover and learn vision-based reward functions from
cross-embodiment demonstration videos that are robust to these differences.
Specifically, we present a self-supervised method for Cross-embodiment Inverse
Reinforcement Learning (XIRL) that leverages temporal cycle-consistency
constraints to learn deep visual embeddings that capture task progression from
offline videos of demonstrations across multiple expert agents, each performing
the same task differently due to embodiment differences. Prior to our work,
producing rewards from self-supervised embeddings has typically required
alignment with a reference trajectory, which may be difficult to acquire. We
show empirically that if the embeddings are aware of task-progress, simply
taking the negative distance between the current state and goal state in the
learned embedding space is useful as a reward for training policies with
reinforcement learning. We find our learned reward function not only works for
embodiments seen during training, but also generalizes to entirely new
embodiments. We also find that XIRL policies are more sample efficient than
baselines, and in some cases exceed the sample efficiency of the same agent
trained with ground truth sparse rewards.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BIGDML: Towards Exact Machine Learning Force Fields for Materials. (arXiv:2106.04229v1 [cond-mat.mtrl-sci])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Sauceda_H/0/1/0/all/0/1">Huziel E. Sauceda</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Galvez_Gonzalez_L/0/1/0/all/0/1">Luis E. G&#xe1;lvez-Gonz&#xe1;lez</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Chmiela_S/0/1/0/all/0/1">Stefan Chmiela</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Paz_Borbon_L/0/1/0/all/0/1">Lauro Oliver Paz-Borb&#xf3;n</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Muller_K/0/1/0/all/0/1">Klaus-Robert M&#xfc;ller</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Tkatchenko_A/0/1/0/all/0/1">Alexandre Tkatchenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04229">
                                    <div class="article-summary-box-inner">
                                        <span>Machine-learning force fields (MLFF) should be accurate, computationally and
data efficient, and applicable to molecules, materials, and interfaces thereof.
Currently, MLFFs often introduce tradeoffs that restrict their practical
applicability to small subsets of chemical space or require exhaustive datasets
for training. Here, we introduce the Bravais-Inspired Gradient-Domain Machine
Learning (BIGDML) approach and demonstrate its ability to construct reliable
force fields using a training set with just 10-200 geometries for materials
including pristine and defect-containing 2D and 3D semiconductors and metals,
as well as chemisorbed and physisorbed atomic and molecular adsorbates on
surfaces. The BIGDML model employs the full relevant symmetry group for a given
material, does not assume artificial atom types or localization of atomic
interactions and exhibits high data efficiency and state-of-the-art energy
accuracies (errors substantially below 1 meV per atom) for an extended set of
materials. Extensive path-integral molecular dynamics carried out with BIGDML
models demonstrate the counterintuitive localization of benzene--graphene
dynamics induced by nuclear quantum effects and allow to rationalize the
Arrhenius behavior of hydrogen diffusion coefficient in a Pd crystal for a wide
range of temperatures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Robust Detection of Out-of-distribution Data (almost) for free. (arXiv:2106.04260v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meinke_A/0/1/0/all/0/1">Alexander Meinke</a>, <a href="http://arxiv.org/find/cs/1/au:+Bitterwolf_J/0/1/0/all/0/1">Julian Bitterwolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1">Matthias Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04260">
                                    <div class="article-summary-box-inner">
                                        <span>When applying machine learning in safety-critical systems, a reliable
assessment of the uncertainy of a classifier is required. However, deep neural
networks are known to produce highly overconfident predictions on
out-of-distribution (OOD) data and even if trained to be non-confident on OOD
data one can still adversarially manipulate OOD data so that the classifer
again assigns high confidence to the manipulated samples. In this paper we
propose a novel method where from first principles we combine a certifiable OOD
detector with a standard classifier into an OOD aware classifier. In this way
we achieve the best of two worlds: certifiably adversarially robust OOD
detection, even for OOD samples close to the in-distribution, without loss in
prediction accuracy and close to state-of-the-art OOD detection performance for
non-manipulated OOD data. Moreover, due to the particular construction our
classifier provably avoids the asymptotic overconfidence problem of standard
neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Sampling in POMDPs with Lipschitz Bandits for Motion Planning in Continuous Spaces. (arXiv:2106.04206v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tas_O/0/1/0/all/0/1">&#xd6;mer &#x15e;ahin Ta&#x15f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauser_F/0/1/0/all/0/1">Felix Hauser</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauer_M/0/1/0/all/0/1">Martin Lauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04206">
                                    <div class="article-summary-box-inner">
                                        <span>Decision making under uncertainty can be framed as a partially observable
Markov decision process (POMDP). Finding exact solutions of POMDPs is generally
computationally intractable, but the solution can be approximated by
sampling-based approaches. These sampling-based POMDP solvers rely on
multi-armed bandit (MAB) heuristics, which assume the outcomes of different
actions to be uncorrelated. In some applications, like motion planning in
continuous spaces, similar actions yield similar outcomes. In this paper, we
utilize variants of MAB heuristics that make Lipschitz continuity assumptions
on the outcomes of actions to improve the efficiency of sampling-based planning
approaches. We demonstrate the effectiveness of this approach in the context of
motion planning for automated driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Byakto Speech: Real-time long speech synthesis with convolutional neural network: Transfer learning from English to Bangla. (arXiv:2106.03937v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nazi_Z/0/1/0/all/0/1">Zabir Al Nazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huda_S/0/1/0/all/0/1">Sayed Mohammed Tasmimul Huda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03937">
                                    <div class="article-summary-box-inner">
                                        <span>Speech synthesis is one of the challenging tasks to automate by deep
learning, also being a low-resource language there are very few attempts at
Bangla speech synthesis. Most of the existing works can&#x27;t work with anything
other than simple Bangla characters script, very short sentences, etc. This
work attempts to solve these problems by introducing Byakta, the first-ever
open-source deep learning-based bilingual (Bangla and English) text to a speech
synthesis system. A speech recognition model-based automated scoring metric was
also proposed to evaluate the performance of a TTS model. We also introduce a
test benchmark dataset for Bangla speech synthesis models for evaluating speech
quality. The TTS is available at https://github.com/zabir-nabil/bangla-tts</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signal Transformer: Complex-valued Attention and Meta-Learning for Signal Recognition. (arXiv:2106.04392v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yihong Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Ying Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Muqiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Songtao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1">Qingjiang Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04392">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have been shown as a class of useful tools for
addressing signal recognition issues in recent years, especially for
identifying the nonlinear feature structures of signals. However, this power of
most deep learning techniques heavily relies on an abundant amount of training
data, so the performance of classic neural nets decreases sharply when the
number of training data samples is small or unseen data are presented in the
testing phase. This calls for an advanced strategy, i.e., model-agnostic
meta-learning (MAML), which is able to capture the invariant representation of
the data samples or signals. In this paper, inspired by the special structure
of the signal, i.e., real and imaginary parts consisted in practical
time-series signals, we propose a Complex-valued Attentional MEta Learner
(CAMEL) for the problem of few-shot signal recognition by leveraging attention
and meta-learning in the complex domain. To the best of our knowledge, this is
also the first complex-valued MAML that can find the first-order stationary
points of general nonconvex problems with theoretical convergence guarantees.
Extensive experiments results showcase the superiority of the proposed CAMEL
compared with the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MindReader: Recommendation over Knowledge Graph Entities with Explicit User Ratings. (arXiv:2106.04209v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brams_A/0/1/0/all/0/1">Anders H. Brams</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakobsen_A/0/1/0/all/0/1">Anders L. Jakobsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jendal_T/0/1/0/all/0/1">Theis E. Jendal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lissandrini_M/0/1/0/all/0/1">Matteo Lissandrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolog_P/0/1/0/all/0/1">Peter Dolog</a>, <a href="http://arxiv.org/find/cs/1/au:+Hose_K/0/1/0/all/0/1">Katja Hose</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04209">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graphs (KGs) have been integrated in several models of
recommendation to augment the informational value of an item by means of its
related entities in the graph. Yet, existing datasets only provide explicit
ratings on items and no information is provided about user opinions of other
(non-recommendable) entities. To overcome this limitation, we introduce a new
dataset, called the MindReader, providing explicit user ratings both for items
and for KG entities. In this first version, the MindReader dataset provides
more than 102 thousands explicit ratings collected from 1,174 real users on
both items and entities from a KG in the movie domain. This dataset has been
collected through an online interview application that we also release open
source. As a demonstration of the importance of this new dataset, we present a
comparative study of the effect of the inclusion of ratings on non-item KG
entities in a variety of state-of-the-art recommendation models. In particular,
we show that most models, whether designed specifically for graph data or not,
see improvements in recommendation quality when trained on explicit non-item
ratings. Moreover, for some models, we show that non-item ratings can
effectively replace item ratings without loss of recommendation quality. This
finding, thanks also to an observed greater familiarity of users towards common
KG entities than towards long-tail items, motivates the use of KG entities for
both warm and cold-start recommendations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mime: Mimicking Centralized Stochastic Algorithms in Federated Learning. (arXiv:2008.03606v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1">Sai Praneeth Karimireddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1">Martin Jaggi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kale_S/0/1/0/all/0/1">Satyen Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohri_M/0/1/0/all/0/1">Mehryar Mohri</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddi_S/0/1/0/all/0/1">Sashank J. Reddi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1">Sebastian U. Stich</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1">Ananda Theertha Suresh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03606">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is a challenging setting for optimization due to the
heterogeneity of the data across different clients which gives rise to the
client drift phenomenon. In fact, obtaining an algorithm for FL which is
uniformly better than simple centralized training has been a major open problem
thus far. In this work, we propose a general algorithmic framework, Mime, which
i) mitigates client drift and ii) adapts arbitrary centralized optimization
algorithms such as momentum and Adam to the cross-device federated learning
setting. Mime uses a combination of control-variates and server-level
statistics (e.g. momentum) at every client-update step to ensure that each
local update mimics that of the centralized method run on iid data. We prove a
reduction result showing that Mime can translate the convergence of a generic
algorithm in the centralized setting into convergence in the federated setting.
Further, we show that when combined with momentum based variance reduction,
Mime is provably faster than any centralized method--the first such result. We
also perform a thorough experimental exploration of Mime&#x27;s performance on real
world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Breaking the Limits of Message Passing Graph Neural Networks. (arXiv:2106.04319v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balcilar_M/0/1/0/all/0/1">Muhammet Balcilar</a>, <a href="http://arxiv.org/find/cs/1/au:+Heroux_P/0/1/0/all/0/1">Pierre H&#xe9;roux</a>, <a href="http://arxiv.org/find/cs/1/au:+Gauzere_B/0/1/0/all/0/1">Benoit Ga&#xfc;z&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasseur_P/0/1/0/all/0/1">Pascal Vasseur</a>, <a href="http://arxiv.org/find/cs/1/au:+Adam_S/0/1/0/all/0/1">S&#xe9;bastien Adam</a>, <a href="http://arxiv.org/find/cs/1/au:+Honeine_P/0/1/0/all/0/1">Paul Honeine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04319">
                                    <div class="article-summary-box-inner">
                                        <span>Since the Message Passing (Graph) Neural Networks (MPNNs) have a linear
complexity with respect to the number of nodes when applied to sparse graphs,
they have been widely implemented and still raise a lot of interest even though
their theoretical expressive power is limited to the first order
Weisfeiler-Lehman test (1-WL). In this paper, we show that if the graph
convolution supports are designed in spectral-domain by a non-linear custom
function of eigenvalues and masked with an arbitrary large receptive field, the
MPNN is theoretically more powerful than the 1-WL test and experimentally as
powerful as a 3-WL existing models, while remaining spatially localized.
Moreover, by designing custom filter functions, outputs can have various
frequency components that allow the convolution process to learn different
relationships between a given input graph signal and its associated properties.
So far, the best 3-WL equivalent graph neural networks have a computational
complexity in $\mathcal{O}(n^3)$ with memory usage in $\mathcal{O}(n^2)$,
consider non-local update mechanism and do not provide the spectral richness of
output profile. The proposed method overcomes all these aforementioned problems
and reaches state-of-the-art results in many downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Task Hierarchical Learning Based Network Traffic Analytics. (arXiv:2106.03850v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barut_O/0/1/0/all/0/1">Onur Barut</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weigang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peilong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03850">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying network traffic is the basis for important network applications.
Prior research in this area has faced challenges on the availability of
representative datasets, and many of the results cannot be readily reproduced.
Such a problem is exacerbated by emerging data-driven machine learning based
approaches. To address this issue, we present(N et)2databasewith three open
datasets containing nearly 1.3M labeled flows in total, with a comprehensive
list of flow features, for there search community1. We focus on broad aspects
in network traffic analysis, including both malware detection and application
classification. As we continue to grow them, we expect the datasets to serve as
a common ground for AI driven, reproducible research on network flow analytics.
We release the datasets publicly and also introduce a Multi-Task Hierarchical
Learning (MTHL)model to perform all tasks in a single model. Our results show
that MTHL is capable of accurately performing multiple tasks with hierarchical
labeling with a dramatic reduction in training time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-grained Out-of-Distribution Detection with Mixup Outlier Exposure. (arXiv:2106.03917v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Inkawhich_N/0/1/0/all/0/1">Nathan Inkawhich</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hai Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03917">
                                    <div class="article-summary-box-inner">
                                        <span>Enabling out-of-distribution (OOD) detection for DNNs is critical for their
safe and reliable operation in the &quot;open world&quot;. Unfortunately, current works
in both methodology and evaluation focus on rather contrived detection
problems, and only consider a coarse level of granularity w.r.t.: 1) the
in-distribution (ID) classes, and 2) the OOD data&#x27;s &quot;closeness&quot; to the ID data.
We posit that such settings may be poor approximations of many real-world tasks
that are naturally fine-grained (e.g., bird species classification), and thus
the reported detection abilities may be over-estimates. Differently, in this
work we make granularity a top priority and focus on fine-grained OOD
detection. We start by carefully constructing five novel fine-grained test
environments in which existing methods are shown to have difficulties. We then
propose a new DNN training algorithm, Mixup Outlier Exposure (MixupOE), which
leverages an outlier distribution and principles from vicinal risk
minimization. Finally, we perform extensive experiments and analyses in our
custom test environments and demonstrate that MixupOE can consistently improve
fine-grained detection performance, establishing a strong baseline in these
more realistic and challenging OOD detection settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Targeted Active Learning for Bayesian Decision-Making. (arXiv:2106.04193v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Filstroff_L/0/1/0/all/0/1">Louis Filstroff</a>, <a href="http://arxiv.org/find/stat/1/au:+Sundin_I/0/1/0/all/0/1">Iiris Sundin</a>, <a href="http://arxiv.org/find/stat/1/au:+Mikkola_P/0/1/0/all/0/1">Petrus Mikkola</a>, <a href="http://arxiv.org/find/stat/1/au:+Tiulpin_A/0/1/0/all/0/1">Aleksei Tiulpin</a>, <a href="http://arxiv.org/find/stat/1/au:+Kylmaoja_J/0/1/0/all/0/1">Juuso Kylm&#xe4;oja</a>, <a href="http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1">Samuel Kaski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04193">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning is usually applied to acquire labels of informative data
points in supervised learning, to maximize accuracy in a sample-efficient way.
However, maximizing the accuracy is not the end goal when the results are used
for decision-making, for example in personalized medicine or economics. We
argue that when acquiring samples sequentially, separating learning and
decision-making is sub-optimal, and we introduce a novel active learning
strategy which takes the down-the-line decision problem into account.
Specifically, we introduce a novel active learning criterion which maximizes
the expected information gain on the posterior distribution of the optimal
decision. We compare our decision-making-aware active learning strategy to
existing alternatives on both simulated and real data, and show improved
performance in decision-making accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TENGraD: Time-Efficient Natural Gradient Descent with Exact Fisher-Block Inversion. (arXiv:2106.03947v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soori_S/0/1/0/all/0/1">Saeed Soori</a>, <a href="http://arxiv.org/find/cs/1/au:+Can_B/0/1/0/all/0/1">Bugra Can</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_B/0/1/0/all/0/1">Baourun Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1">Mert G&#xfc;rb&#xfc;zbalaban</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehnavi_M/0/1/0/all/0/1">Maryam Mehri Dehnavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03947">
                                    <div class="article-summary-box-inner">
                                        <span>This work proposes a time-efficient Natural Gradient Descent method, called
TENGraD, with linear convergence guarantees. Computing the inverse of the
neural network&#x27;s Fisher information matrix is expensive in NGD because the
Fisher matrix is large. Approximate NGD methods such as KFAC attempt to improve
NGD&#x27;s running time and practical application by reducing the Fisher matrix
inversion cost with approximation. However, the approximations do not reduce
the overall time significantly and lead to less accurate parameter updates and
loss of curvature information. TENGraD improves the time efficiency of NGD by
computing Fisher block inverses with a computationally efficient covariance
factorization and reuse method. It computes the inverse of each block exactly
using the Woodbury matrix identity to preserve curvature information while
admitting (linear) fast convergence rates. Our experiments on image
classification tasks for state-of-the-art deep neural architecture on CIFAR-10,
CIFAR-100, and Fashion-MNIST show that TENGraD significantly outperforms
state-of-the-art NGD methods and often stochastic gradient descent in
wall-clock time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards a Theoretical Framework of Out-of-Distribution Generalization. (arXiv:2106.04496v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Haotian Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chuanlong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1">Tianle Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruichen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04496">
                                    <div class="article-summary-box-inner">
                                        <span>Generalization to out-of-distribution (OOD) data, or domain generalization,
is one of the central problems in modern machine learning. Recently, there is a
surge of attempts to propose algorithms for OOD that mainly build upon the idea
of extracting invariant features. Although intuitively reasonable, theoretical
understanding of what kind of invariance can guarantee OOD generalization is
still limited, and generalization to arbitrary out-of-distribution is clearly
impossible. In this work, we take the first step towards rigorous and
quantitative definitions of 1) what is OOD; and 2) what does it mean by saying
an OOD problem is learnable. We also introduce a new concept of expansion
function, which characterizes to what extent the variance is amplified in the
test domains over the training domains, and therefore give a quantitative
meaning of invariant features. Based on these, we prove OOD generalization
error bounds. It turns out that OOD generalization largely depends on the
expansion function. As recently pointed out by Gulrajani and Lopez-Paz (2020),
any OOD learning algorithm without a model selection module is incomplete. Our
theory naturally induces a model selection criterion. Extensive experiments on
benchmark OOD datasets demonstrate that our model selection criterion has a
significant advantage over baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coresets for Classification -- Simplified and Strengthened. (arXiv:2106.04254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1">Tung Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Anup B. Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04254">
                                    <div class="article-summary-box-inner">
                                        <span>We give relative error coresets for training linear classifiers with a broad
class of loss functions, including the logistic loss and hinge loss. Our
construction achieves $(1\pm \epsilon)$ relative error with $\tilde O(d \cdot
\mu_y(X)^2/\epsilon^2)$ points, where $\mu_y(X)$ is a natural complexity
measure of the data matrix $X \in \mathbb{R}^{n \times d}$ and label vector $y
\in \{-1,1\}^n$, introduced in by Munteanu et al. 2018. Our result is based on
subsampling data points with probabilities proportional to their $\ell_1$
$Lewis$ $weights$. It significantly improves on existing theoretical bounds and
performs well in practice, outperforming uniform subsampling along with other
importance sampling methods. Our sampling distribution does not depend on the
labels, so can be used for active learning. It also does not depend on the
specific loss function, so a single coreset can be used in multiple training
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Improving Adversarial Transferability of Vision Transformers. (arXiv:2106.04169v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseer_M/0/1/0/all/0/1">Muzammal Naseer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranasinghe_K/0/1/0/all/0/1">Kanchana Ranasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Fahad Shahbaz Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Porikli_F/0/1/0/all/0/1">Fatih Porikli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04169">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformers (ViTs) process input images as sequences of patches via
self-attention; a radically different architecture than convolutional neural
networks (CNNs). This makes it interesting to study the adversarial feature
space of ViT models and their transferability. In particular, we observe that
adversarial patterns found via conventional adversarial attacks show very low
black-box transferability even for large ViT models. However, we show that this
phenomenon is only due to the sub-optimal attack procedures that do not
leverage the true representation potential of ViTs. A deep ViT is composed of
multiple blocks, with a consistent architecture comprising of self-attention
and feed-forward layers, where each block is capable of independently producing
a class token. Formulating an attack using only the last class token
(conventional approach) does not directly leverage the discriminative
information stored in the earlier tokens, leading to poor adversarial
transferability of ViTs. Using the compositional nature of ViT models, we
enhance the transferability of existing attacks by introducing two novel
strategies specific to the architecture of ViT models. (i) Self-Ensemble: We
propose a method to find multiple discriminative pathways by dissecting a
single ViT model into an ensemble of networks. This allows explicitly utilizing
class-specific information at each ViT block. (ii) Token Refinement: We then
propose to refine the tokens to further enhance the discriminative capacity at
each block of ViT. Our token refinement systematically combines the class
tokens with structural information preserved within the patch tokens. An
adversarial attack, when applied to such refined tokens within the ensemble of
classifiers found in a single vision transformer, has significantly higher
transferability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter Inference with Bifurcation Diagrams. (arXiv:2106.04243v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Szep_G/0/1/0/all/0/1">Gregory Szep</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalchau_N/0/1/0/all/0/1">Neil Dalchau</a>, <a href="http://arxiv.org/find/cs/1/au:+Csikasz_Nagy_A/0/1/0/all/0/1">Attila Csikasz-Nagy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04243">
                                    <div class="article-summary-box-inner">
                                        <span>Estimation of parameters in differential equation models can be achieved by
applying learning algorithms to quantitative time-series data. However,
sometimes it is only possible to measure qualitative changes of a system in
response to a controlled condition. In dynamical systems theory, such change
points are known as \textit{bifurcations} and lie on a function of the
controlled condition called the \textit{bifurcation diagram}. In this work, we
propose a gradient-based semi-supervised approach for inferring the parameters
of differential equations that produce a user-specified bifurcation diagram.
The cost function contains a supervised error term that is minimal when the
model bifurcations match the specified targets and an unsupervised bifurcation
measure which has gradients that push optimisers towards bifurcating parameter
regimes. The gradients can be computed without the need to differentiate
through the operations of the solver that was used to compute the diagram. We
demonstrate parameter inference with minimal models which explore the space of
saddle-node and pitchfork diagrams and the genetic toggle switch from synthetic
biology. Furthermore, the cost landscape allows us to organise models in terms
of topological and geometric equivalence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Limited Memory Neural-Linear Bandits with Likelihood Matching. (arXiv:2102.03799v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nabati_O/0/1/0/all/0/1">Ofir Nabati</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahavy_T/0/1/0/all/0/1">Tom Zahavy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03799">
                                    <div class="article-summary-box-inner">
                                        <span>We study neural-linear bandits for solving problems where {\em both}
exploration and representation learning play an important role. Neural-linear
bandits harnesses the representation power of Deep Neural Networks (DNNs) and
combines it with efficient exploration mechanisms by leveraging uncertainty
estimation of the model, designed for linear contextual bandits on top of the
last hidden layer. In order to mitigate the problem of representation change
during the process, new uncertainty estimations are computed using stored data
from an unlimited buffer. Nevertheless, when the amount of stored data is
limited, a phenomenon called catastrophic forgetting emerges. To alleviate
this, we propose a likelihood matching algorithm that is resilient to
catastrophic forgetting and is completely online. We applied our algorithm,
Limited Memory Neural-Linear with Likelihood Matching (NeuralLinear-LiM2) on a
variety of datasets and observed that our algorithm achieves comparable
performance to the unlimited memory approach while exhibits resilience to
catastrophic forgetting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Runtime-Based Computational Performance Predictor for Deep Neural Network Training. (arXiv:2102.00527v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1">Geoffrey X. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yubo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Golikov_P/0/1/0/all/0/1">Pavel Golikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1">Gennady Pekhimenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00527">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning researchers and practitioners usually leverage GPUs to help
train their deep neural networks (DNNs) faster. However, choosing which GPU to
use is challenging both because (i) there are many options, and (ii) users
grapple with competing concerns: maximizing compute performance while
minimizing costs. In this work, we present a new practical technique to help
users make informed and cost-efficient GPU selections: make performance
predictions with the help of a GPU that the user already has. Our technique
exploits the observation that, because DNN training consists of repetitive
compute steps, predicting the execution time of a single iteration is usually
enough to characterize the performance of an entire training process. We make
predictions by scaling the execution time of each operation in a training
iteration from one GPU to another using either (i) wave scaling, a technique
based on a GPU&#x27;s execution model, or (ii) pre-trained multilayer perceptrons.
We implement our technique into a Python library called Habitat and find that
it makes accurate iteration execution time predictions (with an average error
of 11.8%) on ResNet-50, Inception v3, the Transformer, GNMT, and DCGAN across
six different GPU architectures. Habitat supports PyTorch, is easy to use, and
is open source.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-dataset Pretraining: A Unified Model for Semantic Segmentation. (arXiv:2106.04121v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Bowen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaopeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haohang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1">Wenrui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Junni Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hongkai Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04121">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting annotated data for semantic segmentation is time-consuming and
hard to scale up. In this paper, we for the first time propose a unified
framework, termed as Multi-Dataset Pretraining, to take full advantage of the
fragmented annotations of different datasets. The highlight is that the
annotations from different domains can be efficiently reused and consistently
boost performance for each specific domain. This is achieved by first
pretraining the network via the proposed pixel-to-prototype contrastive loss
over multiple datasets regardless of their taxonomy labels, and followed by
fine-tuning the pretrained model over specific dataset as usual. In order to
better model the relationship among images and classes from different datasets,
we extend the pixel level embeddings via cross dataset mixing and propose a
pixel-to-class sparse coding strategy that explicitly models the pixel-class
similarity over the manifold embedding space. In this way, we are able to
increase intra-class compactness and inter-class separability, as well as
considering inter-class similarity across different datasets for better
transferability. Experiments conducted on several benchmarks demonstrate its
superior performance. Notably, MDP consistently outperforms the pretrained
models over ImageNet by a considerable margin, while only using less than 10%
samples for pretraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Convergence of Entropy-Regularized Natural Policy Gradient with Linear Function Approximation. (arXiv:2106.04096v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cayci_S/0/1/0/all/0/1">Semih Cayci</a>, <a href="http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1">Niao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1">R. Srikant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04096">
                                    <div class="article-summary-box-inner">
                                        <span>Natural policy gradient (NPG) methods with function approximation achieve
impressive empirical success in reinforcement learning problems with large
state-action spaces. However, theoretical understanding of their convergence
behaviors remains limited in the function approximation setting. In this paper,
we perform a finite-time analysis of NPG with linear function approximation and
softmax parameterization, and prove for the first time that widely used entropy
regularization method, which encourages exploration, leads to linear
convergence rate. We adopt a Lyapunov drift analysis to prove the convergence
results and explain the effectiveness of entropy regularization in improving
the convergence rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Deep Q-Network for Autonomous Vehicles at Unsignalized Intersection. (arXiv:2106.04561v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mokhtari_K/0/1/0/all/0/1">Kasra Mokhtari</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1">Alan R. Wagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04561">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a safe DRL approach for autonomous vehicle (AV) navigation through
crowds of pedestrians while making a left turn at an unsignalized intersection.
Our method uses two long-short term memory (LSTM) models that are trained to
generate the perceived state of the environment and the future trajectories of
pedestrians given noisy observations of their movement. A future collision
prediction algorithm based on the future trajectories of the ego vehicle and
pedestrians is used to mask unsafe actions if the system predicts a collision.
The performance of our approach is evaluated in two experiments using the
high-fidelity CARLA simulation environment. The first experiment tests the
performance of our method at intersections that are similar to the training
intersection and the second experiment tests our method at intersections with a
different topology. For both experiments, our methods do not result in a
collision with a pedestrian while still navigating the intersection at a
reasonable speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable AI and Adoption of Financial Algorithmic Advisors: an Experimental Study. (arXiv:2101.02555v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+David_D/0/1/0/all/0/1">Daniel Ben David</a>, <a href="http://arxiv.org/find/cs/1/au:+Resheff_Y/0/1/0/all/0/1">Yehezkel S. Resheff</a>, <a href="http://arxiv.org/find/cs/1/au:+Tron_T/0/1/0/all/0/1">Talia Tron</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02555">
                                    <div class="article-summary-box-inner">
                                        <span>We study whether receiving advice from either a human or algorithmic advisor,
accompanied by five types of Local and Global explanation labelings, has an
effect on the readiness to adopt, willingness to pay, and trust in a financial
AI consultant. We compare the differences over time and in various key
situations using a unique experimental framework where participants play a
web-based game with real monetary consequences. We observed that accuracy-based
explanations of the model in initial phases leads to higher adoption rates.
When the performance of the model is immaculate, there is less importance
associated with the kind of explanation for adoption. Using more elaborate
feature-based or accuracy-based explanations helps substantially in reducing
the adoption drop upon model failure. Furthermore, using an autopilot increases
adoption significantly. Participants assigned to the AI-labeled advice with
explanations were willing to pay more for the advice than the AI-labeled advice
with a No-explanation alternative. These results add to the literature on the
importance of XAI for algorithmic adoption and trust.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Description and Discussion on DCASE 2021 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring under Domain Shifted Conditions. (arXiv:2106.04492v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kawaguchi_Y/0/1/0/all/0/1">Yohei Kawaguchi</a>, <a href="http://arxiv.org/find/eess/1/au:+Imoto_K/0/1/0/all/0/1">Keisuke Imoto</a>, <a href="http://arxiv.org/find/eess/1/au:+Koizumi_Y/0/1/0/all/0/1">Yuma Koizumi</a>, <a href="http://arxiv.org/find/eess/1/au:+Harada_N/0/1/0/all/0/1">Noboru Harada</a>, <a href="http://arxiv.org/find/eess/1/au:+Niizumi_D/0/1/0/all/0/1">Daisuke Niizumi</a>, <a href="http://arxiv.org/find/eess/1/au:+Dohi_K/0/1/0/all/0/1">Kota Dohi</a>, <a href="http://arxiv.org/find/eess/1/au:+Tanabe_R/0/1/0/all/0/1">Ryo Tanabe</a>, <a href="http://arxiv.org/find/eess/1/au:+Purohit_H/0/1/0/all/0/1">Harsh Purohit</a>, <a href="http://arxiv.org/find/eess/1/au:+Endo_T/0/1/0/all/0/1">Takashi Endo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04492">
                                    <div class="article-summary-box-inner">
                                        <span>We present the task description and discussion on the results of the DCASE
2021 Challenge Task 2. Last year, we organized unsupervised anomalous sound
detection (ASD) task; identifying whether the given sound is normal or
anomalous without anomalous training data. In this year, we organize an
advanced unsupervised ASD task under domain-shift conditions which focuses on
the inevitable problem for the practical use of ASD systems. The main challenge
of this task is to detect unknown anomalous sounds where the acoustic
characteristics of the training and testing samples are different, i.e.
domain-shifted. This problem is frequently occurs due to changes in seasons,
manufactured products, and/or environmental noise. After the challenge
submission deadline, we will add challenge results and analysis of the
submissions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$\ell_0$-based Sparse Canonical Correlation Analysis. (arXiv:2010.05620v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lindenbaum_O/0/1/0/all/0/1">Ofir Lindenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Salhov_M/0/1/0/all/0/1">Moshe Salhov</a>, <a href="http://arxiv.org/find/cs/1/au:+Averbuch_A/0/1/0/all/0/1">Amir Averbuch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kluger_Y/0/1/0/all/0/1">Yuval Kluger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05620">
                                    <div class="article-summary-box-inner">
                                        <span>Canonical Correlation Analysis (CCA) models are powerful for studying the
associations between two sets of variables. The canonically correlated
representations, termed \textit{canonical variates} are widely used in
unsupervised learning to analyze unlabeled multi-modal registered datasets.
Despite their success, CCA models may break (or overfit) if the number of
variables in either of the modalities exceeds the number of samples. Moreover,
often a significant fraction of the variables measures modality-specific
information, and thus removing them is beneficial for identifying the
\textit{canonically correlated variates}. Here, we propose $\ell_0$-CCA, a
method for learning correlated representations based on sparse subsets of
variables from two observed modalities. Sparsity is obtained by multiplying the
input variables by stochastic gates, whose parameters are learned together with
the CCA weights via an $\ell_0$-regularized correlation loss. We further
propose $\ell_0$-Deep CCA for solving the problem of non-linear sparse CCA by
modeling the correlated representations using deep nets. We demonstrate the
efficacy of the method using several synthetic and real examples. Most notably,
by gating nuisance input variables, our approach improves the extracted
representations compared to other linear, non-linear and sparse CCA-based
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss. (arXiv:2106.04156v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1">Jeff Z. HaoChen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04156">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works in self-supervised learning have advanced the state-of-the-art
by relying on the contrastive learning paradigm, which learns representations
by pushing positive pairs, or similar examples from the same class, closer
together while keeping negative pairs far apart. Despite the empirical
successes, theoretical foundations are limited -- prior analyses assume
conditional independence of the positive pairs given the same class label, but
recent empirical applications use heavily correlated positive pairs (i.e., data
augmentations of the same image). Our work analyzes contrastive learning
without assuming conditional independence of positive pairs using a novel
concept of the augmentation graph on data. Edges in this graph connect
augmentations of the same data, and ground-truth classes naturally form
connected sub-graphs. We propose a loss that performs spectral decomposition on
the population augmentation graph and can be succinctly written as a
contrastive learning objective on neural net representations. Minimizing this
objective leads to features with provable accuracy guarantees under linear
probe evaluation. By standard generalization bounds, these accuracy guarantees
also hold when minimizing the training contrastive loss. Empirically, the
features learned by our objective can match or outperform several strong
baselines on benchmark vision datasets. In all, this work provides the first
provable analysis for contrastive learning where guarantees for linear probe
evaluation can apply to realistic empirical settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating and Improving Adversarial Robustness of Machine Learning-Based Network Intrusion Detectors. (arXiv:2005.07519v4 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1">Dongqi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Ying Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiahai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shuqiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xingang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xia Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07519">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML), especially deep learning (DL) techniques have been
increasingly used in anomaly-based network intrusion detection systems (NIDS).
However, ML/DL has shown to be extremely vulnerable to adversarial attacks,
especially in such security-sensitive systems. Many adversarial attacks have
been proposed to evaluate the robustness of ML-based NIDSs. Unfortunately,
existing attacks mostly focused on feature-space and/or white-box attacks,
which make impractical assumptions in real-world scenarios, leaving the study
on practical gray/black-box attacks largely unexplored.

To bridge this gap, we conduct the first systematic study of the
gray/black-box traffic-space adversarial attacks to evaluate the robustness of
ML-based NIDSs. Our work outperforms previous ones in the following aspects:
(i) practical-the proposed attack can automatically mutate original traffic
with extremely limited knowledge and affordable overhead while preserving its
functionality; (ii) generic-the proposed attack is effective for evaluating the
robustness of various NIDSs using diverse ML/DL models and non-payload-based
features; (iii) explainable-we propose an explanation method for the fragile
robustness of ML-based NIDSs. Based on this, we also propose a defense scheme
against adversarial attacks to improve system robustness. We extensively
evaluate the robustness of various NIDSs using diverse feature sets and ML/DL
models. Experimental results show our attack is effective (e.g., &gt;97% evasion
rate in half cases for Kitsune, a state-of-the-art NIDS) with affordable
execution cost and the proposed defense method can effectively mitigate such
attacks (evasion rate is reduced by &gt;50% in most cases).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Heavy-Tail Phenomenon in SGD. (arXiv:2006.04740v4 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gurbuzbalaban_M/0/1/0/all/0/1">Mert Gurbuzbalaban</a>, <a href="http://arxiv.org/find/math/1/au:+Simsekli_U/0/1/0/all/0/1">Umut Simsekli</a>, <a href="http://arxiv.org/find/math/1/au:+Zhu_L/0/1/0/all/0/1">Lingjiong Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04740">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, various notions of capacity and complexity have been
proposed for characterizing the generalization properties of stochastic
gradient descent (SGD) in deep learning. Some of the popular notions that
correlate well with the performance on unseen data are (i) the &#x60;flatness&#x27; of
the local minimum found by SGD, which is related to the eigenvalues of the
Hessian, (ii) the ratio of the stepsize $\eta$ to the batch-size $b$, which
essentially controls the magnitude of the stochastic gradient noise, and (iii)
the &#x60;tail-index&#x27;, which measures the heaviness of the tails of the network
weights at convergence. In this paper, we argue that these three seemingly
unrelated perspectives for generalization are deeply linked to each other. We
claim that depending on the structure of the Hessian of the loss at the
minimum, and the choices of the algorithm parameters $\eta$ and $b$, the SGD
iterates will converge to a \emph{heavy-tailed} stationary distribution. We
rigorously prove this claim in the setting of quadratic optimization: we show
that even in a simple linear regression problem with independent and
identically distributed data whose distribution has finite moments of all
order, the iterates can be heavy-tailed with infinite variance. We further
characterize the behavior of the tails with respect to algorithm parameters,
the dimension, and the curvature. We then translate our results into insights
about the behavior of SGD in deep learning. We support our theory with
experiments conducted on synthetic data, fully connected, and convolutional
neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding (Generalized) Label Smoothing whenLearning with Noisy Labels. (arXiv:2106.04149v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jiaheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hangyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04149">
                                    <div class="article-summary-box-inner">
                                        <span>Label smoothing (LS) is an arising learning paradigm that uses the positively
weighted average of both the hard training labels and uniformly distributed
soft labels. It was shown that LS serves as a regularizer for training data
with hard labels and therefore improves the generalization of the model. Later
it was reported LS even helps with improving robustness when learning with
noisy labels. However, we observe that the advantage of LS vanishes when we
operate in a high label noise regime. Puzzled by the observation, we proceeded
to discover that several proposed learning-with-noisy-labels solutions in the
literature instead relate more closely to negative label smoothing (NLS), which
defines as using a negative weight to combine the hard and soft labels! We show
that NLS functions substantially differently from LS in their achieved model
confidence. To differentiate the two cases, we will call LS the positive label
smoothing (PLS), and this paper unifies PLS and NLS into generalized label
smoothing (GLS). We provide understandings for the properties of GLS when
learning with noisy labels. Among other established properties, we
theoretically show NLS is considered more beneficial when the label noise rates
are high. We provide experimental results to support our findings too.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpreting Deep Learning based Cerebral Palsy Prediction with Channel Attention. (arXiv:2106.04471v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Manli Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_Q/0/1/0/all/0/1">Qianhui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_E/0/1/0/all/0/1">Edmond S. L. Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Leung_H/0/1/0/all/0/1">Howard Leung</a>, <a href="http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1">Hubert P. H. Shum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04471">
                                    <div class="article-summary-box-inner">
                                        <span>Early prediction of cerebral palsy is essential as it leads to early
treatment and monitoring. Deep learning has shown promising results in
biomedical engineering thanks to its capacity of modelling complicated data
with its non-linear architecture. However, due to their complex structure, deep
learning models are generally not interpretable by humans, making it difficult
for clinicians to rely on the findings. In this paper, we propose a channel
attention module for deep learning models to predict cerebral palsy from
infants&#x27; body movements, which highlights the key features (i.e. body joints)
the model identifies as important, thereby indicating why certain diagnostic
results are found. To highlight the capacity of the deep network in modelling
input features, we utilize raw joint positions instead of hand-crafted
features. We validate our system with a real-world infant movement dataset. Our
proposed channel attention module enables the visualization of the vital joints
to this disease that the network considers. Our system achieves 91.67%
accuracy, suppressing other state-of-the-art deep learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Generalization despite Distribution Shift via Minimum Discriminating Information. (arXiv:2106.04443v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sutter_T/0/1/0/all/0/1">Tobias Sutter</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_D/0/1/0/all/0/1">Daniel Kuhn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04443">
                                    <div class="article-summary-box-inner">
                                        <span>Training models that perform well under distribution shifts is a central
challenge in machine learning. In this paper, we introduce a modeling framework
where, in addition to training data, we have partial structural knowledge of
the shifted test distribution. We employ the principle of minimum
discriminating information to embed the available prior knowledge, and use
distributionally robust optimization to account for uncertainty due to the
limited samples. By leveraging large deviation results, we obtain explicit
generalization bounds with respect to the unknown shifted distribution. Lastly,
we demonstrate the versatility of our framework by demonstrating it on two
rather distinct applications: (1) training classifiers on systematically biased
data and (2) off-policy evaluation in Markov Decision Processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XtremeDistilTransformers: Task Transfer for Task-agnostic Distillation. (arXiv:2106.04563v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1">Subhabrata Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed Hassan Awadallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04563">
                                    <div class="article-summary-box-inner">
                                        <span>While deep and large pre-trained models are the state-of-the-art for various
natural language processing tasks, their huge size poses significant challenges
for practical uses in resource constrained settings. Recent works in knowledge
distillation propose task-agnostic as well as task-specific methods to compress
these models, with task-specific ones often yielding higher compression rate.
In this work, we develop a new task-agnostic distillation framework
XtremeDistilTransformers that leverages the advantage of task-specific methods
for learning a small universal model that can be applied to arbitrary tasks and
languages. To this end, we study the transferability of several source tasks,
augmentation resources and model architecture for distillation. We evaluate our
model performance on multiple tasks, including the General Language
Understanding Evaluation (GLUE) benchmark, SQuAD question answering dataset and
a massive multi-lingual NER dataset with 41 languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks. (arXiv:2106.04537v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgnia_E/0/1/0/all/0/1">Eitan Borgnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Arjun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Furong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vishkin_U/0/1/0/all/0/1">Uzi Vishkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04537">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are powerful machines for visual pattern recognition,
but reasoning tasks that are easy for humans may still be difficult for neural
models. Humans possess the ability to extrapolate reasoning strategies learned
on simple problems to solve harder examples, often by thinking for longer. For
example, a person who has learned to solve small mazes can easily extend the
very same search techniques to solve much larger mazes by spending more time.
In computers, this behavior is often achieved through the use of algorithms,
which scale to arbitrarily hard problem instances at the cost of more
computation. In contrast, the sequential computing budget of feed-forward
neural networks is limited by their depth, and networks trained on simple
problems have no way of extending their reasoning to accommodate harder
problems. In this work, we show that recurrent networks trained to solve simple
problems with few recurrent steps can indeed solve much more complex problems
simply by performing additional recurrences during inference. We demonstrate
this algorithmic behavior of recurrent networks on prefix sum computation,
mazes, and chess. In all three domains, networks trained on simple problem
instances are able to extend their reasoning abilities at test time simply by
&quot;thinking for longer.&quot;</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Giving Commands to a Self-Driving Car: How to Deal with Uncertain Situations?. (arXiv:2106.04232v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deruyttere_T/0/1/0/all/0/1">Thierry Deruyttere</a>, <a href="http://arxiv.org/find/cs/1/au:+Milewski_V/0/1/0/all/0/1">Victor Milewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1">Marie-Francine Moens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04232">
                                    <div class="article-summary-box-inner">
                                        <span>Current technology for autonomous cars primarily focuses on getting the
passenger from point A to B. Nevertheless, it has been shown that passengers
are afraid of taking a ride in self-driving cars. One way to alleviate this
problem is by allowing the passenger to give natural language commands to the
car. However, the car can misunderstand the issued command or the visual
surroundings which could lead to uncertain situations. It is desirable that the
self-driving car detects these situations and interacts with the passenger to
solve them. This paper proposes a model that detects uncertain situations when
a command is given and finds the visual objects causing it. Optionally, a
question generated by the system describing the uncertain objects is included.
We argue that if the car could explain the objects in a human-like way,
passengers could gain more confidence in the car&#x27;s abilities. Thus, we
investigate how to (1) detect uncertain situations and their underlying causes,
and (2) how to generate clarifying questions for the passenger. When evaluating
on the Talk2Car dataset, we show that the proposed model, \acrfull{pipeline},
improves \gls{m:ambiguous-absolute-increase} in terms of $IoU_{.5}$ compared to
not using \gls{pipeline}. Furthermore, we designed a referring expression
generator (REG) \acrfull{reg_model} tailored to a self-driving car setting
which yields a relative improvement of \gls{m:meteor-relative} METEOR and
\gls{m:rouge-relative} ROUGE-l compared with state-of-the-art REG models, and
is three times faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What training reveals about neural network complexity. (arXiv:2106.04186v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loukas_A/0/1/0/all/0/1">Andreas Loukas</a>, <a href="http://arxiv.org/find/cs/1/au:+Poiitis_M/0/1/0/all/0/1">Marinos Poiitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1">Stefanie Jegelka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04186">
                                    <div class="article-summary-box-inner">
                                        <span>This work explores the hypothesis that the complexity of the function a deep
neural network (NN) is learning can be deduced by how fast its weights change
during training. Our analysis provides evidence for this supposition by
relating the network&#x27;s distribution of Lipschitz constants (i.e., the norm of
the gradient at different regions of the input space) during different training
intervals with the behavior of the stochastic training procedure. We first
observe that the average Lipschitz constant close to the training data affects
various aspects of the parameter trajectory, with more complex networks having
a longer trajectory, bigger variance, and often veering further from their
initialization. We then show that NNs whose biases are trained more steadily
have bounded complexity even in regions of the input space that are far from
any training point. Finally, we find that steady training with Dropout implies
a training- and data-dependent generalization bound that grows
poly-logarithmically with the number of parameters. Overall, our results
support the hypothesis that good training behavior can be a useful bias towards
good generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Residual Feedback Learning for Contact-Rich Manipulation Tasks with Uncertainty. (arXiv:2106.04306v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ranjbar_A/0/1/0/all/0/1">Alireza Ranjbar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vien_N/0/1/0/all/0/1">Ngo Anh Vien</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziesche_H/0/1/0/all/0/1">Hanna Ziesche</a>, <a href="http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1">Joschka Boedecker</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04306">
                                    <div class="article-summary-box-inner">
                                        <span>While classic control theory offers state of the art solutions in many
problem scenarios, it is often desired to improve beyond the structure of such
solutions and surpass their limitations. To this end, \emph{\gls{rpl}} offers a
formulation to improve existing controllers with reinforcement learning (RL) by
learning an additive &quot;residual&quot; to the output of a given controller. However,
the applicability of such an approach highly depends on the structure of the
controller. Often, internal feedback signals of the controller limit an RL
algorithm to adequately change the policy and, hence, learn the task. We
propose a new formulation that addresses these limitations by also modifying
the feedback signals to the controller with an RL policy and show superior
performance of our approach on a contact-rich peg-insertion task under position
and orientation uncertainty. In addition, we use a recent impedance control
architecture as control framework and show the difficulties of standard RPL.
Furthermore, we introduce an adaptive curriculum for the given task to
gradually increase the task difficulty in terms of position and orientation
uncertainty. A video showing the results can be found at
https://youtu.be/SAZm_Krze7U .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Staircase Attention for Recurrent Processing of Sequences. (arXiv:2106.04279v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ju_D/0/1/0/all/0/1">Da Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1">Sainbayar Sukhbaatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04279">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanisms have become a standard tool for sequence modeling tasks,
in particular by stacking self-attention layers over the entire input sequence
as in the Transformer architecture. In this work we introduce a novel attention
procedure called staircase attention that, unlike self-attention, operates
across the sequence (in time) recurrently processing the input by adding
another step of processing. A step in the staircase comprises of backward
tokens (encoding the sequence so far seen) and forward tokens (ingesting a new
part of the sequence), or an extreme Ladder version with a forward step of zero
that simply repeats the Transformer on each step of the ladder, sharing the
weights. We thus describe a family of such models that can trade off
performance and compute, by either increasing the amount of recurrence through
time, the amount of sequential processing via recurrence in depth, or both.
Staircase attention is shown to be able to solve tasks that involve tracking
that conventional Transformers cannot, due to this recurrence. Further, it is
shown to provide improved modeling power for the same size model (number of
parameters) compared to self-attentive Transformers on large language modeling
and dialogue tasks, yielding significant perplexity gains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Hybrid Model for Identity Document Classification. (arXiv:2106.04345v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khandan_N/0/1/0/all/0/1">Nouna Khandan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04345">
                                    <div class="article-summary-box-inner">
                                        <span>Digitization, i.e., the process of converting information into a digital
format, may provide various opportunities (e.g., increase in productivity,
disaster recovery, and environmentally friendly solutions) and challenges for
businesses. In this context, one of the main challenges would be to accurately
classify numerous scanned documents uploaded every day by customers as usual
business processes. For example, processes in banking (e.g., applying for
loans) or the Government Registry of BDM (Births, Deaths, and Marriages)
applications may involve uploading several documents such as a driver&#x27;s license
and passport. There are not many studies available to address the challenge as
an application of image classification. Although some studies are available
which used various methods, a more accurate model is still required. The
current study has proposed a robust fusion model to define the type of identity
documents accurately. The proposed approach is based on two different methods
in which images are classified based on their visual features and text
features. A novel model based on statistics and regression has been proposed to
calculate the confidence level for the feature-based classifier. A fuzzy-mean
fusion model has been proposed to combine the classifier results based on their
confidence score. The proposed approach has been implemented using Python and
experimentally validated on synthetic and real-world datasets. The performance
of the proposed model is evaluated using the Receiver Operating Characteristic
(ROC) curve analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RECOWNs: Probabilistic Circuits for Trustworthy Time Series Forecasting. (arXiv:2106.04148v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thoma_N/0/1/0/all/0/1">Nils Thoma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhongjie Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1">Fabrizio Ventola</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04148">
                                    <div class="article-summary-box-inner">
                                        <span>Time series forecasting is a relevant task that is performed in several
real-world scenarios such as product sales analysis and prediction of energy
demand. Given their accuracy performance, currently, Recurrent Neural Networks
(RNNs) are the models of choice for this task. Despite their success in time
series forecasting, less attention has been paid to make the RNNs trustworthy.
For example, RNNs can not naturally provide an uncertainty measure to their
predictions. This could be extremely useful in practice in several cases e.g.
to detect when a prediction might be completely wrong due to an unusual pattern
in the time series. Whittle Sum-Product Networks (WSPNs), prominent deep
tractable probabilistic circuits (PCs) for time series, can assist an RNN with
providing meaningful probabilities as uncertainty measure. With this aim, we
propose RECOWN, a novel architecture that employs RNNs and a discriminant
variant of WSPNs called Conditional WSPNs (CWSPNs). We also formulate a
Log-Likelihood Ratio Score as better estimation of uncertainty that is tailored
to time series and Whittle likelihoods. In our experiments, we show that
RECOWNs are accurate and trustworthy time series predictors, able to &quot;know when
they do not know&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seamlessly Unifying Attributes and Items: Conversational Recommendation for Cold-Start Users. (arXiv:2005.12979v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shijun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1">Wenqiang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Peng Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.12979">
                                    <div class="article-summary-box-inner">
                                        <span>Static recommendation methods like collaborative filtering suffer from the
inherent limitation of performing real-time personalization for cold-start
users. Online recommendation, e.g., multi-armed bandit approach, addresses this
limitation by interactively exploring user preference online and pursuing the
exploration-exploitation (EE) trade-off. However, existing bandit-based methods
model recommendation actions homogeneously. Specifically, they only consider
the items as the arms, being incapable of handling the item attributes, which
naturally provide interpretable information of user&#x27;s current demands and can
effectively filter out undesired items. In this work, we consider the
conversational recommendation for cold-start users, where a system can both ask
the attributes from and recommend items to a user interactively. This important
scenario was studied in a recent work. However, it employs a hand-crafted
function to decide when to ask attributes or make recommendations. Such
separate modeling of attributes and items makes the effectiveness of the system
highly rely on the choice of the hand-crafted function, thus introducing
fragility to the system. To address this limitation, we seamlessly unify
attributes and items in the same arm space and achieve their EE trade-offs
automatically using the framework of Thompson Sampling. Our Conversational
Thompson Sampling (ConTS) model holistically solves all questions in
conversational recommendation by choosing the arm with the maximal reward to
play. Extensive experiments on three benchmark datasets show that ConTS
outperforms the state-of-the-art methods Conversational UCB (ConUCB) and
Estimation-Action-Reflection model in both metrics of success rate and average
number of conversation turns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Less is More: A privacy-respecting Android malware classifier using Federated Learning. (arXiv:2007.08319v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galvez_R/0/1/0/all/0/1">Rafa G&#xe1;lvez</a>, <a href="http://arxiv.org/find/cs/1/au:+Moonsamy_V/0/1/0/all/0/1">Veelasha Moonsamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_C/0/1/0/all/0/1">Claudia Diaz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08319">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present LiM (&quot;Less is More&quot;), a malware classification
framework that leverages Federated Learning to detect and classify malicious
apps in a privacy-respecting manner. Information about newly installed apps is
kept locally on users&#x27; devices, so that the provider cannot infer which apps
were installed by users. At the same time, input from all users is taken into
account in the federated learning process and they all benefit from better
classification performance. A key challenge of this setting is that users do
not have access to the ground truth (i.e. they cannot correctly identify
whether an app is malicious). To tackle this, LiM uses a safe semi-supervised
ensemble that maximizes classification accuracy with respect to a baseline
classifier trained by the service provider (i.e. the cloud). We implement LiM
and show that the cloud server has F1 score of 95%, while clients have perfect
recall with only 1 false positive in &gt;100 apps, using a dataset of 25K clean
apps and 25K malicious apps, 200 users and 50 rounds of federation.
Furthermore, we conduct a security analysis and demonstrate that LiM is robust
against both poisoning attacks by adversaries who control half of the clients,
and inference attacks performed by an honest-but-curious cloud server. Further
experiments with MaMaDroid&#x27;s dataset confirm resistance against poisoning
attacks and a performance improvement due to the federation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Isometric Gaussian Process Latent Variable Model for Dissimilarity Data. (arXiv:2006.11741v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Jorgensen_M/0/1/0/all/0/1">Martin J&#xf8;rgensen</a>, <a href="http://arxiv.org/find/stat/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11741">
                                    <div class="article-summary-box-inner">
                                        <span>We present a probabilistic model where the latent variable respects both the
distances and the topology of the modeled data. The model leverages the
Riemannian geometry of the generated manifold to endow the latent space with a
well-defined stochastic distance measure, which is modeled locally as Nakagami
distributions. These stochastic distances are sought to be as similar as
possible to observed distances along a neighborhood graph through a censoring
process. The model is inferred by variational inference based on observations
of pairwise distances. We demonstrate how the new model can encode invariances
in the learned manifolds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Multiple Shooting Layers. (arXiv:2106.03885v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Massaroli_S/0/1/0/all/0/1">Stefano Massaroli</a>, <a href="http://arxiv.org/find/cs/1/au:+Poli_M/0/1/0/all/0/1">Michael Poli</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1">Sho Sonoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_T/0/1/0/all/0/1">Taji Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinkyoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamashita_A/0/1/0/all/0/1">Atsushi Yamashita</a>, <a href="http://arxiv.org/find/cs/1/au:+Asama_H/0/1/0/all/0/1">Hajime Asama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03885">
                                    <div class="article-summary-box-inner">
                                        <span>We detail a novel class of implicit neural models. Leveraging time-parallel
methods for differential equations, Multiple Shooting Layers (MSLs) seek
solutions of initial value problems via parallelizable root-finding algorithms.
MSLs broadly serve as drop-in replacements for neural ordinary differential
equations (Neural ODEs) with improved efficiency in number of function
evaluations (NFEs) and wall-clock inference time. We develop the algorithmic
framework of MSLs, analyzing the different choices of solution methods from a
theoretical and computational perspective. MSLs are showcased in long horizon
optimal control of ODEs and PDEs and as latent models for sequence generation.
Finally, we investigate the speedups obtained through application of MSL
inference in neural controlled differential equations (Neural CDEs) for time
series classification of medical data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks. (arXiv:2004.07601v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shaoxiong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07601">
                                    <div class="article-summary-box-inner">
                                        <span>Mental health is a critical issue in modern society, and mental disorders
could sometimes turn to suicidal ideation without effective treatment. Early
detection of mental disorders and suicidal ideation from social content
provides a potential way for effective social intervention. However,
classifying suicidal ideation and other mental disorders is challenging as they
share similar patterns in language usage and sentimental polarity. This paper
enhances text representation with lexicon-based sentiment scores and latent
topics and proposes using relation networks to detect suicidal ideation and
mental disorders with related risk indicators. The relation module is further
equipped with the attention mechanism to prioritize more critical relational
features. Through experiments on three real-world datasets, our model
outperforms most of its counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surveillance of COVID-19 Pandemic using Social Media: A Reddit Study in North Carolina. (arXiv:2106.04515v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whitfield_C/0/1/0/all/0/1">Christopher Whitfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_M/0/1/0/all/0/1">Mohad Anwar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04515">
                                    <div class="article-summary-box-inner">
                                        <span>Coronavirus disease (COVID-19) pandemic has changed various aspects of
people&#x27;s lives and behaviors. At this stage, there are no other ways to control
the natural progression of the disease than adopting mitigation strategies such
as wearing masks, watching distance, and washing hands. Moreover, at this time
of social distancing, social media plays a key role in connecting people and
providing a platform for expressing their feelings. In this study, we tap into
social media to surveil the uptake of mitigation and detection strategies, and
capture issues and concerns about the pandemic. In particular, we explore the
research question, &quot;how much can be learned regarding the public uptake of
mitigation strategies and concerns about COVID-19 pandemic by using natural
language processing on Reddit posts?&quot; After extracting COVID-related posts from
the four largest subreddit communities of North Carolina over six months, we
performed NLP-based preprocessing to clean the noisy data. We employed a custom
Named-entity Recognition (NER) system and a Latent Dirichlet Allocation (LDA)
method for topic modeling on a Reddit corpus. We observed that &#x27;mask&#x27;, &#x27;flu&#x27;,
and &#x27;testing&#x27; are the most prevalent named-entities for &quot;Personal Protective
Equipment&quot;, &quot;symptoms&quot;, and &quot;testing&quot; categories, respectively. We also
observed that the most discussed topics are related to testing, masks, and
employment. The mitigation measures are the most prevalent theme of discussion
across all subreddits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Risk Ranked Recall: Collision Safety Metric for Object Detection Systems in Autonomous Vehicles. (arXiv:2106.04146v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1">Ayoosh Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1">Jayati Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Verucchi_M/0/1/0/all/0/1">Micaela Verucchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Caccamo_M/0/1/0/all/0/1">Marco Caccamo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1">Lui Sha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04146">
                                    <div class="article-summary-box-inner">
                                        <span>Commonly used metrics for evaluation of object detection systems (precision,
recall, mAP) do not give complete information about their suitability of use in
safety critical tasks, like obstacle detection for collision avoidance in
Autonomous Vehicles (AV). This work introduces the Risk Ranked Recall ($R^3$)
metrics for object detection systems. The $R^3$ metrics categorize objects
within three ranks. Ranks are assigned based on an objective cyber-physical
model for the risk of collision. Recall is measured for each rank.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Riemannian Manifolds for Geodesic Motion Skills. (arXiv:2106.04315v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Beik_Mohammadi_H/0/1/0/all/0/1">Hadi Beik-Mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hauberg_S/0/1/0/all/0/1">S&#xf8;ren Hauberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Arvanitidis_G/0/1/0/all/0/1">Georgios Arvanitidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1">Gerhard Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozo_L/0/1/0/all/0/1">Leonel Rozo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04315">
                                    <div class="article-summary-box-inner">
                                        <span>For robots to work alongside humans and perform in unstructured environments,
they must learn new motion skills and adapt them to unseen situations on the
fly. This demands learning models that capture relevant motion patterns, while
offering enough flexibility to adapt the encoded skills to new requirements,
such as dynamic obstacle avoidance. We introduce a Riemannian manifold
perspective on this problem, and propose to learn a Riemannian manifold from
human demonstrations on which geodesics are natural motion skills. We realize
this with a variational autoencoder (VAE) over the space of position and
orientations of the robot end-effector. Geodesic motion skills let a robot plan
movements from and to arbitrary points on the data manifold. They also provide
a straightforward method to avoid obstacles by redefining the ambient metric in
an online fashion. Moreover, geodesics naturally exploit the manifold resulting
from multiple--mode tasks to design motions that were not explicitly
demonstrated previously. We test our learning framework using a 7-DoF robotic
manipulator, where the robot satisfactorily learns and reproduces realistic
skills featuring elaborated motion patterns, avoids previously unseen
obstacles, and generates novel movements in multiple-mode settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Muddling Label Regularization: Deep Learning for Tabular Datasets. (arXiv:2106.04462v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lounici_K/0/1/0/all/0/1">Karim Lounici</a>, <a href="http://arxiv.org/find/cs/1/au:+Meziani_K/0/1/0/all/0/1">Katia Meziani</a>, <a href="http://arxiv.org/find/cs/1/au:+Riu_B/0/1/0/all/0/1">Benjamin Riu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04462">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning (DL) is considered the state-of-the-art in computer vision,
speech recognition and natural language processing. Until recently, it was also
widely accepted that DL is irrelevant for learning tasks on tabular data,
especially in the small sample regime where ensemble methods are acknowledged
as the gold standard. We present a new end-to-end differentiable method to
train a standard FFNN. Our method, \textbf{Muddling labels for Regularization}
(\texttt{MLR}), penalizes memorization through the generation of uninformative
labels and the application of a differentiable close-form regularization scheme
on the last hidden layer during training. \texttt{MLR} outperforms classical NN
and the gold standard (GBDT, RF) for regression and classification tasks on
several datasets from the UCI database and Kaggle covering a large range of
sample sizes and feature to sample ratios. Researchers and practitioners can
use \texttt{MLR} on its own as an off-the-shelf \DL{} solution or integrate it
into the most advanced ML pipelines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hash Layers For Large Sparse Models. (arXiv:2106.04426v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roller_S/0/1/0/all/0/1">Stephen Roller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1">Sainbayar Sukhbaatar</a>, <a href="http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1">Arthur Szlam</a>, <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jason Weston</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04426">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the training of sparse layers that use different parameters
for different inputs based on hashing in large Transformer models.
Specifically, we modify the feedforward layer to hash to different sets of
weights depending on the current token, over all tokens in the sequence. We
show that this procedure either outperforms or is competitive with
learning-to-route mixture-of-expert methods such as Switch Transformers and
BASE Layers, while requiring no routing parameters or extra terms in the
objective function such as a load balancing loss, and no sophisticated
assignment algorithm. We study the performance of different hashing techniques,
hash sizes and input features, and show that balanced and random hashes focused
on the most local features work best, compared to either learning clusters or
using longer-range context. We show our approach works well both on large
language modeling and dialogue tasks, and on downstream fine-tuning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object Based Attention Through Internal Gating. (arXiv:2106.04540v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Lei_J/0/1/0/all/0/1">Jordan Lei</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Benjamin_A/0/1/0/all/0/1">Ari S. Benjamin</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kording_K/0/1/0/all/0/1">Konrad P. Kording</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04540">
                                    <div class="article-summary-box-inner">
                                        <span>Object-based attention is a key component of the visual system, relevant for
perception, learning, and memory. Neurons tuned to features of attended objects
tend to be more active than those associated with non-attended objects. There
is a rich set of models of this phenomenon in computational neuroscience.
However, there is currently a divide between models that successfully match
physiological data but can only deal with extremely simple problems and models
of attention used in computer vision. For example, attention in the brain is
known to depend on top-down processing, whereas self-attention in deep learning
does not. Here, we propose an artificial neural network model of object-based
attention that captures the way in which attention is both top-down and
recurrent. Our attention model works well both on simple test stimuli, such as
those using images of handwritten digits, and on more complex stimuli, such as
natural images drawn from the COCO dataset. We find that our model replicates a
range of findings from neuroscience, including attention-invariant tuning,
inhibition of return, and attention-mediated scaling of activity. Understanding
object based attention is both computationally interesting and a key problem
for computational neuroscience.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Value-network Based Approach for Multi-Driver Order Dispatching. (arXiv:2106.04493v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhiwei Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaodong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yintai Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongtu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jieping Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04493">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works on ride-sharing order dispatching have highlighted the
importance of taking into account both the spatial and temporal dynamics in the
dispatching process for improving the transportation system efficiency. At the
same time, deep reinforcement learning has advanced to the point where it
achieves superhuman performance in a number of fields. In this work, we propose
a deep reinforcement learning based solution for order dispatching and we
conduct large scale online A/B tests on DiDi&#x27;s ride-dispatching platform to
show that the proposed method achieves significant improvement on both total
driver income and user experience related metrics. In particular, we model the
ride dispatching problem as a Semi Markov Decision Process to account for the
temporal aspect of the dispatching actions. To improve the stability of the
value iteration with nonlinear function approximators like neural networks, we
propose Cerebellar Value Networks (CVNet) with a novel distributed state
representation layer. We further derive a regularized policy evaluation scheme
for CVNet that penalizes large Lipschitz constant of the value network for
additional robustness against adversarial perturbation and noises. Finally, we
adapt various transfer learning methods to CVNet for increased learning
adaptability and efficiency across multiple cities. We conduct extensive
offline simulations based on real dispatching data as well as online AB tests
through the DiDi&#x27;s platform. Results show that CVNet consistently outperforms
other recently proposed dispatching methods. We finally show that the
performance can be further improved through the efficient use of transfer
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Markov State Abstractions for Deep Reinforcement Learning. (arXiv:2106.04379v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1">Cameron Allen</a>, <a href="http://arxiv.org/find/cs/1/au:+Parikh_N/0/1/0/all/0/1">Neev Parikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottesman_O/0/1/0/all/0/1">Omer Gottesman</a>, <a href="http://arxiv.org/find/cs/1/au:+Konidaris_G/0/1/0/all/0/1">George Konidaris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04379">
                                    <div class="article-summary-box-inner">
                                        <span>The fundamental assumption of reinforcement learning in Markov decision
processes (MDPs) is that the relevant decision process is, in fact, Markov.
However, when MDPs have rich observations, agents typically learn by way of an
abstract state representation, and such representations are not guaranteed to
preserve the Markov property. We introduce a novel set of conditions and prove
that they are sufficient for learning a Markov abstract state representation.
We then describe a practical training procedure that combines inverse model
estimation and temporal contrastive learning to learn an abstraction that
approximately satisfies these conditions. Our novel training objective is
compatible with both online and offline training: it does not require a reward
signal, but agents can capitalize on reward information when available. We
empirically evaluate our approach on a visual gridworld domain and a set of
continuous control benchmarks. Our approach learns representations that capture
the underlying structure of the domain and lead to improved sample efficiency
over state-of-the-art deep reinforcement learning with visual features -- often
matching or exceeding the performance achieved with hand-designed compact state
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LaplaceNet: A Hybrid Energy-Neural Model for Deep Semi-Supervised Classification. (arXiv:2106.04527v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sellars_P/0/1/0/all/0/1">Philip Sellars</a>, <a href="http://arxiv.org/find/cs/1/au:+Aviles_Rivero_A/0/1/0/all/0/1">Angelica I. Aviles-Rivero</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Sch&#xf6;nlieb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04527">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised learning has received a lot of recent attention as it
alleviates the need for large amounts of labelled data which can often be
expensive, requires expert knowledge and be time consuming to collect. Recent
developments in deep semi-supervised classification have reached unprecedented
performance and the gap between supervised and semi-supervised learning is
ever-decreasing. This improvement in performance has been based on the
inclusion of numerous technical tricks, strong augmentation techniques and
costly optimisation schemes with multi-term loss functions. We propose a new
framework, LaplaceNet, for deep semi-supervised classification that has a
greatly reduced model complexity. We utilise a hybrid energy-neural network
where graph based pseudo-labels, generated by minimising the graphical
Laplacian, are used to iteratively improve a neural-network backbone. Our model
outperforms state-of-the-art methods for deep semi-supervised classification,
over several benchmark datasets. Furthermore, we consider the application of
strong-augmentations to neural networks theoretically and justify the use of a
multi-sampling approach for semi-supervised learning. We demonstrate, through
rigorous experimentation, that a multi-sampling augmentation approach improves
generalisation and reduces the sensitivity of the network to augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Specific Causal Discovery for Categorical Data Using Staged Trees. (arXiv:2106.04416v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Leonelli_M/0/1/0/all/0/1">Manuele Leonelli</a>, <a href="http://arxiv.org/find/stat/1/au:+Varando_G/0/1/0/all/0/1">Gherardo Varando</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04416">
                                    <div class="article-summary-box-inner">
                                        <span>Causal discovery algorithms aims at untangling complex causal relationships
using observational data only. Here, we introduce new causal discovery
algorithms based on staged tree models, which can represent complex and
non-symmetric causal effects. To demonstrate the efficacy of our algorithms, we
introduce a new distance, inspired by the widely used structural interventional
distance, to quantify the closeness between two staged trees in terms of their
corresponding causal inference statements. A simulation study highlights the
efficacy of staged trees in uncovering complex, asymmetric causal relationship
from data and a real-world data application illustrates their use in a
practical causal analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cheap and Good? Simple and Effective Data Augmentation for Low Resource Machine Reading. (arXiv:2106.04134v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Van_H/0/1/0/all/0/1">Hoang Van</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1">Vikas Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1">Mihai Surdeanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04134">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a simple and effective strategy for data augmentation for
low-resource machine reading comprehension (MRC). Our approach first pretrains
the answer extraction components of a MRC system on the augmented data that
contains approximate context of the correct answers, before training it on the
exact answer spans. The approximate context helps the QA method components in
narrowing the location of the answers. We demonstrate that our simple strategy
substantially improves both document retrieval and answer extraction
performance by providing larger context of the answers and additional training
data. In particular, our method significantly improves the performance of BERT
based retriever (15.12\%), and answer extractor (4.33\% F1) on TechQA, a
complex, low-resource MRC task. Further, our data augmentation strategy yields
significant improvements of up to 3.9\% exact match (EM) and 2.7\% F1 for
answer extraction on PolicyQA, another practical but moderate sized QA dataset
that also contains long answer spans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A critical look at the current train/test split in machine learning. (arXiv:2106.04525v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jimin Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Sai Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Gang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jake Zhao</a> (Junbo)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04525">
                                    <div class="article-summary-box-inner">
                                        <span>The randomized or cross-validated split of training and testing sets has been
adopted as the gold standard of machine learning for decades. The establishment
of these split protocols are based on two assumptions: (i)-fixing the dataset
to be eternally static so we could evaluate different machine learning
algorithms or models; (ii)-there is a complete set of annotated data available
to researchers or industrial practitioners. However, in this article, we intend
to take a closer and critical look at the split protocol itself and point out
its weakness and limitation, especially for industrial applications. In many
real-world problems, we must acknowledge that there are numerous situations
where assumption (ii) does not hold. For instance, for interdisciplinary
applications like drug discovery, it often requires real lab experiments to
annotate data which poses huge costs in both time and financial considerations.
In other words, it can be very difficult or even impossible to satisfy
assumption (ii). In this article, we intend to access this problem and
reiterate the paradigm of active learning, and investigate its potential on
solving problems under unconventional train/test split protocols. We further
propose a new adaptive active learning architecture (AAL) which involves an
adaptation policy, in comparison with the traditional active learning that only
unidirectionally adds data points to the training pool. We primarily justify
our points by extensively investigating an interdisciplinary drug-protein
binding problem. We additionally evaluate AAL on more conventional machine
learning benchmarking datasets like CIFAR-10 to demonstrate the
generalizability and efficacy of the new framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sketch-Based Streaming Anomaly Detection in Dynamic Graphs. (arXiv:2106.04486v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1">Siddharth Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wadhwa_M/0/1/0/all/0/1">Mohit Wadhwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1">Bryan Hooi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04486">
                                    <div class="article-summary-box-inner">
                                        <span>Given a stream of graph edges from a dynamic graph, how can we assign anomaly
scores to edges and subgraphs in an online manner, for the purpose of detecting
unusual behavior, using constant time and memory? For example, in intrusion
detection, existing work seeks to detect either anomalous edges or anomalous
subgraphs, but not both. In this paper, we first extend the count-min sketch
data structure to a higher-order sketch. This higher-order sketch has the
useful property of preserving the dense subgraph structure (dense subgraphs in
the input turn into dense submatrices in the data structure). We then propose
four online algorithms that utilize this enhanced data structure, which (a)
detect both edge and graph anomalies; (b) process each edge and graph in
constant memory and constant update time per newly arriving edge, and; (c)
outperform state-of-the-art baselines on four real-world datasets. Our method
is the first streaming approach that incorporates dense subgraph search to
detect graph anomalies in constant memory and time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Robustness of Neural Networks through Fourier Stabilization. (arXiv:2106.04435v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raviv_N/0/1/0/all/0/1">Netanel Raviv</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelley_A/0/1/0/all/0/1">Aidan Kelley</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Michael Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorobeychik_Y/0/1/0/all/0/1">Yevgeny Vorobeychik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04435">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the considerable success of neural networks in security settings such
as malware detection, such models have proved vulnerable to evasion attacks, in
which attackers make slight changes to inputs (e.g., malware) to bypass
detection. We propose a novel approach, \emph{Fourier stabilization}, for
designing evasion-robust neural networks with binary inputs. This approach,
which is complementary to other forms of defense, replaces the weights of
individual neurons with robust analogs derived using Fourier analytic tools.
The choice of which neurons to stabilize in a neural network is then a
combinatorial optimization problem, and we propose several methods for
approximately solving it. We provide a formal bound on the per-neuron drop in
accuracy due to Fourier stabilization, and experimentally demonstrate the
effectiveness of the proposed approach in boosting robustness of neural
networks in several detection settings. Moreover, we show that our approach
effectively composes with adversarial training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seismic Inverse Modeling Method based on Generative Adversarial Network. (arXiv:2106.04197v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Xie_P/0/1/0/all/0/1">Pengfei Xie</a>, <a href="http://arxiv.org/find/stat/1/au:+Yin_Y/0/1/0/all/0/1">YanShu Yin</a>, <a href="http://arxiv.org/find/stat/1/au:+Hou_J/0/1/0/all/0/1">JiaGen Hou</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1">Mei Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1">Lixin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04197">
                                    <div class="article-summary-box-inner">
                                        <span>Seismic inverse modeling is a common method in reservoir prediction and it
plays a vital role in the exploration and development of oil and gas.
Conventional seismic inversion method is difficult to combine with complicated
and abstract knowledge on geological mode and its uncertainty is difficult to
be assessed. The paper proposes an inversion modeling method based on GAN
consistent with geology, well logs, seismic data. GAN is a the most promising
generation model algorithm that extracts spatial structure and abstract
features of training images. The trained GAN can reproduce the models with
specific mode. In our test, 1000 models were generated in 1 second. Based on
the trained GAN after assessment, the optimal result of models can be
calculated through Bayesian inversion frame. Results show that inversion models
conform to observation data and have a low uncertainty under the premise of
fast generation. This seismic inverse modeling method increases the efficiency
and quality of inversion iteration. It is worthy of studying and applying in
fusion of seismic data and geological knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIPS-Plus: The Enhanced Database of Interacting Protein Structures for Interface Prediction. (arXiv:2106.04362v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Morehead_A/0/1/0/all/0/1">Alex Morehead</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sedova_A/0/1/0/all/0/1">Ada Sedova</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cheng_J/0/1/0/all/0/1">Jianlin Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04362">
                                    <div class="article-summary-box-inner">
                                        <span>How and where proteins interface with one another can ultimately impact the
proteins&#x27; functions along with a range of other biological processes. As such,
precise computational methods for protein interface prediction (PIP) come
highly sought after as they could yield significant advances in drug discovery
and design as well as protein function analysis. However, the traditional
benchmark dataset for this task, Docking Benchmark 5 (DB5), contains only a
paltry 230 complexes for training, validating, and testing different machine
learning algorithms. In this work, we expand on a dataset recently introduced
for this task, the Database of Interacting Protein Structures (DIPS), to
present DIPS-Plus, an enhanced, feature-rich dataset of 42,112 complexes for
geometric deep learning of protein interfaces. The previous version of DIPS
contains only the Cartesian coordinates and types of the atoms comprising a
given protein complex, whereas DIPS-Plus now includes a plethora of new
residue-level features including protrusion indices, half-sphere amino acid
compositions, and new profile hidden Markov model (HMM)-based sequence features
for each amino acid, giving researchers a large, well-curated feature bank for
training protein interface prediction methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation. (arXiv:2106.04151v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zhekai Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hongzu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Ke Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04151">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned
from a well-labeled source domain to an unlabeled target domain. Recently,
adversarial domain adaptation with two distinct classifiers (bi-classifier) has
been introduced into UDA which is effective to align distributions between
different domains. Previous bi-classifier adversarial learning methods only
focus on the similarity between the outputs of two distinct classifiers.
However, the similarity of the outputs cannot guarantee the accuracy of target
samples, i.e., target samples may match to wrong categories even if the
discrepancy between two classifiers is small. To challenge this issue, in this
paper, we propose a cross-domain gradient discrepancy minimization (CGDM)
method which explicitly minimizes the discrepancy of gradients generated by
source samples and target samples. Specifically, the gradient gives a cue for
the semantic information of target samples so it can be used as a good
supervision to improve the accuracy of target samples. In order to compute the
gradient signal of target samples, we further obtain target pseudo labels
through a clustering-based self-supervised learning. Extensive experiments on
three widely used UDA datasets show that our method surpasses many previous
state-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation. (arXiv:2106.04399v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bengio_E/0/1/0/all/0/1">Emmanuel Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1">Moksh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Korablyov_M/0/1/0/all/0/1">Maksym Korablyov</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04399">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is about the problem of learning a stochastic policy for
generating an object (like a molecular graph) from a sequence of actions, such
that the probability of generating an object is proportional to a given
positive reward for that object. Whereas standard return maximization tends to
converge to a single return-maximizing sequence, there are cases where we would
like to sample a diverse set of high-return solutions. These arise, for
example, in black-box function optimization when few rounds are possible, each
with large batches of queries, where the batches should be diverse, e.g., in
the design of new molecules. One can also see this as a problem of
approximately converting an energy function to a generative distribution. While
MCMC methods can achieve that, they are expensive and generally only perform
local exploration. Instead, training a generative policy amortizes the cost of
search during training and yields to fast generation. Using insights from
Temporal Difference learning, we propose GFlowNet, based on a view of the
generative process as a flow network, making it possible to handle the tricky
case where different trajectories can yield the same final state, e.g., there
are many ways to sequentially add atoms to generate some molecular graph. We
cast the set of trajectories as a flow and convert the flow consistency
equations into a learning objective, akin to the casting of the Bellman
equations into Temporal Difference methods. We prove that any global minimum of
the proposed objectives yields a policy which samples from the desired
distribution, and demonstrate the improved performance and diversity of
GFlowNet on a simple domain where there are many modes to the reward function,
and on a molecule synthesis task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computer-Assisted Analysis of Biomedical Images. (arXiv:2106.04381v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rundo_L/0/1/0/all/0/1">Leonardo Rundo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04381">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, the amount of heterogeneous biomedical data is increasing more and
more thanks to novel sensing techniques and high-throughput technologies. In
reference to biomedical image analysis, the advances in image acquisition
modalities and high-throughput imaging experiments are creating new challenges.
This huge information ensemble could overwhelm the analytic capabilities needed
by physicians in their daily decision-making tasks as well as by biologists
investigating complex biochemical systems. In particular, quantitative imaging
methods convey scientifically and clinically relevant information in
prediction, prognosis or treatment response assessment, by also considering
radiomics approaches. Therefore, the computational analysis of medical and
biological images plays a key role in radiology and laboratory applications. In
this regard, frameworks based on advanced Machine Learning and Computational
Intelligence can significantly improve traditional Image Processing and Pattern
Recognition approaches. However, conventional Artificial Intelligence
techniques must be tailored to address the unique challenges concerning
biomedical imaging data. This thesis aims at proposing novel and advanced
computer-assisted methods for biomedical image analysis, also as an instrument
in the development of Clinical Decision Support Systems, by always keeping in
mind the clinical feasibility of the developed solutions. In conclusion, the
ultimate goal of these research studies is to gain clinically and biologically
useful insights that can guide differential diagnosis and therapies, leading
towards biomedical data integration for personalized medicine. As a matter of
fact, the proposed computer-assisted bioimage analysis methods can be
beneficial for the definition of imaging biomarkers, as well as for
quantitative medicine and biology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3KG: Contrastive Learning of 12-Lead Electrocardiograms using Physiologically-Inspired Augmentations. (arXiv:2106.04452v1 [physics.med-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Gopal_B/0/1/0/all/0/1">Bryan Gopal</a>, <a href="http://arxiv.org/find/physics/1/au:+Han_R/0/1/0/all/0/1">Ryan W. Han</a>, <a href="http://arxiv.org/find/physics/1/au:+Raghupathi_G/0/1/0/all/0/1">Gautham Raghupathi</a>, <a href="http://arxiv.org/find/physics/1/au:+Ng_A/0/1/0/all/0/1">Andrew Y. Ng</a>, <a href="http://arxiv.org/find/physics/1/au:+Tison_G/0/1/0/all/0/1">Geoffrey H. Tison</a>, <a href="http://arxiv.org/find/physics/1/au:+Rajpurkar_P/0/1/0/all/0/1">Pranav Rajpurkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04452">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised contrastive learning approaches leverage modality-specific
context or invariances to pretrain models using unlabeled data. While
contrastive learning has demonstrated promising on results in the image domain,
there has been limited work on determining how to exploit modality-specific
invariances in biosignals such as the electrocardiogram. In this work, we
propose 3KG, a method to generate positive pairs for contrastive learning using
physiologically-inspired 3D augmentations of the 12-lead electrocardiogram. We
evaluate representation quality by fine-tuning a linear layer for the
downstream task of 24-class diagnosis on the PhysioNet 2020 challenge training
data, and find that models trained with physiologically-inspired augmentations
both outperform and complement standard time-series augmentations. Our best
performing strategy, which incorporates spatial rotation, spatial scaling, and
time masking, achieves a performance increase of 0.16, .086, and .046 in mean
AUROC over a randomly initialized baseline at 1%, 10%, and 100% label fractions
respectively. Additionally, we show that the strength of spatial augmentations
does not significantly affect the quality of the learned representations.
Finally, we investigate the clinical relevance of how physiologically-inspired
augmentations affect the performance of our classifier on different disease
subgroupings. As expert annotations are often expensive and scarce for medical
contexts, our approach highlights the potential of machine learning to tackle
medical problems with large quantities of unlabeled biosignal data by
exploiting their unique biological properties.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating NODE with Pre-trained Neural Differential Operator for Learning Dynamics. (arXiv:2106.04166v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1">Shiqi Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Qi Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lijun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhi-Ming Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04166">
                                    <div class="article-summary-box-inner">
                                        <span>Learning dynamics governed by differential equations is crucial for
predicting and controlling the systems in science and engineering. Neural
Ordinary Differential Equation (NODE), a deep learning model integrated with
differential equations, learns the dynamics directly from the samples on the
trajectory and shows great promise in the scientific field. However, the
training of NODE highly depends on the numerical solver, which can amplify
numerical noise and be unstable, especially for ill-conditioned dynamical
systems. In this paper, to reduce the reliance on the numerical solver, we
propose to enhance the supervised signal in learning dynamics. Specifically,
beyond learning directly from the trajectory samples, we pre-train a neural
differential operator (NDO) to output an estimation of the derivatives to serve
as an additional supervised signal. The NDO is pre-trained on a class of
symbolic functions, and it learns the mapping between the trajectory samples of
these functions to their derivatives. We provide theoretical guarantee on that
the output of NDO can well approximate the ground truth derivatives by proper
tuning the complexity of the library. To leverage both the trajectory signal
and the estimated derivatives from NDO, we propose an algorithm called
NDO-NODE, in which the loss function contains two terms: the fitness on the
true trajectory samples and the fitness on the estimated derivatives that are
output by the pre-trained NDO. Experiments on various of dynamics show that our
proposed NDO-NODE can consistently improve the forecasting accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Random Forest classifier for EEG-based seizure prediction. (arXiv:2106.04510v1 [physics.med-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Messaoud_R/0/1/0/all/0/1">Remy Ben Messaoud</a>, <a href="http://arxiv.org/find/physics/1/au:+Chavez_M/0/1/0/all/0/1">Mario Chavez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04510">
                                    <div class="article-summary-box-inner">
                                        <span>Epileptic seizure prediction has gained considerable interest in the
computational Epilepsy research community. This paper presents a Machine
Learning based method for epileptic seizure prediction which outperforms
state-of-the art methods. We compute a probability for a given epoch, of being
pre-ictal against interictal using the Random Forest classifier and introduce
new concepts to enhance the robustness of the algorithm to false alarms. We
assessed our method on 20 patients of the benchmark scalp EEG CHB-MIT dataset
for a seizure prediction horizon (SPH) of 5 minutes and a seizure occurrence
period (SOP) of 30 minutes. Our approach achieves a sensitivity of 82.07 % and
a low false positive rate (FPR) of 0.0799 /h. We also tested our approach on
intracranial EEG recordings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Closed-Form Analytical Results for Maximum Entropy Reinforcement Learning. (arXiv:2106.03931v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arriojas_A/0/1/0/all/0/1">Argenis Arriojas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiomkin_S/0/1/0/all/0/1">Stas Tiomkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_R/0/1/0/all/0/1">Rahul V. Kulkarni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03931">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a mapping between Maximum Entropy Reinforcement Learning (MaxEnt
RL) and Markovian processes conditioned on rare events. In the long time limit,
this mapping allows us to derive analytical expressions for the optimal policy,
dynamics and initial state distributions for the general case of stochastic
dynamics in MaxEnt RL. We find that soft-$\mathcal{Q}$ functions in MaxEnt RL
can be obtained from the Perron-Frobenius eigenvalue and the corresponding left
eigenvector of a regular, non-negative matrix derived from the underlying
Markov Decision Process (MDP). The results derived lead to novel algorithms for
model-based and model-free MaxEnt RL, which we validate by numerical
simulations. The mapping established in this work opens further avenues for the
application of novel analytical and computational approaches to problems in
MaxEnt RL. We make our code available at:
https://github.com/argearriojas/maxent-rl-mdp-scripts</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmenting Molecular Deep Generative Models with Topological Data Analysis Representations. (arXiv:2106.04464v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/physics/1/au:+Chenthamarakshan_V/0/1/0/all/0/1">Vijil Chenthamarakshan</a>, <a href="http://arxiv.org/find/physics/1/au:+Hoffman_S/0/1/0/all/0/1">Samuel Hoffman</a>, <a href="http://arxiv.org/find/physics/1/au:+Ramamurthy_K/0/1/0/all/0/1">Karthikeyan Natesan Ramamurthy</a>, <a href="http://arxiv.org/find/physics/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04464">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models have emerged as a powerful tool for learning
informative molecular representations and designing novel molecules with
desired properties, with applications in drug discovery and material design.
Deep generative auto-encoders defined over molecular SMILES strings have been a
popular choice for that purpose. However, capturing salient molecular
properties like quantum-chemical energies remains challenging and requires
sophisticated neural net models of molecular graphs or geometry-based
information. As a simpler and more efficient alternative, we present a SMILES
Variational Auto-Encoder (VAE) augmented with topological data analysis (TDA)
representations of molecules, known as persistence images. Our experiments show
that this TDA augmentation enables a SMILES VAE to capture the complex relation
between 3D geometry and electronic properties, and allows generation of novel,
diverse, and valid molecules with geometric features consistent with the
training data, which exhibit a varying range of global electronic structural
properties, such as a small HOMO-LUMO gap - a critical property for designing
organic solar cells. We demonstrate that our TDA augmentation yields better
success in downstream tasks compared to models trained without these
representations and can assist in targeted molecule discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Complexity of Tree Search Configuration: Cutting Planes and Beyond. (arXiv:2106.04033v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1">Maria-Florina Balcan</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasad_S/0/1/0/all/0/1">Siddharth Prasad</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1">Tuomas Sandholm</a>, <a href="http://arxiv.org/find/cs/1/au:+Vitercik_E/0/1/0/all/0/1">Ellen Vitercik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04033">
                                    <div class="article-summary-box-inner">
                                        <span>Cutting-plane methods have enabled remarkable successes in integer
programming over the last few decades. State-of-the-art solvers integrate a
myriad of cutting-plane techniques to speed up the underlying tree-search
algorithm used to find optimal solutions. In this paper we prove the first
guarantees for learning high-performing cut-selection policies tailored to the
instance distribution at hand using samples. We first bound the sample
complexity of learning cutting planes from the canonical family of
Chv\&#x27;atal-Gomory cuts. Our bounds handle any number of waves of any number of
cuts and are fine tuned to the magnitudes of the constraint coefficients. Next,
we prove sample complexity bounds for more sophisticated cut selection policies
that use a combination of scoring rules to choose from a family of cuts.
Finally, beyond the realm of cutting planes for integer programming, we develop
a general abstraction of tree search that captures key components such as node
selection and variable selection. For this abstraction, we bound the sample
complexity of learning a good policy for building the search tree.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Randomness of Input Data Spaces is an A Priori Predictor for Generalization. (arXiv:2106.04181v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Briesch_M/0/1/0/all/0/1">Martin Briesch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sobania_D/0/1/0/all/0/1">Dominik Sobania</a>, <a href="http://arxiv.org/find/cs/1/au:+Rothlauf_F/0/1/0/all/0/1">Franz Rothlauf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04181">
                                    <div class="article-summary-box-inner">
                                        <span>Over-parameterized models can perfectly learn various types of data
distributions, however, generalization error is usually lower for real data in
comparison to artificial data. This suggests that the properties of data
distributions have an impact on generalization capability. This work focuses on
the search space defined by the input data and assumes that the correlation
between labels of neighboring input values influences generalization. If
correlation is low, the randomness of the input data space is high leading to
high generalization error. We suggest to measure the randomness of an input
data space using Maurer&#x27;s universal. Results for synthetic classification tasks
and common image classification benchmarks (MNIST, CIFAR10, and Microsoft&#x27;s
cats vs. dogs data set) find a high correlation between the randomness of input
data spaces and the generalization error of deep neural networks for binary
classification problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforced Few-Shot Acquisition Function Learning for Bayesian Optimization. (arXiv:2106.04335v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsieh_B/0/1/0/all/0/1">Bing-Jing Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_P/0/1/0/all/0/1">Ping-Chun Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xi Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04335">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) conventionally relies on handcrafted acquisition
functions (AFs) to sequentially determine the sample points. However, it has
been widely observed in practice that the best-performing AF in terms of regret
can vary significantly under different types of black-box functions. It has
remained a challenge to design one AF that can attain the best performance over
a wide variety of black-box functions. This paper aims to attack this challenge
through the perspective of reinforced few-shot AF learning (FSAF).
Specifically, we first connect the notion of AFs with Q-functions and view a
deep Q-network (DQN) as a surrogate differentiable AF. While it serves as a
natural idea to combine DQN and an existing few-shot learning method, we
identify that such a direct combination does not perform well due to severe
overfitting, which is particularly critical in BO due to the need of a
versatile sampling policy. To address this, we present a Bayesian variant of
DQN with the following three features: (i) It learns a distribution of
Q-networks as AFs based on the Kullback-Leibler regularization framework. This
inherently provides the uncertainty required in sampling for BO and mitigates
overfitting. (ii) For the prior of the Bayesian DQN, we propose to use a demo
policy induced by an off-the-shelf AF for better training stability. (iii) On
the meta-level, we leverage the meta-loss of Bayesian model-agnostic
meta-learning, which serves as a natural companion to the proposed FSAF.
Moreover, with the proper design of the Q-networks, FSAF is general-purpose in
that it is agnostic to the dimension and the cardinality of the input domain.
Through extensive experiments, we demonstrate that the FSAF achieves comparable
or better regrets than the state-of-the-art benchmarks on a wide variety of
synthetic and real-world test functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Fast Kernel Transform. (arXiv:2106.04487v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ryan_J/0/1/0/all/0/1">John Paul Ryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ament_S/0/1/0/all/0/1">Sebastian Ament</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1">Carla P. Gomes</a>, <a href="http://arxiv.org/find/cs/1/au:+Damle_A/0/1/0/all/0/1">Anil Damle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04487">
                                    <div class="article-summary-box-inner">
                                        <span>Kernel methods are a highly effective and widely used collection of modern
machine learning algorithms. A fundamental limitation of virtually all such
methods are computations involving the kernel matrix that naively scale
quadratically (e.g., constructing the kernel matrix and matrix-vector
multiplication) or cubically (solving linear systems) with the size of the data
set $N.$ We propose the Fast Kernel Transform (FKT), a general algorithm to
compute matrix-vector multiplications (MVMs) for datasets in moderate
dimensions with quasilinear complexity. Typically, analytically grounded fast
multiplication methods require specialized development for specific kernels. In
contrast, our scheme is based on auto-differentiation and automated symbolic
computations that leverage the analytical structure of the underlying kernel.
This allows the FKT to be easily applied to a broad class of kernels, including
Gaussian, Matern, and Rational Quadratic covariance functions and physically
motivated Green&#x27;s functions, including those of the Laplace and Helmholtz
equations. Furthermore, the FKT maintains a high, quantifiable, and
controllable level of accuracy -- properties that many acceleration methods
lack. We illustrate the efficacy and versatility of the FKT by providing timing
and accuracy benchmarks and by applying it to scale the stochastic neighborhood
embedding (t-SNE) and Gaussian processes to large real-world data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Neural Collaborative Filtering. (arXiv:2106.04405v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perifanis_V/0/1/0/all/0/1">Vasileios Perifanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Efraimidis_P/0/1/0/all/0/1">Pavlos S. Efraimidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04405">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we present a federated version of the state-of-the-art Neural
Collaborative Filtering (NCF) approach for item recommendations. The system,
named FedNCF, allows learning without requiring users to expose or transmit
their raw data. Experimental validation shows that FedNCF achieves comparable
recommendation quality to the original NCF system. Although federated learning
(FL) enables learning without raw data transmission, recent attacks showed that
FL alone does not eliminate privacy concerns. To overcome this challenge, we
integrate a privacy-preserving enhancement with a secure aggregation scheme
that satisfies the security requirements against an honest-but-curious (HBC)
entity, without affecting the quality of the original model. Finally, we
discuss the peculiarities observed in the application of FL in a collaborative
filtering (CF) task as well as we evaluate the privacy-preserving mechanism in
terms of computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unbalanced Optimal Transport through Non-negative Penalized Linear Regression. (arXiv:2106.04145v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chapel_L/0/1/0/all/0/1">Laetitia Chapel</a>, <a href="http://arxiv.org/find/math/1/au:+Flamary_R/0/1/0/all/0/1">R&#xe9;mi Flamary</a>, <a href="http://arxiv.org/find/math/1/au:+Wu_H/0/1/0/all/0/1">Haoran Wu</a>, <a href="http://arxiv.org/find/math/1/au:+Fevotte_C/0/1/0/all/0/1">C&#xe9;dric F&#xe9;votte</a>, <a href="http://arxiv.org/find/math/1/au:+Gasso_G/0/1/0/all/0/1">Gilles Gasso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04145">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of Unbalanced Optimal Transport (UOT) in
which the marginal conditions are relaxed (using weighted penalties in lieu of
equality) and no additional regularization is enforced on the OT plan. In this
context, we show that the corresponding optimization problem can be
reformulated as a non-negative penalized linear regression problem. This
reformulation allows us to propose novel algorithms inspired from inverse
problems and nonnegative matrix factorization. In particular, we consider
majorization-minimization which leads in our setting to efficient
multiplicative updates for a variety of penalties. Furthermore, we derive for
the first time an efficient algorithm to compute the regularization path of UOT
with quadratic penalties. The proposed algorithm provides a continuity of
piece-wise linear OT plans converging to the solution of balanced OT
(corresponding to infinite penalty weights). We perform several numerical
experiments on simulated and real data illustrating the new algorithms, and
provide a detailed discussion about more sophisticated optimization tools that
can further be used to solve OT problems thanks to our reformulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PlayVirtual: Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning. (arXiv:2106.04152v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Tao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Cuiling Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1">Mingxiao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04152">
                                    <div class="article-summary-box-inner">
                                        <span>Learning good feature representations is important for deep reinforcement
learning (RL). However, with limited experience, RL often suffers from data
inefficiency for training. For un-experienced or less-experienced trajectories
(i.e., state-action sequences), the lack of data limits the use of them for
better feature learning. In this work, we propose a novel method, dubbed
PlayVirtual, which augments cycle-consistent virtual trajectories to enhance
the data efficiency for RL feature representation learning. Specifically,
PlayVirtual predicts future states based on the current state and action by a
dynamics model and then predicts the previous states by a backward dynamics
model, which forms a trajectory cycle. Based on this, we augment the actions to
generate a large amount of virtual state-action trajectories. Being free of
groudtruth state supervision, we enforce a trajectory to meet the cycle
consistency constraint, which can significantly enhance the data efficiency. We
validate the effectiveness of our designs on the Atari and DeepMind Control
Suite benchmarks. Our method outperforms the current state-of-the-art methods
by a large margin on both benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Machine Unlearning. (arXiv:2106.04378v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1">Varun Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_C/0/1/0/all/0/1">Christopher Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Neel_S/0/1/0/all/0/1">Seth Neel</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifi_Malvajerdi_S/0/1/0/all/0/1">Saeed Sharifi-Malvajerdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Waites_C/0/1/0/all/0/1">Chris Waites</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04378">
                                    <div class="article-summary-box-inner">
                                        <span>Data deletion algorithms aim to remove the influence of deleted data points
from trained models at a cheaper computational cost than fully retraining those
models. However, for sequences of deletions, most prior work in the non-convex
setting gives valid guarantees only for sequences that are chosen independently
of the models that are published. If people choose to delete their data as a
function of the published models (because they don&#x27;t like what the models
reveal about them, for example), then the update sequence is adaptive. In this
paper, we give a general reduction from deletion guarantees against adaptive
sequences to deletion guarantees against non-adaptive sequences, using
differential privacy and its connection to max information. Combined with ideas
from prior work which give guarantees for non-adaptive deletion sequences, this
leads to extremely flexible algorithms able to handle arbitrary model classes
and training methodologies, giving strong provable deletion guarantees for
adaptive deletion sequences. We show in theory how prior work for non-convex
models fails against adaptive deletion sequences, and use this intuition to
design a practical attack against the SISA algorithm of Bourtoule et al. [2021]
on CIFAR-10, MNIST, Fashion-MNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Proxy Causal Learning and its Application to Confounded Bandit Policy Evaluation. (arXiv:2106.03907v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Liyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanagawa_H/0/1/0/all/0/1">Heishiro Kanagawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03907">
                                    <div class="article-summary-box-inner">
                                        <span>Proxy causal learning (PCL) is a method for estimating the causal effect of
treatments on outcomes in the presence of unobserved confounding, using proxies
(structured side information) for the confounder. This is achieved via
two-stage regression: in the first stage, we model relations among the
treatment and proxies; in the second stage, we use this model to learn the
effect of treatment on the outcome, given the context provided by the proxies.
PCL guarantees recovery of the true causal effect, subject to identifiability
conditions. We propose a novel method for PCL, the deep feature proxy variable
method (DFPV), to address the case where the proxies, treatments, and outcomes
are high-dimensional and have nonlinear complex relationships, as represented
by deep neural network features. We show that DFPV outperforms recent
state-of-the-art PCL methods on challenging synthetic benchmarks, including
settings involving high dimensional image data. Furthermore, we show that PCL
can be applied to off-policy evaluation for the confounded bandit problem, in
which DFPV also exhibits competitive performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPANet: Generalized Permutationless Set Assignment for Particle Physics using Symmetry Preserving Attention. (arXiv:2106.03898v1 [hep-ex])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ex/1/au:+Shmakov_A/0/1/0/all/0/1">Alexander Shmakov</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Fenton_M/0/1/0/all/0/1">Michael James Fenton</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Ho_T/0/1/0/all/0/1">Ta-Wei Ho</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Hsu_S/0/1/0/all/0/1">Shih-Chieh Hsu</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Whiteson_D/0/1/0/all/0/1">Daniel Whiteson</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Baldi_P/0/1/0/all/0/1">Pierre Baldi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03898">
                                    <div class="article-summary-box-inner">
                                        <span>The creation of unstable heavy particles at the Large Hadron Collider is the
most direct way to address some of the deepest open questions in physics.
Collisions typically produce variable-size sets of observed particles which
have inherent ambiguities complicating the assignment of observed particles to
the decay products of the heavy particles. Current strategies for tackling
these challenges in the physics community ignore the physical symmetries of the
decay products and consider all possible assignment permutations and do not
scale to complex configurations. Attention based deep learning methods for
sequence modelling have achieved state-of-the-art performance in natural
language processing, but they lack built-in mechanisms to deal with the unique
symmetries found in physical set-assignment problems. We introduce a novel
method for constructing symmetry-preserving attention networks which reflect
the problem&#x27;s natural invariances to efficiently find assignments without
evaluating all permutations. This general approach is applicable to arbitrarily
complex configurations and significantly outperforms current methods, improving
reconstruction efficiency between 19\% - 35\% on typical benchmark problems
while decreasing inference time by two to five orders of magnitude on the most
complex events, making many important and previously intractable cases
tractable.

A full code repository containing a general library, the specific
configuration used, and a complete dataset release, are avaiable at
https://github.com/Alexanders101/SPANet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On $w$-mixtures: Finite convex combinations of prescribed component distributions. (arXiv:1708.00568v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nock_R/0/1/0/all/0/1">Richard Nock</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1708.00568">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the space of $w$-mixtures which is defined as the set of finite
statistical mixtures sharing the same prescribed component distributions closed
under convex combinations. The information geometry induced by the Bregman
generator set to the Shannon negentropy on this space yields a dually flat
space called the mixture family manifold. We show how the Kullback-Leibler (KL)
divergence can be recovered from the corresponding Bregman divergence for the
negentropy generator: That is, the KL divergence between two $w$-mixtures
amounts to a Bregman Divergence (BD) induced by the Shannon negentropy
generator. Thus the KL divergence between two Gaussian Mixture Models (GMMs)
sharing the same Gaussian components is equivalent to a Bregman divergence.
This KL-BD equivalence on a mixture family manifold implies that we can perform
optimal KL-averaging aggregation of $w$-mixtures without information loss. More
generally, we prove that the statistical skew Jensen-Shannon divergence between
$w$-mixtures is equivalent to a skew Jensen divergence between their
corresponding parameters. Finally, we state several properties, divergence
identities, and inequalities relating to $w$-mixtures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Occode: an end-to-end machine learning pipeline for transcription of historical population censuses. (arXiv:2106.03996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pedersen_B/0/1/0/all/0/1">Bj&#xf8;rn-Richard Pedersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Holsbo_E/0/1/0/all/0/1">Einar Holsb&#xf8;</a>, <a href="http://arxiv.org/find/cs/1/au:+Andersen_T/0/1/0/all/0/1">Trygve Andersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shvetsov_N/0/1/0/all/0/1">Nikita Shvetsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravn_J/0/1/0/all/0/1">Johan Ravn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommerseth_H/0/1/0/all/0/1">Hilde Leikny Sommerseth</a>, <a href="http://arxiv.org/find/cs/1/au:+Bongo_L/0/1/0/all/0/1">Lars Ailo Bongo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03996">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning approaches achieve high accuracy for text recognition and
are therefore increasingly used for the transcription of handwritten historical
sources. However, using machine learning in production requires a streamlined
end-to-end machine learning pipeline that scales to the dataset size, and a
model that achieves high accuracy with few manual transcriptions. In addition,
the correctness of the model results must be verified. This paper describes our
lessons learned developing, tuning, and using the Occode end-to-end machine
learning pipeline for transcribing 7,3 million rows with handwritten occupation
codes in the Norwegian 1950 population census. We achieve an accuracy of 97%
for the automatically transcribed codes, and we send 3% of the codes for manual
verification. We verify that the occupation code distribution found in our
result matches the distribution found in our training data which should be
representative for the census as a whole. We believe our approach and lessons
learned are useful for other transcription projects that plan to use machine
learning in production. The source code is available at:
https://github.com/uit-hdl/rhd-codes</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speedy Performance Estimation for Neural Architecture Search. (arXiv:2006.04492v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ru_B/0/1/0/all/0/1">Binxin Ru</a>, <a href="http://arxiv.org/find/stat/1/au:+Lyle_C/0/1/0/all/0/1">Clare Lyle</a>, <a href="http://arxiv.org/find/stat/1/au:+Schut_L/0/1/0/all/0/1">Lisa Schut</a>, <a href="http://arxiv.org/find/stat/1/au:+Fil_M/0/1/0/all/0/1">Miroslav Fil</a>, <a href="http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1">Mark van der Wilk</a>, <a href="http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04492">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable yet efficient evaluation of generalisation performance of a proposed
architecture is crucial to the success of neural architecture search (NAS).
Traditional approaches face a variety of limitations: training each
architecture to completion is prohibitively expensive, early stopped validation
accuracy may correlate poorly with fully trained performance, and model-based
estimators require large training sets. We instead propose to estimate the
final test performance based on a simple measure of training speed. Our
estimator is theoretically motivated by the connection between generalisation
and training speed, and is also inspired by the reformulation of a PAC-Bayes
bound under the Bayesian setting. Our model-free estimator is simple,
efficient, and cheap to implement, and does not require hyperparameter-tuning
or surrogate training before deployment. We demonstrate on various NAS search
spaces that our estimator consistently outperforms other alternatives in
achieving better correlation with the true test performance rankings. We
further show that our estimator can be easily incorporated into both
query-based and one-shot NAS methods to improve the speed or quality of the
search.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-output Gaussian Processes for Uncertainty-aware Recommender Systems. (arXiv:2106.04221v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yinchong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Buettner_F/0/1/0/all/0/1">Florian Buettner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04221">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems are often designed based on a collaborative filtering
approach, where user preferences are predicted by modelling interactions
between users and items. Many common approaches to solve the collaborative
filtering task are based on learning representations of users and items,
including simple matrix factorization, Gaussian process latent variable models,
and neural-network based embeddings. While matrix factorization approaches fail
to model nonlinear relations, neural networks can potentially capture such
complex relations with unprecedented predictive power and are highly scalable.
However, neither of them is able to model predictive uncertainties. In
contrast, Gaussian Process based models can generate a predictive distribution,
but cannot scale to large amounts of data. In this manuscript, we propose a
novel approach combining the representation learning paradigm of collaborative
filtering with multi-output Gaussian processes in a joint framework to generate
uncertainty-aware recommendations. We introduce an efficient strategy for model
training and inference, resulting in a model that scales to very large and
sparse datasets and achieves competitive performance in terms of classical
metrics quantifying the reconstruction error. In addition to accurately
predicting user preferences, our model also provides meaningful uncertainty
estimates about that prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Statistical Arbitrage. (arXiv:2106.04028v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guijarro_Ordonez_J/0/1/0/all/0/1">Jorge Guijarro-Ordonez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelger_M/0/1/0/all/0/1">Markus Pelger</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanotti_G/0/1/0/all/0/1">Greg Zanotti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04028">
                                    <div class="article-summary-box-inner">
                                        <span>Statistical arbitrage identifies and exploits temporal price differences
between similar assets. We propose a unifying conceptual framework for
statistical arbitrage and develop a novel deep learning solution, which finds
commonality and time-series patterns from large panels in a data-driven and
flexible way. First, we construct arbitrage portfolios of similar assets as
residual portfolios from conditional latent asset pricing factors. Second, we
extract the time series signals of these residual portfolios with one of the
most powerful machine learning time-series solutions, a convolutional
transformer. Last, we use these signals to form an optimal trading policy, that
maximizes risk-adjusted returns under constraints. We conduct a comprehensive
empirical comparison study with daily large cap U.S. stocks. Our optimal
trading strategy obtains a consistently high out-of-sample Sharpe ratio and
substantially outperforms all benchmark approaches. It is orthogonal to common
risk factors, and exploits asymmetric local trend and reversion patterns. Our
strategies remain profitable after taking into account trading frictions and
costs. Our findings suggest a high compensation for arbitrageurs to enforce the
law of one price.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Widening Access to Applied Machine Learning with TinyML. (arXiv:2106.04008v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reddi_V/0/1/0/all/0/1">Vijay Janapa Reddi</a>, <a href="http://arxiv.org/find/cs/1/au:+Plancher_B/0/1/0/all/0/1">Brian Plancher</a>, <a href="http://arxiv.org/find/cs/1/au:+Kennedy_S/0/1/0/all/0/1">Susan Kennedy</a>, <a href="http://arxiv.org/find/cs/1/au:+Moroney_L/0/1/0/all/0/1">Laurence Moroney</a>, <a href="http://arxiv.org/find/cs/1/au:+Warden_P/0/1/0/all/0/1">Pete Warden</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Anant Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Banbury_C/0/1/0/all/0/1">Colby Banbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Banzi_M/0/1/0/all/0/1">Massimo Banzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_M/0/1/0/all/0/1">Matthew Bennett</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_B/0/1/0/all/0/1">Benjamin Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Chitlangia_S/0/1/0/all/0/1">Sharad Chitlangia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosal_R/0/1/0/all/0/1">Radhika Ghosal</a>, <a href="http://arxiv.org/find/cs/1/au:+Grafman_S/0/1/0/all/0/1">Sarah Grafman</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaeger_R/0/1/0/all/0/1">Rupert Jaeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_S/0/1/0/all/0/1">Srivatsan Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1">Maximilian Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Leiker_D/0/1/0/all/0/1">Daniel Leiker</a>, <a href="http://arxiv.org/find/cs/1/au:+Mann_C/0/1/0/all/0/1">Cara Mann</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazumder_M/0/1/0/all/0/1">Mark Mazumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Pajak_D/0/1/0/all/0/1">Dominic Pajak</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramaprasad_D/0/1/0/all/0/1">Dhilan Ramaprasad</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1">J. Evan Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Stewart_M/0/1/0/all/0/1">Matthew Stewart</a>, <a href="http://arxiv.org/find/cs/1/au:+Tingley_D/0/1/0/all/0/1">Dustin Tingley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04008">
                                    <div class="article-summary-box-inner">
                                        <span>Broadening access to both computational and educational resources is critical
to diffusing machine-learning (ML) innovation. However, today, most ML
resources and experts are siloed in a few countries and organizations. In this
paper, we describe our pedagogical approach to increasing access to applied ML
through a massive open online course (MOOC) on Tiny Machine Learning (TinyML).
We suggest that TinyML, ML on resource-constrained embedded devices, is an
attractive means to widen access because TinyML both leverages low-cost and
globally accessible hardware, and encourages the development of complete,
self-contained applications, from data collection to deployment. To this end, a
collaboration between academia (Harvard University) and industry (Google)
produced a four-part MOOC that provides application-oriented instruction on how
to develop solutions using TinyML. The series is openly available on the edX
MOOC platform, has no prerequisites beyond basic programming, and is designed
for learners from a global variety of backgrounds. It introduces pupils to
real-world applications, ML algorithms, data-set engineering, and the ethical
considerations of these technologies via hands-on programming and deployment of
TinyML applications in both the cloud and their own microcontrollers. To
facilitate continued learning, community building, and collaboration beyond the
courses, we launched a standalone website, a forum, a chat, and an optional
course-project competition. We also released the course materials publicly,
hoping they will inspire the next generation of ML practitioners and educators
and further broaden access to cutting-edge ML technologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs. (arXiv:2106.04110v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naveh_G/0/1/0/all/0/1">Gadi Naveh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ringel_Z/0/1/0/all/0/1">Zohar Ringel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04110">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) in the infinite width/channel limit have received
much attention recently, as they provide a clear analytical window to deep
learning via mappings to Gaussian Processes (GPs). Despite its theoretical
appeal, this viewpoint lacks a crucial ingredient of deep learning in finite
DNNs, laying at the heart of their success -- feature learning. Here we
consider DNNs trained with noisy gradient descent on a large training set and
derive a self consistent Gaussian Process theory accounting for strong
finite-DNN and feature learning effects. Applying this to a toy model of a
two-layer linear convolutional neural network (CNN) shows good agreement with
experiments. We further identify, both analytical and numerically, a sharp
transition between a feature learning regime and a lazy learning regime in this
model. Strong finite-DNN effects are also derived for a non-linear two-layer
fully connected network. Our self consistent theory provides a rich and
versatile analytical framework for studying feature learning and other non-lazy
effects in finite DNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Label Cleaning with Example-based Explanations. (arXiv:2106.03922v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1">Stefano Teso</a>, <a href="http://arxiv.org/find/cs/1/au:+Bontempelli_A/0/1/0/all/0/1">Andrea Bontempelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1">Fausto Giunchiglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1">Andrea Passerini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03922">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle sequential learning under label noise in applications where a human
supervisor can be queried to relabel suspicious examples. Existing approaches
are flawed, in that they only relabel incoming examples that look
&#x60;&#x60;suspicious&#x27;&#x27; to the model. As a consequence, those mislabeled examples that
elude (or don&#x27;t undergo) this cleaning step end up tainting the training data
and the model with no further chance of being cleaned. We propose Cincer, a
novel approach that cleans both new and past data by identifying pairs of
mutually incompatible examples. Whenever it detects a suspicious example,
Cincer identifies a counter-example in the training set that -- according to
the model -- is maximally incompatible with the suspicious example, and asks
the annotator to relabel either or both examples, resolving this possible
inconsistency. The counter-examples are chosen to be maximally incompatible, so
to serve as explanations of the model&#x27; suspicion, and highly influential, so to
convey as much information as possible if relabeled. Cincer achieves this by
leveraging an efficient and robust approximation of influence functions based
on the Fisher information matrix (FIM). Our extensive empirical evaluation
shows that clarifying the reasons behind the model&#x27;s suspicions by cleaning the
counter-examples helps acquiring substantially better data and models,
especially when paired with our FIM approximation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine Curriculum Learning. (arXiv:2106.04072v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stretcu_O/0/1/0/all/0/1">Otilia Stretcu</a>, <a href="http://arxiv.org/find/cs/1/au:+Platanios_E/0/1/0/all/0/1">Emmanouil Antonios Platanios</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1">Tom M. Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Poczos_B/0/1/0/all/0/1">Barnab&#xe1;s P&#xf3;czos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04072">
                                    <div class="article-summary-box-inner">
                                        <span>When faced with learning challenging new tasks, humans often follow sequences
of steps that allow them to incrementally build up the necessary skills for
performing these new tasks. However, in machine learning, models are most often
trained to solve the target tasks directly.Inspired by human learning, we
propose a novel curriculum learning approach which decomposes challenging tasks
into sequences of easier intermediate goals that are used to pre-train a model
before tackling the target task. We focus on classification tasks, and design
the intermediate tasks using an automatically constructed label hierarchy. We
train the model at each level of the hierarchy, from coarse labels to fine
labels, transferring acquired knowledge across these levels. For instance, the
model will first learn to distinguish animals from objects, and then use this
acquired knowledge when learning to classify among more fine-grained classes
such as cat, dog, car, and truck. Most existing curriculum learning algorithms
for supervised learning consist of scheduling the order in which the training
examples are presented to the model. In contrast, our approach focuses on the
output space of the model. We evaluate our method on several established
datasets and show significant performance gains especially on classification
problems with many labels. We also evaluate on a new synthetic dataset which
allows us to study multiple aspects of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amortized Generation of Sequential Counterfactual Explanations for Black-box Models. (arXiv:2106.03962v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1">Sahil Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Hines_K/0/1/0/all/0/1">Keegan Hines</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1">John P. Dickerson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03962">
                                    <div class="article-summary-box-inner">
                                        <span>Explainable machine learning (ML) has gained traction in recent years due to
the increasing adoption of ML-based systems in many sectors. Counterfactual
explanations (CFEs) provide &#x60;&#x60;what if&#x27;&#x27; feedback of the form &#x60;&#x60;if an input
datapoint were $x&#x27;$ instead of $x$, then an ML-based system&#x27;s output would be
$y&#x27;$ instead of $y$.&#x27;&#x27; CFEs are attractive due to their actionable feedback,
amenability to existing legal frameworks, and fidelity to the underlying ML
model. Yet, current CFE approaches are single shot -- that is, they assume $x$
can change to $x&#x27;$ in a single time period. We propose a novel
stochastic-control-based approach that generates sequential CFEs, that is, CFEs
that allow $x$ to move stochastically and sequentially across intermediate
states to a final state $x&#x27;$. Our approach is model agnostic and black box.
Furthermore, calculation of CFEs is amortized such that once trained, it
applies to multiple datapoints without the need for re-optimization. In
addition to these primary characteristics, our approach admits optional
desiderata such as adherence to the data manifold, respect for causal
relations, and sparsity -- identified by past research as desirable properties
of CFEs. We evaluate our approach using three real-world datasets and show
successful generation of sequential CFEs that respect other counterfactual
desiderata.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Double Descent and Other Interpolation Phenomena in GANs. (arXiv:2106.04003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luzi_L/0/1/0/all/0/1">Lorenzo Luzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dar_Y/0/1/0/all/0/1">Yehuda Dar</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1">Richard Baraniuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04003">
                                    <div class="article-summary-box-inner">
                                        <span>We study overparameterization in generative adversarial networks (GANs) that
can interpolate the training data. We show that overparameterization can
improve generalization performance and accelerate the training process. We
study the generalization error as a function of latent space dimension and
identify two main behaviors, depending on the learning setting. First, we show
that overparameterized generative models that learn distributions by minimizing
a metric or $f$-divergence do not exhibit double descent in generalization
errors; specifically, all the interpolating solutions achieve the same
generalization error. Second, we develop a new pseudo-supervised learning
approach for GANs where the training utilizes pairs of fabricated (noise)
inputs in conjunction with real output samples. Our pseudo-supervised setting
exhibits double descent (and in some cases, triple descent) of generalization
errors. We combine pseudo-supervision with overparameterization (i.e., overly
large latent space dimension) to accelerate training while performing better,
or close to, the generalization performance without pseudo-supervision. While
our analysis focuses mostly on linear GANs, we also apply important insights
for improving generalization of nonlinear, multilayer GANs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Abstractive Unsupervised Summarization of Online News Discussions. (arXiv:2106.03953v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palma_I/0/1/0/all/0/1">Ignacio Tampe Palma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendoza_M/0/1/0/all/0/1">Marcelo Mendoza</a>, <a href="http://arxiv.org/find/cs/1/au:+Milios_E/0/1/0/all/0/1">Evangelos Milios</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03953">
                                    <div class="article-summary-box-inner">
                                        <span>Summarization has usually relied on gold standard summaries to train
extractive or abstractive models. Social media brings a hurdle to summarization
techniques since it requires addressing a multi-document multi-author approach.
We address this challenging task by introducing a novel method that generates
abstractive summaries of online news discussions. Our method extends a
BERT-based architecture, including an attention encoding that fed comments&#x27;
likes during the training stage. To train our model, we define a task which
consists of reconstructing high impact comments based on popularity (likes).
Accordingly, our model learns to summarize online discussions based on their
most relevant comments. Our novel approach provides a summary that represents
the most relevant aspects of a news item that users comment on, incorporating
the social context as a source of information to summarize texts in online
social networks. Our model is evaluated using ROUGE scores between the
generated summary and each comment on the thread. Our model, including the
social attention encoding, significantly outperforms both extractive and
abstractive summarization methods based on such evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Speech Emotion Recognition Using Multi-Scale CNN and Attention. (arXiv:2106.04133v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zixuan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shengfeng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunfeng Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04133">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion recognition from speech is a challenging task. Re-cent advances in
deep learning have led bi-directional recur-rent neural network (Bi-RNN) and
attention mechanism as astandard method for speech emotion recognition,
extractingand attending multi-modal features - audio and text, and thenfusing
them for downstream emotion classification tasks. Inthis paper, we propose a
simple yet efficient neural networkarchitecture to exploit both acoustic and
lexical informationfrom speech. The proposed framework using multi-scale
con-volutional layers (MSCNN) to obtain both audio and text hid-den
representations. Then, a statistical pooling unit (SPU)is used to further
extract the features in each modality. Be-sides, an attention module can be
built on top of the MSCNN-SPU (audio) and MSCNN (text) to further improve the
perfor-mance. Extensive experiments show that the proposed modeloutperforms
previous state-of-the-art methods on IEMOCAPdataset with four emotion
categories (i.e., angry, happy, sadand neutral) in both weighted accuracy (WA)
and unweightedaccuracy (UA), with an improvement of 5.0% and 5.2% respectively
under the ASR setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoPtosis. (arXiv:2106.03905v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Aleem_A/0/1/0/all/0/1">Abdullah Aleem</a>, <a href="http://arxiv.org/find/eess/1/au:+Nallabothula_M/0/1/0/all/0/1">Manoj Prabhakar Nallabothula</a>, <a href="http://arxiv.org/find/eess/1/au:+Setabutr_P/0/1/0/all/0/1">Pete Setabutr</a>, <a href="http://arxiv.org/find/eess/1/au:+Hallak_J/0/1/0/all/0/1">Joelle A. Hallak</a>, <a href="http://arxiv.org/find/eess/1/au:+Yi_D/0/1/0/all/0/1">Darvin Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03905">
                                    <div class="article-summary-box-inner">
                                        <span>Blepharoptosis, or ptosis as it is more commonly referred to, is a condition
of the eyelid where the upper eyelid droops. The current diagnosis for ptosis
involves cumbersome manual measurements that are time-consuming and prone to
human error. In this paper, we present AutoPtosis, an artificial intelligence
based system with interpretable results for rapid diagnosis of ptosis. We
utilize a diverse dataset collected at the University of Illinois Hospital and
Health to successfully develop a robust deep learning model for prediction and
also develop a clinically inspired model that calculates the marginal reflex
distance and iris ratio. AutoPtosis achieved 95.5% accuracy on physician
verified data that had an equal class balance. The proposed algorithm can help
in the rapid and timely diagnosis of ptosis, significantly reduce the burden on
the healthcare system, and save the patients and clinics valuable resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Flows with Invertible Attentions. (arXiv:2106.03959v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sukthanker_R/0/1/0/all/0/1">Rhea Sanjay Sukthanker</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhiwu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Suryansh Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>, <a href="http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03959">
                                    <div class="article-summary-box-inner">
                                        <span>Flow-based generative models have shown excellent ability to explicitly learn
the probability density function of data via a sequence of invertible
transformations. Yet, modeling long-range dependencies over normalizing flows
remains understudied. To fill the gap, in this paper, we introduce two types of
invertible attention mechanisms for generative flow models. To be precise, we
propose map-based and scaled dot-product attention for unconditional and
conditional generative flow models. The key idea is to exploit split-based
attention mechanisms to learn the attention weights and input representations
on every two splits of flow feature maps. Our method provides invertible
attention modules with tractable Jacobian determinants, enabling seamless
integration of it at any positions of the flow-based models. The proposed
attention mechanism can model the global data dependencies, leading to more
comprehensive flow models. Evaluation on multiple generation tasks demonstrates
that the introduced attention flow idea results in efficient flow models and
compares favorably against the state-of-the-art unconditional and conditional
generative flow methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Future is Log-Gaussian: ResNets and Their Infinite-Depth-and-Width Limit at Initialization. (arXiv:2106.04013v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1">Mufan Bill Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Nica_M/0/1/0/all/0/1">Mihai Nica</a>, <a href="http://arxiv.org/find/stat/1/au:+Roy_D/0/1/0/all/0/1">Daniel M. Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04013">
                                    <div class="article-summary-box-inner">
                                        <span>Theoretical results show that neural networks can be approximated by Gaussian
processes in the infinite-width limit. However, for fully connected networks,
it has been previously shown that for any fixed network width, $n$, the
Gaussian approximation gets worse as the network depth, $d$, increases. Given
that modern networks are deep, this raises the question of how well modern
architectures, like ResNets, are captured by the infinite-width limit. To
provide a better approximation, we study ReLU ResNets in the
infinite-depth-and-width limit, where both depth and width tend to infinity as
their ratio, $d/n$, remains constant. In contrast to the Gaussian
infinite-width limit, we show theoretically that the network exhibits
log-Gaussian behaviour at initialization in the infinite-depth-and-width limit,
with parameters depending on the ratio $d/n$. Using Monte Carlo simulations, we
demonstrate that even basic properties of standard ResNet architectures are
poorly captured by the Gaussian limit, but remarkably well captured by our
log-Gaussian limit. Moreover, our analysis reveals that ReLU ResNets at
initialization are hypoactivated: fewer than half of the ReLUs are activated.
Additionally, we calculate the interlayer correlations, which have the effect
of exponentially increasing the variance of the network output. Based on our
analysis, we introduce Balanced ResNets, a simple architecture modification,
which eliminates hypoactivation and interlayer correlations and is more
amenable to theoretical analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FEAR: A Simple Lightweight Method to Rank Architectures. (arXiv:2106.04010v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1">Debadeepta Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1">Shital Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1">Sebastien Bubeck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04010">
                                    <div class="article-summary-box-inner">
                                        <span>The fundamental problem in Neural Architecture Search (NAS) is to efficiently
find high-performing architectures from a given search space. We propose a
simple but powerful method which we call FEAR, for ranking architectures in any
search space. FEAR leverages the viewpoint that neural networks are powerful
non-linear feature extractors. First, we train different architectures in the
search space to the same training or validation error. Then, we compare the
usefulness of the features extracted by each architecture. We do so with a
quick training keeping most of the architecture frozen. This gives fast
estimates of the relative performance. We validate FEAR on Natsbench topology
search space on three different datasets against competing baselines and show
strong ranking correlation especially compared to recently proposed zero-cost
methods. FEAR particularly excels at ranking high-performance architectures in
the search space. When used in the inner loop of discrete search algorithms
like random search, FEAR can cut down the search time by approximately 2.4X
without losing accuracy. We additionally empirically study very recently
proposed zero-cost measures for ranking and find that they breakdown in ranking
performance as training proceeds and also that data-agnostic ranking scores
which ignore the dataset do not generalize across dissimilar datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lexicon Learning for Few-Shot Neural Sequence Modeling. (arXiv:2106.03993v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akyurek_E/0/1/0/all/0/1">Ekin Aky&#xfc;rek</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03993">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence-to-sequence transduction is the core problem in language processing
applications as diverse as semantic parsing, machine translation, and
instruction following. The neural network models that provide the dominant
solution to these problems are brittle, especially in low-resource settings:
they fail to generalize correctly or systematically from small datasets. Past
work has shown that many failures of systematic generalization arise from
neural models&#x27; inability to disentangle lexical phenomena from syntactic ones.
To address this, we augment neural decoders with a lexical translation
mechanism that generalizes existing copy mechanisms to incorporate learned,
decontextualized, token-level translation rules. We describe how to initialize
this mechanism using a variety of lexicon learning algorithms, and show that it
improves systematic generalization on a diverse set of sequence modeling tasks
drawn from cognitive science, formal semantics, and machine translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic Dimension Estimation. (arXiv:2106.04018v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Block_A/0/1/0/all/0/1">Adam Block</a>, <a href="http://arxiv.org/find/stat/1/au:+Jia_Z/0/1/0/all/0/1">Zeyu Jia</a>, <a href="http://arxiv.org/find/stat/1/au:+Polyanskiy_Y/0/1/0/all/0/1">Yury Polyanskiy</a>, <a href="http://arxiv.org/find/stat/1/au:+Rakhlin_A/0/1/0/all/0/1">Alexander Rakhlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04018">
                                    <div class="article-summary-box-inner">
                                        <span>It has long been thought that high-dimensional data encountered in many
practical machine learning tasks have low-dimensional structure, i.e., the
manifold hypothesis holds. A natural question, thus, is to estimate the
intrinsic dimension of a given population distribution from a finite sample. We
introduce a new estimator of the intrinsic dimension and provide finite sample,
non-asymptotic guarantees. We then apply our techniques to get new sample
complexity bounds for Generative Adversarial Networks (GANs) depending only on
the intrinsic dimension of the data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Social Welfare While Preserving Autonomy via a Pareto Mediator. (arXiv:2106.03927v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+McAleer_S/0/1/0/all/0/1">Stephen McAleer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lanier_J/0/1/0/all/0/1">John Lanier</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1">Michael Dennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1">Pierre Baldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_R/0/1/0/all/0/1">Roy Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03927">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning algorithms often make decisions on behalf of agents with
varied and sometimes conflicting interests. In domains where agents can choose
to take their own action or delegate their action to a central mediator, an
open question is how mediators should take actions on behalf of delegating
agents. The main existing approach uses delegating agents to punish
non-delegating agents in an attempt to get all agents to delegate, which tends
to be costly for all. We introduce a Pareto Mediator which aims to improve
outcomes for delegating agents without making any of them worse off. Our
experiments in random normal form games, a restaurant recommendation game, and
a reinforcement learning sequential social dilemma show that the Pareto
Mediator greatly increases social welfare. Also, even when the Pareto Mediator
is based on an incorrect model of agent utility, performance gracefully
degrades to the pre-intervention level, due to the individual autonomy
preserved by the voluntary mediator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Method Based on NARX models and Machine Learning for Pattern Recognition. (arXiv:2106.04021v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Silva_P/0/1/0/all/0/1">P. H. O. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerqueira_A/0/1/0/all/0/1">A. S. Cerqueira</a>, <a href="http://arxiv.org/find/cs/1/au:+Nepomuceno_E/0/1/0/all/0/1">E. G. Nepomuceno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04021">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a novel technique that integrates the methodologies of
machine learning and system identification to solve multiclass problems. Such
an approach allows to extract and select sets of representative features with
reduced dimensionality, as well as predicts categorical outputs. The efficiency
of the method was tested by running case studies investigated in machine
learning, obtaining better absolute results when compared with classical
classification algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11601">
                                    <div class="article-summary-box-inner">
                                        <span>Personalization of natural language generation plays a vital role in a large
spectrum of tasks, such as explainable recommendation, review summarization and
dialog systems. In these tasks, user and item IDs are important identifiers for
personalization. Transformer, which is demonstrated with strong language
modeling capability, however, is not personalized and fails to make use of the
user and item IDs since the ID tokens are not even in the same semantic space
as the words. To address this problem, we present a PErsonalized Transformer
for Explainable Recommendation (PETER), on which we design a simple and
effective learning objective that utilizes the IDs to predict the words in the
target explanation, so as to endow the IDs with linguistic meanings and to
achieve personalized Transformer. Besides generating explanations, PETER can
also make recommendations, which makes it a unified model for the whole
recommendation-explanation pipeline. Extensive experiments show that our small
unpretrained model outperforms fine-tuned BERT on the generation task, in terms
of both effectiveness and efficiency, which highlights the importance and the
nice utility of our design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation. (arXiv:2009.07526v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1">Yuan Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yujing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yue Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07526">
                                    <div class="article-summary-box-inner">
                                        <span>Scene graphs are semantic abstraction of images that encourage visual
understanding and reasoning. However, the performance of Scene Graph Generation
(SGG) is unsatisfactory when faced with biased data in real-world scenarios.
Conventional debiasing research mainly studies from the view of balancing data
distribution or learning unbiased models and representations, ignoring the
correlations among the biased classes. In this work, we analyze this problem
from a novel cognition perspective: automatically building a hierarchical
cognitive structure from the biased predictions and navigating that hierarchy
to locate the relationships, making the tail relationships receive more
attention in a coarse-to-fine mode. To this end, we propose a novel debiasing
Cognition Tree (CogTree) loss for unbiased SGG. We first build a cognitive
structure CogTree to organize the relationships based on the prediction of a
biased SGG model. The CogTree distinguishes remarkably different relationships
at first and then focuses on a small portion of easily confused ones. Then, we
propose a debiasing loss specially for this cognitive structure, which supports
coarse-to-fine distinction for the correct relationships. The loss is
model-agnostic and consistently boosting the performance of several
state-of-the-art models. The code is available at:
https://github.com/CYVincent/Scene-Graph-Transformer-CogTree.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SynthRef: Generation of Synthetic Referring Expressions for Object Segmentation. (arXiv:2106.04403v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazakos_I/0/1/0/all/0/1">Ioannis Kazakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventura_C/0/1/0/all/0/1">Carles Ventura</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellver_M/0/1/0/all/0/1">Miriam Bellver</a>, <a href="http://arxiv.org/find/cs/1/au:+Silberer_C/0/1/0/all/0/1">Carina Silberer</a>, <a href="http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1">Xavier Giro-i-Nieto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04403">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep learning have brought significant progress in visual
grounding tasks such as language-guided video object segmentation. However,
collecting large datasets for these tasks is expensive in terms of annotation
time, which represents a bottleneck. To this end, we propose a novel method,
namely SynthRef, for generating synthetic referring expressions for target
objects in an image (or video frame), and we also present and disseminate the
first large-scale dataset with synthetic referring expressions for video object
segmentation. Our experiments demonstrate that by training with our synthetic
referring expressions one can improve the ability of a model to generalize
across different datasets, without any additional annotation cost. Moreover,
our formulation allows its application to any object detection or segmentation
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Video Configuration and Bitrate Allocation for Vehicles. (arXiv:2102.10898v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Schimpe_A/0/1/0/all/0/1">Andreas Schimpe</a>, <a href="http://arxiv.org/find/eess/1/au:+Hoffmann_S/0/1/0/all/0/1">Simon Hoffmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Diermeyer_F/0/1/0/all/0/1">Frank Diermeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10898">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicles with autonomous driving capabilities are present on public streets.
However, edge cases remain that still require a human in-vehicle driver.
Assuming the vehicle manages to come to a safe state in an automated fashion,
teleoperated driving technology enables a human to resolve the situation
remotely by a control interface connected via a mobile network. While this is a
promising solution, it also introduces technical challenges, one of them being
the necessity to transmit video data of multiple cameras from the vehicle to
the human operator. In this paper, an adaptive video streaming framework
specifically designed for teleoperated vehicles is proposed and demonstrated.
The framework enables automatic reconfiguration of the video streams of the
multi-camera system at runtime. Predictions of variable transmission service
quality are taken into account. With the objective to improve visual quality,
the framework uses so-called rate-quality models to dynamically allocate
bitrates and select resolution scaling factors. Results from deploying the
proposed framework on an actual teleoperated driving system are presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Triad Matching and Reconstruction for Weakly Referring Expression Grounding. (arXiv:2106.04053v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Mingjie Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jimin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1">Eng Gee Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Si Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulermas_J/0/1/0/all/0/1">John Y. Goulermas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04053">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we are tackling the weakly-supervised referring expression
grounding task, for the localization of a referent object in an image according
to a query sentence, where the mapping between image regions and queries are
not available during the training stage. In traditional methods, an object
region that best matches the referring expression is picked out, and then the
query sentence is reconstructed from the selected region, where the
reconstruction difference serves as the loss for back-propagation. The existing
methods, however, conduct both the matching and the reconstruction
approximately as they ignore the fact that the matching correctness is unknown.
To overcome this limitation, a discriminative triad is designed here as the
basis to the solution, through which a query can be converted into one or
multiple discriminative triads in a very scalable way. Based on the
discriminative triad, we further propose the triad-level matching and
reconstruction modules which are lightweight yet effective for the
weakly-supervised training, making it three times lighter and faster than the
previous state-of-the-art methods. One important merit of our work is its
superior performance despite the simple and neat design. Specifically, the
proposed method achieves a new state-of-the-art accuracy when evaluated on
RefCOCO (39.21%), RefCOCO+ (39.18%) and RefCOCOg (43.24%) datasets, that is
4.17%, 4.08% and 7.8% higher than the previous one, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation. (arXiv:2106.04151v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zhekai Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hongzu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Ke Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04151">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation (UDA) aims to generalize the knowledge learned
from a well-labeled source domain to an unlabeled target domain. Recently,
adversarial domain adaptation with two distinct classifiers (bi-classifier) has
been introduced into UDA which is effective to align distributions between
different domains. Previous bi-classifier adversarial learning methods only
focus on the similarity between the outputs of two distinct classifiers.
However, the similarity of the outputs cannot guarantee the accuracy of target
samples, i.e., target samples may match to wrong categories even if the
discrepancy between two classifiers is small. To challenge this issue, in this
paper, we propose a cross-domain gradient discrepancy minimization (CGDM)
method which explicitly minimizes the discrepancy of gradients generated by
source samples and target samples. Specifically, the gradient gives a cue for
the semantic information of target samples so it can be used as a good
supervision to improve the accuracy of target samples. In order to compute the
gradient signal of target samples, we further obtain target pseudo labels
through a clustering-based self-supervised learning. Extensive experiments on
three widely used UDA datasets show that our method surpasses many previous
state-of-the-arts. Codes are available at https://github.com/lijin118/CGDM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-08">2021-06-08</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpanNER: Named Entity Re-/Recognition as Span Prediction. (arXiv:2106.00641v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanjing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00641">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen the paradigm shift of Named Entity Recognition (NER)
systems from sequence labeling to span prediction. Despite its preliminary
effectiveness, the span prediction model&#x27;s architectural bias has not been
fully understood. In this paper, we first investigate the strengths and
weaknesses when the span prediction model is used for named entity recognition
compared with the sequence labeling framework and how to further improve it,
which motivates us to make complementary advantages of systems based on
different paradigms. We then reveal that span prediction, simultaneously, can
serve as a system combiner to re-recognize named entities from different
systems&#x27; outputs. We experimentally implement 154 systems on 11 datasets,
covering three languages, comprehensive results show the effectiveness of span
prediction models that both serve as base NER systems and system combiners. We
make all code and datasets available: \url{https://github.com/neulab/spanner},
as well as an online system demo: \url{this http URL}. Our model also has
been deployed into the ExplainaBoard platform, which allows users to flexibly
perform a system combination of top-scoring systems in an interactive way:
\url{this http URL}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed&#x27;s competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KGPool: Dynamic Knowledge Graph Context Selection for Relation Extraction. (arXiv:2106.00459v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang&#x27;</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraswat_V/0/1/0/all/0/1">Vijay Saraswat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00459">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for relation extraction (RE) from a single
sentence, mapping the sentence and two given entities to a canonical fact in a
knowledge graph (KG). Especially in this presumed sentential RE setting, the
context of a single sentence is often sparse. This paper introduces the KGPool
method to address this sparsity, dynamically expanding the context with
additional facts from the KG. It learns the representation of these facts
(entity alias, entity descriptions, etc.) using neural methods, supplementing
the sentential context. Unlike existing methods that statically use all
expanded facts, KGPool conditions this expansion on the sentence. We study the
efficacy of KGPool by evaluating it with different neural models and KGs
(Wikidata and NYT Freebase). Our experimental evaluation on standard datasets
shows that by feeding the KGPool representation into a Graph Neural Network,
the overall method is significantly more accurate than state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Look Wide and Interpret Twice: Improving Performance on Interactive Instruction-following Tasks. (arXiv:2106.00596v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Van-Quang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Suganuma_M/0/1/0/all/0/1">Masanori Suganuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Okatani_T/0/1/0/all/0/1">Takayuki Okatani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00596">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing interest in the community in making an embodied AI agent
perform a complicated task while interacting with an environment following
natural language directives. Recent studies have tackled the problem using
ALFRED, a well-designed dataset for the task, but achieved only very low
accuracy. This paper proposes a new method, which outperforms the previous
methods by a large margin. It is based on a combination of several new ideas.
One is a two-stage interpretation of the provided instructions. The method
first selects and interprets an instruction without using visual information,
yielding a tentative action sequence prediction. It then integrates the
prediction with the visual information etc., yielding the final prediction of
an action and an object. As the object&#x27;s class to interact is identified in the
first stage, it can accurately select the correct object from the input image.
Moreover, our method considers multiple egocentric views of the environment and
extracts essential information by applying hierarchical attention conditioned
on the current instruction. This contributes to the accurate prediction of
actions for navigation. A preliminary version of the method won the ALFRED
Challenge 2020. The current version achieves the unseen environment&#x27;s success
rate of 4.45% with a single view, which is further improved to 8.37% with
multiple views.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed&#x27;s competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Compression-Compilation Framework for On-mobile Real-time BERT Applications. (arXiv:2106.00526v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1">Zhenglun Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1">Jiexiong Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Caiwen Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00526">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based deep learning models have increasingly demonstrated high
accuracy on many natural language processing (NLP) tasks. In this paper, we
propose a compression-compilation co-design framework that can guarantee the
identified model to meet both resource and real-time specifications of mobile
devices. Our framework applies a compiler-aware neural architecture
optimization method (CANAO), which can generate the optimal compressed model
that balances both accuracy and latency. We are able to achieve up to 7.8x
speedup compared with TensorFlow-Lite with only minor accuracy loss. We present
two types of BERT applications on mobile devices: Question Answering (QA) and
Text Generation. Both can be executed in real-time with latency as low as 45ms.
Videos for demonstrating the framework can be found on
https://www.youtube.com/watch?v&#x3D;_WIRvK_2PZI</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed&#x27;s competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimax Regret for Bandit Convex Optimisation of Ridge Functions. (arXiv:2106.00444v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1">Tor Lattimore</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00444">
                                    <div class="article-summary-box-inner">
                                        <span>We analyse adversarial bandit convex optimisation with an adversary that is
restricted to playing functions of the form $f_t(x) &#x3D; g_t(\langle x,
\theta\rangle)$ for convex $g_t : \mathbb R \to \mathbb R$ and unknown $\theta
\in \mathbb R^d$ that is homogeneous over time. We provide a short
information-theoretic proof that the minimax regret is at most $O(d \sqrt{n}
\log(n \operatorname{diam}(\mathcal K)))$ where $n$ is the number of
interactions, $d$ the dimension and $\operatorname{diam}(\mathcal K)$ is the
diameter of the constraint set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OpenBox: A Generalized Black-box Optimization Service. (arXiv:2106.00421v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wentao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuanwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Huaijun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingchao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiawei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jinyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wentao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Bin Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00421">
                                    <div class="article-summary-box-inner">
                                        <span>Black-box optimization (BBO) has a broad range of applications, including
automatic machine learning, engineering, physics, and experimental design.
However, it remains a challenge for users to apply BBO methods to their
problems at hand with existing software packages, in terms of applicability,
performance, and efficiency. In this paper, we build OpenBox, an open-source
and general-purpose BBO service with improved usability. The modular design
behind OpenBox also facilitates flexible abstraction and optimization of basic
BBO components that are common in other existing systems. OpenBox is
distributed, fault-tolerant, and scalable. To improve efficiency, OpenBox
further utilizes &quot;algorithm agnostic&quot; parallelization and transfer learning.
Our experimental results demonstrate the effectiveness and efficiency of
OpenBox compared to existing systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anti-Koopmanism. (arXiv:2106.00106v2 [math.FA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gonzalez_E/0/1/0/all/0/1">Efrain Gonzalez</a>, <a href="http://arxiv.org/find/math/1/au:+Abudia_M/0/1/0/all/0/1">Moad Abudia</a>, <a href="http://arxiv.org/find/math/1/au:+Jury_M/0/1/0/all/0/1">Michael Jury</a>, <a href="http://arxiv.org/find/math/1/au:+Kamalapurkar_R/0/1/0/all/0/1">Rushikesh Kamalapurkar</a>, <a href="http://arxiv.org/find/math/1/au:+Rosenfeld_J/0/1/0/all/0/1">Joel A. Rosenfeld</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00106">
                                    <div class="article-summary-box-inner">
                                        <span>This article addresses several longstanding misconceptions concerning Koopman
operators, including the existence of lattices of eigenfunctions, common
eigenfunctions between Koopman operators, and boundedness and compactness of
Koopman operators, among others. Counterexamples are provided for each
misconception. This manuscript also proves that the Gaussian RBF&#x27;s native space
only supports bounded Koopman operator corresponding to affine dynamics, which
shows that the assumption of boundedness is very limiting. A framework for DMD
is presented that requires only densely defined Koopman operators over
reproducing kernel Hilbert spaces, and the effectiveness of this approach is
demonstrated through reconstruction examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-06-14T23:39:09.549Z">2021-06-14T23:39:09.549Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>